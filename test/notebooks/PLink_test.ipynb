{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/uoneway/Top2Vec/blob/master/notebooks/topic_modeling_hangil.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPFiI5MjQwQ9"
   },
   "source": [
    "# Topic Modeling\n",
    "김한길"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZnIXSSHnQov"
   },
   "source": [
    "## 기본 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "XDIAYabiQwRJ",
    "outputId": "bb52153c-043a-4e09-9d75-571bb2762218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter envirionment\n"
     ]
    }
   ],
   "source": [
    "# 필수 라이브러리 import\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import seaborn as sns\n",
    "# sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "if get_ipython():\n",
    "    print(\"jupyter envirionment\")\n",
    "    from tqdm import tqdm_notebook as tqdm  #이거 안해주면 한 줄씩 출력됨 ;;\n",
    "else:\n",
    "    print(\"command shell envirionment\")\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mon2-qIeuL_b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/lab13/prepo/submodules', '/home/lab13/prepo', '/home/lab13/prepo/test', '/home/lab13/prepo/test/notebooks', '/home/lab13/.conda/envs/top2vec/lib/python37.zip', '/home/lab13/.conda/envs/top2vec/lib/python3.7', '/home/lab13/.conda/envs/top2vec/lib/python3.7/lib-dynload', '', '/home/lab13/.local/lib/python3.7/site-packages', '/home/lab13/.conda/envs/top2vec/lib/python3.7/site-packages', '/home/lab13/.conda/envs/top2vec/lib/python3.7/site-packages/IPython/extensions', '/home/lab13/.ipython']\n"
     ]
    }
   ],
   "source": [
    "env = \"AWS\"\n",
    "\n",
    "if get_ipython():\n",
    "    if env == \"colab\":\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "\n",
    "        ROOT_DIR = \"/content/drive/My Drive/Colab Notebooks/\"\n",
    "        PROJECT_DIR = ROOT_DIR + \"project/202010_Prepo/\"\n",
    "    elif env == \"AWS\":\n",
    "        PROJECT_DIR = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "        sys.path.insert(0, PROJECT_DIR)\n",
    "        sys.path.insert(0, os.path.dirname(PROJECT_DIR))\n",
    "        sys.path.insert(0, os.path.dirname(PROJECT_DIR) + '/submodules')\n",
    "        print(sys.path)\n",
    "        \n",
    "    DATA_DIR = PROJECT_DIR + '/datasets/'\n",
    "    \n",
    "#     MODU_NEWSPAPER_DIR = ROOT_DIR + 'datasets/modu_corpus/NIKL_NEWSPAPER(v1.0)/'\n",
    "#     MODU_WEB_DIR = ROOT_DIR + 'datasets/modu_corpus/NIKL_WEB(v1.0)/'\n",
    "#     MODU_WRITTEN_DIR = ROOT_DIR + 'datasets/modu_corpus/NIKL_WRITTEN(v1.0)/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dHSPDaRwgAxU"
   },
   "outputs": [],
   "source": [
    "def save_obj(path, file_fullname, obj): \n",
    "    file_name, file_type = file_fullname.split('.')\n",
    "    file_path = path + file_fullname\n",
    "    \n",
    "    if file_type == 'pkl':\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(obj, f)\n",
    "    elif file_type == 'hkl':\n",
    "        hkl.dump(obj, file_path, mode='w')\n",
    "    elif file_type == 'txt':\n",
    "        with open(file_path, 'w') as f:\n",
    "            print(obj, file=f)\n",
    "        \n",
    "\n",
    "# Load data from file\n",
    "def load_obj(path, file_fullname):\n",
    "    file_name, file_type = file_fullname.split('.')\n",
    "    file_path = path + file_fullname\n",
    "    \n",
    "    if file_type == 'pkl':\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    elif file_type == 'hkl':\n",
    "        return hkl.load(file_path)\n",
    "\n",
    "# f = 'directory/filename.joblib'\n",
    "# joblib.dump(file_to_dump, f + '.bz2', compress=('bz2', 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_urls =[\"https://www.nytimes.com/2020/10/20/us/politics/stimulus-deal-mitch-mcconnell-nancy-pelosi.html?action=click&module=Top%20Stories&pgtype=Homepage\",\n",
    "        \"https://news.naver.com/main/ranking/read.nhn?mid=etc&sid1=111&rankingType=popular_day&oid=015&aid=0004435281&date=20201021&type=1&rankingSeq=7&rankingSectionId=101\",\n",
    "        \"https://planbs.tistory.com/entry/Git-Pull%EC%97%90%EC%84%9C-%EC%B6%A9%EB%8F%8C-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0\",\n",
    "        \"planbs.tistory.com/entry/Git-Pull%EC%97%90%EC%84%9C-%EC%B6%A9%EB%8F%8C-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0\",\n",
    "        \"www.nytimes.com/2020/10/20/us/politics/stimulus-deal-mitch-mcconnell-nancy-pelosi.html?action=click&module=Top%20Stories&pgtype=Homepage\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin, urlparse, parse_qs\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단순 url 추출기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "# url = re.findall(regex,string)       \n",
    "# return [x[0] for x in url] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### http/https 안붙은 경우, 붙여주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "http_reg = re.compile(\"https?://\\S*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_prefix_adder(url):\n",
    "    http_reg = re.compile(\"https?://\\S*\")\n",
    "    \n",
    "    if http_reg.match(url):\n",
    "        return url\n",
    "    else:\n",
    "        url_fixed = \"https://\" + url  #http로..?\n",
    "        # requests.get() # 잘되는지 체크가 필요하지만...    \n",
    "        return url_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://planbs.tistory.com/entry/Git-Pull%EC%97%90%EC%84%9C-%EC%B6%A9%EB%8F%8C-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_prefix_adder(test_urls[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if env == \"colab\":\n",
    "    !pip3 install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaper  # from newspaper import Article, Config\n",
    "from datetime import datetime\n",
    "# https://newspaper.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from langdetect import detect\n",
    "# # newspaper.languages()\n",
    "# newspaper_support_lang = set(['fi', 'ru', 'he', 'tr', 'mk', 'be', 'fa', 'vi', 'da', 'nb', 'es', 'en', 'et', 'pl', 'id', 'it', 'ro', 'sw', 'hi', 'de', 'sr', 'ja', 'bg', 'hu', 'no', 'sl', 'el', 'sv', 'zh', 'ar', 'ko', 'hr', 'nl', 'fr', 'pt', 'uk', ])\n",
    "# langdetect_support_lang = set(['af', 'ar', 'bg', 'bn', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et', 'fa', 'fi', 'fr', 'gu', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'kn', 'ko', 'lt', 'lv', 'mk', 'ml', 'mr', 'ne', 'nl', 'no', 'pa', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'so', 'sq', 'sv', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'uk', 'ur', 'vi', 'zh-cn', 'zh-tw',  ])\n",
    "# newspaper_not_support_lang = langdetect_support_lang - newspaper_support_lang\n",
    "# newspaper_not_support_lang\n",
    "\n",
    "# detect(\"螺\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(urls, idx=None):    \n",
    "    docs_info = []\n",
    "    docs_idx = []\n",
    "#     urls_cannot_parse = []\n",
    "    \n",
    "    if idx is not None:\n",
    "        assert len(idx) == len(urls), \"The length of urls and idx should be same.\"\n",
    "    doc_info = {}\n",
    "    urls = set(urls)\n",
    "    \n",
    "    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'\n",
    "    config = newspaper.Config()\n",
    "    config.browser_user_agent = user_agent\n",
    "\n",
    "    for i, url in tqdm(enumerate(urls), desc='scraper'):\n",
    "        url = url_prefix_adder(url)\n",
    "        article = newspaper.Article(url, config=config)  # , language='ko'\n",
    "\n",
    "        try:\n",
    "            article.download()  # request\n",
    "            article.parse()  # parsing\n",
    "            \n",
    "            doc_info = {\n",
    "                'title': article.title,\n",
    "    #             'authors': article.authors,\n",
    "                'publish_date': article.publish_date,\n",
    "                'contents': article.text,\n",
    "                'url': url,\n",
    "                'scrap_at': datetime.now(),\n",
    "                'is_news': article.is_valid_url(),\n",
    "    #             'top_image': article.top_image,\n",
    "    #             'movies': article.movies\n",
    "            }\n",
    "\n",
    "        except:\n",
    "            print(f\"Cannot parse, {url}\")\n",
    "            #urls_cannot_parse.append(url)\n",
    "            continue\n",
    "            \n",
    "        if doc_info['title'] == '' or doc_info['contents'] == '':\n",
    "            print(f\"Cannot get title or contents for {url}\")\n",
    "            #urls_cannot_parse.append(url)\n",
    "            continue\n",
    "        else:\n",
    "            docs_info.append(doc_info)\n",
    "        \n",
    "        if idx is not None:\n",
    "            docs_idx.append(idx[i])\n",
    "\n",
    "    print(f\"Complete scrape {len(docs_info)} among {len(urls)}\")\n",
    "        \n",
    "    return docs_info, docs_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e967f59c000c4eb494b88401138cc107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='scraper'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete scrape 5 among 5\n",
      "[{'title': 'McConnell Moves to Head Off Stimulus Deal as Pelosi Reports Progress', 'publish_date': datetime.datetime(2020, 10, 20, 0, 0), 'contents': 'Above all, Republicans fretted that a vote on such a package could interfere with their hasty timetable for confirming Judge Amy Coney Barrett to the Supreme Court by early next week. Mr. McConnell said he told the White House he was particularly concerned that a deal before then could inject unwanted unpredictability into the schedule, according to the four Republicans.\\n\\nTheir reservations suggested that even as a long-awaited stimulus deal between Democrats and the White House could be coming together, the aid still might have to wait until after Nov. 3.\\n\\n“The mechanics of getting the deal done would be challenging, to say the least,” Senator John Thune of South Dakota, the No. 2 Senate Republican, told reporters. He suggested that the “fog of the election” was warping the talks and would ultimately prevent any action before Nov. 3, adding that “people have gone to their battle stations.”\\n\\nMs. Pelosi appeared pleased with the direction of the talks, hailing what she described in a letter to Democrats on Tuesday evening as a productive dynamic in which “both sides are serious about finding a compromise.”\\n\\n“We’re not just down to a difference of language or a few dollars,” Mark Meadows, the White House chief of staff, warned in an interview on CNBC, declaring that Ms. Pelosi herself remained the biggest obstacle to a deal. “We still have a ways to go, but I would say that the conversations today were productive enough to continue to have discussions tomorrow.”\\n\\nThe latest White House offer would cost nearly $1.9 trillion, White House officials said, nearly four times the size of the $500 billion package that Senate Republicans hoped to advance on Wednesday in a bid to show voters that they were willing to provide some aid — just not what Democrats and Mr. Trump have been discussing. (Democrats were likely to object to the package as inadequate and prevent it from clearing the 60-vote threshold it would need to advance.)\\n\\nMr. McConnell’s remarks about a larger deal were described by four Republicans familiar with the discussion, who spoke on condition of anonymity to disclose details of a private closed lunch. He made it clear that he knew his counsel was likely to leak out, making reference to the possibility that his remarks could appear in the news media, two of the Republicans said.', 'url': 'https://www.nytimes.com/2020/10/20/us/politics/stimulus-deal-mitch-mcconnell-nancy-pelosi.html?action=click&module=Top%20Stories&pgtype=Homepage', 'scrap_at': datetime.datetime(2020, 10, 28, 15, 14, 44, 587547), 'is_news': True}, {'title': '[Git] Pull에서 충돌 해결하기', 'publish_date': datetime.datetime(2018, 5, 23, 10, 0, tzinfo=tzoffset(None, 32400)), 'contents': \"자신의 로컬 저장소에서 진행한 변경 이력을 원격 저장소에 push할 당시에, 로컬 저장소가 최신 버전이 아닌 경우(clone 이후 다른 사람이 remote에 push를 진행했을 경우) 자신의 push 요청이 거절됩니다. 이런 경우 병합(merge) 작업을 진행하여 remote에 반영된 다른 사람의 변경 이력을 로컬 저장소에 갱신해야 합니다. 원격 저장소의 변경 사항을 무시하고 자신의 변경 이력을 덮어쓸 수도 있습니다. 아래는 강제 push의 몇가지 예입니다.\\n\\n$ git push -f $ git push --force $ git push origin +<branch_name>\\n\\n그러나 강제 push를 할 일을 만드는 것은 정말 좋지 않은 일입니다. remote의 변경 이력을 로컬로 merge하는 것이 가장 좋습니다. 그냥 단순히 pull 만 하면 됩니다.\\n\\n$ git pull origin master\\n\\n문제될 상황이 없다면 git이 알아서 변경 사항을 통합해 줍니다. 여기서 문제 상황은 충돌(conflict) 인데, 예를 들어 로컬 저장소에서 README.md라는 파일을 변경했고, 가장 최근 로컬 저장소의 pull 이후 remote의 변경 이력에 README.md의 수정이 포함되어 있다면 충돌이 발생합니다.\\n\\n충돌 해결하기\\n\\n병합 기능은 경우에 따라 자동으로 병합할 수 없는 경우가 있고, 그 경우가 바로 충돌이며, 로컬 저장소의 변경 대상과 remote의 변경 대상이 같을 때 충돌이 발생한다고 했습니다. 두 변경 내용 중 어떤 것을 적용할 것인지 판단할 수 없기 때문입니다. 이 경우 git은 적용할 변경 내용의 판단을 개발자에게 맡깁니다. 따라서 충돌은 수동으로 수정해 주어야 합니다. 아래는 충돌이 난 파일의 예입니다.\\n\\n<<<<<<< HEAD Hello ======= Hello! >>>>>>> aab6d380aaf237a7c0aae28e00ea4607c8a7eec9\\n\\n'======='로 구분된 위쪽 부분이 로컬 저장소, 아래쪽 부분이 remote의 변경 내용입니다. 둘 중 어떤 변경 이력을 적용할 지 선택하고, 모든 충돌 부분을 수정한 이후 커밋을 수행하면 됩니다.\", 'url': 'https://planbs.tistory.com/entry/Git-Pull%EC%97%90%EC%84%9C-%EC%B6%A9%EB%8F%8C-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0', 'scrap_at': datetime.datetime(2020, 10, 28, 15, 14, 44, 806008), 'is_news': False}, {'title': 'McConnell Moves to Head Off Stimulus Deal as Pelosi Reports Progress', 'publish_date': datetime.datetime(2020, 10, 20, 0, 0), 'contents': 'Above all, Republicans fretted that a vote on such a package could interfere with their hasty timetable for confirming Judge Amy Coney Barrett to the Supreme Court by early next week. Mr. McConnell said he told the White House he was particularly concerned that a deal before then could inject unwanted unpredictability into the schedule, according to the four Republicans.\\n\\nTheir reservations suggested that even as a long-awaited stimulus deal between Democrats and the White House could be coming together, the aid still might have to wait until after Nov. 3.\\n\\n“The mechanics of getting the deal done would be challenging, to say the least,” Senator John Thune of South Dakota, the No. 2 Senate Republican, told reporters. He suggested that the “fog of the election” was warping the talks and would ultimately prevent any action before Nov. 3, adding that “people have gone to their battle stations.”\\n\\nMs. Pelosi appeared pleased with the direction of the talks, hailing what she described in a letter to Democrats on Tuesday evening as a productive dynamic in which “both sides are serious about finding a compromise.”\\n\\n“We’re not just down to a difference of language or a few dollars,” Mark Meadows, the White House chief of staff, warned in an interview on CNBC, declaring that Ms. Pelosi herself remained the biggest obstacle to a deal. “We still have a ways to go, but I would say that the conversations today were productive enough to continue to have discussions tomorrow.”\\n\\nThe latest White House offer would cost nearly $1.9 trillion, White House officials said, nearly four times the size of the $500 billion package that Senate Republicans hoped to advance on Wednesday in a bid to show voters that they were willing to provide some aid — just not what Democrats and Mr. Trump have been discussing. (Democrats were likely to object to the package as inadequate and prevent it from clearing the 60-vote threshold it would need to advance.)\\n\\nMr. McConnell’s remarks about a larger deal were described by four Republicans familiar with the discussion, who spoke on condition of anonymity to disclose details of a private closed lunch. He made it clear that he knew his counsel was likely to leak out, making reference to the possibility that his remarks could appear in the news media, two of the Republicans said.', 'url': 'https://www.nytimes.com/2020/10/20/us/politics/stimulus-deal-mitch-mcconnell-nancy-pelosi.html?action=click&module=Top%20Stories&pgtype=Homepage', 'scrap_at': datetime.datetime(2020, 10, 28, 15, 14, 45, 112399), 'is_news': True}, {'title': '[Git] Pull에서 충돌 해결하기', 'publish_date': datetime.datetime(2018, 5, 23, 10, 0, tzinfo=tzoffset(None, 32400)), 'contents': \"자신의 로컬 저장소에서 진행한 변경 이력을 원격 저장소에 push할 당시에, 로컬 저장소가 최신 버전이 아닌 경우(clone 이후 다른 사람이 remote에 push를 진행했을 경우) 자신의 push 요청이 거절됩니다. 이런 경우 병합(merge) 작업을 진행하여 remote에 반영된 다른 사람의 변경 이력을 로컬 저장소에 갱신해야 합니다. 원격 저장소의 변경 사항을 무시하고 자신의 변경 이력을 덮어쓸 수도 있습니다. 아래는 강제 push의 몇가지 예입니다.\\n\\n$ git push -f $ git push --force $ git push origin +<branch_name>\\n\\n그러나 강제 push를 할 일을 만드는 것은 정말 좋지 않은 일입니다. remote의 변경 이력을 로컬로 merge하는 것이 가장 좋습니다. 그냥 단순히 pull 만 하면 됩니다.\\n\\n$ git pull origin master\\n\\n문제될 상황이 없다면 git이 알아서 변경 사항을 통합해 줍니다. 여기서 문제 상황은 충돌(conflict) 인데, 예를 들어 로컬 저장소에서 README.md라는 파일을 변경했고, 가장 최근 로컬 저장소의 pull 이후 remote의 변경 이력에 README.md의 수정이 포함되어 있다면 충돌이 발생합니다.\\n\\n충돌 해결하기\\n\\n병합 기능은 경우에 따라 자동으로 병합할 수 없는 경우가 있고, 그 경우가 바로 충돌이며, 로컬 저장소의 변경 대상과 remote의 변경 대상이 같을 때 충돌이 발생한다고 했습니다. 두 변경 내용 중 어떤 것을 적용할 것인지 판단할 수 없기 때문입니다. 이 경우 git은 적용할 변경 내용의 판단을 개발자에게 맡깁니다. 따라서 충돌은 수동으로 수정해 주어야 합니다. 아래는 충돌이 난 파일의 예입니다.\\n\\n<<<<<<< HEAD Hello ======= Hello! >>>>>>> aab6d380aaf237a7c0aae28e00ea4607c8a7eec9\\n\\n'======='로 구분된 위쪽 부분이 로컬 저장소, 아래쪽 부분이 remote의 변경 내용입니다. 둘 중 어떤 변경 이력을 적용할 지 선택하고, 모든 충돌 부분을 수정한 이후 커밋을 수행하면 됩니다.\", 'url': 'https://planbs.tistory.com/entry/Git-Pull%EC%97%90%EC%84%9C-%EC%B6%A9%EB%8F%8C-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0', 'scrap_at': datetime.datetime(2020, 10, 28, 15, 14, 45, 303084), 'is_news': False}, {'title': '빅히트 주가 급락하자…\"수상한 공모가\" 국민청원까지 등장', 'publish_date': None, 'contents': '방탄소년단(BTS)의 소속사 빅히트. 연합뉴스 방탄소년단(BTS)의 소속사 빅히트. 연합뉴스\\n\\n빅히트엔터테인먼트가 유가증권시장 상장 이후 큰 폭으로 하락한 가운데 빅히트의 공모가격 산정을 두고 의혹을 제기하는 청와대 국민 청원글이 게재됐다.21일 청와대 국민청원 게시판에 따르면 지난 19일 \\'빅히트엔터테인먼트의 공모가격 어떻게 결정되었는지 밝혀주세요\\'라는 청원글이 게재됐다. 해당 청원의 마감일은 내달 18일, 현재 참여한 인원은 122명이다.해당 청원글의 작성자는 \"빅히트 소속가수 방탄소년단(BTS)은 세계에서 가장 유명하고 영향력 있는 대한민국의 가수\"라며 \"빅히트란 회사가 멋지게 코스피에 상장하게 됐고 BTS를 아끼고 사랑하는 팬들 혹은 투자자들이 많은 관심과 지지를 하고 있다\"며 글을 시작했다.이어 \"하지만 상장 2일 만에 언론매체는 빅히트 거품이라는 기사와 함께 BTS 군대문제 등을 문제삼아 기사화 하고 있다\"며 \"투자의 책임은 당연히 본인이 지는 것이 맞지만, 이번 경우는 많이 다른 듯 하다\"며 의혹을 제기했다.그는 \"아이돌 및 연예인의 군입대 관련한 법 개정등 굉장히 민감한 상황이 포함된 문제인듯 하다\"며 \"마치 계획이라도 된듯 문제점을 알고도 공모가격이 부풀려졌고, 팬들은 단순히 회사와 언론을 믿고 이틀 만에 투자금액의 절반을 잃었다\"고 토로했다.작성자는 \"빅히트 공모가는 터무니 없이 거품이 끼었다고 언론에서 보도를 하고 있다\"며 \"일각에서는 조희팔 사건과 옵티머스자산운용 사건 등 사기 사건과 비교하고 있다\"고 지적했다.그러면서 \"세계에서 가장 사랑받는 가수를 앞세워 터무니 없는 가격으로 물건을 파는 형태와 무엇이 다른지 의구심이 든다\"며 \"모든 국민이 궁금해하는 빅히트의 가격 어떻게 결정되고 기준은 무엇인지 명명백백 밝혀주길 바란다\"고 부연했다.이날 오후 1시21분 현재 빅히트는 전날보다 1500원(0.55%) 오른 18만4000원에 거래되고 있다. 상장 5거래일 만에 반등이다. 지난 15일 상장한 빅히트는 상장 첫날 4% 떨어진 데 이어 이튿 날엔 22% 넘게 떨어졌다. 이후 19~20일 각각 5%, 3%대로 급락했다.이송렬 한경닷컴 기자 yisr0203@hankyung.comⓒ 한국경제 & hankyung.com , 무단전재 및 재배포 금지', 'url': 'https://news.naver.com/main/ranking/read.nhn?mid=etc&sid1=111&rankingType=popular_day&oid=015&aid=0004435281&date=20201021&type=1&rankingSeq=7&rankingSectionId=101', 'scrap_at': datetime.datetime(2020, 10, 28, 15, 14, 45, 606498), 'is_news': False}]\n",
      "[1, 2, 3, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "docs_info, docs_idx = scraper(test_urls, [1,2,3,5,7])\n",
    "print(docs_info)\n",
    "print(docs_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2IpZL-Avd9Z"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7puX76dZRLW"
   },
   "source": [
    "### Removing Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "PdV8U3eFeBg1",
    "outputId": "b6cc6503-80bd-4ff2-bd13-c3ebd75feb31"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus 32 f f23 3344 22324 dfgd dfdg22324dfgd 22324 dfgd 22324 $%fgd 2 d d3 '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 공백 이후 숫자로 시작하는 경우만(문자+숫자+문자, 문자+숫자 케이스는 제외), 해당 숫자와 그 뒤 문자를 분리\n",
    "clean = re.compile(r'(\\s\\d+)([^\\d\\s])')\n",
    "corpus = re.sub(clean, r'\\1 \\2', \"corpus 32f f23 3344 22324dfgd dfdg22324dfgd 22324dfgd 22324$%fgd 2d d3 \")\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' corpus 3 2 f f23 3 3 4 4 2 2 3 2 4 dfgd dfdg22324dfgd 2 2 3 2 4 dfgd 2 2 3 2 4 $%fgd 2 d d3'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 공백으로 sentence를 분리 후 숫자인경우만 공백 넣어주기\n",
    "#numbers_reg = re.compile(\"\\s\\d{2,}\\s\")\n",
    "sentence = ''\n",
    "input='corpus 32 f f23 3344 22324 dfgd dfdg22324dfgd 22324 dfgd 22324 $%fgd 2 d d3 '\n",
    "for token in input.split():\n",
    "    if token.isnumeric():\n",
    "        token = ' '.join(token)\n",
    "    sentence+=' '+token\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' corpus 3 2 f f23 3 3 4 4 2 2 3 2 4 dfgd dfdg22324dfgd 2 2 3 2 4 dfgd 2 2 3 2 4 $%fgd 2 d d3'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def number_splitter(sentence):\n",
    "    # 1. 공백 이후 숫자로 시작하는 경우만(문자+숫자+문자, 문자+숫자 케이스는 제외), 해당 숫자와 그 뒤 문자를 분리\n",
    "    num_str_pattern = re.compile(r'(\\s\\d+)([^\\d\\s])')\n",
    "    sentence = re.sub(num_str_pattern, r'\\1 \\2', sentence)\n",
    "\n",
    "    # 2. 공백으로 sentence를 분리 후 숫자인경우만 공백 넣어주기\n",
    "    #numbers_reg = re.compile(\"\\s\\d{2,}\\s\")\n",
    "    sentence_fixed = ''\n",
    "    for token in sentence.split():\n",
    "        if token.isnumeric():\n",
    "            token = ' '.join(token)\n",
    "        sentence_fixed+=' '+token\n",
    "    return sentence_fixed\n",
    "\n",
    "number_splitter(\"corpus 32f f23 3344 22324dfgd dfdg22324dfgd 22324dfgd 22324$%fgd 2d d3 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Q-fP8gPWZRlR",
    "outputId": "08fcae8a-c6ff-4276-aad6-87469f0ec9db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" sdf 2 3 4 3 2 ''`!@#$%^&*(es 2 3 URL sdfs ww f23 3 3 4 4 2 2 3 2 4 dfgd dfdg22324dfgd 우리 3 한국\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE 삭제 추가 등등\n",
    "\n",
    "def noise_remover(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    # url 대체\n",
    "    url_pattern = re.compile(r'https?://\\S*|www\\.\\S*')\n",
    "    text = url_pattern.sub(r'URL', text)\n",
    "\n",
    "    # html 삭제\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text(separator=\" \")\n",
    "\n",
    "    # 숫자 삭제\n",
    "    text = number_splitter(text)\n",
    "    #number_pattern = re.compile('\\w*\\d\\w*') \n",
    "#     number_pattern = re.compile('\\d+') \n",
    "#     text = number_pattern.sub(r'[[NUMBER]]', text)\n",
    "    \n",
    "\n",
    "    # PUCTUACTION_TO_REMOVED = string.punctuation.translate(str.maketrans('', '', '\\\"\\'#$%&\\\\@'))  # !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ 중 적은것을 제외한 나머지를 삭제\n",
    "    # text = text.translate(str.maketrans(PUCTUACTION_TO_REMOVED, ' '*len(PUCTUACTION_TO_REMOVED))) \n",
    "\n",
    "    # remove_redundant_white_spaces\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    return text\n",
    "temp_text = \"sdf 23432''`!@#$%^&*(es 23 http://sdf.com/sdf/ <img src=sdf> sdfs ww f23 3344 22324dfgd dfdg22324dfgd 우리 3한국\"\n",
    "noise_remover(temp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "56HwZaqkgGGN",
    "outputId": "9054dbc0-0613-4621-ae7c-70f3a39b9a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자신의 로컬 저장소에서 진행한 변경 이력을 원격 저장소에 push할 당시에, 로컬 저장소가 최신 버전이 아닌 경우(clone 이후 다른 사람이 remote에 push를 진행했을 경우) 자신의 push 요청이 거절됩니다. 이런 경우 병합(merge) 작업을 진행하여 remote에 반영된 다른 사람의 변경 이력을 로컬 저장소에 갱신해야 합니다. 원격 저장소의 변경 사항을 무시하고 자신의 변경 이력을 덮어쓸 수도 있습니다. 아래는 강제 push의 몇가지 예입니다.\n",
      "\n",
      "$ git push -f $ git push --force $ git push origin +<branch_name>\n",
      "\n",
      "그러나 강제 push를 할 일을 만드는 것은 정말 좋지 않은 일입니다. remote의 변경 이력을 로컬로 merge하는 것이 가장 좋습니다. 그냥 단순히 pull 만 하면 됩니다.\n",
      "\n",
      "$ git pull origin master\n",
      "\n",
      "문제될 상황이 없다면 git이 알아서 변경 사항을 통합해 줍니다. 여기서 문제 상황은 충돌(conflict) 인데, 예를 들어 로컬 저장소에서 README.md라는 파일을 변경했고, 가장 최근 로컬 저장소의 pull 이후 remote의 변경 이력에 README.md의 수정이 포함되어 있다면 충돌이 발생합니다.\n",
      "\n",
      "충돌 해결하기\n",
      "\n",
      "병합 기능은 경우에 따라 자동으로 병합할 수 없는 경우가 있고, 그 경우가 바로 충돌이며, 로컬 저장소의 변경 대상과 remote의 변경 대상이 같을 때 충돌이 발생한다고 했습니다. 두 변경 내용 중 어떤 것을 적용할 것인지 판단할 수 없기 때문입니다. 이 경우 git은 적용할 변경 내용의 판단을 개발자에게 맡깁니다. 따라서 충돌은 수동으로 수정해 주어야 합니다. 아래는 충돌이 난 파일의 예입니다.\n",
      "\n",
      "<<<<<<< HEAD Hello ======= Hello! >>>>>>> aab6d380aaf237a7c0aae28e00ea4607c8a7eec9\n",
      "\n",
      "'======='로 구분된 위쪽 부분이 로컬 저장소, 아래쪽 부분이 remote의 변경 내용입니다. 둘 중 어떤 변경 이력을 적용할 지 선택하고, 모든 충돌 부분을 수정한 이후 커밋을 수행하면 됩니다.\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" 자신의 로컬 저장소에서 진행한 변경 이력을 원격 저장소에 push할 당시에, 로컬 저장소가 최신 버전이 아닌 경우(clone 이후 다른 사람이 remote에 push를 진행했을 경우) 자신의 push 요청이 거절됩니다. 이런 경우 병합(merge) 작업을 진행하여 remote에 반영된 다른 사람의 변경 이력을 로컬 저장소에 갱신해야 합니다. 원격 저장소의 변경 사항을 무시하고 자신의 변경 이력을 덮어쓸 수도 있습니다. 아래는 강제 push의 몇가지 예입니다. $ git push -f $ git push --force $ git push origin + 그러나 강제 push를 할 일을 만드는 것은 정말 좋지 않은 일입니다. remote의 변경 이력을 로컬로 merge하는 것이 가장 좋습니다. 그냥 단순히 pull 만 하면 됩니다. $ git pull origin master 문제될 상황이 없다면 git이 알아서 변경 사항을 통합해 줍니다. 여기서 문제 상황은 충돌(conflict) 인데, 예를 들어 로컬 저장소에서 readme.md라는 파일을 변경했고, 가장 최근 로컬 저장소의 pull 이후 remote의 변경 이력에 readme.md의 수정이 포함되어 있다면 충돌이 발생합니다. 충돌 해결하기 병합 기능은 경우에 따라 자동으로 병합할 수 없는 경우가 있고, 그 경우가 바로 충돌이며, 로컬 저장소의 변경 대상과 remote의 변경 대상이 같을 때 충돌이 발생한다고 했습니다. 두 변경 내용 중 어떤 것을 적용할 것인지 판단할 수 없기 때문입니다. 이 경우 git은 적용할 변경 내용의 판단을 개발자에게 맡깁니다. 따라서 충돌은 수동으로 수정해 주어야 합니다. 아래는 충돌이 난 파일의 예입니다. <<<<<<< head hello ======= hello! >>>>>>> aab6d380aaf237a7c0aae28e00ea4607c8a7eec9 '======='로 구분된 위쪽 부분이 로컬 저장소, 아래쪽 부분이 remote의 변경 내용입니다. 둘 중 어떤 변경 이력을 적용할 지 선택하고, 모든 충돌 부분을 수정한 이후 커밋을 수행하면 됩니다.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(docs_info[3]['contents'])\n",
    "print(\"-------------------------------------\")\n",
    "doc_p = noise_remover(docs_info[3]['contents'])\n",
    "doc_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrOmtHiUxRro"
   },
   "source": [
    "##### 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wINtKzSs6b6X"
   },
   "source": [
    "https://docs.google.com/spreadsheets/d/1-9blXKjtjeKZqsf4NzHeYJCrr49-nXeRF6D80udfcwY/edit#gid=589544265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "DvHiYN26E2hw"
   },
   "outputs": [],
   "source": [
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "jhgoOGRlzwt0",
    "outputId": "8342a840-da4f-4eb6-d215-91b60f367077"
   },
   "outputs": [],
   "source": [
    "def korean_tokenizer(text, use_tags=None, print_tag=False): \n",
    "    tokenizer = MeCab.Tagger(\"-d /usr/local/lib/mecab/dic/mecab-ko-dic\")\n",
    "    parsed = tokenizer.parse(text)\n",
    "    word_tag = [w for w in parsed.split(\"\\n\")]\n",
    "    result = []\n",
    "    \n",
    "    if use_tags:\n",
    "        for word_ in word_tag[:-2]:\n",
    "            word = word_.split(\"\\t\")\n",
    "            tag = word[1].split(\",\")[0]\n",
    "\n",
    "            if(tag in use_tags):     \n",
    "                if print_tag:\n",
    "                    result.append((word[0], tag))\n",
    "                else:\n",
    "                    result.append(word[0]) \n",
    "    else:\n",
    "        for word_ in word_tag[:-2]:\n",
    "            word = word_.split(\"\\t\")\n",
    "            result.append(word[0]) \n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" 자신의 로컬 저장소에서 진행한 변경 이력을 원격 저장소에 push할 당시에, 로컬 저장소가 최신 버전이 아닌 경우(clone 이후 다른 사람이 remote에 push를 진행했을 경우) 자신의 push 요청이 거절됩니다. 이런 경우 병합(merge) 작업을 진행하여 remote에 반영된 다른 사람의 변경 이력을 로컬 저장소에 갱신해야 합니다. 원격 저장소의 변경 사항을 무시하고 자신의 변경 이력을 덮어쓸 수도 있습니다. 아래는 강제 push의 몇가지 예입니다. $ git push -f $ git push --force $ git push origin + 그러나 강제 push를 할 일을 만드는 것은 정말 좋지 않은 일입니다. remote의 변경 이력을 로컬로 merge하는 것이 가장 좋습니다. 그냥 단순히 pull 만 하면 됩니다. $ git pull origin master 문제될 상황이 없다면 git이 알아서 변경 사항을 통합해 줍니다. 여기서 문제 상황은 충돌(conflict) 인데, 예를 들어 로컬 저장소에서 readme.md라는 파일을 변경했고, 가장 최근 로컬 저장소의 pull 이후 remote의 변경 이력에 readme.md의 수정이 포함되어 있다면 충돌이 발생합니다. 충돌 해결하기 병합 기능은 경우에 따라 자동으로 병합할 수 없는 경우가 있고, 그 경우가 바로 충돌이며, 로컬 저장소의 변경 대상과 remote의 변경 대상이 같을 때 충돌이 발생한다고 했습니다. 두 변경 내용 중 어떤 것을 적용할 것인지 판단할 수 없기 때문입니다. 이 경우 git은 적용할 변경 내용의 판단을 개발자에게 맡깁니다. 따라서 충돌은 수동으로 수정해 주어야 합니다. 아래는 충돌이 난 파일의 예입니다. <<<<<<< head hello ======= hello! >>>>>>> aab6d380aaf237a7c0aae28e00ea4607c8a7eec9 '======='로 구분된 위쪽 부분이 로컬 저장소, 아래쪽 부분이 remote의 변경 내용입니다. 둘 중 어떤 변경 이력을 적용할 지 선택하고, 모든 충돌 부분을 수정한 이후 커밋을 수행하면 됩니다.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['자신',\n",
       " '의',\n",
       " '로컬',\n",
       " '저',\n",
       " '장소',\n",
       " '에서',\n",
       " '진행',\n",
       " '한',\n",
       " '변경',\n",
       " '이력',\n",
       " '을',\n",
       " '원격',\n",
       " '저',\n",
       " '장소',\n",
       " '에',\n",
       " 'push',\n",
       " '할',\n",
       " '당시',\n",
       " '에',\n",
       " ',',\n",
       " '로컬',\n",
       " '저',\n",
       " '장소',\n",
       " '가',\n",
       " '최신',\n",
       " '버전',\n",
       " '이',\n",
       " '아닌',\n",
       " '경우',\n",
       " '(',\n",
       " 'clone',\n",
       " '이후',\n",
       " '다른',\n",
       " '사람',\n",
       " '이',\n",
       " 'remote',\n",
       " '에',\n",
       " 'push',\n",
       " '를',\n",
       " '진행',\n",
       " '했',\n",
       " '을',\n",
       " '경우',\n",
       " ')',\n",
       " '자신',\n",
       " '의',\n",
       " 'push',\n",
       " '요청',\n",
       " '이',\n",
       " '거절',\n",
       " '됩니다',\n",
       " '.',\n",
       " '이런',\n",
       " '경우',\n",
       " '병합',\n",
       " '(',\n",
       " 'merge',\n",
       " ')',\n",
       " '작업',\n",
       " '을',\n",
       " '진행',\n",
       " '하',\n",
       " '여',\n",
       " 'remote',\n",
       " '에',\n",
       " '반영',\n",
       " '된',\n",
       " '다른',\n",
       " '사람',\n",
       " '의',\n",
       " '변경',\n",
       " '이력',\n",
       " '을',\n",
       " '로컬',\n",
       " '저',\n",
       " '장소',\n",
       " '에',\n",
       " '갱신',\n",
       " '해야',\n",
       " '합니다',\n",
       " '.',\n",
       " '원격',\n",
       " '저',\n",
       " '장소',\n",
       " '의',\n",
       " '변경',\n",
       " '사항',\n",
       " '을',\n",
       " '무시',\n",
       " '하',\n",
       " '고',\n",
       " '자신',\n",
       " '의',\n",
       " '변경',\n",
       " '이력',\n",
       " '을',\n",
       " '덮',\n",
       " '어',\n",
       " '쓸',\n",
       " '수',\n",
       " '도',\n",
       " '있',\n",
       " '습니다',\n",
       " '.',\n",
       " '아래',\n",
       " '는',\n",
       " '강제',\n",
       " 'push',\n",
       " '의',\n",
       " '몇',\n",
       " '가지',\n",
       " '예',\n",
       " '입니다',\n",
       " '.',\n",
       " '$',\n",
       " 'git',\n",
       " 'push',\n",
       " '-',\n",
       " 'f',\n",
       " '$',\n",
       " 'git',\n",
       " 'push',\n",
       " '--',\n",
       " 'force',\n",
       " '$',\n",
       " 'git',\n",
       " 'push',\n",
       " 'origin',\n",
       " '+',\n",
       " '그러나',\n",
       " '강제',\n",
       " 'push',\n",
       " '를',\n",
       " '할',\n",
       " '일',\n",
       " '을',\n",
       " '만드',\n",
       " '는',\n",
       " '것',\n",
       " '은',\n",
       " '정말',\n",
       " '좋',\n",
       " '지',\n",
       " '않',\n",
       " '은',\n",
       " '일',\n",
       " '입니다',\n",
       " '.',\n",
       " 'remote',\n",
       " '의',\n",
       " '변경',\n",
       " '이력',\n",
       " '을',\n",
       " '로컬',\n",
       " '로',\n",
       " 'merge',\n",
       " '하',\n",
       " '는',\n",
       " '것',\n",
       " '이',\n",
       " '가장',\n",
       " '좋',\n",
       " '습니다',\n",
       " '.',\n",
       " '그냥',\n",
       " '단순히',\n",
       " 'pull',\n",
       " '만',\n",
       " '하',\n",
       " '면',\n",
       " '됩니다',\n",
       " '.',\n",
       " '$',\n",
       " 'git',\n",
       " 'pull',\n",
       " 'origin',\n",
       " 'master',\n",
       " '문제',\n",
       " '될',\n",
       " '상황',\n",
       " '이',\n",
       " '없',\n",
       " '다면',\n",
       " 'git',\n",
       " '이',\n",
       " '알',\n",
       " '아서',\n",
       " '변경',\n",
       " '사항',\n",
       " '을',\n",
       " '통합',\n",
       " '해',\n",
       " '줍니다',\n",
       " '.',\n",
       " '여기',\n",
       " '서',\n",
       " '문제',\n",
       " '상황',\n",
       " '은',\n",
       " '충돌',\n",
       " '(',\n",
       " 'conflict',\n",
       " ')',\n",
       " '인데',\n",
       " ',',\n",
       " '예',\n",
       " '를',\n",
       " '들',\n",
       " '어',\n",
       " '로컬',\n",
       " '저',\n",
       " '장소',\n",
       " '에서',\n",
       " 'readme',\n",
       " '.',\n",
       " 'md',\n",
       " '라는',\n",
       " '파일',\n",
       " '을',\n",
       " '변경',\n",
       " '했',\n",
       " '고',\n",
       " ',',\n",
       " '가장',\n",
       " '최근',\n",
       " '로컬',\n",
       " '저',\n",
       " '장소',\n",
       " '의',\n",
       " 'pull',\n",
       " '이후',\n",
       " 'remote',\n",
       " '의',\n",
       " '변경',\n",
       " '이력',\n",
       " '에',\n",
       " 'readme',\n",
       " '.',\n",
       " 'md',\n",
       " '의',\n",
       " '수정',\n",
       " '이',\n",
       " '포함',\n",
       " '되',\n",
       " '어',\n",
       " '있',\n",
       " '다면',\n",
       " '충돌',\n",
       " '이',\n",
       " '발생',\n",
       " '합니다',\n",
       " '.',\n",
       " '충돌',\n",
       " '해결',\n",
       " '하',\n",
       " '기',\n",
       " '병합',\n",
       " '기능',\n",
       " '은',\n",
       " '경우',\n",
       " '에',\n",
       " '따라',\n",
       " '자동',\n",
       " '으로',\n",
       " '병합',\n",
       " '할',\n",
       " '수',\n",
       " '없',\n",
       " '는',\n",
       " '경우',\n",
       " '가',\n",
       " '있',\n",
       " '고',\n",
       " ',',\n",
       " '그',\n",
       " '경우',\n",
       " '가',\n",
       " '바로',\n",
       " '충돌',\n",
       " '이',\n",
       " '며',\n",
       " ',',\n",
       " '로컬',\n",
       " '저',\n",
       " '장소',\n",
       " '의',\n",
       " '변경',\n",
       " '대상',\n",
       " '과',\n",
       " 'remote',\n",
       " '의',\n",
       " '변경',\n",
       " '대상',\n",
       " '이',\n",
       " '같',\n",
       " '을',\n",
       " '때',\n",
       " '충돌',\n",
       " '이',\n",
       " '발생',\n",
       " '한다고',\n",
       " '했',\n",
       " '습니다',\n",
       " '.',\n",
       " '두',\n",
       " '변경',\n",
       " '내용',\n",
       " '중',\n",
       " '어떤',\n",
       " '것',\n",
       " '을',\n",
       " '적용',\n",
       " '할',\n",
       " '것',\n",
       " '인지',\n",
       " '판단',\n",
       " '할',\n",
       " '수',\n",
       " '없',\n",
       " '기',\n",
       " '때문',\n",
       " '입니다',\n",
       " '.',\n",
       " '이',\n",
       " '경우',\n",
       " 'git',\n",
       " '은',\n",
       " '적용',\n",
       " '할',\n",
       " '변경',\n",
       " '내용',\n",
       " '의',\n",
       " '판단',\n",
       " '을',\n",
       " '개발자',\n",
       " '에게',\n",
       " '맡깁니다',\n",
       " '.',\n",
       " '따라서',\n",
       " '충돌',\n",
       " '은',\n",
       " '수동',\n",
       " '으로',\n",
       " '수정',\n",
       " '해',\n",
       " '주',\n",
       " '어야',\n",
       " '합니다',\n",
       " '.',\n",
       " '아래',\n",
       " '는',\n",
       " '충돌',\n",
       " '이',\n",
       " '난',\n",
       " '파일',\n",
       " '의',\n",
       " '예',\n",
       " '입니다',\n",
       " '.',\n",
       " '<<<<<<<',\n",
       " 'head',\n",
       " 'hello',\n",
       " '=======',\n",
       " 'hello',\n",
       " '!',\n",
       " '>>>>>>>',\n",
       " 'aab',\n",
       " '6',\n",
       " 'd',\n",
       " '380',\n",
       " 'aaf',\n",
       " '237',\n",
       " 'a',\n",
       " '7',\n",
       " 'c',\n",
       " '0',\n",
       " 'aae',\n",
       " '28',\n",
       " 'e',\n",
       " '00',\n",
       " 'ea',\n",
       " '4607',\n",
       " 'c',\n",
       " '8',\n",
       " 'a',\n",
       " '7',\n",
       " 'eec',\n",
       " '9',\n",
       " \"'======='\",\n",
       " '로',\n",
       " '구분',\n",
       " '된',\n",
       " '위쪽',\n",
       " '부분',\n",
       " '이',\n",
       " '로컬',\n",
       " '저',\n",
       " '장소',\n",
       " ',',\n",
       " '아래쪽',\n",
       " '부분',\n",
       " '이',\n",
       " 'remote',\n",
       " '의',\n",
       " '변경',\n",
       " '내용',\n",
       " '입니다',\n",
       " '.',\n",
       " '둘',\n",
       " '중',\n",
       " '어떤',\n",
       " '변경',\n",
       " '이력',\n",
       " '을',\n",
       " '적용',\n",
       " '할',\n",
       " '지',\n",
       " '선택',\n",
       " '하',\n",
       " '고',\n",
       " ',',\n",
       " '모든',\n",
       " '충돌',\n",
       " '부분',\n",
       " '을',\n",
       " '수정',\n",
       " '한',\n",
       " '이후',\n",
       " '커',\n",
       " '밋',\n",
       " '을',\n",
       " '수행',\n",
       " '하',\n",
       " '면',\n",
       " '됩니다',\n",
       " '.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = ['NNG','NNP','NNBC', 'NR', # 일반 명사, 고유 명사, 단위를 나타내는 명사, 수사, \n",
    "            'VV','VA','VCP','VCN',   # 동사, 긍정 지정사, 부정 지정사\n",
    "            'XR',   # 어근, 붙임표(물결,숨김,빠짐)/기타기호 (논리수학기호,화폐기호) 'SY',\n",
    "            'SL', 'SH', ]  # 외국어, 한자, 숫자'SN'\n",
    "\n",
    "\n",
    "#doc_pt = my_tokenizer(doc_p, tags, True)\n",
    "doc_pt = korean_tokenizer(doc_p)\n",
    "doc_pt\n",
    "# m = MeCab.Tagger(\"-d /usr/local/lib/mecab/dic/mecab-ko-dic\")\n",
    "# m.parse(simple_preprocessor(test_text)).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124,
     "referenced_widgets": [
      "63adeffb86684943a2bd8cea2b9a65c2",
      "2104b0d692904fb0a10744008a6111ac",
      "956e6fc808f249e390b438c1fea99af9",
      "9fb75f0165144e8eb9177b1a69fb093e",
      "eb7e80a40e5f45baaf621e65dccd9de4",
      "208ab8fb8c684db893617675f1d16873",
      "5795b03651b44eb191a100983995469b",
      "0fe26c0a5cab401496e73eba458f8418"
     ]
    },
    "id": "KCHTn6zTviZL",
    "outputId": "12c770f4-e747-4937-85ca-383073782c20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"자신 의 로컬 저 장소 에서 진행 한 변경 이력 을 원격 저 장소 에 push 할 당시 에 , 로컬 저 장소 가 최신 버전 이 아닌 경우 ( clone 이후 다른 사람 이 remote 에 push 를 진행 했 을 경우 ) 자신 의 push 요청 이 거절 됩니다 . 이런 경우 병합 ( merge ) 작업 을 진행 하 여 remote 에 반영 된 다른 사람 의 변경 이력 을 로컬 저 장소 에 갱신 해야 합니다 . 원격 저 장소 의 변경 사항 을 무시 하 고 자신 의 변경 이력 을 덮 어 쓸 수 도 있 습니다 . 아래 는 강제 push 의 몇 가지 예 입니다 . $ git push - f $ git push -- force $ git push origin + 그러나 강제 push 를 할 일 을 만드 는 것 은 정말 좋 지 않 은 일 입니다 . remote 의 변경 이력 을 로컬 로 merge 하 는 것 이 가장 좋 습니다 . 그냥 단순히 pull 만 하 면 됩니다 . $ git pull origin master 문제 될 상황 이 없 다면 git 이 알 아서 변경 사항 을 통합 해 줍니다 . 여기 서 문제 상황 은 충돌 ( conflict ) 인데 , 예 를 들 어 로컬 저 장소 에서 readme . md 라는 파일 을 변경 했 고 , 가장 최근 로컬 저 장소 의 pull 이후 remote 의 변경 이력 에 readme . md 의 수정 이 포함 되 어 있 다면 충돌 이 발생 합니다 . 충돌 해결 하 기 병합 기능 은 경우 에 따라 자동 으로 병합 할 수 없 는 경우 가 있 고 , 그 경우 가 바로 충돌 이 며 , 로컬 저 장소 의 변경 대상 과 remote 의 변경 대상 이 같 을 때 충돌 이 발생 한다고 했 습니다 . 두 변경 내용 중 어떤 것 을 적용 할 것 인지 판단 할 수 없 기 때문 입니다 . 이 경우 git 은 적용 할 변경 내용 의 판단 을 개발자 에게 맡깁니다 . 따라서 충돌 은 수동 으로 수정 해 주 어야 합니다 . 아래 는 충돌 이 난 파일 의 예 입니다 . <<<<<<< head hello ======= hello ! >>>>>>> aab 6 d 380 aaf 237 a 7 c 0 aae 28 e 00 ea 4607 c 8 a 7 eec 9 '=======' 로 구분 된 위쪽 부분 이 로컬 저 장소 , 아래쪽 부분 이 remote 의 변경 내용 입니다 . 둘 중 어떤 변경 이력 을 적용 할 지 선택 하 고 , 모든 충돌 부분 을 수정 한 이후 커 밋 을 수행 하 면 됩니다 .\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge\n",
    "doc_ptm = ' '.join(doc_pt)\n",
    "doc_ptm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"자신 의 로컬 저 장소 에서 진행 한 변경 이력 을 원격 저 장소 에 push 할 당시 에 , 로컬 저 장소 가 최신 버전 이 아닌 경우 ( clone 이후 다른 사람 이 remote 에 push 를 진행 했 을 경우 ) 자신 의 push 요청 이 거절 됩니다 . 이런 경우 병합 ( merge ) 작업 을 진행 하 여 remote 에 반영 된 다른 사람 의 변경 이력 을 로컬 저 장소 에 갱신 해야 합니다 . 원격 저 장소 의 변경 사항 을 무시 하 고 자신 의 변경 이력 을 덮 어 쓸 수 도 있 습니다 . 아래 는 강제 push 의 몇 가지 예 입니다 . $ git push - f $ git push -- force $ git push origin + 그러나 강제 push 를 할 일 을 만드 는 것 은 정말 좋 지 않 은 일 입니다 . remote 의 변경 이력 을 로컬 로 merge 하 는 것 이 가장 좋 습니다 . 그냥 단순히 pull 만 하 면 됩니다 . $ git pull origin master 문제 될 상황 이 없 다면 git 이 알 아서 변경 사항 을 통합 해 줍니다 . 여기 서 문제 상황 은 충돌 ( conflict ) 인데 , 예 를 들 어 로컬 저 장소 에서 readme . md 라는 파일 을 변경 했 고 , 가장 최근 로컬 저 장소 의 pull 이후 remote 의 변경 이력 에 readme . md 의 수정 이 포함 되 어 있 다면 충돌 이 발생 합니다 . 충돌 해결 하 기 병합 기능 은 경우 에 따라 자동 으로 병합 할 수 없 는 경우 가 있 고 , 그 경우 가 바로 충돌 이 며 , 로컬 저 장소 의 변경 대상 과 remote 의 변경 대상 이 같 을 때 충돌 이 발생 한다고 했 습니다 . 두 변경 내용 중 어떤 것 을 적용 할 것 인지 판단 할 수 없 기 때문 입니다 . 이 경우 git 은 적용 할 변경 내용 의 판단 을 개발자 에게 맡깁니다 . 따라서 충돌 은 수동 으로 수정 해 주 어야 합니다 . 아래 는 충돌 이 난 파일 의 예 입니다 . <<<<<<< head hello ======= hello ! >>>>>>> aab 6 d 380 aaf 237 a 7 c 0 aae 28 e 00 ea 4607 c 8 a 7 eec 9 '=======' 로 구분 된 위쪽 부분 이 로컬 저 장소 , 아래쪽 부분 이 remote 의 변경 내용 입니다 . 둘 중 어떤 변경 이력 을 적용 할 지 선택 하 고 , 모든 충돌 부분 을 수정 한 이후 커 밋 을 수행 하 면 됩니다 .\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(text, tokenizer=None):\n",
    "    doc_p = noise_remover(text)\n",
    "    if tokenizer is not None:\n",
    "        doc_p = tokenizer(doc_p)\n",
    "        doc_p = ' '.join(doc_p)\n",
    "    \n",
    "    return doc_p\n",
    "\n",
    "doc_pt = preprocessing(doc_p, korean_tokenizer)\n",
    "doc_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization.summarizer import summarize as textrank_summarizer\n",
    "from gensim.summarization.textcleaner import clean_text_by_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자신 의 로컬 저 장소 에서 진행 한 변경 이력 을 원격 저 장소 에 push 할 당시 에 , 로컬 저 장소 가 최신 버전 이 아닌 경우 ( clone 이후 다른 사람 이 remote 에 push 를 진행 했 을 경우 ) 자신 의 push 요청 이 거절 됩니다 .\n",
      "이런 경우 병합 ( merge ) 작업 을 진행 하 여 remote 에 반영 된 다른 사람 의 변경 이력 을 로컬 저 장소 에 갱신 해야 합니다 .\n",
      "$ git push - f $ git push -- force $ git push origin + 그러나 강제 push 를 할 일 을 만드 는 것 은 정말 좋 지 않 은 일 입니다 .\n",
      "remote 의 변경 이력 을 로컬 로 merge 하 는 것 이 가장 좋 습니다 .\n",
      "그냥 단순히 pull 만 하 면 됩니다 .\n",
      "md 라는 파일 을 변경 했 고 , 가장 최근 로컬 저 장소 의 pull 이후 remote 의 변경 이력 에 readme .\n",
      "충돌 해결 하 기 병합 기능 은 경우 에 따라 자동 으로 병합 할 수 없 는 경우 가 있 고 , 그 경우 가 바로 충돌 이 며 , 로컬 저 장소 의 변경 대상 과 remote 의 변경 대상 이 같 을 때 충돌 이 발생 한다고 했 습니다 .\n",
      "아래 는 충돌 이 난 파일 의 예 입니다 .\n",
      "아래 는 충돌 이 난 파일 의 예 입니다 .\n",
      ">>>>>>> aab 6 d 380 aaf 237 a 7 c 0 aae 28 e 00 ea 4607 c 8 a 7 eec 9 '=======' 로 구분 된 위쪽 부분 이 로컬 저 장소 , 아래쪽 부분 이 remote 의 변경 내용 입니다 .\n"
     ]
    }
   ],
   "source": [
    "print(textrank_summarizer(doc_pt, word_count=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sssssssssssss. df sf sf sd .sd \n",
      "자신 의 로컬 저 장소 에서 진행 한 변경 이력 을 원격 저 장소 에 push 할 당시 에 , 로컬 저 장소 가 최신 버전 이 아닌 경우 ( clone 이후 다른 사람 이 remote 에 push 를 진행 했 을 경우 ) 자신 의 push 요청 이 거절 됩니다 . 이런 경우 병합 ( merge ) 작업 을 진행 하 여 remote 에 반영 된 다른 사람 의 변경 이력 을 로컬 저 장소 에 갱신 해야 합니다 . $ git push - f $ git push -- force $ git push origin + 그러나 강제 push 를 할 일 을 만드 는 것 은 정말 좋 지 않 은 일 입니다 . remote 의 변경 이력 을 로컬 로 merge 하 는 것 이 가장 좋 습니다 . 그냥 단순히 pull 만 하 면 됩니다 . md 라는 파일 을 변경 했 고 , 가장 최근 로컬 저 장소 의 pull 이후 remote 의 변경 이력 에 readme . 충돌 해결 하 기 병합 기능 은 경우 에 따라 자동 으로 병합 할 수 없 는 경우 가 있 고 , 그 경우 가 바로 충돌 이 며 , 로컬 저 장소 의 변경 대상 과 remote 의 변경 대상 이 같 을 때 충돌 이 발생 한다고 했 습니다 . 아래 는 충돌 이 난 파일 의 예 입니다 . 아래 는 충돌 이 난 파일 의 예 입니다 . >>>>>>> aab 6 d 380 aaf 237 a 7 c 0 aae 28 e 00 ea 4607 c 8 a 7 eec 9 '=======' 로 구분 된 위쪽 부분 이 로컬 저 장소 , 아래쪽 부분 이 remote 의 변경 내용 입니다 .\n"
     ]
    }
   ],
   "source": [
    "def summarizer(text, word_count=256):\n",
    "    # Check if the text is too short.\n",
    "    INPUT_MIN_LENGTH = 10\n",
    "    sentences = clean_text_by_sentences(text)\n",
    "    if len(sentences) < INPUT_MIN_LENGTH:\n",
    "        return text\n",
    "\n",
    "    text_summarized = textrank_summarizer(text, word_count=word_count)\n",
    "    text_summarized = re.sub('\\n', ' ',text_summarized)\n",
    "    if len(text_summarized) == 0:\n",
    "        return text\n",
    "    \n",
    "    return text_summarized\n",
    "\n",
    "print(summarizer(\"sssssssssssss. df sf sf sd .sd \"))\n",
    "print(summarizer(doc_pt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ㅇㄴㄹ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 블로그 md파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017-09-14-comsent.md',\n",
       " '2018-01-25-duality.md',\n",
       " '2017-10-04-comparison.md',\n",
       " '2017-04-01-surinjection.md',\n",
       " '2017-10-27-avltree.md',\n",
       " '2017-03-09-rnnlstm.md',\n",
       " '2017-06-28-nounad.md',\n",
       " '2017-04-25-representationlearning.md',\n",
       " '2017-05-31-gibbs.md',\n",
       " '2017-11-21-Topological.md',\n",
       " '2017-12-17-compare.md',\n",
       " '2017-10-24-ends.md',\n",
       " '2017-04-05-CNNbackprop.md',\n",
       " '2017-08-16-deepNLP.md',\n",
       " '2017-06-21-ida.md',\n",
       " '2017-05-19-biasvar.md',\n",
       " '2017-11-05-bubblesort.md',\n",
       " '2017-09-11-recurrence.md',\n",
       " '2017-07-01-bayes.md',\n",
       " '2017-04-27-spectral.md',\n",
       " '2017-11-19-BFS.md',\n",
       " '2017-09-27-heapsort.md',\n",
       " '2019-09-12-embedding.md',\n",
       " '2017-10-15-queue.md',\n",
       " '2017-06-27-normal.md',\n",
       " '2017-10-20-projection.md',\n",
       " '2017-03-14-operations.md',\n",
       " '2017-11-12-disjointset.md',\n",
       " '2017-11-06-selectionsort.md',\n",
       " '2017-10-03-mergesort.md',\n",
       " '2017-04-20-docsim.md',\n",
       " '2017-03-20-morpheme.md',\n",
       " '2017-11-29-maxflow.md',\n",
       " '2017-05-21-determinants.md',\n",
       " '2017-10-23-josa.md',\n",
       " '2017-04-21-wordclass.md',\n",
       " '2017-10-13-josa.md',\n",
       " '2017-06-04-thetarole.md',\n",
       " '2017-11-28-MST.md',\n",
       " '2017-12-16-svgen.md',\n",
       " '2017-09-05-NP.md',\n",
       " '2017-04-26-LAsummary.md',\n",
       " '2017-07-06-fasttext.md',\n",
       " '2017-10-09-CNNs.md',\n",
       " '2017-10-05-candidate.md',\n",
       " '2017-11-23-SCC.md',\n",
       " '2017-09-23-MLE.md',\n",
       " '2017-10-18-bucketsort.md',\n",
       " '2018-01-30-genmodels.md',\n",
       " '2017-12-02-maxflow.md',\n",
       " '2017-04-04-langtype.md',\n",
       " '2017-12-05-negative.md',\n",
       " '2018-01-28-VAEs.md',\n",
       " '2017-12-01-NP.md',\n",
       " '2017-10-22-bst.md',\n",
       " '2017-05-09-verb.md',\n",
       " '2017-03-18-HMMs.md',\n",
       " '2017-07-05-bayes2.md',\n",
       " '2017-05-18-naive.md',\n",
       " '2017-04-19-KC.md',\n",
       " '2017-05-07-FDR.md',\n",
       " '2018-01-29-NF.md',\n",
       " '2017-03-10-frequency.md',\n",
       " '2018-02-11-italy.md',\n",
       " '2017-10-14-computeHMMs.md',\n",
       " '2017-03-28-tfidf.md',\n",
       " '2017-10-25-hash.md',\n",
       " '2017-05-20-spaces.md',\n",
       " '2017-09-29-pointer.md',\n",
       " '2017-09-25-gradient.md',\n",
       " '2017-10-01-sentcomp.md',\n",
       " '2017-06-29-generate2.md',\n",
       " '2017-03-24-Ldependence.md',\n",
       " '2017-10-10-RNNsty.md',\n",
       " '2017-05-08-noun.md',\n",
       " '2017-11-16-augmentedDS.md',\n",
       " '2017-12-26-convexfunction.md',\n",
       " '2017-06-01-LDA.md',\n",
       " '2017-12-15-disciminative.md',\n",
       " '2017-05-28-binomial.md',\n",
       " '2017-04-09-glove.md',\n",
       " '2017-06-22-median.md',\n",
       " '2017-04-14-wordweighting.md',\n",
       " '2017-09-06-insmersort.md',\n",
       " '2017-05-23-SVM.md',\n",
       " '2017-11-18-graph.md',\n",
       " '2017-11-20-DFS.md',\n",
       " '2017-04-08-apriori.md',\n",
       " '2019-09-11-xlnet.md',\n",
       " '2017-07-02-logistic.md',\n",
       " '2017-05-04-word2vecpos.md',\n",
       " '2017-12-18-unsugen.md',\n",
       " '2017-03-19-CNN.md',\n",
       " '2017-03-12-s2s.md',\n",
       " '2017-07-17-boolean.md',\n",
       " '2017-03-21-LDA.md',\n",
       " '2017-09-24-loss.md',\n",
       " '2017-11-02-honorification.md',\n",
       " '2017-03-15-words.md',\n",
       " '2017-07-07-generate.md',\n",
       " '2017-09-21-prob.md',\n",
       " '2017-05-30-SVM3.md',\n",
       " '2017-11-10-CRF.md',\n",
       " '2017-05-01-SOM.md',\n",
       " '2018-02-10-milano.md',\n",
       " '2017-10-22-manning.md',\n",
       " '2017-07-13-syntax.md',\n",
       " '2017-12-20-gan.md',\n",
       " '2017-11-09-detertime.md',\n",
       " '2017-07-14-sov.md',\n",
       " '2017-08-11-busan.md',\n",
       " '2017-08-13-summer.md',\n",
       " '2017-03-13-GPU.md',\n",
       " '2017-05-29-SVM2.md',\n",
       " '2017-03-23-linearity.md',\n",
       " '2017-05-17-nounontology.md',\n",
       " '2017-12-03-voice.md',\n",
       " '2017-05-14-backprop.md',\n",
       " '2017-04-29-parsing.md',\n",
       " '2017-09-15-advp.md',\n",
       " '2017-11-01-honorification.md',\n",
       " '2017-10-16-countingsort.md',\n",
       " '2017-04-06-pcasvdlsa.md',\n",
       " '2017-03-26-tree.md',\n",
       " '2017-10-07-prime.md',\n",
       " '2017-04-07-network.md',\n",
       " '2017-10-21-tree.md',\n",
       " '2017-10-30-honorification.md',\n",
       " '2017-11-17-modality.md',\n",
       " '2017-11-22-greedy.md',\n",
       " '2017-10-06-attention.md',\n",
       " '2017-09-18-double.md',\n",
       " '2017-09-22-information.md',\n",
       " '2017-07-03-regression.md',\n",
       " '2017-09-19-quote.md',\n",
       " '2017-05-11-word2vecpos2.md',\n",
       " '2017-11-26-dijkstra.md',\n",
       " '2017-04-24-PCA.md',\n",
       " '2017-06-25-sentimentdict.md',\n",
       " '2017-09-30-list.md',\n",
       " '2017-11-24-CC.md',\n",
       " '2017-09-16-LM.md',\n",
       " '2017-09-26-LAsummary2.md',\n",
       " '2017-11-30-NP.md',\n",
       " '2017-04-30-genegram.md',\n",
       " '2017-07-10-aspect.md',\n",
       " '2017-10-19-sort.md',\n",
       " '2017-10-08-gcd.md',\n",
       " '2017-06-24-RNTN.md',\n",
       " '2017-11-11-aspect.md',\n",
       " '2017-10-02-softmax.md',\n",
       " '2017-11-27-bellmanford.md',\n",
       " '2017-04-10-word.md',\n",
       " '2017-03-25-LUfactorization.md',\n",
       " '2017-12-25-convexset.md',\n",
       " '2018-01-26-KKT.md',\n",
       " '2017-07-09-lda.md',\n",
       " '2017-12-21-gans.md',\n",
       " '2017-12-04-cause.md',\n",
       " '2017-06-30-bayesinfer.md',\n",
       " '2017-11-15-dynamic.md',\n",
       " '2017-06-26-beamsearch.md',\n",
       " '2017-10-12-terms.md',\n",
       " '2017-03-30-word2vec.md',\n",
       " '2017-09-12-funcall.md',\n",
       " '2017-11-08-lexicalaspect.md',\n",
       " '2017-12-24-japan.md',\n",
       " '2017-05-06-BranchingEntropy.md',\n",
       " '2017-04-18-HC.md',\n",
       " '2017-11-14-viterbi.md',\n",
       " '2017-08-10-columbus.md',\n",
       " '2017-09-20-MSSP.md',\n",
       " '2017-10-26-MEMs.md',\n",
       " '2017-09-13-asymptotic.md',\n",
       " '2017-05-10-postag.md',\n",
       " '2017-10-31-honorification.md',\n",
       " '2017-11-25-shortestpath.md',\n",
       " '2017-09-17-binarysearch.md',\n",
       " '2017-03-13-graphnews.md',\n",
       " '2017-04-16-clustering.md',\n",
       " '2017-10-28-rbtree.md',\n",
       " '2017-07-18-consen.md',\n",
       " '2017-04-28-tSNE.md',\n",
       " '2017-04-17-KNN.md',\n",
       " '2017-12-19-vi.md',\n",
       " '2017-05-16-nounontology2.md',\n",
       " '2017-03-22-lexicon.md',\n",
       " '2017-03-29-NNLM.md',\n",
       " '2017-10-11-stack.md',\n",
       " '2017-09-07-algorithm.md',\n",
       " '2017-11-07-shellsort.md',\n",
       " '2017-04-02-logistic.md',\n",
       " '2017-08-12-war.md',\n",
       " '2017-03-08-word2vec.md',\n",
       " '2017-05-25-plsa.md',\n",
       " '2017-04-03-recursive.md',\n",
       " '2017-07-19-valency.md',\n",
       " '2017-08-08-taste.md',\n",
       " '2017-10-17-order.md',\n",
       " '2017-07-11-senttopic.md',\n",
       " '2017-03-11-embedding.md',\n",
       " '2017-11-03-tense.md',\n",
       " '2017-03-16-words2.md',\n",
       " '2017-03-07-start.md',\n",
       " '2017-07-08-treecode.md',\n",
       " '2017-05-26-docclassification.md',\n",
       " '2017-05-22-RLR.md',\n",
       " '2017-09-28-quicksort.md',\n",
       " '2017-11-04-MEMMs.md',\n",
       " '2017-03-17-treeensemble.md',\n",
       " '2018-01-31-AR.md',\n",
       " '2018-01-27-VAE.md',\n",
       " '2017-05-05-cohesion.md',\n",
       " '2017-10-29-maxparam.md',\n",
       " '2017-04-22-NNtricks.md',\n",
       " '2017-06-23-visual.md']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_samples_path = DATA_DIR + 'blog_samples/'\n",
    "blog_samples_filenames = os.listdir(blog_samples_path)\n",
    "blog_samples_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'---\\ntitle: 한국어의 복문\\ncategory: Korean Linguistics\\ntag: syntax\\n---\\n\\n이번 글에서는 한국어 **복문(複文)**에 대해 살펴보도록 하겠습니다. 이번 글은 고려대 정연주 선생님 강의와 \\'한국어문법총론1(구본관 외 지음, 집문당 펴냄)\\'을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.\\n\\n\\n\\n\\n\\n## 복문이란\\n\\n**단문(單文)**이란 주술관계가 한 번 있는 문장을, 복문이란 주술 관계가 둘 이상 포함된 문장을 가리킵니다. 아래 예에서 (가)는 단문, (나)~(라)는 복문입니다.\\n\\n> (가) 우리 집 셋째가 집에서 숙제를 한다.\\n>\\n> (나) \\\\[인생은 짧고\\\\] \\\\[예술은 길다\\\\].\\n>\\n> (다) \\\\[진이가 와서\\\\] \\\\[우리는 모임을 시작했다\\\\].\\n>\\n> (라) \\\\[나는 \\\\[봄이 왔음]을 오늘에서야 깨달았다\\\\].\\n\\n\\n\\n\\n\\n## 학교문법에서 보는 복문의 종류\\n\\n학교문법에서는 복문을 다음과 같이 분류합니다.\\n\\n\\n\\n**이어진문장**\\n\\n- 대등적으로 이어진 문장 : *\\\\[먼동이 트고\\\\] \\\\[별들이 사라진다\\\\]*\\n- 종속적으로 이어진 문장 : *\\\\[먼동이 트자\\\\] \\\\[별들이 사라진다\\\\]*\\n\\n\\n\\n**안은 문장**\\n\\n- 명사절을 안은 문장 : *\\\\[그가 돈이 많음\\\\]이 분명하다*\\n- 관형사절을 안은 문장 : *\\\\[그가 우리를 도와 준\\\\] 일을 잊지 맙시다*\\n- 부사절을 안은 문장 : *그 사람이 \\\\[말도 없이\\\\] 떠나 버렸구나*\\n- 서술절을 안은 문장 : *철수가 \\\\[키가 아주 크다]*\\n\\n\\n\\n그러나 위와 같이 (1) \\'대등적으로 이어진 문장(대등절)\\'과 \\'종속적으로 이어진 문장(종속절)\\'을 구별하고 (2) \\'종속적으로 이어진 문장\\'과 \\'부사절을 안은 문장(부사절)\\'을 별개의 것으로 보는 견해는 국어학계에서 소수라고 합니다. 실제 사례들을 따져보면 예외가 상당히 많이 발생하기 때문입니다. 세 가지 기준으로 살펴보겠습니다.\\n\\n\\n\\n\\n\\n## 이동가능성\\n\\n첫번째 기준은 절이 문장 내에서 이동가능한지 여부로 종속절, 부사절, 대등절을 나눠보는 것입니다. 예문을 살펴보겠습니다.\\n\\n\\n\\n**종속절** : 이동가능\\n\\n> [아버지가 돌아가시자] 진이는 고향을 떠났다.\\n>\\n> 진이는 [아버지가 돌아가시자] 고향을 떠났다.\\n\\n\\n\\n**부사절** : 이동가능\\n\\n> [구름에 달이 흘러가듯이] 나그네가 간다.\\n>\\n> 나그네가 [구름에 달이 흘러가듯이] 간다.\\n\\n\\n\\n**대등절** : 이동불가능\\n\\n> [인생은 짧고] 예술은 길다.\\n>\\n> \\\\*예술은 [인생은 짧고] 길다.\\n\\n\\n\\n학교문법에서는 종속절이 대등절과 비슷하다고 봅니다. 그러나 이동가능성 기준을 놓고 볼 때 종속절은 오히려 부사절과 유사합니다.\\n\\n\\n\\n\\n\\n## 주어의 \\'은/는\\' 결합 가능성\\n\\n두번째 기준은 분석 대상 절의 주어에 조사 \\'-은/는\\'이 붙을 수 있는지 여부입니다. 예문을 보겠습니다.\\n\\n\\n\\n**종속절** : 결합불가능\\n\\n> [{사촌이, *사촌은} 땅을 사서] 배가 아프다.\\n\\n\\n\\n**부사절** : 결합불가능\\n\\n> [{엄마가, *엄마는} 지나가게] 아빠가 길을 비켜 주셨다.\\n\\n\\n\\n**대등절** : 결합가능\\n\\n> [{산이, 산은} 높고] 물은 깊다.\\n\\n\\n\\n주어의 \\'은/는\\' 결합 가능성 기준을 놓고 봐도 종속절은 부사절과 유사합니다.\\n\\n\\n\\n\\n\\n## 재귀 대명사의 결속 가능성\\n\\n세번째 기준은 분석 대상 절에 재귀 대명사가 쓰일 수 있는지 여부입니다. 예문을 보겠습니다.\\n\\n\\n\\n**종속절** : 결속가능\\n\\n> 온달은 [**자기** 아내가 공주이므로] 부마가 된다.\\n\\n\\n\\n**부사절** : 결속가능\\n\\n> 진이는 [**자기** 동생이 지나가게] 길을 비켜 주었다.\\n\\n\\n\\n**대등절** : 결속불가능\\n\\n> 진이는 키가 크고 *\\\\[**자기** 동생은 키가 작다].\\n\\n\\n\\n재귀대명사의 결속 가능성 기준을 놓고 봐도 종속절은 부사절과 유사합니다.\\n\\n\\n\\n\\n\\n## 다시 보는 복문의 종류\\n\\n지금까지 논의한 내용을 바탕으로 복문의 종류를 다시 분류해보면 다음과 같습니다. \\'종속적으로 이어진 문장(종속절)\\' 모두를 \\'부사절을 안은 문장(부사절)\\'으로 보는 것입니다.\\n\\n\\n\\n**이어진 문장**\\n\\n- 대등적으로 이어진 문장\\n\\n\\n\\n**안은 문장**\\n- 명사절을 안은 문장 \\n- 관형사절을 안은 문장 \\n- 부사절을 안은 문장 (종속적으로 이어진 문장 포함)\\n- 서술절을 안은 문장 \\n\\n\\n\\n\\n\\n## 어미의 종류\\n\\n어미를 위치와 기능에 따라 대략적으로 분류한 표는 다음과 같습니다.\\n\\n\\n\\n<a href=\"https://imgur.com/6M5xQHq\"><img src=\"https://i.imgur.com/6M5xQHq.png\" width=\"500px\" title=\"source: imgur.com\" /></a>\\n\\n\\n\\n**어말어미**란 단어의 끝에서 쓰이는 어미입니다. **선어말어미**란 어말어미 앞자리에서 쓰이는 어미입니다. 어말어미엔 **종결어미(문말어미)**와 **비종결어미** 둘로 나뉩니다. 종결어미는 한 문장을 끝맺는 기능을 합니다.\\n\\n비종결어미엔 **연결어미(접속어미)**와 **전성어미**가 있습니다. 연결어미는 한 문장을 다음 문장으로 이어주는 역할을 합니다. 전성어미는 한 문장을 명사나 관형사, 부사와 같은 단어의 자격으로 전성(change)시키는 기능을 합니다. 여기에서 연결어미는 \\'이어진 문장\\', 전성어미는 \\'안은 문장\\'과 더 깊은 관련을 맺고 있습니다.\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_md = []\n",
    "for filename in blog_samples_filenames:\n",
    "    with open(blog_samples_path + filename, 'r') as file:\n",
    "         text = file.read()\n",
    "         docs_md.append(text)\n",
    "docs_md[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_md_prep = []\n",
    "for doc in tqdm(docs_md):\n",
    "    docs_md_prep.append(preprocessing(doc))\n",
    "docs_md_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 링크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-c382e6940590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'choi_urls/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'choi_time_url_df'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minput_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-859c7c6a67df>\u001b[0m in \u001b[0;36mload_obj\u001b[0;34m(path, file_fullname)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Load data from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_fullname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_fullname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_fullname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "input_df = load_obj(DATA_DIR + 'choi_urls/', 'choi_time_url_df')\n",
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://ppss.kr/archives/47698'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.iloc[7,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  0,   1,   2,   3,   5,   6,   7,   8,   9,  10,\n",
       "            ...\n",
       "            636, 637, 638, 639, 640, 641, 642, 643, 644, 645],\n",
       "           dtype='int64', length=629)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94582a0c0c314297ab29c340c2f1ac06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='scraper'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot get title or contents for https://pythonhosted.org/nipype/users/examples/smri_cbs_skullstripping.html\n",
      "Cannot get title or contents for https://darkpgmr.tistory.com/165\n",
      "Cannot get title or contents for https://blog.naver.com/thddlghghgh/220619787456\n",
      "Cannot get title or contents for https://www.kaggle.com/myonin/music-recommendation-random-forest-xgboost\n",
      "Cannot parse, https://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=spm;b1ed4077.04\n",
      "Cannot get title or contents for https://news.hada.io/topic?id=2458\n",
      "Cannot get title or contents for https://bigdata-sme.kr/#/datastore/competition\n",
      "Cannot parse, http://www.nature.com/scitable/topicpage/adaptation-and-phenotypic-variance-Adaptation-and-Phenotypic-Variance-1132\n",
      "Cannot get title or contents for http://www.ats.ucla.edu/stat/stata/ado/analysis/\n",
      "Cannot get title or contents for http://theme.archives.go.kr/next/populationPolicy/statisticsPopup_20.do\n",
      "Cannot get title or contents for https://www.biorxiv.org/content/10.1101/156380v1\n",
      "Cannot parse, https://github.com/AllenDowney/ThinkBayes2/blob/master/code/redline.py\n",
      "Cannot get title or contents for http://cdmanii.com/4414\n",
      "Cannot get title or contents for http://throughkim.kr/2016/04/01/beautifulsoup/\n",
      "Cannot get title or contents for https://medium.com/@omicro03/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-6%EC%9D%BC%EC%B0%A8-%ED%95%9C%EA%B5%AD%EC%96%B4%EC%97%90%EC%84%9C%EC%9D%98-%EC%96%B8%EC%96%B4-%EB%AA%A8%EB%8D%B8-%ED%8E%84%ED%94%8C%EB%A0%89%EC%84%9C%ED%8B%B0-5357e021b050\n",
      "Cannot get title or contents for http://darkpgmr.tistory.com/62\n",
      "Cannot get title or contents for http://www.ats.ucla.edu/stat/stata/webbooks/reg/chapter2/statareg2.htm\n",
      "Cannot get title or contents for https://www.digitalpsych.org/join.html\n",
      "Cannot get title or contents for http://blog.shurain.net/2014/03/bus-wait-1.html\n",
      "Cannot parse, https://theartfulapron.com/connect-with-us/\n",
      "Cannot get title or contents for http://sanghyukchun.github.io/58/\n",
      "Cannot get title or contents for https://www.quora.com/What-are-some-recent-and-potentially-upcoming-breakthroughs-in-deep-learning?__hstc=36392319.566e413a48a3eb7d0a2fee1f8154a4d7.1483080066931.1483080066931.1483082945743.2&__hssc=36392319.1.1483082945743&__hsfp=4265289821\n",
      "Cannot get title or contents for https://googlefonts.github.io/korean/\n",
      "Cannot get title or contents for https://whooing.com/zn5r\n",
      "Cannot get title or contents for https://arena.kakao.com/\n",
      "Cannot get title or contents for https://m.blog.naver.com/PostList.nhn?blogId=kimboramoo\n",
      "Cannot get title or contents for http://www.eunchanbae.com/2017/07/biostatistics.html\n",
      "Cannot parse, https://github.com/solleo/mp2rage_ss\n",
      "Cannot get title or contents for http://www.cidermics.com/contents/detail/1397\n",
      "Cannot get title or contents for https://zetawiki.com/wiki/Wget_%EC%A0%9C%EA%B3%B5%EB%90%98%EB%8A%94_%ED%8C%8C%EC%9D%BC%EB%AA%85%EC%9C%BC%EB%A1%9C_%EB%8B%A4%EC%9A%B4%EB%A1%9C%EB%93%9C\n",
      "Cannot get title or contents for http://www.gitxiv.com/posts/NNHa87KfYbwP8ykLC/icml-2017-curiosity-driven-exploration-by-self-supervised\n",
      "Cannot get title or contents for https://public.tableau.com/profile/lm.7#!/vizhome/Mathematicsusedin100jobs/ENG\n",
      "Cannot get title or contents for https://www.kaggle.com/danielwolffram/topic-modeling-finding-related-articles\n",
      "Cannot parse, https://en.wikipedia.org/wiki/Braess&apos;_paradox\n",
      "Cannot get title or contents for https://norman3.github.io/papers/docs/google_inception.html\n",
      "Cannot get title or contents for https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dttest++.html\n",
      "Cannot get title or contents for https://www.kaggle.com/c/competitive-data-science-predict-future-sales\n",
      "Cannot parse, https://www.biorxiv.org/content/10.1101/568733v1.full\n",
      "Cannot get title or contents for https://carpedm20.github.io/tacotron/en.html\n",
      "Cannot get title or contents for http://ieeexplore.ieee.org/abstract/document/6033613/?reload=true\n",
      "Cannot get title or contents for http://ibg.colorado.edu/cdrom2016/maes/UnivariateAnalysis/scriptsOpenMx.shtml\n",
      "Cannot parse, https://github.com/eyshin05/TIL/blob/master/Things_I&apos;ve_Learned.md\n",
      "Cannot get title or contents for http://biorxiv.org/cgi/content/short/608349v1\n",
      "Cannot parse, http://www.uccs.edu/lbecker/effect-size\n",
      "Cannot get title or contents for https://carbon.now.sh/?bg=rgba(171,%20184,%20195,%201)&t=seti&l=auto&ds=true&wc=true&wa=true&pv=48px&ph=32px&ln=false\n",
      "Cannot get title or contents for https://m.blog.naver.com/PostList.nhn?blogId=mynameisdj\n",
      "Cannot get title or contents for https://groups.google.com/forum/m/#!topic/dcm4che/SRv6z8YwMqs\n",
      "Cannot get title or contents for http://blog.naver.com/haidycoffee/220694488889\n",
      "Cannot get title or contents for http://www.jneurosci.org/content/36/2/432.short\n",
      "Cannot parse, http://nhuf.molit.go.kr/FP/FP05/FP0502/FP05020604.jsp\n",
      "Cannot get title or contents for https://cojette.github.io/zombiestat/\n",
      "Cannot parse, http://www.neuro.uni-jena.de/vbm/segmentation/modulation/\n",
      "Cannot get title or contents for https://owl.english.purdue.edu/owl/\n",
      "Cannot get title or contents for https://www.gwanghwamoon1st.go.kr/front/methodPssrp/methodPssrpBbsViewPage.do?bbs_id=9067ba0524d34a4b9407d967dd679fd6\n",
      "Cannot get title or contents for http://www.jneurosci.org/content/38/20/4724\n",
      "Cannot get title or contents for http://blog.naver.com/japanbooks/220236875006\n",
      "Cannot get title or contents for https://ssumer.com/qa-%EB%A7%A5%EC%97%90%EC%84%9C-ftp-%EC%9D%B4%EC%9A%A9%ED%95%9C-%ED%99%88-nas-%EC%9B%90%EA%B2%A9-%EC%97%B0%EA%B2%B0-%EB%B0%A9%EB%B2%95/\n",
      "Cannot parse, https://taeoh-kim.github.io/blog/generative-models-part-1-vaegandcgan/\n",
      "Cannot get title or contents for http://www.ats.ucla.edu/stat/examples/chp/\n",
      "Cannot get title or contents for https://m.facebook.com/cho.k.hyun/posts/10210003563399240\n",
      "Cannot get title or contents for https://www.dacon.io/m/competitions/official/235640/overview/rules/\n",
      "Cannot get title or contents for http://www.bigdata.go.kr/bbs.html\n",
      "Cannot get title or contents for https://www.aitrics.com/publications/\n",
      "Cannot get title or contents for http://matrix.skku.ac.kr/knou-knowls/CLA-Week-3.html\n",
      "Cannot get title or contents for https://www.kaggle.com/c/trends-assessment-prediction/?utm_medium=email&utm_source=intercom&utm_campaign=trends-email-launch\n",
      "Cannot get title or contents for https://www.quora.com/In-what-way-are-Adversarial-Networks-related-or-different-to-Adversarial-Training/answer/Ian-Goodfellow?__hstc=36392319.566e413a48a3eb7d0a2fee1f8154a4d7.1483080066931.1483080066931.1483082945743.2&__hssc=36392319.1.1483082945743&__hsfp=4265289821\n",
      "Cannot parse, http://www.revisemri.com/questions/pulse_sequences/voxel_size\n",
      "Cannot get title or contents for http://jose-coto.com/styling-with-seaborn\n",
      "Cannot get title or contents for http://dnce.unist.ac.kr/\n",
      "Cannot get title or contents for https://starlakim.wordpress.com/2019/06/29/4020-%ec%9e%91%ec%97%85%eb%b2%95/\n",
      "Cannot get title or contents for https://plot.ly/ipython-notebooks/survival-analysis-r-vs-python/\n",
      "Cannot parse, http://www.phrgcm.com/blog/2016/08/05/bellman-eqation/\n",
      "Cannot get title or contents for http://www.gatsby.ucl.ac.uk/~dayan/book/exercises.html\n",
      "Cannot get title or contents for http://www.deeplearningbook.org/contents/linear_algebra.html\n",
      "Cannot parse, http://fsl.fmrib.ox.ac.uk/fsl/fslview/masking.html\n",
      "Cannot get title or contents for http://thecoatlessprofessor.com/programming/openmp-in-r-on-os-x/\n",
      "Cannot get title or contents for https://cs.mtsu.edu/~rbutler/courses/sam/symdiff/symdiff_rules.html\n",
      "Cannot parse, http://www.ianruginski.com/SEM_FullSEMR_tutorial.html\n",
      "Cannot get title or contents for https://www.kaggle.com/lisphilar/covid-19-data-with-sir-model\n",
      "Cannot get title or contents for http://sf.jikji.org/book/index.html\n",
      "Cannot parse, https://www.biorxiv.org/content/10.1101/578641v1\n",
      "Cannot parse, https://www.youthcenter.go.kr/jynEmpSptNew/jynEmpSptGuide.do?bizId=201903140006\n",
      "Cannot get title or contents for http://webzine.seoulmetro.co.kr/enewspaper/articleview.php?master&aid=1771&ssid=73&mvid=684\n",
      "Cannot parse, https://yjucho1.github.io/spatio-temporal%20data/time-series/time-series-part4/\n",
      "Cannot get title or contents for http://rpubs.com/CCSL/hBayesDM\n",
      "Cannot get title or contents for http://theeluwin.kr/\n",
      "Cannot parse, http://www.nature.com/scitable/topicpage/estimating-trait-heritability-estimating-trait-heritability-46889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot get title or contents for http://wsyang.com/\n",
      "\n",
      "Complete scrape 541 among 629\n"
     ]
    }
   ],
   "source": [
    "docs_info, docs_idx = scraper(input_df['url'], input_df.index)  # .tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'McConnell Moves to Head Off Stimulus Deal as Pelosi Reports Progress',\n",
       "  'publish_date': datetime.datetime(2020, 10, 20, 0, 0),\n",
       "  'contents': 'Above all, Republicans fretted that a vote on such a package could interfere with their hasty timetable for confirming Judge Amy Coney Barrett to the Supreme Court by early next week. Mr. McConnell said he told the White House he was particularly concerned that a deal before then could inject unwanted unpredictability into the schedule, according to the four Republicans.\\n\\nTheir reservations suggested that even as a long-awaited stimulus deal between Democrats and the White House could be coming together, the aid still might have to wait until after Nov. 3.\\n\\n“The mechanics of getting the deal done would be challenging, to say the least,” Senator John Thune of South Dakota, the No. 2 Senate Republican, told reporters. He suggested that the “fog of the election” was warping the talks and would ultimately prevent any action before Nov. 3, adding that “people have gone to their battle stations.”\\n\\nMs. Pelosi appeared pleased with the direction of the talks, hailing what she described in a letter to Democrats on Tuesday evening as a productive dynamic in which “both sides are serious about finding a compromise.”\\n\\n“We’re not just down to a difference of language or a few dollars,” Mark Meadows, the White House chief of staff, warned in an interview on CNBC, declaring that Ms. Pelosi herself remained the biggest obstacle to a deal. “We still have a ways to go, but I would say that the conversations today were productive enough to continue to have discussions tomorrow.”\\n\\nThe latest White House offer would cost nearly $1.9 trillion, White House officials said, nearly four times the size of the $500 billion package that Senate Republicans hoped to advance on Wednesday in a bid to show voters that they were willing to provide some aid — just not what Democrats and Mr. Trump have been discussing. (Democrats were likely to object to the package as inadequate and prevent it from clearing the 60-vote threshold it would need to advance.)\\n\\nMr. McConnell’s remarks about a larger deal were described by four Republicans familiar with the discussion, who spoke on condition of anonymity to disclose details of a private closed lunch. He made it clear that he knew his counsel was likely to leak out, making reference to the possibility that his remarks could appear in the news media, two of the Republicans said.',\n",
       "  'url': 'https://www.nytimes.com/2020/10/20/us/politics/stimulus-deal-mitch-mcconnell-nancy-pelosi.html?action=click&module=Top%20Stories&pgtype=Homepage',\n",
       "  'scrap_at': datetime.datetime(2020, 10, 27, 11, 36, 27, 694378),\n",
       "  'is_news': True},\n",
       " {'title': '빅히트 주가 급락하자…\"수상한 공모가\" 국민청원까지 등장',\n",
       "  'publish_date': None,\n",
       "  'contents': '방탄소년단(BTS)의 소속사 빅히트. 연합뉴스 방탄소년단(BTS)의 소속사 빅히트. 연합뉴스\\n\\n빅히트엔터테인먼트가 유가증권시장 상장 이후 큰 폭으로 하락한 가운데 빅히트의 공모가격 산정을 두고 의혹을 제기하는 청와대 국민 청원글이 게재됐다.21일 청와대 국민청원 게시판에 따르면 지난 19일 \\'빅히트엔터테인먼트의 공모가격 어떻게 결정되었는지 밝혀주세요\\'라는 청원글이 게재됐다. 해당 청원의 마감일은 내달 18일, 현재 참여한 인원은 122명이다.해당 청원글의 작성자는 \"빅히트 소속가수 방탄소년단(BTS)은 세계에서 가장 유명하고 영향력 있는 대한민국의 가수\"라며 \"빅히트란 회사가 멋지게 코스피에 상장하게 됐고 BTS를 아끼고 사랑하는 팬들 혹은 투자자들이 많은 관심과 지지를 하고 있다\"며 글을 시작했다.이어 \"하지만 상장 2일 만에 언론매체는 빅히트 거품이라는 기사와 함께 BTS 군대문제 등을 문제삼아 기사화 하고 있다\"며 \"투자의 책임은 당연히 본인이 지는 것이 맞지만, 이번 경우는 많이 다른 듯 하다\"며 의혹을 제기했다.그는 \"아이돌 및 연예인의 군입대 관련한 법 개정등 굉장히 민감한 상황이 포함된 문제인듯 하다\"며 \"마치 계획이라도 된듯 문제점을 알고도 공모가격이 부풀려졌고, 팬들은 단순히 회사와 언론을 믿고 이틀 만에 투자금액의 절반을 잃었다\"고 토로했다.작성자는 \"빅히트 공모가는 터무니 없이 거품이 끼었다고 언론에서 보도를 하고 있다\"며 \"일각에서는 조희팔 사건과 옵티머스자산운용 사건 등 사기 사건과 비교하고 있다\"고 지적했다.그러면서 \"세계에서 가장 사랑받는 가수를 앞세워 터무니 없는 가격으로 물건을 파는 형태와 무엇이 다른지 의구심이 든다\"며 \"모든 국민이 궁금해하는 빅히트의 가격 어떻게 결정되고 기준은 무엇인지 명명백백 밝혀주길 바란다\"고 부연했다.이날 오후 1시21분 현재 빅히트는 전날보다 1500원(0.55%) 오른 18만4000원에 거래되고 있다. 상장 5거래일 만에 반등이다. 지난 15일 상장한 빅히트는 상장 첫날 4% 떨어진 데 이어 이튿 날엔 22% 넘게 떨어졌다. 이후 19~20일 각각 5%, 3%대로 급락했다.이송렬 한경닷컴 기자 yisr0203@hankyung.comⓒ 한국경제 & hankyung.com , 무단전재 및 재배포 금지',\n",
       "  'url': 'https://news.naver.com/main/ranking/read.nhn?mid=etc&sid1=111&rankingType=popular_day&oid=015&aid=0004435281&date=20201021&type=1&rankingSeq=7&rankingSectionId=101',\n",
       "  'scrap_at': datetime.datetime(2020, 10, 27, 11, 36, 28, 4168),\n",
       "  'is_news': False},\n",
       " {'title': '[Git] Pull에서 충돌 해결하기',\n",
       "  'publish_date': datetime.datetime(2018, 5, 23, 10, 0, tzinfo=tzoffset(None, 32400)),\n",
       "  'contents': \"자신의 로컬 저장소에서 진행한 변경 이력을 원격 저장소에 push할 당시에, 로컬 저장소가 최신 버전이 아닌 경우(clone 이후 다른 사람이 remote에 push를 진행했을 경우) 자신의 push 요청이 거절됩니다. 이런 경우 병합(merge) 작업을 진행하여 remote에 반영된 다른 사람의 변경 이력을 로컬 저장소에 갱신해야 합니다. 원격 저장소의 변경 사항을 무시하고 자신의 변경 이력을 덮어쓸 수도 있습니다. 아래는 강제 push의 몇가지 예입니다.\\n\\n$ git push -f $ git push --force $ git push origin +<branch_name>\\n\\n그러나 강제 push를 할 일을 만드는 것은 정말 좋지 않은 일입니다. remote의 변경 이력을 로컬로 merge하는 것이 가장 좋습니다. 그냥 단순히 pull 만 하면 됩니다.\\n\\n$ git pull origin master\\n\\n문제될 상황이 없다면 git이 알아서 변경 사항을 통합해 줍니다. 여기서 문제 상황은 충돌(conflict) 인데, 예를 들어 로컬 저장소에서 README.md라는 파일을 변경했고, 가장 최근 로컬 저장소의 pull 이후 remote의 변경 이력에 README.md의 수정이 포함되어 있다면 충돌이 발생합니다.\\n\\n충돌 해결하기\\n\\n병합 기능은 경우에 따라 자동으로 병합할 수 없는 경우가 있고, 그 경우가 바로 충돌이며, 로컬 저장소의 변경 대상과 remote의 변경 대상이 같을 때 충돌이 발생한다고 했습니다. 두 변경 내용 중 어떤 것을 적용할 것인지 판단할 수 없기 때문입니다. 이 경우 git은 적용할 변경 내용의 판단을 개발자에게 맡깁니다. 따라서 충돌은 수동으로 수정해 주어야 합니다. 아래는 충돌이 난 파일의 예입니다.\\n\\n<<<<<<< HEAD Hello ======= Hello! >>>>>>> aab6d380aaf237a7c0aae28e00ea4607c8a7eec9\\n\\n'======='로 구분된 위쪽 부분이 로컬 저장소, 아래쪽 부분이 remote의 변경 내용입니다. 둘 중 어떤 변경 이력을 적용할 지 선택하고, 모든 충돌 부분을 수정한 이후 커밋을 수행하면 됩니다.\",\n",
       "  'url': 'https://planbs.tistory.com/entry/Git-Pull%EC%97%90%EC%84%9C-%EC%B6%A9%EB%8F%8C-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0',\n",
       "  'scrap_at': datetime.datetime(2020, 10, 27, 11, 36, 28, 215417),\n",
       "  'is_news': False},\n",
       " {'title': 'McConnell Moves to Head Off Stimulus Deal as Pelosi Reports Progress',\n",
       "  'publish_date': datetime.datetime(2020, 10, 20, 0, 0),\n",
       "  'contents': 'Above all, Republicans fretted that a vote on such a package could interfere with their hasty timetable for confirming Judge Amy Coney Barrett to the Supreme Court by early next week. Mr. McConnell said he told the White House he was particularly concerned that a deal before then could inject unwanted unpredictability into the schedule, according to the four Republicans.\\n\\nTheir reservations suggested that even as a long-awaited stimulus deal between Democrats and the White House could be coming together, the aid still might have to wait until after Nov. 3.\\n\\n“The mechanics of getting the deal done would be challenging, to say the least,” Senator John Thune of South Dakota, the No. 2 Senate Republican, told reporters. He suggested that the “fog of the election” was warping the talks and would ultimately prevent any action before Nov. 3, adding that “people have gone to their battle stations.”\\n\\nMs. Pelosi appeared pleased with the direction of the talks, hailing what she described in a letter to Democrats on Tuesday evening as a productive dynamic in which “both sides are serious about finding a compromise.”\\n\\n“We’re not just down to a difference of language or a few dollars,” Mark Meadows, the White House chief of staff, warned in an interview on CNBC, declaring that Ms. Pelosi herself remained the biggest obstacle to a deal. “We still have a ways to go, but I would say that the conversations today were productive enough to continue to have discussions tomorrow.”\\n\\nThe latest White House offer would cost nearly $1.9 trillion, White House officials said, nearly four times the size of the $500 billion package that Senate Republicans hoped to advance on Wednesday in a bid to show voters that they were willing to provide some aid — just not what Democrats and Mr. Trump have been discussing. (Democrats were likely to object to the package as inadequate and prevent it from clearing the 60-vote threshold it would need to advance.)\\n\\nMr. McConnell’s remarks about a larger deal were described by four Republicans familiar with the discussion, who spoke on condition of anonymity to disclose details of a private closed lunch. He made it clear that he knew his counsel was likely to leak out, making reference to the possibility that his remarks could appear in the news media, two of the Republicans said.',\n",
       "  'url': 'https://www.nytimes.com/2020/10/20/us/politics/stimulus-deal-mitch-mcconnell-nancy-pelosi.html?action=click&module=Top%20Stories&pgtype=Homepage',\n",
       "  'scrap_at': datetime.datetime(2020, 10, 27, 11, 36, 28, 532471),\n",
       "  'is_news': True},\n",
       " {'title': '[Git] Pull에서 충돌 해결하기',\n",
       "  'publish_date': datetime.datetime(2018, 5, 23, 10, 0, tzinfo=tzoffset(None, 32400)),\n",
       "  'contents': \"자신의 로컬 저장소에서 진행한 변경 이력을 원격 저장소에 push할 당시에, 로컬 저장소가 최신 버전이 아닌 경우(clone 이후 다른 사람이 remote에 push를 진행했을 경우) 자신의 push 요청이 거절됩니다. 이런 경우 병합(merge) 작업을 진행하여 remote에 반영된 다른 사람의 변경 이력을 로컬 저장소에 갱신해야 합니다. 원격 저장소의 변경 사항을 무시하고 자신의 변경 이력을 덮어쓸 수도 있습니다. 아래는 강제 push의 몇가지 예입니다.\\n\\n$ git push -f $ git push --force $ git push origin +<branch_name>\\n\\n그러나 강제 push를 할 일을 만드는 것은 정말 좋지 않은 일입니다. remote의 변경 이력을 로컬로 merge하는 것이 가장 좋습니다. 그냥 단순히 pull 만 하면 됩니다.\\n\\n$ git pull origin master\\n\\n문제될 상황이 없다면 git이 알아서 변경 사항을 통합해 줍니다. 여기서 문제 상황은 충돌(conflict) 인데, 예를 들어 로컬 저장소에서 README.md라는 파일을 변경했고, 가장 최근 로컬 저장소의 pull 이후 remote의 변경 이력에 README.md의 수정이 포함되어 있다면 충돌이 발생합니다.\\n\\n충돌 해결하기\\n\\n병합 기능은 경우에 따라 자동으로 병합할 수 없는 경우가 있고, 그 경우가 바로 충돌이며, 로컬 저장소의 변경 대상과 remote의 변경 대상이 같을 때 충돌이 발생한다고 했습니다. 두 변경 내용 중 어떤 것을 적용할 것인지 판단할 수 없기 때문입니다. 이 경우 git은 적용할 변경 내용의 판단을 개발자에게 맡깁니다. 따라서 충돌은 수동으로 수정해 주어야 합니다. 아래는 충돌이 난 파일의 예입니다.\\n\\n<<<<<<< HEAD Hello ======= Hello! >>>>>>> aab6d380aaf237a7c0aae28e00ea4607c8a7eec9\\n\\n'======='로 구분된 위쪽 부분이 로컬 저장소, 아래쪽 부분이 remote의 변경 내용입니다. 둘 중 어떤 변경 이력을 적용할 지 선택하고, 모든 충돌 부분을 수정한 이후 커밋을 수행하면 됩니다.\",\n",
       "  'url': 'https://planbs.tistory.com/entry/Git-Pull%EC%97%90%EC%84%9C-%EC%B6%A9%EB%8F%8C-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0',\n",
       "  'scrap_at': datetime.datetime(2020, 10, 27, 11, 36, 28, 712149),\n",
       "  'is_news': False}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_info_df = pd.DataFrame.from_dict(docs_info)\n",
    "docs_info_df = docs_info_df.reindex(docs_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            90\n",
       "publish_date    375\n",
       "contents         90\n",
       "url              90\n",
       "scrap_at         90\n",
       "is_news          90\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_info_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(DATA_DIR + 'choi_urls/', 'docs_info_df', docs_info_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-4764f9446a24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocs_info_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'choi_urls/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'docs_info_df'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdocs_info_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-164-859c7c6a67df>\u001b[0m in \u001b[0;36mload_obj\u001b[0;34m(path, file_fullname)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Load data from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_fullname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_fullname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_fullname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "docs_info_df = load_obj(DATA_DIR + 'choi_urls/', 'docs_info_df', )\n",
    "docs_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>contents</th>\n",
       "      <th>url</th>\n",
       "      <th>scrap_at</th>\n",
       "      <th>is_news</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지하철 집단감염? 상대적으로 가능성 높지 않은 이유는</td>\n",
       "      <td>2020-03-11 07:37:56+09:00</td>\n",
       "      <td>[뉴스의 행간] 구로 콜센터 집단감염, 기로에 선 수도권\\n\\n서울 구로콜센터와 관...</td>\n",
       "      <td>http://www.newstof.com/news/articleView.html?i...</td>\n",
       "      <td>2020-10-26 18:20:38.102723</td>\n",
       "      <td>True</td>\n",
       "      <td>2015-11-05 13:58:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>슬럼프에 빠진 창작자에게: 작가의 벽을 넘어서는 법</td>\n",
       "      <td>2018-04-03 02:26:23+09:00</td>\n",
       "      <td>※ The New Yorker의 「How to Beat Writer’s Block」...</td>\n",
       "      <td>http://ppss.kr/archives/77846</td>\n",
       "      <td>2020-10-26 18:20:38.798942</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-05 14:09:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mixture model</td>\n",
       "      <td>None</td>\n",
       "      <td>Not to be confused with mixed model\\n\\nIn stat...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Mixture_model</td>\n",
       "      <td>2020-10-26 18:20:39.987001</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-05 17:24:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>genEpi Helper Functions</td>\n",
       "      <td>None</td>\n",
       "      <td>I'm trying to pull out estimates in a matrix u...</td>\n",
       "      <td>https://openmx.ssri.psu.edu/thread/3190</td>\n",
       "      <td>2020-10-26 18:20:41.912356</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-06 11:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Part Ⅲ. Neural Networks 최적화] 4. Dropout - 라온피...</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[Machine Learning ...</td>\n",
       "      <td>http://m.blog.naver.com/laonple/220542170499</td>\n",
       "      <td>2020-10-26 18:20:43.938598</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-08 22:23:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-15 20:19:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-15 20:21:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-15 20:21:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-15 20:24:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-19 18:25:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0                        지하철 집단감염? 상대적으로 가능성 높지 않은 이유는   \n",
       "1                         슬럼프에 빠진 창작자에게: 작가의 벽을 넘어서는 법   \n",
       "2                                        Mixture model   \n",
       "3                              genEpi Helper Functions   \n",
       "5    [Part Ⅲ. Neural Networks 최적화] 4. Dropout - 라온피...   \n",
       "..                                                 ...   \n",
       "640                                                NaN   \n",
       "641                                                NaN   \n",
       "642                                                NaN   \n",
       "643                                                NaN   \n",
       "645                                                NaN   \n",
       "\n",
       "                  publish_date  \\\n",
       "0    2020-03-11 07:37:56+09:00   \n",
       "1    2018-04-03 02:26:23+09:00   \n",
       "2                         None   \n",
       "3                         None   \n",
       "5                         None   \n",
       "..                         ...   \n",
       "640                        NaN   \n",
       "641                        NaN   \n",
       "642                        NaN   \n",
       "643                        NaN   \n",
       "645                        NaN   \n",
       "\n",
       "                                              contents  \\\n",
       "0    [뉴스의 행간] 구로 콜센터 집단감염, 기로에 선 수도권\\n\\n서울 구로콜센터와 관...   \n",
       "1    ※ The New Yorker의 「How to Beat Writer’s Block」...   \n",
       "2    Not to be confused with mixed model\\n\\nIn stat...   \n",
       "3    I'm trying to pull out estimates in a matrix u...   \n",
       "5    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[Machine Learning ...   \n",
       "..                                                 ...   \n",
       "640                                                NaN   \n",
       "641                                                NaN   \n",
       "642                                                NaN   \n",
       "643                                                NaN   \n",
       "645                                                NaN   \n",
       "\n",
       "                                                   url  \\\n",
       "0    http://www.newstof.com/news/articleView.html?i...   \n",
       "1                        http://ppss.kr/archives/77846   \n",
       "2          https://en.wikipedia.org/wiki/Mixture_model   \n",
       "3              https://openmx.ssri.psu.edu/thread/3190   \n",
       "5         http://m.blog.naver.com/laonple/220542170499   \n",
       "..                                                 ...   \n",
       "640                                                NaN   \n",
       "641                                                NaN   \n",
       "642                                                NaN   \n",
       "643                                                NaN   \n",
       "645                                                NaN   \n",
       "\n",
       "                      scrap_at is_news                time  \n",
       "0   2020-10-26 18:20:38.102723    True 2015-11-05 13:58:24  \n",
       "1   2020-10-26 18:20:38.798942   False 2015-11-05 14:09:24  \n",
       "2   2020-10-26 18:20:39.987001   False 2015-11-05 17:24:55  \n",
       "3   2020-10-26 18:20:41.912356   False 2015-11-06 11:44:44  \n",
       "5   2020-10-26 18:20:43.938598   False 2015-11-08 22:23:54  \n",
       "..                         ...     ...                 ...  \n",
       "640                        NaT     NaN 2020-10-15 20:19:22  \n",
       "641                        NaT     NaN 2020-10-15 20:21:09  \n",
       "642                        NaT     NaN 2020-10-15 20:21:56  \n",
       "643                        NaT     NaN 2020-10-15 20:24:59  \n",
       "645                        NaT     NaN 2020-10-19 18:25:08  \n",
       "\n",
       "[538 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_info_df.join(input_df['time'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f78023fa1b09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 전처리 적용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdocs_info_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocs_info_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdocs_info_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'contents'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocs_info_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'contents'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdocs_info_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/top2vec/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-6e8e8ee5beb1>\u001b[0m in \u001b[0;36mpreprocessing\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdoc_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise_remover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdoc_pt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdoc_ptm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_pt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-310417649713>\u001b[0m in \u001b[0;36mnoise_remover\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnoise_remover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# url 삭제\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0murl_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'https?://\\S*|www\\.\\S*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# 전처리 적용\n",
    "docs_info_df['title'] = docs_info_df['title'].apply(preprocessing)\n",
    "docs_info_df['contents'] = docs_info_df['title'] + \n",
    "docs_info_df['contents'] = docs_info_df['contents'].apply(preprocessing)\n",
    "docs_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(input_df, docs_info_df, how=\"left\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = load_obj(DATA_DIR + 'choi_urls/', 'docs_info_df')\n",
    "temp_df.to_csv(DATA_DIR + 'choi_urls/docs_info.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643\n",
      "556\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "print(len(urls), len(docs_info), len(urls_cannot_parse), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(DATA_DIR + 'choi_urls/', 'docs_info_df_choi', docs_info_df)\n",
    "save_obj(DATA_DIR + 'choi_urls/', 'urls_cannot_parse_choi', urls_cannot_parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### newspaper library에서 값 가져오지 못하는 URL 검토"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin, urlparse, parse_qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Basal_ganglia',\n",
       " 'https://openmx.ssri.psu.edu/node/4269',\n",
       " 'http://sanghyukchun.github.io/74/',\n",
       " 'http://aisociety.kr/prml2017s/',\n",
       " 'http://lavaan.ugent.be/tutorial/mediation.html',\n",
       " 'https://news.v.daum.net/v/20200904050635053',\n",
       " 'https://www.ncbi.nlm.nih.gov/pubmed/30532080',\n",
       " 'http://www.databaser.net/moniwiki/wiki.php/%EA%B5%AC%EC%A1%B0%EB%B0%A9%EC%A0%95%EC%8B%9D',\n",
       " 'http://www.nature.com/nrneurol/journal/v13/n4/full/nrneurol.2017.27.html?foxtrotcallback=true',\n",
       " 'http://www.newstof.com/news/articleView.html?idxno=10401',\n",
       " 'https://brownbears.tistory.com/501',\n",
       " 'https://hcnoh.github.io/2018-10-19-effective-python-way35',\n",
       " 'https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/',\n",
       " 'https://marcnu.github.io/2016-08-17/Tensorflow-v0.10-installed-from-scratch-Ubuntu-16.04-CUDA8.0RC-cuDNN5.1-1080GTX/',\n",
       " 'https://www.newyorker.com/culture/persons-of-interest/ted-chiangs-soulful-science-fiction',\n",
       " 'https://www.theatlantic.com/science/archive/2018/03/captivity-unlocks-curiosity-in-orangutans/554813/',\n",
       " 'http://brainmind.com/BrainLecture5.html',\n",
       " 'https://science.sciencemag.org/content/363/6428/692.full',\n",
       " 'http://r.789695.n4.nabble.com/binary-exogenous-variable-in-path-analysis-in-sem-or-lavaan-td3355987.html',\n",
       " 'https://arxiv.org/abs/1802.03690',\n",
       " 'https://m.hankookilbo.com/News/Read/201611210459586024',\n",
       " 'https://edition-m.cnn.com/2018/11/28/health/adhd-diagnosis-august-kindergarten-study/index.html',\n",
       " 'https://marshall-ku.com/web/tips/%EC%9C%88%EB%8F%84%EC%9A%B0%EC%97%90-%EC%9A%B0%EB%B6%84%ED%88%AC-%EC%84%A4%EC%B9%98%ED%95%98%EA%B8%B0',\n",
       " 'https://www.nature.com/articles/nature25158',\n",
       " 'https://support.snel.com/902085-Install-VNC-on-Ubuntu-1604',\n",
       " 'http://0561blue.tistory.com/44',\n",
       " 'http://mutefreeze.tistory.com/9',\n",
       " 'https://news.v.daum.net/v/20200831100205444',\n",
       " 'https://wikidocs.net/45339',\n",
       " 'https://velog.io/@iamchanii/build-a-blog-with-gatsby-and-typescript-part-4',\n",
       " 'https://tbates.github.io/models/twin/1980/06/10/twin-umxACE.html',\n",
       " 'https://hunkim.github.io/ml/',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2892746/',\n",
       " 'https://brunch.co.kr/@readme999/190',\n",
       " 'https://ko.m.wikipedia.org/wiki/%EA%B8%B0%EC%9A%A4_%EB%93%9C_%EC%83%B9%ED%8F%AC',\n",
       " 'http://bokeh.pydata.org/en/latest/',\n",
       " 'http://nilearn.github.io/auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html',\n",
       " 'http://blog.engintruder.com/147',\n",
       " 'http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4315464/',\n",
       " 'http://mbtaviz.github.io/',\n",
       " 'http://sunyzero.tistory.com/m/245',\n",
       " 'http://www.gatsby.ucl.ac.uk/teaching/phd/Gatsby%20PhD%20Programme.html',\n",
       " 'http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3707392/#!po=13.0682',\n",
       " 'https://fabl1106.github.io/python/2019/04/25/%ED%8C%8C%EC%9D%B4%EC%8D%AC-22.-%EB%8F%99%EC%A0%81%ED%81%AC%EB%A1%A4%EB%A7%81(Ajax,-JSON).html',\n",
       " 'https://onlinelibrary.wiley.com/doi/full/10.1111/cdev.12394',\n",
       " 'https://news.v.daum.net/v/20200401123551004',\n",
       " 'https://www.curiousily.com/posts/demand-prediction-with-lstms-using-tensorflow-2-and-keras-in-python/',\n",
       " 'https://blog.cogneurostats.com/2015/01/23/some-exposure-to-mri-transforms-in-afni/',\n",
       " 'https://blog.linewalks.com/archives/6522',\n",
       " 'https://lindeloev.github.io/tests-as-linear/',\n",
       " 'http://schoolofweb.net/blog/posts/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%ED%8D%BC%EC%8A%A4%ED%8A%B8%ED%81%B4%EB%9E%98%EC%8A%A4-%ED%95%A8%EC%88%98-first-class-function/',\n",
       " 'https://chukycheese.github.io/data%20science/why-im-not-making-covid19-visualization/',\n",
       " 'http://pythonkim.tistory.com/71',\n",
       " 'https://mchankins.wordpress.com/2013/04/21/still-not-significant-2/',\n",
       " 'http://m.ohmynews.com/NWS_Web/Mobile/at_pg.aspx?CNTN_CD=A0002069519',\n",
       " 'http://operativeneurosurgery.com/doku.php?id=basal_ganglia',\n",
       " 'https://www.cell.com/trends/neurosciences/fulltext/S0166-2236(19)30019-0',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5028200/',\n",
       " 'https://m.blog.naver.com/bluefish850/220749045909',\n",
       " 'https://maternalgrandfather.tistory.com/entry/%EB%AF%B8%EA%B5%AD%EC%A3%BC%EC%8B%9D-%EA%B1%B0%EB%9E%98%EC%8B%9C-%EC%A6%9D%EA%B6%8C%EC%82%AC%EB%B3%84-%EC%88%98%EC%88%98%EB%A3%8C-%EB%B9%84%EA%B5%90%EA%B8%80',\n",
       " 'http://askubuntu.com/questions/760934/graphics-issues-after-while-installing-ubuntu-16-04-with-nvidia-graphics',\n",
       " 'http://trib.al/MiBPyQT',\n",
       " 'https://www.nature.com/articles/s41562-017-0234-y',\n",
       " 'https://velog.io/@iamchanii/build-a-blog-with-gatsby-and-typescript-part-2',\n",
       " 'https://www.neca.re.kr/lay1/bbs/S1T12C49/A/12/view.do?article_seq=8324&cpage=1&rows=10&condition=&keyword=&show=&cat=',\n",
       " 'https://mental.jmir.org/2017/2/e19/',\n",
       " 'http://science.sciencemag.org/content/352/6282/216',\n",
       " 'https://ko.m.wikipedia.org/wiki/%EB%B3%B4%ED%8E%B8%EB%85%BC%EC%9F%81',\n",
       " 'https://ko.wikipedia.org/wiki/%EC%B9%98%ED%84%B0',\n",
       " 'https://ko.m.wikipedia.org/wiki/%EA%B4%80%EB%85%90%EB%A1%A0',\n",
       " 'https://link.springer.com/article/10.1007/s00702-017-1807-7',\n",
       " 'https://openmx.ssri.psu.edu/node/4252',\n",
       " 'http://alphago.pe.kr/m/entry/Ubuntu-1604-%EC%84%A4%EC%B9%98-%EC%B4%9D%EC%A0%95%EB%A6%AC',\n",
       " 'https://science.sciencemag.org/content/354/6317/1273.abstract',\n",
       " 'https://m.blog.naver.com/PostView.nhn?blogId=kimboramoo&logNo=221007407490&navType=tl',\n",
       " 'https://m.hankookilbo.com/News/Read/202004231827323119',\n",
       " 'http://m.blog.naver.com/naver_diary/220887633829',\n",
       " 'https://n.news.naver.com/article/353/0000037266',\n",
       " 'http://english.seoul.go.kr/seoul-makes-efforts-for-zero-confirmed-covid-19-cases-in-the-subway/',\n",
       " 'http://www.boxnwhis.kr/2016/03/25/how_to_be_a_developer_as_a_statistician.html',\n",
       " 'https://www.scientificamerican.com/article/cognitive-ability-and-vulnerability-to-fake-news/',\n",
       " 'https://pyformat.info/',\n",
       " 'https://resumegenius.com/letter-of-recommendation/student-and-teacher-samples#For-Student',\n",
       " 'https://dpaniukov.github.io/2016/06/06/brain-extraction-with-ants.html',\n",
       " 'https://imaginary.org/background-material/school-taskbook-from-5-to-15',\n",
       " 'https://www.bbc.com/korean/international-53900606',\n",
       " 'http://www.dongascience.com/news/view/11467',\n",
       " 'https://pythonhosted.org/nipype/users/examples/smri_ants_registration.html',\n",
       " 'http://science.sciencemag.org/content/351/6268/24',\n",
       " 'https://rdrr.io/cran/umx/man/umxACE.html',\n",
       " 'https://robotenomics.com/2014/02/03/why-machine-learning-and-big-data-need-behavioral-economists/',\n",
       " 'https://www.culture.go.kr/bigdata/user/main.do',\n",
       " 'https://www.moel.go.kr/news/enews/report/enewsView.do;jsessionid=7tbE0golfgwaDETHSYPpe3TS4NFsuLrfjyQFr9Gro41l2mUaVGGYr9ur2fDqKNz9.moel_was_outside_servlet_www2?news_seq=11434',\n",
       " 'https://brunch.co.kr/@justinleeanac/2',\n",
       " 'https://medium.com/refactoring-ui/7-practical-tips-for-cheating-at-design-40c736799886',\n",
       " 'http://www.lead-dbs.org/about-the-mni-spaces/',\n",
       " 'https://onlinelibrary.wiley.com/doi/full/10.1111/ejn.14397',\n",
       " 'https://futurism.com/googles-new-ai-is-better-at-creating-ai-than-the-companys-engineers/',\n",
       " 'https://hogni.tistory.com/65',\n",
       " 'http://stackoverflow.com/questions/36278590/numpy-array-dtype-is-coming-as-int32-by-default-in-a-windows-10-64-bit-machine',\n",
       " 'https://jinchory.tistory.com/335?category=424330',\n",
       " 'https://www.pnas.org/content/110/Supplement_2/10438',\n",
       " 'https://lucasg.github.io/Dependencies/',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2583456/',\n",
       " 'https://discourse.slicer.org/t/how-can-i-convert-vtk-file-to-nifti-format/1034',\n",
       " 'https://python-3-patterns-idioms-test.readthedocs.io/en/latest/Comprehensions.html',\n",
       " 'https://afni.nimh.nih.gov/SimAna',\n",
       " 'https://stackoverflow.com/questions/52796148/python-2-7-replace-percentage-to-slash-but-got-double-slash',\n",
       " 'https://wonism.github.io/create-blog-with-gatsby/',\n",
       " 'https://neuroscience.stanford.edu/mbct/training-programs/mbct-training-program',\n",
       " 'https://piie.com/publications/working-papers/origins-superrich-billionaire-characteristics-database',\n",
       " 'https://stackoverflow.com/questions/37497948/aov-error-term-in-r-whats-the-difference-bw-errorid-and-errorid-timevar',\n",
       " 'https://datadryad.org/resource/doi:10.5061/dryad.rd5rn/4',\n",
       " 'http://engineering.nyu.edu/academics/departments/computer-science-engineering/majors-programs/bridge?utm_content=buffer8ec31&utm_medium=social&utm_source=facebook.com&utm_campaign=buffer',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4196856/',\n",
       " 'https://arxiv.org/abs/1706.01242',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5370364/',\n",
       " 'https://github.com/ateshkoul/NeuroImaging/blob/master/spm/peak_nii/JHU-ICBM-tracts-maxprob-thr0-1mm.nii',\n",
       " 'https://imnews.imbc.com/replay/2020/nwdesk/article/5788251_32524.html',\n",
       " 'https://aws.amazon.com/getting-started/tutorials/launch-a-virtual-machine/',\n",
       " 'https://www.google.co.kr/amp/m.ohmynews.com/NWS_Web/Mobile/amp.aspx%3fCNTN_CD=A0002642905',\n",
       " 'http://flyingdcat4.tistory.com/m/76',\n",
       " 'https://www.technologyreview.com/s/609968/a-new-map-of-the-darknet-suggests-your-local-drug-pusher-now-works-online/',\n",
       " 'https://afni.nimh.nih.gov',\n",
       " 'https://www.j-alz.com/content/low-grip-strength-linked-impaired-cognition-memory-loss-older-americans',\n",
       " 'https://www.jamieoliver.com/recipes/rice-recipes/a-basic-risotto-recipe/',\n",
       " 'https://m.hankookilbo.com/News/Read/A2020082714580002597?rPrev=A2020092318060002879',\n",
       " 'https://stackoverflow.com/questions/11183788/in-a-git-repository-how-to-properly-rename-a-directory',\n",
       " 'https://cni.stanford.edu/wiki/MR_Protocols',\n",
       " 'https://www.google.co.kr/amp/s/m.biz.chosun.com/news/article.amp.html%3fcontid=2020051501319',\n",
       " 'https://economiology.com/%EB%B2%84%ED%8C%80%EB%AA%A9-%EC%A0%84%EC%84%B8%EC%9E%90%EA%B8%88-%EB%8C%80%EC%B6%9C%EC%9D%98-%EC%A1%B0%EA%B1%B4%EA%B3%BC-%EC%9D%B4%EC%9C%A8-%EB%B0%8F-%ED%95%9C%EB%8F%84/',\n",
       " 'https://hurcy.github.io/awesome-ehr-deeplearning/',\n",
       " 'https://github.com/erreurt/MahjongAI',\n",
       " 'http://www.navisphere.net/?p=2486',\n",
       " 'https://forum.arduino.cc/index.php?topic=351557.0',\n",
       " 'https://stackoverflow.com/questions/14175348/why-does-pythons-multiprocessing-module-import-main-when-starting-a-new-pro',\n",
       " 'https://www.abg.psychol.cam.ac.uk/news/2positions',\n",
       " 'https://medium.com/mathpresso/mathpresso-%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D-%EC%8A%A4%ED%84%B0%EB%94%94-3-%EC%98%A4%EC%B0%A8%EB%A5%BC-%EB%8B%A4%EB%A3%A8%EB%8A%94-%EB%B0%A9%EB%B2%95-7d1fb64ea0cf',\n",
       " 'https://stats.stackexchange.com/questions/235673/is-there-any-relationship-among-cosine-similarity-pearson-correlation-and-z-sc',\n",
       " 'https://www.mhanational.org/mental-health-america-releases-may-2020-screening-data-88000-have-anxiety-or-depression-and-results',\n",
       " 'https://neuroscience.stanford.edu/',\n",
       " 'https://bryan7.tistory.com/1077',\n",
       " 'https://hiseon.me/linux/ubuntu/ubuntu-kakaotalk/',\n",
       " 'http://m.news.naver.com/rankingRead.nhn?oid=032&aid=0002726065&ntype=RANKING',\n",
       " 'https://github.com/ANTsX/ANTs/issues/636',\n",
       " 'https://ifyourfriendishacker.tistory.com/m/5',\n",
       " 'https://github.com/ninjaaron/replacing-bash-scripting-with-python#the-subprocess-module',\n",
       " 'https://www.nytimes.com/2017/06/15/well/family/talking-to-boys-the-way-we-talk-to-girls.html',\n",
       " 'https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1643-7',\n",
       " 'http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3116741/',\n",
       " 'https://www.frontiersin.org/articles/10.3389/fncom.2019.00040/full',\n",
       " 'https://arxiv.org/abs/1809.07435v1',\n",
       " 'http://www.grahamwideman.com/gw/brain/fs/surfacefileformats.htm',\n",
       " 'https://www.rdocumentation.org/packages/ggpubr/versions/0.2.5/topics/stat_compare_means',\n",
       " 'https://news.v.daum.net/v/20200831143144195',\n",
       " 'https://robotenomics.com/2014/02/25/the-intersection-of-behavioral-economics-and-machine-learning-to-understand-big-data/',\n",
       " 'https://beomi.github.io/2017/09/28/HowToMakeWebCrawler-Headless-Chrome/',\n",
       " 'https://www.vox.com/2018/6/13/17449118/stanford-prison-experiment-fraud-psychology-replication',\n",
       " 'http://sergeswin.com/980',\n",
       " 'https://brunch.co.kr/@ljh0113m/1',\n",
       " 'https://www.r-bloggers.com/r-tutorial-series-anova-pairwise-comparison-methods/',\n",
       " 'http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4251716/',\n",
       " 'https://vipbg.vcu.edu/academics/courses/course-materials/openmx-fall09/',\n",
       " 'https://m.blog.naver.com/frankbyon/120210821809',\n",
       " 'https://biaswatchneuro.com/',\n",
       " 'https://openmx.ssri.psu.edu/forums/openmx-help/teaching-sem-using-openmx',\n",
       " 'https://www.pylint.org/#install',\n",
       " 'http://ppss.kr/archives/105164',\n",
       " 'https://miykael.github.io/nipype_tutorial/',\n",
       " 'https://datascienceplus.com/two-way-anova-with-repeated-measures/',\n",
       " 'https://sites.google.com/site/shinnosuketakamichi/publication/jsut',\n",
       " 'https://www.mturk.com/mturk/welcome',\n",
       " 'https://brunch.co.kr/@gkicarus/42',\n",
       " 'http://blog.daum.net/gundown/4808369',\n",
       " 'http://journal.frontiersin.org/article/10.3389/fnhum.2014.00054/full',\n",
       " 'https://wikidocs.net/book/587',\n",
       " 'http://stats.stackexchange.com/questions/70096/locomotive-problem-with-various-size-companies',\n",
       " 'https://python.bakyeono.net/chapter-11-5.html',\n",
       " 'http://www.lucidarme.me/?p=4087',\n",
       " 'https://deepmind.com/blog/imagine-creating-new-visual-concepts-recombining-familiar-ones/',\n",
       " 'https://www.cell.com/neuron/fulltext/S0896-6273(17)30509-3',\n",
       " 'http://weekly.donga.com/3/all/11/1300368/1',\n",
       " 'https://www.frontiersin.org/articles/10.3389/fpsyt.2018.00363/full',\n",
       " 'https://galid1.tistory.com/109',\n",
       " 'https://en.wikipedia.org/wiki/Pr%C3%A9f%C3%A9rence',\n",
       " 'https://1boon.daum.net/newsade/coldnoodles?dmp_channel=foodfighter&dmp_id=1131422',\n",
       " 'https://tbates.github.io/container/2015/06/10/container-Twin-model-articles.html',\n",
       " 'http://www.sthda.com/english/wiki/two-way-anova-test-in-r#multiple-pairwise-comparison-between-the-means-of-groups',\n",
       " 'https://brunch.co.kr/@lifejobcrafting/27',\n",
       " 'https://www.google.co.kr/amp/s/m.yna.co.kr/amp/view/GYH20200515000800044',\n",
       " 'https://hackernoon.com/thinking-of-self-studying-machine-learning-remind-yourself-of-these-6-things-b55a5f2b6c7d',\n",
       " 'http://cython.org',\n",
       " 'https://github.com/cmawer/pycon-2017-eda-tutorial/blob/master/EDA-cheat-sheet.md',\n",
       " 'https://medium.com/@thoszymkowiak/deepmind-just-published-a-mind-blowing-paper-pathnet-f72b1ed38d46#.2c23zca05',\n",
       " 'https://www.newyorker.com/tech/elements/the-book-that-colored-charles-darwins-world',\n",
       " 'http://zhiyzuo.github.io/installation-rJava/',\n",
       " 'https://capmh.biomedcentral.com/articles/10.1186/s13034-016-0112-9',\n",
       " 'http://www.nature.com/nrneurol/journal/v10/n11/abs/nrneurol.2014.178.html?foxtrotcallback=true',\n",
       " 'http://skyeong.net/m/123',\n",
       " 'https://hsaghir.github.io/data_science/jupyter-notebook-on-a-remote-machine-linux/',\n",
       " 'https://ko.m.wikipedia.org/wiki/%EC%BA%94%ED%84%B0%EB%B2%A0%EB%A6%AC%EC%9D%98_%EC%95%88%EC%85%80%EB%AA%A8',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6368853/',\n",
       " 'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0126255',\n",
       " 'http://askubuntu.com/questions/624966/cant-login-after-nvidia-driver-install-v-14-04',\n",
       " 'https://wikidocs.net/book/4542',\n",
       " 'https://m-clark.github.io/docs/mixedModels/anovamixed.html',\n",
       " 'https://developers.google.com/machine-learning/rules-of-ml/',\n",
       " 'https://en.wikipedia.org/wiki/Variance_inflation_factor',\n",
       " 'https://homecuisine.co.kr/hc25/82454',\n",
       " 'https://kr.mathworks.com/help/stats/corr.html',\n",
       " 'https://github.com/phg0804/melon-playlist-continuation',\n",
       " 'http://ppss.kr/archives/47698',\n",
       " 'https://tensorflow.blog/2017/03/08/%EB%B2%84%ED%81%B4%EB%A6%AC-%EB%8C%80%ED%95%99%EC%9D%98-%EC%9C%A0%ED%88%AC%EB%B8%8C-%EA%B0%95%EC%A2%8C%EA%B0%80-%EC%82%AD%EC%A0%9C%EB%90%A9%EB%8B%88%EB%8B%A4/',\n",
       " 'https://www.sciencemag.org/news/2019/04/physicist-trying-make-sense-brain-s-tangled-networks',\n",
       " 'http://m.news.naver.com/rankingRead.nhn?oid=020&aid=0002937089&sid1=&ntype=RANKING',\n",
       " 'https://www.google.co.kr/amp/s/mc.ai/topic-modeling-with-bert/%3famp',\n",
       " 'https://www.princeton.edu/~otorres/Stata/statnotes',\n",
       " 'http://blog.daum.net/gundown/4807821',\n",
       " 'https://m.blog.naver.com/guess1241/221506070695',\n",
       " 'https://www.bbc.com/korean/international-53956248',\n",
       " 'https://www.scientificamerican.com/article/3-brain-technologies-to-watch-in-2018/',\n",
       " 'https://www.scientificamerican.com/article/does-the-adult-brain-really-grow-new-neurons/',\n",
       " 'https://brunch.co.kr/@readme999/150',\n",
       " 'https://neurostars.org/t/preprocessing-for-atlas-based-connectivity-matrices/743/12',\n",
       " 'http://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html',\n",
       " 'https://github.com/GenLouvain/GenLouvain',\n",
       " 'http://protocols.humanconnectome.org/HCP/3T/imaging-protocols.html',\n",
       " 'https://m.facebook.com/story.php?story_fbid=1340177956041067&id=100001466253230&refid=52&__tn__=%2As',\n",
       " 'http://palpit.tistory.com/765',\n",
       " 'https://en.wikipedia.org/wiki/Linear%E2%80%93quadratic_regulator',\n",
       " 'http://askubuntu.com/questions/760934/graphics-issues-after-while-installing-ubuntu-16-04-16-10-with-nvidia-graphics/762073',\n",
       " 'http://www.bloter.net/archives/248374',\n",
       " 'https://www.nature.com/articles/s41380-019-0384-6',\n",
       " 'https://www.ncbi.nlm.nih.gov/pubmed/28465167/',\n",
       " 'http://www.write.com/writing-guides/general-writing/grammar/clauses-and-phrases/',\n",
       " 'https://gorakgarak.tistory.com/1255',\n",
       " 'https://chris.beams.io/posts/git-commit/',\n",
       " 'https://brunch.co.kr/@ebprux/628',\n",
       " 'https://blog.dataiku.com/introducing-polyamor-the-two-way-translator-between-python-and-r',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3400125/',\n",
       " 'http://www.hani.co.kr/arti/culture/book/867497.html',\n",
       " 'https://xcorr.net/2020/04/21/an-online-summer-school-for-computational-neuroscience/',\n",
       " 'https://www.google.co.kr/amp/s/www.ksakosmos.com/amp/%25EB%25AC%25BC%25EB%25A6%25AC%25ED%2595%2599%25EC%259E%2590-sir-%25EB%25AA%25A8%25EB%258D%25B8%25EB%25A1%259C-%25EC%25A0%2584%25EC%2597%25BC%25EB%25B3%2591%25EC%259D%2584-%25EC%2598%2588%25EC%25B8%25A1%25ED%2595%2598%25EB%258B%25A4',\n",
       " 'http://web.stanford.edu/group/bdl/blog/tda-cme-paper/',\n",
       " 'https://www.hindawi.com/journals/bmri/2014/312142/',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5003599/',\n",
       " 'https://python.quantecon.org/sir_model.html',\n",
       " 'http://homecuisine.co.kr/index.php?mid=hc25&category=1471&document_srl=46180',\n",
       " 'https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent',\n",
       " 'https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/documents.html',\n",
       " 'https://en.m.wikipedia.org/wiki/Bellman_equation',\n",
       " 'http://m.news.naver.com/rankingRead.nhn?oid=055&aid=0000370772&sid1=&ntype=RANKING',\n",
       " 'http://andysbrainblog.blogspot.kr/2012/11/creating-masks-in-fsl.html',\n",
       " 'http://m.blog.naver.com/laonple/220542170499',\n",
       " 'https://brownbears.tistory.com/292',\n",
       " 'http://askubuntu.com/questions/38780/how-do-i-set-nomodeset-after-ive-already-installed-ubuntu',\n",
       " 'https://www.bbc.com/korean/news-53125182',\n",
       " 'https://dataitgirls2.github.io/tutorial/Tutorial_180719_BeautifulSoup.html',\n",
       " 'https://github.com/yuq-1s/JiaoEle/tree/0bc283a6e43e1a1630846cc4eafb002f0e6844e3/course_collector/course_collector',\n",
       " 'https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6',\n",
       " 'https://ko.m.wikipedia.org/wiki/%ED%94%BC%EC%97%90%EB%A5%B4_%EC%95%84%EB%B2%A8%EB%9D%BC%EB%A5%B4',\n",
       " 'http://link.springer.com/chapter/10.1007/978-3-319-46675-0_57',\n",
       " \"https://en.wikipedia.org/wiki/Braess'_paradox\",\n",
       " 'https://gist.github.com/vaclavcadek/d29bfd605c90fa91fe7f',\n",
       " 'https://www.vox.com/science-and-health/2018/6/28/17509470/stanford-prison-experiment-zimbardo-interview',\n",
       " 'http://adilmoujahid.com/',\n",
       " 'https://nipy.org/nibabel/coordinate_systems.html',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3281589/',\n",
       " 'https://github.com/domyounglee/korbert-mecab-multigpu',\n",
       " 'https://forum.synology.com/enu/viewtopic.php?t=97097',\n",
       " 'http://luke77.tistory.com/44',\n",
       " 'https://medium.com/analytics-vidhya/forecasting-in-python-with-esrnn-model-75f7fae1d242',\n",
       " 'https://wayhome25.github.io/python/2017/02/26/py-15-class-oop/',\n",
       " 'https://phoby.github.io/ngrok/',\n",
       " 'http://docs.nvidia.com/cuda/cuda-installation-guide-linux/#axzz4ckbljPbv',\n",
       " 'https://techdows.com/2018/05/disable-remove-avast-overseer.html',\n",
       " 'https://www.probabilitycourse.com/chapter5/5_3_1_covariance_correlation.php',\n",
       " 'https://www.rdocumentation.org/packages/umx/versions/1.9.1/topics/umxACE',\n",
       " 'https://end-to-end-machine-learning.teachable.com/',\n",
       " 'https://ko.m.wikipedia.org/wiki/%EB%A1%9C%EC%8A%A4%EC%BC%88%EB%A6%AC%EB%88%84%EC%8A%A4',\n",
       " 'http://minheeblog.tistory.com/49',\n",
       " 'https://www.mathfactory.net/10678',\n",
       " 'https://www.nature.com/articles/d41586-018-00107-4',\n",
       " 'http://m.biz.khan.co.kr/view.html?art_id=201708110600035',\n",
       " 'https://github.com/jeonghanlee/kakaotalk-env',\n",
       " 'https://www.andysbrainblog.com/andysbrainblog/2017/5/5/extracting-timecourses-with-3dmaskdump',\n",
       " 'https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005508',\n",
       " 'https://www.technologyreview.com/s/421505/tracking-the-brains-ability-to-bluff/',\n",
       " 'https://github.com/binder-examples/conda/blob/master/README.md',\n",
       " 'https://en.wikipedia.org/wiki/Inward-rectifier_potassium_ion_channel',\n",
       " 'https://arxiv.org/abs/1606.06121',\n",
       " 'https://stackoverflow.com/questions/46032944/r-post-hoc-comparisons-of-ezanova',\n",
       " 'https://www.fil.ion.ucl.ac.uk/spm/doc/books/hbf2/',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5504789/',\n",
       " 'https://www.frontiersin.org/articles/10.3389/fnhum.2014.00546/full',\n",
       " 'https://m.blog.naver.com/jekyll13/221533203503',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3937846/',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4624839/',\n",
       " 'https://www.nytimes.com/2017/10/27/business/how-to-be-a-ceo.html',\n",
       " 'https://github.com/ContinuumIO/anaconda-issues/issues/11359',\n",
       " 'https://homecuisine.co.kr/hc25/4479',\n",
       " 'https://arxiv.org/abs/1703.06988',\n",
       " 'https://r.789695.n4.nabble.com/lme-vs-lmer-how-do-they-differ-td2534332.html',\n",
       " 'https://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=FSL;39310bd0.0903',\n",
       " 'http://m.blog.daum.net/_blog/_m/articleView.do?blogid=0Uv0f&articleno=171',\n",
       " 'https://m.blog.naver.com/PostView.nhn?blogId=ndb796&logNo=221162559976',\n",
       " 'https://stackoverflow.com/questions/2361945/detecting-consecutive-integers-in-a-list',\n",
       " 'https://www.quantamagazine.org/neutrinos-suggest-solution-to-mystery-of-universes-existence-20171212/',\n",
       " 'http://mn.kbs.co.kr/mobile/news/view.do?ncd=4447307',\n",
       " 'https://statart.tistory.com/m/37',\n",
       " 'https://en.wikipedia.org/wiki/Sensation_seeking',\n",
       " 'https://www.hindawi.com/journals/cmmm/2012/961257/',\n",
       " 'https://www.bbc.com/korean/resources/idt-48d3c9a7-4063-4289-9726-611b5ea9d7b5?at_custom1=%5Bpost%20type%5D',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4705276/',\n",
       " 'http://www.navisphere.net/2530/think-bayes-10-%EA%B7%BC%EC%82%AC-%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88-%EA%B3%84%EC%82%B0/',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5028200/#R44',\n",
       " 'http://ncov.mohw.go.kr/tcmBoardView.do?brdId=&brdGubun=&dataGubun=&ncvContSeq=358768&contSeq=358768&board_id=&gubun=ALL',\n",
       " 'https://www.theguardian.com/books/2004/apr/24/featuresreviews.guardianreview23',\n",
       " 'https://en.m.wikipedia.org/wiki/Red_Queen_Hypothesis',\n",
       " 'https://github.com/ibab/tensorflow-wavenet',\n",
       " 'http://anster.tistory.com/152',\n",
       " 'https://arxiv.org/abs/1803.05627',\n",
       " 'http://mica-mni.github.io/index.html',\n",
       " 'http://journals.sagepub.com/doi/abs/10.1177/0959353513503989?journalCode=fapa',\n",
       " 'https://m.blog.naver.com/urg81/220812908654',\n",
       " 'http://joobarista.khan.kr/40',\n",
       " 'https://www.sciencedaily.com/releases/2015/05/150511090118.htm',\n",
       " 'https://www.gov.kr/portal/coronaPolicy/list/svc/indvdl',\n",
       " 'https://en.wikipedia.org/wiki/Spike-triggered_average',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5383683/',\n",
       " 'https://zapary.blogspot.kr/2015/02/grub-uefi-booting-second-hdd.html?m=1',\n",
       " 'https://en.wikipedia.org/wiki/Mixture_model',\n",
       " 'http://blog.neonkid.xyz/66',\n",
       " 'https://drsimonj.svbtle.com/plotting-individual-observations-and-group-means-with-ggplot2',\n",
       " 'https://blog.outsider.ne.kr/346',\n",
       " 'https://github.com/quqixun/BrainPrep',\n",
       " 'http://news20.busan.com/controller/newsController.jsp?newsId=20180731000047',\n",
       " 'https://stats.stackexchange.com/questions/60842/correcting-for-multiple-2-way-anova-testing',\n",
       " 'http://scikit-learn.org/stable/modules/mixture.html',\n",
       " 'https://www.ncbi.nlm.nih.gov/pubmed/29500078',\n",
       " 'https://github.com/CCS-Lab/hBayesDM',\n",
       " 'https://www.nitrc.org/projects/wfu_pickatlas/',\n",
       " 'https://www.donga.com/news/article/all/20200209/99601504/1',\n",
       " 'http://www.deeplearningbook.org/',\n",
       " 'http://dbr.donga.com/article/view/1203/article_no/8259',\n",
       " 'https://www.ted.com/talks/karissa_sanbonmatsu_the_biology_of_gender_from_dna_to_the_brain?language=ko',\n",
       " 'http://www.ohmynews.com/NWS_Web/View/at_pg.aspx?CNTN_CD=A0002104955',\n",
       " 'https://www.ncbi.nlm.nih.gov/pubmed/29225570/',\n",
       " 'http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/76-add-p-values-and-significance-levels-to-ggplots/',\n",
       " 'http://www.wildml.com/deep-learning-glossary/',\n",
       " 'https://covid19-projections.com/',\n",
       " 'https://docs.python.org/2/library/multiprocessing.html#windows',\n",
       " 'https://github.com/datascopeanalytics/metis-data-science-bootcamp-prework/blob/master/exercises.md',\n",
       " 'http://askubuntu.com/questions/320666/how-do-i-kill-the-x-server',\n",
       " 'https://50plus.or.kr/detail.do?id=1229533',\n",
       " 'https://www.cogsci.uci.edu/',\n",
       " 'https://www.theguardian.com/lifeandstyle/2018/mar/31/elena-ferrante-exclamation-mark',\n",
       " 'http://ejklike.github.io/2017/03/06/install-tensorflow1.0-on-ubuntu16.04-1.html',\n",
       " 'https://github.com/keithito/tacotron/issues/72',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2628634/',\n",
       " 'https://psychologyrocksblog.wordpress.com/gender-and-obedience/',\n",
       " 'https://www.nature.com/articles/d41586-018-00004-w',\n",
       " 'https://brunch.co.kr/@nomdequoii/1',\n",
       " 'https://sites.harding.edu/fmccown/r/',\n",
       " 'http://m.news.naver.com/rankingRead.nhn?oid=055&aid=0000483918&sid1=&ntype=RANKING',\n",
       " 'https://arxiv.org/abs/1706.03762',\n",
       " 'https://m.blog.naver.com/PostView.nhn?blogId=seoyeon_choi&logNo=220451283289',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4746317/',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5225116/',\n",
       " 'http://m.blog.naver.com/sbssbi69/220936702948',\n",
       " 'https://excelsior-cjh.tistory.com/m/86',\n",
       " 'http://pythonkim.tistory.com/m/48',\n",
       " 'http://m.blog.naver.com/PostView.nhn?blogId=crinkim&logNo=220592629201',\n",
       " 'http://onlinelibrary.wiley.com/doi/10.1002/ana.24664/full',\n",
       " 'https://kirillmaltsev.net/blog/personal-knowledge-base',\n",
       " \"https://github.com/eyshin05/TIL/blob/master/Things_I've_Learned.md\",\n",
       " 'http://journal.frontiersin.org/article/10.3389/fncom.2016.00094/full',\n",
       " 'https://www.theguardian.com/books/2017/dec/28/unclear-unfunny-delete-editors-notes-on-milo-yiannopoulos-book-revealed',\n",
       " 'https://mons1220.tistory.com/m/62',\n",
       " 'http://onlinelibrary.wiley.com/book/10.1002/9781119013563',\n",
       " 'https://tensorflow.blog/2017/03/02/review-paper-of-dl-rl/',\n",
       " 'https://openmx.ssri.psu.edu/thread/4102',\n",
       " 'https://stats.stackexchange.com/questions/14088/why-do-lme-and-aov-return-different-results-for-repeated-measures-anova-in-r',\n",
       " 'https://scikit-learn.org/stable/modules/lda_qda.html',\n",
       " 'https://openmx.ssri.psu.edu/thread/1704',\n",
       " 'https://link.springer.com/article/10.1007/s00424-014-1660-6',\n",
       " 'http://adilmoujahid.com/posts/2014/07/baseball-analytics/',\n",
       " 'https://stats.stackexchange.com/questions/2492/is-normality-testing-essentially-useless',\n",
       " 'https://www.nature.com/articles/tp201760',\n",
       " 'https://github.com/kassambara/ggpubr/blob/0df7aee06dc47d748d01cbde2adcc69fa9ceebd4/R/compare_means.R',\n",
       " 'https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=105&oid=003&aid=0009233125',\n",
       " 'https://www.inverse.com/article/53065-can-bees-do-math-wtf',\n",
       " 'http://www.bbc.com/news/world-africa-43079341',\n",
       " 'http://www.mit.edu/afs.new/athena/system/rhlinux/redhat-6.1/doc/rhgsg/s1-managing-working-with-files.htm',\n",
       " 'http://askubuntu.com/questions/841876/how-to-disable-nouveau-kernel-driver',\n",
       " 'http://kindtis.tistory.com/m/590',\n",
       " 'https://github.com/PennBBL/utils/wiki/How-to-Make-Pretty-Surface-Renderings-of-Parcellations-Using-Connectome-Workbench',\n",
       " 'http://thelazylog.com/install-python-as-local-user-on-linux/',\n",
       " 'https://stats.stackexchange.com/questions/13784/repeated-measures-anova-with-lme-lmer-in-r-for-two-within-subject-factors',\n",
       " 'http://gizmodo.com/artificial-curiosity-allows-this-bot-to-triumph-at-mont-1781067908',\n",
       " 'http://dupress.com/articles/behavioral-economics-predictive-analytics/',\n",
       " 'http://internet-nayana.tistory.com/m/47',\n",
       " 'https://en.m.wikipedia.org/wiki/Long_short-term_memory',\n",
       " 'https://physionet.org/content/mimiciii-demo/1.4/',\n",
       " 'https://elementaryforums.com/index.php?threads/howto-install-latest-nvidia-driver-on-linux-without-getting-black-screen.7/',\n",
       " 'https://www.uc.utoronto.ca/programs-study-academic-programs-cognitive-science',\n",
       " 'https://cooking.nytimes.com/recipes/1013327-herbed-white-bean-and-sausage-stew?smid=ck-recipe-iOS-share',\n",
       " 'https://www.nitrc.org/forum/message.php?msg_id=17175',\n",
       " 'https://en.wikipedia.org/wiki/Softmax_function',\n",
       " 'https://www.sciencetimes.co.kr/?news=%eb%b3%b5%ec%96%b4%ea%b0%80-%eb%b3%84%eb%af%b8%ec%9d%b8-%ec%9d%b4%ec%9c%a0%eb%8a%94',\n",
       " 'http://www.grahamwideman.com/gw/brain/fs/coords/fscoords.htm',\n",
       " 'http://m.blog.naver.com/mindo1103/90103407031',\n",
       " 'https://openmx.ssri.psu.edu/thread/2403',\n",
       " 'https://gyuha.tistory.com/491',\n",
       " 'https://kr.mathworks.com/hardware-support/data-acquistion-software.html',\n",
       " 'https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system',\n",
       " 'https://covid19-projections.com/south-korea',\n",
       " 'https://www.nature.com/articles/d41586-017-08835-9',\n",
       " 'https://www.nytimes.com/2020/03/18/magazine/title-ix-sexual-harassment-accusations.html',\n",
       " 'https://gongboobub.tistory.com/83',\n",
       " 'https://blog.ibk.co.kr/1377',\n",
       " 'https://github.com/ANTsX/ANTs/issues/400',\n",
       " 'http://ropas.snu.ac.kr/~kwang/4541.664A/14/',\n",
       " 'http://sciencebooks.minumsa.com/eq-test/',\n",
       " 'https://chatbotsmagazine.com/tensorflow-install-for-gpu-on-linux-902b404b6b30',\n",
       " 'https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python/',\n",
       " 'https://github.com/shoark7/Effective-Python/blob/master/files/BetterWay36_Usesubprocess.md',\n",
       " 'https://ko.m.wikipedia.org/wiki/%EC%9C%A0%EB%AA%85%EB%A1%A0',\n",
       " 'http://brainblogger.com/2014/12/18/does-high-iq-increase-the-risk-of-depression-and-mental-disorders/',\n",
       " 'https://paolotoffanin.wordpress.com/2017/06/04/multiple-mediation-example/',\n",
       " 'https://emmarobinson01.com/2016/02/10/unofficial-guide-to-the-hcp-surface-file-formats/',\n",
       " 'http://m.news.naver.com/rankingRead.nhn?oid=001&aid=0008894051&sid1=&ntype=RANKING',\n",
       " 'https://ko.m.wikipedia.org/wiki/%EC%98%A4%EC%BB%B4%EC%9D%98_%EC%9C%8C%EB%A6%AC%EC%97%84',\n",
       " 'http://www.navisphere.net/2517/think-bayes-8-%EA%B4%80%EC%B8%A1-%ED%8E%B8%ED%96%A5/',\n",
       " 'https://openmx.ssri.psu.edu/thread/443',\n",
       " 'http://bcs.wiley.com/he-bcs/Books?action=index&itemId=1119960746&bcsId=7251',\n",
       " 'https://evols-atirev.tistory.com/14',\n",
       " 'https://www.frontiersin.org/articles/10.3389/fnins.2018.00741/full',\n",
       " 'http://imnt.tistory.com/m/210',\n",
       " 'https://en.wikipedia.org/wiki/Approximate_Bayesian_computation',\n",
       " 'https://openwetware.org/wiki/Beauchamp:Lab_Notebook',\n",
       " 'https://www.ncbi.nlm.nih.gov/pubmed/19209958/',\n",
       " 'https://docs.python.org/3/tutorial/datastructures.html',\n",
       " 'https://techblog-history-younghunjo1.tistory.com/m/24',\n",
       " 'http://stackoverflow.com/questions/3402168/permanently-add-a-directory-to-pythonpath',\n",
       " 'https://ko.m.wikipedia.org/wiki/%ED%98%95%EC%9D%B4%EC%83%81%ED%95%99',\n",
       " 'https://m.blog.naver.com/jjaprince/220309027929',\n",
       " 'https://link.springer.com/article/10.1007/s10985-020-09494-1',\n",
       " 'http://onlinelibrary.wiley.com/doi/10.1002/gps.2643/full',\n",
       " 'https://github.com/ryansmcgee/seirsplus/issues/1',\n",
       " 'https://www.nature.com/articles/tp2014133',\n",
       " 'https://github.com/datanada/Awesome-Korean-NLP/blob/master/README.md',\n",
       " 'https://ko.m.wikipedia.org/wiki/%EC%8B%A4%EC%9E%AC',\n",
       " 'https://www.cambridge.org/core/journals/developmental-medicine-and-child-neurology/article/fine-motor-skills-and-effects-of-methylphenidate-in-children-with-attentiondeficithyperactivity-disorder-and-developmental-coordination-disorder/FBD6CF347709A9AB39A72F8396D85F7C',\n",
       " 'http://sansanee.tistory.com/30',\n",
       " 'https://www.google.co.kr/amp/s/www.hankyung.com/economy/amp/2020070923491',\n",
       " 'https://news.v.daum.net/v/20200904050633049',\n",
       " 'https://www.gutekueche.at/krautfleckerl-rezept-2632',\n",
       " 'https://www.theguardian.com/science/2014/jan/12/what-scientific-idea-is-ready-for-retirement-edge-org?CMP=twt_gu',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4667127/#mmc1',\n",
       " 'https://seaborn.pydata.org/tutorial/relational.html#relational-tutorial',\n",
       " 'http://operativeneurosurgery.com/doku.php?id=supplementary_motor_area',\n",
       " 'https://pythonhosted.org/nipype/index.html',\n",
       " 'http://www.freesurfer.net/fswiki/CerebellumParcellation_Buckner2011',\n",
       " 'https://m.blog.naver.com/PostView.nhn?blogId=mynameisdj&logNo=221785559557',\n",
       " 'https://openmx.ssri.psu.edu/thread/3999',\n",
       " 'https://m.blog.naver.com/kiddwannabe/221811618848',\n",
       " 'http://stackoverflow.com/questions/14444520/two-forward-slashes-in-python',\n",
       " 'http://covid19seoulmind.org/',\n",
       " 'https://www.ncbi.nlm.nih.gov/pubmed/27608958',\n",
       " 'http://www.2cpu.co.kr/bbs/board.php?bo_table=QnA&wr_id=441425',\n",
       " 'http://sanghyukchun.github.io/62/',\n",
       " 'http://pbpython.com/seaborn09.html',\n",
       " 'https://github.com/tomlepaine/fast-wavenet',\n",
       " 'http://schoolofweb.net/blog/posts/%ED%8C%8C%EC%9D%B4%EC%8D%AC-oop-part-2-%ED%81%B4%EB%9E%98%EC%8A%A4%EC%99%80-%EC%9D%B8%EC%8A%A4%ED%84%B4%EC%8A%A4class-and-instance/',\n",
       " 'http://www.kaps.or.kr/src/popup/article.php?no=67',\n",
       " 'https://pythontips.com/2013/08/04/args-and-kwargs-in-python-explained/',\n",
       " 'http://www.johnjosephadams.com/the-living-dead/free-stories-excerpts/some-zombie-contingency-plans-by-kelly-link/',\n",
       " 'https://www.quantamagazine.org/new-theory-cracks-open-the-black-box-of-deep-learning-20170921/',\n",
       " 'http://ppss.kr/archives/77846',\n",
       " 'https://web.mit.edu/cocosci/josh.html',\n",
       " 'http://scikit-learn.org/stable/modules/feature_selection.html',\n",
       " 'https://arxiv.org/abs/1802.06765',\n",
       " 'http://sunyzero.tistory.com/225',\n",
       " 'https://www.edx.org/course/analytics-edge-mitx-15-071x-2',\n",
       " 'https://hbr.org/2018/07/why-women-volunteer-for-tasks-that-dont-lead-to-promotions',\n",
       " 'https://fmrif.nimh.nih.gov/public/other-courses/mvpa',\n",
       " 'https://docs.scrapy.org/en/latest/_modules/scrapy/downloadermiddlewares/redirect.html',\n",
       " 'https://en.wikipedia.org/wiki/Boltzmann_distribution',\n",
       " 'https://stats.stackexchange.com/questions/123651/geometric-interpretation-of-multiple-correlation-coefficient-r-and-coefficient',\n",
       " 'https://arxiv.org/abs/1903.03294',\n",
       " 'http://ksgd2020.org/webzine/2002/02.php',\n",
       " 'https://www.nature.com/articles/s41592-018-0235-4',\n",
       " 'https://www.ncbi.nlm.nih.gov/m/pubmed/23164820/',\n",
       " 'https://stackoverflow.com/questions/43151440/remove-seaborn-barplot-legend-title',\n",
       " 'http://drake.kr/61662',\n",
       " 'http://sugswritersblog.blogspot.kr/2015/07/exhibition-by-31-women-peggy-guggenheim.html?m=1',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3323737/',\n",
       " 'http://m.news.naver.com/rankingRead.nhn?oid=028&aid=0002313953&sid1=105&ntype=RANKING',\n",
       " 'https://hai.stanford.edu/course-offerings',\n",
       " 'http://yuhanrox.co.kr/CleaningTip/40813',\n",
       " 'https://www.nejm.org/doi/10.1056/NEJMoa1806828',\n",
       " 'http://onlinelibrary.wiley.com/doi/10.1002/mds.22285/full',\n",
       " 'https://openmx.ssri.psu.edu/node/4341',\n",
       " 'https://bluese05.tistory.com/30',\n",
       " 'https://www.acmicpc.net/',\n",
       " 'http://science.sciencemag.org/content/338/6103/72',\n",
       " 'http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0148332',\n",
       " 'https://stats.stackexchange.com/questions/221213/specifying-error-in-r-aov-function',\n",
       " 'https://anaconda.org/milesgranger/gap-statistic/notebook',\n",
       " 'https://www.dacon.io/m/competitions/official/235608/codeshare/1274?page=2&dtype=recent&ptype=pub&utm_source=DACON_v2.0&utm_campaign=f91025acf5-EMAIL_CAMPAIGN_2020_08_12_02_08_COPY_01&utm_medium=email&utm_term=0_233bb2c999-f91025acf5-408816797',\n",
       " 'https://www.fast.ai/',\n",
       " 'https://ruccs.rutgers.edu/cdll',\n",
       " 'https://www.cdc.gov/nchs/covid19/pulse/mental-health.htm',\n",
       " 'http://ppss.kr/archives/86481',\n",
       " 'https://openmx.ssri.psu.edu/thread/3190',\n",
       " 'https://can-acn.org/canadian-graduate-programs-in-neuroscience/',\n",
       " 'https://www.analyticsvidhya.com/blog/2015/11/easy-methods-deal-categorical-variables-predictive-modeling/',\n",
       " 'http://m.blog.daum.net/kmozzart/9194',\n",
       " 'https://kr.mathworks.com/help/daq/',\n",
       " 'http://jose-coto.com/styling-with-seaborn',\n",
       " 'https://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=spm;b1ed4077.04',\n",
       " 'http://schoolofweb.net/blog/posts/%ED%8C%8C%EC%9D%B4%EC%8D%AC-oop-part-1-%EA%B0%9D%EC%B2%B4-%EC%A7%80%ED%96%A5-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8Doop%EC%9D%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80-%EC%99%9C-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94%EA%B0%80/',\n",
       " 'http://1boon.kakao.com/bookclub/minibook20180203',\n",
       " 'https://en.wikipedia.org/wiki/Finite-state_transducer',\n",
       " 'https://medium.com/@DakshHub/object-oriented-python-class-es-and-object-s-f9f016674e40',\n",
       " 'https://deepmind.com/blog/article/cognitive-psychology',\n",
       " 'https://sites.google.com/site/econometricsacademy/econometrics-models/bivariate-probit-and-logit-models',\n",
       " 'https://www.kobic.re.kr/',\n",
       " 'https://www.charmcitycakes.com/baltimore-orderacake',\n",
       " 'http://numba.pydata.org/',\n",
       " 'https://medium.com/@pks2974/gatsby-%EB%A1%9C-blog-%EB%A7%8C%EB%93%A4%EA%B8%B0-ac3eed48e068',\n",
       " 'https://www.scientificamerican.com/article/nice-brains-finish-last/',\n",
       " 'https://n.news.naver.com/article/015/0004134571',\n",
       " 'http://jnnp.bmj.com/content/88/2/152',\n",
       " 'https://beenkim.github.io/',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4884740/',\n",
       " 'https://en.wikipedia.org/wiki/Yang_Kyoungjong',\n",
       " 'https://vzio.tistory.com/20',\n",
       " 'http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/79-plot-meansmedians-and-error-bars/',\n",
       " 'https://homecuisine.co.kr/hc25/67419',\n",
       " 'http://www.cureffi.org/2013/02/04/how-to-calculate-heritability/',\n",
       " 'http://m.hankookilbo.com/News/Read/200310200028060953',\n",
       " 'https://brunch.co.kr/@kakao-it/51',\n",
       " 'https://ko.m.wikipedia.org/wiki/SEIR_%EB%AA%A8%ED%98%95',\n",
       " 'https://www.hankyung.com/society/article/2020060235541',\n",
       " 'http://econlog.econlib.org/archives/2012/01/an_answer_to_a.html',\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2605405/',\n",
       " 'https://en.wikipedia.org/wiki/Bandersnatch',\n",
       " 'https://rdrr.io/cran/permuco/man/aovperm.html',\n",
       " 'https://ratsgo.github.io/statistics/2017/05/28/binomial/',\n",
       " 'http://www.ictchallenge.kr/index.php']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_can_parse = list(set(urls) - set(urls_cannot_parse))\n",
    "urls_can_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scheme</th>\n",
       "      <th>netloc</th>\n",
       "      <th>path</th>\n",
       "      <th>params</th>\n",
       "      <th>query</th>\n",
       "      <th>fragment</th>\n",
       "      <th>can_parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https</td>\n",
       "      <td>en.wikipedia.org</td>\n",
       "      <td>/wiki/Basal_ganglia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https</td>\n",
       "      <td>openmx.ssri.psu.edu</td>\n",
       "      <td>/node/4269</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http</td>\n",
       "      <td>sanghyukchun.github.io</td>\n",
       "      <td>/74/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http</td>\n",
       "      <td>aisociety.kr</td>\n",
       "      <td>/prml2017s/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http</td>\n",
       "      <td>lavaan.ugent.be</td>\n",
       "      <td>/tutorial/mediation.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>https</td>\n",
       "      <td>www.ncbi.nlm.nih.gov</td>\n",
       "      <td>/pmc/articles/PMC2605405/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>https</td>\n",
       "      <td>en.wikipedia.org</td>\n",
       "      <td>/wiki/Bandersnatch</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>https</td>\n",
       "      <td>rdrr.io</td>\n",
       "      <td>/cran/permuco/man/aovperm.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>https</td>\n",
       "      <td>ratsgo.github.io</td>\n",
       "      <td>/statistics/2017/05/28/binomial/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>http</td>\n",
       "      <td>www.ictchallenge.kr</td>\n",
       "      <td>/index.php</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>552 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    scheme                  netloc                              path params  \\\n",
       "0    https        en.wikipedia.org               /wiki/Basal_ganglia          \n",
       "1    https     openmx.ssri.psu.edu                        /node/4269          \n",
       "2     http  sanghyukchun.github.io                              /74/          \n",
       "3     http            aisociety.kr                       /prml2017s/          \n",
       "4     http         lavaan.ugent.be          /tutorial/mediation.html          \n",
       "..     ...                     ...                               ...    ...   \n",
       "547  https    www.ncbi.nlm.nih.gov         /pmc/articles/PMC2605405/          \n",
       "548  https        en.wikipedia.org                /wiki/Bandersnatch          \n",
       "549  https                 rdrr.io    /cran/permuco/man/aovperm.html          \n",
       "550  https        ratsgo.github.io  /statistics/2017/05/28/binomial/          \n",
       "551   http     www.ictchallenge.kr                        /index.php          \n",
       "\n",
       "    query fragment  can_parse  \n",
       "0                        True  \n",
       "1                        True  \n",
       "2                        True  \n",
       "3                        True  \n",
       "4                        True  \n",
       "..    ...      ...        ...  \n",
       "547                      True  \n",
       "548                      True  \n",
       "549                      True  \n",
       "550                      True  \n",
       "551                      True  \n",
       "\n",
       "[552 rows x 7 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_component = []\n",
    "for url in urls_can_parse:\n",
    "    urls_component.append(urlparse(url))\n",
    "    \n",
    "urls_can_parse_df = pd.DataFrame(data=urls_component)\n",
    "urls_can_parse_df['can_parse'] = True\n",
    "urls_can_parse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scheme</th>\n",
       "      <th>netloc</th>\n",
       "      <th>path</th>\n",
       "      <th>params</th>\n",
       "      <th>query</th>\n",
       "      <th>fragment</th>\n",
       "      <th>can_parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https</td>\n",
       "      <td>googlefonts.github.io</td>\n",
       "      <td>/korean/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http</td>\n",
       "      <td>ieeexplore.ieee.org</td>\n",
       "      <td>/abstract/document/6033613/</td>\n",
       "      <td></td>\n",
       "      <td>reload=true</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https</td>\n",
       "      <td>theartfulapron.com</td>\n",
       "      <td>/connect-with-us/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http</td>\n",
       "      <td>www.fil.ion.ucl.ac.uk</td>\n",
       "      <td>/mfd_archive/2013/page1/DCM_fMRI_MfD_12_03_201...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http</td>\n",
       "      <td>theeluwin.kr</td>\n",
       "      <td>/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https</td>\n",
       "      <td>www.cs.cmu.edu</td>\n",
       "      <td>/~mktoneva/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https</td>\n",
       "      <td>pythonhosted.org</td>\n",
       "      <td>/nipype/users/examples/smri_cbs_skullstripping...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http</td>\n",
       "      <td>matrix.skku.ac.kr</td>\n",
       "      <td>/knou-knowls/CLA-Week-3.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https</td>\n",
       "      <td>afni.nimh.nih.gov</td>\n",
       "      <td>/pub/dist/doc/program_help/3dttest++.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http</td>\n",
       "      <td>theme.archives.go.kr</td>\n",
       "      <td>/next/populationPolicy/statisticsPopup_20.do</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https</td>\n",
       "      <td>arena.kakao.com</td>\n",
       "      <td>/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>http</td>\n",
       "      <td>dnce.unist.ac.kr</td>\n",
       "      <td>/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https</td>\n",
       "      <td>cs.mtsu.edu</td>\n",
       "      <td>/~rbutler/courses/sam/symdiff/symdiff_rules.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https</td>\n",
       "      <td>bigdata-sme.kr</td>\n",
       "      <td>/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>/datastore/competition</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>http</td>\n",
       "      <td>www.nature.com</td>\n",
       "      <td>/scitable/topicpage/adaptation-and-phenotypic-...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>http</td>\n",
       "      <td>www.ats.ucla.edu</td>\n",
       "      <td>/stat/stata/webbooks/reg/chapter2/statareg2.htm</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>http</td>\n",
       "      <td>wsyang.com</td>\n",
       "      <td>/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https</td>\n",
       "      <td>m.blog.naver.com</td>\n",
       "      <td>/PostList.nhn</td>\n",
       "      <td></td>\n",
       "      <td>blogId=kimboramoo</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>http</td>\n",
       "      <td>www.ianruginski.com</td>\n",
       "      <td>/SEM_FullSEMR_tutorial.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>http</td>\n",
       "      <td>www.ats.ucla.edu</td>\n",
       "      <td>/stat/examples/chp/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>https</td>\n",
       "      <td>www.kaggle.com</td>\n",
       "      <td>/myonin/music-recommendation-random-forest-xgb...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>http</td>\n",
       "      <td>blog.shurain.net</td>\n",
       "      <td>/2014/03/bus-wait-1.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https</td>\n",
       "      <td>www.quora.com</td>\n",
       "      <td>/What-are-some-recent-and-potentially-upcoming...</td>\n",
       "      <td></td>\n",
       "      <td>__hstc=36392319.566e413a48a3eb7d0a2fee1f8154a4...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>http</td>\n",
       "      <td>www.bigdata.go.kr</td>\n",
       "      <td>/bbs.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>http</td>\n",
       "      <td>www.deeplearningbook.org</td>\n",
       "      <td>/contents/linear_algebra.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https</td>\n",
       "      <td>carbon.now.sh</td>\n",
       "      <td>/</td>\n",
       "      <td></td>\n",
       "      <td>bg=rgba(171,%20184,%20195,%201)&amp;t=seti&amp;l=auto&amp;...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>http</td>\n",
       "      <td>cdmanii.com</td>\n",
       "      <td>/4414</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>http</td>\n",
       "      <td>blog.naver.com</td>\n",
       "      <td>/japanbooks/220236875006</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>http</td>\n",
       "      <td>s-space.snu.ac.kr</td>\n",
       "      <td>/handle/10371/94414</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>https</td>\n",
       "      <td>m.blog.naver.com</td>\n",
       "      <td>/PostList.nhn</td>\n",
       "      <td></td>\n",
       "      <td>blogId=mynameisdj</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>http</td>\n",
       "      <td>ibg.colorado.edu</td>\n",
       "      <td>/cdrom2016/maes/UnivariateAnalysis/scriptsOpen...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>https</td>\n",
       "      <td>www.aitrics.com</td>\n",
       "      <td>/publications/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>https</td>\n",
       "      <td>academic.oup.com</td>\n",
       "      <td>/ijnp/article/22/2/105/5098511</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>http</td>\n",
       "      <td>www.neuro.uni-jena.de</td>\n",
       "      <td>/vbm/segmentation/modulation/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>https</td>\n",
       "      <td>www.kaggle.com</td>\n",
       "      <td>/c/trends-assessment-prediction/</td>\n",
       "      <td></td>\n",
       "      <td>utm_medium=email&amp;utm_source=intercom&amp;utm_campa...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>http</td>\n",
       "      <td>blog.naver.com</td>\n",
       "      <td>/haidycoffee/220694488889</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>https</td>\n",
       "      <td>www.gwanghwamoon1st.go.kr</td>\n",
       "      <td>/front/methodPssrp/methodPssrpBbsViewPage.do</td>\n",
       "      <td></td>\n",
       "      <td>bbs_id=9067ba0524d34a4b9407d967dd679fd6</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>https</td>\n",
       "      <td>www.quora.com</td>\n",
       "      <td>/In-what-way-are-Adversarial-Networks-related-...</td>\n",
       "      <td></td>\n",
       "      <td>__hstc=36392319.566e413a48a3eb7d0a2fee1f8154a4...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>https</td>\n",
       "      <td>www.kaggle.com</td>\n",
       "      <td>/lisphilar/covid-19-data-with-sir-model</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>https</td>\n",
       "      <td>www.youthcenter.go.kr</td>\n",
       "      <td>/jynEmpSptNew/jynEmpSptGuide.do</td>\n",
       "      <td></td>\n",
       "      <td>bizId=201903140006</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>http</td>\n",
       "      <td>thecoatlessprofessor.com</td>\n",
       "      <td>/programming/openmp-in-r-on-os-x/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>http</td>\n",
       "      <td>fsl.fmrib.ox.ac.uk</td>\n",
       "      <td>/fsl/fslview/masking.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>https</td>\n",
       "      <td>groups.google.com</td>\n",
       "      <td>/forum/m/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>!topic/dcm4che/SRv6z8YwMqs</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>http</td>\n",
       "      <td>www.cidermics.com</td>\n",
       "      <td>/contents/detail/1397</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>https</td>\n",
       "      <td>zetawiki.com</td>\n",
       "      <td>/wiki/Wget_%EC%A0%9C%EA%B3%B5%EB%90%98%EB%8A%9...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>https</td>\n",
       "      <td>owl.english.purdue.edu</td>\n",
       "      <td>/owl/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>https</td>\n",
       "      <td>norman3.github.io</td>\n",
       "      <td>/papers/docs/google_inception.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>https</td>\n",
       "      <td>starlakim.wordpress.com</td>\n",
       "      <td>/2019/06/29/4020-%ec%9e%91%ec%97%85%eb%b2%95/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>http</td>\n",
       "      <td>www.ats.ucla.edu</td>\n",
       "      <td>/stat/stata/ado/analysis/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>http</td>\n",
       "      <td>throughkim.kr</td>\n",
       "      <td>/2016/04/01/beautifulsoup/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>http</td>\n",
       "      <td>www.uccs.edu</td>\n",
       "      <td>/lbecker/effect-size</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>http</td>\n",
       "      <td>www.gitxiv.com</td>\n",
       "      <td>/posts/NNHa87KfYbwP8ykLC/icml-2017-curiosity-d...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>https</td>\n",
       "      <td>public.tableau.com</td>\n",
       "      <td>/profile/lm.7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>!/vizhome/Mathematicsusedin100jobs/ENG</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>https</td>\n",
       "      <td>plot.ly</td>\n",
       "      <td>/ipython-notebooks/survival-analysis-r-vs-python/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>https</td>\n",
       "      <td>news.hada.io</td>\n",
       "      <td>/topic</td>\n",
       "      <td></td>\n",
       "      <td>id=2458</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>https</td>\n",
       "      <td>www.digitalpsych.org</td>\n",
       "      <td>/join.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>https</td>\n",
       "      <td>github.com</td>\n",
       "      <td>/solleo/mp2rage_ss</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>http</td>\n",
       "      <td>www.jneurosci.org</td>\n",
       "      <td>/content/36/2/432.short</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>http</td>\n",
       "      <td>darkpgmr.tistory.com</td>\n",
       "      <td>/62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>https</td>\n",
       "      <td>www.biorxiv.org</td>\n",
       "      <td>/content/10.1101/578641v1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>https</td>\n",
       "      <td>whooing.com</td>\n",
       "      <td>/zn5r</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>https</td>\n",
       "      <td>www.biorxiv.org</td>\n",
       "      <td>/content/10.1101/568733v1.full</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>http</td>\n",
       "      <td>brain.oxfordjournals.org</td>\n",
       "      <td>/content/136/10/2992</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>https</td>\n",
       "      <td>cojette.github.io</td>\n",
       "      <td>/zombiestat/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>https</td>\n",
       "      <td>m.facebook.com</td>\n",
       "      <td>/cho.k.hyun/posts/10210003563399240</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>http</td>\n",
       "      <td>www.phrgcm.com</td>\n",
       "      <td>/blog/2016/08/05/bellman-eqation/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>http</td>\n",
       "      <td>www.revisemri.com</td>\n",
       "      <td>/questions/pulse_sequences/voxel_size</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>https</td>\n",
       "      <td>www.jstor.org</td>\n",
       "      <td>/stable/25126398</td>\n",
       "      <td></td>\n",
       "      <td>seq=1</td>\n",
       "      <td>page_scan_tab_contents</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>http</td>\n",
       "      <td>www.nature.com</td>\n",
       "      <td>/scitable/topicpage/estimating-trait-heritabil...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>https</td>\n",
       "      <td>www.kaggle.com</td>\n",
       "      <td>/c/competitive-data-science-predict-future-sales</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>http</td>\n",
       "      <td>webzine.seoulmetro.co.kr</td>\n",
       "      <td>/enewspaper/articleview.php</td>\n",
       "      <td></td>\n",
       "      <td>master&amp;aid=1771&amp;ssid=73&amp;mvid=684</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>http</td>\n",
       "      <td>www.gatsby.ucl.ac.uk</td>\n",
       "      <td>/~dayan/book/exercises.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>https</td>\n",
       "      <td>www.dacon.io</td>\n",
       "      <td>/m/competitions/official/235640/overview/rules/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>https</td>\n",
       "      <td>www.biorxiv.org</td>\n",
       "      <td>/content/10.1101/156380v1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>https</td>\n",
       "      <td>yjucho1.github.io</td>\n",
       "      <td>/spatio-temporal%20data/time-series/time-serie...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>https</td>\n",
       "      <td>darkpgmr.tistory.com</td>\n",
       "      <td>/165</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>http</td>\n",
       "      <td>nhuf.molit.go.kr</td>\n",
       "      <td>/FP/FP05/FP0502/FP05020604.jsp</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>https</td>\n",
       "      <td>ssumer.com</td>\n",
       "      <td>/qa-%EB%A7%A5%EC%97%90%EC%84%9C-ftp-%EC%9D%B4%...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>http</td>\n",
       "      <td>rpubs.com</td>\n",
       "      <td>/CCSL/hBayesDM</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>http</td>\n",
       "      <td>sf.jikji.org</td>\n",
       "      <td>/book/index.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>http</td>\n",
       "      <td>www.eunchanbae.com</td>\n",
       "      <td>/2017/07/biostatistics.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>https</td>\n",
       "      <td>blog.naver.com</td>\n",
       "      <td>/thddlghghgh/220619787456</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>https</td>\n",
       "      <td>www.google.co.kr</td>\n",
       "      <td>/</td>\n",
       "      <td></td>\n",
       "      <td>gfe_rd=cr&amp;ei=Gk9GV9npEez98we94JCYAg</td>\n",
       "      <td>q=cingulate+mask+fslview</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>https</td>\n",
       "      <td>github.com</td>\n",
       "      <td>/AllenDowney/ThinkBayes2/blob/master/code/redl...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>https</td>\n",
       "      <td>www.kaggle.com</td>\n",
       "      <td>/danielwolffram/topic-modeling-finding-related...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>http</td>\n",
       "      <td>biorxiv.org</td>\n",
       "      <td>/cgi/content/short/608349v1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>https</td>\n",
       "      <td>carpedm20.github.io</td>\n",
       "      <td>/tacotron/en.html</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>http</td>\n",
       "      <td>www.jneurosci.org</td>\n",
       "      <td>/content/38/20/4724</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>http</td>\n",
       "      <td>sanghyukchun.github.io</td>\n",
       "      <td>/58/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>https</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>/@omicro03/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%9...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>https</td>\n",
       "      <td>taeoh-kim.github.io</td>\n",
       "      <td>/blog/generative-models-part-1-vaegandcgan/</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scheme                     netloc  \\\n",
       "0   https      googlefonts.github.io   \n",
       "1    http        ieeexplore.ieee.org   \n",
       "2   https         theartfulapron.com   \n",
       "3    http      www.fil.ion.ucl.ac.uk   \n",
       "4    http               theeluwin.kr   \n",
       "5   https             www.cs.cmu.edu   \n",
       "6   https           pythonhosted.org   \n",
       "7    http          matrix.skku.ac.kr   \n",
       "8   https          afni.nimh.nih.gov   \n",
       "9    http       theme.archives.go.kr   \n",
       "10  https            arena.kakao.com   \n",
       "11   http           dnce.unist.ac.kr   \n",
       "12  https                cs.mtsu.edu   \n",
       "13  https             bigdata-sme.kr   \n",
       "14   http             www.nature.com   \n",
       "15   http           www.ats.ucla.edu   \n",
       "16   http                 wsyang.com   \n",
       "17  https           m.blog.naver.com   \n",
       "18   http        www.ianruginski.com   \n",
       "19   http           www.ats.ucla.edu   \n",
       "20  https             www.kaggle.com   \n",
       "21   http           blog.shurain.net   \n",
       "22  https              www.quora.com   \n",
       "23   http          www.bigdata.go.kr   \n",
       "24   http   www.deeplearningbook.org   \n",
       "25  https              carbon.now.sh   \n",
       "26   http                cdmanii.com   \n",
       "27   http             blog.naver.com   \n",
       "28   http          s-space.snu.ac.kr   \n",
       "29  https           m.blog.naver.com   \n",
       "30   http           ibg.colorado.edu   \n",
       "31  https            www.aitrics.com   \n",
       "32  https           academic.oup.com   \n",
       "33   http      www.neuro.uni-jena.de   \n",
       "34  https             www.kaggle.com   \n",
       "35   http             blog.naver.com   \n",
       "36  https  www.gwanghwamoon1st.go.kr   \n",
       "37  https              www.quora.com   \n",
       "38  https             www.kaggle.com   \n",
       "39  https      www.youthcenter.go.kr   \n",
       "40   http   thecoatlessprofessor.com   \n",
       "41   http         fsl.fmrib.ox.ac.uk   \n",
       "42  https          groups.google.com   \n",
       "43   http          www.cidermics.com   \n",
       "44  https               zetawiki.com   \n",
       "45  https     owl.english.purdue.edu   \n",
       "46  https          norman3.github.io   \n",
       "47  https    starlakim.wordpress.com   \n",
       "48   http           www.ats.ucla.edu   \n",
       "49   http              throughkim.kr   \n",
       "50   http               www.uccs.edu   \n",
       "51   http             www.gitxiv.com   \n",
       "52  https         public.tableau.com   \n",
       "53  https                    plot.ly   \n",
       "54  https               news.hada.io   \n",
       "55  https       www.digitalpsych.org   \n",
       "56  https                 github.com   \n",
       "57   http          www.jneurosci.org   \n",
       "58   http       darkpgmr.tistory.com   \n",
       "59  https            www.biorxiv.org   \n",
       "60  https                whooing.com   \n",
       "61  https            www.biorxiv.org   \n",
       "62   http   brain.oxfordjournals.org   \n",
       "63  https          cojette.github.io   \n",
       "64  https             m.facebook.com   \n",
       "65   http             www.phrgcm.com   \n",
       "66   http          www.revisemri.com   \n",
       "67  https              www.jstor.org   \n",
       "68   http             www.nature.com   \n",
       "69  https             www.kaggle.com   \n",
       "70   http   webzine.seoulmetro.co.kr   \n",
       "71   http       www.gatsby.ucl.ac.uk   \n",
       "72  https               www.dacon.io   \n",
       "73  https            www.biorxiv.org   \n",
       "74  https          yjucho1.github.io   \n",
       "75  https       darkpgmr.tistory.com   \n",
       "76   http           nhuf.molit.go.kr   \n",
       "77  https                 ssumer.com   \n",
       "78   http                  rpubs.com   \n",
       "79   http               sf.jikji.org   \n",
       "80   http         www.eunchanbae.com   \n",
       "81  https             blog.naver.com   \n",
       "82  https           www.google.co.kr   \n",
       "83  https                 github.com   \n",
       "84  https             www.kaggle.com   \n",
       "85   http                biorxiv.org   \n",
       "86  https        carpedm20.github.io   \n",
       "87   http          www.jneurosci.org   \n",
       "88   http     sanghyukchun.github.io   \n",
       "89  https                 medium.com   \n",
       "90  https        taeoh-kim.github.io   \n",
       "\n",
       "                                                 path params  \\\n",
       "0                                            /korean/          \n",
       "1                         /abstract/document/6033613/          \n",
       "2                                   /connect-with-us/          \n",
       "3   /mfd_archive/2013/page1/DCM_fMRI_MfD_12_03_201...          \n",
       "4                                                   /          \n",
       "5                                         /~mktoneva/          \n",
       "6   /nipype/users/examples/smri_cbs_skullstripping...          \n",
       "7                        /knou-knowls/CLA-Week-3.html          \n",
       "8           /pub/dist/doc/program_help/3dttest++.html          \n",
       "9        /next/populationPolicy/statisticsPopup_20.do          \n",
       "10                                                  /          \n",
       "11                                                  /          \n",
       "12   /~rbutler/courses/sam/symdiff/symdiff_rules.html          \n",
       "13                                                  /          \n",
       "14  /scitable/topicpage/adaptation-and-phenotypic-...          \n",
       "15    /stat/stata/webbooks/reg/chapter2/statareg2.htm          \n",
       "16                                                  /          \n",
       "17                                      /PostList.nhn          \n",
       "18                        /SEM_FullSEMR_tutorial.html          \n",
       "19                                /stat/examples/chp/          \n",
       "20  /myonin/music-recommendation-random-forest-xgb...          \n",
       "21                           /2014/03/bus-wait-1.html          \n",
       "22  /What-are-some-recent-and-potentially-upcoming...          \n",
       "23                                          /bbs.html          \n",
       "24                      /contents/linear_algebra.html          \n",
       "25                                                  /          \n",
       "26                                              /4414          \n",
       "27                           /japanbooks/220236875006          \n",
       "28                                /handle/10371/94414          \n",
       "29                                      /PostList.nhn          \n",
       "30  /cdrom2016/maes/UnivariateAnalysis/scriptsOpen...          \n",
       "31                                     /publications/          \n",
       "32                     /ijnp/article/22/2/105/5098511          \n",
       "33                      /vbm/segmentation/modulation/          \n",
       "34                   /c/trends-assessment-prediction/          \n",
       "35                          /haidycoffee/220694488889          \n",
       "36       /front/methodPssrp/methodPssrpBbsViewPage.do          \n",
       "37  /In-what-way-are-Adversarial-Networks-related-...          \n",
       "38            /lisphilar/covid-19-data-with-sir-model          \n",
       "39                    /jynEmpSptNew/jynEmpSptGuide.do          \n",
       "40                  /programming/openmp-in-r-on-os-x/          \n",
       "41                          /fsl/fslview/masking.html          \n",
       "42                                          /forum/m/          \n",
       "43                              /contents/detail/1397          \n",
       "44  /wiki/Wget_%EC%A0%9C%EA%B3%B5%EB%90%98%EB%8A%9...          \n",
       "45                                              /owl/          \n",
       "46                 /papers/docs/google_inception.html          \n",
       "47      /2019/06/29/4020-%ec%9e%91%ec%97%85%eb%b2%95/          \n",
       "48                          /stat/stata/ado/analysis/          \n",
       "49                         /2016/04/01/beautifulsoup/          \n",
       "50                               /lbecker/effect-size          \n",
       "51  /posts/NNHa87KfYbwP8ykLC/icml-2017-curiosity-d...          \n",
       "52                                      /profile/lm.7          \n",
       "53  /ipython-notebooks/survival-analysis-r-vs-python/          \n",
       "54                                             /topic          \n",
       "55                                         /join.html          \n",
       "56                                 /solleo/mp2rage_ss          \n",
       "57                            /content/36/2/432.short          \n",
       "58                                                /62          \n",
       "59                          /content/10.1101/578641v1          \n",
       "60                                              /zn5r          \n",
       "61                     /content/10.1101/568733v1.full          \n",
       "62                               /content/136/10/2992          \n",
       "63                                       /zombiestat/          \n",
       "64                /cho.k.hyun/posts/10210003563399240          \n",
       "65                  /blog/2016/08/05/bellman-eqation/          \n",
       "66              /questions/pulse_sequences/voxel_size          \n",
       "67                                   /stable/25126398          \n",
       "68  /scitable/topicpage/estimating-trait-heritabil...          \n",
       "69   /c/competitive-data-science-predict-future-sales          \n",
       "70                        /enewspaper/articleview.php          \n",
       "71                        /~dayan/book/exercises.html          \n",
       "72    /m/competitions/official/235640/overview/rules/          \n",
       "73                          /content/10.1101/156380v1          \n",
       "74  /spatio-temporal%20data/time-series/time-serie...          \n",
       "75                                               /165          \n",
       "76                     /FP/FP05/FP0502/FP05020604.jsp          \n",
       "77  /qa-%EB%A7%A5%EC%97%90%EC%84%9C-ftp-%EC%9D%B4%...          \n",
       "78                                     /CCSL/hBayesDM          \n",
       "79                                   /book/index.html          \n",
       "80                        /2017/07/biostatistics.html          \n",
       "81                          /thddlghghgh/220619787456          \n",
       "82                                                  /          \n",
       "83  /AllenDowney/ThinkBayes2/blob/master/code/redl...          \n",
       "84  /danielwolffram/topic-modeling-finding-related...          \n",
       "85                        /cgi/content/short/608349v1          \n",
       "86                                  /tacotron/en.html          \n",
       "87                                /content/38/20/4724          \n",
       "88                                               /58/          \n",
       "89  /@omicro03/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%9...          \n",
       "90        /blog/generative-models-part-1-vaegandcgan/          \n",
       "\n",
       "                                                query  \\\n",
       "0                                                       \n",
       "1                                         reload=true   \n",
       "2                                                       \n",
       "3                                                       \n",
       "4                                                       \n",
       "5                                                       \n",
       "6                                                       \n",
       "7                                                       \n",
       "8                                                       \n",
       "9                                                       \n",
       "10                                                      \n",
       "11                                                      \n",
       "12                                                      \n",
       "13                                                      \n",
       "14                                                      \n",
       "15                                                      \n",
       "16                                                      \n",
       "17                                  blogId=kimboramoo   \n",
       "18                                                      \n",
       "19                                                      \n",
       "20                                                      \n",
       "21                                                      \n",
       "22  __hstc=36392319.566e413a48a3eb7d0a2fee1f8154a4...   \n",
       "23                                                      \n",
       "24                                                      \n",
       "25  bg=rgba(171,%20184,%20195,%201)&t=seti&l=auto&...   \n",
       "26                                                      \n",
       "27                                                      \n",
       "28                                                      \n",
       "29                                  blogId=mynameisdj   \n",
       "30                                                      \n",
       "31                                                      \n",
       "32                                                      \n",
       "33                                                      \n",
       "34  utm_medium=email&utm_source=intercom&utm_campa...   \n",
       "35                                                      \n",
       "36            bbs_id=9067ba0524d34a4b9407d967dd679fd6   \n",
       "37  __hstc=36392319.566e413a48a3eb7d0a2fee1f8154a4...   \n",
       "38                                                      \n",
       "39                                 bizId=201903140006   \n",
       "40                                                      \n",
       "41                                                      \n",
       "42                                                      \n",
       "43                                                      \n",
       "44                                                      \n",
       "45                                                      \n",
       "46                                                      \n",
       "47                                                      \n",
       "48                                                      \n",
       "49                                                      \n",
       "50                                                      \n",
       "51                                                      \n",
       "52                                                      \n",
       "53                                                      \n",
       "54                                            id=2458   \n",
       "55                                                      \n",
       "56                                                      \n",
       "57                                                      \n",
       "58                                                      \n",
       "59                                                      \n",
       "60                                                      \n",
       "61                                                      \n",
       "62                                                      \n",
       "63                                                      \n",
       "64                                                      \n",
       "65                                                      \n",
       "66                                                      \n",
       "67                                              seq=1   \n",
       "68                                                      \n",
       "69                                                      \n",
       "70                   master&aid=1771&ssid=73&mvid=684   \n",
       "71                                                      \n",
       "72                                                      \n",
       "73                                                      \n",
       "74                                                      \n",
       "75                                                      \n",
       "76                                                      \n",
       "77                                                      \n",
       "78                                                      \n",
       "79                                                      \n",
       "80                                                      \n",
       "81                                                      \n",
       "82                gfe_rd=cr&ei=Gk9GV9npEez98we94JCYAg   \n",
       "83                                                      \n",
       "84                                                      \n",
       "85                                                      \n",
       "86                                                      \n",
       "87                                                      \n",
       "88                                                      \n",
       "89                                                      \n",
       "90                                                      \n",
       "\n",
       "                                  fragment  can_parse  \n",
       "0                                               False  \n",
       "1                                               False  \n",
       "2                                               False  \n",
       "3                                               False  \n",
       "4                                               False  \n",
       "5                                               False  \n",
       "6                                               False  \n",
       "7                                               False  \n",
       "8                                               False  \n",
       "9                                               False  \n",
       "10                                              False  \n",
       "11                                              False  \n",
       "12                                              False  \n",
       "13                  /datastore/competition      False  \n",
       "14                                              False  \n",
       "15                                              False  \n",
       "16                                              False  \n",
       "17                                              False  \n",
       "18                                              False  \n",
       "19                                              False  \n",
       "20                                              False  \n",
       "21                                              False  \n",
       "22                                              False  \n",
       "23                                              False  \n",
       "24                                              False  \n",
       "25                                              False  \n",
       "26                                              False  \n",
       "27                                              False  \n",
       "28                                              False  \n",
       "29                                              False  \n",
       "30                                              False  \n",
       "31                                              False  \n",
       "32                                              False  \n",
       "33                                              False  \n",
       "34                                              False  \n",
       "35                                              False  \n",
       "36                                              False  \n",
       "37                                              False  \n",
       "38                                              False  \n",
       "39                                              False  \n",
       "40                                              False  \n",
       "41                                              False  \n",
       "42              !topic/dcm4che/SRv6z8YwMqs      False  \n",
       "43                                              False  \n",
       "44                                              False  \n",
       "45                                              False  \n",
       "46                                              False  \n",
       "47                                              False  \n",
       "48                                              False  \n",
       "49                                              False  \n",
       "50                                              False  \n",
       "51                                              False  \n",
       "52  !/vizhome/Mathematicsusedin100jobs/ENG      False  \n",
       "53                                              False  \n",
       "54                                              False  \n",
       "55                                              False  \n",
       "56                                              False  \n",
       "57                                              False  \n",
       "58                                              False  \n",
       "59                                              False  \n",
       "60                                              False  \n",
       "61                                              False  \n",
       "62                                              False  \n",
       "63                                              False  \n",
       "64                                              False  \n",
       "65                                              False  \n",
       "66                                              False  \n",
       "67                  page_scan_tab_contents      False  \n",
       "68                                              False  \n",
       "69                                              False  \n",
       "70                                              False  \n",
       "71                                              False  \n",
       "72                                              False  \n",
       "73                                              False  \n",
       "74                                              False  \n",
       "75                                              False  \n",
       "76                                              False  \n",
       "77                                              False  \n",
       "78                                              False  \n",
       "79                                              False  \n",
       "80                                              False  \n",
       "81                                              False  \n",
       "82                q=cingulate+mask+fslview      False  \n",
       "83                                              False  \n",
       "84                                              False  \n",
       "85                                              False  \n",
       "86                                              False  \n",
       "87                                              False  \n",
       "88                                              False  \n",
       "89                                              False  \n",
       "90                                              False  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_component = []\n",
    "for url in urls_cannot_parse:\n",
    "    urls_component.append(urlparse(url))\n",
    "\n",
    "urls_cannot_parse_df = pd.DataFrame(data=urls_component)\n",
    "urls_cannot_parse_df['can_parse'] = False\n",
    "urls_cannot_parse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_parse_df = pd.concat([urls_can_parse_df, urls_cannot_parse_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_row', 500)\n",
    "temp_df = urls_parse_df.loc[:, ['netloc', 'can_parse']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "netloc                                        can_parse\n",
       "www.ncbi.nlm.nih.gov                          True         33\n",
       "github.com                                    True         25\n",
       "en.wikipedia.org                              True         16\n",
       "m.blog.naver.com                              True         16\n",
       "ko.m.wikipedia.org                            True         11\n",
       "www.nature.com                                True         11\n",
       "stackoverflow.com                             True         10\n",
       "openmx.ssri.psu.edu                           True         10\n",
       "brunch.co.kr                                  True          9\n",
       "arxiv.org                                     True          9\n",
       "stats.stackexchange.com                       True          8\n",
       "www.google.co.kr                              True          6\n",
       "onlinelibrary.wiley.com                       True          6\n",
       "medium.com                                    True          6\n",
       "m.news.naver.com                              True          6\n",
       "askubuntu.com                                 True          6\n",
       "news.v.daum.net                               True          5\n",
       "www.kaggle.com                                False         5\n",
       "science.sciencemag.org                        True          5\n",
       "www.bbc.com                                   True          5\n",
       "link.springer.com                             True          4\n",
       "scikit-learn.org                              True          4\n",
       "www.scientificamerican.com                    True          4\n",
       "homecuisine.co.kr                             True          4\n",
       "m.hankookilbo.com                             True          4\n",
       "www.frontiersin.org                           True          4\n",
       "ppss.kr                                       True          4\n",
       "www.theguardian.com                           True          4\n",
       "en.m.wikipedia.org                            True          3\n",
       "wikidocs.net                                  True          3\n",
       "www.navisphere.net                            True          3\n",
       "journals.plos.org                             True          3\n",
       "www.ats.ucla.edu                              False         3\n",
       "blog.naver.com                                False         3\n",
       "www.nytimes.com                               True          3\n",
       "www.biorxiv.org                               False         3\n",
       "kr.mathworks.com                              True          3\n",
       "schoolofweb.net                               True          3\n",
       "www.sthda.com                                 True          3\n",
       "tbates.github.io                              True          2\n",
       "github.com                                    False         2\n",
       "pythonhosted.org                              True          2\n",
       "tensorflow.blog                               True          2\n",
       "www.grahamwideman.com                         True          2\n",
       "pythonkim.tistory.com                         True          2\n",
       "www.hindawi.com                               True          2\n",
       "www.cell.com                                  True          2\n",
       "journal.frontiersin.org                       True          2\n",
       "r.789695.n4.nabble.com                        True          2\n",
       "rdrr.io                                       True          2\n",
       "sunyzero.tistory.com                          True          2\n",
       "covid19-projections.com                       True          2\n",
       "robotenomics.com                              True          2\n",
       "darkpgmr.tistory.com                          False         2\n",
       "sanghyukchun.github.io                        True          2\n",
       "brownbears.tistory.com                        True          2\n",
       "docs.python.org                               True          2\n",
       "sites.google.com                              True          2\n",
       "deepmind.com                                  True          2\n",
       "velog.io                                      True          2\n",
       "www.technologyreview.com                      True          2\n",
       "neuroscience.stanford.edu                     True          2\n",
       "n.news.naver.com                              True          2\n",
       "www.newyorker.com                             True          2\n",
       "www.nitrc.org                                 True          2\n",
       "m.blog.naver.com                              False         2\n",
       "blog.daum.net                                 True          2\n",
       "adilmoujahid.com                              True          2\n",
       "operativeneurosurgery.com                     True          2\n",
       "www.nature.com                                False         2\n",
       "www.vox.com                                   True          2\n",
       "m.blog.daum.net                               True          2\n",
       "www.quantamagazine.org                        True          2\n",
       "www.quora.com                                 False         2\n",
       "www.jiscmail.ac.uk                            True          2\n",
       "www.rdocumentation.org                        True          2\n",
       "www.jneurosci.org                             False         2\n",
       "afni.nimh.nih.gov                             True          2\n",
       "matrix.skku.ac.kr                             False         1\n",
       "hiseon.me                                     True          1\n",
       "maternalgrandfather.tistory.com               True          1\n",
       "hogni.tistory.com                             True          1\n",
       "hcnoh.github.io                               True          1\n",
       "marshall-ku.com                               True          1\n",
       "ko.wikipedia.org                              True          1\n",
       "hbr.org                                       True          1\n",
       "hsaghir.github.io                             True          1\n",
       "hackernoon.com                                True          1\n",
       "mbtaviz.github.io                             True          1\n",
       "gyuha.tistory.com                             True          1\n",
       "mchankins.wordpress.com                       True          1\n",
       "groups.google.com                             False         1\n",
       "gorakgarak.tistory.com                        True          1\n",
       "googlefonts.github.io                         False         1\n",
       "gongboobub.tistory.com                        True          1\n",
       "gizmodo.com                                   True          1\n",
       "medium.com                                    False         1\n",
       "hai.stanford.edu                              True          1\n",
       "m.ohmynews.com                                True          1\n",
       "hunkim.github.io                              True          1\n",
       "marcnu.github.io                              True          1\n",
       "ksgd2020.org                                  True          1\n",
       "kindtis.tistory.com                           True          1\n",
       "journals.sagepub.com                          True          1\n",
       "lavaan.ugent.be                               True          1\n",
       "lindeloev.github.io                           True          1\n",
       "lucasg.github.io                              True          1\n",
       "luke77.tistory.com                            True          1\n",
       "m-clark.github.io                             True          1\n",
       "m.biz.khan.co.kr                              True          1\n",
       "jose-coto.com                                 True          1\n",
       "joobarista.khan.kr                            True          1\n",
       "jnnp.bmj.com                                  True          1\n",
       "jinchory.tistory.com                          True          1\n",
       "internet-nayana.tistory.com                   True          1\n",
       "imnt.tistory.com                              True          1\n",
       "imnews.imbc.com                               True          1\n",
       "m.facebook.com                                False         1\n",
       "imaginary.org                                 True          1\n",
       "m.facebook.com                                True          1\n",
       "ifyourfriendishacker.tistory.com              True          1\n",
       "ieeexplore.ieee.org                           False         1\n",
       "ibg.colorado.edu                              False         1\n",
       "hurcy.github.io                               True          1\n",
       "kirillmaltsev.net                             True          1\n",
       "zhiyzuo.github.io                             True          1\n",
       "gist.github.com                               True          1\n",
       "bookdown.org                                  True          1\n",
       "blog.ibk.co.kr                                True          1\n",
       "blog.linewalks.com                            True          1\n",
       "blog.neonkid.xyz                              True          1\n",
       "blog.outsider.ne.kr                           True          1\n",
       "blog.shurain.net                              False         1\n",
       "bluese05.tistory.com                          True          1\n",
       "bmcbioinformatics.biomedcentral.com           True          1\n",
       "bokeh.pydata.org                              True          1\n",
       "brain.oxfordjournals.org                      False         1\n",
       "galid1.tistory.com                            True          1\n",
       "brainblogger.com                              True          1\n",
       "brainmind.com                                 True          1\n",
       "bryan7.tistory.com                            True          1\n",
       "can-acn.org                                   True          1\n",
       "capmh.biomedcentral.com                       True          1\n",
       "carbon.now.sh                                 False         1\n",
       "carpedm20.github.io                           False         1\n",
       "cdmanii.com                                   False         1\n",
       "blog.engintruder.com                          True          1\n",
       "blog.dataiku.com                              True          1\n",
       "blog.cogneurostats.com                        True          1\n",
       "biorxiv.org                                   False         1\n",
       "1boon.daum.net                                True          1\n",
       "1boon.kakao.com                               True          1\n",
       "50plus.or.kr                                  True          1\n",
       "academic.oup.com                              False         1\n",
       "afni.nimh.nih.gov                             False         1\n",
       "aisociety.kr                                  True          1\n",
       "alphago.pe.kr                                 True          1\n",
       "anaconda.org                                  True          1\n",
       "andysbrainblog.blogspot.kr                    True          1\n",
       "anster.tistory.com                            True          1\n",
       "arena.kakao.com                               False         1\n",
       "aws.amazon.com                                True          1\n",
       "bcs.wiley.com                                 True          1\n",
       "beenkim.github.io                             True          1\n",
       "beomi.github.io                               True          1\n",
       "biaswatchneuro.com                            True          1\n",
       "bigdata-sme.kr                                False         1\n",
       "chatbotsmagazine.com                          True          1\n",
       "chris.beams.io                                True          1\n",
       "chukycheese.github.io                         True          1\n",
       "econlog.econlib.org                           True          1\n",
       "edition-m.cnn.com                             True          1\n",
       "ejklike.github.io                             True          1\n",
       "elementaryforums.com                          True          1\n",
       "mica-mni.github.io                            True          1\n",
       "emmarobinson01.com                            True          1\n",
       "end-to-end-machine-learning.teachable.com     True          1\n",
       "engineering.nyu.edu                           True          1\n",
       "english.seoul.go.kr                           True          1\n",
       "evols-atirev.tistory.com                      True          1\n",
       "excelsior-cjh.tistory.com                     True          1\n",
       "fabl1106.github.io                            True          1\n",
       "flyingdcat4.tistory.com                       True          1\n",
       "fmrif.nimh.nih.gov                            True          1\n",
       "forum.arduino.cc                              True          1\n",
       "forum.synology.com                            True          1\n",
       "fsl.fmrib.ox.ac.uk                            False         1\n",
       "futurism.com                                  True          1\n",
       "economiology.com                              True          1\n",
       "dupress.com                                   True          1\n",
       "cni.stanford.edu                              True          1\n",
       "drsimonj.svbtle.com                           True          1\n",
       "cojette.github.io                             False         1\n",
       "cooking.nytimes.com                           True          1\n",
       "covid19seoulmind.org                          True          1\n",
       "cs.mtsu.edu                                   False         1\n",
       "cython.org                                    True          1\n",
       "datadryad.org                                 True          1\n",
       "dataitgirls2.github.io                        True          1\n",
       "datascienceplus.com                           True          1\n",
       "dbr.donga.com                                 True          1\n",
       "developer.mozilla.org                         True          1\n",
       "developers.google.com                         True          1\n",
       "discourse.slicer.org                          True          1\n",
       "dnce.unist.ac.kr                              False         1\n",
       "docs.nvidia.com                               True          1\n",
       "docs.scrapy.org                               True          1\n",
       "dpaniukov.github.io                           True          1\n",
       "drake.kr                                      True          1\n",
       "mental.jmir.org                               True          1\n",
       "paolotoffanin.wordpress.com                   True          1\n",
       "minheeblog.tistory.com                        True          1\n",
       "www.google.co.kr                              False         1\n",
       "www.fast.ai                                   True          1\n",
       "www.fil.ion.ucl.ac.uk                         False         1\n",
       "                                              True          1\n",
       "www.freesurfer.net                            True          1\n",
       "www.gatsby.ucl.ac.uk                          False         1\n",
       "                                              True          1\n",
       "www.gitxiv.com                                False         1\n",
       "www.gov.kr                                    True          1\n",
       "www.edx.org                                   True          1\n",
       "www.gutekueche.at                             True          1\n",
       "www.gwanghwamoon1st.go.kr                     False         1\n",
       "www.hani.co.kr                                True          1\n",
       "www.hankyung.com                              True          1\n",
       "www.ianruginski.com                           False         1\n",
       "www.ictchallenge.kr                           True          1\n",
       "www.inverse.com                               True          1\n",
       "www.eunchanbae.com                            False         1\n",
       "www.dongascience.com                          True          1\n",
       "www.jamieoliver.com                           True          1\n",
       "www.culture.go.kr                             True          1\n",
       "www.cambridge.org                             True          1\n",
       "www.canada.ca                                 True          1\n",
       "www.cdc.gov                                   True          1\n",
       "www.charmcitycakes.com                        True          1\n",
       "www.cidermics.com                             False         1\n",
       "www.cogsci.uci.edu                            True          1\n",
       "www.cs.cmu.edu                                False         1\n",
       "www.cureffi.org                               True          1\n",
       "www.donga.com                                 True          1\n",
       "www.curiousily.com                            True          1\n",
       "www.dacon.io                                  False         1\n",
       "                                              True          1\n",
       "www.databaser.net                             True          1\n",
       "www.deeplearningbook.org                      False         1\n",
       "                                              True          1\n",
       "www.digitalpsych.org                          False         1\n",
       "www.j-alz.com                                 True          1\n",
       "www.johnjosephadams.com                       True          1\n",
       "www.bloter.net                                True          1\n",
       "www.uc.utoronto.ca                            True          1\n",
       "www.r-bloggers.com                            True          1\n",
       "www.revisemri.com                             False         1\n",
       "www.sciencedaily.com                          True          1\n",
       "www.sciencemag.org                            True          1\n",
       "www.sciencetimes.co.kr                        True          1\n",
       "www.ted.com                                   True          1\n",
       "www.theatlantic.com                           True          1\n",
       "www.uccs.edu                                  False         1\n",
       "www.probabilitycourse.com                     True          1\n",
       "www.wildml.com                                True          1\n",
       "www.write.com                                 True          1\n",
       "www.youthcenter.go.kr                         False         1\n",
       "xcorr.net                                     True          1\n",
       "yjucho1.github.io                             False         1\n",
       "yuhanrox.co.kr                                True          1\n",
       "zapary.blogspot.kr                            True          1\n",
       "www.pylint.org                                True          1\n",
       "www.princeton.edu                             True          1\n",
       "www.jstor.org                                 False         1\n",
       "www.mit.edu                                   True          1\n",
       "www.kaps.or.kr                                True          1\n",
       "www.kobic.re.kr                               True          1\n",
       "www.lead-dbs.org                              True          1\n",
       "www.lucidarme.me                              True          1\n",
       "www.machinelearningplus.com                   True          1\n",
       "www.mathfactory.net                           True          1\n",
       "www.mhanational.org                           True          1\n",
       "www.moel.go.kr                                True          1\n",
       "www.pnas.org                                  True          1\n",
       "www.mturk.com                                 True          1\n",
       "www.neca.re.kr                                True          1\n",
       "www.nejm.org                                  True          1\n",
       "www.neuro.uni-jena.de                         False         1\n",
       "www.newstof.com                               True          1\n",
       "www.ohmynews.com                              True          1\n",
       "www.phrgcm.com                                False         1\n",
       "www.boxnwhis.kr                               True          1\n",
       "www.bigdata.go.kr                             False         1\n",
       "miykael.github.io                             True          1\n",
       "python.bakyeono.net                           True          1\n",
       "piie.com                                      True          1\n",
       "plot.ly                                       False         1\n",
       "protocols.humanconnectome.org                 True          1\n",
       "psychologyrocksblog.wordpress.com             True          1\n",
       "public.tableau.com                            False         1\n",
       "pyformat.info                                 True          1\n",
       "python-3-patterns-idioms-test.readthedocs.io  True          1\n",
       "python.quantecon.org                          True          1\n",
       "phoby.github.io                               True          1\n",
       "pythonhosted.org                              False         1\n",
       "pythontips.com                                True          1\n",
       "ratsgo.github.io                              True          1\n",
       "resumegenius.com                              True          1\n",
       "ropas.snu.ac.kr                               True          1\n",
       "rpubs.com                                     False         1\n",
       "ruccs.rutgers.edu                             True          1\n",
       "physionet.org                                 True          1\n",
       "pbpython.com                                  True          1\n",
       "sanghyukchun.github.io                        False         1\n",
       "news20.busan.com                              True          1\n",
       "mn.kbs.co.kr                                  True          1\n",
       "mons1220.tistory.com                          True          1\n",
       "mutefreeze.tistory.com                        True          1\n",
       "ncov.mohw.go.kr                               True          1\n",
       "neurostars.org                                True          1\n",
       "news.hada.io                                  False         1\n",
       "news.naver.com                                True          1\n",
       "nhuf.molit.go.kr                              False         1\n",
       "zetawiki.com                                  False         1\n",
       "nilearn.github.io                             True          1\n",
       "nipy.org                                      True          1\n",
       "norman3.github.io                             False         1\n",
       "numba.pydata.org                              True          1\n",
       "openwetware.org                               True          1\n",
       "owl.english.purdue.edu                        False         1\n",
       "palpit.tistory.com                            True          1\n",
       "s-space.snu.ac.kr                             False         1\n",
       "sansanee.tistory.com                          True          1\n",
       "www.andysbrainblog.com                        True          1\n",
       "weekly.donga.com                              True          1\n",
       "trib.al                                       True          1\n",
       "vipbg.vcu.edu                                 True          1\n",
       "vzio.tistory.com                              True          1\n",
       "wayhome25.github.io                           True          1\n",
       "web.mit.edu                                   True          1\n",
       "web.stanford.edu                              True          1\n",
       "webzine.seoulmetro.co.kr                      False         1\n",
       "whooing.com                                   False         1\n",
       "throughkim.kr                                 False         1\n",
       "wonism.github.io                              True          1\n",
       "wsyang.com                                    False         1\n",
       "www.2cpu.co.kr                                True          1\n",
       "www.abg.psychol.cam.ac.uk                     True          1\n",
       "www.acmicpc.net                               True          1\n",
       "www.aitrics.com                               False         1\n",
       "www.analyticsvidhya.com                       True          1\n",
       "towardsdatascience.com                        True          1\n",
       "theme.archives.go.kr                          False         1\n",
       "sciencebooks.minumsa.com                      True          1\n",
       "statart.tistory.com                           True          1\n",
       "seaborn.pydata.org                            True          1\n",
       "sergeswin.com                                 True          1\n",
       "sf.jikji.org                                  False         1\n",
       "sites.harding.edu                             True          1\n",
       "skyeong.net                                   True          1\n",
       "ssumer.com                                    False         1\n",
       "starlakim.wordpress.com                       False         1\n",
       "sugswritersblog.blogspot.kr                   True          1\n",
       "thelazylog.com                                True          1\n",
       "support.snel.com                              True          1\n",
       "taeoh-kim.github.io                           False         1\n",
       "techblog-history-younghunjo1.tistory.com      True          1\n",
       "techdows.com                                  True          1\n",
       "theartfulapron.com                            False         1\n",
       "thecoatlessprofessor.com                      False         1\n",
       "theeluwin.kr                                  False         1\n",
       "0561blue.tistory.com                          True          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_parse_df.loc[:, ['netloc', 'can_parse']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 트레이닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepo import utils\n",
    "from prepo.scraper import scrap\n",
    "from prepo.preprocessor import preprocessing, summarize\n",
    "from submodules.Top2Vec.top2vec import Top2Vec\n",
    "from prepo.topic_model import TopicModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>contents</th>\n",
       "      <th>url</th>\n",
       "      <th>crawl_at</th>\n",
       "      <th>is_news</th>\n",
       "      <th>clip_at</th>\n",
       "      <th>contents_prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bivariate Probit and Logit Models</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThere are no videos fo...</td>\n",
       "      <td>https://sites.google.com/site/econometricsacad...</td>\n",
       "      <td>2020-11-04 12:36:11.015926</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-05 13:58:24</td>\n",
       "      <td>bivariate probit and logit models . there are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variance inflation factor</td>\n",
       "      <td>None</td>\n",
       "      <td>In statistics, the variance inflation factor (...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Variance_inflati...</td>\n",
       "      <td>2020-11-04 12:36:12.470149</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-05 14:09:24</td>\n",
       "      <td>it turns out that the square of this standard ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Statistical Analysis with Missing Data</td>\n",
       "      <td>None</td>\n",
       "      <td>Praise for the First Edition of Statistical An...</td>\n",
       "      <td>http://onlinelibrary.wiley.com/book/10.1002/97...</td>\n",
       "      <td>2020-11-04 12:36:13.857509</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-05 17:24:55</td>\n",
       "      <td>statistical analysis with missing data . prais...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>DATA ANALYSIS NOTES: LINKS AND GENERAL GUIDELI...</td>\n",
       "      <td>https://www.princeton.edu/~otorres/Stata/statn...</td>\n",
       "      <td>2020-11-04 12:36:18.837473</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-08 22:23:54</td>\n",
       "      <td>!! data analysis : annotated output exploring ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>고지방 식이가 뇌에도 영향을 준다?</td>\n",
       "      <td>2017-11-05 01:00:11+09:00</td>\n",
       "      <td>지방은 사실 반드시 필요한 영양소다. 여러 필수 지방산은 우리가 생존하는 데 있어 ...</td>\n",
       "      <td>http://ppss.kr/archives/47698</td>\n",
       "      <td>2020-11-04 12:36:23.706657</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-09 01:26:38</td>\n",
       "      <td>루이지애나 주립 대학 의 연구자 들 은 저널 ‘ biological psychiat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>MULTI GPU환경에서 ETRI 한국어 BERT모델 활용한 Korquad 학습 방법</td>\n",
       "      <td>None</td>\n",
       "      <td>We use optional third-party analytics cookies ...</td>\n",
       "      <td>https://github.com/domyounglee/korbert-mecab-m...</td>\n",
       "      <td>2020-11-04 12:51:16.270920</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-15 20:21:09</td>\n",
       "      <td>multi gpu 환경 에서 etri 한국어 bert 모델 활용 한 korquad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>NLP 비전공자가 챗봇 프로젝트를 구현하기까지</td>\n",
       "      <td>2019-11-16 16:12:00+09:00</td>\n",
       "      <td>안녕하세요. Universtiy of California, San Diego에서 P...</td>\n",
       "      <td>https://brunch.co.kr/@ljh0113m/1</td>\n",
       "      <td>2020-11-04 12:51:16.492966</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-15 20:21:56</td>\n",
       "      <td>우선 , 멀티 캠퍼스 교육 과정 을 통해 각각 의 다른 전공 과 배경 을 가지 고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>Topic Modeling with BERT</td>\n",
       "      <td>2020-10-06 06:48:38.700000+00:00</td>\n",
       "      <td>Image by the author.\\n\\nTopic Modeling with BE...</td>\n",
       "      <td>https://towardsdatascience.com/topic-modeling-...</td>\n",
       "      <td>2020-11-04 12:51:19.294852</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-15 20:24:59</td>\n",
       "      <td>moreover , i wanted to use transformer - based...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>Building a personal knowledge base — Blog — Ki...</td>\n",
       "      <td>None</td>\n",
       "      <td>I try to unload all information that has any m...</td>\n",
       "      <td>https://kirillmaltsev.net/blog/personal-knowle...</td>\n",
       "      <td>2020-11-04 12:51:20.621195</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-19 18:09:14</td>\n",
       "      <td>in this blog post , i ’ m going to describe my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>Topic Modeling with BERT</td>\n",
       "      <td>2020-10-05 13:03:29+00:00</td>\n",
       "      <td>Image by the author.\\n\\nTopic Modeling with BE...</td>\n",
       "      <td>https://www.google.co.kr/amp/s/mc.ai/topic-mod...</td>\n",
       "      <td>2020-11-04 12:51:22.993020</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-19 18:25:08</td>\n",
       "      <td>moreover , i wanted to use transformer - based...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0                    Bivariate Probit and Logit Models   \n",
       "1                            Variance inflation factor   \n",
       "2               Statistical Analysis with Missing Data   \n",
       "3                                        Data Analysis   \n",
       "4                                  고지방 식이가 뇌에도 영향을 준다?   \n",
       "..                                                 ...   \n",
       "529    MULTI GPU환경에서 ETRI 한국어 BERT모델 활용한 Korquad 학습 방법   \n",
       "530                          NLP 비전공자가 챗봇 프로젝트를 구현하기까지   \n",
       "531                           Topic Modeling with BERT   \n",
       "532  Building a personal knowledge base — Blog — Ki...   \n",
       "533                           Topic Modeling with BERT   \n",
       "\n",
       "                         publish_date  \\\n",
       "0                                None   \n",
       "1                                None   \n",
       "2                                None   \n",
       "3                                None   \n",
       "4           2017-11-05 01:00:11+09:00   \n",
       "..                                ...   \n",
       "529                              None   \n",
       "530         2019-11-16 16:12:00+09:00   \n",
       "531  2020-10-06 06:48:38.700000+00:00   \n",
       "532                              None   \n",
       "533         2020-10-05 13:03:29+00:00   \n",
       "\n",
       "                                              contents  \\\n",
       "0    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThere are no videos fo...   \n",
       "1    In statistics, the variance inflation factor (...   \n",
       "2    Praise for the First Edition of Statistical An...   \n",
       "3    DATA ANALYSIS NOTES: LINKS AND GENERAL GUIDELI...   \n",
       "4    지방은 사실 반드시 필요한 영양소다. 여러 필수 지방산은 우리가 생존하는 데 있어 ...   \n",
       "..                                                 ...   \n",
       "529  We use optional third-party analytics cookies ...   \n",
       "530  안녕하세요. Universtiy of California, San Diego에서 P...   \n",
       "531  Image by the author.\\n\\nTopic Modeling with BE...   \n",
       "532  I try to unload all information that has any m...   \n",
       "533  Image by the author.\\n\\nTopic Modeling with BE...   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://sites.google.com/site/econometricsacad...   \n",
       "1    https://en.wikipedia.org/wiki/Variance_inflati...   \n",
       "2    http://onlinelibrary.wiley.com/book/10.1002/97...   \n",
       "3    https://www.princeton.edu/~otorres/Stata/statn...   \n",
       "4                        http://ppss.kr/archives/47698   \n",
       "..                                                 ...   \n",
       "529  https://github.com/domyounglee/korbert-mecab-m...   \n",
       "530                   https://brunch.co.kr/@ljh0113m/1   \n",
       "531  https://towardsdatascience.com/topic-modeling-...   \n",
       "532  https://kirillmaltsev.net/blog/personal-knowle...   \n",
       "533  https://www.google.co.kr/amp/s/mc.ai/topic-mod...   \n",
       "\n",
       "                      crawl_at  is_news             clip_at  \\\n",
       "0   2020-11-04 12:36:11.015926    False 2015-11-05 13:58:24   \n",
       "1   2020-11-04 12:36:12.470149    False 2015-11-05 14:09:24   \n",
       "2   2020-11-04 12:36:13.857509    False 2015-11-05 17:24:55   \n",
       "3   2020-11-04 12:36:18.837473    False 2015-11-08 22:23:54   \n",
       "4   2020-11-04 12:36:23.706657    False 2015-11-09 01:26:38   \n",
       "..                         ...      ...                 ...   \n",
       "529 2020-11-04 12:51:16.270920    False 2020-10-15 20:21:09   \n",
       "530 2020-11-04 12:51:16.492966    False 2020-10-15 20:21:56   \n",
       "531 2020-11-04 12:51:19.294852    False 2020-10-15 20:24:59   \n",
       "532 2020-11-04 12:51:20.621195    False 2020-10-19 18:09:14   \n",
       "533 2020-11-04 12:51:22.993020    False 2020-10-19 18:25:08   \n",
       "\n",
       "                                         contents_prep  \n",
       "0    bivariate probit and logit models . there are ...  \n",
       "1    it turns out that the square of this standard ...  \n",
       "2    statistical analysis with missing data . prais...  \n",
       "3    !! data analysis : annotated output exploring ...  \n",
       "4    루이지애나 주립 대학 의 연구자 들 은 저널 ‘ biological psychiat...  \n",
       "..                                                 ...  \n",
       "529  multi gpu 환경 에서 etri 한국어 bert 모델 활용 한 korquad ...  \n",
       "530  우선 , 멀티 캠퍼스 교육 과정 을 통해 각각 의 다른 전공 과 배경 을 가지 고 ...  \n",
       "531  moreover , i wanted to use transformer - based...  \n",
       "532  in this blog post , i ’ m going to describe my...  \n",
       "533  moreover , i wanted to use transformer - based...  \n",
       "\n",
       "[534 rows x 8 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 데이터 가져오기/스크랩하기\n",
    "user_data_dir = TEST_DIR + \"datasets/choi_urls/\"\n",
    "user_docs_info_data_filename = 'docs_info_df.pkl'\n",
    "user_urls_data_filename = 'choi_time_url_df.pkl'\n",
    "\n",
    "docs_info_prep_df = utils.load_obj(user_data_dir, 'docs_info_prep_df.pkl')\n",
    "docs_info_prep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title              0\n",
       "publish_date     340\n",
       "contents           0\n",
       "url                0\n",
       "crawl_at           0\n",
       "is_news            0\n",
       "clip_at            0\n",
       "contents_prep      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_info_prep_df.isnull( ).sum( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for index, row in docs_info_prep_df.iterrows():\n",
    "    print(type(row['title']))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>contents</th>\n",
       "      <th>url</th>\n",
       "      <th>crawl_at</th>\n",
       "      <th>is_news</th>\n",
       "      <th>clip_at</th>\n",
       "      <th>contents_prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>리눅스에서 그래픽 드라이버 설치후 화면이 안나와요 :: 2cpu, 지름이 시작되는 곳!</td>\n",
       "      <td>None</td>\n",
       "      <td>정보가 안나오는 팬은 무엇이 문제일까요?</td>\n",
       "      <td>http://www.2cpu.co.kr/bbs/board.php?bo_table=Q...</td>\n",
       "      <td>2020-11-04 12:39:18.295792</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-03-30 06:15:10</td>\n",
       "      <td>리눅스 에서 그래픽 드라이버 설치 후 화면 이 안 나와요 : : 2 cpu , 지름...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Welcome to our Support Portal</td>\n",
       "      <td>None</td>\n",
       "      <td>Welcome to our Support Portal</td>\n",
       "      <td>https://support.snel.com/902085-Install-VNC-on...</td>\n",
       "      <td>2020-11-04 12:42:43.002572</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-03-09 15:43:46</td>\n",
       "      <td>welcome to our support portal . welcome to our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Course Materials: Introduction to OpenMx [Fall...</td>\n",
       "      <td>None</td>\n",
       "      <td>About who we are</td>\n",
       "      <td>https://vipbg.vcu.edu/academics/courses/course...</td>\n",
       "      <td>2020-11-04 12:45:35.890248</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-03-25 13:51:27</td>\n",
       "      <td>course materials : introduction to openmx [ fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>오토픽션에 대하여</td>\n",
       "      <td>2019-11-07 23:35:00+09:00</td>\n",
       "      <td>언어의 모험에서 모험의 언어로</td>\n",
       "      <td>https://brunch.co.kr/@nomdequoii/1</td>\n",
       "      <td>2020-11-04 12:50:04.230311</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-16 20:13:36</td>\n",
       "      <td>오토 픽션 에 대하 여 . 언어 의 모험 에서 모험 의 언어 로</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "99    리눅스에서 그래픽 드라이버 설치후 화면이 안나와요 :: 2cpu, 지름이 시작되는 곳!   \n",
       "200                      Welcome to our Support Portal   \n",
       "299  Course Materials: Introduction to OpenMx [Fall...   \n",
       "461                                          오토픽션에 대하여   \n",
       "\n",
       "                  publish_date                       contents  \\\n",
       "99                        None         정보가 안나오는 팬은 무엇이 문제일까요?   \n",
       "200                       None  Welcome to our Support Portal   \n",
       "299                       None               About who we are   \n",
       "461  2019-11-07 23:35:00+09:00               언어의 모험에서 모험의 언어로   \n",
       "\n",
       "                                                   url  \\\n",
       "99   http://www.2cpu.co.kr/bbs/board.php?bo_table=Q...   \n",
       "200  https://support.snel.com/902085-Install-VNC-on...   \n",
       "299  https://vipbg.vcu.edu/academics/courses/course...   \n",
       "461                 https://brunch.co.kr/@nomdequoii/1   \n",
       "\n",
       "                      crawl_at  is_news             clip_at  \\\n",
       "99  2020-11-04 12:39:18.295792    False 2017-03-30 06:15:10   \n",
       "200 2020-11-04 12:42:43.002572     True 2018-03-09 15:43:46   \n",
       "299 2020-11-04 12:45:35.890248    False 2019-03-25 13:51:27   \n",
       "461 2020-11-04 12:50:04.230311    False 2020-07-16 20:13:36   \n",
       "\n",
       "                                         contents_prep  \n",
       "99   리눅스 에서 그래픽 드라이버 설치 후 화면 이 안 나와요 : : 2 cpu , 지름...  \n",
       "200  welcome to our support portal . welcome to our...  \n",
       "299  course materials : introduction to openmx [ fa...  \n",
       "461                오토 픽션 에 대하 여 . 언어 의 모험 에서 모험 의 언어 로  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_info_prep_df[docs_info_prep_df['contents'].str.len() - docs_info_prep_df['title'].str.len() <10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_docs_df =  docs_info_prep_df.iloc[:-60, :]\n",
    "\n",
    "user_docs_post1_df = docs_info_prep_df.iloc[-60:-30, :]\n",
    "user_docs_post2_df = docs_info_prep_df.iloc[-30:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=474, step=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_docs_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-07 19:54:04,477 - top2vec - INFO - Pre-processing documents for training\n",
      "INFO:top2vec:Pre-processing documents for training\n",
      "2020-11-07 19:54:04,864 - top2vec - INFO - Downloading universal-sentence-encoder-multilingual model\n",
      "INFO:top2vec:Downloading universal-sentence-encoder-multilingual model\n",
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-multilingual/3'.\n",
      "INFO:absl:Downloaded https://tfhub.dev/google/universal-sentence-encoder-multilingual/3, Total size: 266.88MB\n",
      "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-multilingual/3'.\n",
      "2020-11-07 19:54:17,607 - top2vec - INFO - Creating joint document/word embedding\n",
      "INFO:top2vec:Creating joint document/word embedding\n",
      "2020-11-07 19:54:25,929 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "INFO:top2vec:Creating lower dimension embedding of documents\n",
      "2020-11-07 19:54:35,616 - top2vec - INFO - Finding dense areas of documents\n",
      "INFO:top2vec:Finding dense areas of documents\n",
      "2020-11-07 19:54:35,636 - top2vec - INFO - Finding topics\n",
      "INFO:top2vec:Finding topics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.3 s, sys: 7.32 s, total: 46.6 s\n",
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# umap_args = {'n_neighbors': 3,\n",
    "#                     'n_components': 5,\n",
    "#                     'metric': 'cosine'}\n",
    "hdbscan_args = {'min_samples': 2,\n",
    "                'min_cluster_size': 3,\n",
    "                #'cluster_selection_epsilon': 0.5,\n",
    "               # 'cluster_selection_method':'leaf'\n",
    "               }\n",
    "\n",
    "# embedding_model은 tf hub를 사용하여 한 번 받으면 캐싱되어 그 이후에는 재다운 받지 않음\n",
    "# universal-sentence-encoder-multilingual\n",
    "# https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\n",
    "# 16 languages (Arabic, Chinese-simplified, Chinese-traditional, English, French, German, Italian, Japanese, Korean, Dutch, Polish, Portuguese, Spanish, Thai, Turkish, Russian) \n",
    "tm_model = Top2Vec(user_docs_df['contents_prep'], \n",
    "                   min_count=10,\n",
    "                   embedding_model='universal-sentence-encoder-multilingual',  # distiluse-base-multilingual-cased\n",
    "                   #speed=\"learn\", #use_corpus_file=True, # modeldl doc2vec일때만 사용됨\n",
    "                   workers=16,   # deep-learn'\n",
    "                   # keep_documents=False, \n",
    "                   verbose=True,\n",
    "                   document_ids=user_docs_df.index,\n",
    "                   hdbscan_args=hdbscan_args\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "yDTr_0DRTYDa",
    "outputId": "66a848bc-2919-4aa3-d53e-76c70c2950b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_model.get_num_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "fLXx_fHaIdcf",
    "outputId": "c854b40b-3670-42f3-bc44-4a812a47f0a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23 21 21 17 17 17 15 15 14 13 13 13 12 12 11 11 10 10 10  9  9  9  8  8\n",
      "  7  7  7  6  6  6  6  6  6  6  6  6  6  6  6  5  5  5  5  5  5  4  4  4\n",
      "  4  4  4  3  3  3]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53]\n"
     ]
    }
   ],
   "source": [
    "topic_sizes, topic_nums = tm_model.get_topic_sizes()\n",
    "print(topic_sizes)\n",
    "print(topic_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39, 21, 25,  9, 48,  3,  8,  6,  0, 51,  0, 51, 40, 12, 12,  8, 24,\n",
       "        4,  4,  8, 41, 29,  0, 17, 23, 29, 37, 10, 45, 45, 19,  0, 22, 22,\n",
       "       10, 25,  1,  6,  2,  2,  2,  2,  2,  2, 44, 28,  5,  5, 33, 45, 40,\n",
       "        2, 45,  1, 49, 49, 11, 16,  5,  0, 12,  6, 42,  0,  1,  5, 28,  1,\n",
       "       28,  4,  5,  5,  6, 42,  7,  0, 11, 12, 12,  6, 35, 18,  5,  5, 18,\n",
       "        0,  2,  2, 13, 13, 13,  2, 46,  8, 13,  2, 35,  2,  2,  2,  2,  2,\n",
       "       13,  2, 32, 17,  6, 29,  0, 23,  6,  1,  1, 37, 32, 28, 22, 34, 25,\n",
       "       35, 24,  5, 18,  8, 18,  3,  3,  5, 22,  1, 16, 31, 20,  1, 41, 29,\n",
       "       13, 12, 25, 17, 15,  3, 20, 15, 20, 31, 15, 16, 16,  4, 27, 10, 15,\n",
       "        4, 49,  4,  4,  8,  4, 26, 15, 20, 21, 21, 50, 31,  4,  5,  1, 10,\n",
       "       42,  9,  2, 31, 42, 48, 44, 40, 40, 22, 35, 26,  4,  0, 13, 37,  2,\n",
       "        4, 18,  6, 21, 21, 18, 44, 47, 19,  2,  2, 37, 29, 18, 26, 34, 32,\n",
       "       23,  0, 22, 23, 47, 14, 21,  6, 19, 19, 23, 23, 39,  3, 12,  1, 12,\n",
       "       32,  1,  1, 26, 31,  9, 10, 24, 32, 24, 10, 27,  0, 20, 19, 40, 11,\n",
       "       13, 34,  9, 17, 14, 14, 10, 34, 37, 37,  4, 50, 13, 16, 16, 16, 16,\n",
       "       18,  3,  3, 24,  5, 24, 13,  6,  1, 20,  8, 15, 15,  1,  3, 17, 17,\n",
       "       46,  8, 43,  8, 26, 36, 17,  6,  5,  8, 41,  5,  3,  6, 20,  3, 39,\n",
       "       39, 47, 39,  3,  3, 31, 13, 14, 14,  4,  6, 15, 15, 36, 38, 14, 15,\n",
       "       10,  1, 50, 15,  3,  7,  7, 18, 22, 43,  7, 25, 43,  0,  3, 27, 43,\n",
       "        5, 46, 24, 30, 30,  3, 11,  0,  4, 16, 27, 36, 44, 36, 36,  6, 17,\n",
       "       14, 10, 10, 11, 11, 11, 13,  3,  4, 18, 38, 26, 38,  8, 53, 53, 53,\n",
       "       52, 52,  4, 36,  7, 23, 12,  4, 35, 30, 35, 50,  7,  7, 48, 44, 17,\n",
       "       17, 38, 38, 38,  8, 22, 10,  7, 16, 34,  8,  7, 26,  7, 43, 30, 27,\n",
       "       25, 25,  1, 41,  3, 23,  9,  1,  7, 11,  7,  7, 10,  0, 34, 42, 11,\n",
       "       12,  8, 51, 20, 11, 28, 30, 32, 30, 48, 14,  1, 20, 27,  7,  0, 29,\n",
       "       19, 14, 14, 14, 41, 19, 19, 49,  1,  1,  1, 19,  7, 11, 11,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9, 33, 52, 33, 46,  5, 21, 28, 47,  6, 21,  0,\n",
       "       11,  0, 12, 33, 33, 12, 33,  0,  5,  0,  0,  0, 10, 21,  0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_model.doc_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06741048,  0.04101736, -0.02166332, ..., -0.05179536,\n",
       "         0.00920707,  0.02210309],\n",
       "       [-0.06904152, -0.0652594 ,  0.01097934, ..., -0.02282716,\n",
       "        -0.02033136,  0.0285086 ],\n",
       "       [-0.05994328, -0.05615741, -0.05382682, ..., -0.05164806,\n",
       "        -0.02380924, -0.02313579],\n",
       "       ...,\n",
       "       [ 0.05253817, -0.01115385, -0.0124107 , ..., -0.06557632,\n",
       "         0.04465484,  0.05191088],\n",
       "       [-0.06395165, -0.01587186, -0.05122649, ...,  0.0563542 ,\n",
       "         0.00962775, -0.03008479],\n",
       "       [ 0.06587603, -0.00184992, -0.04457127, ...,  0.01879145,\n",
       "         0.01905644,  0.02869681]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_model._get_document_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'cluster': 39},\n",
       " 1: {'cluster': 23},\n",
       " 2: {'cluster': 20},\n",
       " 3: {'cluster': 2},\n",
       " 4: {'cluster': 43},\n",
       " 5: {'cluster': 46},\n",
       " 6: {'cluster': 44},\n",
       " 7: {'cluster': 6},\n",
       " 8: {'cluster': 21},\n",
       " 9: {'cluster': 3},\n",
       " 10: {'cluster': 17},\n",
       " 11: {'cluster': 3},\n",
       " 12: {'cluster': 3},\n",
       " 13: {'cluster': 2},\n",
       " 14: {'cluster': 46},\n",
       " 15: {'cluster': 26},\n",
       " 16: {'cluster': 5},\n",
       " 17: {'cluster': 4},\n",
       " 18: {'cluster': 22},\n",
       " 19: {'cluster': 46},\n",
       " 20: {'cluster': 12},\n",
       " 21: {'cluster': 14},\n",
       " 22: {'cluster': 16},\n",
       " 23: {'cluster': 26},\n",
       " 24: {'cluster': 0},\n",
       " 25: {'cluster': 13},\n",
       " 26: {'cluster': 16},\n",
       " 27: {'cluster': 31},\n",
       " 28: {'cluster': 13},\n",
       " 29: {'cluster': 48},\n",
       " 30: {'cluster': 48},\n",
       " 31: {'cluster': 16},\n",
       " 32: {'cluster': 40},\n",
       " 33: {'cluster': 1},\n",
       " 34: {'cluster': 1},\n",
       " 35: {'cluster': 38},\n",
       " 36: {'cluster': 20},\n",
       " 37: {'cluster': 23},\n",
       " 38: {'cluster': 3},\n",
       " 39: {'cluster': 0},\n",
       " 40: {'cluster': 35},\n",
       " 41: {'cluster': 47},\n",
       " 42: {'cluster': 10},\n",
       " 43: {'cluster': 10},\n",
       " 44: {'cluster': 10},\n",
       " 45: {'cluster': 10},\n",
       " 46: {'cluster': 34},\n",
       " 47: {'cluster': 45},\n",
       " 48: {'cluster': 8},\n",
       " 49: {'cluster': 8},\n",
       " 50: {'cluster': 2},\n",
       " 51: {'cluster': 48},\n",
       " 52: {'cluster': 3},\n",
       " 53: {'cluster': 47},\n",
       " 54: {'cluster': 48},\n",
       " 55: {'cluster': 11},\n",
       " 56: {'cluster': 44},\n",
       " 57: {'cluster': 18},\n",
       " 58: {'cluster': 9},\n",
       " 59: {'cluster': 27},\n",
       " 60: {'cluster': 8},\n",
       " 61: {'cluster': 17},\n",
       " 62: {'cluster': 15},\n",
       " 63: {'cluster': 6},\n",
       " 64: {'cluster': 21},\n",
       " 65: {'cluster': 17},\n",
       " 66: {'cluster': 11},\n",
       " 67: {'cluster': 8},\n",
       " 68: {'cluster': 49},\n",
       " 69: {'cluster': 18},\n",
       " 70: {'cluster': 49},\n",
       " 71: {'cluster': 4},\n",
       " 72: {'cluster': 8},\n",
       " 73: {'cluster': 8},\n",
       " 74: {'cluster': 6},\n",
       " 75: {'cluster': 21},\n",
       " 76: {'cluster': 1},\n",
       " 77: {'cluster': 17},\n",
       " 78: {'cluster': 9},\n",
       " 79: {'cluster': 15},\n",
       " 80: {'cluster': 15},\n",
       " 81: {'cluster': 6},\n",
       " 82: {'cluster': 6},\n",
       " 83: {'cluster': 19},\n",
       " 84: {'cluster': 8},\n",
       " 85: {'cluster': 8},\n",
       " 86: {'cluster': 19},\n",
       " 87: {'cluster': 37},\n",
       " 88: {'cluster': 35},\n",
       " 89: {'cluster': 47},\n",
       " 90: {'cluster': 5},\n",
       " 91: {'cluster': 5},\n",
       " 92: {'cluster': 5},\n",
       " 93: {'cluster': 10},\n",
       " 94: {'cluster': 5},\n",
       " 95: {'cluster': 12},\n",
       " 96: {'cluster': 5},\n",
       " 97: {'cluster': 10},\n",
       " 98: {'cluster': 16},\n",
       " 99: {'cluster': 10},\n",
       " 100: {'cluster': 10},\n",
       " 101: {'cluster': 10},\n",
       " 102: {'cluster': 35},\n",
       " 103: {'cluster': 10},\n",
       " 104: {'cluster': 10},\n",
       " 105: {'cluster': 0},\n",
       " 106: {'cluster': 0},\n",
       " 107: {'cluster': 6},\n",
       " 108: {'cluster': 1},\n",
       " 109: {'cluster': 17},\n",
       " 110: {'cluster': 21},\n",
       " 111: {'cluster': 6},\n",
       " 112: {'cluster': 11},\n",
       " 113: {'cluster': 18},\n",
       " 114: {'cluster': 31},\n",
       " 115: {'cluster': 0},\n",
       " 116: {'cluster': 11},\n",
       " 117: {'cluster': 1},\n",
       " 118: {'cluster': 26},\n",
       " 119: {'cluster': 20},\n",
       " 120: {'cluster': 37},\n",
       " 121: {'cluster': 16},\n",
       " 122: {'cluster': 8},\n",
       " 123: {'cluster': 19},\n",
       " 124: {'cluster': 12},\n",
       " 125: {'cluster': 19},\n",
       " 126: {'cluster': 7},\n",
       " 127: {'cluster': 7},\n",
       " 128: {'cluster': 8},\n",
       " 129: {'cluster': 1},\n",
       " 130: {'cluster': 5},\n",
       " 131: {'cluster': 11},\n",
       " 132: {'cluster': 27},\n",
       " 133: {'cluster': 32},\n",
       " 134: {'cluster': 24},\n",
       " 135: {'cluster': 11},\n",
       " 136: {'cluster': 5},\n",
       " 137: {'cluster': 16},\n",
       " 138: {'cluster': 5},\n",
       " 139: {'cluster': 15},\n",
       " 140: {'cluster': 20},\n",
       " 141: {'cluster': 0},\n",
       " 142: {'cluster': 4},\n",
       " 143: {'cluster': 36},\n",
       " 144: {'cluster': 24},\n",
       " 145: {'cluster': 4},\n",
       " 146: {'cluster': 24},\n",
       " 147: {'cluster': 32},\n",
       " 148: {'cluster': 4},\n",
       " 149: {'cluster': 4},\n",
       " 150: {'cluster': 12},\n",
       " 151: {'cluster': 4},\n",
       " 152: {'cluster': 3},\n",
       " 153: {'cluster': 38},\n",
       " 154: {'cluster': 4},\n",
       " 155: {'cluster': 4},\n",
       " 156: {'cluster': 18},\n",
       " 157: {'cluster': 22},\n",
       " 158: {'cluster': 22},\n",
       " 159: {'cluster': 12},\n",
       " 160: {'cluster': 22},\n",
       " 161: {'cluster': 33},\n",
       " 162: {'cluster': 4},\n",
       " 163: {'cluster': 24},\n",
       " 164: {'cluster': 23},\n",
       " 165: {'cluster': 23},\n",
       " 166: {'cluster': 42},\n",
       " 167: {'cluster': 32},\n",
       " 168: {'cluster': 4},\n",
       " 169: {'cluster': 8},\n",
       " 170: {'cluster': 18},\n",
       " 171: {'cluster': 29},\n",
       " 172: {'cluster': 21},\n",
       " 173: {'cluster': 2},\n",
       " 174: {'cluster': 47},\n",
       " 175: {'cluster': 32},\n",
       " 176: {'cluster': 21},\n",
       " 177: {'cluster': 24},\n",
       " 178: {'cluster': 34},\n",
       " 179: {'cluster': 3},\n",
       " 180: {'cluster': 3},\n",
       " 181: {'cluster': 8},\n",
       " 182: {'cluster': 13},\n",
       " 183: {'cluster': 33},\n",
       " 184: {'cluster': 22},\n",
       " 185: {'cluster': 40},\n",
       " 186: {'cluster': 5},\n",
       " 187: {'cluster': 31},\n",
       " 188: {'cluster': 3},\n",
       " 189: {'cluster': 10},\n",
       " 190: {'cluster': 26},\n",
       " 191: {'cluster': 19},\n",
       " 192: {'cluster': 6},\n",
       " 193: {'cluster': 23},\n",
       " 194: {'cluster': 23},\n",
       " 195: {'cluster': 19},\n",
       " 196: {'cluster': 34},\n",
       " 197: {'cluster': 51},\n",
       " 198: {'cluster': 28},\n",
       " 199: {'cluster': 35},\n",
       " 200: {'cluster': 35},\n",
       " 201: {'cluster': 31},\n",
       " 202: {'cluster': 16},\n",
       " 203: {'cluster': 19},\n",
       " 204: {'cluster': 33},\n",
       " 205: {'cluster': 22},\n",
       " 206: {'cluster': 0},\n",
       " 207: {'cluster': 13},\n",
       " 208: {'cluster': 17},\n",
       " 209: {'cluster': 1},\n",
       " 210: {'cluster': 13},\n",
       " 211: {'cluster': 41},\n",
       " 212: {'cluster': 36},\n",
       " 213: {'cluster': 23},\n",
       " 214: {'cluster': 6},\n",
       " 215: {'cluster': 28},\n",
       " 216: {'cluster': 28},\n",
       " 217: {'cluster': 13},\n",
       " 218: {'cluster': 13},\n",
       " 219: {'cluster': 39},\n",
       " 220: {'cluster': 36},\n",
       " 221: {'cluster': 15},\n",
       " 222: {'cluster': 11},\n",
       " 223: {'cluster': 15},\n",
       " 224: {'cluster': 0},\n",
       " 225: {'cluster': 11},\n",
       " 226: {'cluster': 18},\n",
       " 227: {'cluster': 33},\n",
       " 228: {'cluster': 32},\n",
       " 229: {'cluster': 2},\n",
       " 230: {'cluster': 38},\n",
       " 231: {'cluster': 7},\n",
       " 232: {'cluster': 16},\n",
       " 233: {'cluster': 45},\n",
       " 234: {'cluster': 29},\n",
       " 235: {'cluster': 3},\n",
       " 236: {'cluster': 17},\n",
       " 237: {'cluster': 24},\n",
       " 238: {'cluster': 28},\n",
       " 239: {'cluster': 3},\n",
       " 240: {'cluster': 9},\n",
       " 241: {'cluster': 5},\n",
       " 242: {'cluster': 26},\n",
       " 243: {'cluster': 0},\n",
       " 244: {'cluster': 0},\n",
       " 245: {'cluster': 14},\n",
       " 246: {'cluster': 14},\n",
       " 247: {'cluster': 29},\n",
       " 248: {'cluster': 26},\n",
       " 249: {'cluster': 31},\n",
       " 250: {'cluster': 31},\n",
       " 251: {'cluster': 4},\n",
       " 252: {'cluster': 42},\n",
       " 253: {'cluster': 5},\n",
       " 254: {'cluster': 27},\n",
       " 255: {'cluster': 27},\n",
       " 256: {'cluster': 27},\n",
       " 257: {'cluster': 27},\n",
       " 258: {'cluster': 19},\n",
       " 259: {'cluster': 7},\n",
       " 260: {'cluster': 7},\n",
       " 261: {'cluster': 45},\n",
       " 262: {'cluster': 30},\n",
       " 263: {'cluster': 45},\n",
       " 264: {'cluster': 5},\n",
       " 265: {'cluster': 6},\n",
       " 266: {'cluster': 18},\n",
       " 267: {'cluster': 24},\n",
       " 268: {'cluster': 12},\n",
       " 269: {'cluster': 24},\n",
       " 270: {'cluster': 4},\n",
       " 271: {'cluster': 11},\n",
       " 272: {'cluster': 7},\n",
       " 273: {'cluster': 0},\n",
       " 274: {'cluster': 0},\n",
       " 275: {'cluster': 12},\n",
       " 276: {'cluster': 26},\n",
       " 277: {'cluster': 21},\n",
       " 278: {'cluster': 0},\n",
       " 279: {'cluster': 0},\n",
       " 280: {'cluster': 30},\n",
       " 281: {'cluster': 12},\n",
       " 282: {'cluster': 41},\n",
       " 283: {'cluster': 16},\n",
       " 284: {'cluster': 7},\n",
       " 285: {'cluster': 6},\n",
       " 286: {'cluster': 51},\n",
       " 287: {'cluster': 7},\n",
       " 288: {'cluster': 39},\n",
       " 289: {'cluster': 39},\n",
       " 290: {'cluster': 41},\n",
       " 291: {'cluster': 39},\n",
       " 292: {'cluster': 7},\n",
       " 293: {'cluster': 7},\n",
       " 294: {'cluster': 32},\n",
       " 295: {'cluster': 5},\n",
       " 296: {'cluster': 14},\n",
       " 297: {'cluster': 14},\n",
       " 298: {'cluster': 4},\n",
       " 299: {'cluster': 6},\n",
       " 300: {'cluster': 4},\n",
       " 301: {'cluster': 4},\n",
       " 302: {'cluster': 0},\n",
       " 303: {'cluster': 0},\n",
       " 304: {'cluster': 14},\n",
       " 305: {'cluster': 4},\n",
       " 306: {'cluster': 29},\n",
       " 307: {'cluster': 11},\n",
       " 308: {'cluster': 42},\n",
       " 309: {'cluster': 4},\n",
       " 310: {'cluster': 7},\n",
       " 311: {'cluster': 1},\n",
       " 312: {'cluster': 1},\n",
       " 313: {'cluster': 19},\n",
       " 314: {'cluster': 1},\n",
       " 315: {'cluster': 30},\n",
       " 316: {'cluster': 1},\n",
       " 317: {'cluster': 20},\n",
       " 318: {'cluster': 30},\n",
       " 319: {'cluster': 17},\n",
       " 320: {'cluster': 7},\n",
       " 321: {'cluster': 3},\n",
       " 322: {'cluster': 30},\n",
       " 323: {'cluster': 16},\n",
       " 324: {'cluster': 5},\n",
       " 325: {'cluster': 5},\n",
       " 326: {'cluster': 25},\n",
       " 327: {'cluster': 25},\n",
       " 328: {'cluster': 7},\n",
       " 329: {'cluster': 9},\n",
       " 330: {'cluster': 17},\n",
       " 331: {'cluster': 43},\n",
       " 332: {'cluster': 27},\n",
       " 333: {'cluster': 3},\n",
       " 334: {'cluster': 0},\n",
       " 335: {'cluster': 34},\n",
       " 336: {'cluster': 0},\n",
       " 337: {'cluster': 0},\n",
       " 338: {'cluster': 1},\n",
       " 339: {'cluster': 0},\n",
       " 340: {'cluster': 14},\n",
       " 341: {'cluster': 29},\n",
       " 342: {'cluster': 29},\n",
       " 343: {'cluster': 9},\n",
       " 344: {'cluster': 9},\n",
       " 345: {'cluster': 9},\n",
       " 346: {'cluster': 5},\n",
       " 347: {'cluster': 7},\n",
       " 348: {'cluster': 22},\n",
       " 349: {'cluster': 19},\n",
       " 350: {'cluster': 0},\n",
       " 351: {'cluster': 1},\n",
       " 352: {'cluster': 0},\n",
       " 353: {'cluster': 44},\n",
       " 354: {'cluster': 50},\n",
       " 355: {'cluster': 50},\n",
       " 356: {'cluster': 50},\n",
       " 357: {'cluster': 25},\n",
       " 358: {'cluster': 25},\n",
       " 359: {'cluster': 22},\n",
       " 360: {'cluster': 3},\n",
       " 361: {'cluster': 0},\n",
       " 362: {'cluster': 21},\n",
       " 363: {'cluster': 13},\n",
       " 364: {'cluster': 15},\n",
       " 365: {'cluster': 22},\n",
       " 366: {'cluster': 6},\n",
       " 367: {'cluster': 25},\n",
       " 368: {'cluster': 6},\n",
       " 369: {'cluster': 33},\n",
       " 370: {'cluster': 42},\n",
       " 371: {'cluster': 1},\n",
       " 372: {'cluster': 1},\n",
       " 373: {'cluster': 43},\n",
       " 374: {'cluster': 34},\n",
       " 375: {'cluster': 0},\n",
       " 376: {'cluster': 0},\n",
       " 377: {'cluster': 0},\n",
       " 378: {'cluster': 0},\n",
       " 379: {'cluster': 0},\n",
       " 380: {'cluster': 12},\n",
       " 381: {'cluster': 8},\n",
       " 382: {'cluster': 29},\n",
       " 383: {'cluster': 1},\n",
       " 384: {'cluster': 27},\n",
       " 385: {'cluster': 26},\n",
       " 386: {'cluster': 12},\n",
       " 387: {'cluster': 6},\n",
       " 388: {'cluster': 33},\n",
       " 389: {'cluster': 1},\n",
       " 390: {'cluster': 30},\n",
       " 391: {'cluster': 25},\n",
       " 392: {'cluster': 3},\n",
       " 393: {'cluster': 20},\n",
       " 394: {'cluster': 20},\n",
       " 395: {'cluster': 44},\n",
       " 396: {'cluster': 14},\n",
       " 397: {'cluster': 46},\n",
       " 398: {'cluster': 13},\n",
       " 399: {'cluster': 2},\n",
       " 400: {'cluster': 7},\n",
       " 401: {'cluster': 1},\n",
       " 402: {'cluster': 9},\n",
       " 403: {'cluster': 1},\n",
       " 404: {'cluster': 1},\n",
       " 405: {'cluster': 38},\n",
       " 406: {'cluster': 17},\n",
       " 407: {'cluster': 51},\n",
       " 408: {'cluster': 21},\n",
       " 409: {'cluster': 9},\n",
       " 410: {'cluster': 15},\n",
       " 411: {'cluster': 12},\n",
       " 412: {'cluster': 3},\n",
       " 413: {'cluster': 20},\n",
       " 414: {'cluster': 9},\n",
       " 415: {'cluster': 49},\n",
       " 416: {'cluster': 25},\n",
       " 417: {'cluster': 0},\n",
       " 418: {'cluster': 25},\n",
       " 419: {'cluster': 43},\n",
       " 420: {'cluster': 14},\n",
       " 421: {'cluster': 18},\n",
       " 422: {'cluster': 24},\n",
       " 423: {'cluster': 3},\n",
       " 424: {'cluster': 3},\n",
       " 425: {'cluster': 1},\n",
       " 426: {'cluster': 37},\n",
       " 427: {'cluster': 20},\n",
       " 428: {'cluster': 28},\n",
       " 429: {'cluster': 14},\n",
       " 430: {'cluster': 36},\n",
       " 431: {'cluster': 14},\n",
       " 432: {'cluster': 36},\n",
       " 433: {'cluster': 28},\n",
       " 434: {'cluster': 28},\n",
       " 435: {'cluster': 11},\n",
       " 436: {'cluster': 18},\n",
       " 437: {'cluster': 11},\n",
       " 438: {'cluster': 18},\n",
       " 439: {'cluster': 28},\n",
       " 440: {'cluster': 1},\n",
       " 441: {'cluster': 9},\n",
       " 442: {'cluster': 9},\n",
       " 443: {'cluster': 2},\n",
       " 444: {'cluster': 2},\n",
       " 445: {'cluster': 2},\n",
       " 446: {'cluster': 2},\n",
       " 447: {'cluster': 2},\n",
       " 448: {'cluster': 2},\n",
       " 449: {'cluster': 2},\n",
       " 450: {'cluster': 2},\n",
       " 451: {'cluster': 2},\n",
       " 452: {'cluster': 25},\n",
       " 453: {'cluster': 2},\n",
       " 454: {'cluster': 5},\n",
       " 455: {'cluster': 8},\n",
       " 456: {'cluster': 23},\n",
       " 457: {'cluster': 49},\n",
       " 458: {'cluster': 41},\n",
       " 459: {'cluster': 6},\n",
       " 460: {'cluster': 23},\n",
       " 461: {'cluster': 13},\n",
       " 462: {'cluster': 9},\n",
       " 463: {'cluster': 37},\n",
       " 464: {'cluster': 13},\n",
       " 465: {'cluster': 2},\n",
       " 466: {'cluster': 2},\n",
       " 467: {'cluster': 15},\n",
       " 468: {'cluster': 2},\n",
       " 469: {'cluster': 15},\n",
       " 470: {'cluster': 30},\n",
       " 471: {'cluster': 40},\n",
       " 472: {'cluster': 40},\n",
       " 473: {'cluster': 40},\n",
       " 474: {'cluster': 38},\n",
       " 475: {'cluster': 20},\n",
       " 476: {'cluster': 37}}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dict = {}\n",
    "for doc_id, cluster_idx in zip(user_docs_df.index, tm_model.doc_top):\n",
    "    temp_dict[doc_id] = {'cluster': cluster_idx}\n",
    "temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 83, 123, 125, 313,  86, 195, 349, 258, 191, 203])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 50)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_model._find_topic_words_and_scores(tm_model.topic_vectors)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1, 4)(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>477 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cluster\n",
       "0         39\n",
       "1         23\n",
       "2         20\n",
       "3          2\n",
       "4         43\n",
       "..       ...\n",
       "472       40\n",
       "473       40\n",
       "474       38\n",
       "475       20\n",
       "476       37\n",
       "\n",
       "[477 rows x 1 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_cluster_df = pd.DataFrame(tm_model.doc_top, index=docs_idx, columns =['cluster']) \n",
    "docs_cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[42, 28, 5, 24, 50, 3],\n",
       " [22, 25, 47, 0],\n",
       " [52, 7, 40, 16, 48, 33, 49, 36, 38, 11],\n",
       " [4, 9, 45, 44, 26, 41, 30],\n",
       " [12, 23, 54, 2],\n",
       " [14, 8, 34, 1],\n",
       " [39, 13, 10, 18, 17],\n",
       " [51, 43, 32, 29, 27],\n",
       " [6, 53, 15, 46, 19],\n",
       " [37, 21, 20, 35, 31]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 줄이고 싶다면 일단 아래 함수를 한번 부른 후 \n",
    "clusters_reduced = tm_model.hierarchical_topic_reduction(10)\n",
    "clusters_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 함수에 reduced=True 넣어줘야함\n",
    "tm_model.get_num_topics(reduced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([22, 22, 19, 19, 17, 15, 14, 14, 14, 13, 12, 12, 10, 10, 10, 10,  9,\n",
       "         9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,  7,\n",
       "         6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,\n",
       "         4,  4,  4,  3]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "        51, 52, 53, 54]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_nums = tm_model.get_topic_sizes()\n",
    "topic_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True is True:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_reduced_cluster(cluster, clusters_reduced):\n",
    "    for idx, sub_cluster in enumerate(clusters_reduced):\n",
    "        if cluster in sub_cluster:\n",
    "            return idx\n",
    "get_reduced_cluster(9, clusters_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_reduced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>477 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cluster  cluster_reduced\n",
       "0         39                1\n",
       "1         23                1\n",
       "2         20                1\n",
       "3          2                4\n",
       "4         43                0\n",
       "..       ...              ...\n",
       "472       40                3\n",
       "473       40                3\n",
       "474       38                2\n",
       "475       20                1\n",
       "476       37                3\n",
       "\n",
       "[477 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_cluster_df['cluster_reduced'] = docs_cluster_df['cluster'].apply(lambda x: get_reduced_cluster(x, clusters_reduced))\n",
    "docs_cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>contents</th>\n",
       "      <th>url</th>\n",
       "      <th>crawl_at</th>\n",
       "      <th>is_news</th>\n",
       "      <th>clip_at</th>\n",
       "      <th>contents_prep</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_reduced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bivariate Probit and Logit Models</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThere are no videos fo...</td>\n",
       "      <td>https://sites.google.com/site/econometricsacad...</td>\n",
       "      <td>2020-10-30 08:09:41.048296</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-05 13:58:24</td>\n",
       "      <td>bivariate probit and logit models . there are ...</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variance inflation factor</td>\n",
       "      <td>None</td>\n",
       "      <td>In statistics, the variance inflation factor (...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Variance_inflati...</td>\n",
       "      <td>2020-10-30 08:09:41.849368</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-05 14:09:24</td>\n",
       "      <td>it turns out that the square of this standard ...</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Statistical Analysis with Missing Data</td>\n",
       "      <td>None</td>\n",
       "      <td>Praise for the First Edition of Statistical An...</td>\n",
       "      <td>http://onlinelibrary.wiley.com/book/10.1002/97...</td>\n",
       "      <td>2020-10-30 08:09:43.493087</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-05 17:24:55</td>\n",
       "      <td>statistical analysis with missing data . prais...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>DATA ANALYSIS NOTES: LINKS AND GENERAL GUIDELI...</td>\n",
       "      <td>https://www.princeton.edu/~otorres/Stata/statn...</td>\n",
       "      <td>2020-10-30 08:09:48.192109</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-08 22:23:54</td>\n",
       "      <td>!! data analysis : annotated output exploring ...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>고지방 식이가 뇌에도 영향을 준다?</td>\n",
       "      <td>2017-11-05 01:00:11+09:00</td>\n",
       "      <td>지방은 사실 반드시 필요한 영양소다. 여러 필수 지방산은 우리가 생존하는 데 있어 ...</td>\n",
       "      <td>http://ppss.kr/archives/47698</td>\n",
       "      <td>2020-10-30 08:09:52.934917</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-09 01:26:38</td>\n",
       "      <td>루이지애나 주립 대학 의 연구자 들 은 저널 ‘ biological psychiat...</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>이태원 사태로 변한 국내 이동량은?...'통계청·SKT 빅데이터 분석'</td>\n",
       "      <td>2020-05-15 10:23:17+09:00</td>\n",
       "      <td>신종 코로나바이러스 감염증(코로나19)이 확산하면서 작년 대비 58% 수준까지 떨어...</td>\n",
       "      <td>https://www.google.co.kr/amp/s/m.biz.chosun.co...</td>\n",
       "      <td>2020-10-30 08:24:55.558336</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-24 20:29:31</td>\n",
       "      <td>이태원 사태 로 변한 국내 이 동량 은 ? ...' 통계청 · skt 빅 데이터 분...</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>KBS NEWS</td>\n",
       "      <td>None</td>\n",
       "      <td>http://news.kbs.co.kr/news/list.do?icd=19588\\n...</td>\n",
       "      <td>http://mn.kbs.co.kr/mobile/news/view.do?ncd=44...</td>\n",
       "      <td>2020-10-30 08:24:56.085810</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-24 20:30:06</td>\n",
       "      <td>URL 정부 가 sk 텔레콤 의 인구 이동 빅 데이터 를 이용해 코로나 19 의 영...</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>The Accusations Were Lies. But Could We Prove It?</td>\n",
       "      <td>2020-03-18 00:00:00</td>\n",
       "      <td>Once we began sharing what was happening to us...</td>\n",
       "      <td>https://www.nytimes.com/2020/03/18/magazine/ti...</td>\n",
       "      <td>2020-10-30 08:24:58.270745</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-28 10:29:10</td>\n",
       "      <td>think about so - called deepfakes , those wome...</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Modeling COVID 19 ¶</td>\n",
       "      <td>None</td>\n",
       "      <td>This is a Python version of the code for analy...</td>\n",
       "      <td>https://python.quantecon.org/sir_model.html</td>\n",
       "      <td>2020-10-30 08:24:58.731276</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-29 20:55:12</td>\n",
       "      <td>modeling covid 1 9 ¶. this is a python version...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>코로나바이러스감염증-19 &gt; 뉴스 &amp; 이슈 &gt; 보도자료 내용보기 \" 코로나바이러스감...</td>\n",
       "      <td>None</td>\n",
       "      <td>코로나바이러스감염증-19 국내 발생 현황 (7월 29일 정례브리핑)\\n\\n질병관리본...</td>\n",
       "      <td>http://ncov.mohw.go.kr/tcmBoardView.do?brdId=&amp;...</td>\n",
       "      <td>2020-10-30 08:24:59.140949</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-29 21:03:26</td>\n",
       "      <td>코로나 바이러스 감염증 - 19 국내 발생 현황 ( 7 월 2 9 일 정례 브리핑 ...</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>477 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0                    Bivariate Probit and Logit Models   \n",
       "1                            Variance inflation factor   \n",
       "2               Statistical Analysis with Missing Data   \n",
       "3                                        Data Analysis   \n",
       "4                                  고지방 식이가 뇌에도 영향을 준다?   \n",
       "..                                                 ...   \n",
       "472            이태원 사태로 변한 국내 이동량은?...'통계청·SKT 빅데이터 분석'   \n",
       "473                                           KBS NEWS   \n",
       "474  The Accusations Were Lies. But Could We Prove It?   \n",
       "475                                Modeling COVID 19 ¶   \n",
       "476  코로나바이러스감염증-19 > 뉴스 & 이슈 > 보도자료 내용보기 \" 코로나바이러스감...   \n",
       "\n",
       "                  publish_date  \\\n",
       "0                         None   \n",
       "1                         None   \n",
       "2                         None   \n",
       "3                         None   \n",
       "4    2017-11-05 01:00:11+09:00   \n",
       "..                         ...   \n",
       "472  2020-05-15 10:23:17+09:00   \n",
       "473                       None   \n",
       "474        2020-03-18 00:00:00   \n",
       "475                       None   \n",
       "476                       None   \n",
       "\n",
       "                                              contents  \\\n",
       "0    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThere are no videos fo...   \n",
       "1    In statistics, the variance inflation factor (...   \n",
       "2    Praise for the First Edition of Statistical An...   \n",
       "3    DATA ANALYSIS NOTES: LINKS AND GENERAL GUIDELI...   \n",
       "4    지방은 사실 반드시 필요한 영양소다. 여러 필수 지방산은 우리가 생존하는 데 있어 ...   \n",
       "..                                                 ...   \n",
       "472  신종 코로나바이러스 감염증(코로나19)이 확산하면서 작년 대비 58% 수준까지 떨어...   \n",
       "473  http://news.kbs.co.kr/news/list.do?icd=19588\\n...   \n",
       "474  Once we began sharing what was happening to us...   \n",
       "475  This is a Python version of the code for analy...   \n",
       "476  코로나바이러스감염증-19 국내 발생 현황 (7월 29일 정례브리핑)\\n\\n질병관리본...   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://sites.google.com/site/econometricsacad...   \n",
       "1    https://en.wikipedia.org/wiki/Variance_inflati...   \n",
       "2    http://onlinelibrary.wiley.com/book/10.1002/97...   \n",
       "3    https://www.princeton.edu/~otorres/Stata/statn...   \n",
       "4                        http://ppss.kr/archives/47698   \n",
       "..                                                 ...   \n",
       "472  https://www.google.co.kr/amp/s/m.biz.chosun.co...   \n",
       "473  http://mn.kbs.co.kr/mobile/news/view.do?ncd=44...   \n",
       "474  https://www.nytimes.com/2020/03/18/magazine/ti...   \n",
       "475        https://python.quantecon.org/sir_model.html   \n",
       "476  http://ncov.mohw.go.kr/tcmBoardView.do?brdId=&...   \n",
       "\n",
       "                      crawl_at  is_news             clip_at  \\\n",
       "0   2020-10-30 08:09:41.048296    False 2015-11-05 13:58:24   \n",
       "1   2020-10-30 08:09:41.849368    False 2015-11-05 14:09:24   \n",
       "2   2020-10-30 08:09:43.493087    False 2015-11-05 17:24:55   \n",
       "3   2020-10-30 08:09:48.192109    False 2015-11-08 22:23:54   \n",
       "4   2020-10-30 08:09:52.934917    False 2015-11-09 01:26:38   \n",
       "..                         ...      ...                 ...   \n",
       "472 2020-10-30 08:24:55.558336     True 2020-07-24 20:29:31   \n",
       "473 2020-10-30 08:24:56.085810    False 2020-07-24 20:30:06   \n",
       "474 2020-10-30 08:24:58.270745     True 2020-07-28 10:29:10   \n",
       "475 2020-10-30 08:24:58.731276    False 2020-07-29 20:55:12   \n",
       "476 2020-10-30 08:24:59.140949    False 2020-07-29 21:03:26   \n",
       "\n",
       "                                         contents_prep  cluster  \\\n",
       "0    bivariate probit and logit models . there are ...       39   \n",
       "1    it turns out that the square of this standard ...       23   \n",
       "2    statistical analysis with missing data . prais...       20   \n",
       "3    !! data analysis : annotated output exploring ...        2   \n",
       "4    루이지애나 주립 대학 의 연구자 들 은 저널 ‘ biological psychiat...       43   \n",
       "..                                                 ...      ...   \n",
       "472  이태원 사태 로 변한 국내 이 동량 은 ? ...' 통계청 · skt 빅 데이터 분...       40   \n",
       "473  URL 정부 가 sk 텔레콤 의 인구 이동 빅 데이터 를 이용해 코로나 19 의 영...       40   \n",
       "474  think about so - called deepfakes , those wome...       38   \n",
       "475  modeling covid 1 9 ¶. this is a python version...       20   \n",
       "476  코로나 바이러스 감염증 - 19 국내 발생 현황 ( 7 월 2 9 일 정례 브리핑 ...       37   \n",
       "\n",
       "     cluster_reduced  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  4  \n",
       "4                  0  \n",
       "..               ...  \n",
       "472                3  \n",
       "473                3  \n",
       "474                2  \n",
       "475                1  \n",
       "476                3  \n",
       "\n",
       "[477 rows x 10 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_docs_df = user_docs_df.join(docs_cluster_df, how='left')\n",
    "user_docs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_obj(user_data_dir, \"user_docs_df.pkl\", user_docs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lz_4-HsH6rI"
   },
   "source": [
    "- topic_sizes: The number of documents most similar to each topic. (decreasing size order)\n",
    "- topic_nums: The unique index of every topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1008 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tm_model.generate_documents_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "h3gIl9k5TYDi"
   },
   "outputs": [],
   "source": [
    "topic_words, word_scores, topic_nums = tm_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['variance', '변수', 'covariance', ..., 'optimization',\n",
       "        'interactions', 'data'],\n",
       "       ['neural', 'neurons', 'networks', ..., 'correlations', 'nucleus',\n",
       "        'correlated'],\n",
       "       ['tutorial', '학습', 'learning', ..., '우분투', 'html', 'programs'],\n",
       "       ...,\n",
       "       ['mask', 'fsl', 'mxpath', ..., 'patients', 'text', 'questions'],\n",
       "       ['groups', 'activation', 'group', ..., '파티션', 'movement', '부분'],\n",
       "       ['apk', 'android', '우분투', ..., '과정', 'safari', 'version']],\n",
       "      dtype='<U15')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[list(zip(topic_words[i],word_scores[i]))for i in range(len(topic_nums))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8Yr1MAwSTYDp",
    "outputId": "f0fc0b28-d152-4a47-8a5e-3f3647fdb0d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  (array(['python', 'numpy', '파이썬', 'tensorflow', 'function', 'kwargs', '변수',\n",
       "          'integers', 'functions', 'args', 'computational', 'github',\n",
       "          'coding', 'preprocessing', 'algorithm', 'dataset', 'matlab',\n",
       "          'encoding', 'nipype', 'variables', 'functional', 'module',\n",
       "          'processes', 'variable', 'optimization', 'import', '기능',\n",
       "          'parameter', '인코딩', 'ubuntu', '코드', 'array', 'program', 'linux',\n",
       "          'hippocampus', 'mozilla', 'code', 'utf', 'func', 'py',\n",
       "          'parameters', 'tutorial', '프로세스', 'kernel', 'keyword',\n",
       "          'processing', 'xorg', 'foldername', 'process', '과정'], dtype='<U15'),\n",
       "   array([0.4201187 , 0.3455378 , 0.33073246, 0.24728239, 0.2161268 ,\n",
       "          0.21596757, 0.20947121, 0.20243955, 0.1959648 , 0.18737306,\n",
       "          0.17879285, 0.17821383, 0.17776805, 0.17606455, 0.17278647,\n",
       "          0.17003119, 0.16345873, 0.1625199 , 0.16095081, 0.15987577,\n",
       "          0.15768597, 0.15459798, 0.15069339, 0.14444137, 0.14292023,\n",
       "          0.14137706, 0.14107937, 0.13758062, 0.13719718, 0.13421297,\n",
       "          0.1339301 , 0.1337666 , 0.13334933, 0.13321283, 0.13280115,\n",
       "          0.132778  , 0.13160682, 0.13001199, 0.1276824 , 0.12192366,\n",
       "          0.11728077, 0.11536714, 0.11465085, 0.11413647, 0.11131141,\n",
       "          0.1109507 , 0.1097036 , 0.10851471, 0.10825209, 0.10758838],\n",
       "         dtype=float32))),\n",
       " (1,\n",
       "  (array(['neuroscience', 'neural', 'neurons', 'neuroimaging',\n",
       "          'computational', 'university', '신경망', 'brain', 'psychology',\n",
       "          'intelligence', 'technology', 'scientists', 'cerebral', 'science',\n",
       "          'computer', 'cognitive', 'scientific', 'study', '과학', 'college',\n",
       "          '학습', 'alzheimer', 'ability', 'program', 'researchers', 'nucleus',\n",
       "          'network', 'networks', 'midbrain', 'institute', 'degree',\n",
       "          'subjects', '프로그램', '과정', 'web', 'coding', 'studies', 'matlab',\n",
       "          'student', 'algorithm', 'learning', 'apply', 'programs',\n",
       "          'artificial', 'knowledge', 'anova', 'students', 'hippocampus',\n",
       "          'information', 'correlated'], dtype='<U15'),\n",
       "   array([0.3069026 , 0.2574802 , 0.23561057, 0.18808368, 0.17228626,\n",
       "          0.17132467, 0.16220349, 0.15801282, 0.1566474 , 0.15368661,\n",
       "          0.14765802, 0.1456588 , 0.14197317, 0.14174187, 0.14012173,\n",
       "          0.13024533, 0.1270246 , 0.12680937, 0.12661925, 0.12128358,\n",
       "          0.1196837 , 0.11867507, 0.11749348, 0.11659517, 0.11648493,\n",
       "          0.11638467, 0.11600011, 0.1157739 , 0.11201847, 0.11105003,\n",
       "          0.1104953 , 0.10795923, 0.10794684, 0.10749526, 0.10656043,\n",
       "          0.10616958, 0.10585991, 0.10530674, 0.10505833, 0.10457831,\n",
       "          0.10425403, 0.10239088, 0.10231964, 0.10222915, 0.09963197,\n",
       "          0.0992479 , 0.09908276, 0.09897843, 0.09744584, 0.09700607],\n",
       "         dtype=float32))),\n",
       " (2,\n",
       "  (array(['url', 'html', 'utf', 'firefox', 'github', 'browser', 'localhost',\n",
       "          'chrome', 'python', 'mozilla', 'encoding', 'tensorflow', 'request',\n",
       "          'mxpath', '파이썬', 'google', 'web', 'page', 'function', 'requests',\n",
       "          'coding', '변수', 'safari', 'functions', '페이지', 'parameters',\n",
       "          'parameter', 'kwargs', 'source', 'regression', 'correlations',\n",
       "          'string', 'solution', 'path', 'index', 'correlated',\n",
       "          'optimization', 'correlation', '구글', 'dataset', 'variables',\n",
       "          'variable', '인코딩', 'functional', 'site', 'solve', '요청', 'xorg',\n",
       "          'code', 'paths'], dtype='<U15'),\n",
       "   array([0.29055095, 0.2440621 , 0.21230721, 0.21178363, 0.20547448,\n",
       "          0.19962801, 0.19653448, 0.18098113, 0.17954114, 0.17754227,\n",
       "          0.1678628 , 0.16305576, 0.16304795, 0.16175355, 0.15888494,\n",
       "          0.15872043, 0.15812764, 0.151434  , 0.1482405 , 0.14662598,\n",
       "          0.141481  , 0.14126833, 0.1387959 , 0.13808444, 0.13774204,\n",
       "          0.13703188, 0.13568738, 0.13293767, 0.12979785, 0.12852791,\n",
       "          0.1278116 , 0.12712955, 0.12403159, 0.12387674, 0.12344125,\n",
       "          0.12336272, 0.1226559 , 0.12178367, 0.11940215, 0.11870483,\n",
       "          0.11723482, 0.11646996, 0.11497612, 0.11384066, 0.11355986,\n",
       "          0.11328979, 0.11213668, 0.11096649, 0.10828469, 0.10808654],\n",
       "         dtype=float32))),\n",
       " (3,\n",
       "  (array(['소고기', '파스타', '토마토', '올리브', '소스', '법칙', 'process', 'keyword',\n",
       "          'terms', 'approach', 'grub', 'term', 'parameter', 'processes',\n",
       "          '프로세스', '과정', '법선', 'parameters', '전세', 'preprocessing',\n",
       "          'services', 'method', 'language', 'states', 'food', '처리',\n",
       "          'understanding', 'defined', 'state', 'methods', 'estimated',\n",
       "          'kwargs', 'approaches', '일반', 'processing', 'significance',\n",
       "          'google', 'sum', 'general', 'health', 'summary', 'differences',\n",
       "          'specific', 'notes', 'difference', '서비스', 'service', '기본', 'tasks',\n",
       "          'note'], dtype='<U15'),\n",
       "   array([0.19097547, 0.18866   , 0.17807126, 0.1524541 , 0.14651757,\n",
       "          0.13979408, 0.13411614, 0.1271667 , 0.1255545 , 0.12525623,\n",
       "          0.12444888, 0.12346382, 0.12314646, 0.1221981 , 0.11956818,\n",
       "          0.11868416, 0.11838718, 0.11832801, 0.11759294, 0.11739574,\n",
       "          0.11736299, 0.11726798, 0.11712524, 0.11710775, 0.11521704,\n",
       "          0.11365254, 0.11183541, 0.11182915, 0.11069666, 0.10939008,\n",
       "          0.10910323, 0.10851768, 0.10841942, 0.10836143, 0.10810158,\n",
       "          0.10695339, 0.10595971, 0.10399634, 0.1039203 , 0.10366859,\n",
       "          0.10364945, 0.10362838, 0.10317197, 0.10307266, 0.10269967,\n",
       "          0.10191886, 0.10182256, 0.10174686, 0.10159604, 0.10132749],\n",
       "         dtype=float32))),\n",
       " (4,\n",
       "  (array(['adhd', 'depression', 'depressive', 'disorders', 'disorder',\n",
       "          'symptoms', 'dopamine', 'mental', 'psychology', 'neuroimaging',\n",
       "          'cognitive', 'anxiety', 'behavioural', 'behavioral', 'emotional',\n",
       "          'dementia', 'alzheimer', '신경망', 'correlation', 'behaviors',\n",
       "          'impairment', 'traits', 'neuroscience', 'correlations', 'behavior',\n",
       "          'clinical', 'correlated', 'neurons', 'disease', 'statistics',\n",
       "          'coefficients', 'effects', 'statistical', 'neural', 'mood',\n",
       "          'stress', 'cerebral', 'prefrontal', 'populations', '영향',\n",
       "          'interaction', 'effect', 'groups', 'adolescents', 'activities',\n",
       "          'patients', 'features', 'intelligence', 'activity', 'regression'],\n",
       "         dtype='<U15'),\n",
       "   array([0.2462304 , 0.23952267, 0.20050323, 0.19827455, 0.19771683,\n",
       "          0.18780735, 0.17720497, 0.17681676, 0.17224075, 0.16690493,\n",
       "          0.16503754, 0.15847196, 0.15404595, 0.1512038 , 0.1454509 ,\n",
       "          0.13096029, 0.13089636, 0.12847722, 0.12820657, 0.12793264,\n",
       "          0.12665948, 0.12663418, 0.12471385, 0.12063975, 0.11526164,\n",
       "          0.11516848, 0.10873416, 0.10860334, 0.10204507, 0.10193264,\n",
       "          0.10035661, 0.09846772, 0.09844042, 0.09749283, 0.09454815,\n",
       "          0.09452271, 0.09361446, 0.09115143, 0.0877813 , 0.08691093,\n",
       "          0.08519424, 0.08281547, 0.08022301, 0.07941377, 0.07743221,\n",
       "          0.07740238, 0.07705526, 0.0751677 , 0.074696  , 0.06867603],\n",
       "         dtype=float32))),\n",
       " (5,\n",
       "  (array(['tensorflow', 'github', '우분투', 'ubuntu', 'linux', 'localhost',\n",
       "          'xorg', 'kernel', 'numpy', 'python', 'matlab', 'sudo', 'directory',\n",
       "          'nvidia', 'vtk', 'ssh', 'mxpath', 'gpu', 'kwargs', 'usb',\n",
       "          'computational', 'port', 'foldername', 'script', 'install',\n",
       "          'openmx', 'cpu', '파이썬', 'ip', 'distribution', 'installing', '리눅스',\n",
       "          'cp', 'ctrl', 'default', 'fmriprep', 'nipype', 'cuda',\n",
       "          'distributed', 'fsl', 'software', 'hippocampus', 'command',\n",
       "          'postaladdress', 'tutorial', 'integration', '파일', 'mv', 'textrm',\n",
       "          'ftd'], dtype='<U15'),\n",
       "   array([0.2970832 , 0.28586918, 0.2609602 , 0.24675825, 0.2326105 ,\n",
       "          0.23136383, 0.21030672, 0.2083211 , 0.19873536, 0.19515184,\n",
       "          0.19297409, 0.18594745, 0.17113236, 0.16508785, 0.16118029,\n",
       "          0.15827268, 0.15517744, 0.14963076, 0.14880928, 0.14552267,\n",
       "          0.14550269, 0.14339536, 0.14292488, 0.13936636, 0.13639331,\n",
       "          0.13564797, 0.13457052, 0.13427487, 0.1342141 , 0.13118772,\n",
       "          0.1308735 , 0.12806356, 0.12635517, 0.12087938, 0.11860462,\n",
       "          0.11597445, 0.11576299, 0.11470205, 0.11386931, 0.11312887,\n",
       "          0.11147387, 0.11074468, 0.11042371, 0.10920286, 0.10889483,\n",
       "          0.10880879, 0.1079689 , 0.10776449, 0.10743535, 0.10650048],\n",
       "         dtype=float32))),\n",
       " (6,\n",
       "  (array(['tutorial', '학습', '강의', 'learning', 'class', 'training',\n",
       "          'students', '과정', 'tensorflow', 'student', 'learn', 'trained',\n",
       "          'pdf', 'introduction', 'school', 'neural', '교수', 'subjects',\n",
       "          'university', 'theoretical', 'technology', '기술', 'guide', 'course',\n",
       "          'derived', 'manual', '러닝', '교육', 'neuroscience', 'college',\n",
       "          'source', 'practice', 'ubuntu', 'computational', 'concepts',\n",
       "          'study', 'preprocessing', 'knowledge', 'matlab', 'institute',\n",
       "          'subject', 'sneakers', '리눅스', 'processes', 'ability', 'linux',\n",
       "          'train', 'article', 'stanford', 'extraction'], dtype='<U15'),\n",
       "   array([0.2515047 , 0.23758137, 0.22845083, 0.21976943, 0.20691516,\n",
       "          0.20418316, 0.20347723, 0.20330557, 0.20220089, 0.19956413,\n",
       "          0.18872216, 0.18746358, 0.17449847, 0.17249805, 0.1666661 ,\n",
       "          0.16619173, 0.16531906, 0.15793693, 0.15713239, 0.15520471,\n",
       "          0.1493627 , 0.14872828, 0.14842221, 0.14584658, 0.14447743,\n",
       "          0.14408892, 0.14397125, 0.1428454 , 0.13885018, 0.13879067,\n",
       "          0.13857566, 0.13363364, 0.13246799, 0.13086149, 0.12954344,\n",
       "          0.12840934, 0.12825282, 0.12758774, 0.12590194, 0.1258471 ,\n",
       "          0.12449674, 0.12399036, 0.12275971, 0.12269768, 0.12217683,\n",
       "          0.12047976, 0.12029884, 0.12008298, 0.11977494, 0.11882441],\n",
       "         dtype=float32))),\n",
       " (7,\n",
       "  (array(['dataset', 'correlation', 'data', 'correlations', '데이터',\n",
       "          'computational', '회귀분석', 'integration', 'matlab', 'algorithm',\n",
       "          'information', 'correlated', 'numpy', 'regression', 'tensorflow',\n",
       "          'statistics', 'parameters', 'populations', 'statistical',\n",
       "          'analytics', 'datetime', 'analysis', 'optimization', 'population',\n",
       "          'covariance', '정보', 'coefficients', 'analyses', 'voxel',\n",
       "          'estimates', 'bmatrix', 'distributed', 'parameter', '분석', 'mxpath',\n",
       "          'extraction', 'voxels', '관련', 'plots', 'encoding', 'plot',\n",
       "          'estimated', 'estimate', 'variance', 'individuals', 'index',\n",
       "          'preprocessing', 'predict', 'patients', '계산'], dtype='<U15'),\n",
       "   array([0.21084733, 0.16997448, 0.16336489, 0.1632517 , 0.14459345,\n",
       "          0.14234872, 0.1375014 , 0.13697417, 0.13285464, 0.13258569,\n",
       "          0.13111845, 0.12989357, 0.1277852 , 0.12183462, 0.11895485,\n",
       "          0.11694401, 0.11601657, 0.11571732, 0.11541785, 0.10576856,\n",
       "          0.10419537, 0.10315154, 0.10297942, 0.09794006, 0.09534582,\n",
       "          0.09512375, 0.09300465, 0.09267418, 0.09236365, 0.09169273,\n",
       "          0.08849496, 0.08846301, 0.08706086, 0.08473068, 0.08447459,\n",
       "          0.08439665, 0.08360595, 0.08315435, 0.08147322, 0.08024631,\n",
       "          0.08008958, 0.07997075, 0.07996436, 0.07959678, 0.07846552,\n",
       "          0.07797743, 0.07650707, 0.07596116, 0.07520896, 0.07501142],\n",
       "         dtype=float32))),\n",
       " (8,\n",
       "  (array(['neural', 'networks', 'neurons', 'network', 'neuroscience',\n",
       "          'neuroimaging', 'algorithm', 'computational', '신경망', 'dataset',\n",
       "          'tensorflow', 'coefficients', 'regression', 'theoretical',\n",
       "          'learning', 'traits', 'training', 'information', 'derived',\n",
       "          'numpy', 'matlab', 'trained', 'class', 'layers', 'optimization',\n",
       "          'populations', 'data', 'intelligence', 'github', 'distributed',\n",
       "          'layer', '회귀분석', 'technology', '학습', 'connectivity', 'nucleus',\n",
       "          'cognitive', 'concepts', 'systems', 'coding', 'computer',\n",
       "          'sequence', 'cerebral', 'linear', 'genetic', 'psychology', 'learn',\n",
       "          'features', 'brain', 'functions'], dtype='<U15'),\n",
       "   array([0.3034889 , 0.26958746, 0.25939253, 0.2544439 , 0.23430917,\n",
       "          0.2180796 , 0.21217418, 0.2024193 , 0.18445608, 0.15076664,\n",
       "          0.15052857, 0.13350196, 0.13023767, 0.13018972, 0.13006312,\n",
       "          0.12558419, 0.12506504, 0.12050711, 0.12027944, 0.12024239,\n",
       "          0.11905749, 0.11842439, 0.11781917, 0.11743113, 0.11712924,\n",
       "          0.11599597, 0.11584986, 0.11505944, 0.11492002, 0.11307579,\n",
       "          0.11237335, 0.10803491, 0.10781322, 0.10735945, 0.10599437,\n",
       "          0.10469572, 0.10467863, 0.10459416, 0.10348798, 0.10310452,\n",
       "          0.10276941, 0.10207896, 0.10178072, 0.09943508, 0.09776847,\n",
       "          0.09770882, 0.09759907, 0.09759095, 0.09683566, 0.09679234],\n",
       "         dtype=float32))),\n",
       " (9,\n",
       "  (array(['대출', 'documents', 'account', 'application', 'interest',\n",
       "          'applications', 'document', '세대주', '방정식', 'benefit', 'apply', '증가',\n",
       "          'applied', 'previous', '적용', '회귀분석', '기본', 'multiple', 'alt',\n",
       "          'term', 'default', 'app', 'lower', 'hypo', 'form', 'services',\n",
       "          'preprocessing', '일반', '소금', 'basal', '계산', 'primary', 'most',\n",
       "          'age', 'general', 'terms', 'cell', 'common', 'processes',\n",
       "          'relative', 'process', 'low', 'population', '청년', 'depression',\n",
       "          '전세', 'cells', 'number', 'increased', 'rate'], dtype='<U15'),\n",
       "   array([0.23494273, 0.13848077, 0.13469759, 0.1313229 , 0.12433518,\n",
       "          0.12232816, 0.11943141, 0.1136431 , 0.11273327, 0.1110408 ,\n",
       "          0.10902198, 0.09717527, 0.0933513 , 0.08962325, 0.08929126,\n",
       "          0.08925617, 0.08899708, 0.08729184, 0.08698878, 0.08429538,\n",
       "          0.08312833, 0.08247164, 0.08154494, 0.08142063, 0.08077115,\n",
       "          0.08051617, 0.08028442, 0.07973704, 0.07924496, 0.07877558,\n",
       "          0.07875782, 0.07798149, 0.07736814, 0.07711238, 0.07708582,\n",
       "          0.07696813, 0.07688366, 0.07682351, 0.07646165, 0.07265409,\n",
       "          0.07261515, 0.07196417, 0.07141941, 0.07103319, 0.07102618,\n",
       "          0.071004  , 0.07100232, 0.06955767, 0.06897964, 0.06849279],\n",
       "         dtype=float32))),\n",
       " (10,\n",
       "  (array(['xorg', 'ubuntu', 'nvidia', 'kernel', 'sudo', 'gpu', 'linux',\n",
       "          '우분투', '부팅', 'grub', '드라이버', 'cpu', 'driver', 'boot', '그래픽',\n",
       "          'tensorflow', 'graphics', 'install', 'command', '윈도우', 'fix',\n",
       "          'installing', '명령', 'firefox', 'windows', 'fixed', 'desktop',\n",
       "          '리눅스', 'github', 'problem', 'openmx', 'latest', 'matlab', 'run',\n",
       "          '명령어', 'runs', 'vtk', 'startvar', 'kwargs', 'alt', 'derived',\n",
       "          'help', 'nouveau', '화면', 'args', 'textrm', 'xbp', 'give',\n",
       "          'default', 'remove'], dtype='<U15'),\n",
       "   array([0.43199867, 0.39229864, 0.38804403, 0.30863038, 0.3016294 ,\n",
       "          0.29591513, 0.290309  , 0.25238743, 0.21627793, 0.20820495,\n",
       "          0.19973746, 0.19552743, 0.19309616, 0.18648174, 0.18254612,\n",
       "          0.18219712, 0.17495286, 0.16723669, 0.1626666 , 0.15901978,\n",
       "          0.15850157, 0.152338  , 0.15146956, 0.15106305, 0.15004301,\n",
       "          0.14825073, 0.14767238, 0.14273472, 0.13968606, 0.1377339 ,\n",
       "          0.13743569, 0.13552041, 0.1346714 , 0.13265991, 0.13092452,\n",
       "          0.12918144, 0.127976  , 0.1278686 , 0.12500127, 0.1236881 ,\n",
       "          0.12365147, 0.12332816, 0.12322567, 0.12125099, 0.12023714,\n",
       "          0.11980236, 0.11976671, 0.11778885, 0.11742596, 0.11702704],\n",
       "         dtype=float32))),\n",
       " (11,\n",
       "  (array(['regression', 'statistical', 'statistics', 'parameters', 'predict',\n",
       "          'parameter', 'matlab', 'optimization', 'coefficients', 'estimated',\n",
       "          'variance', 'models', 'estimate', 'covariance', '모델', 'estimates',\n",
       "          '예측', 'sigma', 'model', 'populations', 'mathbf', 'numpy',\n",
       "          'population', 'bmatrix', 'correlation', '회귀분석', 'approach', '방정식',\n",
       "          'dataset', 'algorithm', 'alzheimer', 'global', 'args',\n",
       "          'correlations', 'computational', 'max', 'prefrontal', 'bias',\n",
       "          'template', '변수', 'previous', 'data', 'sum', 'values',\n",
       "          'representation', 'modeling', 'default', 'future',\n",
       "          'representations', 'impairment'], dtype='<U15'),\n",
       "   array([0.17968196, 0.17301244, 0.1627444 , 0.16071391, 0.15068236,\n",
       "          0.14261535, 0.13862664, 0.13820235, 0.13785419, 0.12656836,\n",
       "          0.12443773, 0.12437537, 0.12254601, 0.12002227, 0.1174345 ,\n",
       "          0.11704919, 0.11313757, 0.11114324, 0.10925507, 0.10580654,\n",
       "          0.1050972 , 0.10089004, 0.09938107, 0.0948627 , 0.09422985,\n",
       "          0.09374568, 0.09083292, 0.09007278, 0.08607036, 0.08544929,\n",
       "          0.08420873, 0.08176306, 0.08153788, 0.07873611, 0.07850458,\n",
       "          0.07725506, 0.07713165, 0.07678308, 0.07592521, 0.07538748,\n",
       "          0.07437193, 0.0737848 , 0.07310487, 0.07234745, 0.07035755,\n",
       "          0.07019583, 0.06893435, 0.06841584, 0.065466  , 0.06324916],\n",
       "         dtype=float32))),\n",
       " (12,\n",
       "  (array(['correlation', 'correlations', 'correlated', 'cognitive',\n",
       "          'neuroscience', 'interaction', 'neuroimaging', 'interactions',\n",
       "          'neural', 'neurons', 'connectivity', 'cerebral', '신경망',\n",
       "          'coefficients', 'brain', 'psychology', 'networks', 'functional',\n",
       "          '기능', '관계', 'associated', 'functions', 'intelligence',\n",
       "          'covariance', 'differences', 'network', 'relationship',\n",
       "          'regression', 'traits', '메모리', 'connection', 'between', 'features',\n",
       "          'emotional', 'factor', 'behavioural', 'internal', 'function',\n",
       "          'memory', 'variance', 'related', 'ability', 'association',\n",
       "          'alzheimer', 'directory', 'difference', 'changes', 'connections',\n",
       "          'integration', 'index'], dtype='<U15'),\n",
       "   array([0.19104224, 0.1876675 , 0.18671364, 0.17191201, 0.16218926,\n",
       "          0.15317062, 0.15143764, 0.14450878, 0.1391593 , 0.13580315,\n",
       "          0.1279877 , 0.1275809 , 0.12112383, 0.11886159, 0.11871456,\n",
       "          0.11635635, 0.11265135, 0.10794152, 0.10733377, 0.10687499,\n",
       "          0.10521117, 0.10327183, 0.10139485, 0.09924001, 0.09852867,\n",
       "          0.09595694, 0.09544017, 0.09308904, 0.09305664, 0.08840748,\n",
       "          0.08837844, 0.08753635, 0.08743329, 0.08495606, 0.08468916,\n",
       "          0.08385968, 0.08321489, 0.08309472, 0.0820578 , 0.08097942,\n",
       "          0.08051673, 0.07996619, 0.07993259, 0.07873082, 0.07867821,\n",
       "          0.0779114 , 0.07715385, 0.0743071 , 0.0742139 , 0.07307027],\n",
       "         dtype=float32))),\n",
       " (13,\n",
       "  (array(['author', 'authors', 'novel', 'scientists', 'emotional',\n",
       "          'published', 'read', 'write', 'written', '과학', 'neuroscience',\n",
       "          '이야기', 'book', 'scientific', 'gatsby', 'human', 'article',\n",
       "          'science', 'self', '없이', 'without', 'subject', '아닌', 'mind', '아니',\n",
       "          'non', 'resonance', 'mental', 'humans', 'intelligence', 'deep',\n",
       "          'person', 'latent', '인간', 'though', 'artificial', 'ability', 'no',\n",
       "          'midbrain', 'depressive', 'environmental', 'mood', 'arguments',\n",
       "          'independent', 'space', 'brain', 'others', 'plot', 'labels',\n",
       "          'itself'], dtype='<U15'),\n",
       "   array([0.26626232, 0.26168907, 0.2263763 , 0.17228067, 0.16666052,\n",
       "          0.15371297, 0.15314879, 0.1531197 , 0.1491035 , 0.14625871,\n",
       "          0.14431751, 0.14401077, 0.14304075, 0.14180845, 0.13134104,\n",
       "          0.1282117 , 0.12637806, 0.1227452 , 0.12101585, 0.11985094,\n",
       "          0.11818043, 0.11817126, 0.11590048, 0.11409801, 0.11373881,\n",
       "          0.11345771, 0.11307119, 0.11284368, 0.11107959, 0.11034684,\n",
       "          0.11019301, 0.10976177, 0.1090212 , 0.10887417, 0.10810373,\n",
       "          0.107738  , 0.10748436, 0.1061816 , 0.10574228, 0.10493277,\n",
       "          0.10442221, 0.1030325 , 0.10227399, 0.10163399, 0.10096271,\n",
       "          0.09969185, 0.09869677, 0.09803744, 0.09801979, 0.0978184 ],\n",
       "         dtype=float32))),\n",
       " (14,\n",
       "  (array(['dataset', 'plot', 'plots', 'data', '데이터', 'geom', 'matlab',\n",
       "          'numpy', '그래픽', 'gradient', 'statistics', 'statistical',\n",
       "          'correlation', 'correlations', 'information', 'populations',\n",
       "          'graphics', 'coefficients', 'distribution', 'github',\n",
       "          'significance', 'variables', 'datetime', '정보', 'variance',\n",
       "          'tensorflow', 'regression', 'distributed', 'linear', 'labels',\n",
       "          'population', 'index', 'correlated', 'df', '변수', 'traits',\n",
       "          'values', 'python', '행렬', 'scale', 'predict', 'covariance', 'date',\n",
       "          'bmatrix', 'estimates', 'algorithm', 'rate', 'variable', 'levels',\n",
       "          'label'], dtype='<U15'),\n",
       "   array([0.2916876 , 0.28439862, 0.2638349 , 0.23540026, 0.2138631 ,\n",
       "          0.18949956, 0.18281592, 0.18261662, 0.17771497, 0.16730833,\n",
       "          0.16662706, 0.16071714, 0.15778485, 0.15229036, 0.15213457,\n",
       "          0.15096079, 0.14913155, 0.13882339, 0.13704333, 0.13652404,\n",
       "          0.1360248 , 0.13596764, 0.13429257, 0.1341396 , 0.13342449,\n",
       "          0.13183898, 0.13097224, 0.12975042, 0.12865591, 0.12794024,\n",
       "          0.1279327 , 0.12767541, 0.1256194 , 0.12155719, 0.11864713,\n",
       "          0.11750764, 0.11719399, 0.11695406, 0.11585167, 0.11567092,\n",
       "          0.11507253, 0.11464481, 0.11357573, 0.11192961, 0.11115   ,\n",
       "          0.11071774, 0.10961908, 0.10925485, 0.10860109, 0.10746395],\n",
       "         dtype=float32))),\n",
       " (15,\n",
       "  (array(['browser', 'firefox', 'mozilla', 'html', 'chrome', 'analytics',\n",
       "          '사이트', 'github', 'web', '페이지', 'page', 'site', 'analyses',\n",
       "          'safari', 'matlab', 'learning', 'mxpath', 'algorithm', 'bmatrix',\n",
       "          'numpy', 'blog', 'useful', 'tutorial', 'learn', 'url', 'log',\n",
       "          '파이썬', 'comparisons', 'dataset', 'analysis', '구글', 'compare',\n",
       "          'python', 'better', 'optimization', 'computational', '변수', 'xorg',\n",
       "          'assess', 'parameters', 'processes', 'online', 'ctrl', 'script',\n",
       "          'good', 'compared', 'coding', '학습', 'ylab', 'samples'],\n",
       "         dtype='<U15'),\n",
       "   array([0.29305536, 0.27265728, 0.22614226, 0.22454867, 0.21755229,\n",
       "          0.20711349, 0.19202328, 0.17544183, 0.16233298, 0.16047841,\n",
       "          0.15927649, 0.15892705, 0.1539437 , 0.15056485, 0.15017998,\n",
       "          0.14773445, 0.14225303, 0.1410815 , 0.1407567 , 0.13708161,\n",
       "          0.13543074, 0.13517568, 0.13338326, 0.13282618, 0.13194333,\n",
       "          0.12910253, 0.12874304, 0.12850417, 0.12723348, 0.12689479,\n",
       "          0.12579675, 0.12473635, 0.12431245, 0.12314206, 0.12180847,\n",
       "          0.12157767, 0.12110822, 0.12088145, 0.12025867, 0.1197028 ,\n",
       "          0.11769232, 0.11677431, 0.11359102, 0.11325599, 0.11255029,\n",
       "          0.11226337, 0.11108452, 0.11077968, 0.110549  , 0.1104474 ],\n",
       "         dtype=float32))),\n",
       " (16,\n",
       "  (array(['dataset', 'data', '데이터', 'statistics', 'matlab', 'tensorflow',\n",
       "          'statistical', 'computational', 'analytics', 'numpy', 'samples',\n",
       "          'analysis', 'correlations', 'estimates', 'sample', 'coefficients',\n",
       "          'regression', 'correlation', 'analyses', 'integration', 'datetime',\n",
       "          'github', 'estimate', 'neural', '회귀분석', 'training', 'predict',\n",
       "          'parameters', 'estimated', '예측', '분석', 'correlated', 'future',\n",
       "          'values', 'modeling', 'module', 'models', 'python', '모델', 'linear',\n",
       "          'information', 'neuroscience', 'parameter', '학습', '계산', 'neurons',\n",
       "          'linux', '기능', 'ubuntu', 'preprocessing'], dtype='<U15'),\n",
       "   array([0.25794968, 0.21491224, 0.19819587, 0.18901914, 0.18515894,\n",
       "          0.18505242, 0.18348527, 0.18017921, 0.17323309, 0.17167956,\n",
       "          0.15302485, 0.14567381, 0.14550482, 0.14458591, 0.14392278,\n",
       "          0.14223735, 0.14030237, 0.14020123, 0.1381324 , 0.1360999 ,\n",
       "          0.12696315, 0.1263378 , 0.12567073, 0.12439638, 0.12278914,\n",
       "          0.12180477, 0.12125193, 0.12064369, 0.12015633, 0.11745362,\n",
       "          0.11540103, 0.11494391, 0.11201675, 0.10756294, 0.10599278,\n",
       "          0.10508502, 0.10460627, 0.10345684, 0.10342734, 0.10107077,\n",
       "          0.0997179 , 0.09965921, 0.09523714, 0.09437071, 0.09377669,\n",
       "          0.09306306, 0.09142782, 0.09101897, 0.08959632, 0.08803707],\n",
       "         dtype=float32))),\n",
       " (17,\n",
       "  (array(['다시', 'renaming', 'trying', 'again', '적용', 'regression', 'error',\n",
       "          '행동', 'behavioral', 'applied', 'experiment', 'once', 'behavior',\n",
       "          'nouveau', 'back', 'apply', 'dropout', 'mode', 'application',\n",
       "          'works', 're', 'try', 'behaviors', '작업', 'measures', 'effort',\n",
       "          'practice', 'work', '한글', 'times', 'method', 'ways', 'fix',\n",
       "          'behavioural', '진행', 'normal', '다른', '한지', 'adjustment', 'working',\n",
       "          '이름', 'methods', 'copy', 'impairment', '종료', 'process', 'still',\n",
       "          '이동', 'sequence', 'just'], dtype='<U15'),\n",
       "   array([0.18979883, 0.17488386, 0.14873603, 0.14289212, 0.1411049 ,\n",
       "          0.13660283, 0.13238393, 0.13013458, 0.12341708, 0.12245537,\n",
       "          0.12204008, 0.12142873, 0.11807916, 0.11807529, 0.1180471 ,\n",
       "          0.11389032, 0.11371014, 0.11278673, 0.11139125, 0.11137865,\n",
       "          0.11043943, 0.11025006, 0.11023623, 0.10929865, 0.10530241,\n",
       "          0.10436168, 0.10424154, 0.10223313, 0.10203596, 0.10160281,\n",
       "          0.10153566, 0.09948993, 0.09931621, 0.09904017, 0.09891768,\n",
       "          0.09838495, 0.0975171 , 0.09692641, 0.09316282, 0.09290545,\n",
       "          0.09263544, 0.09203565, 0.09189548, 0.09155522, 0.09142485,\n",
       "          0.09137563, 0.0912987 , 0.09069911, 0.09045891, 0.09009985],\n",
       "         dtype=float32))),\n",
       " (18,\n",
       "  (array(['statistical', 'covariance', 'statistics', 'distribution',\n",
       "          'variance', 'distributed', 'sample', 'random', 'coefficients',\n",
       "          'samples', 'correlations', 'predict', 'correlation', 'populations',\n",
       "          'bias', 'comparisons', 'regression', 'mixture', 'population',\n",
       "          'sigma', 'integration', 'correlated', 'cases', 'tensorflow',\n",
       "          'examples', 'computational', 'estimated', 'numpy', 'mixed',\n",
       "          'optimization', 'sum', '회귀분석', 'compare', '예측', 'estimate',\n",
       "          'theoretical', 'variables', 'groups', 'sequence', 'instance',\n",
       "          'estimates', 'consistent', '비교', 'matlab', 'participants',\n",
       "          'example', 'algorithm', 'group', '변수', 'mathbf'], dtype='<U15'),\n",
       "   array([0.24084628, 0.23070797, 0.20788911, 0.20477962, 0.20359242,\n",
       "          0.19525224, 0.1847098 , 0.18235332, 0.18034403, 0.16769613,\n",
       "          0.15369081, 0.15236497, 0.15222241, 0.13648552, 0.13078485,\n",
       "          0.12282974, 0.12082744, 0.12079655, 0.11979167, 0.11932258,\n",
       "          0.11930227, 0.11898877, 0.11642517, 0.11401229, 0.11230648,\n",
       "          0.1110934 , 0.11037293, 0.10842153, 0.1083333 , 0.10802538,\n",
       "          0.10729025, 0.10541081, 0.10371579, 0.10185827, 0.10173972,\n",
       "          0.099854  , 0.09983121, 0.09960191, 0.09719089, 0.09703832,\n",
       "          0.09613306, 0.09519815, 0.09260319, 0.09233811, 0.09198823,\n",
       "          0.09125523, 0.08952393, 0.08786593, 0.08748476, 0.08629958],\n",
       "         dtype=float32))),\n",
       " (19,\n",
       "  (array(['arxiv', 'supporting', 'contribution', 'support', '지원',\n",
       "          'community', 'giving', 'organizations', 'benefit', 'groups', 'don',\n",
       "          'foundation', 'give', 'we', '우리', '가입', 'join', 'group', 'us',\n",
       "          'increased', 'you', 'september', 'voxels', 'reward', 'our',\n",
       "          'scientific', 'provide', 'your', 'help', 'voxel', '증가',\n",
       "          'populations', 'improve', 'create', 'rewards', 'gather', 'df',\n",
       "          'movement', 'useful', 'new', 'activation', 'provides', 'anova',\n",
       "          'let', 'improvements', 'aov', 'send', 'already', 'creating',\n",
       "          'science'], dtype='<U15'),\n",
       "   array([0.2790783 , 0.26876494, 0.26458138, 0.25350606, 0.25141376,\n",
       "          0.21422829, 0.19029981, 0.18829589, 0.18280151, 0.1760457 ,\n",
       "          0.17513157, 0.17381549, 0.17358504, 0.17165218, 0.16969231,\n",
       "          0.16051276, 0.15970367, 0.15776902, 0.15722904, 0.14669967,\n",
       "          0.14510785, 0.1446175 , 0.14432746, 0.1417577 , 0.13926394,\n",
       "          0.13777515, 0.13438928, 0.13356845, 0.13314502, 0.13292377,\n",
       "          0.13292323, 0.13262323, 0.13130169, 0.13120812, 0.13020626,\n",
       "          0.12843193, 0.12829621, 0.1265026 , 0.12636197, 0.12607467,\n",
       "          0.12393942, 0.12273982, 0.12162425, 0.12152746, 0.12101717,\n",
       "          0.11891665, 0.11810981, 0.11771359, 0.11771342, 0.11723956],\n",
       "         dtype=float32))),\n",
       " (20,\n",
       "  (array(['statistical', 'statistics', 'dataset', 'regression', 'data',\n",
       "          'correlation', '회귀분석', 'correlations', '데이터', 'significance',\n",
       "          'predict', 'correlated', 'variance', 'estimates', 'coefficients',\n",
       "          'estimated', 'populations', 'estimate', 'computational',\n",
       "          'population', 'sample', 'covariance', 'average', 'variables',\n",
       "          'distribution', 'distributed', 'analysis', 'important',\n",
       "          'analytics', 'individual', 'samples', 'total', '예측', 'significant',\n",
       "          'independent', 'parameters', 'random', 'values', '변수', 'global',\n",
       "          'analyses', 'datetime', 'means', 'scale', 'groups', '관계', 'tool',\n",
       "          'individuals', 'include', 'significantly'], dtype='<U15'),\n",
       "   array([0.33209187, 0.31010014, 0.23621382, 0.2136201 , 0.21010128,\n",
       "          0.19744423, 0.19458704, 0.1942317 , 0.19201884, 0.17082927,\n",
       "          0.16660583, 0.16442916, 0.16177075, 0.15578936, 0.1541363 ,\n",
       "          0.15256943, 0.1469204 , 0.14468431, 0.1392642 , 0.13904044,\n",
       "          0.1285615 , 0.1283721 , 0.12710205, 0.12692255, 0.12501033,\n",
       "          0.12392799, 0.12288405, 0.12247249, 0.11813422, 0.1150593 ,\n",
       "          0.11432935, 0.11350065, 0.11265466, 0.11121708, 0.109953  ,\n",
       "          0.10853697, 0.10825683, 0.10708426, 0.10643396, 0.10518897,\n",
       "          0.10452339, 0.1032556 , 0.10290801, 0.10172311, 0.10129485,\n",
       "          0.10097982, 0.10095929, 0.09978436, 0.0991919 , 0.09829786],\n",
       "         dtype=float32))),\n",
       " (21,\n",
       "  (array(['neuroscience', 'scientists', '과학', 'science', 'neurons',\n",
       "          'scientific', 'neural', 'magnetic', 'neuroimaging', 'brain',\n",
       "          'researchers', 'theoretical', 'alzheimer', 'intelligence',\n",
       "          'theory', '신경망', 'nucleus', 'computational', 'psychology',\n",
       "          'matlab', 'integers', 'technology', 'cerebral', 'midbrain',\n",
       "          'mathrm', '토마토', 'ants', 'complex', 'small', 'mind', 'mice',\n",
       "          'algorithm', 'lab', 'hippocampus', 'mathbf', 'studies', 'study',\n",
       "          '연구', 'computer', 'knowledge', 'subjects', 'university', 'solve',\n",
       "          'tasks', 'kernel', 'students', 'new', 'sneakers', 'research',\n",
       "          'coding'], dtype='<U15'),\n",
       "   array([0.3155995 , 0.31407887, 0.2835564 , 0.27124217, 0.25286815,\n",
       "          0.23583943, 0.21406686, 0.1973301 , 0.19260868, 0.18789342,\n",
       "          0.18289798, 0.17567609, 0.17456648, 0.16856235, 0.1661311 ,\n",
       "          0.15985282, 0.15831444, 0.1304948 , 0.12380372, 0.1232418 ,\n",
       "          0.12175179, 0.11995432, 0.11788742, 0.11699423, 0.11651614,\n",
       "          0.10984611, 0.10609166, 0.10516865, 0.10472598, 0.1027451 ,\n",
       "          0.10044262, 0.10032234, 0.09995348, 0.09943816, 0.09821569,\n",
       "          0.09671246, 0.09608098, 0.09597676, 0.094726  , 0.09354834,\n",
       "          0.09213702, 0.09210585, 0.09186755, 0.09065743, 0.08879721,\n",
       "          0.0882291 , 0.08788188, 0.08782364, 0.08712794, 0.08694828],\n",
       "         dtype=float32))),\n",
       " (22,\n",
       "  (array(['neuroimaging', 'neuroscience', 'dopamine', 'correlation',\n",
       "          'neurons', 'correlated', 'correlations', 'researchers', 'rewards',\n",
       "          'neural', 'reward', 'psychology', 'interaction', 'cognitive',\n",
       "          'behavioural', 'behavioral', '신경망', 'interactions', 'results',\n",
       "          '연구', 'studies', '결과', 'positive', 'behaviors', 'benefit',\n",
       "          'findings', 'result', 'effects', 'activities', 'depression',\n",
       "          'effect', 'hippocampus', 'scientists', 'ventral', 'delayed',\n",
       "          'behavior', 'activity', 'functions', 'populations', 'intelligence',\n",
       "          '영향', 'coefficients', 'functional', 'selection', '효과',\n",
       "          'statistical', 'interest', 'participants', 'anxiety',\n",
       "          'performance'], dtype='<U15'),\n",
       "   array([0.18589534, 0.18471707, 0.1810342 , 0.17373437, 0.17230615,\n",
       "          0.16696174, 0.16574287, 0.1654484 , 0.16085207, 0.1596007 ,\n",
       "          0.15931195, 0.15667482, 0.1467186 , 0.14483082, 0.14043202,\n",
       "          0.13742997, 0.13714021, 0.13159668, 0.13062012, 0.12999235,\n",
       "          0.12034962, 0.11732619, 0.1164078 , 0.11550233, 0.11450362,\n",
       "          0.11209989, 0.10987568, 0.10981898, 0.10921085, 0.10893323,\n",
       "          0.10740536, 0.10702682, 0.10700139, 0.1037978 , 0.10366297,\n",
       "          0.10296184, 0.10258121, 0.1023833 , 0.10124638, 0.10036131,\n",
       "          0.09466702, 0.0942739 , 0.09378015, 0.09338021, 0.09323503,\n",
       "          0.09316165, 0.09164745, 0.09156992, 0.09147447, 0.09068034],\n",
       "         dtype=float32))),\n",
       " (23,\n",
       "  (array(['변수', 'variables', 'variable', 'variance', 'covariance',\n",
       "          'independent', 'parameters', 'regression', 'statistics',\n",
       "          'statistical', 'parameter', 'coefficients', '모델', 'correlation',\n",
       "          'correlations', 'dependent', 'individual', 'estimates', 'models',\n",
       "          'predict', 'model', 'estimated', 'estimate', 'differences',\n",
       "          'interaction', '회귀분석', 'modeling', 'interactions', 'sample',\n",
       "          'correlated', 'patients', 'factor', '변화', '예측', 'difference',\n",
       "          'dataset', 'different', 'adult', 'relationship', 'analysis',\n",
       "          'analytics', 'changes', 'samples', '관계', 'own', 'expr',\n",
       "          'individuals', 'module', 'args', 'single'], dtype='<U15'),\n",
       "   array([0.3087626 , 0.2723217 , 0.24536553, 0.23639008, 0.19501151,\n",
       "          0.19052167, 0.18759784, 0.18750238, 0.17233074, 0.16832083,\n",
       "          0.16665846, 0.15042098, 0.14513217, 0.14107725, 0.1328572 ,\n",
       "          0.12664229, 0.1240495 , 0.12385213, 0.12313295, 0.12053399,\n",
       "          0.11677879, 0.11510357, 0.11425745, 0.10641675, 0.10496138,\n",
       "          0.10273752, 0.10236656, 0.10114498, 0.09972104, 0.09902065,\n",
       "          0.09830858, 0.0951841 , 0.09331892, 0.09258088, 0.09251291,\n",
       "          0.0911047 , 0.09029381, 0.08471081, 0.08395731, 0.0803858 ,\n",
       "          0.07921117, 0.07839671, 0.07838207, 0.0780748 , 0.07561211,\n",
       "          0.07543214, 0.07521867, 0.07409602, 0.07402503, 0.07369085],\n",
       "         dtype=float32))),\n",
       " (24,\n",
       "  (array(['genetic', '유전자', 'adhd', 'variance', 'generation', 'selection',\n",
       "          'populations', 'traits', 'covariance', 'distributed', 'regression',\n",
       "          'models', 'correlation', 'correlated', 'alzheimer', 'born',\n",
       "          'distribution', '세대주', 'neuroimaging', 'correlations', 'model',\n",
       "          'population', 'individual', 'statistical', 'risk', '모델',\n",
       "          'individuals', '생성', 'dataset', 'select', 'parameters',\n",
       "          'variables', 'disorders', 'discounting', 'ad', '변수', 'increased',\n",
       "          'quality', 'statistics', 'patterns', 'template', 'create',\n",
       "          'neuroscience', 'available', 'disorder', 'pairs', 'choice',\n",
       "          'dementia', 'cdh', 'impairment'], dtype='<U15'),\n",
       "   array([0.22073609, 0.21414787, 0.17581546, 0.14244716, 0.13722767,\n",
       "          0.13067564, 0.11858515, 0.11619879, 0.11208524, 0.11034925,\n",
       "          0.10880484, 0.10837805, 0.10736436, 0.10702051, 0.10672024,\n",
       "          0.10620856, 0.10584509, 0.10146607, 0.10109575, 0.09837012,\n",
       "          0.09479713, 0.09476138, 0.09403794, 0.09395631, 0.09362884,\n",
       "          0.09354303, 0.09125595, 0.09035891, 0.08999244, 0.08829327,\n",
       "          0.08825481, 0.08702008, 0.08413586, 0.08412945, 0.08361134,\n",
       "          0.08355896, 0.08285988, 0.08265152, 0.08250823, 0.0824508 ,\n",
       "          0.08244798, 0.0803327 , 0.07829599, 0.0779075 , 0.07713294,\n",
       "          0.0763775 , 0.07600622, 0.07460973, 0.07427172, 0.07266639],\n",
       "         dtype=float32))),\n",
       " (25,\n",
       "  (array(['github', 'account', 'git', 'development', 'commit', '구글', '개발',\n",
       "          'project', 'email', 'tensorflow', 'problems', 'dataset', 'delayed',\n",
       "          '문제', 'issues', 'problem', 'delay', 'disease', 'projected',\n",
       "          'environment', 'kwargs', 'environmental', '코드', 'significant',\n",
       "          'disorders', '기본', 'issue', 'code', 'coding', '변수', 'pain',\n",
       "          'community', 'encoding', 'we', 'variables', 'significantly', 'our',\n",
       "          '우리', 'feature', '데이터', 'data', 'regression', 'lib', 'fix',\n",
       "          'google', 'create', 'larger', 'important', 'variable', 'concepts'],\n",
       "         dtype='<U15'),\n",
       "   array([0.33879718, 0.16346014, 0.16229707, 0.1619767 , 0.14974529,\n",
       "          0.145287  , 0.14388633, 0.1374123 , 0.12690169, 0.10911712,\n",
       "          0.10795322, 0.10696268, 0.10675855, 0.10393058, 0.09775393,\n",
       "          0.09637858, 0.09617037, 0.09595727, 0.09340364, 0.09201629,\n",
       "          0.09157528, 0.09044014, 0.08906578, 0.08518507, 0.08401216,\n",
       "          0.08230072, 0.08220034, 0.08163552, 0.08106906, 0.08012167,\n",
       "          0.07773516, 0.07637429, 0.0749633 , 0.07436129, 0.0742529 ,\n",
       "          0.07383556, 0.0723425 , 0.07137652, 0.07118871, 0.07051816,\n",
       "          0.06989469, 0.06909329, 0.06867268, 0.06729121, 0.06711871,\n",
       "          0.06551389, 0.06535372, 0.06525391, 0.06517285, 0.06511824],\n",
       "         dtype=float32))),\n",
       " (26,\n",
       "  (array(['psychology', 'cognitive', 'behavioural', 'neuroimaging',\n",
       "          'neuroscience', 'neural', 'neurons', 'behavioral', 'performance',\n",
       "          'interaction', 'coefficients', 'behaviors', '신경망', 'dementia',\n",
       "          'mental', 'individuals', 'alzheimer', 'physical', 'ability',\n",
       "          'traits', 'behavior', 'adhd', 'activity', 'brain', 'statistical',\n",
       "          'correlated', 'individual', 'impairment', 'emotional',\n",
       "          'correlation', 'activities', 'activation', 'statistics',\n",
       "          'populations', 'scores', 'clinical', 'visual', '영향', 'assess',\n",
       "          'regression', 'effect', 'interactions', 'index', 'correlations',\n",
       "          'rate', 'effects', 'cerebral', 'features', 'movement', 'person'],\n",
       "         dtype='<U15'),\n",
       "   array([0.17500944, 0.16927083, 0.14440972, 0.14205208, 0.14196593,\n",
       "          0.13969013, 0.13858898, 0.13830039, 0.13281216, 0.12747575,\n",
       "          0.12684686, 0.12376568, 0.12307927, 0.12295927, 0.1214247 ,\n",
       "          0.12113142, 0.12068506, 0.11896922, 0.11625625, 0.11284575,\n",
       "          0.11152235, 0.10863385, 0.10766304, 0.10633231, 0.10588151,\n",
       "          0.10471117, 0.10428883, 0.1035731 , 0.10261506, 0.10251611,\n",
       "          0.10092963, 0.09914196, 0.09794386, 0.09765111, 0.09743696,\n",
       "          0.09714305, 0.09658173, 0.09602422, 0.09460808, 0.09346129,\n",
       "          0.09294371, 0.09227693, 0.09221839, 0.09182549, 0.09156793,\n",
       "          0.09134792, 0.09126098, 0.0907387 , 0.09059177, 0.08907085],\n",
       "         dtype=float32))),\n",
       " (27,\n",
       "  (array(['neurons', 'neuroimaging', 'neural', 'neuroscience', 'brain',\n",
       "          'nucleus', '신경망', 'midbrain', 'cerebral', 'cells', 'hippocampus',\n",
       "          'cell', 'basal', 'module', 'alzheimer', 'cognitive', 'ventral',\n",
       "          'functions', 'internal', 'mental', 'disorders', 'cortex',\n",
       "          'development', '기능', 'function', 'motor', 'memory', 'functional',\n",
       "          'genetic', 'disorder', 'psychology', 'intelligence', 'traits',\n",
       "          'mind', '메모리', 'symptoms', 'ability', 'body', 'interactions', '개발',\n",
       "          'interaction', 'primary', 'features', 'kernel', 'potential',\n",
       "          'disease', 'form', 'regions', 'movement', 'func'], dtype='<U15'),\n",
       "   array([0.2888014 , 0.2545275 , 0.25413004, 0.23282152, 0.22018322,\n",
       "          0.21692258, 0.21368101, 0.21069944, 0.20014676, 0.15871662,\n",
       "          0.14449939, 0.14422175, 0.13475154, 0.13346323, 0.1323202 ,\n",
       "          0.129867  , 0.12827031, 0.12756014, 0.12714636, 0.12210453,\n",
       "          0.11901358, 0.11682222, 0.11208887, 0.10734653, 0.10712738,\n",
       "          0.1061427 , 0.10599154, 0.10512386, 0.10503048, 0.10396712,\n",
       "          0.10337722, 0.10165898, 0.10013036, 0.09757181, 0.09389903,\n",
       "          0.09337506, 0.09323792, 0.09175145, 0.09153828, 0.0911814 ,\n",
       "          0.08968516, 0.08804125, 0.08692217, 0.08531344, 0.08466938,\n",
       "          0.08421085, 0.08234574, 0.08070587, 0.08029766, 0.07948597],\n",
       "         dtype=float32))),\n",
       " (28,\n",
       "  (array(['변수', 'variables', 'variable', 'variance', 'covariance', 'numpy',\n",
       "          'dataset', 'coefficients', 'statistical', 'regression', 'values',\n",
       "          'statistics', 'tensorflow', 'correlation', 'matlab', 'estimates',\n",
       "          'correlations', 'computational', 'estimated', 'parameters',\n",
       "          'parameter', 'data', '모델', 'estimate', 'value', 'python', 'models',\n",
       "          '데이터', 'mathbf', '회귀분석', 'algorithm', 'model', 'optimization',\n",
       "          'datetime', 'correlated', '계산', '방정식', 'populations', 'sum',\n",
       "          'sigma', 'anova', 'comparisons', 'integers', 'modeling', 'rate',\n",
       "          'integration', 'pairs', 'error', 'function', 'openmx'],\n",
       "         dtype='<U15'),\n",
       "   array([0.2931808 , 0.2908987 , 0.25903344, 0.2536111 , 0.25136176,\n",
       "          0.24127787, 0.22008838, 0.2171711 , 0.19787821, 0.19759144,\n",
       "          0.1967496 , 0.19272849, 0.18082419, 0.18005231, 0.17867842,\n",
       "          0.17678377, 0.17050213, 0.17025465, 0.16281417, 0.16157214,\n",
       "          0.15731676, 0.15126713, 0.15073259, 0.15031926, 0.14437178,\n",
       "          0.13831913, 0.13323313, 0.13227122, 0.1314061 , 0.13071823,\n",
       "          0.1296517 , 0.12894629, 0.12836538, 0.12448859, 0.12390077,\n",
       "          0.12352826, 0.12268123, 0.1199012 , 0.11679406, 0.11321826,\n",
       "          0.11174807, 0.11091302, 0.10682015, 0.10613454, 0.10354288,\n",
       "          0.1031688 , 0.10250431, 0.10242231, 0.10212993, 0.10200675],\n",
       "         dtype=float32))),\n",
       " (29,\n",
       "  (array(['women', 'gender', 'men', 'scientists', 'researchers',\n",
       "          'statistics', 'correlations', 'studies', 'correlation',\n",
       "          'statistical', 'values', 'comparisons', 'groups', 'levels',\n",
       "          'scientific', 'differences', 'findings', 'compared', 'rate',\n",
       "          'populations', 'correlated', 'subjects', '관계', '교수', '연구',\n",
       "          'students', 'study', 'coefficients', 'degree', 'inference',\n",
       "          'student', 'science', 'relationship', 'psychology', 'neuroscience',\n",
       "          'compare', 'factors', 'difference', 'estimated', 'variance',\n",
       "          'polyamor', 'adolescents', '비교', 'intelligence', 'scores', 'array',\n",
       "          'bias', 'emotional', 'population', 'factor'], dtype='<U15'),\n",
       "   array([0.2945645 , 0.24153125, 0.19706805, 0.14635035, 0.13698375,\n",
       "          0.1368147 , 0.13432378, 0.1292646 , 0.1266334 , 0.12412423,\n",
       "          0.12156482, 0.12101898, 0.12031361, 0.11899838, 0.11764383,\n",
       "          0.11608101, 0.11368263, 0.11332594, 0.1117291 , 0.11162772,\n",
       "          0.11098003, 0.10989575, 0.10923954, 0.10861345, 0.10679908,\n",
       "          0.1053257 , 0.10408612, 0.10302445, 0.10283823, 0.10267468,\n",
       "          0.10231245, 0.10208355, 0.10186689, 0.09998969, 0.09888586,\n",
       "          0.09759034, 0.09680119, 0.09665115, 0.09583648, 0.09583014,\n",
       "          0.09577724, 0.09487266, 0.09474252, 0.09363661, 0.09344283,\n",
       "          0.09168603, 0.0912383 , 0.08928685, 0.0892015 , 0.08915675],\n",
       "         dtype=float32))),\n",
       " (30,\n",
       "  (array(['neural', 'neurons', 'neuroscience', 'neuroimaging',\n",
       "          'computational', 'models', 'brain', '모델', '신경망', 'cerebral',\n",
       "          'model', 'coefficients', 'modeling', 'networks', 'correlations',\n",
       "          'functional', '메모리', 'correlation', 'memory', 'dataset', 'traits',\n",
       "          'correlated', 'intelligence', 'cognitive', 'psychology', 'data',\n",
       "          'statistical', 'network', 'functions', 'distributed', 'features',\n",
       "          'predict', 'statistics', 'friston', 'information', '기능',\n",
       "          'estimates', 'regression', 'midbrain', 'individuals', 'ability',\n",
       "          'theoretical', 'estimated', '데이터', 'concepts', '계산', 'patterns',\n",
       "          'populations', 'computer', 'optimization'], dtype='<U15'),\n",
       "   array([0.23009636, 0.21872824, 0.21479863, 0.19299465, 0.17867413,\n",
       "          0.15363328, 0.15313923, 0.1503871 , 0.14727023, 0.14483564,\n",
       "          0.13862711, 0.12741688, 0.12703913, 0.12572837, 0.12172346,\n",
       "          0.12168182, 0.12101705, 0.12097147, 0.1207618 , 0.1192947 ,\n",
       "          0.1172889 , 0.11419563, 0.11260875, 0.11206029, 0.10886715,\n",
       "          0.10758518, 0.10741327, 0.10697529, 0.10342419, 0.10267282,\n",
       "          0.10244406, 0.09949471, 0.09795602, 0.09374412, 0.09305693,\n",
       "          0.09266831, 0.09113217, 0.09011786, 0.08993233, 0.08851585,\n",
       "          0.08762369, 0.08669533, 0.08631612, 0.086255  , 0.08561523,\n",
       "          0.08478488, 0.08446462, 0.08383758, 0.08360033, 0.08280624],\n",
       "         dtype=float32))),\n",
       " (31,\n",
       "  (array(['prison', 'psychology', 'experiment', 'scientists', 'populations',\n",
       "          'samples', 'mental', 'stanford', 'individuals', 'theory', 'sample',\n",
       "          'scientific', 'hippocampus', 'trained', 'published', 'parkinson',\n",
       "          'statistics', 'species', 'groups', '과학', 'students', 'free',\n",
       "          'coefficients', 'plasticity', 'people', 'neuroscience', 'science',\n",
       "          'variables', 'humans', 'similar', 'public', 'were', 'numpy',\n",
       "          'population', 'evidence', 'library', '학습', 'researchers',\n",
       "          'studies', 'findings', 'cognitive', 'hippocampal', 'gatsby',\n",
       "          'individual', 'traits', 'behavioural', 'book', 'variable',\n",
       "          'adolescents', '변수'], dtype='<U15'),\n",
       "   array([0.26055098, 0.20732023, 0.15318574, 0.14809664, 0.14533707,\n",
       "          0.1322507 , 0.12933432, 0.12816247, 0.12363449, 0.11715917,\n",
       "          0.11398065, 0.10761258, 0.10719791, 0.10510944, 0.10433808,\n",
       "          0.10389158, 0.1015074 , 0.09765457, 0.09756552, 0.09524474,\n",
       "          0.09444354, 0.09358411, 0.09341615, 0.09248212, 0.09167845,\n",
       "          0.08970702, 0.08940135, 0.08932748, 0.08917578, 0.08799139,\n",
       "          0.08743834, 0.08606979, 0.08567984, 0.08527635, 0.08523391,\n",
       "          0.08523259, 0.08496739, 0.08481062, 0.08472565, 0.08437328,\n",
       "          0.08346105, 0.08345908, 0.08172882, 0.08160769, 0.08035421,\n",
       "          0.08012006, 0.08004002, 0.07996484, 0.07964072, 0.07949308],\n",
       "         dtype=float32))),\n",
       " (32,\n",
       "  (array(['access', 'options', 'article', '옵션', 'side', 'library', 'option',\n",
       "          'pdf', 'available', 'genetic', '유전자', '여기', 'psychology', '기술',\n",
       "          'mxpath', 'here', 'left', 'document', 'cerebral', 'technology',\n",
       "          'documents', 'allows', '연구', 'midbrain', 'disease', 'items',\n",
       "          'able', 'social', 'dementia', 'disorders', 'section', 'prefrontal',\n",
       "          'shared', 'conditions', 'this', 'space', 'depression', 'alzheimer',\n",
       "          '가능', 'patients', 'disorder', 'these', 'environment', 'part',\n",
       "          'published', 'environmental', '파티션', 'supporting', 'such', '아래'],\n",
       "         dtype='<U15'),\n",
       "   array([0.32876384, 0.17953068, 0.17832409, 0.17755428, 0.16759339,\n",
       "          0.166818  , 0.16636677, 0.1616992 , 0.15948962, 0.15563075,\n",
       "          0.14955564, 0.14610505, 0.1399171 , 0.1362013 , 0.1313802 ,\n",
       "          0.13122757, 0.12913892, 0.12800373, 0.12790462, 0.12700778,\n",
       "          0.12653029, 0.12366472, 0.12352941, 0.12289535, 0.12219128,\n",
       "          0.12127305, 0.12002438, 0.1198521 , 0.11947457, 0.11737616,\n",
       "          0.11596173, 0.11398514, 0.11353432, 0.11330482, 0.11248599,\n",
       "          0.11159606, 0.11141793, 0.11068232, 0.11041187, 0.10876103,\n",
       "          0.10799027, 0.10687116, 0.10513086, 0.10490642, 0.1044417 ,\n",
       "          0.10278614, 0.10267441, 0.10252532, 0.10172804, 0.10119544],\n",
       "         dtype=float32))),\n",
       " (33,\n",
       "  (array(['neuroscience', 'neurons', 'neural', 'neuroimaging', 'brain',\n",
       "          '신경망', 'cerebral', 'midbrain', 'cognitive', 'mental', 'memory',\n",
       "          'computational', '메모리', 'psychology', 'nucleus', 'alzheimer',\n",
       "          'concepts', 'mind', 'scientific', 'intelligence', 'theoretical',\n",
       "          'temporal', 'computer', '개념', '과학', 'cortex', 'scientists', 'body',\n",
       "          'science', 'selection', '시간', 'functions', 'theory', 'parameters',\n",
       "          'clinical', 'coefficients', 'objects', 'physical', 'hippocampus',\n",
       "          'internal', 'delayed', 'index', 'humans', '계산', 'datetime',\n",
       "          'ability', 'disorders', 'dementia', 'parameter', 'symptoms'],\n",
       "         dtype='<U15'),\n",
       "   array([0.34335905, 0.33637807, 0.31083614, 0.29428422, 0.25575757,\n",
       "          0.2515765 , 0.2138933 , 0.20706892, 0.17175393, 0.15880013,\n",
       "          0.14758131, 0.14621213, 0.14417762, 0.13926527, 0.13606568,\n",
       "          0.13303505, 0.1257771 , 0.12529378, 0.11524326, 0.11512475,\n",
       "          0.11228454, 0.11223488, 0.10621509, 0.10132643, 0.09977107,\n",
       "          0.0949728 , 0.09212027, 0.09051442, 0.08992195, 0.08929509,\n",
       "          0.08862471, 0.08672281, 0.0863371 , 0.08614477, 0.08610845,\n",
       "          0.08557872, 0.08500956, 0.08473131, 0.08305961, 0.0828037 ,\n",
       "          0.08269239, 0.08170419, 0.08069892, 0.08038011, 0.07911527,\n",
       "          0.07904927, 0.07787714, 0.07745972, 0.07744351, 0.0770051 ],\n",
       "         dtype=float32))),\n",
       " (34,\n",
       "  (array(['인간', 'ability', 'human', 'humans', 'main', 'mask', 'traits',\n",
       "          'name', 'revealed', 'matrix', 'species', 'derived', '생성',\n",
       "          'amygdala', 'effects', 'alt', 'individuals', '발생', '이름', 'list',\n",
       "          'types', 'items', '사람', 'rank', 'inputs', 'enter', 'random',\n",
       "          'type', '라는', '기술', 'keyword', 'real', 'technology', 'special',\n",
       "          'who', 'numpy', 'significant', 'previous', 'major', 'role', 'max',\n",
       "          'utf', 'caudate', 'deep', 'authors', 'evidence', 'these', 'arxiv',\n",
       "          'nipype', 'health'], dtype='<U15'),\n",
       "   array([0.17265399, 0.17168081, 0.16828412, 0.15892804, 0.14091074,\n",
       "          0.14028075, 0.1366134 , 0.13615517, 0.13364658, 0.1277161 ,\n",
       "          0.12617965, 0.12616116, 0.12567125, 0.12357725, 0.11990584,\n",
       "          0.11848211, 0.11811364, 0.11581281, 0.1134304 , 0.11236119,\n",
       "          0.11204447, 0.10985713, 0.10906082, 0.10828927, 0.10812202,\n",
       "          0.10788603, 0.10775481, 0.10731144, 0.10729428, 0.10690891,\n",
       "          0.10680042, 0.10556953, 0.10534695, 0.10385151, 0.1037783 ,\n",
       "          0.10361606, 0.10318666, 0.1030668 , 0.10275484, 0.1026167 ,\n",
       "          0.10198966, 0.10185   , 0.10161029, 0.10160911, 0.10154769,\n",
       "          0.1010723 , 0.10105913, 0.10101113, 0.10092448, 0.10092324],\n",
       "         dtype=float32))),\n",
       " (35,\n",
       "  (array(['부팅', 'ubuntu', '파티션', 'boot', '우분투', 'linux', 'grub', 'xorg',\n",
       "          'kernel', '윈도우', 'usb', 'sudo', '옵션', 'default', 'windows', 'gb',\n",
       "          'option', 'options', 'sd', 'directory', '기본', '리눅스', 'cpu',\n",
       "          'nvidia', 'firefox', 'decision', '종료', 'choice', 'format', '명령',\n",
       "          'optimization', 'kwargs', 'localhost', 'mdd', '메모리', '설치',\n",
       "          'install', '명령어', 'gpu', 'command', 'openmx', 'approach',\n",
       "          'approaches', 'parameter', 'processes', 'section', 'mxpath',\n",
       "          'computational', '방정식', 'preference'], dtype='<U15'),\n",
       "   array([0.35287553, 0.30337158, 0.26814148, 0.26365227, 0.24262011,\n",
       "          0.23545234, 0.2186256 , 0.19258493, 0.19146726, 0.16428787,\n",
       "          0.16254163, 0.16050799, 0.15998986, 0.159161  , 0.15491688,\n",
       "          0.15187995, 0.13468572, 0.1259864 , 0.12309657, 0.12083238,\n",
       "          0.11316536, 0.11025299, 0.10744341, 0.1053804 , 0.1047753 ,\n",
       "          0.10331666, 0.10288119, 0.10072602, 0.10034504, 0.10005011,\n",
       "          0.09892793, 0.098234  , 0.09780829, 0.09729728, 0.09456025,\n",
       "          0.09436603, 0.09417561, 0.09413254, 0.0933369 , 0.09324242,\n",
       "          0.09318177, 0.09128387, 0.09100574, 0.09044875, 0.09028417,\n",
       "          0.09013277, 0.08853243, 0.08795366, 0.08781311, 0.08742528],\n",
       "         dtype=float32))),\n",
       " (36,\n",
       "  (array(['textrm', 'dataset', 'covariance', 'mxalgebra', 'text', 'cov',\n",
       "          'numpy', 'data', 'matlab', 'values', 'mathrm', 'statistical',\n",
       "          'variance', 'variables', 'bmatrix', 'comparisons', 'compare',\n",
       "          'regression', 'labels', 'statistics', 'xorg', 'variable',\n",
       "          'tensorflow', 'significance', 'label', 'algorithm', 'voxel',\n",
       "          'correlation', 'plot', 'compared', 'vtk', 'integration', 'value',\n",
       "          'correlations', 'sum', 'mxpath', 'graphics', 'computational',\n",
       "          'information', 'script', 'matrix', '데이터', '행렬', 'anova', 'means',\n",
       "          '변수', 'fmriprep', 'company', '회귀분석', 'group'], dtype='<U15'),\n",
       "   array([0.33714068, 0.2907315 , 0.2576838 , 0.21668702, 0.20176235,\n",
       "          0.19898438, 0.19493665, 0.1940717 , 0.19239235, 0.18859798,\n",
       "          0.18483147, 0.18428221, 0.18406755, 0.18211266, 0.17982891,\n",
       "          0.1766531 , 0.17598063, 0.17527217, 0.17283723, 0.17218228,\n",
       "          0.17149082, 0.16908433, 0.16795504, 0.1663019 , 0.16564238,\n",
       "          0.16283876, 0.16175061, 0.16143163, 0.16133144, 0.16098163,\n",
       "          0.1608685 , 0.16077936, 0.15953791, 0.15845174, 0.15745619,\n",
       "          0.15533057, 0.15182365, 0.15161161, 0.15014137, 0.14992517,\n",
       "          0.14909613, 0.1488373 , 0.1481351 , 0.14757857, 0.14751934,\n",
       "          0.14710937, 0.14556   , 0.14322849, 0.14070815, 0.13943991],\n",
       "         dtype=float32))),\n",
       " (37,\n",
       "  (array(['상황', 'cases', 'public', 'things', 'case', '발생', 'population',\n",
       "          'alzheimer', '가장', 'symptoms', 'many', 'important', 'dementia',\n",
       "          'significant', 'lot', '많이', 'involved', 'disorders', 'common',\n",
       "          'delayed', 'others', '문제', 'prefrontal', 'populations', 'issues',\n",
       "          'most', 'multiple', '패러다임', 'people', 'significantly', 'anxiety',\n",
       "          'processes', 'disease', 'organizations', '종료', 'process',\n",
       "          'evidence', '이상', 'impairment', '한글', '약간', '정리', '옵션', 'close',\n",
       "          'problem', 'matter', 'various', 'attention', 'issue', 'recent'],\n",
       "         dtype='<U15'),\n",
       "   array([0.15589839, 0.15484792, 0.15301879, 0.1279191 , 0.12389772,\n",
       "          0.11977333, 0.11880416, 0.11383268, 0.1073549 , 0.10644701,\n",
       "          0.10603526, 0.10541778, 0.10457374, 0.10262273, 0.10155267,\n",
       "          0.10145795, 0.10110322, 0.10080329, 0.10063979, 0.10039636,\n",
       "          0.09949827, 0.099324  , 0.0992695 , 0.09890734, 0.09888374,\n",
       "          0.09811536, 0.09759689, 0.09752151, 0.0973274 , 0.09705092,\n",
       "          0.09638126, 0.09612711, 0.09551167, 0.09546974, 0.0949036 ,\n",
       "          0.0945667 , 0.0944875 , 0.09393707, 0.09358461, 0.0924618 ,\n",
       "          0.09159819, 0.09136099, 0.09122204, 0.09106807, 0.09048413,\n",
       "          0.09021617, 0.09011059, 0.0899212 , 0.08951735, 0.08891237],\n",
       "         dtype=float32))),\n",
       " (38,\n",
       "  (array(['scientists', 'individual', 'individuals', 'institute', 'humans',\n",
       "          '교수', 'organizations', '우리', 'must', 'self', 'evidence',\n",
       "          'alzheimer', 'us', 'we', 'nii', 'degree', 'documents', 'agent',\n",
       "          'our', '해야', 'lead', 'independent', 'need', 'others',\n",
       "          'intelligence', 'disease', 'nucleus', 'models', '직선', '기준', '필요',\n",
       "          '인간', 'papers', 'inference', 'ants', '자신', 'people', 'students',\n",
       "          'max', 'researchers', '각각', 'every', 'species', 'scientific',\n",
       "          'populations', 'theoretical', 'document', 'sneakers', 'no',\n",
       "          'authors'], dtype='<U15'),\n",
       "   array([0.15405394, 0.13708994, 0.13098215, 0.12232608, 0.11946198,\n",
       "          0.11935638, 0.11583861, 0.11541833, 0.11061768, 0.10939819,\n",
       "          0.10726734, 0.10719424, 0.10579786, 0.1032822 , 0.10321765,\n",
       "          0.10213321, 0.100647  , 0.09594663, 0.09578367, 0.09268993,\n",
       "          0.09262824, 0.09087355, 0.09042121, 0.09012783, 0.08986791,\n",
       "          0.08976851, 0.08971117, 0.08917087, 0.08888443, 0.08863765,\n",
       "          0.08850703, 0.08847848, 0.08767745, 0.08758035, 0.08684064,\n",
       "          0.08638662, 0.08546898, 0.08542937, 0.08483098, 0.08436485,\n",
       "          0.0843151 , 0.08404289, 0.08400034, 0.08285297, 0.08279065,\n",
       "          0.08268544, 0.0817297 , 0.08082224, 0.07957069, 0.07919606],\n",
       "         dtype=float32))),\n",
       " (39,\n",
       "  (array(['모델', 'models', 'modeling', 'correlations', 'correlation', 'model',\n",
       "          'correlated', 'twin', '관계', 'relationship', 'statistics', '관련',\n",
       "          'pairs', 'statistical', 'related', 'covariance', 'interactions',\n",
       "          'regression', 'distributed', 'integration', 'associated',\n",
       "          'interaction', 'genetic', 'dataset', 'relative', 'distribution',\n",
       "          'variance', 'coefficients', 'patterns', 'connectivity',\n",
       "          'connections', 'tensorflow', 'traits', 'template', '유전자',\n",
       "          'samples', 'documents', 'pairwise', 'analytics', 'source', 'data',\n",
       "          'generation', 'pattern', '데이터', 'computational', 'analyses',\n",
       "          'cross', 'comparisons', 'shared', 'both'], dtype='<U15'),\n",
       "   array([0.30137783, 0.29382372, 0.29286575, 0.27363896, 0.26607603,\n",
       "          0.25520554, 0.24625733, 0.21663433, 0.1856738 , 0.18391384,\n",
       "          0.17895085, 0.175614  , 0.17462999, 0.17040168, 0.170243  ,\n",
       "          0.16767746, 0.15406491, 0.15230934, 0.15016176, 0.13798954,\n",
       "          0.13786313, 0.13598512, 0.13580912, 0.13580742, 0.13434188,\n",
       "          0.13412015, 0.13140035, 0.13064831, 0.12916568, 0.12020992,\n",
       "          0.11730275, 0.1156157 , 0.1135235 , 0.11280802, 0.11110394,\n",
       "          0.11070514, 0.10874212, 0.10844214, 0.10666598, 0.10629632,\n",
       "          0.10461517, 0.10323501, 0.10216516, 0.09732504, 0.09290244,\n",
       "          0.09121981, 0.09121165, 0.09068035, 0.09067969, 0.08976045],\n",
       "         dtype=float32))),\n",
       " (40,\n",
       "  (array(['데이터', 'statistics', 'statistical', 'data', 'population',\n",
       "          'populations', 'dataset', 'correlation', 'rate', 'correlations',\n",
       "          'pain', 'neurons', 'impairment', 'results', 'scale',\n",
       "          'neuroimaging', '유전자', 'drug', 'effects', 'correlated',\n",
       "          'neuroscience', '계산', 'estimated', 'neural', 'factors', '발생',\n",
       "          'levels', 'level', 'findings', 'alzheimer', 'computational',\n",
       "          'effect', 'information', 'lead', 'factor', 'scientific', '회귀분석',\n",
       "          'dropout', '영향', 'estimates', 'result', 'normal', '변환', '결과', '수준',\n",
       "          'disorders', 'coefficients', 'datetime', 'dementia', 'disease'],\n",
       "         dtype='<U15'),\n",
       "   array([0.20103067, 0.1727393 , 0.17209278, 0.16767523, 0.16577327,\n",
       "          0.15396085, 0.12940428, 0.12021035, 0.11939175, 0.11900879,\n",
       "          0.11727469, 0.11721687, 0.11607324, 0.11542834, 0.11479288,\n",
       "          0.11470508, 0.11353573, 0.11284149, 0.1122952 , 0.11106516,\n",
       "          0.11101379, 0.10945607, 0.10895467, 0.10773549, 0.10650027,\n",
       "          0.10560401, 0.10543176, 0.10454878, 0.10329527, 0.10266918,\n",
       "          0.10250512, 0.10125833, 0.10057851, 0.09982927, 0.0996249 ,\n",
       "          0.0987798 , 0.09848765, 0.09663716, 0.09600655, 0.0958204 ,\n",
       "          0.09367306, 0.09288297, 0.09281148, 0.09226882, 0.0921637 ,\n",
       "          0.09187146, 0.09148196, 0.09139854, 0.09134276, 0.0912892 ],\n",
       "         dtype=float32))),\n",
       " (41,\n",
       "  (array(['correlations', 'correlation', 'covariance', 'correlated',\n",
       "          'relationship', '관계', 'pairs', 'relative', 'variance', 'related',\n",
       "          'genetic', 'twin', 'statistical', 'comparisons', '유전자',\n",
       "          'coefficients', 'pairwise', 'statistics', '관련', 'traits',\n",
       "          'associated', 'interactions', 'connectivity', 'interaction', '비교',\n",
       "          'similar', 'compare', 'shared', 'connections', 'consistent',\n",
       "          'dataset', 'together', 'models', 'regression', 'cognitive',\n",
       "          'differences', 'variables', '모델', 'groups', 'estimated',\n",
       "          'association', 'distributed', 'populations', 'distribution',\n",
       "          'estimate', 'compared', 'corresponding', 'connection', 'species',\n",
       "          'group'], dtype='<U15'),\n",
       "   array([0.28856215, 0.28703374, 0.2603192 , 0.25961643, 0.23030719,\n",
       "          0.2275226 , 0.22064233, 0.21878359, 0.19589865, 0.1898334 ,\n",
       "          0.1892298 , 0.18283193, 0.18123001, 0.1783566 , 0.17658725,\n",
       "          0.17535502, 0.17229916, 0.17067498, 0.16673449, 0.16607475,\n",
       "          0.16352008, 0.15639925, 0.15426892, 0.14952697, 0.14302394,\n",
       "          0.14258148, 0.14257583, 0.13968666, 0.12978141, 0.12932752,\n",
       "          0.12890619, 0.12779188, 0.12575841, 0.12571467, 0.12456879,\n",
       "          0.12390767, 0.12151597, 0.12124753, 0.11991651, 0.11925613,\n",
       "          0.11899136, 0.11888583, 0.11817913, 0.11747343, 0.11683473,\n",
       "          0.11448382, 0.11349502, 0.11277566, 0.11181295, 0.11124279],\n",
       "         dtype=float32))),\n",
       " (42,\n",
       "  (array(['email', 'postaladdress', 'neuroscience', 'scientists', 'address',\n",
       "          'scientific', 'science', 'electronic', '과학', 'interest', 'none',\n",
       "          'neurons', 'send', 'dopamine', 'neural', 'alzheimer',\n",
       "          'neuroimaging', 'magnetic', '교수', 'species', 'ants', '신경망',\n",
       "          'environmental', 'humans', 'cells', 'random', 'space', 'positive',\n",
       "          'nucleus', 'researchers', 'benefit', 'not', 'environment',\n",
       "          'effective', 'individuals', '아닌', 'don', 'psychology', 'message',\n",
       "          'note', 'particular', 'arrows', 'pdf', 'subjects', 'notes',\n",
       "          'specific', 'cell', '메소드', 'no', 'non'], dtype='<U15'),\n",
       "   array([0.32834366, 0.22658962, 0.2235829 , 0.2221094 , 0.214621  ,\n",
       "          0.20635188, 0.19319794, 0.18790784, 0.18666604, 0.18656048,\n",
       "          0.18634313, 0.17754006, 0.16503084, 0.15944012, 0.1567398 ,\n",
       "          0.1555702 , 0.15117949, 0.15113173, 0.15108341, 0.15106036,\n",
       "          0.14677979, 0.14639297, 0.1435255 , 0.14197004, 0.14189312,\n",
       "          0.14062971, 0.13995376, 0.13791823, 0.13748811, 0.13715911,\n",
       "          0.13595164, 0.13541251, 0.13536595, 0.1349518 , 0.1336376 ,\n",
       "          0.13246979, 0.13156724, 0.12978032, 0.12923282, 0.12873802,\n",
       "          0.12854065, 0.12837484, 0.12816949, 0.12747781, 0.1273304 ,\n",
       "          0.12715492, 0.12597351, 0.12570424, 0.1248173 , 0.12438875],\n",
       "         dtype=float32))),\n",
       " (43,\n",
       "  (array(['groups', 'activation', 'group', '효과', '영향', 'activity', 'items',\n",
       "          'activities', 'effects', '연구', '기능', 'neuroscience', 'researchers',\n",
       "          'interactions', 'neurons', 'factors', 'scientific', 'interaction',\n",
       "          'effect', 'functions', 'functional', 'negative', 'selection',\n",
       "          'article', '과학', 'role', 'neural', 'findings', 'interest',\n",
       "          'scientists', 'areas', 'feature', 'func', 'tool', 'arrows',\n",
       "          'science', 'tasks', 'tools', 'populations', 'extraction',\n",
       "          'benefit', 'neuroimaging', 'function', 'genetic', 'features',\n",
       "          '신경망', 'components', '파티션', 'movement', '부분'], dtype='<U15'),\n",
       "   array([0.18828088, 0.16122515, 0.16101298, 0.15116349, 0.15094775,\n",
       "          0.15022859, 0.14772278, 0.14579873, 0.14453489, 0.14322056,\n",
       "          0.1395835 , 0.13957775, 0.13925669, 0.13854887, 0.1326621 ,\n",
       "          0.13213742, 0.13126409, 0.12964015, 0.1260951 , 0.12353124,\n",
       "          0.12062286, 0.12023847, 0.11987426, 0.11978022, 0.11954379,\n",
       "          0.11827331, 0.11473413, 0.11252781, 0.11200297, 0.1118432 ,\n",
       "          0.11174839, 0.11154938, 0.10579436, 0.10542169, 0.10505594,\n",
       "          0.1034217 , 0.10312044, 0.10232374, 0.10159864, 0.1006725 ,\n",
       "          0.09932174, 0.09903914, 0.09895132, 0.09894855, 0.09865457,\n",
       "          0.09808123, 0.09784684, 0.0972156 , 0.09655523, 0.09497535],\n",
       "         dtype=float32))),\n",
       " (44,\n",
       "  (array(['correlation', 'correlations', 'correlated', 'statistical',\n",
       "          'groups', 'statistics', 'group', 'coefficients', '관계',\n",
       "          'relationship', 'regression', 'dataset', 'associated',\n",
       "          'distributed', 'comparisons', 'interaction', 'related', 'index',\n",
       "          '비교', '회귀분석', 'pairs', 'populations', 'relative', 'networks',\n",
       "          'compared', 'neurons', 'connectivity', 'scores', 'variance',\n",
       "          'neuroimaging', 'interactions', 'neural', '관련', 'covariance',\n",
       "          'distribution', 'individuals', 'primary', 'connections',\n",
       "          'psychology', 'average', '신경망', 'independent', 'population',\n",
       "          'computational', 'patterns', 'network', 'table', 'compare',\n",
       "          'individual', 'association'], dtype='<U15'),\n",
       "   array([0.21941198, 0.21893352, 0.21276003, 0.18178633, 0.16219859,\n",
       "          0.15770109, 0.15360211, 0.15176262, 0.14708005, 0.13033363,\n",
       "          0.12735331, 0.12259671, 0.1180525 , 0.11711387, 0.11650316,\n",
       "          0.11371997, 0.11231022, 0.1105796 , 0.1078103 , 0.10776181,\n",
       "          0.10660823, 0.10416566, 0.10386995, 0.10258845, 0.10190897,\n",
       "          0.10023254, 0.0996305 , 0.09905714, 0.098946  , 0.09824611,\n",
       "          0.09693156, 0.09683125, 0.09630804, 0.09566601, 0.09565389,\n",
       "          0.0912823 , 0.08899089, 0.08826691, 0.0865408 , 0.08626439,\n",
       "          0.08469189, 0.08455085, 0.08452318, 0.08358975, 0.08339866,\n",
       "          0.08338054, 0.08265334, 0.08263291, 0.08129207, 0.08122171],\n",
       "         dtype=float32))),\n",
       " (45,\n",
       "  (array(['tensorflow', 'files', '파일', 'mxpath', 'file', 'numpy', 'matlab',\n",
       "          '변환', 'bmatrix', 'format', 'dataset', 'convert', 'foldername',\n",
       "          'parameters', 'github', '인코딩', '변수', 'variable', 'mv', 'nii',\n",
       "          'encoding', 'variables', 'parameter', 'data', 'mxalgebra',\n",
       "          'python', 'import', 'linear', 'kwargs', 'path', 'mni', 'download',\n",
       "          'renaming', 'integers', 'paths', 'reg', 'gradient', '우분투', 'gb',\n",
       "          'mathrm', 'ftd', 'geom', 'measures', 'transform', '데이터', 'openmx',\n",
       "          'inputs', 'behavioural', 'input', 'nipype'], dtype='<U15'),\n",
       "   array([0.24236429, 0.21051618, 0.20577128, 0.20066604, 0.19415812,\n",
       "          0.18605599, 0.17895672, 0.15919684, 0.15585016, 0.15191744,\n",
       "          0.14847079, 0.147618  , 0.14392266, 0.14346868, 0.13942342,\n",
       "          0.1391663 , 0.13671759, 0.13665491, 0.1347778 , 0.13190584,\n",
       "          0.13166192, 0.13108796, 0.12884517, 0.12863463, 0.12408978,\n",
       "          0.12209867, 0.12091023, 0.11925662, 0.11924182, 0.11923637,\n",
       "          0.1180584 , 0.11649606, 0.11611468, 0.11433638, 0.1129273 ,\n",
       "          0.1128259 , 0.11074032, 0.11012824, 0.10825025, 0.10818388,\n",
       "          0.10784018, 0.10751387, 0.10749662, 0.10749544, 0.10732336,\n",
       "          0.10721454, 0.10719314, 0.10691323, 0.10639129, 0.1059259 ],\n",
       "         dtype=float32))),\n",
       " (46,\n",
       "  (array(['mask', 'mxpath', 'matlab', 'layers', 'fsl', 'algorithm',\n",
       "          'methods', 'numpy', 'layer', 'method', 'openmx', '메소드', 'several',\n",
       "          'bmatrix', 'multiple', 'dataset', 'textrm', 'parameters', 'many',\n",
       "          'multi', 'objects', 'processes', 'preprocessing', 'cortex',\n",
       "          'field', 'treatment', 'arxiv', 'areas', 'neural', 'subjects', '변수',\n",
       "          'parameter', 'tutorial', 'variables', 'various', 'basal',\n",
       "          'tensorflow', 'alzheimer', 'humans', 'analyses', 'diffusion',\n",
       "          'sigma', 'voxels', 'tasks', 'paths', 'few', 'measures',\n",
       "          'prefrontal', 'specific', 'encoding'], dtype='<U15'),\n",
       "   array([0.32172903, 0.20728755, 0.18464214, 0.17846218, 0.1702019 ,\n",
       "          0.16159578, 0.15928143, 0.14961618, 0.14608552, 0.13756217,\n",
       "          0.13422152, 0.13399178, 0.13070226, 0.12914902, 0.12491404,\n",
       "          0.12397495, 0.12293199, 0.12009553, 0.11936244, 0.11897664,\n",
       "          0.11850506, 0.11826367, 0.11818075, 0.11801339, 0.11496358,\n",
       "          0.1149027 , 0.11444142, 0.11151227, 0.11111727, 0.10893351,\n",
       "          0.10867929, 0.1076861 , 0.1030616 , 0.10263056, 0.10261807,\n",
       "          0.10242929, 0.10204487, 0.10175444, 0.1013765 , 0.10050356,\n",
       "          0.09887224, 0.09842549, 0.09787889, 0.09743269, 0.09709245,\n",
       "          0.09705065, 0.09683469, 0.09664824, 0.09645039, 0.096069  ],\n",
       "         dtype=float32))),\n",
       " (47,\n",
       "  (array(['cpu', 'linux', 'optimization', 'xorg', 'processes', 'ubuntu',\n",
       "          '메모리', 'kernel', '리눅스', 'performance', '부팅', '명령어', '프로세스', '명령',\n",
       "          'command', 'memory', 'process', 'computational', 'preprocessing',\n",
       "          'gpu', 'ctrl', 'script', 'localhost', '우분투', '윈도우', 'treatment',\n",
       "          '시스템', 'system', 'sudo', 'systems', 'processing', 'nvidia', 'gb',\n",
       "          'parameter', 'matlab', '처리', 'relative', 'features', 'primary',\n",
       "          'functions', 'renaming', 'directory', 'function', '기능', 'firefox',\n",
       "          'feature', 'windows', 'args', 'textrm', 'default'], dtype='<U15'),\n",
       "   array([0.2708577 , 0.2503894 , 0.23008236, 0.2250703 , 0.22084793,\n",
       "          0.21060899, 0.2104901 , 0.20426719, 0.20327982, 0.20163594,\n",
       "          0.19910368, 0.19282442, 0.19140153, 0.18741393, 0.17873412,\n",
       "          0.17261863, 0.17246556, 0.17200726, 0.16785176, 0.16343445,\n",
       "          0.15752909, 0.15392019, 0.14886855, 0.14836401, 0.14700717,\n",
       "          0.14390603, 0.14048585, 0.13726373, 0.13529298, 0.1349861 ,\n",
       "          0.13311781, 0.13296749, 0.12908608, 0.12826265, 0.12416886,\n",
       "          0.12391591, 0.12377702, 0.12373289, 0.1235016 , 0.12333941,\n",
       "          0.12098256, 0.12089565, 0.1208808 , 0.1202689 , 0.12013283,\n",
       "          0.11980729, 0.11949978, 0.11879156, 0.11876193, 0.11853431],\n",
       "         dtype=float32))),\n",
       " (48,\n",
       "  (array(['numpy', 'hypo', 'python', 'hippocampus', 'statistical',\n",
       "          'likelihood', 'estimated', 'sigma', 'dataset', 'coefficients',\n",
       "          'statistics', 'regression', 'variance', 'estimate', 'estimates',\n",
       "          'parameter', 'hippocampal', 'variables', '변수', 'int', 'def',\n",
       "          'parameters', 'values', '파이썬', 'function', 'data', 'variable',\n",
       "          'algorithm', 'assess', 'covariance', 'matlab', 'computational',\n",
       "          'predict', 'functions', 'model', 'conf', 'nipype', 'alzheimer',\n",
       "          'methods', 'fmriprep', 'random', 'method', 'integers', 'default',\n",
       "          'mathbf', 'correlations', 'similar', 'rate', 'approach', 'think'],\n",
       "         dtype='<U15'),\n",
       "   array([0.3230807 , 0.23256306, 0.23037842, 0.22515264, 0.21443026,\n",
       "          0.21406808, 0.20950483, 0.20655489, 0.19836038, 0.19832098,\n",
       "          0.19758694, 0.19218999, 0.18856108, 0.18672645, 0.18636644,\n",
       "          0.18613109, 0.18526405, 0.17754394, 0.17580144, 0.17527366,\n",
       "          0.1751377 , 0.17473584, 0.17466086, 0.17343503, 0.17335027,\n",
       "          0.17264453, 0.17248766, 0.17177588, 0.16957042, 0.16944021,\n",
       "          0.16782662, 0.16549201, 0.1651564 , 0.1645471 , 0.16237065,\n",
       "          0.1616902 , 0.16167066, 0.16077402, 0.1604644 , 0.160081  ,\n",
       "          0.15858178, 0.15839738, 0.15820602, 0.15764853, 0.15686397,\n",
       "          0.15613888, 0.15544093, 0.15511456, 0.15346065, 0.15272439],\n",
       "         dtype=float32))),\n",
       " (49,\n",
       "  (array(['mathbf', 'mathrm', 'computational', 'matlab', '계산',\n",
       "          'coefficients', '방정식', 'mxalgebra', 'linear', 'sum', 'statistics',\n",
       "          'integers', 'algorithm', 'vector', 'convex', 'bmatrix',\n",
       "          'statistical', 'sigma', 'square', 'matrix', 'estimated', '평면',\n",
       "          'angle', 'cos', '회귀분석', 'complex', '행렬', 'dataset', 'estimate',\n",
       "          'functions', 'relationship', 'solve', 'geom', 'sin', 'factor',\n",
       "          'regression', 'gradient', 'correlation', 'correlations', 'numpy',\n",
       "          'textrm', '벡터', 'derived', '관계', 'integration', 'estimates',\n",
       "          'account', 'software', 'representation', 'similar'], dtype='<U15'),\n",
       "   array([0.3985378 , 0.35855275, 0.27088928, 0.25657845, 0.23029591,\n",
       "          0.20551647, 0.18500033, 0.18260983, 0.18107627, 0.17988665,\n",
       "          0.17061785, 0.16986002, 0.16844499, 0.16369218, 0.16250907,\n",
       "          0.16037664, 0.15577252, 0.15260267, 0.15062009, 0.14534444,\n",
       "          0.1440576 , 0.14383814, 0.14348908, 0.13869295, 0.13851029,\n",
       "          0.13828337, 0.13612628, 0.13386892, 0.13323319, 0.12978117,\n",
       "          0.12866524, 0.12653801, 0.12528871, 0.12417477, 0.12314761,\n",
       "          0.12290388, 0.12240374, 0.12153082, 0.12129854, 0.12078866,\n",
       "          0.11983299, 0.11971851, 0.11920868, 0.11884487, 0.11842446,\n",
       "          0.11829685, 0.11778152, 0.11525995, 0.11516404, 0.11473812],\n",
       "         dtype=float32))),\n",
       " (50,\n",
       "  (array(['apk', 'android', '우분투', '파일', 'jar', 'app', 'github', 'file',\n",
       "          'files', '코드', 'shared', 'localhost', 'component', 'lib', 'ubuntu',\n",
       "          'vtk', 'application', 'similar', 'kernel', 'school', 'port',\n",
       "          'tutorial', '실행', 'integration', 'mozilla', 'instance', 'install',\n",
       "          'installing', 'ip', 'url', '설치', 'covariance', 'foldername',\n",
       "          'source', 'class', 'mixture', 'sudo', '구글', 'linux', 'code', 'cp',\n",
       "          'path', 'coding', 'prison', 'extraction', 'method', 'encoding',\n",
       "          '과정', 'safari', 'version'], dtype='<U15'),\n",
       "   array([0.43755174, 0.24147682, 0.21304542, 0.1902074 , 0.18312329,\n",
       "          0.17946891, 0.17799559, 0.17373526, 0.17359486, 0.16317962,\n",
       "          0.16234078, 0.15460521, 0.14817564, 0.14619876, 0.14534132,\n",
       "          0.14015156, 0.13793807, 0.13409957, 0.1313061 , 0.13101564,\n",
       "          0.13061388, 0.12768091, 0.12730242, 0.12550886, 0.12281831,\n",
       "          0.12204836, 0.12203503, 0.12092451, 0.12031294, 0.11732398,\n",
       "          0.11638729, 0.11372039, 0.1136582 , 0.11346509, 0.110663  ,\n",
       "          0.11065726, 0.11014429, 0.10914011, 0.10849786, 0.10823388,\n",
       "          0.10767609, 0.10739632, 0.10718105, 0.10512706, 0.10490452,\n",
       "          0.10471882, 0.10418397, 0.10378202, 0.10372191, 0.10312122],\n",
       "         dtype=float32))),\n",
       " (51,\n",
       "  (array(['covariance', 'selection', 'populations', 'variance', '유전자',\n",
       "          'genetic', 'statistical', 'correlation', 'correlations',\n",
       "          'individual', 'traits', 'correlated', 'independent', 'statistics',\n",
       "          'variables', 'distributed', 'select', 'population', 'individuals',\n",
       "          'separate', 'interaction', 'species', '선택', 'differences', '변수',\n",
       "          'interactions', 'choice', 'distribution', 'dataset', 'regression',\n",
       "          'groups', 'variable', 'sample', 'psychology', 'samples',\n",
       "          'behavioural', 'behaviors', 'environment', 'dependent', 'relative',\n",
       "          'behavior', 'nature', '영향', 'preference', 'factors', '결과',\n",
       "          'experiment', 'behavioral', 'options', 'findings'], dtype='<U15'),\n",
       "   array([0.17772509, 0.1717753 , 0.16745567, 0.16609815, 0.15330198,\n",
       "          0.14904672, 0.14664212, 0.14074242, 0.14073955, 0.13908969,\n",
       "          0.13310349, 0.12820354, 0.12397364, 0.11746633, 0.11702639,\n",
       "          0.11628389, 0.11538057, 0.11520082, 0.1147427 , 0.11234517,\n",
       "          0.11016588, 0.10980197, 0.10822723, 0.1062208 , 0.10534138,\n",
       "          0.10203513, 0.10003133, 0.09983277, 0.09613454, 0.09560164,\n",
       "          0.0915718 , 0.09123372, 0.0908482 , 0.09014592, 0.08994669,\n",
       "          0.08742058, 0.08724961, 0.0861952 , 0.08514375, 0.08212171,\n",
       "          0.08021156, 0.0794726 , 0.07902078, 0.07881522, 0.07873805,\n",
       "          0.07866225, 0.07713387, 0.0747108 , 0.07160358, 0.07026172],\n",
       "         dtype=float32)))]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(topic_nums, zip(topic_words,word_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "id": "3oOUN0ccNzYB",
    "outputId": "9caf6fa7-20ee-4946-8e0d-e9dd5111fcbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_num: 19, The number of Document: 9\n",
      "['neuroscience' 'neurons' 'neural' 'neuroimaging' 'brain' '신경망' 'cerebral'\n",
      " 'midbrain' 'cognitive' 'memory' '메모리' 'nucleus' 'alzheimer' 'mental'\n",
      " 'computational' 'psychology' 'intelligence' 'hippocampus' 'mind'\n",
      " 'scientific' 'scientists' 'concepts' 'temporal' '과학' 'computer' 'science'\n",
      " 'researchers' 'theoretical' 'cortex' 'coefficients' 'dementia'\n",
      " 'selection' 'cells' 'humans' 'disorders' 'ability' 'correlated' 'studies'\n",
      " 'mice' 'functions' 'dopamine' 'theory' '계산' '연구' 'clinical' 'groups' '시간'\n",
      " 'symptoms' '개념' 'module'] \n",
      "\n",
      "Document: 161, Score: 0.8514077067375183, URL: https://www.ncbi.nlm.nih.gov/pubmed/28465167/\n",
      "the neural basis of delay discounting : a review and preliminary model . the phenomenology of delay discounting ( e . g . shape of the discount function ; relation to mental health ) has been reviewed in detail previously , but not its neural substrates . its neuropsychology is crucial for both theory and clinical practice . so , here , we review the neural underpinnings of delay discounting . we introduce its objective summary measures ; provide an atheoretical summary of current findings - linking brain regions to each objectively measurable variable ; and then provide a preliminary five - stage summary model of cognitive processing ; followed by a mapping of parameters to the flow of information through neural systems . the whole is designed to stimulate future research on the roles of each brain region in delay discounting . delay and payoff produce activity in many brain areas : thalamus ; sensory , parietal , temporal , cingulate , prefrontal , motor , and insular cortex ; and basal ganglia . delay discounting , then , appears to emerge from the interaction of neural systems as they process streams of events in recurrent loops and not to be a simple calculation carried out in a single center in the brain .\n",
      "\n",
      "Document: 388, Score: 0.8123074769973755, URL: https://science.sciencemag.org/content/354/6317/1273.abstract\n",
      "midbrain dopamine neurons control judgment of time . time is a subjective experience time , like space , is one of the fundamental dimensions of all our experiences . however , organisms do not work like clocks , and our judgment about the passage of time is variable , depending on circumstances . soares et al . systematically investigated midbrain dopaminergic neurons during timing behavior in mice ( see the perspective by simen and matell ) . when measuring and manipulating mouse activity , the authors observed that dopaminergic neurons controlled temporal judgments on a time scale of seconds . science , this issue p . 1 2 7 3 ; see also p . 1 2 3 1\n",
      "\n",
      "Document: 183, Score: 0.8096346855163574, URL: https://www.nature.com/articles/d41586-018-00107-4\n",
      "chen is among a growing number of researchers using brain imaging to identify the activity patterns involved in creating and recalling a specific memory . in 2 0 0 9 , she and her team boosted the level of a key memory protein called creb in some cells in the amygdala ( an area involved in processing fear ) , and showed that those neurons were especially likely to fire when mice learnt , and later recalled , a fearful association between an auditory tone and foot shocks . in a follow - up study , tonegawa ’ s team placed mice in a new cage and delivered foot shocks , while at the same time re - activating neurons that formed the engram of a ‘ safe ’ cage . in the case of chen ’ s sherlock studies , her group found that patterns of brain activity across 5 0 scenes of the opening episode could be clearly distinguished from one another . clustering related memories could also help people use prior knowledge to learn new things , according to research by neuroscientist alison preston at the university of texas at austin . in a 2 0 1 2 study , preston ’ s group found that when some people view one pair of images ( such as a basketball and a horse ) , and later see another pair ( such as a horse and a lake ) that shares a common item , their brains reactivate the pattern associated with the first pair 12 .\n",
      "\n",
      "Document: 227, Score: 0.7900047302246094, URL: https://www.frontiersin.org/articles/10.3389/fnhum.2014.00546/full\n",
      "we then elaborate our ‘ herstory ’ in section concepts , knowledge productions , and reflective approaches of feminist neurosciences by summarizing findings of recent critical research on sex / gender and the brain . we incorporate different perspectives of neuroscientific epistemologies that highlight plasticity concepts in particular in order to gain a more differentiated view on brain - behavior development in gendered socio - cultural experiences and contexts . finally , and with respect to the conceptual background of neuroscientific research , a differentiated understanding of sex / gender and the brain was developed in the context of plasticity concepts in the neurosciences , the history of which spans more than 5 0 years , beginning with the first notions of structural changes in synaptic connections , developed in animal studies in the 1 9 6 0 s ( rosenzweig et al . , 2 0 1 2 , the special issue on neuroscience and sex / gender edited by dussauge and kaiser , 2 0 1 2 b , and the anthology on gendered neurocultures : feminist and queer perspectives on current brain discourses edited by schmitz and höppner , 2 0 1 4 ) . from feminist and queer perspectives , they reflect the influences of gendered and intersected norms and values in brain research and brain imaging procedures and , conversely , research the impacts of neuroscientific knowledge production on processes of normalization ( dussauge , 2 0 1 4 ; fitsch , 2 0 1 4 ; kaiser , 2 0 1 4 ; kuria , 2 0 1 4 ) .\n",
      "\n",
      "Document: 204, Score: 0.716682493686676, URL: https://www.scientificamerican.com/article/does-the-adult-brain-really-grow-new-neurons/\n",
      "in a direct challenge to earlier studies , the authors report adults produce no new cells in the hippocampus , a key hub for processing memories . the study signals the latest volley in a debate over whether and to what extent the human brain produces new cells in adulthood . emerging techniques for labeling dividing cells revealed the birth of new neurons — a process called neurogenesis — in parts of the adult rat brain . and in a 1 9 9 8 landmark study researchers reported the phenomenon in the adult human hippocampus . another major study in 2 0 1 3 corroborated those findings , estimating that about 1 , 400 hippocampal neurons are made daily in adult brains . “ we went into the hippocampus expecting to see many young neurons , ” says senior author arturo alvarez - buylla , a neuroscientist at the university of california , san francisco . in adult samples the researchers found no new neurons . “ this paper not only shows very convincing evidence of a lack of neurogenesis in the adult human hippocampus but also shows that some of the evidence presented by other studies was not conclusive , ” he says . ” goldman has had his doubts since the early 2 0 0 0 s , when his group isolated neural precursor cells from the adult human brain . goldman believes the latest study will help temper runaway expectations adult neurogenesis can be leveraged to treat patients ’ memory or mood disorders .\n",
      "\n",
      "Document: 168, Score: 0.7018033266067505, URL: https://www.scientificamerican.com/article/nice-brains-finish-last/\n",
      "a new study published in nature human behavior suggests that those who value economic equity , at their brain ’ s core , are more likely to be depressed . masahiko haruno suggested in nature neuroscience that primal brain structures like the amygdala “ lie at the core of prosocial orientation . ” his research group found that , when exposed to economic inequity , prosocials have strong activation of the amygdala , an evolutionally ancient region of the brain associated with automatic feelings of stress . haruno ’ s group took on the question of whether this pro - social pattern of brain activation correlated with longer - term clinical symptoms of depression . an additional finding in this study was that the hippocampus , another primitive brain region involved with automatic stress responses , also showed a different pattern of activity between pro - socials and individualists . haruno ’ s group found that having a prosocial pattern of brain activation was associated with more depression . although the average pro - social may have a sensitive amygdala ( and hippocampus , the other primal stress related brain region in the study ) , there are plenty of other higher - order brain regions involved in depression , including the prefrontal cortex , a brain region associated with regulation of these automatic feelings , delgado says . but by training higher - level brain processes like the pre - frontal cortex , pro - socials can learn to control these emotions and fight depression .\n",
      "\n",
      "Document: 369, Score: 0.6323771476745605, URL: https://ruccs.rutgers.edu/cdll\n",
      "i moved because of its support for cross - discipline work and the strength of the rutgers center for cognitive science ( ruccs ) . i have developed ways to uncover and study the ease with which young children acquire intuitive understandings of natural number and arithmetic , that different sources of energy support the movement and change over time about separably moveable animate and inanimate objects , that outcomes have causes , learn words and conversational ly appropriate ways of talking . a second major theme is dedicated to describing the difficulties that humans have learning about the nature of rational numbers , algebra , mechanics , biology and so on . on the theoretical side my effort is dedicated to the task of developing the kind of theory of learning that accommodates both the early learnings that occurs on the fly and the later learning that requires effort and a protracted period of time . the theoretical task is two - fold : to spell out how new mental structures are acquired and to achieve a theory of environment that that supports such learning . ongoing research in my lab includes studies of both verbal and nonverbal representations of number and arithmetic . i also have students and collaborators studying the development course of learning about quantifiers and numerals ; counting systems in different culture ; and the nature of inputs for learning verbs . finally , a group of us are developing a research agenda for studying dyscalculia .\n",
      "\n",
      "Document: 351, Score: 0.5729383230209351, URL: https://www.technologyreview.com/s/421505/tracking-the-brains-ability-to-bluff/\n",
      "read montague , a neuroscientist at baylor college of medicine , uses a combination of brain imaging and interactive games to explore this skill , with the long - term goal of developing new diagnostic tests for psychiatric disorders . ” in a study published today , montague and collaborators found that people take one of three strategies when playing a simple economics game , and that specific parts of the brain seem to be more active in people who choose to bluff . a second paper published last month shows how the strategies chosen by healthy people playing a similar game change depending on the mental status of their opponent . “ the capacity that breaks down the most in mental illness is ‘ social software , ’ such as the ability to pick up signals from people in groups and to collaborate , ” says montague . ” montague and others in the field of neuroeconomics — a relatively young branch of neuroscience that explores how the brain makes decisions — assess how people make choices by asking them to play interactive games . researchers had pairs of people play a simple trust game in which one player , the “ investor , ” gave a certain amount of money to the investee . ” montague , in collaboration with fonagy , now plans to test this approach on a much greater number of people , with the intention of refining the ability to classify them as either healthy or suffering from a psychiatric disorder .\n",
      "\n",
      "Document: 277, Score: 0.5173431038856506, URL: https://www.inverse.com/article/53065-can-bees-do-math-wtf\n",
      "in the paper , published wednesday in science advances , researchers described how they used color - coded shapes to train 1 4 honeybees to do simple arithmetic , as the video above details . rmit university of course , these honeybees didn ’ t solve math problems like we do , with the questions written out in numerals with plus and minus symbols between them . the researchers write that these results are exciting because arithmetic is a complex cognitive process , requiring the bees to use both long - term memory to remember rules and short - term working memory to deal with the figures in front of them . scientists trained bees to do addition ( bottom ) and subtraction ( top ) based on the color of shapes . while math itself may not be crucial to bees ’ survival , they write , the simultaneous use of long - and short - term memory has an evolutionary purpose when it comes to tasks like remembering the size , shape , and petal arrangement of flowers that are more nutritious . “ this important step in combining the arithmetic and symbolic learning abilities of an insect has identified numerous new areas for future research and also poses the question of whether these complex numeric understandings may be accessible to other species without large brains , such as the honeybee , ” the authors write . we show that honeybees , with a miniature brain , can learn to use blue and yellow as symbolic representations for addition or subtraction .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_num = 19\n",
    "num_docs = tm_model.get_topic_sizes()[0][topic_num]\n",
    " \n",
    "documents, document_scores, document_ids = tm_model.search_documents_by_topic(topic_num=topic_num, num_docs=num_docs)\n",
    "print(f\"topic_num: {topic_num}, The number of Document: {num_docs}\")\n",
    "print(topic_words[topic_num], '\\n')\n",
    "\n",
    "for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
    "    print(f\"Document: {doc_id}, Score: {score}, URL: {docs_info_prep_df['url'][doc_id]}\")\n",
    "    print(doc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(161,\n",
       "  'the neural basis of delay discounting : a review and preliminary model . the phenomenology of delay discounting ( e . g . shape of the discount function ; relation to mental health ) has been reviewed in detail previously , but not its neural substrates . its neuropsychology is crucial for both theory and clinical practice . so , here , we review the neural underpinnings of delay discounting . we introduce its objective summary measures ; provide an atheoretical summary of current findings - linking brain regions to each objectively measurable variable ; and then provide a preliminary five - stage summary model of cognitive processing ; followed by a mapping of parameters to the flow of information through neural systems . the whole is designed to stimulate future research on the roles of each brain region in delay discounting . delay and payoff produce activity in many brain areas : thalamus ; sensory , parietal , temporal , cingulate , prefrontal , motor , and insular cortex ; and basal ganglia . delay discounting , then , appears to emerge from the interaction of neural systems as they process streams of events in recurrent loops and not to be a simple calculation carried out in a single center in the brain .'),\n",
       " (388,\n",
       "  'midbrain dopamine neurons control judgment of time . time is a subjective experience time , like space , is one of the fundamental dimensions of all our experiences . however , organisms do not work like clocks , and our judgment about the passage of time is variable , depending on circumstances . soares et al . systematically investigated midbrain dopaminergic neurons during timing behavior in mice ( see the perspective by simen and matell ) . when measuring and manipulating mouse activity , the authors observed that dopaminergic neurons controlled temporal judgments on a time scale of seconds . science , this issue p . 1 2 7 3 ; see also p . 1 2 3 1'),\n",
       " (183,\n",
       "  'chen is among a growing number of researchers using brain imaging to identify the activity patterns involved in creating and recalling a specific memory . in 2 0 0 9 , she and her team boosted the level of a key memory protein called creb in some cells in the amygdala ( an area involved in processing fear ) , and showed that those neurons were especially likely to fire when mice learnt , and later recalled , a fearful association between an auditory tone and foot shocks . in a follow - up study , tonegawa ’ s team placed mice in a new cage and delivered foot shocks , while at the same time re - activating neurons that formed the engram of a ‘ safe ’ cage . in the case of chen ’ s sherlock studies , her group found that patterns of brain activity across 5 0 scenes of the opening episode could be clearly distinguished from one another . clustering related memories could also help people use prior knowledge to learn new things , according to research by neuroscientist alison preston at the university of texas at austin . in a 2 0 1 2 study , preston ’ s group found that when some people view one pair of images ( such as a basketball and a horse ) , and later see another pair ( such as a horse and a lake ) that shares a common item , their brains reactivate the pattern associated with the first pair 12 .'),\n",
       " (227,\n",
       "  'we then elaborate our ‘ herstory ’ in section concepts , knowledge productions , and reflective approaches of feminist neurosciences by summarizing findings of recent critical research on sex / gender and the brain . we incorporate different perspectives of neuroscientific epistemologies that highlight plasticity concepts in particular in order to gain a more differentiated view on brain - behavior development in gendered socio - cultural experiences and contexts . finally , and with respect to the conceptual background of neuroscientific research , a differentiated understanding of sex / gender and the brain was developed in the context of plasticity concepts in the neurosciences , the history of which spans more than 5 0 years , beginning with the first notions of structural changes in synaptic connections , developed in animal studies in the 1 9 6 0 s ( rosenzweig et al . , 2 0 1 2 , the special issue on neuroscience and sex / gender edited by dussauge and kaiser , 2 0 1 2 b , and the anthology on gendered neurocultures : feminist and queer perspectives on current brain discourses edited by schmitz and höppner , 2 0 1 4 ) . from feminist and queer perspectives , they reflect the influences of gendered and intersected norms and values in brain research and brain imaging procedures and , conversely , research the impacts of neuroscientific knowledge production on processes of normalization ( dussauge , 2 0 1 4 ; fitsch , 2 0 1 4 ; kaiser , 2 0 1 4 ; kuria , 2 0 1 4 ) .'),\n",
       " (204,\n",
       "  'in a direct challenge to earlier studies , the authors report adults produce no new cells in the hippocampus , a key hub for processing memories . the study signals the latest volley in a debate over whether and to what extent the human brain produces new cells in adulthood . emerging techniques for labeling dividing cells revealed the birth of new neurons — a process called neurogenesis — in parts of the adult rat brain . and in a 1 9 9 8 landmark study researchers reported the phenomenon in the adult human hippocampus . another major study in 2 0 1 3 corroborated those findings , estimating that about 1 , 400 hippocampal neurons are made daily in adult brains . “ we went into the hippocampus expecting to see many young neurons , ” says senior author arturo alvarez - buylla , a neuroscientist at the university of california , san francisco . in adult samples the researchers found no new neurons . “ this paper not only shows very convincing evidence of a lack of neurogenesis in the adult human hippocampus but also shows that some of the evidence presented by other studies was not conclusive , ” he says . ” goldman has had his doubts since the early 2 0 0 0 s , when his group isolated neural precursor cells from the adult human brain . goldman believes the latest study will help temper runaway expectations adult neurogenesis can be leveraged to treat patients ’ memory or mood disorders .'),\n",
       " (168,\n",
       "  'a new study published in nature human behavior suggests that those who value economic equity , at their brain ’ s core , are more likely to be depressed . masahiko haruno suggested in nature neuroscience that primal brain structures like the amygdala “ lie at the core of prosocial orientation . ” his research group found that , when exposed to economic inequity , prosocials have strong activation of the amygdala , an evolutionally ancient region of the brain associated with automatic feelings of stress . haruno ’ s group took on the question of whether this pro - social pattern of brain activation correlated with longer - term clinical symptoms of depression . an additional finding in this study was that the hippocampus , another primitive brain region involved with automatic stress responses , also showed a different pattern of activity between pro - socials and individualists . haruno ’ s group found that having a prosocial pattern of brain activation was associated with more depression . although the average pro - social may have a sensitive amygdala ( and hippocampus , the other primal stress related brain region in the study ) , there are plenty of other higher - order brain regions involved in depression , including the prefrontal cortex , a brain region associated with regulation of these automatic feelings , delgado says . but by training higher - level brain processes like the pre - frontal cortex , pro - socials can learn to control these emotions and fight depression .'),\n",
       " (369,\n",
       "  'i moved because of its support for cross - discipline work and the strength of the rutgers center for cognitive science ( ruccs ) . i have developed ways to uncover and study the ease with which young children acquire intuitive understandings of natural number and arithmetic , that different sources of energy support the movement and change over time about separably moveable animate and inanimate objects , that outcomes have causes , learn words and conversational ly appropriate ways of talking . a second major theme is dedicated to describing the difficulties that humans have learning about the nature of rational numbers , algebra , mechanics , biology and so on . on the theoretical side my effort is dedicated to the task of developing the kind of theory of learning that accommodates both the early learnings that occurs on the fly and the later learning that requires effort and a protracted period of time . the theoretical task is two - fold : to spell out how new mental structures are acquired and to achieve a theory of environment that that supports such learning . ongoing research in my lab includes studies of both verbal and nonverbal representations of number and arithmetic . i also have students and collaborators studying the development course of learning about quantifiers and numerals ; counting systems in different culture ; and the nature of inputs for learning verbs . finally , a group of us are developing a research agenda for studying dyscalculia .'),\n",
       " (351,\n",
       "  'read montague , a neuroscientist at baylor college of medicine , uses a combination of brain imaging and interactive games to explore this skill , with the long - term goal of developing new diagnostic tests for psychiatric disorders . ” in a study published today , montague and collaborators found that people take one of three strategies when playing a simple economics game , and that specific parts of the brain seem to be more active in people who choose to bluff . a second paper published last month shows how the strategies chosen by healthy people playing a similar game change depending on the mental status of their opponent . “ the capacity that breaks down the most in mental illness is ‘ social software , ’ such as the ability to pick up signals from people in groups and to collaborate , ” says montague . ” montague and others in the field of neuroeconomics — a relatively young branch of neuroscience that explores how the brain makes decisions — assess how people make choices by asking them to play interactive games . researchers had pairs of people play a simple trust game in which one player , the “ investor , ” gave a certain amount of money to the investee . ” montague , in collaboration with fonagy , now plans to test this approach on a much greater number of people , with the intention of refining the ability to classify them as either healthy or suffering from a psychiatric disorder .'),\n",
       " (277,\n",
       "  'in the paper , published wednesday in science advances , researchers described how they used color - coded shapes to train 1 4 honeybees to do simple arithmetic , as the video above details . rmit university of course , these honeybees didn ’ t solve math problems like we do , with the questions written out in numerals with plus and minus symbols between them . the researchers write that these results are exciting because arithmetic is a complex cognitive process , requiring the bees to use both long - term memory to remember rules and short - term working memory to deal with the figures in front of them . scientists trained bees to do addition ( bottom ) and subtraction ( top ) based on the color of shapes . while math itself may not be crucial to bees ’ survival , they write , the simultaneous use of long - and short - term memory has an evolutionary purpose when it comes to tasks like remembering the size , shape , and petal arrangement of flowers that are more nutritious . “ this important step in combining the arithmetic and symbolic learning abilities of an insect has identified numerous new areas for future research and also poses the question of whether these complex numeric understandings may be accessible to other species without large brains , such as the honeybee , ” the authors write . we show that honeybees , with a miniature brain , can learn to use blue and yellow as symbolic representations for addition or subtraction .')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 83, 123, 125, 313,  86, 195, 349, 258, 191, 203])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문서 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"\"\n",
    "doc_info = crawling(url)\n",
    "doc_info['content'] = preprocessing(doc_info['content'])\n",
    "\n",
    "tm_model.add_documents([doc_info['content']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"제 가 오랫동안 업데이트 를 하 지 않 았 네요 . 2020 . 01 . 21 . 업데이트 노트 지금 16 , 18 버전 이 나온 상황 에서 가장 좋 은 방법 은 루트 경로 ( '/') 에 50 gb 정도 를 파티션 분할 하 시 고 , 나머지 세부 적 인 파티션 은 안 잡 고 루트 에 우분 트 설치 하 는 것 이 나중 에 문제 가 발생 하 지 않 는 것 같 습니다 . 제 가 쓰 는 건 ubuntu 14 . 04 . 4 lts 버전 입니다 . 특별히 다른 이유 가 있 지 않 는 한 반드시 x 86 , amd 64 , intel 64 시스템 의 경우 다음 과 같 은 파티션 을 생성 하 는 것 이 좋 습니다 : swap 파티션 ( 일반 적 으로 메모리 의 1 ~ 2 배 정도 ) / boot 파티션 ( 1 gb ) / 파티션 ( 30 gb ~ 50 gb 이상 하 시 길 바랍니다 . ) / home 파티션 ( 나머지 용량 의 대부분 ) 제 가 실제 ubuntu install 과정 에서 나눈 파티션 ( 2 tb 기준 ) 순서 대로 파티션 생성 하 시 길 권장 합니다 . swap - 32 gb ( 주 파티션 , 스왑 ) 스왑 파티션 은 가상 메모리 를 지원 하 는 데 사용 됩니다 . 즉 , 시스템 이 처리 하 는 데이터 를 저장 할 ram 이 충분 하 지 않 을 때 스왑 파티션 에 자료 가 기록 됩니다 . 저희 랩 실에 ddr 4 16 gb 쓰 고 있 기 때문 에 32 gb 로 설정 해 줬 습니다 . / - 50 gb ( 주 파티션 , ex 4 ) 저희 연구실 특성 상 linux 에 install 할 프로그램 이 많 아서 / 파티션 의 용량 을 크 게 잡 았 습니다 . 50 gb 정도 로 잡 았 는데 지금 실제 사용량 이 16 gb 입니다 . 용량 이 넉넉 하 다면 30 ~ 50 gb 정도 잡 아 주 시 면 될 것 같 습니다 . / boot - 1 gb ( 주 파티션 , ex 4 ) boot 할 때 필요 한 파일 들 이 있 는 곳 입니다 . 저희 랩 실 컴 에서 실제 사용량 은 100 mb 내외 입니다 . 여기 파티션 이 작 아야 부팅 할 때 컴퓨터 가 탐색 해야 될 부분 이 작아지 고 부팅 이 빨라 지 게 됩니다 . / var - 5 gb ( 논리 파티션 , ex 4 ) / tmp - 5 gb ( 논리 파티션 , ex 4 ) 파티션 나누 는 것 을 추천 합니다 . 2010 년 쯤 에 tmp 가 파티션 으로 따로 지정 되 어 있 지 않 다면 일반 user 가 tmp 에 들어가 서 root 권한 을 획득 할 수 있 다는 보안 의 취약점 이 발견 되 었 습니다 . 파티션 나누 는 것 으로 막 을 수 있 다고 합니다 . / database - 150 gb ( 논리 파티션 , ex 4 ) 개인 적 인 필요 에 의해 만든 것 입니다 . / home - 나머지 1 . 8 tb 이상 ( 논리 파티션 , ex 4 ) 여기 에 계정 들 을 위치 시켜서 유저 들 공간 으로 만들 었 습니다 . 주 파티션 과 논리 파티션 은 개념 이 조금 복잡 합니다 . 우리 가 쓰 고 있 는 하드 디스크 는 아무리 파티션 을 많이 나눠 봐야 4 개 까지 밖 에 나눠 지 지 않 습니다 . 그래서 4 개 이상 의 파티션 을 만들 기 위해서 도입 한 것 이 논리 파티션 입니다 . 더 자세 한 내용 을 쓰 고 싶 지만 제 지식 이 짧 아서 . . 궁금 하 신 분 들 은 더 찾아보 시 길 바랍니다 . 16 . 04 버전 으로 넘어가 면서 커널 을 업데이트 할 때 , boot 용량 이 많이 필요 하 네요 . . 500 mb 에서 1 gb 로 수정 합니다 . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ========================= reference : [ URL ]\",\n",
       "       '무엇 보다 나 를 알 아 가 는 길 북 클럽 오리진 이 함께 합니다 세상 을 탐구 하 고 타인 을 이해 하 며 북 클럽 오리진 의 [ 미니 북 ] 은 손바닥 안 의 책 한 권 입니다 . 화제 의 저자 인터뷰 를 비롯 한 긴 호흡 의 글 을 전합니다 . 오늘 은 \\' 얼굴 없 는 작가 \\' 로 유명 한 엘레나 페란테 인터뷰 입니다 . 최근 국내 에 도 완역 된 세계 적 인 베스트셀러 < 나폴리 4 부작 > 의 저자 입니다 . < 나폴리 4 부작 > 은 이탈리아 나폴리 를 배경 으로 두 여성 의 유년 시절 부터 노년 에 이르 기 까지 우정 과 인생 사 를 담 은 대하 소설 입니다 . 1 권 < 나 의 눈부신 친구 > 출간 직후 부터 세계 유수 의 언론 들 로부터 폭발 적 인 관심 과 찬사 를 받 기 시작 한 엘레나 페란테 는 \\' 얼굴 없 는 작가 \\' 로 도 화제 가 돼 왔 습니다 . 4 부작 의 마지막 편인 < 잃어버린 아이 이야기 > 는 2016 년 소설가 한 강의 < 채식주의자 > 가 영국 의 맨 부커 인터내셔널 상 을 수상 했 을 때 최종 후보 로 경합 했 습니다 . 오직 작품 으로 만 자신 을 말 하 겠 다는 뜻 을 밝힌 페란테 는 1992 년 데뷔 이후 , 단 한 번 도 대중 앞 에 모습 을 드러낸 적 도 자신 의 신원 을 밝힌 적 도 없 습니다 . 나폴리 태생 으로 고전 문학 을 전공 한 뒤 해외 에서 오랫동안 지낸 작가 라는 사실 정도 만 알려져 있 습니다 . 자신 의 글 과 출판사 의 전언 을 통해서 만 간간히 소통 해 왔 을 뿐 입니다 . < 나폴리 4 부작 > 의 국내 완역 출간 에 맞춰 출판사 인 한길사 를 통해 저자 에게 이메일 인터뷰 질문 을 보냈 고 저자 는 해 를 넘긴 끝 에 답변 을 보내왔 습니다 . 작품 이면 의 생각 을 읽 을 수 있 는 드문 기회 입니다 . 질문 을 이탈 리어 로 옮기 고 답변 을 우리 말 로 옮기 는 과정 에서 < 나폴리 4 부작 > 의 번역자 이 기 도 한 김지우 번역가 의 도움 을 받 았 습니다 . -< 나폴리 4 부작 > 이 2011 년 부터 매년 한 권 씩 출간 됐 지요 . 지금 까지 몇 개국 에 번역 됐 나요 ? 요즘 도 인터뷰 나 취재 요청 이 많이 들어오 나요 ? 네 , 요즘 도 인터뷰 와 취재 요청 을 많이 받 고 있 습니다 . < 나폴리 4 부작 > 이 지금 도 세계 여러 나라 에서 출간 되 고 있 으니까요 . 현재 전 세계 주요 언어 로 는 거의 다 번역 이 됐 다고 알 고 있 습니다 . -< 나폴리 4 부작 > 은 주인공 인 릴라 와 레누 , 두 여성 을 중심 으로 어린 시절 부터 노년 에 이르 기 까지 이야기 를 세밀 하 게 다뤘 습니다 . 마치 오랫동안 꼼꼼히 써둔 기록 을 모아서 작품 화 한 것 같 습니다 . 한 인터뷰 에서 는 원래 다른 책 의 이야기 에서 점점 발전 된 것 이 라고 밝혔 더군요 . 작품 을 구상 하 거나 집필 하 게 된 과정 을 들려 주 실 수 있 나요 ? 쉽 게 답변 드릴 수 있 는 질문 은 아니 군요 . 이야기 의 기원 으로 보 자면 아마도 저 의 친한 친구 의 죽음 이 있 었 던 것 같 습니다 . 또 언젠가 제 가 나폴리 에서 참석 했 던 성대 한 결혼식 에서 도 영감 을 받 았 습니다 . 여기 에 저 의 전작 인 < 어둠 의 딸 > 에서 다룬 주제 를 다시 다뤄 보 고 싶 은 생각 도 있 었 습니다 . 초고 는 정신없이 1 년 만 에 써내려갔 습니다 . 그때 까지 만 해도 분량 은 많 아도 이야기 를 책 한 권 에 다 담 을 수 있 을 거 라고 생각 했 습니다 . 하지만 퇴고 를 하 면서 이야기 가 확장 되 는 것 을 느꼈 습니다 . 편집자 들 과 함께 고민 한 끝 에 책 을 한 권 이상 으로 나눠서 출간 하 기 로 결정 했 습니다 . - 소설 은 한 번 쓰 고 나 면 저자 와 는 독립 적 인 것 이 되 어 스스로 독자 를 찾아가 기 마련 이 라고 말씀 하 신 적 이 있 지요 . 이제 한국 에서 도 전 4 권 이 다 완역 되 어 독자 를 만나 게 되 었 습니다 . 한국 에 대해서 는 얼마나 아 시 는지요 ? 소감 이 어떠신가요 ? 저 는 번역가 들 에 대한 존경심 을 가지 고 있 습니다 . 번역가 는 국가 간 의 경계 를 허무 는 일 을 합니다 . 제 소설 의 화자 인 레누 가 친구 릴라 의 이야기 를 한국어 로 도 들려 준다니 정말 기쁩니다 . 안타깝 게 도 저 는 아직 까지 한국 에 가 보 지 는 못했 지만 조만간 방문 해 보 고 싶 습니다 . - 작품 전편 에 걸쳐 전후 이탈리아 의 격동 적 인 경제 , 사회 , 정치 변화 를 배경 으로 다양 한 인물 의 부침 을 그렸 습니다 . 한국 사회 도 그 와 비슷 한 과정 을 거쳤 기 때문 에 깊이 공감 할 수 있 었 습니다 . 정치 나 역사 에 도 관심 이 많 습니까 ? 지금 이탈리아 나 세계 전반 의 흐름 에 대해서 는 의견 이 있 으신 가요 ? 가장 큰 관심사 는 무엇 입니까 ? 저 는 정치 를 좋 아 합니다 . 문학 이 하나 의 세계 를 창조 하 는 작업 이 라면 , 정치 는 더불 어 살아가 는 사회 의 틀 을 만드 는 역할 을 합니다 . 불행 하 게 도 여느 국가 와 마찬가지 로 이탈리아 정치인 들 역시 자신 에게 부여 된 임무 가 얼마나 중요 한지 , 또 그 책임 이 얼마나 막중 한지 깨닫 지 못하 는 것 같 습니다 . 가장 이상 적 인 정치 란 개개인 이나 특정 집단 또는 특정 국가 의 이익 이 아니 라 인류 전체 의 이익 실현 을 추구 하 는 것 이 라고 생각 합니다 . 그런 면 에서 현대 사회 는 전망 이 밝 지만은 않 다고 봅니다 . -< 나폴리 4 부작 > 을 읽 으면서 전체 적 으로 가장 인상 깊 었 던 것 은 인간 내면 에 대한 미시 적 인 정직성 입니다 . 인간 과 삶 의 어떤 점 을 이야기 하 고 싶 었 나요 ? 원래 저 는 우정 에 대한 이야기 를 하 고 싶 었 습니다 . 그러 다 보 니 종종 모순 적 이 면서 조밀 하 게 짜인 인간 의 감정 에 대한 이야기 도 하 게 되 었 습니다 . 소설 을 쓸 때 는 인간 의 단편 적 인 모습 이 아니 라 총체 적 인 면모 를 파악 해야 합니다 . 저 는 겉 으로 보이 는 모습 에 만족 하 지 않 으려고 합니다 . 인간 의 행동 은 결코 선형 적 이 지 않 으며 절대로 단순 하 지 않 습니다 . 이야기 의 대상 이 가지 고 있 는 복합 성 에 대한 두려움 이야말로 모든 화자 가 가지 고 있 는 진정 한 취약점 입니다 . - 작품 속 에서 주인공 릴라 를 통해 \\' 경계 의 해체 \\' 라고 부르 면서 묘사 한 현상 이 독특 하 게 느껴졌 습니다 . 흔히 말 하 는 신경증 이나 정신 분열증 과 는 다른 의미 인가요 ? 무엇 을 이야기 하 려 한 거 지요 ? ‘ 경계 의 해체 ’ 란 인간 사회 의 불 확실 성 에서 기인 한 증상 입니다 . 우리 주변 의 모든 것 이 한 순간 액체 화 하 거나 해체 되 거나 공중분해 될 수 있 다는 뜻 입니다 . -『 뉴요커 』 와 의 인터뷰 에서 인간 존재 의 상호 연결 성 을 이야기 하 면서 ‘ 프란 투 말리아 ’( frantumaglia ) 라는 단어 를 쓴 것 을 봤 습니다 . 『 파리 리뷰 』 와 의 인터뷰 에서 는 당신 의 어머니 가 자주 쓴 표현 이 라고 도 했 지요 . 글쓰기 에 관한 당신 의 에세이 집 제목 이 기 도 합니다 . ‘ 프란 투 말리아 ’ 가 무엇 인지 더 설명 해 주 시 겠 습니까 ? ‘ 프란 투 말리아 ’ 는 자아 를 여러 개 로 분리 된 조각 의 집합체 로 인식 하 는 것 입니다 . 그런 인식 을 한다는 것 은 위기 의 순간 이 라는 뜻 이 기 도 하 지만 어떻 게 보 면 새로운 출발점 이 라고 생각 할 수 도 있 지요 . 제 소설 속 인물 들 이 새로운 질서 를 부여 하 거나 존재 의 의미 를 찾 거나 자신 만 의 스토리 를 만들 어 좀 더 단단 해 지 기 위해 어떤 행동 에 나서 는 순간 은 바로 이런 느낌 을 받 았 을 때 입니다 . - 디지털 시대 로 오 면서 모바일 중독 과 주 의 분산 이 사회 적 인 문제 로 떠올랐 습니다 . 인간 은 집중 과 중독 , 분산 과 해체 를 반복 할 수 밖에 없 는 존재 일까요 ? 디지털 자체 는 좋 은 것 도 나쁜 것 도 아닙니다 . 우리 는 디지털 기기 를 잘 사용 하 면 그만 이 고 , 그렇게 될 수 있 도록 통제 하 는 것 은 정치가 가 할 일 이 지요 . 물론 디지털 시대 가 거대 기업 들 이 취할 수 있 는 모든 이윤 을 취하 도록 방치 한다는 것 을 뜻 한다면 문제 가 되 겠 지요 . 그렇게 되 면 사람 들 은 갈수록 소형 화 되 는 전자 기기 와 어플리케이션 에 중독 되 어 점점 정신 이 흐리멍덩 해 지 고 최면 에 걸린 것 같 은 상태 에서 살아갈 테 니까요 . - 소설 속 에 자주 등장 하 는 주요 요소 들 중 하나 가 폭력성 입니다 . 남성 의 육체 적 폭력 뿐 아니 라 크 고 작 은 언어 폭력 , 그리고 그 로 인한 정신 적 외상 도 자주 등장 합니다 . 심지어 따뜻 한 말 이나 표면 적 인 선의 의 행동 도 대개 는 복선 이 깔려 있 거나 냉소 적 인 인상 을 주 곤 합니다 . 인간 의 선의 는 취약 하 고 믿 을 것 이 못 된다는 뜻 인가요 ? 아뇨 , 전혀 그렇 지 않 습니다 . 선의 야말로 우리 의 강점 이 지요 . 하지만 선의 를 갖 는다고 해서 그 결과 가 반드시 좋 은 것 은 아닙니다 . 인간 은 균일 하 지 않 은 요소 들 로 구성 된 존재 입니다 . 그러 니 결속력 이 강하 지 도 않 고 일관 적 이 지 도 않 지요 . 몸짓 하나 , 예기 치 않 은 감정 만 으로 도 일 이 전혀 의도 하 지 않 은 방향 으로 흘러갈 수 있 습니다 . 그럼에도 선의 를 지향 하 는 것 은 인간 의 가장 존경 할 만 한 특성 입니다 . 비록 그 결과 가 좋 지 않 더라도 우리 는 이러 한 장점 을 지켜 가 야 합니다 . - 수많 은 등장인물 을 통해 시간 의 격랑 을 건너 는 다양 한 모습 이 그려집니다 . 돈 과 지식 , 사랑 , 시기 , 질투 , 탐욕 , 연민 이 교차 합니다 . 그런 가운데 순수 한 사랑 이나 희생 같 은 숭고 한 가치 는 뒤 로 밀려나 는 것 처럼 보입니다 . 인간 의 현실 에 대해 비관 적 인 입장 이 신가요 ? 아닙니다 . 저 는 근거 없 는 낙관주의 를 비판 할 뿐 입니다 . 우리 가 살 고 있 는 세계 가 지상 낙원 이 아니 라는 점 에 주목 할 필요 가 있 습니다 . 그렇지만 저 는 이상 적 인 세상 을 만드 는 것 이 불 가능 하 지 않 다고 생각 합니다 . 저 는 그러 한 확신 을 가지 고 있 습니다 . 그런 이상 적 인 세상 을 만드 는 데 방해 가 되 는 것 이 바로 근거 없 는 눈먼 낙관주의 입니다 . 살 아 있 는 권력 앞 에 굽실대 며 뭐 그렇게 불평불만 이 많 냐고 , 지금 살 고 있 는 세상 에서 더 나아질 게 뭐 가 있 겠 느냐고 말 하 는 사람 들 입니다 . - 친구 와 연인 , 가족 사이 에 욕설 이 오가 고 , 폭력 , 섹스 , 불 륜 장면 도 자주 등장 합니다 . 어떤 대목 은 ‘ 막장 드라마 ’ 같 기 도 합니다 . 이런 것 을 시시콜콜 쓴 것 은 어떤 의도 가 있 었 나요 ? 저 는 독자 들 이 소설 에 몰입 할 수 있 도록 제 가 알 고 있 는 기술 을 총동원 했 습니다 . 하지만 일단 이야기 속 에 들어오 면 독자 들 은 잘 만든 대중 소설 에서 나올 법 하 다고 기대 했 던 예상 이 모두 빗나가 는 것 을 경험 하 게 되 지요 . 저 는 ‘ 진짜 ’ 에 관심 이 있 지 진짜 와 유사 한 것 에 관심 이 있 는 것 이 아닙니다 . 그렇지만 다른 한편 으로 독자 들 을 잠들 게 하 지 않 고 소설가 로서 진실 에 도달 하 기 위해 노력 하 는 작가 들 을 존경 합니다 . 소설 이 정말로 생명력 을 잃 는 것 은 독자 가 생명력 을 잃 을 때 입니다 . - 두 주인공 릴라 와 레누 의 우정 어린 성 장사 를 다뤘 지만 둘 사이 에 는 끊임없이 애증 이 교차 합니다 . 인간 은 누구 와 도 온전히 화해 할 수 는 없 다는 뜻 인가요 ? 제 가 무슨 이야기 를 하 고자 했 는지 는 중요 하 지 않 습니다 . 개인 적 인 경험 을 책 에 투영 하 고 여기 에서 필요 한 부분 을 취하 는 것 은 독자 들 의 몫 입니다 . - 작품 속 에 그려진 것 처럼 끝 없 는 상호 충돌 과 자기 분열 이 세상 의 숙명 이 라면 개인 이나 공동체 는 어떤 희망 과 기대 를 가지 고 살아갈 수 있 을까요 ? 인생 은 충돌 이 아니 라 만남 으로 이루어집니다 . 일반 적 으로 좋 은 만남 이 좋 지 않 은 만남 보다 많 다고 생각 합니다 . 물론 가끔 충돌 이 불가피 할 때 가 있 죠 . 하지만 그런 경우 에 도 충돌 을 만남 으로 승화 하 기 위해 노력 해야 합니다 . 앞 에서 도 말씀 드렸 지만 중요 한 것 은 선한 의지 입니다 . 우리 는 선의 를 가진 사람 들 의 범 지구 적 인 통합 을 이루 기 위해 노력 해야 합니다 . - 릴라 와 레누 는 여러 면 에서 대조 적 이 면서 어떤 점 , 특히 글쓰기 , 학습 욕 , 세상 을 바꿔 보 려는 의지 등 은 비슷 합니다 . 그러 면서 시종일관 서로 경쟁 합니다 . 하지만 노력 하 는 레누 보다 는 타고난 릴라 를 특별 한 존재 로 설정 한 것 같 습니다 . 그럼에도 릴라 는 스스로 \\' 특별 한 삶 의 욕망 은 없 는 \\' 인물 이 라고 말 합니다 . 릴라 라는 캐릭터 를 통해 특별히 전달 하 고 싶 은 것 이 있 었 나요 ? 저 는 어떤 메시지 를 전달 하 려는 것 이 아닙니다 . 진정 성 있 는 이야기 를 전할 뿐 입니다 . - 요즘 미국 을 필두 로 곳곳 에서 남성 의 성폭력 이 문제 가 되 면서 여성 피해자 의 폭로 도 잇따르 고 있 습니다 . 당신 의 작품 은 마치 이런 상황 을 예견 이 라도 한 듯 그런 실상 을 묘사 했 습니다 . 소설 속 에 는 남자 가 여성 을 한낱 성적 대상 으로 보 거나 , 가르치 려 드 는 태도 가 자주 등장 합니다 . 소설 을 쓸 때 그것 을 의식 하 고 다뤘 나요 ? 지금 상황 에 대해서 는 어떻 게 보 시 나요 ? 우리 가 살 고 있 는 이 세계 는 여전히 가부장 적 입니다 . 그동안 많 은 발전 이 있 기 는 했 지만 아직 도 모든 분야 에서 여성 은 남성 보다 열등 한 존재 로 평가 받 고 있 습니다 . 사람 들 은 여성 을 종속 적 인 존재 로 여기 며 남성 의 성적 욕구 에 따라 마음대로 다뤄도 된다고 생각 합니다 . 여성 문제 에 관한 한 지금 상황 은 아주 좋 지 않 습니다 . 크 고 작 은 권력 을 가진 남성 들 중 에 는 자신 이 여성 을 대상 으로 행사 한 폭력 행위 에 대해 수치심 을 느껴야 할 사람 이 많 습니다 . 그런데 도 이 들 은 수치심 을 느끼 기 는커녕 그러 한 폭력 이 남성 의 권리 라고 생각 합니다 . 오히려 성 추행 의 원인 을 제공 하 는 쪽 이 여성 이 라고 생각 합니다 . 그런 남성 들 에게 맞서 수치 스러워 하 지 않 고 당당 하 게 입 을 열 고 , 이 들 의 만행 을 고발 하 는 것 이 중요 합니다 . 다만 , 이 모든 것 이 지나치 지 않 도록 주의 해야 합니다 . 과도 함 때문 에 오히려 정당 성 이 약화 될 수 있 으니까요 . - 저 는 남성 입니다 . 당신 의 작품 속 묘사 를 통해 여성 을 좀 더 이해 하 게 되 었 습니다 . 그만큼 여성 의 복잡 한 심리 묘사 가 탁월 합니다 . 그 에 비해 남성 에 대한 묘사 는 상대 적 으로 단순 하 고 단조 롭 다는 느낌 을 받 았 습니다 . 어떤 이유 에서 든 본래 그런 차이 가 있 다고 생각 하 시 나요 ? 그렇 습니다 . 남성 은 여성 의 참모습 을 잘 모릅니다 . 물론 모든 남성 이 그렇 다는 것 은 아닙니다 . 일반 적 으로 그렇 다는 이야기 입니다 . 남성 은 여성 뿐 아니 라 남성 자신 조차 도 정형 화 된 스테레오 타입 에 끼워 맞추 는 것 을 선호 합니다 . 남성 은 아직 도 운명 의 파도 를 헤쳐 나가 는 자신 들 을 다재다능 한 율리시스 ( = 오디세우스 ) 라고 생각 하 죠 . 그 에 비해 아내 인 페넬로페 의 임무 는 그저 베틀 로 직물 이나 짰 다가 다시 풀 기 나 하 는 것 이 라고 생각 합니다 . 하지만 이런 식 의 사고방식 은 이제 더 이상 유효 하 지 않 습니다 . 여성 의 사회 참여 가 늘어날수록 남성 의 지위 는 위험 할 정도 로 취약 해 지 고 있 습니다 . 이러 한 현상 은 여성 과 남성 그리고 인류 전체 에 위험 합니다 . - 당신 의 소설 속 에서 연인 과 가족 마저 개인 에게 족쇄 이 자 낙인 이 되 고 마 는 것 을 봅니다 . \" 확실 한 것 은 정절 과 믿음 을 바탕 으로 한 동 거의 시대 는 남녀 를 불문 하 고 끝 났 다 \" 는 표현 도 나옵니다 . 남녀 관계 나 결혼 , 가족 의 미래 에 대해서 는 어떻게 생각 하 시 나요 ? 소설 과 마찬가지 로 가족 이 라는 관계 는 항상 위태 로워 보이 지만 결코 사라지 지 는 않 을 것 입니다 . 그렇지만 그 동안 가족 이 라는 개념 에 정말 많 은 변화 가 있 었 고 지금 도 그러 한 변화 가 진행 되 고 있 습니다 . 이러 한 변화 는 매우 본질 적 인 부분 까지 포함 하 고 있 습니다 . 그 동안 젠더 의 개념 과 성 역할 , 부부 라는 전통 적 인 동거 형태 , 결혼 서약 의 의미 마저 많이 변했 습니다 . 사랑 이 라는 감정 은 예전 보다 유통 기간 이 짧아졌 고 , 생식 의 방식 도 달라졌 죠 . 그 외 에 도 변한 것 이 많 습니다 . 가족 은 영원히 사라지 지 않 을 테 지만 시간 이 갈수록 그 개념 과 형태 는 많이 달라질 수 밖에 없 고 그런 변화 가 꼭 나쁘 다고 만 할 수 는 없 습니다 . - 작품 속 에서 지식 과 학습 이 중요 한 도구 로 등장 합니다 . 한국 에 도 \" 개천 에서 용 난다 \" 라는 속담 이 있 습니다 . 하지만 이제 는 많 은 사람 이 그 말 을 의심 합니다 . 지식 은 인터넷 에 넘쳐나 는 정보 와 등식 화 되 고 있 습니다 . 상속 받 은 재산 이 후손 의 장래 를 결정 한다고 냉소 적 으로 말 합니다 . 이런 환경 에서 지식 과 학습 은 어떤 의미 가 있 을까요 ? 제 소설 에서 도 학습 은 이미 신분 상승 의 수단 이 아닙니다 . 사실 레누 가 이룬 업적 도 실망 스러운 것 이 죠 . 따지 고 보 면 레누 와 니노 는 크 게 성공 하 지 는 못 합니다 . 둘 은 기득 권 에 의해 선택 받 을 뿐 정작 정말로 중요 한 계층 의 중심부 에 는 편입 되 지 못합니다 . 저 는 릴라 의 무정부주의 적 인 방식 을 선호 합니다 . 릴라 는 학습 을 신분 상승 을 위한 수단 으로 사용 하 는 것 이 아니 라 실제로 해결 해야 하 는 문제 를 풀 기 위한 도구 로 사용 합니다 . 아니면 단순히 살아가 면서 직면 하 는 여러 인생 문제 에 대한 답 을 찾 기 위해 학습 을 합니다 . - 한 인터뷰 에서 고전학 을 공부 했 다고 밝힌 바 있 습니다 . 그래서인지 작품 속 세계관 이 고대 그리스 비극 과 통하 는 것 같 기 도 합니다 . \\' 포스트 휴먼 \\' \\' 트랜스 휴먼 \\' 을 이야기 하 는 이 첨단 의 시대 에 여전히 고전 적 인간관 과 세계관 이 우리 에게 말 해 줄 것 이 있 다고 생각 하 시 나요 ? 저 는 ‘ 포스트 ’ 나 ‘ 트랜스 ’ 같 은 접두사 가 붙 는 단어 에 큰 의미 를 부여 하 지 않 습니다 . 모호 한 개념 이 기 때문 이 죠 . 예전 에 존재 하 지 않 았 던 새로운 현상 이 나타난다면 굳이 ‘ 포스트 ’ 나 ‘ 트랜스 ’ 같 은 접두사 를 붙이 지 않 고서 도 그 에 알맞 은 명칭 을 가지 게 될 것 입니다 . - 어느 인터뷰 에서 글쓰기 를 투쟁 이 라고 표현 했 더군요 . 왜 그렇게 생각 하 시 지요 ? 처음 에 ‘ 이야기 ’ 는 혼란 스러운 상태 이 며 가공 되 지 않 은 원료 에 불과 합니다 . 적합 한 형태 와 기능 을 갖추 기 위해서 는 투쟁 해야 합니다 . - 꿈 을 꾼 후 에 기억나 는 것 들 을 적 어 보 는 것 이 좋 은 글 쓰 기 훈련 이 될 수 있 다는 말 도 했 지요 . 작가 지망 생 들 에게 그 외 에 어떤 조언 을 해 주 고 싶 습니까 ? 위대 한 고전 을 읽 으면서 배우 고 , 글 쓰 기 연습 을 최대한 많이 하 라고 조언 하 고 싶 습니다 . 꿈 을 충실히 글 로 옮긴다는 것 은 사실 상 불 가능 합니다 . 단어 와 문법 과 문장 으로 번역 하 는 순간 실제 꾼 꿈 을 왜곡 하 게 될 테 니까요 . -< 나폴리 4 부작 > 이 tv 드라마 로 각색 되 고 있 지요 . 대본 작업 에 도 직접 참여 하 신다고 들 었 습니다 . 얼마나 진행 되 었 습니까 ? 작업 과정 에서 힘든 점 은 ? 소설 과 차이 가 있 나요 ? 어떤 점 을 부각 시킬 생각 인가요 ? 글쎄요 . tv 드라마 는 감독 의 역할 이 중요 하 지요 . 책 을 쓸 때 는 작가 가 모든 문장 을 완벽 하 게 통제 합니다 . 하지만 영상 을 위한 이야기 는 다양 한 능력 과 수많 은 사람 의 의견 이 감독 의 지휘 하 에 조율 되 어 완성 되 지요 . 각본 은 이런 다양 한 능력 을 취합 한 결과물 에 들어가 는 한 가지 일 뿐 입니다 . 영상 을 만들 기 위한 이야기 를 구축 하 되 이러 한 목표 를 달성 하 기 위한 수단 으로 글 을 사용 하 는 것 입니다 . 물론 각본 이 중요 하 지만 영화 의 결정 적 인 요소 는 아닙니다 . 영화 가 완성 되 기 까지 거쳐야 하 는 수많 은 단계 중 하나 일 뿐 이 죠 . - 당신 이 나 고 자랐 다는 나폴리 는 한국인 에게 이탈리아 가곡 과 경치 좋 은 관광지 로 만 알려져 있 습니다 . 마지막 4 권 『 잃어버린 아이 이야기 』 에서 는 나폴리 를 \" 역사 발전 과 진보 , 민주주의 의 이상 은 허구 임 을 일찌감치 보여준 환멸 의 도시 \" 라고 표현 했 더군요 . 지금 은 어떻게 생각 하 십니까 ? 아직 도 그렇 게 생각 합니다 . - 나이 가 많 으신 것 으로 압 니다 ( 위키피디아 에 는 1943 년 생 으로 올라 있 더군요 ) . 살아오 면서 시간 에 따라 인생관 이나 글쓰기 에 대한 변화 가 있 었 나요 ? ( * 다른 인터뷰 의 답변 과 글 을 보 면 연로 한 것 으로 유추 할 수 있 다 . ) 저라 면 위키피디아 정보 를 그대로 믿 지 않 겠 습니다 . 어쨌든 세월 이 흐르 면서 사상 적 으로 비 타협 적 이 된 것 같 습니다 . 글 쓰 기 로 말 하 자면 다양 한 시도 를 해 본 결과 근본 적 으로 제 문장 의 리듬 은 열 여섯 살 때 와 달라진 것 이 하나 도 없 다는 결론 을 내렸 습니다 . - 작품 후반부 에서 \" 명예 도 돈 도 없 는 노년 의 불안 \" 에 대해 언급 했 습니다 . 어느 정도 나이 가 든 지금 남 은 생 을 보 며 드 는 소회 를 이야기 해 줄 수 있 습니까 ? 어떤 나이 를 말씀 하 시 는 거 죠 ? 위키피디아 에 나온 나이 말씀 인가요 ? - 최근 에 후속 작품 을 집필 중 이 라는 기사 를 봤 습니다 . 혹시 어떤 작품 인지 간략히 소개 해 주 실 수 있 나요 ? 글 쓰 기 연습 일 뿐 입니다 . 저 는 매일 글 을 씁니다 . 어떤 결과 가 있 을지 장담 할 수 는 없 습니다 . - 당신 은 \\' 얼굴 없 는 작가 \\' 로 관심 을 모았 습니다 . 신원 을 밝히 지 않 는 것 은 글쓰기 에 집중 하 기 위해서 라고 했 습니다 . 인간 관계 가 불가피 하 게 야기 하 는 소란 스러움 속 에 얽히 기 싫 어서 인가요 ? 이제 는 오히려 자신 을 숨기 는 것 이 더 힘들 거나 불편 해 지 진 않 았 나요 ? 평생 , 심지어 사후 에 도 얼굴 없 는 작가 로 남 고 싶 으신 가요 ?',\n",
       "       '정보 기술 의 발전 과 더불 어 다양 한 형태 의 데이터 들 이 기하급수 적 으로 생성 되 고 , 융합 학문 의 중요 성 과 더불 어 복잡 한 데이터 의 분석 에 대한 필요 성 이 여러 학문 분야 에서 부각 되 고 있 습니다 . 이러 한 기술 적 요구 와 더불 어 기계 학습 및 패턴 인식 에 대한 관심 이 그 어느 때 보다 도 높 습니다 . 이 에 한국 정보 과 학회 인공지능 소사이어티 에서 는 2017 년 7 월 11 일 - 12 일 2 일 에 걸쳐 “ 2017 년 패턴 인식 및 기계 학습 여름 학교 ” 를 개최 합니다 . 다양 한 분야 에서 패턴 인식 및 기계 학습 을 연구 하 고 계시 는 국내 최고 권위 의 연사 들 을 모시 고 , 알찬 강의 를 준비 해 보 았 습니다 . 최근 인공지능 시대 를 맞 아 다양 한 알고리즘 들 이 생 성 / 응용 되 고 있 습니다 . 그렇지만 이 들 의 뿌리 가 되 는 핵심 개념 에 대한 이해 가 부족 하 여 알고리즘 을 설계 하 거나 제대로 응용 하 는 데 부족 함 이 있 습니다 . 따라서 이번 여름 학교 는 기계 학습 의 기본 개념 및 원리 에 대한 기초 지식 을 심 도 있 게 정립 하 는 데 중점 을 두 었 습니다 . 2017 년 5 월 13 일 한국 정보 과 학회 인공지능 소사이어티 교육 부회장 신현정 ( 아주 대학교 ) 한국 정보 과 학회 인공지능 소사이어티 수석 부회장 최승진 ( postech ) 한국 정보 과 학회 인공지능 소사이어티 회장 김 선 ( 서울 대학교 )',\n",
       "       '이전 에 제 데스크 탑 에 각종 리눅스 ( deepin os , ubuntu , debian , fedora , elementary os 등 ) 를 설치 해 보 면서 겪 어 본 바 로 는 , 생각 보다 리눅스 호환 성 이 좋 지 는 않 다 ( ......) 는 것 입니다 . 그래서 한 번 설치 기 를 올려 보 려고 합니다 . 저 같 은 경우 는 한 20 시간 삽질 하 면서 해 봤 네요 . 일단 제 데스크 탑 기준 으로 설명 할 것 입니다 . 사양 은 다음 과 같 습니다 . cpu : intel i 7 - 5820 k ram : 16 gb mainboard : msi x 99 s sli plus graphic card : gtx 970 hdd : sata 2 seagate 320 gb 로 추정 됨 1 . 일단 원 하 는 리눅스 를 다운 받 습니다 . 저 같 은 경우 는 ubuntu 16 . 04 ( 현재 최신 ubuntu lts 버전 ) 을 다운 받 았 습니다 . 2 . usb 이동식 디스크 에 리눅스 iso 파일 을 굽 습니다 . 이때 추천 해 드리 는 툴 이 rufus 입니다 . 개인 적 으로 많이 애용 하 고 , 다른 툴 에 비해 호환 성 도 좋 더군요 . 3 . iso 파일 을 구운 usb 이동식 디스크 를 넣 고 부팅 합니다 . bios 창 에서 usb 이동식 디스크 를 부팅 옵션 최 상단 에 두 거나 , 저 같 은 경우 f 11 을 눌러서 부트 메뉴 에서 선택 할 수 있 었 습니다 . 4 . 이제 기본 적 인 grub ( 주로 쓰이 는 리눅스 부트 로더 ) 가 보입니다 . 이때 한 번 install os 또는 start os 등 을 눌러서 부팅 을 시도 해 봅니다 . 저 같 은 경우 는 이후 화면 이 이상 하 게 바뀌 거나 검정 색 이 되 면서 아무것 도 되 지 않 았 습니다 . 원인 은 nvidia 그래픽 카드 때문 이 죠 . ( 리누즈 토르발스 가 엔 비디아 에 욕 을 날린 이유 가 분명 있 습니다 ㅇㅇ ) 따라서 다시 컴퓨터 를 재 시작 하 고 다시 grub 화면 까지 진입 한 후 , e 를 눌러 명령어 수정 을 시도 합니다 . 잘 찾아보 면 대체 적 인 desktop linux 버전 에서 는 아마 splash 명령어 가 보일 겁니다 . 거기 앞 또는 뒤 에 nomodeset 을 넣 어 줍니다 . 그리고 f 10 인가 를 눌러서 부팅 을 시도 합니다 . 아마 잘 될 겁니다 . 5 . 부팅 을 시도 한 뒤 언어 를 설정 하 고 맘대로 설치 하 시 면 됩니다 . 개인 적 으로 추천 해 드리 고 싶 은 파티션 구조 는 / boot 에 500 mb 정도 할당 , swap 에 자신 의 램 의 1 ~ 2 배 할당 , 나머지 를 / 에 할당 하 는 겁니다 . 귀찮 으시 면 default 옵션 으로 가셔도 되 고 요 . 6 . 설치 후 이제 리눅스 gui 화면 에 진입 했 을 것 입니다 . 일단 grub 부트 옵션 을 부팅 할 때 마다 일일히 넣 어 줄 수 없 으니 , 수정 해서 넣 어야 합니다 . sudo vi / etc / default / grub 으로 grub 부트 옵션 을 수정 할 수 있 습니다 . 아래 와 같 은 화면 이 나올 텐데 , 뭐 grub _ cmdline _ linux 에 nomodeset 만 넣 어도 충분 하 지만 , 저 같 은 경우 언제 또 리눅스 가 죽 을지 모르 기 때문 에 ( ㅠㅠ ) 부트 로그 를 보여 주 지 않 는 옵션 인 splash quiet 옵션 을 지우 고 넣 었 습니다 . 저 처럼 하 시 면 grub 에서 선택 후 멋 - 진 리눅스 부팅 로그 를 구경 하 실 수 있 습니다 하핫 저 같 은 경우 는 트리플 모니터 를 사용 하 는데 이 상황 에선 하나 밖 에 인식 이 안 됩니다 . 그래픽 카드 드라이버 가 깔리 지 않 았 기 때문 이 죠 . 이제 깔 아 주 러 갑니다 . 가능 하 면 검색 해서 나오 는 대로 까 시 지 말 고 ( 전 그렇게 했 다가 무한 로그인 만나 고 gg 쳤 습니다 ) 제 방식 대로 하 시 면 잘 될 거 라 생각 됩니다 . 7 . 구글 에 검색 해 보 시 면 ( nvidia linux driver 등 . ..) 엔 비디아 에서 다운 받 을 수 있 는 리눅스 드라이버 가 있 습니다 . 이때 파일 확장자 를 . run 을 선택 하 시 는 걸 추천 드립니다 . ( 딱히 증명 된 건 아니 지만 일단 전 잘 되 었 거든요 쿨럭 . ..) 저 는 nvidia - linux - x 86 _ 64 - 367 . 35 . run 를 다운 받 았 네요 . 8 . 다운 받 은 후 드라이버 를 깔 기 위해서 gui 모드 를 끕니다 . ubuntu 의 경우 , ctrl + alt + f 1 을 누르 면 cli 모드 에 진입 할 수 있 습니다 . 진입 한 후 , 일단 su 로 root 계정 로그인 후 service lightdm stop 으로 gui 를 끌 수 있 습니다 . 9 . 종료 후 , run 파일 을 찾 아서 실행 합니다 . 적당히 동의 해 주 시 면 됩니다 . 참고 로 저 는 모든 곳 에서 다 동의 했 습니다 . 듣 기 로 는 리눅스 드라이버 깔 때 opengl 을 깔 것 이 냐 가 뜰 수 도 있 는데 , opengl 까 는 건 무시 해야 나중 에 무한 로그인 화면 이 뜨 지 않 는다고 하 더군요 . 전 그런 창 뜨 진 않 았 네요 : ) 10 . 다 까 신 후 , 재 부팅 하 시 고 무한 로그인 화면 만 안 뜨 시 면 어느 정도 성공 하 신 겁니다 ! 뭐 개인 적 으로 디자인 이 이쁜 deepin os 나 elementary os 를 쓰 고 싶 었 는데 , 제 컴 에서 아예 부팅 조차 되 지 않 는 괴 랄 한 ( ...) 현상 이 보여서 시도 조차 못 해 본 게 조금 아쉽 긴 합니다 .',\n",
       "       '이진 탐색 전 아직 donald knuth 의 the art of computer programming 을 본 적 은 없 습니다 만 , 스택 오버 플로우 에 올라온 질문 에 의하 면 , 이런 말 을 했 다고 합니다 . “ although the basic idea of binary search is comparatively straightforward , the details can be surprisingly tricky … ” 무엇 이 까다로운지 는 아래 서 다루 겠 습니다 . 하지만 바이너리 서치 가 고려 해야 될 점 이 몇 개 있 다는 건 알 아 두 고 진행 하 지요 . 1 . overview 이진 탐색 은 정렬 된 자료 를 대상 으로 실행 될 경우 에 만 유효 합니다 . 왜냐하면 방법 자체 에서 이미 정렬 되 어 있 다고 가정 하 기 때문 입니다 . 먼저 그림 을 보 시 죠 . 76 을 찾 고 싶 다고 할 때 , 다음 과 같이 이진 탐색 이 진행 됩니다 . 결국 이진 탐색 이 란 현재 자료 의 좌측 은 현재 값 보다 작 고 , 우측 은 현재 값 보다 크 다고 가정 하 고 탐색 하 는 방법 입니다 . 따라서 최악 의 경우 o ( logn ) 의 성능 을 내 며 , 가장 빠를 때 는 o ( 1 ) 입니다 . 당연히 일반 적 인 선형 탐색 ( linear search ) 보다 빠르 나 배열 이 정렬 되 어 있 어야 한다는 전제 조건 이 붙 습니다 . 유사 하 게 , hash 의 경우 에 도 이진 탐색 보다 평균 적 으로 더 빠르 지만 더 제약 조건 이 많 죠 . 2 . binary search implementation 이진 탐색 은 두 가지 버전 으로 구현 할 수 있 습니다 . 첫 째 는 재귀 ( reculsive ) 고 두 번 째 는 반복 ( interative ) 입니다 . 반복 부터 보 시 겠 습니다 . iterative version int binary _ search ( int * arr , int length , int value ) { if ( arr == nullptr || length < 0 ) return - 1 ; int left = 0 ; int right = length - 1 ; int mid ; while ( left <= right ) { mid = left + ( right - left ) / 2 ; if ( arr [ mid ] == value ) { return mid ; } else if ( arr [ mid < value ] ) { left = mid + 1 ; } else if ( arr [ mid ] > value ) { right = mid - 1 ; } } return - 1 ; } reculsive version int binary _ search ( int * arr , int value , int left , int right ) { if ( left > right ) { return - 1 ; } int mid = left + ( right - left ) / 2 ; if ( arr [ mid ] == value ) return mid ; else if ( arr [ mid ] > value ) { binary _ search _ reculsive ( arr , value , left , mid - 1 ) ; } else { binary _ search _ reculsive ( arr , value , mid + 1 , right ) ; } } 3 . problems 여기 에 의하 면 knuth 는 taocp 에서 이진 탐색 은 1946 년 에 발표 되 었 으나 , 그 의 정확 한 구현 은 1962 년 에 이루 어 졌 다고 지적 했 습니다 . 또한 bentley 는 벨 연구소 나 ibm 에서 일 하 는 박사 과정 학생 들 에게 두 시간 을 주 고 이진 검색 을 구현 하 라고 했 을 때 90 % 가 버그 있 는 코드 를 제출 했 다고 말 했 습니다 . 어떤 요소 들 이 이진 탐색 의 구현 을 어렵 게 만드 는 걸까요 ? numerical underflows / overflows 가장 흔히 발생 하 는 오류 는 오버 플로우 입니다 . 여기 에 의하 면 , 프로그래머 들 은 종종 다음 과 같이 문제 가 있 는 코드 를 작성 하 곤 합니다 . 1 : public static int binarysearch ( int [ ] a , int key ) { 2 : int low = 0 ; 3 : int high = a . length - 1 ; 4 : 5 : while ( low <= high ) { 6 : int mid = ( low + high ) / 2 ; 7 : int midval = a [ mid ] ; 8 : 9 : if ( midval < key ) 10 : low = mid + 1 11 : else if ( midval > key ) 12 : high = mid - 1 ; 13 : else 14 : return mid ; / / key found 15 : } 16 : return -( low + 1 ) ; / / key not found . 17 : } 6 번 째 줄 을 주목 해 주 세요 . ( low + high ) / 2 는 중간값 을 돌려주 지만 그것 은 int 의 범위 내 에서 입니다 . 무슨 말 인고 하 니 , low 와 high 를 더 했 을 때 32 bit int 의 최대 값 인 ( 2 ^ 31 - 1 ) 보다 크 다면 , 오버 플로우 가 일어날 겁니다 . 그리고 음수 값 이 되 겠 지요 . c 라면 unpredictable results 를 만들 거 고 자바라 면 a r r a yindexoutofboundexception 이 발생 할 겁니다 . 따라서 6 번 째 줄 의 코드 는 6 : int mid = low + ( ( high - low ) / 2 ) ; 위 와 같이 고치 거나 , >>> 연산자 가 있 는 언어 라면 6 : int mid = ( low + high ) >>> 1 ; >>> 가 없 는 c 와 c ++ 같 은 언어 라면 다음 과 같이 고칠 수 있 겠 습니다 . 6 : mid = ( ( unsigned int ) low + ( unsigned int ) high ) ) >> 1 ; handling of duplicate items 이진 탐색 에서 단순히 값 만 같 은 원소 를 돌려주 는 게 아니 라 , 첫 번 째 로 값 이 같 은 ( 인덱스 상 에서 가장 좌측 에 위치 한 ) 원소 를 돌려주 려면 조금 생각 을 해 봐야 합니다 . 찾 았 을 경우 인덱스 를 – 하 면서 루프 를 한번 더 돈다 던가요 . recursive vs non - reculsive 어떤 구현 이 현재 의 자료 의 사이즈 와 형태 탐색 에서 더 나 은 성능 을 보여줄지 생각 하 고 결정 해야 합니다 . 일반 적 으로 는 재귀 보다 는 반 복문 이 스택 으로 인한 오버헤드 가 없 어서 더 선호 되 는 편 입니다 . off - by - one errors 경계값 에러 는 항상 발생 합니다 . 이를테면 , 위 코드 에서 5 번 째 줄 을 다음 과 같이 구현 했 을 경우 5 : while ( low < high ) { 원소 가 { 0 , 1 } 두 개 이 고 , 1 을 찾 고자 할 때 찾 지 못합니다 . low == high 인 경우 루프 를 돌 지 않 으니까요 . 경계값 을 올바르 게 나누 는 방법 에 대해서 알 고 싶 으시 다면 여기 를 참조 하 시 면 되 겠 습니다 . 간단히 내용 을 소개 하 자면 , 중간 포지션 을 기점 으로 좌우 를 나누 는 로직 을 다룬 내용 인데 아래 와 같 습니다 . 구분 left half right half natural division 0 <= i < n / 2 ( n + 1 ) / 2 <= i < n left + division 0 <= i < ( n + 1 ) / 2 ( n + 1 ) / 2 <= i < n right division 0 <= i < n / 2 n / 2 <= i < n left cut out center division 0 <= i < ( n + 1 ) / 2 - 1 ( n + 1 ) / 2 <= i < n right cut out center division 0 <= i < n / 2 n / 2 + 1 <= i < n 사실 natural division 만 기억 하 고 계시 면 될 듯 합니다 . 중간값 을 포함 하 는 경우 는 흔치 않 고 , 왼쪽 에서 중간값 을 커팅 하 냐 오른쪽 에서 해내 냐 는 사실 별 의미 가 없 는 것 같 습니다 . 다음 포스팅 은 binary search tree 구현 과 dfs , bfs 가 될 것 같 습니다 . 감사 합니다 . references',\n",
       "       \"작년 11 월 에 제 블로그 방명록 을 통해서 시식 평가 초청 을 해온 식당 이 있 었 습니다 . 그런 인연 으로 인터뷰 기사 까지 올리 게 되 었 죠 . 해당 기사 를 보 시 려면 여기 를 클릭 ! ! 그럴만한 실력 과 열정 이 있 는 곳 이 라는 판단 에서 였 는데 , 제 소개 로 다녀가 본 지인 들 의 평가 도 전반 적 으로 양호 한 편 이 었 습니다 . 그 식당 의 소개 입니다 . 홍대입구역 에서 부 터 찾 아 갔 더니 꽤 나 거리 가 있 더군요 . 상수역 1 번 출구 부근 의 차량 이 못 다닐 정도 로 좁 은 골목길 안 에 있 습니다 . 보행 인구 가 뜸 한 골목길 에 있 기에 이런 외부 광고 물 은 생각 보다 효과 가 없 을 것 같 은데 말 이 죠 . 저 같 으면 업소 품격 을 위해 달 지 않 을 듯 . 오픈 초기 와 는 달리 요즈음 은 손 님 이 많 아 져서 항시 만석 이 라니 이제 는 철거 하 는 것 이 어떨지 싶 네요 . 제법 분위기 있 는 입구 입니다 . 경북 포항 에서 처음 시작 한 중국 만 두 집 의 이름 이 ' 만 포장 ' 이 었 는데 그걸 이어서 일본식 으로 표기 한 상호 라는군요 . 진짜 초 가 아닌 걸 아 시 죠 ? ' 최초 발상지 ' 가 되 려면 앞 으로 널리 퍼져 나가 야 만 하 겠 죠 ? ^^ 일본 에 와 있 는 듯 한 분위기 인데 좁 은 것 도 마찬가지 입니다 . 항상 만석 인지라 예약 않 고서 가 면 곤란 을 겪 을 수 도 있 습니다 . 주방 은 잘 관리 되 고 있 고 위생 복장 착용 도 완벽 . 저 탕수육 에 주목 하 시 길 . . 다다미방 에 는 2 인 탁자 4 개 가 있 습니다 . 대식 도전 으로 는 시간 이 무척 짧 군요 . 보통 은 십 분 이상 은 주 는데 말 이 죠 . 많이 먹 기 보다 는 빨리 먹 기 과제 가 될 듯 . 벽면 이 부착물 로 빼곡 하 게 들어차 있 습니다 . 주방 처럼 화장실 도 관리 상태 양호 . 이 집 의 대표 메뉴 중 하나 가 나 가 사 끼 짬뽕 . 수저 를 전후 방향 으로 놓 는 것 은 우리 식 이 고 일본 은 좌우 . 중화 풍 의 스프 인데 녹말 을 푼 계란탕 일 듯 . 게살 이 약간 들 었 던 듯 도 . .. 아쉽 게 도 , 생맥주 는 국산 만 있 네요 . 관리 상태 는 양호 했 습니다 . 처음 에 는 일본 생맥주 도 준비 했 는데 주머니 가 가벼운 젊 은 층 고객 이 주 를 이루 다 보 니 판매 가 저조 해서 뺏 다는군요 . 앞 으로 고객 층 이 달라지 면 다시 등장 시키 는 게 좋 겠 죠 . 술안주 서비스 로 갓 튀겨 따끈 바삭 한 말린 새우 와 새우 칲을 주 시 네요 . 만물 상 의 건어 물편 에서 일본 의 말린 새우 이야기 를 길 게 했 는데 편 집 에서 살아남 으려나 모르 겠 군요 . 첫 방문 이 었 기 에 업소 측 에서 권하 는 것 으로 맛 을 봤 습니다 . 장어구이 입니다 . 일본 에서 배워 온 솜씨 로 일본 음식점 을 하 는 것 이 지만 , 나름 의 연구 로 자신 만 의 소스 와 맛 을 내려 노력 한다는군요 . 그래서인지 약간 씩 다르 기 는 했 습니다 . 이 장어구이 도 소스 가 일본 에서 보다 덜 달 고 덜 짭니다 . 인공 조미료 를 쓰 질 않 는다는 데 그래서인지 일본 음식 특유 의 강한 감칠맛 도 상대 적 으로 덜 한 편 . 참 , 장어 는 바닷장어 를 씁니다 . 민물 장어 는 가격 이 세 고 양식 에 따른 문 젯 점 ( 항생제 등 ) 우려 도 있 지만 바닷장어 는 양 식산 이 없 고 가격 이 저렴 하 여 나름 의 장점 이 있 죠 . 손질 과 조리 솜씨 에 따라서 는 민물 장어 에 버금가 는 맛 을 내 고요 . 그레서 요즈음 은 고급 일식집 의 초밥 에 도 바닷장어 를 흔히 쓰 고 있 습니다 . 일본 이 었 으면 오크라 를 곁들이 면 좋 았 겠 죠만 꽈리고추 도 나쁘 지 않 습니다 . 준비 와 조리 과정 이 까다로와 서 일 일 한정량 만 판매 한다는데 , 이 집 에 여럿 이 갈 경우 챙겨 드실 만 합니다 . 모노 마트 에서 구입 한 공장 제 팩 제품 을 뜯 어서 데워 만 내 는 시 중 의 이자 까 야 들 로서 는 흉내 도 못 낼 음식 이 죠 . 메뉴 거의 전부 를 모노 마트 제 로 채운 게 이자 까 야 들 음식 이 면서 값 은 더럽 게 높 게 받 아 먹 기 에 저 는 내 돈 내고 는 이자 까 야 ( 국내 의 ) 를 가질 않 습니다 . 누가 사 주 면 몰라도 . . 이 집 은 재료 는 물론 이 고 양념 이나 소스 도 모노 마트 제 는 전혀 쓰 질 않 고 그 대부분 을 직접 만든다 하 는데 그게 맞 는 것 같이 느껴 지 더군요 . 특히 공 이 많이 드 는 장어구이 소스 는 전문점 이 아닌 한 은 공장 제 를 쓰 는 게 일반 적 이 죠 . 이건 장어구이 만 나오 는 것 이 고 , 양 과 가격 이 부담 스럽 다면 덮밥 으로 고르 면 되 겠 습니다 . 청주 의 안주 로 제격 이 겠 네요 , 단맛 이 있 기 에 술 은 가급적 드라이 ( 카라 구치 ) 한 것 으로 . . 블랙 치킨 이 란 이름 의 닭튀김 입니다 . ' 흑 형 치킨 ' 이 라는 음식 이 연상 되 지만 어떤 유사 성 이 있 는지 는 모르 겠 군요 . 흑 형 치킨 을 먹 어 보 질 않 아서 ;; 일본풍 의 양념치킨 내지 는 닭강정 이 라고 해야 할까요 . 그 와 유사 하 단 뜻 은 아닙니다 . 반죽 과 나중 에 입히 는 양념 에 비밀 이 있 겠 지만 , 고소 함 과 달 큰 함 이 강한 게 괜찮 은 맛 입니다 . 특히 , 맥주 안주 로 게 발 이 된 게 아닌가 싶 게 잘 어울립니다 . 치킨 ( 닭튀김 ) 애호가 라면 경험 해 보 라 권하 고 싶 습니다 . 고구마 맛 탕 도 곁들여져 있 네요 . 함께 제공 되 는 양배추 샐러드 . 돈 까스 입니다 . 이렇게 두 조각 이 나오 는 경우 하나 는 안심 하나 는 등심 일 때 가 흔한데 여기 는 같 은 등심 이 라고 하 더군요 . 그런데 , 두툼 하 며 육질 이 좋 고 잘 익혀 졌으며 소스 도 잘 어울려서 유명 전문점 을 싸대 기 치 고 도 남 을 솜씨 로 생각 됩니다 . 먹거리 x 파일 에서 착한 식당 으로 돈 까스 집 을 선정 한다며 홍대 유명 업소 들 을 다녔 던 지난 여름 이 떠오르 는군요 . 어찌 하나 같이 그리도 형편 없 던지 원 ;;;; 결국 서울 에서 는 찾 지 못하 고 제주 에서 발견 했 지만 업주 가 출연 을 고사 해서 선정 치 못했었 죠 . 고등어구이 덮밥 . 꾀리 고추 와 매실 절임 이 얹혔 습니다 . 일본 에서 는 고등어구이 를 덮밥 으로 하 지 는 않 는데 오너 셰프 가 고안 해 낸 것 이 라는군요 . 여기 가 ' 발상지 ' 가 될 메 ㅐ뉴 겠 죠 . 조만간 일본 오사카 에 진출 할 예정 이 라는데 그 에 앞서 일본 의 요리 스승 님 께 자문 을 구했 더니 충분히 승산 이 있 다는 평가 를 받 았 다는군요 . 저 도 이 음식 의 개성 과 완성도 에 있 어서 일본인 들 의 반응 이 나쁘 지 는 않 을 것 이 라 예상 을 합니다 . 그걸 떠나 서 , 고등어 + 구이 + 양념 + 덮밥 이런 각 구성 요소 들 이 일본인 들 에게 매우 친숙 하 며 선호 되 는 것 들 이 죠 . 일본식 냉면 이 한국 에 상륙 하 여 참패 를 겪 은 것 과 는 다른 차원 의 접근 이 되 리라 봅니다 . 이번 게시물 은 사진 이 좀 수다 스럽 네요 . ^^; 일본 술 투입 . 그 나라 음식 과 가장 잘 어울리 는 것 은 그 나라 술 이 죠 . 앞서 의 독일 식당 에서 도 그랬 고 우리 음식 도 그렇 듯 일본 도 마찬가지 . ' 카라 이 나베 ' 라고 해서 우리 식 으로 는 얼큰 전골 쯤 되 겠 습니다 . 조개 오징어 새우 등 의 해산물 들 과 버섯 채소 가 들어가 는 얼큰 한 국물 의 냄비 요리 입니다 . 술안주 로 여럿 이 나눠 먹 기 좋 겠 죠 . 사진 이 많 아서 나눠 올립니다 . 계속 해서 보 시 려면 여기 를 클릭 ! !\",\n",
       "       \"상대 적 으로 저렴 하 며 대중 적 인 음식 종류 를 소개 해 달 라는 요청 이 있 어서 올려 봅니다 . 사실 만 원 가까운 가격 이 다 보 니 저 렴 과 는 거리 가 좀 있 기 는 하 지만 , 근래 에 블로그 에 올려졌 던 식당 과 해외 여행기 에 비교 하 면 그렇 다는 이야기 입니다 . 사 누끼 우동 집 으로 주목 을 받 고 있 는 곳 이 죠 . 위치 가 애매 함 에 도 방송 도 타 면서 더욱 유명 해져서 항시 손님 들 로 가득 합니다 . 합정역 에서 절두 산 순교 성지 쪽 으로 가 다 중간 쯤 에 있 습니다 . 매우 일본 스러운 외양 . 교다 이야 의 뜻 이 무엇 인지 는 쉽 게 아실 수 있 죠 . 실제로 형제 가 운영 하 는지 는 모르 겠 습니다만 . . 제대로 의 사 누끼 우동 은 수타 를 넘어서 서 족 타 ( 반죽 을 양발 로 밟 아 물 과 공기 를 빼내 는 작업 ) 의 단계 까지 도달 해야 하 죠 . 그래야 탄력 의 강도 와 지속력 이 일반 우동 면발 을 뛰어넘 게 됩니다 . . 방송 출연 의 효과 가 가라앉 아서 인지 대기 없이 입장 . 지난 3 월 의 방문 이 었 습니다 . 홍대 에서 의 모임 을 마치 고 2 차 로 들렸 던 . .. 제 면실 이 보이 고 이 시간 에 도 면 을 만들 기 에 바쁩니다 . 보통 의 우동 집 들 은 미리 삶 아 둔 것 을 쓰 는데 보통 은 삶 아 둔 것 을 두세 시간 에 걸쳐 사용 하 죠 . 사 누끼 우동 은 그랬다간 큰일나 고 . ... 여기 서 재미난 사실 하나 가 . ... 이 곳 의 오너 셰프 가 분당 의 야마다 야 출신 이 라는군요 . 저 에게 그리 좋 지 는 않 은 평 을 받 았 던 야마다 야 죠 . 사 누끼 우동 애호가 의 한 사람 으로 좀 ㄷ 당황 스러웠 던 그 집 의 우동 이 었 기에 . .. 그때 의 게시물 을 보 지 못했 거나 기억 이 가물거리 는 분 은 여기 를 클릭 ! ! 사람 들 이 사 누끼 가 정확히 뭔지 모를 때 여서 그 정도 로 대단 한 인기 를 누렸 다는 게 참 부러울 따름 인 야마다 야 . 지금 은 달라졌 을려나 . .... 아무튼 , 그런 곳 출신 이 면서 그 보다 월등히 잘 하 고 있 다는 것 은 청출어람 일지 아니 면 타산지석 일지 혹은 서 필경 . ... 아니 , 이건 아니 고 . ..;; 아무튼 , 제 입장 에서 는 야마다 야 출신 이 란 것 은 부정 적 인 이미지 를 주 기 는 합니다만 현재 의 성과 가 좋 으니 그냥 넘어가 도록 하 겠 습니다 . 바로 반죽 해서 쓰 는 칼국수 와 는 달리 우동 은 반죽 하 여 손 으로 혹은 발 로 치대 며 공기 와 물 을 빼낸 후 숙성 을 거쳐 사용 합니다 . 그러 며 탄력 이 생기 고 말 가루 내 가 훨씬 줄어들 게 되 죠 . 칼국수 의 면발 이 쫄깃 한 것 은 우동 처럼 숙성 을 시켜서 도 있 겠 지만 대부분 은 첨가물 을 넣 어서 그렇게 만듭니다 . 대표 적 인 것 이 명반 등 의 화학 첨가물 과 글루텐 분말 . 그래서 칼국수 집 의 면발 이 유난히 쫄깃 하 면 저 는 멀리 하 죠 . 집 에서 해 먹 듯 꾸득 하 여야 정상 이 니 . .. 표지 껍닥 . 우동 을 주문 하 면 국수 그릇 만 나오 는 게 아니 라 이렇게 정식 스럽 게 구성 됩니다 . 실제 정식 종류 는 여기 에 초밥 이 하나 더 나오 고 튀김 과 후식 도 곁들여 지 는 . . 가마 붓 카 케 우동 . 기본 구성 의 유부 초밥 한 개 . 정체불명 국적 불명 의 롤 한 개 주 는 것 보다 이게 훨씬 낫 죠 . 단 품 으로 주문 해도 괜찮 을 만큼 신경 써 만들 었 습니다 . 촉촉 한 일본 의 유부 초밥 과 는 달리 국내 일본 식당 이나 우동 집 들 의 것 은 어찌 그리 하나 같이 퍽퍽 한지 . ... 아마 잔뜩 만들 어서 냉장고 에 넣 어 뒀 다 쓰 기 때문 이 아닌가 싶 죠 . 일본 우동 과 우리 우동 의 차이 중 하나 가 생강 다진 것 입니다 . 일본 에서 는 거의 대부분 넣 어서 들 드십니다 . 우리 의 칼국수 보다 밀가루 냄새 가 훨씬 적 은 것 이 일본 우동 입니다 . 숙성 을 거치 기 떄문 이 죠 . 그럼에도 혹시나 있 을지 모를 미세 한 냄새 조 차 거북 해 하 는 분 들 을 위해 생강 다진 것 을 제공 하 고 의례 넣 어서 먹 고 들 있 는 . .. 그러 고 보 니 , 저 도 아무 생각 없이 항상 넣 어 먹 습니다 . 처음 부터 그렇게 배우 서의 습관 이 고 익숙 함 이 어서 일 듯 . 밀가루 내 따위 때문 이 아닌 . . 저 와 마찬가지 로 일본인 들 상당수 는 밀가루 냄새 때문 이 라기 보다 는 그렇게 배워서 의 익숙 함 으로 생강 을 넣 겠 죠 . 순대 국밥 에 새우젓 넣 고 크림 스프 에 후 추가 루 치 듯 . 직접 만들 었 는지 ( 가능 성 은 적 을 것 같 습니다 만 ) 혹은 공장 제 를 다시 손 봤 는지 단무지 가 서걱거리 지 않 고 꼬 들 하 네요 . 야마다 야 시절 의 흔적 일 듯 . 저 에게 는 별 의미 없 는 구성 요소 . 가마 붓 카 케 는 면 을 삶 아 그대로 그릇 에 담아내 어 양념간장 으로 비벼 먹 는 우동 입니다 . 거기 에 달걀 반숙 까지 포함 되 어 취향 에 따라서 추가 로 넣 죠 . 이건 자루 붓 카 케 우동 . 그릇 이 야마다 야 의 것 과 동일 하 네요 . 이건 삶 은 면발 을 찬물 에 헹궈서 차갑 게 하 여 양념간장 을 뿌려 비벼 먹 습니다 . 여기 에다 반숙 달걀 을 추가 주문 했 더니 아까 와 는 달리 튀긴 것 으로 나오 는군요 . 제 가 시킨 우동 이 아니 라서 다행 . 저 의 선택 은 자루 우동 입니다 . 자루 소바 처럼 차가운 면 을 양념간장 ( 쯔 유 ) 에 적셔 먹 습니다 . 이날 주문 한 우동 들 은 하나 같이 국물 이 없 죠 . 전 에 도 말씀 드렸 지만 , 사 누끼 우동 은 오사 까 나 도 꾜식 우동 들 과 는 달리 국물 이 아닌 면발 자체 를 즐기 는 음식 입니다 . 그러 다 보 니 , 현지 의 우동 명 점 들 에 가 도 국물 을 어떻 게 내 는지 에 대한 자랑 은 찾아보 기 어렵 고 면발 에 만 홍보 를 집중 합니다 . 토핑 으로 더 해 지 는 튀김 도 큰 의미 를 두 지 않 습니다 , . 그러 다 보 니 , 대부분 의 업소 들 은 갓 튀겨 의 따끈 바삭 한 게 아닌 미리 튀겨 두 어 상온 상태 의 눅눅 한 튀김 조각 을 우동 에 얹 어 냅니다 . 동경 식 이나 오 사 까 식 에 익숙 한 한국 분 들 은 그 에 당황 하 죠 . 국물 은 대부분 그냥 공장 제 를 쓰 고 튀김 이 그 모양 이 니 . .. 마찬가지 로 , 일본 의 타 지역 분 들 또한 그런 면 에서 사 누끼 우동 에 대한 호불호 가 강하 게 갈립니다 . 일본인 이 라고 해서 모두 가 사 누끼 우동 을 좋아하 는 게 아니 라는 말씀 . 저 또 한 사 누끼 우동 은 굵 은 면발 의 탄력 감 을 즐기 기 위해서 먹 기에 이런 자루 우동 종류 를 가장 좋 아 합니다 . 토핑 은 관심 없 고 . . 또한 차가운 면발 이 라야 제대로 의 탄력 감 을 느낄 수 있 어서 따뜻 한 종류 로 는 주문 을 잘 않 습니다 . 한 겨울 의 엄동설한 일 망정 . 겨울 이 라고 평 냉 냉면 대신 온 명 이나 잔치국수 를 주문치 는 않 듯 말 이 죠 . 이 집 면발 좋 습니다 . 얼마 전 에 소개 한 분당 야탑 의 겐 우동 도 괜찮 기 는 한데 면발 로 놓 고 보 자면 이 집 의 85 % 정도 라고 봐야 겠 네요 . 면발 하나 만 놓 고 보 자면 국내 에서 몇 손가락 안 에 들 겠 고 , 그 외 의 요소 ( 국물 이나 토핑 등 ) 도 중요시 여기 는 한국 의 일반 소비자 들 의 관점 에서 는 등수 가 각자 의 취향 에 따라 좀 달라질 듯 합니다 . good : 솜씨 있 는 면발 의 사 누끼 우동 을 만나 는 반가움 . bad : 야마다 야 에 트라우마 가 있 는 이 에게 는 곳곳 의 흔적 들 이 반갑 지 않 을지 도 . 우동 만 내 며 가격 도 낮춘 메뉴 는 생각 없 는지 . . don ' t miss : 사 누끼 우동 은 면발 탄력 을 즐기 는 것 임 을 잊 지 말 자 . 따뜻 한 국물 에 다양 한 토핑 의 우동 을 원한다면 도쿄 식 이나 오사카 식 을 파 는 곳 으로 가 라 . me ? : 이 집 이 낫 지만 위치 상 강남역 의 마루가메 제면 을 더 자주 가 게 된다 . 멀리 사 는 형제 보다 가까이 의 친구 가 더 낫 다는 속담 처럼 인가 . ... 메뉴 는 여기 를 클릭 ! ! 교다 이야 서울시 마포구 성지 길 39 02 - 2654 - 2654 ( 번호 좋 다 ! ! )\",\n",
       "       '네트워크 파일 시스템 ( nfs ) 를 사용 할 경우 간단 하 게 파일 들 을 공유 할 수 있 습니다 . 이 를 처음 마운트 하 고 재 부팅 시 에 도 연결 이 지속 되 도록 하 는 명령어 예요 . nfs 마운트 하 는 명령어 1 . 먼저 연결 할 디렉 토리 를 생성 한다 . $ mkdir nfsdata 2 . nfs 디렉 토리 를 연결 한다 . sudo mount - t nfs ip 주소 : 절대경 로 위치 생성 한 디렉 토리 ex ) $ sudo mount - t nfs 10 . 254 . 0 . 5 : / shares / data nfsdata 여기 까지 하 면 재 부팅 전 까지 는 계속 연결 이 되 어 있 지만 재 부팅 을 했 을 경우 끊기 기 때문 에 2 번 을 수행 해야 붙 습니다 . 이 를 부팅 시 바로 붙이 기 위해서 는 / etc / fstab 에 아래 사항 을 추가 하 면 됩니다 . ip 주소 : 절대경 로 위치 생성 한 디렉 토리 ( 절대 경로 ) nfs tcp , nolock 0 0 ex ) 10 . 254 . 0 . 5 : / shares / data / home / ubuntu / nfsdata nfs tcp , nolock 0 0 혹시 설정 도중 access denied by server while mounting 문제 가 뜰 경우 nfs 서버 쪽 / etc / exports 에 파일 권한 설정 을 해야 합니다 .',\n",
       "       'msi pe 60 - 2 qe 노트북 을 새로 구입 하 고 나 서 windows 10 을 처음 설치 하 였 습니다 . 원래 가 windows 10 에 최적 화 된 노트북 이 어서 windows 를 설치 후 불량 여부 판단 확인 후 에 리눅스 를 설치 를 하 려고 했 습니다 . 그런데 , 우분투 리눅스 를 설치 하 려니 여러 가지 문제점 들 이 많 았 는데요 . 이 문제점 찾 느라 1 개월 정도 시간 이 걸렸 습니다 . 사실 원래 nvidia 의 리눅스 드라이버 가 호환 성 이 딱히 좋 지 않 았 습니다 . 아 시 다시피 optimus 기술 을 사용 하 는 노트북 제품 은 정식 드라이버 가 없 어서 2 년 전 까지 만 해도 비 공식 드라이버 인 bumblebee 를 사용 해 여야 했었 죠 . . 그러나 이 는 nvidia 그래픽 드라이버 를 사용 하 는 데 문제 였 지만 x 를 구동 하 는 데 도 방해 가 될 줄 은 상상 도 하 지 못했 습니다 . nouveau 우리말 로 하 면 최근 이 라는 의미 를 가지 고 있 는 이 단어 는 우분투 리눅스 에서 x org server 와 연관 이 있 습니다 . nvidia 계열 의 그래픽 카드 ( 특히 노트북 에서 문제 가 자주 있 음 ) 를 사용 하 는 제품 에서 추가 드라이버 로 기본 live cd 에 도 들어가 는 드라이버 입니다 . 그런데 , 이 드라이버 가 nvidia 제품 과 호환 성 이 매우 좋 지 않 아 x server 로드 를 방해 하 고 , 심지어 는 kernel panic 을 일으키 기 도 합니다 . nouveau e [ pfifo ] [ 0000 : 01 : 00 . 0 ] sched _ error 보통 nouveau 와 nvidia 그래픽 의 호환 성 의 문제 가 생기 는 위 오류 로 화면 을 도배 하 기 도 합니다 . 그러나 잠깐 은 화면 이 뜨 기 도 하 는데 , 그러다가 어차피 는 다운 되 므로 별 기대 를 안 하 시 는 것 이 좋 습니다 ㅡㅡ ^ 설치 할 때 만약 이런 오류 가 나타난다면 nouveau 를 off 하 고 설치 하 면 되 는데요 . 그런데 , 이 off 를 하 는 방법 에 도 두 가지 로 분류 됩니다 . 1 . legacy ( bios ) 를 사용 하 시 는 pc / 노트북 2 . efi ( uefi ) 를 사용 하 시 는 pc / 노트북 어차피 우분투 리눅스 를 부팅 하 는 옵션 을 수정 하 는 것 은 똑같이 grub 를 수정 하 기 때문 에 원리 만 이해 하 신 분 이 시 라면 굳이 저 두 가지 로 분류 하 는 게 무슨 의미 가 있 느냐 라는 말씀 도 하 실지 모르 겠 지만 초보 자분 들 을 위해서 두 가지 분류 로 나눠서 설명 하 도록 하 겠 습니다 . 1 . bios 를 사용 하 는 경우 , , 설치 cd / dvd , usb 로 부팅 하 시 게 되 면 우분투 설치 초기 화면 이 나타납니다 . 이 때 키보드 에서 f 6 을 누르 게 되 면 nomodeset 이 보이 게 됩니다 . 바로 저 nomodeset 옵션 을 추가 해 주 면 nouveau x 서버 를 올리 지 않 고 부팅 하 게 됩니다 . windows 로 말 하 자면 표준 vga 어댑터 로 그래픽 드라이버 를 로드 시킨 다음 에 부팅 한다는 것 이 죠 . 2 . uefi 를 사용 하 는 경우 , , uefi 로 부팅 하 게 될 경우 , install ubuntu 나 trying ubuntu with install 메뉴 에서 키보드 e 를 누르 면 위 화면 처럼 부팅 옵션 을 수정 할 수 있 는 화면 을 보여 줍니다 . 위 화면 과 실제 내용 이 다를 수 있 지만 흡사 합니다 . 여기 서 quiet splash 부분 옆 에 nomodeset 을 추가 로 입력 한 후 키보드 f 10 을 눌러 부팅 합니다 . ubuntu 설치 후 nouveau off 하 는 법 그렇 게 설치 가 끝 났 는데 , 부팅 을 하 려니 또 nouveau 가 활성 화 되 면서 이번 엔 실 부팅 이 안 된다 . .. 조금 눈치 가 있 으신 분 들 이 라면 이미 grub 에서 nomodeset 을 추가 해서 하 시 는 분 들 도 있 겠 지만 저 는 다른 방법 으로 좀 더 쉽 게 ( ? 아닐 수 도 있 습니다 ㅠㅠ ) 하 는 법 을 적 어 보 도록 하 겠 습니다 . 우분투 설치 후 부팅 하 게 되 면 위 화면 과 같이 recovery mode ( 복구 모드 ) 로 들어갈 수 있 는 메뉴 가 있 씁니다 . 그 쪽 메뉴 를 통해서 부팅 합니다 . 부팅 이 끝나 면 위 화면 이 나타납니다 . 여기 서 failsafex 메뉴 를 선택 한 후 ok 합니다 . 그러 면 nouveau off 상태 로 부팅 됩니다 . 자 이제 nouveau 를 블랙리스트 에 추가 하 여 실행 을 못 하 게 하 고 , 커널 에 nouveau = 0 을 추가 하 여 로드 하 는 과정 을 진행 하 면 정상 적 인 우분투 리눅스 를 사용 할 수 있 게 됩니다 . 먼저 root 권한 으로 터미널 을 실행 합니다 . vim 혹은 nano 등 의 에디터 를 이용 하 여 / etc / modprobe . d / blacklist - nouveau . conf 라는 이름 의 파일 을 생성 하 고 다음 내용 을 추가 합니다 . blacklist nouveau blacklist lbm - nouveau options nouveau modeset = 0 alias nouveau off alias lbm - nouveau off 다 입력 하 셨 으면 저장 하 고 터미널 로 다시 되돌아옵니다 . # echo options nouveau modeset = 0 | sudo tee - a / etc / modprobe . d / nouveau - kms . conf nouveau 옵션 을 0 으로 바꿔 줍니다 . # update - initramfs - u 그리고 그 설정 값 을 커널 에 포 팅 하 면 모든 작업 이 끝납니다 . tip 혹시 nouveau 옵션 을 바꿔 주 는 부분 에서 에러 가 나타날 경우 , 다음 소프트웨어 를 설치 후 진행 하 세요 . $ sudo apt - get install dkms build - essentials linux - header - generic linux - header - generic 은 기본 커널 바탕 으로 대부분 깔려 있 겠 지만 dkms 나 build - essentials 은 커널 컴파일 시 사용 되 는 툴 로 일반 적 으로 설치 가 안 된 경우 가 있 으므로 참고 하 시 기 바랍니다 .',\n",
       "       'introduction 얼마 전 지인 중 한 명 이 다음 의 문제 를 페이스북 에 공개 하 였 다 . 흥미 로운 부분 이 있 기 에 이 를 논해 보 고자 한다 . 학교 에서 집 까지 가 는 방법 은 버스 a 를 타 고 10 분 동안 이동한 뒤 내려서 5 분 동안 걸어가 는 방법 과 버스 b 를 타 고 8 분 동안 이동한 뒤 내려서 1 분 동안 걸어가 는 방법 이 있 다 . 버스 a 의 배차 간격 은 3 분 이 고 버스 b 의 배차 간격 은 15 분 이 라고 알려져 있 다 . ( 위 의 상수 는 임의 의 숫자 로 변경 될 수 있 음 ) seoulbus 나 버스 정류장 의 전광판 등 버스 의 도착 예정 시간 을 알 수 있 는 방법 이 없 다고 할 때 , 어떤 기준 으로 버스 를 타 야 도착 시간 의 기대 값 을 가장 빠르 게 할 수 있 을까 ? 문제 가 조금 은 복잡 해 보이 지만 정리 해 보 면 다음 과 같 다 . 버스 a : 배차 3 분 이동 15 분 버스 b : 배차 15 분 이동 9 분 얼핏 생각 해 보 면 평균 적 으로 버스 a 를 기다리 는 시간 은 1 . 5 분 이 고 버스 b 는 7 . 5 분 으로 각각 더 하 면 16 . 5 분 의 같 은 값 을 갖 는 걸로 보인다 . 그렇 다면 나 의 전략 은 가장 먼저 오 는 버스 를 타 는 것 일 터 이 다 . 과연 그럴까 ? 문제 설명 에 주어진 것 만 으로 는 이 문제 를 풀 수 없 다 . 몇 가지 추가 적 인 가정 이 필요 한데 , 가령 배차 간격 의 분포 등 이 필요 하 다 . 그리고 그 가정 에 의해 문제 의 복잡도 가 달라지 는데 이 는 length time bias 때문 이 다 . length time bias 만약 버스 가 정확 하 게 15 분 혹은 3 분 의 배차 간격 을 두 고 운행 이 된다면 , 평균 적 으로 내 가 버스 를 기다리 는 시간 은 각각 7 . 5 분과 1 . 5 분 이 된다 . 하지만 정확 하 게 시간 을 지키 지 않 고 평균 적 으로 그 정도 의 시간 만 지키 면서 조금 씩 달라질 수 있 다면 결과 가 달라지 게 된다 . 왜냐하면 버스 배차 간격 이 긴 경우 에 내 가 정류장 에 도달 할 확률 이 그렇 지 않 은 경우 보다 높 기 때문 이 다 . 앞서 지나간 버스 와 이 를 뒤따르 는 버스 사이 의 시간 간격 을 배차 간격 이 라 하 자 . 배차 간격 이 주어진 경우 에 승객 이 정류장 에 도달 하 는 것 은 균등 분포 를 따른다 . 그러므로 기대 대기 시간 은 배차 간격 의 절반 이 된다 . 하지만 승객 이 정류장 에 도착 하 는 것 이 균등 하 다면 더 큰 배차 간격 에 떨어질 확률 이 높 다 . 위 의 이미지 에서 $ x _ i $ 는 배차 간격 , $\\\\ bar { w }$ 는 평균 대기 시간 이 다 . 이 는 위 의 삼각형 으로 이루어진 함수 의 평균 값 이 된다 . $$\\\\ bar { w } = \\\\ frac { 1 }{ t } \\\\ sum _{ i = 1 }^ n \\\\ frac { 1 }{ 2 } x _ i ^ 2 $$ 평균 대기 시간 은 전체 시간 인 $ t $ 를 버스 의 총 개수 인 $ n $ 으로 나눈 값 이 므로 , $$\\\\ bar { w } = \\\\ frac { 1 }{ 2 }\\\\ frac {\\\\ bar { x ^ 2 }}{\\\\ bar { x }}$$ 이 다 . poisson / exponential 분포 만약 버스 가 도달 하 는 사건 이 푸아송 분포 를 따른다면 , 그 배차 간격 은 지수 분포 를 따를 것 이 며 다음 의 수식 을 만족 한다 . $$ var ( x ) = \\\\ bar { x }^ 2 $$ 그리고 분산 은 제곱 의 평균 - 평균 의 제곱 이 므로 , $$\\\\ bar { x ^ 2 } = 2 \\\\ bar { x }^ 2 $$ 이 를 활용 하 면 , $$ \\\\ bar { w } = \\\\ bar { x }$$ 가 된다 . 사실 이런 방법 을 쓰 지 않 더라도 지수 분포 는 memoryless 성질 이 있 어서 승객 의 도착 시간 과 무관 하 게 평균 대기 시간 은 항상 같 으므로 $\\\\ bar { w } = \\\\ bar { x }$ 임 을 알 수 있 다 . 정규 분포 $$ var ( x ) = \\\\ sigma ^ 2 $$ 위 와 같 은 방법 을 사용 하 면 , $$\\\\ bar { x ^ 2 } = \\\\ sigma ^ 2 + \\\\ bar { x }^ 2 $$ 이 를 똑같이 대입 하 면 , $$\\\\ bar { w } = \\\\ frac { 1 }{ 2 }\\\\ frac {\\\\ sigma ^ 2 + \\\\ bar { x }^ 2 }{\\\\ bar { x }}$$ 이 다 . 만약 배차 간격 이 정확 하 게 지켜진다면 분산 은 0 이 되 고 그렇 다면 $\\\\ bar { w } = \\\\ frac { 1 }{ 2 } \\\\ bar { x }$ 가 될 것 이 다 . 엄밀 하 게 말 하 자면 정규 분포 는 음 의 값 을 가질 수 있 으므로 배차 간격 을 모델링 하 기 에 적합 하 지 않 다 . 하지만 현실 에서 는 버스 사이 의 배차 간격 을 운전수 들 이 조절 하 려고 노력 하 기 때문 에 ( 표준 편차 가 현실 적 이 라면 ) 배차 간격 이 지수 분포 를 따르 지 않 는 경우 를 모델 링 할 수 있 을 것 이 다 . 전략 버스 배차 간격 이 지수 분포 를 따른다면 자명 하 게 먼저 오 는 버스 를 타 는 것 이 가장 좋 은 전략 이 다 . 버스 b 가 먼저 도착 한다면 당연히 버스 b 를 타 는 것 이 좋 고 , 버스 a 가 먼저 도착 하 더라도 버스 b 가 도착 하 기 까지 의 기대 대기 시간 이 15 분 이 기 때문 이 다 . 만약 버스 배차 간격 이 정규 분포 를 따른다면 어떨까 ? 버스 b 가 먼저 도착 하 면 당연히 버스 b 를 타 면 된다 . 버스 a 가 먼저 도착 한다면 다음 버스 b 가 도달 하 는 시간 을 추론 해 볼 수 있 다 . 내 가 버스 a 를 $\\\\ alpha $ 분 만큼 기다렸 다면 버스 b 가 도착 하 기 까지 평균 적 으로 $\\\\ frac {\\\\ sigma ^ 2 + 225 }{ 30 } - \\\\ alpha $ 분 남 았 다고 생각 할 수 있 다 . ( 분산 이 충분히 작 아서 무시 할 수 있 다고 가정 하 면 ) 남 은 평균 대기 시간 은 $ 7 . 5 - \\\\ alpha $ 분 이 다 . 지금 당장 버스 a 를 타 면 15 분 후 에 집 에 도착 하 게 되 고 , 버스 b 를 기다렸 다가 타 면 평균 적 으로 $ 7 . 5 - \\\\ alpha + 9 = 16 . 5 - \\\\ alpha $ 분 후 에 집 에 도착 하 게 된다 . 결국 내 가 1 . 5 분 이상 버스 a 를 기다렸 다면 , 버스 b 가 오 기 를 기다렸 다가 버스 b 를 타 고 내려가 는 것 이 평균 적 으로 집 에 더 빠르 게 도착 하 는 방법 이 된다 . discussion 이번 글 에서 는 아주 간략 하 게 length time bias 를 소개 하 고 이 에 따른 버스 대기 시간 의 변화 에 대해 논하 였 다 . 그리고 아주 단순 한 전략 을 소개 하 였 는데 , 다음 글 에서 는 최적 전략 이 무엇 인지 알아보 도록 하 겠 다 .',\n",
       "       '시 놀 로지 외부 액세스 설정 으로 외부 에서 접속 하 기 시 놀 로지 외부 액세스 설정 으로 외부 에서 접속 하 기 편 입니다 . synology ds 1513 + 를 놓 고 예시 를 보여 드리 겠 습니다 . 유무 선 공유기 는 디링크 dir - 850 l 을 쓰 고 있 는 상태 라고 해 보 죠 . 그리고 초보 자 가 셋 팅 하 는 방법 을 기준 으로 설명 합니다 . 설명 드리 면 어렵 진 않 습니다 . 시 놀 로지 외부 액세스 설정 으로 ftp 를 외부 에서 접속 해 보 도록 하 죠 . 포트 포워딩 및 복잡 한 설정 은 잘 모르 겠 고 간단히 연결 설정 만 해서 ftp 접속 해서 쓰 는 방법 만 소개 하 겠 습니다 . 물론 좀 더 세부 옵션 을 조정 하 면 다양 한 접속 이 가능 하 며 여기 서 는 쉬운 단계 를 보여 드리 기 위해서 아래 설명 만 하 겠 습니다 . 시 놀 로지 외부 액세스 설정 은 말 그대로 외부 에서 nas 를 접근 할 수 있 도록 셋 팅 을 하 는 것 을 말 합니다 . 그런데 여기 에서 복잡 하 려면 얼마 든지 복잡 해질 수 있 습니다 . 포트 포워딩 도 필요 하 고 ddns 도 있 으면 좋 고 . 근데 복잡 하 죠 . 간단히 설명 드리 죠 . 시 놀 로지 외부 액세스 설정 ftp 써 보 기 ds 1513 + 을 집 에 켜 놓 았 습니다 . 저 는 노트북 을 들 고 외부 로 나왔 습니다 . 그런데 갑자기 nas 에 들 어 있 는 이미지 를 다운로드 받 아야 합니다 . 그것 도 다량 의 파일 을 말 이 죠 . 노트북 으로 받 아야 하 고 노트북 은 지금 무선 으로 유무 선 공유기 에 연결 이 되 어 있 습니다 . ftp 로 접속 해서 받 으려면 뭘 해 놓 아야 할까요 ? 아래 에서 알아보 죠 . 시 놀 로지 외부 액세스 설정 ftp 설정 가능 하 면 쉽 게 설명 드리 죠 . 먼저 집 에서 웹 브라우저 를 열 기 합니다 . [ URL ] 이 라고 주소 에 입력 하 면 위 와 같 은 화면 이 뜹니다 . ( 사진 상 에서 주소 는 제 가 설명 드리 기 위해서 외부 에서 접속 해서 외부 주소 가 떠 있 습니다 . ) admin 로그인 을 하 고 난 뒤 , 제어판 을 실행 합니다 . 왼쪽 메뉴 에서 파일 서비스 를 선택 합니다 . ftp 서비스 활성 화 를 체크 합니다 . utf - 8 파일 이름 지원 활성 화 도 체크 합니다 . 한글 파 일 명 을 ftp 에서 쓰 기 위해서 입니다 . ftp 포트 는 제 경우 에 는 21 번 이 막혀 있 어 2121 으로 하 였 습니다 . 이제 ftp 활성 화 가 끝났 습니다 . ftp 클라이언트 프로그램 을 실행 후 아이디 암호 를 입력 하 면 해당 유저 의 파일 들 이 나타납니다 . 다만 이것 은 내부 네트워크 망 에서 만 연결 이 잘 됩니다 . 외부 에서 하 려면 유무 선 공유기 내 에 있 는 nas 로 접근 이 안 됩니다 . 그래서 아래 의 과정 을 거칩니다 . 제어판 에서 왼쪽 메뉴 중 [ 외부 엑세스 ] 를 선택 합니다 . ddns 에서 추가 버튼 을 누릅니다 . ( 제 경우 에 는 이미 ddns 가 동작 중 이 여서 아래 에 주소 가 나타납니다 . 처음 에 는 없 다는 가정 하 에 진행 합니다 . ) ddns 지원 활성 화 를 체크 합니다 . 서비스 제공 업체 는 synology 를 선택 합니다 . 참고 로 이것 외 에 도 다양 한 무료 및 유료 ddns 를 활용 할 수 있 습니다 . 위 와 같이 양식 에 맞 게 입력 을 한 뒤 연결 테스트 를 누릅니다 . 연결 이 완료 되 었 습니다 . 상단 메뉴 중 라우터 구성 을 선택 합니다 . 라우터 설정 버튼 을 누릅니다 . 자동 으로 유무 선 공유기 설정 을 불러온 뒤 적용 버튼 이 뜹니다 . 이 과정 에서 포트 를 지정 하 는 부분 이 나타날 수 있 습니다 . 이 때 ftp 를 체크 를 합니다 . 적용 을 누릅니다 . 참고 로 직접 생 성 버튼 을 누른 뒤 ftp 를 체크 할 수 도 있 습니다 . ftp 를 찾 아서 체크 후 적용 버튼 을 누릅니다 . 체크 가 된 상태 에서 저장 을 누릅니다 . 연결 테스트 를 눌러서 연결 이 잘 되 는지 테스트 할 수 있 습니다 . 이제 외부망 에서 ftp 클라이언트 를 실행 후 주소 에 는 ddns 의 주소 를 아이디 암호 는 유저 계정 의 아이디 암호 를 입력 해서 접속 해 봅니다 . 접속 이 잘 되 는 것 을 볼 수 있 습니다 . 위 와 같 은 방법 으로 ftp 는 물론 다른 서비스 들 도 포트 를 개방 해서 쓸 수 있 습니다 .',\n",
       "       '서울시 covid 19 심리 지원 단과 서울시 자살 예방 센터 에서 는 아시아 최초 로 비대 면 기반 으로 생명 지킴이 ( gatekeeper ) 를 양성 하 는 s - 생명 지기 교육 프로그램 을 개발 해 시민 들 에게 첫 선 을 보입니다 . 우리 가족 과 이웃 의 소중 한 생명 을 지키 는 s - 생명 지 기 ! 서울 시민 여러분 의 많 은 참여 를 기다립니다 .',\n",
       "       \"고등학교 수학 에서 조건부 확률 이 라는 걸 배운다 . 그런데 그게 나중 에 가 면 베이지안 확률 이 라는 이름 으로 불리 면서 사람 을 엄청 햇갈리 게 한다 . 1 . 베이즈 정리 베이즈 정리 ( bayes ' s theorem ) 또는 베이즈 룰 ( rule ) , 베이즈 법칙 ( law ) 라고 불리 는 이 녀석 은 결국 다음 과 같 은 조건부 확률 계산 식 이 다 ( x : 모델 , z : 관측 ) . 베 이지언 확률 은 사후 확률 ( posterior probability ) 을 사전 확률 ( prior probability ) 과 likelihood 를 이용 해서 계산 할 수 있 도록 해 주 는 확률 변 환식 이 다 . 베이지안 확률 은 영상 처리 에서 classification 문제 , detection 문제 가 나오 면 거의 빠지 지 않 고 나오 는 약방 의 감초 같 은 존재 로서 , 사람 들 이 자신 의 방법 론 에 대해 무언가 수학 적 모델 이 필요 할 경우 에 1 차 적 으로 생각 하 는 게 바로 베 이지언 확률 이 다 . ☞ likelihood : p ( z | x ) , 어떤 모델 에서 해당 데이터 ( 관측 값 ) 이 나올 확률 ☞ 사전 확률 ( prior probability ) : p ( x ) , 관측자 가 관측 을 하 기 전 에 시스템 또는 모델 에 대해 가지 고 있 는 선험 적 확률 . 예 를 들 어 , 남여 의 구성비 를 나타내 는 p ( 남자 ) , p ( 여자 ) 등 이 사전 확률 에 해당 한다 . ☞ 사후 확률 ( posterior probability ) : p ( x | z ) , 사건 이 발생 한 후 ( 관측 이 진행 된 후 ) 그 사건 이 특정 모델 에서 발생 했 을 확률 2 . ml 와 map 확률 을 이용 해서 classification 문제 를 푸 는 방법 은 크 게 2 가지 가 있 다 . 바로 ml ( maximum likelihood ) 방법 과 map ( maximum a posteriori ) 방법 이 다 . 관측 값 을 z , 그 값 이 나온 클래스 ( 또는 모델 ) 를 x 라 하 자 . 예 를 들 어 , 바닥 에 떨어진 머리카락 의 길이 ( z ) 를 보 고 그 머리카락 이 남자 것 인지 여자 것 인지 성별 ( x ) 을 판단 하 는 문제 를 생각 해 보 자 . ml ( maximum likelihood ) 방법 : ml 방법 은 남자 에게서 그러 한 머리카락 이 나올 확률 p ( z | 남 ) 과 여자 에게서 그러 한 머리카락 이 나올 확률 p ( z | 여 ) 을 비교 해서 가장 확률 이 큰 , 즉 likelihood 가 가장 큰 클래스 ( 성별 ) 를 선택 하 는 방법 이 다 . ml 방법 은 남자 에게서 그러 한 머리카락 이 나올 확률 p ( z | 남 ) 과 여자 에게서 그러 한 머리카락 이 나올 확률 p ( z | 여 ) 을 비교 해서 가장 확률 이 큰 , 즉 likelihood 가 가장 큰 클래스 ( 성별 ) 를 선택 하 는 방법 이 다 . map ( maximum a posteriori ) 방법 : map 방법 은 z 라는 머리카락 이 발견 되 었 는데 그것 이 남자 것 일 확률 p ( 남 | z ) , 그것 이 여자 것 일 확률 p ( 여 | z ) 를 비교 해서 둘 중 큰 값 을 갖 는 클래스 ( 성별 ) 를 선택 하 는 방법 이 다 . 즉 , 사후 확률 ( posterior prabability ) 를 최대 화 시키 는 방법 으로서 map 에서 사후 확률 을 계산 할 때 베이즈 정리 가 이용 된다 . 머 가 다른 것 인지 정말 햇 갈린다 ( 사실 본인 도 얼마 전 까지 는 그랬 다 ) . 그런데 , ml 과 map 차이 는 남녀 의 성비 를 고려 하 면 명확 해진다 . 만일 인구 의 90 % 가 남 자고 여자 는 10 % 밖 에 없 다고 하 자 . ml 은 남녀 의 성비 는 완전히 무시 하 고 순수 하 게 남자 중 에서 해당 길이 의 머리카락 을 가질 확률 , 여자 중 에서 해당 길이 의 머리카락 을 가질 확률 만 을 비교 하 는 것 이 다 . 반면 에 map 는 각각 의 성 에서 해당 머리카락 이 나올 확률 뿐 만 아니 라 남녀 의 성비 까지 고려 하 여 최종 클래스 를 결정 하 는 방법 이 다 . map 로 머리카락 이 여자 것 일 확률 을 베이즈 정리 를 이용 해 구해 보 면 다음 과 같 다 . 정리 하 면 , ml 보다 는 map 방법 이 보다 정확 한 classification 방법 임 을 알 수 있 다 . 하지만 많 은 경우 , 사전 확률 ( prior probability ) 인 p ( 남 ) , p ( 여 ) 를 모르 는 경우 가 대부분 이 기 때문 에 단순 하 게 p ( 남 ) = p ( 여 ) 로 놓 고 문제 를 푸 는 경우 가 많 은데 , 이 경우 map 는 ml 과 같 게 된다 . 3 . 피부색 검출 예제 베이지안 방법 이 영상 처리 에 사용 되 는 한 예 로 영상 에서 피부색 을 검출 하 는 문제 를 살펴보 자 . 영상 에서 피부색 을 검출 하 는 문제 는 결국 , 영상 의 각 픽셀 이 피부색 인지 아닌지 여부 를 결정 하 는 classification 문제 로 볼 수 있 다 . 피부색 검출 을 위해서 는 먼저 샘플 영상 들 을 열심히 수집 해서 피부색 db 와 일반 색상 db 를 구성 해야 한다 . db 구성 이 끝나 면 이제 입력 영상 의 각 픽셀 값 이 피부색 인지 여부 를 베 이지언 방법 으로 판단 해 보 기 로 하 자 . 입력 픽셀 값 이 z 라 하 면 p ( z | 피부색 ) 은 피부색 db 에 있 는 데이터 들 중 에서 z 와 같 은 색 을 가진 데이터 의 비율 을 세 면 된다 . 또한 p ( z | 일반 색 ) 은 일반 색 db 에 있 는 데이터 들 중 에서 z 와 같 은 색 을 가진 데이터 의 비율 이 다 . 만일 ml 로 피부색 검출 을 한다면 p ( z | 피부색 ) 과 p ( z | 일반 색 ) 을 비교 해서 확률 이 큰 값 을 선택 하 면 될 것 이 다 . 그런데 , 이 문제 를 map 로 풀 면 어떻게 될까 ? 수집 된 db 에 있 는 데이터 의 개수 를 이용 하 여 p ( 피부색 ) = | 피부색 db |/(| 피부색 db |+| 일반 색 db |), p ( 일반 색 ) = | 일반 색 db |/(| 피부색 db |+| 일반 색 db |) 라 놓 고 map 를 적용 하 면 되 는 것 일까 ? 대답 은 no ! p ( 피부색 ) 은 세상 에 존재 하 는 모든 이미지 색상 들 중 에서 피부색 이 얼마나 되 느냐 를 나타내 는 말 이 다 . 따라서 , 자신 이 수집 한 피부색 db 와 일반 색 db 의 크기 만 을 가지 고 이 확률 을 추정 하 는 것 은 무리 가 있 다 . 오히려 일반 색 db 에 있 는 데이터 들 중 에서 피부색 db 에 있 는 색 과 같 은 색 을 갖 는 데이터 들 의 비율 을 p ( 피부색 ) 이 라 잡 는 것 이 보다 합리 적 일 것 이 다 . 이 와 같이 prior 확률 p ( x ) 를 구하 는 것 은 쉬운 문제 가 아니 기 때문 에 현실 적 으로 는 map 대신 ml 이 사용 되 는 경우 도 많 다 . ☞ 이 글 은 [ URL ] 글 에 대한 엮인 글 ( 트랙백 ) 로 작성 한 글 입니다 . ☞ 베 이지언 ( bayesian ) 확률 에 대한 보다 기본 적 인 이해 를 위해서 는 베 이지언 확률 ( bayesian probability ) 글 을 참고 하 시 면 좋 습니다 . by 다크 프로그래머\",\n",
       "       '데이터 분석 의 기본기 , 회귀분석 일반 회귀분석 vs . 분위 회귀분석 qr 은 위 와 같이 종속 변수 를 기준 으로 분석 대상 을 줄 세우 고 이 를 n 등 분 했 을 때 , 나뉜 각각 의 구간 에서 독립 변수 들 이 지니 는 효과 의 크기 가 모두 다를 수 있 음 을 상정 한다는 측면 에서 일반 적 인 회귀분석 과 두드러진 차이점 을 지닌다 . 다시 보험 회사 a 의 케이스 를 예 로 들 어 생각 하 자면 qr 은 전체 고객 을 의료비 지출 수준 이 높 은 고객 군 과 중간 수준 의 고객 군 , 낮 은 수준 의 고객 군 등 으로 세분 화 해 각각 의 고객 군 에서 경쟁사 를 통한 추가 적 인 보험 가입 여부 , 확진 된 만성 질환 의 수 , 나이 와 나이 의 제곱 , 성별 , 소득 이 의료비 지출 수준 에 미치 는 영향 을 개별 적 으로 ( 즉 , 구간 별 로 ) 추정 해 내 는 방법 인 것 이 다 . 물론 고객 을 몇 개 의 구간 으로 세분 화 할지 는 분석 자 가 상황 에 맞 게 임의 대로 설정 할 수 있 다 . 이질 성 에 대한 접근 : “ 그 들 은 모두 체계 적 으로 다르 다 ( they are all systematically different ) ” qr 은 일반 적 인 회귀분석 보다 큰 규모 의 데이터 를 요구 하 기 때문 이 다 . 즉 , 보험 회사 a 가 qr 을 활용 하 기 위해서 는 그동안 일반 회귀분석 을 위해 통상 적 으로 요구 됐 던 것 이상 으로 상당 한 수준 의 고객 데이터 가 확보 돼야 한다 . 하지만 데이터 의 시대 를 살아가 고 있 는 우리 에게 다행히 도 데이터 의 크기 는 더 이상 큰 이슈 가 되 지 않 는다 . 다시 말 해 ‘ 구슬 의 개수 ’ 는 이미 충분 하 다 . 또한 , qr 의 경우 상술 한 예 에서 말 했 던 ß 1 ∼ ß 6 ( 영향 및 효과 의 크기 ) 를 도출 하 기 위한 계산 과정 ( computation process ) 역시 일반 회귀분석 에 비해 매우 복잡 하 다 . 하 지만 stata , r 등 상용 되 고 있 는 많 은 통계 프로그램 패키지 는 부트 스 트래핑 ( bootstrapping ) 4 을 비롯 해 qr 을 위한 일련 의 계산 기능 을 포괄 적 으로 제공 한다 . 즉 , 데이터 의 규모 와 계산 의 복잡 성 문제 가 해결 된 오늘날 은 바야흐로 qr 이 그 유용 성 을 인정받 고 기업 의 의사 결정 과정 에서 진가 를 발휘 해야 하 는 시기 인 것 이 다 . “ 넘쳐나 는 데이터 도 꿰 어야 보배 ” 첫째 , 데이터 의 크기 ( the number of observations ) 가 충분히 큰 경우 , 둘째 , 종속 변수 의 기술 통계량 ( descriptive statistics ) 을 살펴봤 을 때 분포 에 상당 한 이질 성 이 관찰 된 경우 , 셋째 , 독립 변수 ( x ) 가 종속 변수 ( y ) 에 미치 는 효과 를 구간 별 로 상세히 알아내 야 할 필요 가 있 을 경우',\n",
       "       '서버 가 느려졌 어요 ! 서버 를 운영 하 다가 보 면 간혹 눈 에 띄 게 서버 가 느려 지 는 현상 을 경험 하 게 된다 . 시스템 에 접근 하 는 것 은 정상 인데 웹 이 느려졌 을 수 도 있 고 어쩌면 그 반대 일 가능 성 도 있 다 . 시스템 이 느리 다는 것 은 관리자 혹은 사용 자 가 요청 한 이슈 에 대한 응답 속도 가 떨어진다는 것 을 의미 한다 . 이 는 시스템 의 튜닝 을 통해 개선 할 수 도 있 으나 시스템 의 어느 곳 에서 병목현상 이 일어나 는지 를 알 아야 만 그 에 맞 게 적절 한 조치 를 취해 성능 을 높일 수 있 다 . 여기 서 는 이 와 같 은 상황 에서 시스템 의 어느 부분 에 대 규모 부하 가 발생 하 는지 를 점검 하 는 방법 을 살펴보 자 . 웹 이 느려졌 어요 ! 먼저 서버 가 느려 지 는 현상 은 크 게 웹 접속 속도 가 느려졌 을 때 와 시스템 내 의 부하 로 인해서 느려 지 는 두 가지 경우 로 구분 해 살펴볼 수 있 다 . 시스템 의 접속 속도 는 빠르 지만 웹 만 느려졌 을 경우 에 는 그 문제점 을 찾 기 가 한층 쉽 다 . 서비스 거부 ( dos ) 공격 등 외부 요인 에 의한 비 정상 적 인 상황 을 제외 하 고 일반 적 인 상태 에서 웹 이 느려 지 는 이유 는 크 게 3 가지 정도 로 압축 할 수 있 다 . 가장 대표 적 인 것 이 웹 서버 의 로그 크기 이 다 . 아파치 웹 서버 를 이용 해 웹 서비스 를 제공 할 때 , 웹 로그 를 쌓 아 놓 고 있 다면 그 크기 를 먼저 살펴보 자 . 아파치 웹 로그 의 최대 크기 는 2 gb 인데 이 용량 을 넘 으면 웹 서버 가 정상 적 으로 동작 하 지 않 는다 . 또한 웹 로그 의 크기 가 클수록 웹 서버 가 열리 는 속도 도 느려진다 . 따라서 로그 로 인한 웹 속도 의 감소 를 방지 하 기 위해서 는 로그 를 주기 적 으로 로테이션 ( rotation ) 시켜 주 는 것 이 좋 다 . 이 를 위해서 는 여러 가지 방법 이 있 는데 다음 과 같이 24 시간 에 한 번 씩 로그 를 로테이션 시켜 주 는 것 도 방법 이 다 . transferlog “ |/ usr / sbin / rotatelogs / usr / local / apache / logs / man - access _ log 86400 ” customlog “ | bin / rotatelogs / usr / local / apache / logs / man - access _ log 86400 ” 2 . x 버전 의 경우 customlog ‘| bin / rotatelogs / usr / local / apache / logs / man - access _ log 100 m ’ 과 같이 로그 크기 를 지정 해 로테이션 할 수 도 있 다 . 만일 로그 크기 의 문제 가 아니 라면 netstat , ps 명령 등 을 통해 ‘ maxclients ( 최대 동시 접속자 수 ) ’ 를 점검 해 보 자 . maxclients 를 150 으로 설정 해 놓 았 는데 동시 접속자 가 150 에 가깝 거나 혹은 그 이상 이 라면 선행 된 연결 이 끊기 기 전 까지 는 새로운 사용 자 가 접속 되 지 않 아 웹 의 접근 속도 가 느려진 것 처럼 보일 수 있 다 . 이런 경우 에 는 서버 의 성능 에 따라 maxclients 를 적절히 늘려 주 거나 keepalive timeout ( 한 번 연결 됐 던 클라이언트 는 다시 연결 을 시도 할 가능 성 이 높 으므로 keepalivetimeout 시간 만큼 기다렸 다가 그 시간 안 에 연결 요청 이 있 으면 새로운 연결 을 맺 는 시간 을 ( 3 way handshake ) 절약 할 수 있 으므로 성능 향상 에 도움 을 준다 . 하지만 여기 에 설정 된 시간 만큼 실제 사용 하 지 않 아도 연결 을 맺 고 있 게 되 므로 동시 접속자 에 영향 을 미치 게 된다 ) 을 개별 웹 서비스 의 특성 을 고려 해 적절히 조정 하 면 웹 접근 속도 를 높일 수 있 다 . 마지막 으로 웹 서버 의 응답 속도 가 느려질 수 있 는 또 다른 경우 는 php 등 의 웹 프로그래밍 내 에서 사용 하 지 않 는 잘못 된 도메인 으로 연결 을 시도 하 는 경우 나 해당 페이지 의 로드 를 요청 하 는 사용자 의 dns 서버 가 오동작 을 해 해당 ( 특정 ) 도메인 을 찾 지 못해 시스템 의 응답 이 느려 지 는 경우 다 . 즉 코드 내 에 iframe 으로 test . co . kr / test / test . php 를 불러 와서 로딩 하 는 코드 가 있 다고 가정 할 때 , 만일 test . co . kr 가 잘못 된 도메인 이 라면 dns 는 test . co . kr 에 대해서 resolve 를 실시 하 고 , timeout 이 발생 할 때 까지 기다렸 다가 응답 이 없 으면 요청 한 사용자 에게 없 는 도메인 이 라는 응답 을 회신 하 게 된다 . 이 처럼 웹 페이지 내 에 잘못 된 도메인 링크 가 많이 걸려 있 다면 웹 페이지 의 로드 속도 가 줄어들 고 당연히 웹 접속 속도 가 느려질 것 이 다 . 이 경우 에 는 해당 도메인 을 웹 소스 에서 제거 해 주 면 속도 가 빨라 지 며 만일 사용 자 의 dns 잘못 으로 인해서 도메인 을 찾 지 못하 는 것 이 라면 사용 자 컴퓨터 의 dns 를 다른 dns 로 변경 해 보 는 방법 도 있 다 ( 참고 로 웹 페이지 의 호출 ( 접근 ) 은 서버 가 가리키 는 dns 를 사용 하 는 것 이 아니 라 웹 페이지 를 호출 하 는 사용 자 컴퓨터 에 설정 된 dns 를 사용 한다 ) . 이 밖 에 도 직접 접속 을 시도 하 는 사용자 와 서버 가 있 는 네트워크 간 의 트래픽 이 증가 해 느려 지 는 경우 도 있 다 . 윈도우 에서 는 tracert 또는 pathping 이 란 프로그램 으로 측정 할 수 있 으며 , 리눅스 에서 는 traceroute 와 pathchar 라는 프로그램 으로 측정 할 수 있 다 . pathchar ( ftp : / / ftp . ee . lbl . gov / pathchar ) 라는 프로그램 을 처음 들 어 본 관리자 도 있 을 것 이 다 . 이 프로그램 은 트레이스 ( trace ) 처럼 목적지 로 가 기 위한 경로 를 보여 줄 뿐 만 아니 라 , 각 경로 사이 의 전송 속도 도 확인 해 볼 수 있 는 프로그램 이 다 ( 단 이 때 전송 속도 는 정확 한 것 은 아니 며 테스트 에 의한 대략 의 값 이 다 ) . 하지만 이 프로그램 은 속도 가 느리 고 각 경로 사이 의 전송 속도 측정 을 위해 많 은 트래픽 을 발생 시키 므로 실제로 사용 하 기 에 는 무리 가 있 다 . 은 daum . net 으로 pathchar 를 시도 한 결과 이 다 ( 2004 년 에 4 월 기준 으로 테스트 했 던 내용 이 므로 현재 네트워크 속도 와 는 다를 수 있 다 ) . 지금 까지 네트워크 의 병목현상 이나 또는 웹 서버 의 설정 으로 인해서 웹 응답 속도 가 느려 지 는 몇 가지 원인 을 살펴봤 다 . 이제 시스템 내 의 부하 로 인해 시스템 의 응답 이 느려 지 는 경우 병목 지점 을 확인 하 는 방법 과 해결 방법 에 대해서 알아보 자 . 구간 별 정송 속도 확인 vmstat 1 실행 시스템 이 느려졌 어요 ! 시스템 자체 가 느릴 경우 에 체크 해 볼 포인트 는 웹 과 마찬가지 로 대략 3 ~ 4 개 정도 이 다 . 시스템 자체 가 느리 다는 것 은 어느 프로그램 또는 프로세스 가 cpu 나 메모리 , i / o 를 많이 사용 하 고 있 다는 것 을 의미 하 므로 해당 프로그램 이나 프로세서 를 찾 아서 중지 또는 종료 시켜야 한다 . 먼저 < 화면 2 > 와 같이 vmstat 명령 으로 시스템 전체 의 리소스 상황 을 모니터링 한다 ( < 화면 2 > 를 이해 하 기 위해서 는 < 그림 1 > 과 < 표 1 > 를 참고 하 면 된다 ) . 이 를 통해 어느 곳 에서 병목 현상 이 발생 하 고 있 는지 점검 하 고 각 영역 에 맞 는 대응 방안 을 마련 하 도록 한다 . < 그림 1 > vmstat 의 각 항목 별 참고 할 부분 < 표 1 > vmstat 의 각 항복 별 에 대한 설명 구분 설명 proc r cpu 에서 대기 중 인 프로세스 의 수 를 의미 한다 . 이 값 이 증가 하 거나 r 개수 / cpu 개수 의 값 이 항상 2 이상 나온다면 cpu 의 성능 을 높여 주 어야 한다 . b 동작 하 는 블럭 프로세스 의 수 이 값 이 높 다면 블럭 디바이스 의 속도 를 높여야 한다 . w swap out 되 는 프로세서 의 수이 다 . w 에 값 이 증가 하 면 메모리 가 매우 부족 하 다는 의미 이 므로 메모리 를 늘려야 한다 . memory ( kb ) swapd 현재 메모리 가 부족 해 swap 을 사용 하 고 있 는 양 을 의미 한다 . 평소 에 이 값 이 높 다고 해도 free 메모리 의 여유 가 있 다면 메모리 가 부족 한 것 이 아니 다 . 한번 swap 으로 떨어진 프로 레스 는 메모리 의 여유 가 생기 더라도 cpu 에서 다시 호 풀 하 지 않 는 한 메모리 로 넘 어 오 지 않 는다 . free 현재 사용 하 지 않 고 남 아 있 는 메모리 buffer 버퍼 로 사용 되 고 있 는 메모리 양 ( 퍼포먼스 에 관련 ) cache 현재 캐시 로 사용 되 고 있 는 메모리 양 ( 퍼포먼스 에 관련 ) swap ( kb / s ) si 디스크 에서 메모리 로 swap in 되 는 양 을 의미 하 며 , swap 공간 에 있 는 데이터 를 실제 메모리 로 호출 한다 . so 메모리 에서 디스크 로 swap out 되 는 양 을 의미 하 며 , 이 는 곧 메모리 가 부족 해 실제 메모리 에 있 는 데이터 를 swap 공간 으로 보내 는 것 이 다 . io ( blocks / s ) bi / bo bi 는 초당 블럭 디바이스 로 보내 는 블럭 수 이 며 bo 는 블럭 디바이스 로부터 받 은 블럭 수이 다 . 이 두 값 이 높 다는 것 은 i / o 즉 하드 디스크 에 읽 고 쓴 느 값 이 많 다는 것 이 다 . system in 초 당 인터럽트 되 는 양 이 다 . 여기 에 는 time clock 과 이더넷 의 패킷 도 포함 되 는데 즉 인터럽트 의 수 가 많 다면 네트워크 쪽 을 점검 해 볼 필요 가 있 다 . cs 초 당 context switch 되 는 양 이 다 . cpu 에 사 실행 하 는 명령 들 이 자신 의 우선 순위 보다 높 은 명령 이 오 거나 혹은 자신 에게 할당 된 cpu 점유 시간 이 만료 되 면 우선 순위 에서 밀리 게 되 고 이때 context switch 가 발생 하 게 된다 . cpu us 유저 프로세스 가 cpu 를 사용 하 는 시간 sy 시스템 프로세스 가 cpu 를 사용 하 는 시간 id cpu 가 아무 일 도 하 지 않 고 여유 있 는 시간 < 화면 3 > top 실행 < 화면 4 > iostat - x 1 실행 < 화면 5 > isof 실행 만일 아파치 , mysql 등 서비스 를 위해 필요 한 프로그램 들 이 정상 적 인 방법 으로 사용 되 면서 시스템 리소스 를 많이 사용 하 고 있 다면 cpu 와 메모리 를 증설 하 거나 더 빠른 디스크 로 교체 해야 겠지만 , 그것 이 아니 라면 어느 부분 에 문제 가 있 는지 확인 해 이 를 더 세밀 하 게 점검 해야 한다 . 이 를 위해서 는 top , ps , sar , iostat , netstat 명령 등 을 추가 로 사용 하 는 데 예 를 들 어 sar 는 10 분 간격 ( 기본 값 이 며 / etc / cron . d / sysstat 에서 수정 할 수 있 다 ) 으로 모든 시스템 활동 정보 ( system activity information ) 를 저장 , 수집 해 보 고 하 는 기능 을 지원 해 과거 리소스 를 분석 하 는데 특히 유용 하 다 . 여기 에 는 매우 많 은 정보 를 포함 하 고 있 으므로 man sar 를 참고 하 기 바란다 . 이 밖 에 도 시스템 의 리소스 를 분석 하 는 명령 에 는 여러 가지 가 있 다 . 예 를 들 어 vmstat 결과 cpu 와 메모리 의 사용량 이 많 을 때 는 < 화면 3 > 과 같이 top 또는 ps 를 이용 해 cpu 와 메모리 를 많이 사용 하 는 프로세스 를 확인 할 수 있 으며 이런 프로세스 를 확인 하 면 pid , kill 등 을 이용 해 해당 process 를 종료 시킬 수 있 다 . 만일 vmstat 를 통해 모니터링 하 던 중 i / o 의 로드 가 많 다고 확인 되 면 iostat - x 1 명령 을 통해 어느 디스크 에서 사용 이 많 은지 를 확인 할 수 있 다 . < 화면 4 > 를 보 면 iostat 출력 결과 / dev / hda 3 에서 i / o 를 많이 사용 하 는 것 을 알 수 있 다 . 그렇 다면 현재 이 i / o 에서 어떤 프로그램 혹은 파일 이 동작 되 고 있 는지 도 살펴보 자 . < 화면 5 > 처럼 losf 명령 을 이용 하 면 / dev / hda 3 에서 사용 중 인 프로그램 과 파일 을 볼 수 있 으며 이것 이 병목 을 일으키 는 원인 이 라면 프로그램 을 중지 시키 거나 혹은 pid 번호 를 이용 해 kill 명령 으로 해당 프로세스 를 종료 시키 면 된다 . 이 때 만일 ide 하드 디스크 를 사용 하 고 있 고 커널 에서 dma ( direct memory access ) 를 지원 하 도록 설정 되 어 있 다면 hdparm 을 이용 해서 i / o 버스 의 32 비트 지원 과 dma 를 사용 하 도록 설정 해 i / o 의 성능 을 향상 시킬 수 있 으며 병목현상 도 줄일 수 있 다 . < 화면 6 > f - prot / usr / sbin 실행 < 화면 7 > clamscan - i - r / var / qmail / queue / mess / 실행 바이러스 ? 그러나 시스템 리소스 분석 을 통해서 도 그 이유 를 찾 지 못했 다면 바이러스 나 웜 을 점검 해 바이러스 에 감염 되 지 않 았 는지 확인 해 보 기 바란다 . 일반 적 으로 리눅스 는 바이러스 에 잘 감염 되 지 않 는다고 알려져 있 으나 지난 1998 년 이후 리눅스 에 도 수많 은 종류 의 바이러스 가 등장 하 고 있 다 . 대표 적 인 것 이 elf ( executable and linking format ) 파일 을 감염 시키 는 rst . b 바이러스 다 . 여기 에 감염 된 명령 을 실행 하 면 elf 바이너리 명령어 파일 이 연쇄 적 으로 감염 되 고 , 다시 이 들 명령 을 사용 하 면 해당 명령 이 정상 적 으로 실행 되 지 않 거나 실행 후 에 도 메모리 에서 사라지 지 않 아 메모리 와 cpu 를 점유 하 고 결국 시스템 리소스 를 고갈 시키 게 된다 . 또한 바이러스 에 감염 된 명령 을 실행 하 면 외부 의 특정 네트워크 로 접속 을 지속 적 으로 시도 하 는 등 다양 한 감염 증상 이 나타나 결과 적 으로 시스템 이 느려 지 게 된다 . 리눅스 에서 많이 사용 하 는 바이러스 검색 프로그램 에 는 f - prot 와 clamav 가 있 다 . f - prot ( [ URL ] 웹 사이트 와 clamav ( [ URL ] 웹 사이트 에서 무료 로 다운로드 해 사용 할 수 있 다 ( 단 윈도우 에서 사용 하 려면 비용 을 지불 해야 한다 ) . < 화면 6 > 은 f - prot 를 이용 해 / usr / sbin 아래 의 파일 을 검색 한 화면 이 다 . 바이너리 명령 들 이 감염 된 것 을 확인 할 수 있 다 . f - prot 는 설치 도 간편 하 고 설치 후 아무런 설정 없이 바로 실행 이 가능 하 다는 장점 이 있 다 . < 화면 7 > 은 clamav 를 실행 해 / var / qmail / queue / mess 의 메시지 를 점검 한 결과 다 ( 여기 서 탐지 된 바이러스 는 리눅스 바이러스 가 아니 라 윈도우 바이러 스다 ) . clamav 는 f - prot 보다 많 은 바이러스 패턴 을 가지 고 있 으며 업데이트 역시 단순 한 명령 한 줄 로 가능 한 것 이 특징 이 다 . 파일 에 감염 된 바이러스 , 웜 은 물론 메일 프로그램 과 연동 해 메일 로 들어오 는 바이러스 를 필터링 함 으로써 바이러스 메일 필터링 프로그램 으로 사용 할 수 도 있 다 ( 단 clamav 를 사용 하 기 위해서 는 몇 가지 설정 파일 을 변경 해야 한다 ) . 감염 된 파일 을 삭제 하 려면 f - prot 는 - delete 옵션 , clamav 는 -- remove 옵션 을 추가 하 면 된다 . 단 만 일 삭제 된 파일 이 시스템 명령어 이 거나 운영 상 중요 파일 일 경우 에 는 시스템 이 정상 적 으로 동작 하 지 않 을 수 있 으므로 시스템 명령 이나 운영 상 중요 한 파일 이 감염 된 것 을 확인 했 을 때 는 감염 되 지 않 은 동일 한 버전 의 서버 에서 명령어 나 중요 파일 을 복사 해서 덮어쓰 거나 rpm 등 으로 재 설치 를 해 주 는 것 이 바람직 하 다 . 그러나 메일 등 에서 바이러스 나 웜 이 검출 되 면 삭제 를 해 주 는 것 이 2 차 피해 를 막 기 위해 바람직 하 다 . 여기 서 는 시스템 이 느려질 때 병목현상 을 식별 하 고 이 를 제거 하 기 위한 방법 을 설명 하 는 것 에 초점 을 맞추 고 있 으므로 바이러스 에 대해 깊이 설명 하 지 는 않 겠 다 . 그러나 리눅스 서버 가 바이러스 나 웜 에 감염 됐 다는 것 은 ( 메일 제외 ) , 바이러스 가 감염 된 파일 을 다운 받 아 실행 했 거나 혹은 외부 침입 을 통해 바이러스 가 감염 된 파일 이 실행 됐 을 가능 성 이 높 다 . 따라서 바이러스 나 웜 감염 이 확인 되 면 외부 침입 에 자주 사용 되 는 / tmp , / var / tmp , / dev / shm 디렉 토리 에 이상 한 파일 이 없 는지 그리고 취약 한 패스워드 는 없 는지 웹 으로부터 의 불법 접속 은 없 었 는지 등 을 시스템 로그 와 웹 로그 를 참조 하 여 점검 해 보 기 바란다 . 지금 까지 관리 하 는 서버 가 느려 지 는 현상 이 발생 해 시스템 을 점검 할 때 사용 할 수 있 는 몇 가지 방법 들 을 살펴봤 다 . 이 와 병행 해 시스템 의 성능 향상 을 위한 튜닝 방법 까지 익혀 둔다면 현재 관리 하 고 있 는 리눅스 시스템 을 최적 의 환경 에서 운영 할 수 있 을 것 이 다 . 출처 : [ URL ]',\n",
       "       '이 글 은 ubuntu 16 . 04 운영 체제 에 nvidia gpu 와 tensorflow 기반 의 딥 러닝 환경 을 구축 하 고자 하 는 사람 들 을 위해 작성 되 었 다 . 필자 는 주로 파이썬 으로 데이터 를 다루 기 때문 에 최신 anaconda 파이썬 3 . 6 버전 을 사용 할 것 이 며 텐서 플로 를 별도 의 가상 환경 에 분리 하 지 않 을 것 이 다 . 순정 우분투 16 . 04 . 2 설치 를 마친 직후 라 가정 하 고 서술 하 겠 다 . 만약 설치 하 려는데 검정 색 빈 화면 만 나와 애 를 먹 고 있 다면 이전 포스트 를 참 고 하 자 . 텐서 플로 공식 홈페이지 에 소개 된 바 에 따르 면 우분투 에서 nvidia 그래픽 카드 를 사용 하 기 위해서 는 아래 나열 된 nvidia 관련 소프트웨어 를 설치 해야 한다 . ( pip install tensorflow 만 하 면 끝 일 줄 알 았 다면 순진 한 거 다 ! 사실 막연 하 게 그랬 으면 좋 겠 다고 생각 했 다 . .) cuda ® toolkit 8 . 0 cuda 8 . 0 과 호환 되 는 nvidia 그래픽 드라이버 cudnn v 5 . 1 tensorflow 가 본인 의 gpu 를 지원 하 지 않 는다면 텐서 플로 gpu 버전 을 깔 아도 gpu 를 사용 하 지 않 는다 . 먼저 이 를 확인 해 보 자 . 0 . gpu 버전 을 설치 할까 ? cpu only 버전 을 설치 할까 ? 먼저 , 본인 pc 에 설치 된 gpu 가 tensorflow 사용 가능 한 gpu 인지 확인 해야 한다 . ( gpu 가 없 다면 당연히 cpu only 버전 … ) 아래 두 가지 조건 을 충족 하 면 gpu 버전 의 tensorflow 를 설치 하 여 사용 할 수 있 다 . 그렇 지 않 다면 gpu 버전 의 tensorflow 는 무용지물 . cuda 를 지원 하 는 gpu 인가 ? 여기 에 접속 하 여 본인 pc 에 장착 된 gpu 를 찾아보 자 . 본인 의 gpu 가 목록 에 있 다면 , 그 옆 에 compute capability 를 확인 하 고 2 번 으로 고고 . nvidia compute capability 3 . 0 이상 인가 ? tensorflow 공식 문서 에 의하 면 cuda 를 지원 하 더라도 nvidia compute capability 가 3 . 0 이하 이 면 tensorflow 를 사용 할 수 없 다 . 1 . nvidia 그래픽 드라이버 설치 우분투 설치 를 마친 직후 부팅 해 보 면 운영 체제 에서 그래픽 카드 를 아직 인식 하 지 못한 상태 이 기 때문 에 해상도 가 매우 낮 을 수 있 다 . 이 때 , 그래픽 드라이버 를 설치 하 면 고해상도 가 된다 . nvidia 그래픽 드라이버 를 배포 하 는 ppa 를 설치 하 고 업데이트 를 한다 . ( 367 . 4 x 버전 이상 의 최신 버전 이 어야 함 ) $ sudo add - apt - repository ppa : graphics - drivers / ppa $ sudo apt - get update $ sudo apt - get install nvidia - 375 설치 가 끝나 면 재 부팅 한다 . $ sudo reboot 재 부팅 후 고해상도 화면 이 나오 면 성공 이 라고 생각 하 면 된다 . 터미널 에 nvidia - smi 를 입력 하 면 아래 와 같이 드라이버 버전 과 시스템 에 인식 된 gpu 를 확인 할 수 있 다 . $ nvidia - smi mon mar 6 01 : 01 : 51 2017 + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ------------------------+ | nvidia - smi 375 . 39 driver version : 375 . 39 | | - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - -+----------------------+ | gpu name persistence - m | bus - id disp . a | volatile uncorr . ecc | | fan temp perf pwr : usage / cap | memory - usage | gpu - util compute m . | | = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = + = = = = = = = = = = = = = = = = = = = = = =+======================| | 0 geforce gtx 970 off | 0000 : 05 : 00 . 0 on | n / a | | 0 % 29 c p 8 12 w / 180 w | 292 mib / 4034 mib | 0 % default | + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - -+----------------------+ + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ------------------------+ | processes : gpu memory | | gpu pid type process name usage | | = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ========================| | 0 1128 g / usr / lib / xorg / xorg 169 mib | | 0 1887 g compiz 121 mib | + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ------------------------+ 만약 그래픽 드라이버 설치 도중 바이오스 화면 이 뜨 거나 , 설치 를 완료 하 고 부팅 했 는데 무한 로그인 loop 에 빠진 다면 바이오스 설정 에서 secure boot 옵션 을 disabled 상태 로 바꾸 자 . 몇 달 전 이 문제 때문 에 몇 시간 동안 고생 했었 다 . . 2 . cuda toolkit 8 . 0 설치 공식 다운로드 페이지 에서 우분투 16 . 04 의 runfile ( local ) 을 다운로드 한다 . 모두 받 았 다면 아래 와 같이 실행 한다 . $ sudo sh cuda _ 8 . 0 . 61 _ 375 . 26 _ linux . run 장문 의 라이센스 문구 가 나오 는데 , enter 를 입력 하 며 넘기 기 귀찮 다면 ctrl + c 를 입력 하 자 . 한 번 에 아래 질문 으로 넘어간다 . 이후 의 질문 에 아래 와 같이 답 하 자 . do you accept the previously read eula ? accept / decline / quit : accept install nvidia accelerated graphics driver for linux - x 86 _ 64 375 . 26 ? ( y ) es / ( n ) o / ( q ) uit : n install the cuda 8 . 0 toolkit ? ( y ) es / ( n ) o / ( q ) uit : y enter toolkit location [ default is / usr / local / cuda - 8 . 0 ] : do you want to install a symbolic link at / usr / local / cuda ? ( y ) es / ( n ) o / ( q ) uit : y install the cuda 8 . 0 samples ? ( y ) es / ( n ) o / ( q ) uit : n enter cuda samples location [ default is / home / your _ id ] : 설치 를 마친 뒤 환경 변수 설정 을 한다 . 터미널 에 아래 와 같이 입력 하 자 . $ echo - e \" ## cuda and cudnn paths \" >> ~/. bashrc $ echo \\' export path =/ usr / local / cuda - 8 . 0 / bin : ${ path }\\' >> ~/. bashrc $ echo \\' export ld _ library _ path =/ usr / local / cuda - 8 . 0 / lib 64 : ${ ld _ library _ path }\\' >> ~/. bashrc 위 와 같이 실행 하 면 ~/. bashrc 에 마지막 부분 에 아래 내용 이 추가 된다 . ## cuda and cudnn paths export path = / usr / local / cuda - 8 . 0 / bin : $ { path } export ld _ library _ path = / usr / local / cuda - 8 . 0 / lib 64 : $ { ld _ library _ path } 변경 된 환경 변수 를 적용 하 고 cuda 설치 여부 를 확인 하 자 . $ source ~/. bashrc $ nvcc -- version nvcc : nvidia ( r ) cuda compiler driver copyright ( c ) 2005 - 2016 nvidia corporation built on tue _ jan _ 10 _ 13 : 22 : 03 _ cst _ 2017 cuda compilation tools , release 8 . 0 , v 8 . 0 . 61 다음 단계 로 넘어가 기 전 에 cuda 가 어느 위치 에 설치 되 어 있 는지 확인 하 고 넘어가 자 . cudnn 파일 을 붙여 넣 을 경로 를 보여 주 므로 중요 하 다 . 기본 으로 / usr / local / cuda / 인 경우 가 많 은데 , 나 의 경우 는 / usr / local / cuda - 8 . 0 / 이 다 . $ which nvcc / usr / local / cuda - 8 . 0 / bin / nvcc 3 . cudnn v 5 . 1 설치 공식 다운로드 페이지 에서 cudnn 을 다운로드 받 는다 ( 회원 가입 이 필요 하 다 ) . 여러 파일 목록 중 cudnn v 5 . 1 library for linux ( 파 일 명 : cudnn - 8 . 0 - linux - x 64 - v 5 . 1 . tgz ) 를 받 자 . 아래 와 같이 압축 을 풀 고 그 안 의 파일 을 cuda 폴더 ( 주의 : which nvcc 출력 값 확인 ) 에 붙여 넣 고 권한 설정 을 한다 . which nvcc 실행 결과 cuda 폴더 가 / usr / local / cuda - 8 . 0 이 아니 라 / usr / local / cuda 일 수 도 있 으니 꼼꼼히 확인 하 자 . $ tar xzvf cudnn - 8 . 0 - linux - x 64 - v 5 . 1 . tgz $ which nvcc / usr / local / cuda - 8 . 0 / bin / nvcc $ sudo cp cuda / lib 64 / * / usr / local / cuda - 8 . 0 / lib 64 / $ sudo cp cuda / include / * / usr / local / cuda - 8 . 0 / include / $ sudo chmod a + r / usr / local / cuda - 8 . 0 / lib 64 / libcudnn * $ sudo chmod a + r / usr / local / cuda - 8 . 0 / include / cudnn . h 아래 와 같 은 명령어 를 입력 하 여 비슷 한 출력 값 이 나오 면 설치 성공 이 다 . $ cat / usr / local / cuda / include / cudnn . h | grep cudnn _ major - a 2 # define cudnn _ major 5 # define cudnn _ minor 1 # define cudnn _ patchlevel 10 -- # define cudnn _ version ( cudnn _ major * 1000 + cudnn _ minor * 100 + cudnn _ patchlevel ) # include \" driver _ types . h \" nvidia cuda profiler tools interface 를 터미널 에 아래 와 같이 입력 하 여 설치 한다 . 이전 에 보 지 못했 던 패키지 인데 공식 문서 에서 필요 하 다고 하 니 설치 하 자 . sudo apt - get install libcupti - dev 다음 포스트 에서 는 anaconda 파이썬 3 . 6 과 bazel 을 설치 한다 . references',\n",
       "       '우분투 에 그래픽 드라이버 잡 는 거 그거 뭐 라고 만 하루 를 꼬박 설치 하 는 데 만 보내 냐 ㅠㅠ 그때 그때 발생 하 는 에러 를 잡 기 위해서 구글 에 있 는 관련 문서 는 한글 영어 가리 지 않 고 거의 다 본 것 같 다 . 본 포스팅 은 다시 개발 환경 을 밀 고 설치 를 할 때 똑같 은 실수 를 반복 하 지 않 고 , 나 와 같 은 처지 였 던 사람 들 에게 해결 방법 을 알리 기 위함 이 다 . 정말 많 은 포스팅 이 있 는 데 볼수록 헷갈리 기 만 하 니까 이 포스팅 에서 아주 자세히 설명 을 할 테 니 빠짐없이 그대로 따라 하 길 바란다 . ( 1 ) 사전 준비 작업 그동안 정들 었 던 theano 기반 keras 개발 환경 을 과감 하 게 밀 어 버리 고 tensorflow 로 넘어가 기 위해 우분투 설치 usb 를 만들 고 일단 그래픽 카드 를 본체 에서 제거 하 고 설치 를 하 자 ( 이유 는 질문 하 면 알려 주 겠 다 ) . 설치 후 네트워크 를 연결 하 고 nvidia 홈페이지 에서 그래픽 카드 최신 버전 ( 내 경우 는 64 bits 버전 nvidia - linux - x 86 _ 64 - 367 . 44 . run ) 을 home 폴더 에 다운로드 받 자 . 내친김 에 cuda 와 cudnn 도 받 아 놓 자 ( cuda _ 7 . 5 . 18 _ linux . run , cudnn - 7 . 5 - linux - x 64 - v 5 . 0 - ga . tgz ) . 그리고 터미널 을 켜 고 다음 두 명령어 를 입력 한다 . sudo apt - get update sudo apt - get install build - essential ( 2 ) nouveau 비활성 화 nvidia 계열 드라이버 설치 시 첫 번 째 만나 는 난관 은 nouveau 다 . 우분투 설치 시 기본 적 으로 설치 되 는 드라이버 인데 이 녀석 이 nvidia 드라이버 와 충돌 을 일으킨다 . 자세 한 설명 은 여기 로 ( [ URL ] 요약 하 자면 nouveau 를 끄 고 드라이버 를 설치 해야 한다 . 터미널 을 실행 시키 고 다음 과 같이 명령어 를 입력 하 면 된다 . sudo vi / etc / modprobe . d / blacklist - nouveau . conf blacklist nouveau blacklist lbm - nouveau options nouveau modeset = 0 alias nouveau off alias lbm - nouveau off : wq 를 누르 고 저장 후 다시 터미널 로 나와서 다음 명령어 를 입력 한 후 일단 컴퓨터 를 끄 자 . sudo update - initramfs - u sudo shutdown - h now ( 3 ) 드라이버 설치 컴퓨터 를 끈 후 그래픽 카드 를 장착 하 고 디스플레이 를 그래픽 카드 로 연결 한다 . 그리고 부팅 하 면 \" the system is running in low - graphics mode \" 라는 처음 맞이 하 는 메시지 가 나타났 다 . 처음 엔 뭐 지 하 다가 가만 생각 해 보 니 그래픽 카드 드라이버 를 설치 한 적 이 없 으니 당연히 low graphics mode 로 동작 하 는 거 다 . 참고 로 내 그래픽 카드 는 nvidia gtx titanx 다 ( 갑자기 왠 자랑 질 ? ?). 침착 하 게 ctrl + alt + f 1 을 눌러 콘솔 로 진입 한 다음 로그인 을 하 자 . 다른 포스팅 을 보 면 lightdm 을 stop 하 라고 되 어 있 는데 아마 지금 상태 면 lightdm 이 이미 stop 되 어 있 는 상태 일 것 이 다 . 그래서 할 필요 가 없 다 . ( 1 ) 단계 에서 받 아 놓 은 드라이버 를 바로 설치 하 면 된다 . sudo sh nvidia - linux - x 86 _ 64 - 367 . 44 . run no 하 는 것 없이 디폴트 로 다 설치 하 자 . 설치 가 다 되 면 다음 명령어 를 입력 하 자 sudo nvidia - xconfig 위 에 명령어 입력 안 하 면 x window 실행 할 때 xorg 관련 problem 이 뜰 것 이 다 . 그러니까 까먹 지 말 자 . 여기 까지 문제 없이 실행 했 다면 디스플레이 매니저 를 실행 하 자 . sudo service lightdm start 로그인 화면 이 뜨 고 문제 없이 로그인 이 될 것 이 다 . 그런데 문제 가 하나 있 다 . ctrl + alt + f 1 을 누르 면 콘솔 로 넘어가 야 하 는데 아마 까만 화면 만 뜨 고 아무것 도 안 나올 것 이 다 . 당황 하 지 말 고 재 부팅 한 후 다음 grub 파일 을 수정 하 면 된다 . sudo vi / etc / default / grub 파일 을 열 고 grub _ cmdline _ linux _ default =\" quiet _ spolash \" 라는 부분 을 아래 와 같이 고쳐 준다 . grub _ cmdline _ linux _ default =\" quiet _ spolash nomodeset \" 저장 후 나와서 grub 파일 을 업데이트 한 후 재 부팅 한다 . sudo update - grub sudo reboot 여기 까지 실행 하 면 드라이버 는 깔끔 하 게 설치 된 것 이 다 . ( 4 ) cuda 설치 ctrl + alt + f 1 으로 콘솔 화면 으로 나온 후 로그인한 다음 에 디스플레이 매니저 를 끄 자 . sudo service lightdm stop ( 1 ) 에서 다운로드 받 았 던 cuda 파일 을 실행 하 면 된다 . sudo sh cuda _ 7 . 5 . 18 _ linux . run 여기 서 그래픽 드라이버 는 설치 했 기 때문 에 그래픽 드라이버 설치 하 시 겠 습니까 ( 영어 로 나온다 잘 해석 하 면 됨 ) 라고 물 어 보 는 질문 에 는 no , 나머지 는 디 폴드 로 다 설치 하 자 . 설치 후 bashrc 파일 에 cuda 경로 를 설정 해 줘야 한다 . sudo vi ~/. bashrc 위 명령어 로 파일 을 열 어서 마지막 에 아래 경로 를 추가 하 면 된다 . export ld _ library _ path =\"$ ld _ library _ path : / usr / local / cuda / lib 64 \" export cuda _ home =/ usr / local / cuda 혹시 cuda 설치 시 다음 과 같 은 에러 가 발생 한다면 \" the driver installation is unable to locate the kernel source . .. \" 커널 을 설치 해 주 면 된다 . sudo apt - get install dkms fakeroot build - essential linux - headers - generic 혹은 다음 과 같 은 에러 가 발생 한다면 \" you appear to be running an x server . .. \" 프로세스 관련 폴더 를 지우 면 된다 . cd / tmp rm - rf . x 0 - lock ( 참조 [ URL ] 의 5 . troubleshooting 부분 ) ( 5 ) cudnn 설치 cudnn 설치 는 간단 하 다 . ( 1 ) 에서 다운로드 받 았 던 파일 의 압축 을 풀 고 파일 을 복사 해 주 면 끝 이 다 . tar xvzf cudnn - 7 . 5 - linux - x 64 - v 5 . 0 - rc . tgz 를 입력 하 면 압축 이 풀리 고 home 에 cuda 폴더 가 생긴다 . cd cuda / include sudo cp cudnn . h / usr / local / cuda / include cd . . cd lib 64 sudo cp libcudnn * / usr / local / cuda / lib 64 sudo chmod a + r / usr / local / cuda / lib 64 / libcudnn * 이제 cudnn 까지 설치 가 끝 났 다 . ( 6 ) 그 외 설정 cuda 를 설치 할 때 home 폴더 에 nividia sample 폴더 가 생성 되 었 을 것 이 다 . 컴파일 해 주 자 . cd nvidia _ cuda - 7 . 5 _ samples / 1 _ utilities / devicequery make 만약 에 make 시 에러 가 난다면 build - essential 이 제대로 설치 가 안 된 것 이 므로 ( 1 ) 의 build - essential 을 다시 설치 하 자 . 위 과정 까지 끝났으면 제대로 컴파일 되 었 는지 테스트 를 해본다 . ./ devicequery 실행 결과 가 pass 이 면 제대로 설치 된 것 이 다 . 지금 까지 수고 했 다 . 마지막 대망 의 확인 작업 만 이 남 았 다 . nvcc - v nvidia - smi 위 명령어 를 실행 해서 문제 없이 버전 과 gpu 스펙 을 확인 할 수 있 다면 마지막 확인 작업 이 끝난 것 이 다 . 이제 tensorflow 설치 준비 가 끝 났 다 !',\n",
       "       '셰 퍼즈 파이 는 영국 전통 음식 으로 양치기 가 양 을 치 면서 먹 은 음식 이 라고 하 는 데 남 은 ( 고기 ) 음식 에 매쉬 드 포테이토 를 얹 어서 구워 먹 는 음식 에서 유래 했 다 . 정확 하 게 쉐 퍼즈 파이 는 양고기 로 만든 것 이 고 소고기 로 만든 것 은 코티지 파이 cottage pie 이 다 . 요즘 은 통칭 해서 대충 다 셰 퍼즈 파이 라고 부르 기 도 한다 . 사용 한 재료 는 소고기 필링 으로 소고기 다짐 육 400 그램 버터 1 스푼 양파 중 간 것 1 개 마늘 3 개 밀가루 1 스푼 비프 스톡 0 . 5 스푼 토마토 페이스트 2 스푼 물 1 . 5 컵 오레 가노 약간 타임 약간 넛 맥 약간 소금 , 후추 매시드 포테이토 로 감자 3 개 버터 3 스푼 우유 약 100 미리 파마 산 치즈 1 줌 소금 , 후추 체다 치즈 듬뿍 ㄱ 고곡 고기 깊 기 피 필 필 ㄹ 리링 링 ㅇ에에 ㄱ 가 감감 ㅈ 자 잔 자 느 는 는 ㅆ씨씻씻ㅇ어어서 으어 어 이거 뭐 야 ;;; 고기 필링 에 는 샐러리 와 당근 을 각각 양파 의 반정 도 곱 게 썰 어 넣 으면 더 좋 다 . 고 형 비프 스톡 을 사용 했 는데 대신 치킨 스톡 을 사용 해도 괜찮 다 . 매시드 포테이토 에 는 생크림 이나 여러 가지 치즈 를 넣 어서 풍미 를 더 할 수 있 다 . 감자 는 씻 어서 잠길 정도 로 물 을 붓 고 40 분 정도 푹 삶 았 다 . 시간 이 많이 드 니까 껍질 을 벗겨서 4 등분 으로 잘라 삶 고 건져서 수분 을 조금 날리 는 것 도 괜찮 다 . 구운 감자 는 껍질 을 벗기 고 뜨거울 때 으깨 서 버터 를 넣 고 녹이 고 우유 를 붓 고 파 근 파 근 하 게 매시드 포테이토 를 만들 었 다 . 소금 과 후추 도 약간 씩 넣 었 다 . 팬 에 넣 고 우유 가 완전히 흡수 되 도록 끓이 고 파마 산 치즈 를 한 줌 넣 어서 섞 어서 완성 . 곱 게 하 려면 체 에 치 는 것 도 좋 은데 일 이 많 아 진다 . 소고기 는 팬 에 넣 고 센 불 에 잘 게 부숴 가 면서 노릇노릇 하 게 볶 고 키친 타올 에 받쳐 기름 을 제거 했 다 . 팬 은 닦 아 내 고 다시 열 을 올려 버터 를 약간 두르 고 양파 와 마늘 을 볶 다가 볶 은 고기 를 넣 고 한 번 볶 은 다음 밀가루 를 1 스푼 넣 어서 볶 았 다 . 여기 에 비프 스톡 , 토마토 페이스트 , 물 을 넣 고 소고기 가 부드러워 지 도록 끓이 고 그동안 오레 가노 , 타임 , 넛 맥 , 소금 , 후추 도 약간 씩 넣 었 다 . 소고기 필링 은 수분 이 거의 없 도록 바 특 하 게 졸였 다 . 오븐 용 그릇 에 소고기 필링 을 깔 고 매시드 포테이토 를 얹 어서 토닥토닥 한 다음 체다 치즈 를 듬뿍 올렸 다 . 180 도 의 오븐 에 15 ~ 20 분 정도 치즈 가 노릇노릇 하 게 익 을 정도 로 구워서 완성 . 뜨거우 니까 5 분 정도 식혀서 먹 으면 적당 하 다 . 전통 음식 들 은 보통 익숙 하 고 좋 은 조합 이 많 으니 셰 퍼즈 파이 역시 소고기 필링 에 매쉬 드 포테이토 의 조합 이 좋 다 . 구수 하 면서 도 고소 하 고 치즈 도 노릇노릇 하 니 잘 어울리 고 고기 와 감자 가 전반 적 으로 부드러워서 먹 기 도 좋 았 다 .',\n",
       "       '과학 철학자 들 중 에서 대중 에게 가장 알려진 학자 는 단연 컨대 토마스 쿤 입니다 . 많 은 사람 들 이 애매 하 게 나마 알 다시피 그 는 과학 에 있 어서 \\' 패러다임 \\' 이 중요 하 다고 주장 하 였 고 , 그 패러다임 은 과학자 집단 이 라는 하나 의 사회 가 결정 하 는 것 이 라고 하 였 습니다 . 콰인 에서 도 그랬 지만 , 토마스 쿤 에서 도 직접 적 으로 비트겐슈타인 의 후기 사상 을 언급 하 지 는 않 을 것 입니다 . 그러나 읽 으시 다 보 면 그 와 의 연관 점 을 찾 게 될 것 이 라고 믿 습니다 . 쿤 의 혁명 적 인 주장 : 과학 은 사회 다 쿤 이전 까지 는 과학 을 평면 적 인 것 으로 생각 해 왔 습니다 . 논리 실증주의 - 검증 주의 나 반증주의 는 아 에 과학 의 구조 를 논하 지 않 았 고 , 콰인 은 중심부 - 주변 부 의 구조 를 제시 했 지만 , 이 는 매우 단순 한 도식 이 었 습니다 . 쿤 은 과학 에 분명 한 구조 가 있 으며 , 그 구조 는 콰인 처럼 단순 하 게 평면 적 인 도식 으로 제시 될 수 있 는 것 이 아니 라고 합니다 . 그 는 과학 은 매우 입체 적 인 구조 를 지닌다고 하 며 과학 을 하나 의 사회 로 여기 기 도 합니다 . 심지어 는 그 는 과학 의 구조 를 종교 의 구조 와 동일시 하 기 도 합니다 . 쿤 이 보 기 에 종교 에 는 핵심 교리 가 있 고 주변 적 인 교리 들 이 있 고 , 교리 들 을 가르치 고 , 지지 하 는 사제 들 이 있 습니다 . 쿤 은 과학 역시 중심 이론 이 있 고 , 주변 적 인 이론 이나 결과물 들 이 있 다고 합니다 . 이 부분 까지 는 콰인 의 이론 과 비슷 하 게 들릴 수 있 지만 , 그 는 이 에 더 해 과학 에 는 과학 이론 , 구조 를 지지 하 고 가르치 는 \\' 과학자 집단 ( 각 전공 자 들 의 학회 등 ) \\' 이 있 다고 합니다 . 그 가 보 기 에 는 과학 역시 사람 들 에 의해 운영 되 는 하나 의 사회 이 며 사회 현상 이 라고 하 였 습니다 . 그 는 구체 적 으로 어떻게 과학 이 사회 현상 에 가까운지 를 , 또한 사회 와 는 어떻게 다른지 를 그 만 의 독창 적 인 \\' 패러다임 ( paradigm ) \\' 이 라는 개념 으로 설명 합니다 . 패러다임 ( paradigm ) : 과학 의 이론 적 틀 쿤 의 패러다임 개념 은 크 게 \\' 분야 매트릭스 ( disciplinary matrix ) \\' 와 \\' 모범 예제 ( exemplar ) \\' 로 나눌 수 있 습니다 . 분야 매트릭스 ( paradigm as disciplinary matrix ) 는 핵심 이론 , 이론 적 인 가정 들 , 실험 방법 에 대한 지침 , 과학 적 테크닉 들 ( 가령 미분 방정식 을 푸 는 방법 들 ) , 무엇 이 해당 과학 분야 의 연구 방법 인가 에 대한 합의 , 과학 이 가진 형 이 상학 적 인 믿음 등 을 총체 하 는 단어 입니다 . 모범 예제 ( paradigm as exemplar ) 는 좁 은 의미 로 사용 되 는 \\' 패러다임 \\' 의 의미 인데 , 과학 적 연구 의 모범 사례 에 대한 합의 로 이해 하 시 면 좋 을 것 같 습니다 . 가령 , 물리학 문제 가 출제 되 었 을 때 , 어떤 접근 방식 으로 , 어떤 수식 을 써서 그 문제 를 풀 것 인가 를 제시 하 는 것 이 모범 예제 로서 의 패러다임 입니다 ㅡ 물론 이 는 분야 매트릭스 로서 의 패러다임 을 전제 합니다 ㅡ . 가령 쿤 은 뉴턴 의 『 principia mathematica ( 수학 의 원리 ) 』 을 하나 의 패러다임 으로 제시 합니다 . 뉴턴 의 저서 에 는 뉴턴 의 법칙 과 뉴턴 이 제시 한 실험 테크닉 , 수학 적 테크닉 ( 미적분 ) 도 있 지만 ( 이 는 분야 매트릭스 ) , 뉴턴 의 이론 을 적용 해서 당면 한 과학 의 문제 들 을 어떻게 풀 것 인가 에 대한 방법 론 이 제시 되 어 있 습니다 ( 모범 예제 ) . 뉴턴 의 저서 는 물리학 적 문제 ( puzzle ) 를 어떻게 풀 어야 할지 에 대한 방법 론 이 제시 되 어 있 습니다 . 고전 역학 시대 의 과학자 집단 은 그 방법 론 들 을 받아들여 연구 를 진행 합니다 . 후차 적 으로 자세히 설명 하 겠 지만 , 쿤 은 과학 의 변화 란 곧 패러다임 의 변화 이 고 , 이 는 \\' 혁명 \\' 적 으로 이루어진다고 합니다 . 그 는 패러다임 의 변화 는 곧 정치 적 혁명 이 며 , 종교 의 개종 과 같 다고 합니다 . 누적 적 으로 , 점진 적 으로 과학 이 발전 해 나가 는 것 이 아니 라 , 어떠 한 급격 한 문제 들 이나 심각 한 위기 를 만나 패러다임 의 전환 이 이루어진다고 합니다 ㅡ정확히는 여러 문제 들 이 쌓이 다가 그것 들 이 치명 적 인 공격 을 가하 기 시작 했 을 때 혁명 이 일어납니다 ㅡ . 마치 갑작스럽 게 정치 적 혁명 이 점진 적 으로 일어날 수 는 없 고 , 무신론자 가 유신론자 가 되 는 것 이 점진 적 일 수 없 듯이 , 패러다임 의 변화 역시 혁명 적 으로 이루어진다고 합니다 . 이 는 천동설 에서 지동설 로 옮겨간 것 이 혁명 적 으로 , 한 순간 에 바뀐 것 과 가 다고 합니다 . 그 는 과학 에서 \\' 개종 \\' 을 언급 한 놀라운 사람 이 었 습니다 . 그 는 과학 의 역사 란 곧 패러다임 변천 인데 , 패러다임 의 변화 는 반증주의 처럼 은 이루어지 지 않 는다고 했 습니다 . 즉 , 대담 하 게 가설 을 내세우 고 , 그것 을 부정 하 는 사례 가 나올 경우 과학 이론 이 뒤집 어 지 는 것 은 아니 라고 했 습니다 . 오히려 과학자 집단 에서 는 그런 사례 를 \\' 오류 \\' 라고 부르 기 도 합니다 . 실제로 , 빛 보다 빠른 중성 미자 가 발견 되 었 다는 실험 결과 가 발표 되 었 을 때 , 과학자 들 은 \" 그런 일 은 불 가능 하 다 \" 라고 단정짓 기 도 했 습니다 . 자기 가 신 고 있 는 양말 을 삼키 겠 다는 이야기 도 들 었 던 것 같 습니다 . 이런 부분 콰인 과 쿤 은 비슷 한 의견 을 펼치 고 있 습니다 . 이론 을 부정 하 는 결과 가 나온다고 해서 과학 이론 자체 가 붕괴 되 는 것 은 아니 라고 주장 하 니까요 . 쿤 에게 있 어서 는 이러 한 주장 은 과학 이론 이 패러다임 을 지닌다는 것 과 같 은 이야기 입니다 . 과학 이 구조 가 없이 단순히 원자론 - 환원주의 적 으로 이해 될 수 있 다면 , 패러다임 을 부정 하 는 사례 가 단 한 가지 만 나오 더라도 패러다임 은 붕괴 할 것 입니다 . 그러나 과학 에서 는 과학자 들 이 인정 하 는 핵심 이론 들 이 있 고 , 어떤 문제 에 당면 했 을 때 그 를 해결 할 수 있 는 관료제 적 인 ( 즉 입체 적 인 ) 매뉴얼 들 이 있 고 , 각 이론 들 은 콰인 이 주장 한 것 처럼 유기 적 으로 얽혀 있 습니다 . 그렇 기 때문 에 과학자 집단 은 패러다임 에 반하 는 문제 가 생겼 을 때 그 문제 를 \\' 오류 \\' 등 으로 치환 하 고 , 이론 의 중심부 가 큰 타격 을 입 을 때 까지 는 패러다임 에 반하 는 퍼즐 들 은 큰 문제 가 되 지 않 는다고 합니다 . 그러나 중심부 에 치명 적 인 타격 이 왔 을 때 , 패러다임 의 전환 이 비로소 일어나 게 됩니다 . 쿤 은 패러다임 의 전환 이 일어났 을 때 , 기존 의 패러다임 과 새로 받아들인 패러다임 은 서로 상이 한 것 이 라고 말 합니다 . 약간 의 논쟁 은 될 수 있 겠 습니다 만 , 과격 하 게 말 하 면 그 는 \\' 과학 에 는 진보 가 없 다 \\' 는 주장 을 피 게 됩니다 . 그 는 그 에 대해 \\' 통약 불 가능 성 ( incommensurability ) \\' 라는 개념 을 사용 합니다 . 통약 불 가능 성 ( incommensurability ) : 패러다임 의 곧 과학 의 변화 를 진보 라고 할 만 한 기준 이 있 는가 ? 쿤 은 패러다임 의 전환 이 일어났 을 때 , 기존 의 패러다임 과 새로운 패러다임 을 비교 할 수 있 는 직접 적 인 기준 은 없 다고 말 합니다 . 즉 , 둘 중 어떤 패러다임 이 더 옳 은 것 인지 , 더 좋 은 것 인지 는 알 수 없 다고 합니다 . 그 는 종교 에 있 어서 불교 와 기독교 의 세계관 이 다르 기 때문 에 어느 것 이 더 낫 다고 보 기 힘들 듯이 , 패러다임 역시 서로 다른 세계관 이 라고 말 합니다 . 즉 , 두 패러다임 의 비교 는 가치 기준 이 다르 기 때문 에 양자 를 비교 하 는 공약수 가 없 다고 합니다 . 이것 이 \\' 통약 불 가능 성 \\' 의 개념 입니다 . 가령 17 세기 에 뉴턴 역학 이 등장 했 을 때 이 를 받아들이 지 못하 는 사람 들 이 많 았 습니다 . 예 를 들 면 뉴턴 은 그저 중력 에 대한 개념 을 제시 하 는 것 으로 그쳤 습니다 . 이 는 혁신 적 인 방식 이 기 도 했 지만 , 물질 의 움직임 이나 중력 이 왜 존재 하 는 가 에 대한 대답 은 해 주 지 못했 습니다 . 당시 에 는 아리스토텔레스 나 데카르트 등 의 형 이 상학자 들 의 이론 이 받아들여 지 고 있 었 는데 , 이 들 은 그 에 대한 근본 적 인 해답 을 제시 했 습니다 ( 형 이 상학 적 인 ) . 그 들 에 비하 면 뉴턴 의 설명 은 매우 부족 했 습니다 . 그러나 뉴턴 역학 이 받아들여 지 고 난 다음 에 는 자연 에 대한 근본 적 인 설명 부족 등 을 기준 으로 뉴턴 을 바라보 는 방식 은 사라졌 습니다 . 자연 을 움직이 는 근본 적 인 힘 ( 그것 이 형 이 상학 적 인 것 이 든 현대 물리학 이 인정 하 는 네 가지 기초 적 이 힘 이 든 ) 에 대한 설명 이 없 어도 뉴턴 을 받아들이 게 되 었 습니다 . 근본 적 인 설명 으로 따지 면 아리스토텔레스 나 데카르트 의 방식 이 더 나 을 수 있 었 습니다 만 , 사람 들 은 뉴턴 의 기준 을 받아들이 게 되 었 습니다 . 그러나 과연 둘 은 서로 비교 가능 할까요 ? 쿤 은 뉴턴 이전 의 패러다임 과 뉴턴 의 패러다임 으로 옮겨오 면서 세계 를 바라보 는 방식 이나 기준 이 바뀌 었 기 때문 에 , 직접 적 으로 둘 을 비교 하 는 것 은 불 가능 하 다고 합니다 . 쿤 은 그러 한 패러다임 의 통약 불 가능 성 을 1 . 방법 론 적 통약 불 가능 성 2 . 관찰 의 통약 불 가능 성 3 . 의미론 적 통약 불 가능 성 세 가지 로 제시 합니다 . 1 . 방법 론 적 통약 불 가능 성 ( methological incommensurability ) 뉴턴 이전 과 뉴 턴 이후 는 서로 비교 방법 이나 비교 기준 이 달라졌 고 , 가치 에 대한 인식 이 달라졌 습니다 . 뉴턴 이전 에 는 세계 에 대한 근본 적 인 인식 을 당대 의 기준 에 일관 적 으로 설명 해 주 기 를 바랐 으나 , 뉴턴 이후 는 뉴턴 의 방식 대로 눈 앞 의 현상 을 잘 설명 하 기 만 되 면 되 었 습니다 . 쿤 에 따르 면 서로 가 받아들이 고 있 는 가치 기준 이 달랐 기 때문 에 , 둘 중 어느 것 이 더 낫 다고 말 할 수 없 습니다 . 각각 의 패러다임 은 해결 하 려는 문제 가 다르 고 , 그 에 대한 접근 방식 도 다릅니다 . 쿤 은 어떤 문제 를 해결 할 것 인가 하 는 것 을 결정 하 는 것 에 는 기계 적 으로 우위 를 결정 할 수 있 는 수단 이 없 다고 합니다 . 이 는 과학자 집단 의 decision making 에 관한 문제 입니다 . 이것 이 첫째 통약 불 가능 성 입니다 . 2 . 관찰 통약 불 가능 성 ( observational incommensurability ) 쿤 은 각각 의 패러다임 에 속한 과학자 들 은 각자 의 분야 매트릭스 의 패러다임 이 제시 하 는 이론 들 을 가지 고 현상 을 바라본다고 합니다 . 콰인 과 마찬가지 로 그 는 \\' 이론 의 관찰 의 존성 ( theory - dependence of observation ) \\' 을 제시 합니다 . 과학자 집단 은 패러다임 에 속한 기존 의 연구 들 , 실험 결과 , 이론 들 을 기준 으로 현상 을 바라봅니다 . 따라서 다른 패러다임 에 속한 과학자 들 은 같 은 현상 에 대해 서로 다른 해석 을 내놓 고 , 다른 결과 를 내놓 습니다 . 방법 론 적 통약 불 가능 성 에 의해 현상 을 해석 하 는 테크닉 이나 추론 방식 은 패러다임 에 의해 달리 됩니다 . 쿤 은 패러다임 들 이 현상 에 대한 동일 한 추론 방식 , 동일 한 해석 방식 을 내놓 더라도 , 각각 의 패러다임 의 주어진 데이터 / 현상 에 대한 인식 은 다르 다고 합니다 . 즉 , 과학자 들 은 패러다임 에 의존 하 여 현상 을 바라보 기 때문 에 , 데이터 로부터 정보 를 얻 는 추론 방식 이나 데이터 의 해석 방식 이 같 다고 하 더라도 , 그 데이터 가 본질 적 으로 어떤 것 을 의미 하 는가 는 각각 의 패러다임 에 의해 달리 된다고 합니다 ㅡ즉 서로 다른 패러다임 은 서로 다른 세계 를 봅니다 ㅡ . 이것 이 두 번 째 통약 불 가능 성 입니다 . 3 . 의미론 적 통약 불 가능 성 ( semantical incommensurability ) 쿤 은 서로 다른 패러다임 끼리 의 용어 는 서로 치환 되 거나 번역 될 수 없 다고 합니다 . 즉 , 같 은 과학 적 용어 라도 패러다임 에 따라 다른 의미 를 지니 고 , 그 의미 는 각각 의 패러다임 의 한쪽 으로 속할 수 없 다고 합니다 . 가령 고대 철학자 인 데모크리토스 의 원자론 에서 등장 하 는 \\' 원자 ( atom ) \\' 와 근대 물리학 의 개념 으로서 의 달톤 의 \\' 원자 ( atom ) \\' 라는 개념 은 서로 치환 되 거나 겹치 는 부분 이 없 다고 합니다 . 데모크리토스 의 원자 개념 은 세계 에 대한 형 이 상학 적 설명 을 위해 도입 된 철학 적 개념 이 고 , 근대 물리학 의 원자 는 세계 를 물리 적 으로 설명 하 기 위한 개념 이 니까요 . 실제로 데모크리토스 의 원자 는 \\' 결코 쪼개 질 수 없 고 세계 를 구성 하 는 무한 한 질료 이 자 서로 독립 적 인 가장 기본 단위 \\' 의 개념 이 지만 , 근대 의 원자 개념 은 현대 에 와서 더 작 은 단위 ( 쿼크 등 으로 ) 로 나뉠 수 있 고 , 유한 한 실체 들 입니다 . 쿤 은 뉴턴 역학 과 상대 성 이론 의 \\' 질량 ( mass ) \\' 에 대한 개념 또한 서로 포함 관계 에 있 거나 하 지 않 고 완전히 공통성 이 없 다고 합니다 . 가령 뉴턴 의 질량 은 질량 보존 의 법칙 을 따라 질량 의 총량 은 변하 지 않 지만 , 아인슈타인 에서 는 질량 은 에너지 로 치환 될 수 있 습니다 . 쿤 은 둘 은 같 은 용어 이 지만 서로 논리 적 으로 치환 되 거나 하 지 않 고 개념 이 서로 다르 다고 합니다 . 일반 적 인 뉴턴 - 아인슈타인 이론 의 정설 은 뉴턴 은 거시 세계 의 현상 을 설명 하 기 에 유용 하 고 , 아인슈타인 의 이론 은 거시 와 미시 세계 를 모두 설명 하 기 에 아인슈타인 으로 의 패러다임 전환 은 과학 적 진보 라고 여겼 습니다 . 그러나 쿤 에 있 어서 는 사용 되 는 개념 마저 비교 할 수 없 을 정도 로 , 각각 의 패러다임 사이 에서 는 \\' 다름 \\' 이 강조 되 게 됩니다 . 이것 이 셋째 통약 불 가능 성 입니다 . 셋째 통약 불 가능 성 은 특히 쿤 의 전체 론 적 관점 을 보여 줍니다 . 뉴턴 에서 아인슈타인 으로 의 패러다임 전환 에서 \\' 질량 \\' 이 라는 언어 의 의미 가 변한 것 은 , 각각 의 패러다임 이 유기 적 으로 작동 하 였 기 때문 입니다 . 각각 의 패러다임 은 서로 다른 세계관 을 가지 고 있 고 , 서로 다른 방법 론 에 , 과학 적 테크닉 도 다릅니다 . 또한 해결 하 고자 하 는 문제 가 다릅니다 . 그렇 기 때문 에 다른 패러다임 내 에서 사용 되 는 용어 는 이름 은 같 더라도 의미 가 다를 수 밖에 없 습니다 . 언어 는 원자론 - 환원주의 적 으로 이해 될 수 없 고 , 각각 이 어떤 언어 체계 내부 에서 어떤 의미 를 지니 는가 에 따라 결정 되 기 때문 입니다 . 이 부분 은 비트겐슈타인 으로부터 왔 다고 이해 되 는 부분 입니다 . 쿤 은 위 와 같 은 세 가지 통약 불 가능 성 을 기준 으로 패러다임 은 서로 치환 이 불 가능 하 고 , 어느 쪽 이 어느 쪽 에 포함 된다고 생각 하 지 않 았 습니다 . 즉 , 패러다임 은 서로 다를 뿐 이 라는 것 입니다 . 이러 한 생각 은 과학 에 상대주의 논쟁 을 불러 왔 습니다 . 즉 , 과학 에 진보 가 없 고 다를 뿐 이 라면 도대체 패러다임 의 변화 에 는 무슨 의미 가 있 냐는 논쟁 이 벌어졌 습니다 . 패러다임 의 전환 에 진보 가 없 다면 데모크리토스 의 원자론 에서 달톤 의 원자론 으로 , 아리스토텔레스 에서 뉴턴 으로 , 뉴턴 에서 아인슈타인 으로 의 패러다임 전환 이 무슨 의미 가 있 냐는 논쟁 입니다 . 진보 를 논할 수 있 으려면 그 를 논할 어떤 기준 이 필요 한데 , 쿤 에 따르 면 패러다임 은 서로 다를 뿐 이 기 에 그 에 대한 공통 적 인 기준 을 세울 수 가 없 습니다 . 그것 이 통약 불 가능 성 에서 그 가 논하 고자 했 던 것 이 었 습니다 . 쿤 은 그러 한 비판 에 대해 자신 은 상대주의자 가 아니 며 , 패러다임 사이 의 비교 가 불 가능 한 것 은 아니 라고 주장 했 습니다 . 그 는 패러다임 의 전환 을 설명 할 수 있 는 다섯 가지 기준 이 있 다고 하 였 습니다 . 1 . 정확 성 ( accuracy ) 2 . 일관 성 ( consistency ) 3 . 범위 ( scope ) 4 . 단순 성 ( simplicity ) 5 . 생산 성 ( fruitfulness ) \\' 정확 성 \\' 은 패러다임 을 받아들였 을 때 패러다임 의 이론 이 동일 한 과학 분야 내 에서 기존 의 관찰 들 과 실험 들 에 대해 모순 을 낳 지 않 아야 한다는 것 입니다 . \\' 일관 성 \\' 은 동일 한 과학 분야 뿐 만 아니 라 관련 된 과학 이론 들 과 모순 을 낳 지 않 아야 함 을 의미 합니다 . \\' 범위 \\' 는 패러다임 이 얼마나 현상 을 설명 할 수 있 는 범위 를 나타냅니다 . \\' 단순 성 \\' 은 패러다임 이 단순 하 면서 어떠 한 것 을 받아들이 지 않 았 을 때 그 \\' 단순 성 \\' 이 현상 에 대한 설명 이 혼란 스러워 지 거나 고립 되 는 경우 가 적 어야 한다는 것 입니다 . \\' 생산 성 \\' 은 패러다임 을 받아들였 을 때 향후 과학 연구 에 불 을 붙일 수 있 음 을 나타냅니다 . 즉 , 패러다임 을 통해 이러이러 한 새로운 현상 을 설명 할 수 있 고 , 과거 에 밝혀 지 지 않 은 관계 들 을 설명 하 고 밝힐 수 있 음 을 나타냅니다 . 쿤 은 정확 성 이 높 고 , 더 일관 적 이 고 , 설명 할 수 있 는 범위 가 넓 고 , 단순 하 고 , 생산 성 이 높 은 패러다임 으로 의 전환 이 이루어진다고 하 였 습니다 . 패러다임 들 이 통약 불 가능 할지라도 비교 가 불 가능 한 것 은 아니 며 , 위 와 같 은 기준 을 통해 패러다임 의 전환 이 이루어진다고 하 였 습니다 . 쿤 은 이러 한 패러다임 의 개념 을 가지 고 과학 이론 의 역사 를 설명 합니다 . 지금 부터 는 그 에 대해 살펴보 도록 하 겠 습니다 . 과학 의 역사 : 패러다임 은 어떻게 흘러가 는가 쿤 은 과학 의 역사 의 구조 를 \\' 전 과학 ( prescience ) - 정상 과학 ( normal science ) - 위기 - 혁명 - 새로운 정상 과학 - 새로운 위기 -...\\' 로 제시 했 습니다 . \\' 전 과학 \\' 은 말 그대로 과학 이전 의 단계 를 의미 합니다 . 정확히 말 하 자면 \\' 패러다임 \\' 이 부재 한 학문 단계 를 의미 합니다 . 정상 과학 은 하나 의 패러다임 이 유일 하 게 존재 하 는 단계 를 의미 합니다 . 어떤 것 이 \\' 패러다임 \\' 인가 아닌가 하 는 것 은 위 에서 설명 한 분야 매트릭스 , 모범 예제 로 의 패러다임 이 말 해 주 지만 , 이 를 최종 적 으로 결정 하 는 것 은 학문 공동체 입니다 . 패러다임 이 되 기 위해서 는 학문 공동체 에 속한 구성원 들 이 100 % 에 수렴 하 도록 같 은 분야 매트릭스 , 모범 예제 를 수용 해야 만 합니다 . 즉 , 패러다임 의 전환기 가 아닌 시대 ( 곧 정상 과학 의 시기 ) 에 는 모든 학자 들 이 한 현상 에 대해 같 은 해석 을 내놓 아야 하 며 , 모순 되 거나 매우 다른 이야기 를 해서 는 안 됩니다 . 모두 가 동일 한 학문 적 방법론 이나 세계관 , 과학 적 테크닉 , 현상 에 대한 해석 방법 을 가지 고 있 어야 하 고 , 무엇 보다 도 학문 공동체 에서 나타나 는 주 이론 에 대해 이견 ( 異見 ) 이 없 어야 합니다 . 만약 이러 한 것 들 이 학문 공동체 내 에서 만장일치 에 가깝 게 인정 된다면 ( 사실 상 일상 적 인 수준 에서 만장일치 라고 보 는 게 좋 습니다 ) , 비로소 그 학문 을 과학 이 라고 할 수 있 습니다 . 이 에 따르 면 인간 간 의 메커니즘 을 따지 는 현대 의 어떤 학문 도 과학 이 될 수 없 습니다 . 현대 사회 에서 는 경제학 , 통계학 , 심리학 등 을 사회 \\' 과학 \\' 이라고 부르 지만 쿤 의 기준 에서 는 그렇 지 않 습니다 . 꽁 트 나 논리 실증주의 의 영향 을 받 아 양 적 연구 가 대세 적 으로 활발히 이루어지 긴 하 지만 , 자연 이 아닌 인간 현상 에 대한 해석 이 양 적 연구 만 으로 는 완전히 하나 로 겹쳐지 지 않 기 때문 입니다 . 사회 과학 의 연구 방법 에 대해 실증주의 적 연구 ( 양 적 연구 ) 와 해석학 적 연구 ( 곧 질 적 연구 ) , 변증법 적 연구 방법 등 에 대한 논란 이 \\' 존재 \\' 합니다 . 쿤 의 기준 에 따르 면 과학 에서 는 그런 논란 자체 가 불 가능 해야 합니다 . 게다가 사회 과학 에서 모든 학자 들 이 하나 의 세계관 , 동일 한 연구 방법 을 지닌 것 은 아니 며 , 이론 에 대한 절대 적 인 동의 가 있 지 는 않 습니다 . 즉 , 사회 과학 에 는 패러다임 이 존재 하 지 않 습니다 . 결론 적 으로 , 어떤 학문 이 과학 인가 아닌가 하 는 것 은 전환기 가 아닐 때 에 유일 한 패러다임 이 존재 하 는가 아닌가 로 나뉘 게 됩니다 . 전 과학 에서 비로소 패러다임 이 탄생 하 면 , 그 학문 은 과학 이 되 며 , 그 상태 를 \\' 정상 과학 ( normal science ) \\' 이라고 합니다 ( 혹은 통상 과학 이 라고 도 합니다 ) . 정상 과학 의 시기 에 는 패러다임 에 따라 연구 를 수행 하 며 , 각종 퍼즐 들 을 풀 게 됩니다 . 정상 과학 의 시기 에 항상 문제 가 없 는 것 은 아니 며 , 예외 사항 이나 풀리 지 않 는 문제 들 은 있 다고 합니다 . 그러나 정상 과학 시기 에 패러다임 의 문제 를 발견 한 사람 은 과학자 집단 에게 공격 을 받 습니다 . 가령 뉴턴 시기 에 아인슈타인 을 주장 하 게 되 면 , 그 사람 은 패러다임 을 벗어난 과학자 로서 고전 역학 을 지지 하 는 과학자 들 에게서 공격 을 받 습니다 . 혹은 문제 가 있 는 부분 만 일부 수정 하 거나 변칙 사례 로 받아들이 는 식 으로 상황 이 전개 된다고 합니다 . 이 는 반증주의 적 인 생각 과 는 반대 이 며 , 콰인 의 생각 과 비슷 합니다 . 정상 과학 의 시기 에서 예외 나 변칙 사례 가 쌓이 고 강력 하 게 제시 되 어서 패러다임 의 중심부 , 세계관 , 기본 적 인 가정 들 을 흔들 게 되 면 그때 가 바로 패러다임 \\' 위기 \\' 의 때 입니다 . 쿤 은 위기 의 때 에 정상 과학자 들 은 형 이 상학 적 인 논쟁 을 벌이 기 시작 하 고 , 기존 의 패러다임 에 대한 불만 을 토로 한다고 합니다 . 그 들 은 이론 적 혁신 을 주장 하 게 됩니다 . 만약 , 이러 한 때 에 문제 를 잘 해결 해 줄 것 으로 보이 는 새로운 과학 이론 이 나타나 게 되 면 , 기존 의 패러다임 과 의 경쟁 이 시작 된다고 합니다 . 이 때 에 위기 에 처한 과학 을 \\' 비 통상 적 과학 ( extraorinary science ) \\' 라고 부릅니다 . 기존 의 패러다임 을 지닌 비 통상 적 과학 과 새로운 패러다임 을 제시 해 줄 것 으로 보이 는 과학 이론 사이 에 경쟁 이 일어납니다 . 그러나 통약 불 가능 성 에 의해서 이 들 의 논쟁 이 결코 어떤 것 이 더 논증 적 이 고 옳 은 것 인가 를 보장 해 줄 수 없 습니다 . 그저 그 들 은 서로 다른 기준 을 가지 고 논쟁 을 벌이 고 있 을 뿐 입니다 . 경쟁 하 는 과학자 들 은 서로 인신공격 도 하 고 , 과학 의 영역 을 벗어나 다른 학문 ( 주로 철학 ) 적 영역 에 대해서 논하 기 시작 하 고 , 각각 의 과학 이론 이 함축 할 수 있 는 \\' 의미 \\' 에 대해서 도 따진다고 합니다 . 그러나 쿤 은 패러다임 의 논쟁 은 논증 의 문제 가 아닌 \\' 설득 \\' 의 문제 이 며 , 이 는 곧 과학자 공동체 의 문제 라고 합니다 . 비트겐슈타인 식 으로 말 하 자면 , 생활 양식 이 전혀 다른 공동체 중 에서 무엇 을 골라야 하 는가 와 같 은 것 입니다 . 쿤 은 이때 에 과학자 집단 이 위 에서 설명 한 다섯 가지 기준 으로 패러다임 을 고르 게 된다고 합니다 . 이때 에 패러다임 의 변화 가 일어나 는데 , 쿤 은 이것 이 과학 이론 의 \\' 혁명 \\' 이라고 했 습니다 . 비 통상 적 과학 에서 새로운 과학 이론 으로 넘어가 는 것 은 마치 천동설 에서 지동설 로 넘어가 는 것 과 같 으며 , 종교 에서 의 개종 과 도 같 다고 했 습니다 . 그렇게 패러다임 의 전환 은 갑작스럽 게 혁명 적 으로 일어납니다 . 비 통상 적 과학 은 이제 더 이상 패러다임 이 되 지 못하 고 , 경쟁 에서 이긴 과학 이론 이 새로운 \\' 패러다임 \\' 으로 제시 되 고 , 새로운 정상 과학 의 시기 가 된다고 합니다 . 새로운 패러다임 이 받아들여 지 고 나서 는 전 에 있 었 던 형 이 상학 적 논쟁 들 과 과학 분야 이외 의 논쟁 은 모두 종료 된다고 합니다 . 시간 이 지남 에 따라 모든 과학자 집단 이 새로운 패러다임 을 따르 게 됩니다 . 새로운 정상 과학 은 다시 위 와 같 은 과학 혁명 의 구조 를 거치 게 되 며 , 이 는 지속 됩니다 . 결국 패러다임 의 문제 는 과학자 집단 이 무엇 을 받아들일 것 인가 에 관한 문제 입니다 . 이것 이 맨 처음 에 언급 했 던 \\' 과학 은 사회 다 \\' 라는 문장 의 의미 입니다 . 이 는 비트겐슈타인 후기 이론 에서 언어 는 결국 언어 를 사용 하 는 \\' 공동체 \\' 에 의해 결정 된다는 의미 와 도 상통 합니다 . 또한 언어 의 의미 는 언어 체계 에서 어떤 역할 을 하 느냐 에 따라 결정 되 고 , 생활 양식 , 언어 의 사회 성 에 의해 결정 된다는 전체 론 적 인 관점 도 쿤 에 투영 되 어 있 습니다 . 쿤 역시 의미론 적 통약 불 가능 성 에서 뉴턴 의 \\' 질량 \\' 과 아인슈타인 의 \\' 질량 \\' 개념 은 서로 다른 패러다임 의 유기 성 안 에서 의미 가 결정 되 기 때문 에 서로 다르 다는 것 을 이야기 했 습니다 . 또한 콰인 에서 언급 된 \\' 관찰 의 이론 의 존성 \\' 또한 쿤 에서 도 \\' 패러다임 \\' 에 의해 관찰 이 달라진다는 내용 을 이야기 하 고 있 습니다 . 이 는 논리 실증주의 - 검증 주의 를 비판 하 는 논거 가 됩니다 ( 구조 의 유기성 ) . 구조 에 관해서 는 콰인 역시 구조 를 이야기 했 지만 , 쿤 만큼 상세 하 게 논의 가 진행 되 지 않 았 습니다 . 말 하 자면 , 콰인 은 전체론 을 전제 한 단순 한 중심부 - 주변 부 의 이론 이 었 다면 , 쿤 은 그 에 더 해 과학자 집단 의 논쟁 들 , 과학자 집단 의 세계관 , 연구 방법 등 입체 적 인 구조 를 이야기 했 습니다 . 이상 이 언급 할 만 한 쿤 의 과학 철학 입니다 . 이렇게 해서 2014 년 5 월 4 일 에 시작 한 비트겐슈타인 11 부작 연재 가 2015 년 8 월 11 일 ( 현재 새벽 1 시 50 분 ) 에 끝나 게 되 네요 . . 정말 오래 기다리 게 해서 미안 하 고 , 기다려 주 셔서 감사 합니다 . 앞 으로 는 집중 할 문제 도 있 고 곧 학기 시작 이 라 언제 돌아올지 모르 겠 지만 , 그때 는 아마 yudwig 님 께서 요청 하 신 \\' 크립키 \\' 의 언어 철학 으로 돌아올 것 같 습니다 ㅡ프레게의 언어 철학 부터 시작 할지 아니 면 크립키 만 할 것 인지 는 차후 에 생각 하 도록 하 겠 습니다 ㅡ . 다음 학기 에 두 학교 에서 불 완정 성 정리 를 배우 기 도 하 기 때문 에 마저 못 한 괴델 을 완성 할 수 도 있 을 것 같 습니다 . 항상 읽 어 주 셔서 감사 합니다 .',\n",
       "       '1 . htop 란 htop 란 텍스트 모드 대화 식 프로세스 뷰어 로 ms 윈도우 의 \\' 작업 관리자 \\' 와 비슷 하 며 cpu 사용량 , 메모리 사용량 등 리눅스 운영 체제 에서 시스템 자원 을 비 쥬 얼 적 으로 모니터링 이 가능 합니다 . 다양 한 기능 을 가지 면서 손쉽 세 사용 할 수 있 다는 것 이 htop 의 특징 입니다 . 2 . htop 기능 - 프로세스 선택 을 커서 나 , 마우스 를 사용 할 수 있 습니다 . - pstree 와 top 을 함께 보 는 기능 이 있 습니다 . - 선택 된 프로세스 를 죽이 거나 우선 순위 를 변경 할 수 있 습니다 . - 특정 프로세스 이름 으로 검색 , 필터링 하 여 현황 을 볼 수 있 습니다 . - 선택 된 프로세스 의 \\' lsof \\' 명령 결과 를 볼 수 있 습니다 . - 선택 된 프로세스 의 시스템 콜 을 확인 하 는 strace 를 할 수 있 습니다 . 3 . htop 다운로드 , 설치 및 실행 ▶ 다운로드 [ root @ localhost ~] wget [ URL ] [ 32 비트 ] [ root @ localhost ~] wget [ URL ] [ 64 비트 ] ▶ 설치 [ root @ localhost ~] rpm - uvh htop - 1 . 0 . 3 - 1 . el 6 . rf . i 686 . rpm [ root @ localhost ~] tar xvfp htop - 1 . 0 . 2 . tar . gz [ root @ localhost ~] cd htop - 1 . 0 . 2 [ root @ localhost ~] . / configure [ root @ localhost ~] make && make install ( libncurses 라이브러리 관련 오류 가 나 면 , yum install ncurses * 을 설치 합니다 . ) ▶ 실행 [ root @ localhost ~ ] htop htop 화면 을 살펴보 면 왼쪽 상단 에 cpu , swap 메모리 , 메모리 사용 률 이 표현 되 어 있 으며 하단 에 는 모니터링 되 고 있 는 프로세스 가 보입니다 . 이 는 기본 적 으로 1 초 에 한 번 갱신 됩니다 . htop 에서 는 f 1 ~ f 10 까지 단축키 가 있 으며 단축키 마다 기능 이 정해져 있 습니다 . 4 . 프로세스 정보 pid : 프로세스 의 프로세스 id 번호 user : 프로세스 의 소유자 pr : 프로세스 의 우선 순위 ni : 우선 순위 에 영향 을 주 는 프로세스 의 nice 값 virt : 프로세스 가 사용 중 인 가상 메모리 양 res : 프로세스 가 사용 중 인 물리 ram 의 양 ( 단위 는 킬로바이트 ) shr : 프로세스 가 사용 중 인 공유 메모리 양 s : 프로세스 의 현재 상태 ( zombied , sleeping , running , uninterruptedly sleeping , traced ) % cpu : 프로세스 가 프로세서 를 사용 한 시간 의 백분율 % mem : 프로세스 가 사용 중 인 물리 ram 의 백분율 time + : 프로세스 가 프로세서 를 사용 한 시간 command : 프로세스 시작 에 사용 한 명령어 명 ▶ f 1 ( help ) : htop 의 도움 말 을 볼 수 있 으며 , 단 축기 의 기능 을 알 수 있 다 . cpu , 메모리 등 막대그래프 의 색깔 별 의미 를 알 수 있 다 . 아무 키나 누르 면 도움 말 페이지 에서 빠져 나갈 수 있 습니다 . ▶ f 2 ( setup ) : htop 설정 단축키 로써 f 2 또는 \\' s \\' 대문자 키 를 입력 하 면 됩니다 . 설정 에서 는 상단 에 보여 줄 cpu 메모리 에 대한 정보 를 추가 / 제거 할 수 있 으며 디스플레이 옵션 설정 도 가능 합니다 . 옵션 을 통해 색상 과 보여 주 기 옵션 을 bar -> led 로 바꾸 어 보 았 습니다 . ▶ f 3 ( search ) : f 3 또는 \\'/\\' 눌러 해당 프로세스 를 검색 할 수 있 습니다 . http 프로세스 를 검색 한 결과 입니다 . 단어 를 입력 하 는 순간 해당 프로세스 로 이동 하 게 되 며 f 3 키 를 다시 입력 하 면 다음 프로세스 로 이동 됩니다 . ▶ f 4 ( filter ) : f 4 또는 \\'\\\\\\' 를 입력 하 면 됩니다 . ps - ef | grep mysqld 같 은 명령어 로써 원 하 는 프로세스 만 모니터링 할 수 있 는 기능 입니다 . 필터 기능 을 사용 하 여 \\' mysql \\' 프로세스 를 찾 았 습니다 . \\' enter \\' 키 를 입력 하 면 필터링 된 프로세스 만 보이 게 됩니다 . ▶ f 5 ( tree ) : f 5 또는 \\' t \\' 키 를 입력 하 면 됩니다 . pstree 명령어 와 같 은 기능 으로 프로세스 의 부모 자식 관계 를 트리 형태 로 보여 주 는 기능 이 며 , 한번 더 키 를 입력 하 면 트리 를 보여 주 거나 그 반대 기능 을 합니다 . \\'+\\' \\'-\\' 키 를 이용 해 트리 를 펼치 거나 접 을 수 있 습니다 . 프로세스 를 트리 구조 형태 로 볼 수 있 어 편리 합니다 . * pstree 명령어 는 프로세스 간 의 부모 자식 관계 를 트리 형태 로 출력 함 으로써 시스템 의 프로세스 의 상태 를 점거 하 는 툴 입니다 . ▶ f 6 ( sort ) : 프로세스 를 cpu , 메모리 , 사용자 , 우선 순위 , 프로세스 이름 등 원 하 는 방식 으로 정렬 하 여 보다 쉽 게 모니터링 할 수 있 습니다 . pid 기준 으로 정렬 한 모습 입니다 . f 6 에서 p ( cpu ) , m ( mem ) , t ( time ) 키 를 사용 해서 도 가능 합니다 . ▶ f 7 , f 8 ( nice ) : 프로세스 의 우선 순위 를 바꾸 는 단 축기 입니다 . 해당 프로세스 를 선택 하 여 f 7 ehsms \"]\" 키 를 사용 하 여 높이 며 \\' f 8 \\' 키 또는 \\']\\' 를 사용 하 여 우선 순위 를 내릴 수 있 습니다 . ▶ f 9 ( kill ) : 프로세스 를 종료 시키 는 단축키 입니다 . 보통 프로세스 를 종료 시키 려면 ps 명령어 로 해당 pid 를 찾 아 kill - 9 pid 명령어 로 종료 시킵니다 . htop 에서 해당 프로세스 를 선택 후 f 9 또는 \\' k \\' 키 를 입력 하 여 해당 프로세스 를 종료 시킬 수 있 습니다 . 만약 여러 프로세스 를 한 번 에 종료 시키 려면 \\' space \\' 키 로 다수 의 프로세스 를 선택 후 \\' f 9 \\' 키 를 눌러 취소 합니다 . ▶ f 10 ( quit ) : htop 종료 ▶ 그 밖 의 기타 기능 1 . 특정 프로세스 모니터링 \" u \" 키 를 입력 하 면 실행 중 특정 사용 자 의 프로세스 만 볼 수 있 습니다 . 사용자 를 선택 하 여 해당 사용 자 의 프로세스 만 볼 수 있 습니다 . 2 . 우선 순위 변경 : \\' i \\' 키 를 입력 하 면 i / o 우선 순위 를 변경 할 수 있 습니다 . 3 . 시스템 콜 트레이스 ( strace ) : 특정 프로세스 선택 후 \\' s \\' 키 를 누르 게 되 면 , 해당 프로세스 의 콜 을 보여 줍니다 . strace 란 ? stem - call tracer 의미 하 는 말 로 strace 에 의해 추적 되 는 프로세스 의 시스템 콜 , 신호 를 모두 화면 에 출력 합니다 . 4 . 열린 파일 확인 ( lsof ) : 프로세스 선택 후 , \\' l \\' 키 를 누르 면 특정 프로세스 에서 열 고 있 는 파일 을 볼 수 있 습니다 . 5 . htop 화면 에서 숫자 를 입력 하 면 해당 pid 가진 프로세스 를 찾 을 수 있 습니다 . 대한민국 대표 idc korea idc l 서버 호스팅 , 코 로케이션 , 매니 지드 호스팅 , idc , 도메인 , 웹 호스팅 [ URL ]',\n",
       "       '때아닌 곰탕 이 논란 에 휩싸였 습니다 . 구속 된 비선 실세 가 조사 를 받 는 도중 배달 시켜 먹 었 다는 메뉴 가 곰탕 인 데 서 비롯 된 것 인데요 . 곰탕 암호 설 에 순 살 곰탕 출시 해프닝 까지 . ... 우습 지만 웃 지 못할 일 들 이 연일 쏟아지 고 있 지요 . 곰탕 은 서민 적 이 면서 도 남녀노소 ( 간혹 물 에 빠진 고기 를 안 좋 아 하 시 는 분 들 을 제외 하 고 는 ) 대부분 좋 아 하 는 한 끼 식사 메뉴 죠 . 곰탕 이 란 곰국 이 라고 도 부르 는 데 , 소 의 뼈 나 양 · 곱창 · 양지머리 등 의 국거리 를 넣 고 진하 게 푹 고 아서 끓인 국 을 말 한답니다 . 특히 요즘 처럼 바람 이 차가워질 때 면 더 생각나 는 음식 이 기 도 . .... 참 , 비슷 한 메뉴 인 설렁탕 과 곰탕 의 차이점 은 알 고 계시 죠 ? 소 의 뼈 를 고아 만들 어 국물 이 뽀얀 것 은 설렁탕 , 고기 와 내장 을 넣 고 고아 국물 이 맑 은 건 곰탕 . .. 이 라는 점 . 주바리 도 곰탕 을 무척 좋 아 하 는 데 요 , 제 가 좋 아 하 는 곰탕 이 애꿎 은 눈총 을 받 고 있 어 마음 이 짠하 답니다 . ‘ 이러 려고 내 가 곰탕 을 먹 었 나 ~’ 하 는 심정 이 라고 나 할까 ㅋㅋ . 따끈따끈 한 곰탕 에 하얀 쌀밥 을 말 고 알맞 게 잘 익 은 깍두기 하나 얹 어서 한 입 , 크 ~ 생각 만 해도 내장 이 후끈 데워 지 는 기분 이 드 네요 . 이번 포스팅 에서 는 우리 서민 들 의 차갑 고 쓰린 마음 속 까지 따 ~ 뜻 하 게 데워줄 곰탕 맛집 을 가 볼까 합니다 . ◇ 하 동관 곰탕 하 면 가장 많 은 분 들 이 떠올릴 만 한 식당 이 바로 이 곳 , 하 동관 인데요 . 대 를 이 어 70 년 간 명맥 을 이 어 왔 다는 사실 만 으로 도 인정 할 수 밖에 없 는 . ... 그런 식당 . 십 여 년 전 청계 천 일 대 의 재 개발 사업 으로 60 여 년 간 영업 을 하 던 수 하동 을 떠나 명동 에 새로 둥지 를 틀 었 고요 , 여의도 와 코엑스몰 에 도 직영 점 을 운영 하 고 있 답니다 . 한국 사람 보다 요우 커 들 이 더 많 아 요즘 엔 별로 가 고 싶 지 않 은 명동 거리 한 복판 에 자리 잡 은 하 동관 . 이번 에 알 게 된 놀라운 사실 은 하 동관 에서 는 70 여 년 간 한 번 도 탕 을 더 끓이 거나 탕 이 남 아 본 적 이 없 다는 것 이 전통 이 자 자랑 거리 라고 하 네요 . 지금 도 오후 4 시 까지 밖 에 영업 을 하 지 않 는 데 , 예전 부터 특별히 손 님 이 많 은 날 이 면 2 시 에 도 문 을 닫 기 일쑤 였 다고 . ... 얼마나 대단 한 맛 인지 . .. 이 까칠 한 주바리 가 한 번 먹 어 보 도록 하 겠 습니다 . 아직 12 시 도 채 되 지 않 은 11 시 30 분경 이 었 는데 꽤 많 은 손님 들 이 들락날락 하 는 모습 을 볼 수 있 었 습니다 . 이 때 는 대기 없이 입장 했 지만 몇 분 지나 지 않 아 줄 을 서기 시작 하 더라고요 . 날씨 가 쌀쌀 해질수록 대기 시간 은 길 어 지 리라 짐작 되 고요 . 그런데 식당 문 을 들어서 자마자 자리 에 앉 기 도 전 에 계산 부터 하 라며 손바닥 을 흔드 는 카운터 의 아주머니 ( 사장 님 일 수도 ) . 개인 적 으로 선불 시스템 도 꺼려할 뿐 더러 불쾌 함 이 곰탕 국물 처럼 우러나왔 지만 취재 를 위해 꾹 참고 착석 . 메뉴 는 곰탕 과 수육 뿐 . 그런데 차림표 에 특이 한 내용 이 눈 에 띄 죠 ? 보 , 특은 당연히 보통 , 특은 스페셜 일 테 지만 , 그 밑 에 씌 어 져 있 는 ‘ 엄지 척 ’ 옆 에 20 공 20 , 000 원 25 공 은 25 , 000 원 . ... 이건 대체 무슨 말 일까요 ? 예전 엔 단골 들 만 알 고 있 는 암호 같 은 것 이 있 다고 하 더라고요 . 밥 을 줄이 고 고기 를 더 넣 은 맛 배기 , 고기 를 더 풍성 하 게 놓 은 스무 공 , 깍두기 국물 을 부 은 ‘ 깍 둑 ’ 날달걀 을 넣 은 ‘ 통닭 ’ 등등 . ... 을밀대 에 가 면 메뉴판 에 써 있 지 는 않 지만 “ 양 마니 ” 라고 외치 는 것 과 같 은 암호 인 거 죠 . 그러니까 20 공 은 특보 다도 더 고기 가 많이 얹 어 져 있 는 것 을 말 하 는 거 고 , 25 공 은 그 보다 더 더 많이 올린 것 이 겠 죠 ? 잠시 후 에 테이블 에 나온 보통 곰탕 사진 을 보 시 면 아마도 20 공 ! 하 고 외치 고 싶 으실 겁니다 ㅋㅋ 곰탕 에 빠져서 는 안 될 파 는 테이블 기본 세팅 . .. 느끼 함 을 잡 아 주 고 향기 를 더 해 주 죠 . 배추김치 와 깍두기 가 섞여 있 는 1 인 1 김치 . 보통 하나 , 특 하나 의 곰탕 두 그릇 이 나왔 습니다 . 입장 과 동시 에 주문 하 고 계산 하 고 자리 에 앉 으면 번개 같이 음식 이 서빙 되 더라는 . ... 이게 12 , 000 원 짜리 보통 ( 고기 의 양 이 심하 게 섭섭 하 죠 ㅋㅋ ) 이게 15 , 000 원 짜리 특 ( 내장 섞 은 것 ) . 밥 은 미리 말 아 져 나오 고요 , 놋그릇 을 사용 하 는 전통 을 버리 지 않 은 점 은 맘 에 드 네요 . 곰탕 국물 이 탁하 지 않 고 깔끔 한 편 이 죠 . 맛 도 군더더기 없이 깔끔 했 습니다 . 조미료 에 길들여진 젊 은 사람 들 입맛 에 는 좀 싱겁 고 밋밋 할 수 도 . ... 제게는 좋 은 걸 보 면 이제 어르신 입맛 에 근접 했 나 봅니다 . 한우 암소 고기 를 사용 해 , 서울 반 가촌 의 전통 을 그대로 이어 끓여 낸다는 이야기 가 이 국물 에서 그대로 느껴 지 네요 . 군더더기 없이 깔끔 담백 한 맛 . 더군다나 80 년 가까이 같 은 거래처 에서 고기 를 들여 온다고 하 니 대단 하 네요 . 이제 파 를 투척 해서 처묵 처묵 해 볼까요 . 파 없 는 설렁탕 이나 곰탕 은 생각 하 기 가 힘들 죠 . 평양 면옥 의 냉면 처럼 맑 은 국물 에 는 간 도 거의 최소 화 한 듯 . .. 싱거운 분 은 테이블 에 놓인 굵 은 소금 으로 입맛 에 맛 게 간 을 하 면 됩니다 . 요렇게 밥 과 국물 을 함께 떠서 고기 한 점 올리 고 시큼 한 깍두기 까지 한 입 베 어 물면 . ... 캬 ~~ 입 속 의 힐링 은 특별 한 음식 이 아니 라 이런 친근 한 맛 에서 비롯 되 는 듯 합니다 . 그런데 또 거슬리 는 점 이 있 네요 . 곰탕 을 먹 기 시작 하 면서 부터 대기 손님 들 이 가게 안 으로 물밀 듯 밀려 들어왔 습니다 ( 사진 보다 더 많 은 대 기자 가 있 었 는데 사진 찍 기 가 좀 곤란 해 남기 질 못했 고 . ..). 테이블 과 테이블 사이 에 많 은 사람 들 이 서 있 다 보 니 , 먹 는 사람 도 불편 하 고 서 있 는 사람 도 뻘쭘 하 고 . ... 손 님 이 맛있 는 음식 을 제대로 즐기 도록 가게 밖 으로 줄 을 서 게 하 거나 , 대기 장소 를 따로 마련 해야 하 는 것 아닌가요 . 하 동관 은 그 이름값 만큼 맛 에 있 어서 는 엄지 쌍 따 봉 을 줄 만 하 지만 맛 빼 고 다른 면 에 있 어서 는 눈살 을 좀 지 푸 리 게 했 습니다 . 80 년 전통 의 하 동관 . .... 문 앞 에 내건 문구 처럼 그 맛 은 대대로 전해 마땅 하오나 그 상혼 만큼 은 절대 이번 대 에서 끊기 기 를 바람 . ◇ 애 성 회관 하 동관 이 전통 의 곰탕 강자 라고 한다면 이 집 은 신흥 강자 ( ? ) 정도 로 불릴 만 한 대요 . 2012 년 에 북창동 에 오픈 한 한우 곰탕 전문점 , 애 성 회관 입니다 . 몇 년 전 식신 이 나오 는 맛집 프로그램 에 소개 된 걸 보 고 회사 근처 라 찾아가 보 게 됐 지요 . 맛집 프로그램 을 다 신뢰 하 는 건 아니 지만 해당 프로그램 5 주년 특집 으로 숟가락 다섯 개 ( 만점 ) 를 받 은 몇 안 되 는 식당 이 었 어요 . 곰탕 과 수육 , 불고기 등 고기 메뉴 외 에 낙지볶음 정도 의 단출 한 메뉴 . 저녁 때 회식 하 기 에 도 적당 하 지만 점심 때 는 99 % 곰탕 손 님 으로 바글바글 . .. 한우 원뿔 에 투 뿔 까지 사용 한다는 자랑 . .. 최상위 로얄 급 까지 는 오버 인 듯 하 고 ㅋㅋ 이 곳 은 맛있 는 곰탕 을 7 , 000 원 에 맛볼 수 있 어 인근 직장인 들 의 점심 메뉴 로 인기 폭발 입니다 . 12 시 넘 어 도착 하 면 줄 서기 일쑤 입죠 테이블 좌석 반 , 방석 좌석 반 으로 구성 돼 있 습니다 . 하동 관급 의 다른 식당 에 비해 착한 곰탕 가격 . .. 보통 은 7 천 원 , 특은 9 천 원 . 하 동관 의 보통 12 , 000 원 특 15 , 000 원 에 비하 면 가 성비 에서 고민 없이 애 성 회관 이 위너 . 주방 이모님 피곤 하 신 듯 . ... 맛있 는 곰탕 해 주 시 느라 노고 가 많 으시 군요 . 덜 어 먹 도록 돼 있 는 김치 그릇 에 뚜껑 시스템 . .. 아주 좋 습니다 . 물개 박수 ~~ 여기 도 마찬가지 로 배추 와 무 가 섞여 있 는 김치 . .. 적당히 익 어 맛 이 좋 습니다 . 보통 하나 , 특 하나 . ... 2 , 000 원 의 차이 만큼 고기 의 양 이 풍성 . 밥 이나 국물 은 비슷 . 고기 의 부드러움 이 눈 으로 도 느껴 지 시 나요 ? 부위 가 달라서 그런지 하 동관 과 는 조금 다른 비주얼 . 하 동관 고기 가 씹 는 맛 이 있 다면 이 집 의 것 은 부드러움 그 자체 . 문 앞 에 내건 문구 대로 고기 만큼 은 최상 의 것 을 사용 한다는 점 , 의심 의 여지 가 없 네요 . 하 동관 국물 이 맑 은 편 이 라면 이 집 은 간장 을 사용 했 는지 색깔 이 좀 있 네요 . 적절 한 비유 인 지 모르 겠 으나 하 동관 이 평양 면옥 이 라면 애 상회 관 은 우래 옥이 라고 할까 ? 토렴 한 밥 과 함께 곁들여져 나오 는 국수 의 비주얼 도 사뭇 다릅니다 . 설렁탕 에서 볼 수 있 는 얇 은 소면 이 아니 라 중면 보다 살짝 두껍 고 우동 보다 는 가 는 면 . 그래서 금세 불 지 않 고 호로록 호로록 즐길 수 가 있 네요 . 작 은 방 이 하 나 있 어 8 명 정도 의 회식 이 가능 . ... 방 문 은 따로 없 고요 . 저녁 때 방문 해서 수육 도 먹 어 봤 습니다 . 곰탕 의 착한 가격 에 비하 면 35 , 000 원 은 만만찮 은 가격 이 지만 한우 라는 점 과 푸짐 한 양 을 생각 하 면 나쁘 지 않 습니다 . 곰탕 의 고기 처럼 수육 고기 도 부드럽 고 더욱 도톰 하 네요 . 수육 을 다 먹 고 나 면 요기 에 곰탕 안 에 들 어 있 던 소면 을 추가 합니다 . 부족 할까봐 국수 추가 ~ 이 넘 의 면 욕심 은 언제 쯤 놓 으려나 ㅋㅋ 국수 전골 로 새롭 게 시작 하 는 기분 ~ 애 성 회관 곰탕 은 깔끔 한 맛 에 찬한 가격 도 만족 스러웠 지만 , 선불 도 아니 고 카운터 를 보 는 사장 님 으로 추정 되 는 분 도 무척 친절 했 더랬 습니다 . 서너 번 방문 해 봤 는데 맛 에 도 편차 가 없 었 고요 . 자주 방문 하 고 싶 은 주바리 의 맛집 리스트 에 추가 했 답니다 . ◇ 은 호식 당 이번 엔 보양 식 으로 으뜸 인 꼬리곰탕 맛집 으로 가 보 실까요 ? 이 곳 도 하동 관 못지않 은 역사 를 지니 신 곳 . 원래 남대문시장 에서 인기 를 누리 던 꼬리곰탕 집 인데 서소문 에 있 는 분점 으로 찾아가 봤 습니다 . 그냥 곰탕 이 아닌 꼬리곰탕 인지라 가격 도 좀 후 덜덜 . ... 설렁탕 이나 내 장탕 등 의 메뉴 도 있 군요 . 한우 도 아니 고 호주 산 인데 도 고가 인 걸 보 면 꼬리 가 비싼 재료 이 긴 한가 봅니다 . 다른 곳 처럼 김치 는 덜 어 먹 는 시스템 . ... 깍두기 먹 기 좋 게 잘라 주 는 건 밥 얻 어 드 시 는 분 의 도리 ㅋㅋ 뚜껑 까지 구비 해 주 시 면 감사 할 텐데 . .. 꼬리 토막 하나 , 꼬리곰탕 하나 . . 비교 를 위해서 시켜 봤 습니다 . 꼬리 토막 이 뭘까 궁금 했 는데 꼬리 의 크기 를 보 니 알 겠 더군요 . 꼬리 토막 ↑ 그냥 꼬리곰탕 ↓ 원근법 감안 해서 비교 해 보 시 고요 . 꼬리 토막 은 꼬리 가 시작 되 는 부분 이 고 일반 꼬리곰탕 은 아랫 쪽 얇 은 꼬리 부분 인가 봅니다 . 곰탕 과 달리 꼬리곰탕 은 밥 이 토렴 돼 있 지 않 고 공깃밥 으로 따로 나오 네요 . 밥 을 말 지 않 고 먹 는 건 직무 유기 . .... 오래 도록 고 아 낸 꼬리 살 이 부드럽 게 떼 어 지 네요 . 포크 는 이런 용도 로 준비 된 듯 . 꼬리 살 은 곰탕 용 고기 와 는 또 다른 식감 이 네요 부드러우면서도 졸깃 함 이 . .... 국물 은 또 어떻 고요 , 곰탕 보다 확실히 진한 맛 이 입 안 과 위 를 든든 하 게 채워 줍니다 . 지난 번 국물 보양 식 편 에서 소개 해 드린 또 다른 꼬리곰탕 강자 종로 3 가 영춘 옥 도 맛있 었 지만 여기 은호 식당 도 내공 이 있 으시 네요 . 간혹 분점 이 라서 남대문 본점 보다 맛 이 덜 하 다고 지적 하 시 는 분 들 이 계시 던데 . .. 여기 서소문 점 도 전 충분히 맛있 는데요 . .... 본점 이 더 맛있 는 지 조만간 확인 취재 가 야 겠 습니다 ㅋㅋ . 아삭 시큼 깍두기 는 이 한 숟가락 을 거들 뿐 . 좀 엽기 적 인 컷 이 긴 하 지만 . .. 꼬리 토막 과 일반 꼬리 의 크기 비교 해 보 시 라고 . ... ㅎㅎ ;; 요 ~ 요 ~ 꼬리곰탕 느 님 , 찬바람 불 때 마다 생각날 것 같 아요 . 요즘 몸 도 맘 도 많이 추우 시 죠 ? 오늘 점심 엔 곰탕 한 그릇 하 러 가 야 겠 습니다 . 주말 마다 촛불 밝히 시 느라 추위 에 얼어붙 은 몸 까지 녹여줄 곰탕 같 은 사람 이 그리운 계절 이 네요 . 곰탕 같 은 마음 으로 공감 하트 도 꾸욱 해 주 세요 . ^^',\n",
       "       '유한 상태 기계 ( finite - state machine , fsm ) 유한 상태 기계 는 ai 를 구현 하 는 가장 기본 적 인 방법 중 하나 입니다 . 그림 과 같이 캐릭터 가 수행 할 행동 에 대해 상태 를 정의 해 주 고 , 컨디션 에 따라 상태 가 변경 이 됩니다 . 새로운 행동 을 추가 하 기 위해서 는 새로운 상태 를 만들 고 , 기존 상태 와 연결 을 시켜 주 면 됩니다 . 캐릭터 의 행동 을 각 상태 로 모듈 화 하 였 기 때문 에 캐릭터 의 행동 추가 / 삭제 에 대해 어느 정도 유연 함 을 가지 고 있 는 편 입니다 . 다만 , 연관 되 어 있 는 상태 들 이 많 아 지 면 많 아 질수록 컨디션 설정 도 복잡 해 지 며 관리 가 힘들 어 집니다 . 예 를 들 어 idle / move / attack 상태 에서 사용 할 수 있 는 superattack 상태 가 추가 된다고 했 을 때 , idle / move / attack 상태 에 superattack 을 사용 할 수 있 는 컨디션 을 모두 추가 수정 해야 합니다 . 행동 트리 ( behavior trees ) 행동 트리 는 유한 상태 기계 와 다르 게 이름 처럼 트리 방식 으로 행동 을 정의 합니다 . 각 node 에 selector 와 sequence 노드 를 이용 하 여 컨디션 을 체크 하 고 , 액션 을 정의 해 트리 를 구성 하 게 됩니다 . selector 는 자식 노드 를 실행 하 여 , 이 중 하나 라도 true 를 리턴 하 면 true 를 리턴 하 고 , sequence 는 모든 자식 노드 가 true 를 리턴 할 때 , true 를 리턴 하 게 됩니다 . 반 대로 sequence 는 자식 중 하나 라도 false 면 false 를 리턴 합니다 . 코드 로 보 면 이해 하 기 쉽 습니다 . class node { public : virtual bool invoke ( ) = 0 ; }; class compositenode : public node { public : void addchild ( node * node ) { mchildren . emplace _ back ( node ) ; } const std : : list & getchildren ( ) { return mchildren ; } private : std : : list mchildren ; }; class selector : public compositenode { public : virtual bool invoke ( ) override { for ( auto node : getchildren ( ) ) { if ( node -> invoke ( ) ) return true ; } return false ; } }; class sequence : public compositenode { public : virtual bool invoke ( ) override { for ( auto node : getchildren ( ) ) { if ( ! node -> invoke ( ) ) return false ; } return true ; } }; bt : : sequence * root = new bt : : sequence ( ) ; / / 루트 노드 ( 시퀀스 노드 로 생성 ) bt : : selector * selector = new bt : : selector ( ) ; / / 셀 렉터 bt : : sequence * seqorckill = new bt : : sequence ( ) ; / / 오크 가 있 으면 오크 를 공격 하 는 시퀀스 bt : : sequence * seqmove = new bt : : sequence ( ) ; / / 플레이어 이동 시퀀스 bt : : node * playerisdead = new playerisdead ( ) ; / / 플레이어 가 죽 었 는지 체크 bt : : node * checkishereorc = new checkishereorc ( ) ; / / 현 위치 에 오크 가 있 는지 체크 bt : : node * attackorc = new attackorc ( ) ; / / 오크 공격 액션 bt : : node * playermove = new playermove ( ) ; / / 플레이어 이동 액션 root -> addchild ( selector ) ; root -> addchild ( playerisdead ) ; selector -> addchild ( seqorckill ) ; selector -> addchild ( seqmove ) ; seqorckill -> addchild ( checkishereorc ) ; seqorckill -> addchild ( attackorc ) ; seqmove -> addchild ( playermove ) ; while ( ! root -> invoke ( ) ) { std : : cout << \" - - - - - - - - - - - - - - ------------------------\" << std : : endl ; std : : this _ thread : : sleep _ for ( std : : chrono : : seconds ( 1 ) ) ; } 유한 상태 기계 에서 스테이트 가 추가 될 때 마다 연결 되 는 스테이트 에 컨디션 을 추가 해 주 는 것 과 는 다르 게 행동 트리 에서 컨디션 체크 는 자신 의 노드 에 대해서 만 이루어집니다 . 그렇 기 때문 에 추가 확장 이 굉장히 자유 롭 습니다 . 노드 를 필요 한 곳 에 중복 복사 해서 붙여 넣 기 해도 무방 하 죠 . 위 에서 오크 가 있 을 때 공격 하 는 시퀀스 와 이동 시퀀스 를 아래 와 같이 묶 어도 됩니다 ( 그냥 짤라서 붙여 넣 기 하 면 되 죠 ) 유의 할 점 은 노드 는 추가 된 순서 에 따라 차례 대로 호출 되 기 때문 에 노드 순서 가 캐릭터 의 행동 에 영향 을 끼치 게 됩니다 . 위 의 오크 사냥 행동 트리 가 작동 되 는 동작 순서 를 보 면 . .. root 에 selector 를 먼저 추가 하 였 기 때문 에 실행 되 면 selector 의 노드 를 먼저 탐 하 게 됩니다 . selector 에 는 오크 를 찾 아 공격 하 는 시퀀스 와 플레이어 를 이동 하 는 시퀀스 2 개 가 추가 되 어 있 습니다 . 먼저 첫 번 째 시퀀스 인 오크 를 찾 아 공격 하 는 시퀀스 를 탐색 하 게 됩니다 . checkishereorc 노드 를 통해 오크 가 현 위치 에 있 는 경우 true 가 리턴 되 기 때문 에 다음 노드 인 attackorc 노드 가 실행 됩니다 . 만약 오크 가 없 다면 false 가 리턴 되 기 때문 에 다음 노드 를 실행 하 지 않 고 , 현재 시퀀스 노드 도 false 를 리턴 합니다 . 첫 번 째 시퀀스 가 false 가 되 면 , selector 는 다음 시퀀스 노드 를 탐색 하 게 됩니다 . 두 번 째 시퀀스 에 는 playermove 만 있 습니다 . 이 는 플레이어 이동 후 true 를 리턴 하 게 됩니다 . selector 는 두 번 째 시퀀스 에서 true 를 리턴 받 았 기 때문 에 true 를 리턴 해줍니다 . root 는 이제 다음 노드 인 isplayerdead 를 실행 합니다 . 플레이어 가 죽 었 다면 true , 아직 안 죽 었 으면 false 를 리턴 합니다 . 이렇게 노드 들 을 탐색 하 면서 root 노드 가 true 를 리턴 하 게 되 면 ( isplayerdead 가 true 면 ) 프로그램 을 종료 하 게 됩니다 . 참고 [ URL ] [ URL ] [ URL ]',\n",
       "       '민현석 토모 큐브 의학 드라마 는 방송가 에서 새롭 지 않 더라도 끊임없이 소환 되 는 단골 소재 중 하나 이 다 . 그만큼 흥행 이 보증 된 흥행 보증 수표 로써 대중 의 관심 을 붙잡 는다 . 삶 과 죽음 을 가르 는 생명 의 최 전선 에서 의료진 의 고군분투 로 극 적 긴장감 을 불어넣 어 한국 뿐 아니 라 많 은 나라 의 단골 소재 이 다 . 그러나 현실 에서 의료 계 에 계신 분 들 과 만나 보 면 많 은 분 들 이 너무 현실 성 이 없 어서 차마 볼 수 가 없 다고 하 신다 . 그 말 을 듣 고 다시 생각 해 보 니 , 많 은 의학 드라마 들 은 그냥 병원 에서 연애 하 는 드라마 이 거나 모든 걸 다 헌신 하 는 한 명 의 천재 의사 가 모든 것 을 해결 하 는 무협지 같 은 드라마 였 다 . 현실 에서 실제 사람 을 살리 고 계신 분 들 에게 시절 좋 게 연애 나 하 고 뭐 든지 해결 하 는 무공 과 같 은 의술 을 펼치 는 드라마 가 다시 없 을 코미디 일 듯 하 다 . 그런데 최근 들 어 의료 계 에 많이 적용 되 고 이슈 가 되 고 있 는 ai 기술 들 이 언론 을 통해 공개 되 는 장면 을 보 고 있 자면 그런 의학 드라마 같 은 면 이 많 다 . 이 글 에서 는 몇 연구 가 언론 에 소개 되 어 전달 되 는 모습 을 통해 의료 ai 의 발전 과 함께 문제점 을 짚 어 보 고자 한다 . 아무리 이쁜 기술 을 멋진 회사 에서 만들 었 어도 현실 을 무시 했 으면 그냥 이쁜 쓰레기 이 다 . 딥 러닝 ( deep learning ) 이 라고 불리 는 기계 학습 의 한 방법 론 이 크 게 이슈 가 되 어 영상 인식 , 자연어 처리 등 여러 분야 에서 엄청난 성능 향상 을 불러 왔 다 . 의료 계 에서 는 다른 분야 에서 의 성공 보다 는 당뇨 성 망막 병증 을 안저 영상 으로 진단 하 여 안과의 만큼 의 성능 을 보여 it 기업 인 구글 의 논문 이 의료 계 에 저명 한 저널 인 jama 에 실린 사건 이 ai 라 불리 는 기술 을 달리 보 게 된 계기 가 되 었 다 [ 1 ] . 그런 구글 의 의료 연구 팀 이 이후 망막 스캔 영상 을 통한 심장 질환 발병 가능 성 을 예측 하 는 연구 를 nature biomedical engineering 지에 발표 한다 [ 2 ] . 많 은 신문 기사 와 블로그 에서 는 이 연구 를 두 고 \" 망막 스캔 으로 심장 질환 발병 가능 성 을 진단 하 는 ai 기술 \" 로 표현 하 고 심장 내 과 임상 에서 기존 에 쓰이 는 방법 을 대체 할 수 있 고 간단히 더 좋 은 성능 을 낼 수 있 다고 보도 했 다 [ 3 ] . 그러나 이 논문 에서 예측 하 려고 하 는 당뇨 ( hba 1 c ) , 고 혈압 , 고지혈증 , 고령 , 남성 , 비만 ( bmi ) , 흡연 등 은 논문 에서 최종 적 으로 예측 하 려고 하 는 major advere cardiovasc event ( mace ) 의 predisposing risk factor 이 다 . 이 들 위험 인 자 들 이 오랜 기간 지속 되 면 동맥 경화 로 macro - and microvascular complication 을 일으키 고 최종 진행 단계 에서 , 결국 target organ failure ( tof ) 가 발생 하 는데 , mace 는 심장 혈관 의 tof 이 다 . 그러므로 논문 의 내용 은 tof 에 해당 하 는 안저 소견 으로 predisposing factor 를 예측 하 는 것 은 \\' 결과 \\' 로 \\' 원인 \\' 을 예측 하 는 격 이 된다 . 당연히 관계 는 있 으므로 유의 한 상관 관계 는 얻 을 수 있 겠 지만 , 인과관계 가 뒤집힐 수 있 어 해석 상 의 오류 가능 성 이 높 다 . 그리고 예측 하 는 risk factor 여부 는 환자 에게 질문 하 면 얻 을 수 있 는 것 들 이 대부분 이 다 . 한마디 로 안저 검사 까지 할 필요 는 없 다 . 또한 많 은 기사 그리고 구글 홍보 행사 에서 는 기존 병원 에서 진행 하 는 혈액 검사 만큼 좋 다고 광고 하 는데 , 논문 결과 로 보 면 혈압 , bmi , 성별 , 나이 , 흡연 여부 만 넣 어도 72 % 의 정확도 를 확보 한다고 나와 있 고 제안 된 안저 영상 분석 까지 더 하 면 1 % 나아진 73 % 의 정확도 를 나타낸다 . 참조 논문 이나 다른 임상 논문 을 다시 혈액 이나 기본 적 인 검사 만 으로 도 80 % 이상 을 이미 보이 고 있 다 . 물론 mace 를 예측 하 기 위해 가 기 전 단계 의 과정 으로 학습 했 다고 하 더라도 인과 관계 가 뒤집힐 수 있 는 상황 이 니 이건 무리수 다 . 또한 , 결과 에서 당뇨 여부 와 상관 없이 결과 가 안정 적 으로 나온다고 주장 하 였 는데 , mace 의 매우 중요 한 위험 인 자 당뇨 유병 기간 , 공복 혈당 , 혈당 조절 상태 ( hba 1 c ) 등 당뇨 에 관한 변수 가 완전히 빠져 있 다 . 또한 데이터베이스 구성 에서 보 면 전체 환자 의 55 % 정도 만 이 hba 1 c 정보 를 갖 고 있 었 고 , 심지어 \\' 환자 말 \\' 만 듣 고 당뇨 진단 내린 경우 들 도 있 다 . 또한 당뇨 와 관계 없 다고 하 지만 , 학습 데이터 대부분 이 당뇨 환자 인 데이터베이스 가 주 이 므로 코호트 가 바이 어스 되 었 고 , 전체 환자 의 16 % 만 이 이 연구 의 primary endpoint 인 mace 정보 를 갖 고 있 었 다 . 결국 mace 모델링 에 는 정답 을 가진 16 % 의 환자 만 포함 된 제한 적 인 환경 에서 이루 어 졌 다 . 또한 이 연구 에서 는 당뇨 변수 정의 나 진단 자체 를 신뢰 하 기 어려운 데이터 를 사용 하 고 당뇨 와 의 관계 가 없 다고 주장 하 고 있 다 . 신빙성 없 고 일관 성 을 확인 할 수 없 는 데이터 를 썼으니 당연히 그 요인 이 나타나 지 않 은 것 으로 보 는 것 이 관계 가 없 다고 하 는 것 보다 는 합리 적 인 주장 일 것 이 다 . 아마 구글 에서 진행 된 연구 이 니 엄청난 자금 이 투입 되 었 을 거 고 , 기존 문진 과 간단 한 검사 보다 1 % 나아진 결과 이 지만 그럼에도 불구 하 고 유명 저널 에 나왔 고 , 그리고 여기저기 서 의료 혁신 을 이루 었 다고 광고 하 니 만약 어느 스타트업 에서 했 으면 투자 받 기 딱 좋 은 연구 이 다 . 그러나 연구 도 이쁘 고 , 기술 도 이쁘 나 , 제대로 된 현실 과 임상 프로세스 를 반영 하 지 못했 다면 쓸 데 가 없 는 이쁜 쓰레기 일 뿐 이 다 . 무협지 무공 비서 처럼 ai 혼자 서 혁신 을 가지 고 오지 는 않 는다 . 최근 미 시 건 대학교 에서 는 stimulated raman histology ( srh ) 라는 기술 로 생성 된 영상 에 딥 러닝 기술 을 적용 하 여 빠르 게 수술 중 뇌종양 병리 진단 을 할 수 있 는 연구 를 nature medicine 에 개제 하 였 다 [ 4 ] . 이 연구 에 관련 하 여 국내 신문 기사 에 제목 은 “ 닥터 ai , 뇌종양 진단 도 전문 의 뛰어넘 었 다 ” 이 고 , “ ai , 150 초 만 에 뇌종양 진단 ” 이 라고 홍보 했 다 [ 5 ] . ai 가 적용 되 니 갑자기 진단 정확도 도 전문의 를 뛰어넘 었 고 , 그 진단 시간 도 엄청나 게 단축 되 었 다고 기사 에 실려 있 다 . 그러나 이 논문 을 이렇게 이해 하 면 안 된다 . 왜 수술 중 병리 진단 이 왜 빨라야 하 고 왜 지금 오래 걸리 는지 를 이해 해야 한다 . 수술 중 병변 의 병리 진단 을 요청 하 면 그것 을 병리 과 전문의 들 이 볼 수 있 는 영상 으로 얻 기 위해서 는 굳히 고 얇 게 썰 고 염색 하 는 과정 이 필요 하 다 . 그러나 이 과정 을 수술 과정 중 에 빨리 해야 하 기 에 빨리 굳히 기 위해서 얼리 고 , 썰 어서 염색 한다 . 분석 프로그램 으로 적용 된 ai 를 적용 한다고 이 과정 이 빨라 지지 는 않 는다 . 이 논문 의 저자 들 인 미시 건 대학 의 sandra camelo - piragua 와 daniel a . orringer 교수 는 stimulated raman scattering microscopy 로 가상 적 인 조직 염색 영상 을 만드 는 연구 를 진행 했 던 분 들 이 다 [ 6 ] . 그러니깐 분자 의 진동 정도 같 은 걸 측정 할 수 있 는 레이저 장비 를 써서 새로운 모달 리티 영상 을 만들 고 , 그 영상 을 기반 으로 h & e 영상 과 같 은 가상 의 병리 조직 염색 영상 을 생성 하 는 연구 를 진행 했었 다 . 이 를 통해 염색 과정 없이 병리 조직 영상 을 얻 을 수 있 어서 진단 시간 이 줄어든 것 이 다 . 단순히 갑자기 ai 를 적용 했 다고 기존 임상 프로세스 가 비약 적 으로 빨라 지 거나 영상 이 빨리 생성 되 지 는 않 았 다 . 또한 이 연구 에서 는 control group 인 병리 과 전문의 분 들 은 frozen h & e 염색 영상 을 보 고 진단 하 고 , ai 는 생성 된 srh 영상 을 보 고 판단 했 다 . 그리고 양쪽 그룹 에서 틀린 부분 이 다르 므로 ai 와 병리학자 가 보완 적 인 판단 하 고 이 를 합치 면 100 % 에 가까운 정확도 를 확보 할 수 있 다고 주장 하 고 있 다 . 그러나 ai 와 병리 전문의 가 보완 적 인 판단 을 했 다기 보다 는 서로 다른 모달 리티 가 보완 적 인 정보 를 제공 했 다고 보 는 게 맞 다 . ai 가 병리 전문의 의 데이터 에서 배우 지 못한 부분 을 맞추 고 잘 가르친 영역 을 계속 틀린 다면 그 ai 의 신뢰 성 이 오히려 의심 받 아야 한다 . 이렇 듯 단순히 ai 기술 혼자 서 의료 계 의 오래 된 문제 를 해결 하 진 않 는다 . 새로운 영상 모달 리티 가 개발 된 후 에 는 새로운 기술 이 아직 의료 계 의 교육 시스템 에 못 들어갔 기에 h & e 영상 과 같이 의료 게 에서 이미 익숙 한 모달 리티 와 의 상관 관계 를 제공 하 고 , 이 를 기반 으로 ai 기술 이 적용 되 어야 한다 . 그리고 또 의료 계 에 들어가 기 위해서 는 의료 계 에서 인정 된 임상 검증 절차 에 따라 검증 되 어야 한다 . 우리 나라 에 도 세계 적 으로 선도 적 인 새로운 모달 리티 가 개발 되 고 있 다 . 일례 로 토모 큐브 라는 회사 에서 는 srh 와 같이 염색 없이 조직 및 세포 의 3 차원 구조 를 실시간 으로 관찰 할 수 있 는 기술 을 개발 하 여 적용 하 고 있 다 [ 7 ] . 이러 한 기술 이 ai 뿐 아니 라 제대로 된 의료 문제 와 만나 야 한다 . 그리고 임상 에서 제대로 검증 받 아야 한다 . ai 는 무협지 에 나오 는 무공 비서 가 아니 라 문제 해결 을 위한 하나 의 도구 일 뿐 이 다 . ai 를 의료 에 적용 하 려면 ai 와 같 은 모호 한 단어 들 을 없애 야 한다 . 최근 nature communications 에 는 일본 에서 진행 된 전립선암 관련 병리 영상 연구 가 \" automated acquisition of explainable knowledge from unannotated histopathology images \" 이 라는 제목 의 논문 으로 개제 되 었 다 [ 8 ] . 이 연구 는 단순히 전립선암 판단 기준 으로 사용 되 는 gleason score ( gs ) 과 비교 하 여 환자 가 1 년 후 혹은 5 년 후 재발 할 확률 을 높 은 성능 으로 예측 할 수 있 는 딥 러닝 모델 을 개발 했 다는 내용 이 다 . 또한 스스로 이런 과정 에서 설명 가능 한 지식 을 정답 이 표기 되 지 않 은 병리 영상 을 통해 얻 을 수 있 다고 주장 하 고 있 다 . 이런 연구 를 언론 에서 는 “ ai 스스로 암 특징 발견 ” 이 라는 제목 으로 세계 통용 암 진단 기준 외 새로운 병변 도 발견 한다고 기술 한다고 적 고 있 다 [ 9 ] . \" unannotated \" 란 단어 에 만 집중 하 면 이 과정 을 전체 적 으로 \" 스스로 \" 란 단어 에 묻혀서 자동 으로 진단 한다거나 모든 과정 이 스스로 된다고 오해 할 수 있 게 적 었 다 . 이 부분 은 딥 러닝 이 나오 기 전 에 기계 학습 분야 에서 는 특징 추출 과 분류 로 나뉘 는 과정 에서 보 자면 , 어떤 특징 인지 디자인 하 거나 알려 주 는 과정 이 있 었 는데 , 그 과정 을 딥 러닝 , 아니 정확히 는 딥 러닝 기반 의 auto - encoder 와 clustering 으로 자동 적 으로 학습 하 게 한다는 것 이 다 . 물론 그 특징 추출 이후 판단 으로 넘어가 는 과정 에서 는 지도 학습 과정 이 다 . 이 는 병원 에서 정성 들여 만든 1 년 후 에 재발 그룹 과 아닌 그룹 으로 나누 어 데이터 를 기반 으로 하 고 있 기 때문 이 다 . 이 논문 을 읽 을 때 비교 하 면서 읽 으면 좋 은 논문 은 \" predicting non - small cell lung cancer prognosis by fully automated microscopic pathology image features \" [ 10 ] 일 거 같 다 . 이 논문 은 병리 영상 을 보 고 폐암 환자 의 예후 를 예측 하 는 논문 으로 비슷 한 목적 성 을 갖 는다 . 차이 는 이 논문 은 그동안 알려진 정말 많 은 영상 특징 을 뽑 았 고 , 그걸 조합 해서 예측 에 사용 했 다 . 두 연구 의 방법 론 적 차이 는 특징 을 어떻게 디자인 했 냐 이 다 . 특징 을 미리 알려진 특징 을 뽑 았 는지 아니 면 그 과정 을 일부 비지 도 학습 방법 을 사용 하 였 는가 이 다 . 물론 그렇게 선택 된 많 은 특징 들 을 두 논문 다 특징 선택 ( feature selection ) 과정 을 거치 게 되 어 있 다 . 이런 과정 들 이 있 는데 이번 논문 이 뭐 든 스스로 된 다 는 애매 모호 한 말 로 포장 하 면 이 는 사기 이 다 . 오히려 정말 자동 화 된 연구 가 들어올 자리 를 미리 없애 는 행위 일 수 있 다 . 또한 , 설명 가능 한 ( explainable ) 지식 이 라고 표현 했 지만 위 에서 언급 한 대로 특징 을 뽑 아서 의사 선생 님 들 이 다시 리뷰 를 해 봤 더니 이러저러 한 특징 도 뽑혔 다고 인지 할 수 있 다는 의미 에 더 가깝 다 . 이런 경우 에 는 오히려 해석 가능 한 ( interpretable ) 이 란 용어 가 더 어울린다 . 설명 가능 하 다기 보다 는 일부 특징 이 일부 전문의 들 이 아 는 정보 와 맞닿 아 있 어 해석 이 가능 한 경우 가 있 었 다고 표현 하 는 것 이 맞 다 . 해석 이 가능 하 다고 설명 가능 하 진 않 다 . 또한 , 이 논문 의 실험 은 gs 라는 , 기존 에 암 의 진행 정도 를 나타내 는 아주 오래 된 기준 에 비하 여 자동 화 되 어 뽑힌 100 여 개 의 특징 을 이용 하 면 나 은 정확도 를 보여 주 었 다 . 즉 , 이미지 를 아주 단순 한 1 차원 수 로 줄인 특징 하나 와 애써 뽑 은 100 여 개 의 수치 와 비교 했 을 때 에 100 여 개 가 낫 다는 결과 이 다 . 그것 도 gs 는 1 년 후 예후 예측 을 위해 설계 되 거나 구축 된 수치 도 아니 다 . 당장 수술 해야 하 는 위험 한 암 이 라도 그 암 이 1 년 후 재발 이 잘 되 는 거 인지 아닌지 의 기술 로 평가 하 진 않 으니깐 기준 자체 가 다른 수치 이 다 . 기준 을 제대로 읽 어 보 면 이 등급 을 특징 으로써 정량 화 된 값 으로 쓰 기 엔 무리 가 있 다는 걸 알 수 있 다 . 그러 니 이 프레임 을 씌워서 의사 가 보다 잘 한다는 언론 의 홍보 기사 는 연구 의 요지 를 곡해 한 것 이 다 . 가끔 주제넘 게 외부 에서 ai 적용 에 대해 세미나 를 할 때 면 “ ai 를 적용 하 려면 ai 를 없애 야 한다 \" 라고 주장 한다 . 공상 소설 에서 등장 하 여 쓰 게 된 ai 란 용어 만큼 그 정의 가 애매 모호 한 경우 도 없 다 . 그러나 의료 와 같 은 실제 분야 에 적용 하 기 위해서 는 이 애매 함 을 지우 는 것 이 중요 하 다 . 그림 . 1 . 비둘기 가 학습 을 통하 여 약 90 % 의 정확도 로 유암 방 을 감별 한다고 보 고 [ 11 ] . 현실 성 없 음 에 눈 감 는 방관자 가 아니 라 참여 자 가 되 어야 한다 . 앞 에서 몇 의료 ai 연구 와 언론 에서 그 연구 들 이 어떻게 소개 되 었 는지 살펴보 았 다 . 좋 은 연구 를 했 지만 현실 을 반영 하 지 못하 여 쓰이 지 못하 기 도 하 고 , 현실 을 제대로 알 지 못하 는 언론 과 현실 보다 는 홍보 가 목적 인 기사 들 을 통해 연구 의 의도 에서 벗어난 오해 를 불러일으키 기 도 했 다 . 그러나 의료 ai 는 분명 지난 몇 년 간 엄청나 게 발전 하 였 고 , 의료 의 발전 을 위해서 는 함께 가 야 한다 . 현실 성 없 게 정신없이 바쁜 병원 에서 연애 나 하 는 얘기 가 나온다고 의학 드라마 를 보 지 않 기 보다 는 제대로 된 시선 과 기준 으로 현실 을 반영 하 고 제대로 된 인식 과 메시지 를 전달 할 수 있 는 의학 드라마 가 나올 수 있 게 전문가 들 이 나 서 줘야 한다 . 그렇 지 않 으면 한국 의료 ai 분야 에 는 절대 임상 에 사용 될 수 없 는 이쁜 쓰레기 들 이 넘쳐날 것 이 고 그런 것 들 을 이용 한 사기 꾼 이 국가 예산 과 투자 금 을 눈먼 돈 처럼 사라지 게 할 것 이 다 . 간혹 제한 된 데이터 에서 검증 되 지 않 은 높 은 정확도 란 수치 를 내세우 며 기술 변화 가 빠른 분야 이 니 다른 기준 이 적용 되 어야 한다거나 스타트업 이나 기업 을 살리 기 위해 의학 계 에서 오랫동안 기준 이 되 는 임상 절차 와 그 프로세스 가 과하 다고 말 하 는 정치가 와 기업가 들 이 있 다 . 비둘기 도 학습 을 통하 면 유방암 감별 에 약 90 % 라는 높 은 수치 를 나타냈었 다 [ 11 ] . 그 논리 대로 라면 우리 는 비둘기 에게 도 문 을 활짝 열 어야 한다 . 새로운 기술 에 대해 열린 자세 로 협력 하 는 것 과 전문가 들 이 오랫동안 만들 어 온 기준 을 무너 트리 는 것 과 는 다른 얘기 이 다 . 그래서 더욱더 의료 계 에서 는 의료 ai 분야 에 방관자 가 아니 라 참여 자 가 되 어야 한다 . 어설프 게 ai 를 배우 라는 얘기 가 아니 라 자신 의 분야 에 더 전문 성 을 발휘 하 고 제대로 된 기준 과 프로세스 를 의료 ai 에 요구 하 여야 한다 . 적당히 논문 이나 과제 , 그리고 투 자금 이나 바라 는 연구 와 회사 들 에 의해 기준 과 프로세스 가 무너지 지 않 게 하 고 오해 가 생기 지 않 게 해 주 어야 한다 . 그러 면서 도 새로운 기술 이 제대로 된 방식 으로 의료 계 에 들어올 수 있 도록 지도 하 고 관리 해 주 고 그 바탕 이 되 는 데이터 들 이 제대로 쌓이 게 해 주 어야 한다 . 그렇 지 않 으면 시청 률 만 잘 나오 면 그 만인 현실 성 없 는 의학 드라마 가 판 을 치 듯 , 의료 현실 이 무엇 이 든 한국 의료 ai 계 가 어떻게 되 든 투자 많이 받 아 기업 공개 나 하 고 매각 이 목표 인 의료 ai 업체 들 이 판 을 칠 것 이 다 . 그리고 그 들 이 돈 만 들 고 떠난 후 의료 계 에 는 쓸 수 없 는 이쁜 쓰레기 만 넘쳐날 수 도 있 다 . 그리고 그런 의료 계 에 남 아서 문제 를 계속 해결 하 셔야 하 는 분 들 은 묵묵히 계속 사람 을 살린 죄 밖에 없 는 의료인 들 이 다 .',\n",
       "       '기반 시스템 정보 : system memory : 8 g processor : intel core i 5 - 2500 k 3 . 3 ghz x 4 graphics : geforce gtx 970 / pcie / sse 2 os type : ubuntu 64 - bit ( 영문 ) 본 내용 은 예람 님 의 블로그 내용 ( refer ) 을 참고 하 여 작성 되 었 음 . 기타 참고 사이트 [ URL ] [ URL ] [ URL ] [ URL ] [ URL ] [ URL ] [ URL ] [ URL ] 0 . 그래픽 카드 드라이버 설정 ( 작업 편의 성 을 위함 , 이미 설치 되 어 있 다면 skip 해도 됨 ) 1 ) 터미널 을 실행 시키 고 , ubutu 에 gpu drivers ppa 를 추가 하 고 소프트웨어 소스 를 업데이트 함 sudo add - apt - repository ppa : graphics - drivers / ppa sudo apt update 2 ) system settings 을 실행 시키 고 , system 카테고리 의 software & updates 를 실행 함 . additional drivers 탭 에서 최신 바이너리 드라이버 항목 을 선택 하 고 \" apply changes \" 선택 . 해당 드라이버 가 자동 으로 다운로드 되 고 설치 됨 . 시스템 을 리부팅 하 면 설치 완료 . 1 . anaconda 설치 1 ) [ URL ] 에서 anaconda for linux python 2 . 7 linux 64 - bit 버전 다운로드 함 . 2 ) 터미널 에서 다운로드 받 은 폴더 로 이동 하 고 , 다음 을 입력 하 여 anaconda 를 설치 함 bash anaconda 2 - 4 . 1 . 1 - linux - x 86 _ 64 . sh ( 버전 명 은 다를 수 있 으므로 다운로드 받 은 파일 에서 확인 할 것 ) 중간 중간 에 나오 는 질문 에 는 모두 \" yes \" 한다 . home 으로 나와서 ( cd ~ 입력 ) gedit . bashrc 입력 . 맨 하단 에 anaconda path 가 다음 의 형태 로 잘 적용 되 어 있 는지 확인 함 . # added by anaconda 2 4 . 1 . 1 installer export path =\"/ home / 사용 자 명 / anaconda 2 / bin : $ path \" terminal 을 종료 하 고 재 실행 후 python 을 입력 . 다음 과 같 은 형태 의 문구 가 보이 고 , import matplotlib 를 입력 했 을 때 에러 가 없 다면 성공 . 2 . cuda toolkit 설치 공식 tensorflow 설치 페이지 를 보 면 , 현재 까지 는 cuda toolkit 7 . 5 와 cudnn v 4 를 반드시 설치 하 여야 함 . 1 ) [ URL ] 에 접속 하 여 linux 용 runfile ( local ) 파일 다운로드 . 2 ) cuda 7 . 5 와 호환 되 는 gcc 컴파일러 설치 sudo apt - get install gcc - 4 . 9 g ++- 4 . 9 3 ) 추가 패키지 설치 sudo apt - get install nvidia - modprobe freeglut 3 - dev libx 11 - dev libxmu - dev libxi - dev libglu 1 - mesa - dev 4 ) 다운로드 받 은 폴더 로 이동하 여 , 런 파일 을 이용 한 cuda 설치 - eula 동의 : accept - you are attempting to install on an unsupported configuration . do you with to continue ? : yes - install nvidia accelerated graphics driver for linux - x 86 _ 64 352 . 39 ? no ( 이미 설치 했 음 ) - install the cuda 7 . 5 toolkit ? yes - enter toolkit location : enter ( default ) - do you want to install a symbolic link at / usr / local / cuda ? yes - install the cuda 7 . 5 samples ? no - enter cuda samples location : enter ( default ) sudo sh cuda _ 7 . 5 . 18 _ linux . run -- override 5 ) cd ~ 입력 후 홈 으로 이동 . gedit . bashrc 입력 / 실행 . 맨 마지막 줄 에 다음 을 입력 후 저장 export ld _ library _ path =\"$ ld _ library _ path : / usr / local / cuda / lib 64 \" export cuda _ home =/ usr / local / cuda 3 . cudnn 설치 1 ) [ URL ] 접속 . download 버튼 을 통해 설치 ( nvidia 가입 필요 ) 2 ) 다운로드 받 은 파일 을 우 클릭 하 여 압축 을 품 . cuda 폴더 가 생성 됨 . 3 ) 다음 을 입력 하 여 관리자 권한 으로 탐색기 실행 . usr / local / cuda 로 진입 sudo nautilus 4 ) cuda / include 폴더 내 에 들 어 있 는 파일 을 usr / local / cuda / include 에 복사 5 ) cuda / lib 64 폴더 내 에 들 어 있 는 파일 을 usr / local / cuda / lib 64 에 복사 6 ) 다음 명령어 수행 ( cudnn 을 전체 사용 자 가 사용 ) sudo chmod a + r / usr / local / cuda / lib 64 / libcudnn * 4 . tesnsorflow 설치 1 ) bazel 컴파일러 설치 ( from google ) - 자바 설치 sudo add - apt - repository ppa : webupd 8 team / java sudo apt - get update sudo apt - get install oracle - java 8 - installer - 압축 프로그램 for bazel 설치 sudo apt - get install pkg - config zip g ++ zlib 1 g - dev unzip - bazel 다운로드 ( 현재 버전 0 . 3 . 1 ) : [ URL ] - 다운로드 받 은 폴더 에서 하 기 의 내용 을 입력 하 고 bazel 설치 chmod + x bazel - 0 . 3 . 1 - installer - linux - x 86 _ 64 . sh . / bazel - 0 . 3 . 1 - installer - linux - x 86 _ 64 . sh -- user - cd ~ 으로 홈 으로 이동 . gedit . bashrc 를 입력 / 실행 하 고 맨 하단 에 다음 을 입력 및 저장 export path =\"$ path : $ home / bin \" 2 ) numpy 설치 sudo apt - get install python - numpy swig python - dev 3 ) tensorflow 다운로드 및 설치 - git 설치 sudo apt - get install git - tensorflow 소스 다운로드 git clone -- recurse - submodules [ URL ] - tensorflow 설정 . tensorflow 폴더 진입 및 configure 설정 cd ~/ tensorflow . / configure please specify the location of python . - enter ( default ) do you with to build tensorflow with google cloud platform support ? n do you wish to build tensorflow with gpu support ? y please specify which gcc should be used by nvcc as the host complier . : / usr / bin / gcc - 4 . 8 please specify the cuda sdk version you want to use : 7 . 5 please specify the location where cuda 7 . 5 toolkit is installed . refer to readme . md for more details . : enter ( default ) please specify the cudnn version you want to use . : 4 please specify the location where cudnn 4 . 0 library is installed . refer to readme . md for more details . : enter ( default ) please note that each additional compute capability significantly increases your build time and binary size . : 3 . 5 - tensorflow 소스 컴파일 ( 상기 tensorflow 폴더 에서 ) bazel build - c opt -- config = cuda / / tensorflow / tools / pip _ package : build _ pip _ package - 컴파일 중 에러 발생 시 확인 사항 컴파일러 호환 문제 라면 gcc 4 . 8 설치 ( 예 . # error -- unsupported gnu version ! gcc versions later than 4 . 9 are not supported ! ) sudo apt - get install gcc - 4 . 8 g ++- 4 . 8 기타 여러 에러 발생 시 , 홈 폴더 이동하 여 , tensorflow / third _ party / gpus / crosstool / 내 crosstool 파일 에서 , * cxx _ builtin _ include _ directory : \"/ usr / local / cuda - 7 . 5 / include \" ( cxx _ builtin _ 등 이 있 는 부분 에 모두 삽입 ) * cxx _ flag : \"- std = c ++ 11 \" 하단 에 ( 두 군데 존재 ) 삽입 cxx _ flag : \"- d _ force _ inlines \" cxx _ flag : \"- d _ mwaitxintrin _ h _ included \" - tensorflow 설치 패키지 생성 bazel - bin / tensorflow / tools / pip _ package / build _ pip _ package / tmp / tensorflow _ pkg - 패키지 확인 : tmp / tensorflow _ pkg 내 tensorflow - 0 . 9 . 0 - py 2 - none - any . whl 파일 이 있 는지 확인 ( 버전 명 은 상이 할 수 있 음 ) - anaconda 에 tensorflow 설치 ( 버전 명 은 상이 할 수 있 음 ) pip install / tmp / tensorflow _ pkg / tensorflow - 0 . 9 . 0 - py 2 - none - any . whl - tensorflow 설치 확인 : 하 기 의 소스 코드 를 실행 하 여 결과 확인 ( 터미널 실행 후 python 입력 ) python import matplotlib import tensorflow as tf sess = tf . session ( config = tf . configproto ( log _ device _ placement = true ) ) - 다음 과 같이 출력 되 면 성공 . cuda 관련 library 들 이 제대로 로딩 되 고 , gpu 가 제대로 인식 되 면 됨 - 만일 modprobe : error : could not insert \\' nvidia _ xxx _ uvm \\': invalid argument 와 같 은 에러 와 함께 gpu 인식 이 되 지 않 는다면 그래픽 드라이버 호환 의 문제 일 가능 성 이 높 음 . 이 경우 필자 의 경우 엔 , nvidia cuda toolkit 을 설치 하 고 해당 되 는 에러 의 그래픽 드라이버 버전 으로 재 설치 하 였 음 . toolkit 설치 sudo apt install nvidia - cuda - toolkit 드라이버 재설 치 sudo apt - get purge nvidia * sudo killall nvidia - persistenced ( 없 다고 나오 면 그냥 skip ) sudo apt - get update sudo apt - get install nvidia - 358 nvidia - prime sudo reboot 5 . ide 설치 ( 여기 서 는 pycharm 설치 ) 1 ) pycharm 다운로드 ( [ URL ] - community 의 경우 무료 - professional 의 경우 , 학생 이 라면 1 년 간 무료 이용 가능 2 ) 다운로드 받 은 폴더 로 가 서 압축 을 품 . pycharm 디렉 토리 를 적당 한 위치 에 복사 ( 여기 서 는 home 에 복사 ) 3 ) cd pycharm - 2016 . 2 / bin 이동 ( 폴더 명 은 상이 할 수 있 음 ) 4 ) gedit pycharm 64 . vmoptions 으로 해당 파일 을 메모장 에 열 고 , xmx 750 m 을 부분 을 수정 한다 . 최대 메모리 를 설정 하 는 것 으로 여기 서 는 4096 m 으로 수정 ( 4 gb ) 5 ) bash pycharm . sh 를 입력 하 여 설치 및 실행 6 ) pycharm 아이콘 을 우 클릭 하 여 , lock from launcher 를 클릭 하 여 런처 에 고정 함 . 7 ) 터미널 을 열 고 다음 을 입력 함 ( 경로 는 상이 할 수 있 으니 확인 할 것 ) sudo ldconfig / usr / local / cuda / lib 64 8 ) pycharm 종료 후 다시 실행 시키 고 프로젝트 생성 후 다음 의 코드 를 통해 실행 여부 확인 - 처음 실행 시 , updating indicies , updating python interpreter 작업 으로 첫 코딩 가능 시간 까지 시간 이 걸림 . - gpu test ( 다음 의 코드 입력 후 실행 시키 면 반드시 하 기 스크린 샷 과 같 은 결과 가 도출 되 어야 함 ) : google tensorflow 관련 내용 참고 ( 링크 ) import tensorflow as tf # creates a graph . a = tf . constant ( [ 1 . 0 , 2 . 0 , 3 . 0 , 4 . 0 , 5 . 0 , 6 . 0 ] , shape =[ 2 , 3 ] , name =\\' a \\') b = tf . constant ( [ 1 . 0 , 2 . 0 , 3 . 0 , 4 . 0 , 5 . 0 , 6 . 0 ] , shape =[ 3 , 2 ] , name =\\' b \\') c = tf . matmul ( a , b ) # creates a session with log _ device _ placement set to true . sess = tf . session ( config = tf . configproto ( log _ device _ placement = true ) ) # runs the op . print sess . run ( c ) - 결과 - 최종 적 으로 linear regression 예제 가 gpu 연산 으로 제대로 돌아가 는 지 확인 한다 . ( 관련 소스 링크 )',\n",
       "       '고시원 청년 , 우울증 노인 … ‘ 부동산 난민 ’ 들 의 자화상 ‘ 집값 폭 등 ’ 이 바꾼 삶 고시원 10 년 새 2 . 5 배 증가 60 대 ‘ 월세 ’ 는 3 . 9 % p 늘 어 한국 의 부동산 은 그 널뛰 는 가격 만큼 이나 시민 들 의 삶 을 흔들 고 있 다 . 아이 들 은 사 는 아파트 브랜드 에 따라 차별 을 경험 하 고 , 저소득층 청년 들 은 비좁 고 캄캄 한 고시원 의 장기 투숙객 으로 전락 하 고 있 다 . 젊 은 층 의 결혼 과 출산 은 한없이 미뤄 지 고 나이 가 먹 고 자산 이 쌓여 도 높 은 부동산 가격 으로 인한 설움 에서 벗어나 긴 힘들 다 . 은퇴 후 낸 가게 가 임대료 상승 에 폐업 이 라도 하 면 황혼 의 삶 은 나락 으로 떨어진다 . 인간 이 쉬 기 위해 만든 ‘ 집 ’ 이 란 공간 이 한국 에서 는 인간 스스로 를 구속 하 는 공간 으로 탈바꿈 하 고 있 는 것 이 다 . 10 일 부동산 업계 의 말 을 종합 하 면 가격 이 오른 아파트 들 을 중심 으로 주택 의 ‘ 계급 화 ’ 현상 이 심각 하 다 . 최근 서울 송파구 에 새로 들 어서 는 한 아파트 의 입주 예정자 들 은 얼마 전 외벽 에 새겨진 sh ( 서울 주택 도시 공사 ) 로고 를 삭제 했 다 . ‘ 저소득층 주거지 ’ 로 낙인찍힌다 는 이유 도 있 었 지만 , “ 아이 들 이 다른 아파트 아이 로부터 차별 받 을까 봐 걱정 된다 ” 는 게 또 다른 이유 였 던 것 으로 전해졌 다 . 이 들 의 우려 는 괜한 걱정 으로 치부 하 기 힘들 다 . 주거지 를 이유 로 한 차별 문제 는 몇 해 전 부터 지속 적 으로 불거졌 다 . 임대 아파트 와 분양 아파트 거주민 들 이 함께 어울리 도록 하 는 ‘ 소셜 믹스 ’ 정책 이 이뤄지기 도 했 지만 차별 사례 는 사라지 지 않 고 있 다 . 최근 에 는 인터넷 등 에 임대 아파트 거주민 을 비하 하 는 신조어 도 등장 해 논란 이 됐 다 . 부동산 가격 폭 등 의 쓴맛 은 대학 에 들어가 면 본격 적 으로 체감 한다 . 집값 상승 에 따라 대학 근처 원룸 임대료 도 오르 다 보 니 많 은 청년 들 은 고시원 으로 들어가 야 한다 . 최근 에 는 대출 이 어려워 집 을 구하 지 못하 는 비정규직 직장인 들 까지 고시원 으로 향하 고 있 다 . 고시원 은 저소득 청년층 증가 와 1 인 가구 증가세 에 힘입 어 빠르 게 늘 고 있 다 . 10 년 전 인 2007 년 까지 만 해도 4722 개 였으나 올해 1 만 1800 개 로 2 . 5 배 증가 했 다 . 청년 들 은 지하실 과 옥탑방 , 고시원 의 고단 한 삶 을 풍자 해 ‘ 지 · 옥 · 고 ’ 라 부르 고 있 다 . 집 없 는 청년 들 은 결혼 과 출산 에서 도 소외 되 고 있 다 . 최근 마강 래 중앙 대 교수 등 이 발표 한 연구 를 보 면 주택 가격 은 남성 은 물론 여성 들 의 결혼 시기 까지 늦추 고 있 다 . 부모 의 경제 적 능력 이 자녀 의 결혼 시기 에 미치 는 영향 도 커 지 고 있 다 . 젊은이 들 이 천신만고 끝 에 결혼 해도 서울 의 직장 근처 에 집 을 구하 기 는 힘들 때 가 많 다 . 이 때문 에 많 은 이 들 이 서울 외곽 이나 경기도 등 으로 밀려나 고 있 으며 아침 마다 장거리 통근 으로 곤욕 을 치른다 . 통계청 자료 를 보 면 2010 년 부터 5 년 간 서울 에서 경기도 로 옮긴 인구 는 57 만 1000 명 이 었 다 . 수도 권 인구 중 회사 나 학교 까지 1 시간 넘 게 걸리 는 이 들 은 2010 년 329 만 1000 명 에서 2015 년 392 만 9000 명 으로 약 60 만 명 증가 했 다 . 저소득 가계 라면 거주 비 증가 가 팍팍 한 삶 으로 이어진다 . 소득 하위 20 % 계층 인 1 분위 가구 들 의 전 · 월세 등 실제 주거비 는 2014 년 부터 지난해 까지 전년 대비 11 % 이상 올랐 다 . 같 은 기간 가계 는 여가 나 소비 생활 에 열 었 던 지갑 을 우선 닫 았 다 . 의류 신발 , 통신 , 오락 문화 , 음식 숙박 등 의 비용 이 줄어든 것 이 다 . 노후 가 돼 자산 이 쌓인다 해도 걱정 은 그치 지 않 는다 . 삼성 생명 은퇴 연구소 가 지난해 발간 한 보고서 를 보 면 , 한국 의 부모 들 은 자녀 의 결혼 을 위해 노후 대비 자금 의 절반 이 넘 는 ( 55 %) 1 억 3000 만 원 을 지출 했 다 . 대부분 은 자녀 의 주택 마련 에 드 는 돈 이 다 . 일부 은퇴 세대 는 자녀 들 의 결혼 자금 을 덜 어 낸 뒤 남 은 노후 자금 으로 가게 를 열 지만 , 주변 땅값 이 상승 하 고 임대료 가 오르 면 영업부 담 이 커져 폐업 하 는 사례 가 적 지 않 다 . 2010 년 부터 5 년 간 60 ~ 69 세 인구 의 자 가 거주 비율 은 1 . 6 % 포인트 줄 었 고 , 월세 거주 비율 은 3 . 9 % 포인트 늘 었 다 . 박선영 고려대 교수 의 최근 연구 를 보 면 월세 를 부담 하 는 고령 층 은 자가 나 전셋집 거주자 보다 우울 감 이 더 심화 돼 있 었 다 . 박 교수 는 “ 주거비 에 대한 부담 은 사람 들 의 삶 의 질 과 밀접 한 관계 가 있 다 ” 며 “ 주거 안정 성 을 보장 하 는 정책 이 중요 한 이유 ” 라고 설명 했 다 .',\n",
       "       '너무 간간히 연동 하 다 보 니 할 때 마다 항상 새롭 다 . 당연히 삽질 도 새롭 게 다시 시작 하 고 . .. 또 잊어버리 기 전 에 기록 해 두 어야 겠다 . 1 . 프로젝트 등록 ( 구글 개발자 콘솔 ) [ URL ] 에서 새 프로젝트 를 등록 한다 . firebase 에서 새 앱 을 생성 할 때 프로젝트 가 필요 한다 . ( 잘 모르 겠 는 경우 \" 구글 개발자 콘솔 프로젝트 등록 \" 으로 검색 해 보 자 ) 2 . 새 앱 생성 ( firebase 개발자 콘솔 ) [ URL ] 에서 프로젝트 를 추가 한다 . 생성 된 프로젝트 에서 \" 설정 -> 내 앱 -> 앱 추가 \" 순서 로 진입 한다 . ( 잘 모르 겠 는 경우 \" firebase 개발자 콘솔 앱 추가 \" 로 검색 해 보 자 ) 패키지 명과 닉네임 을 작성 한다 . 디버그 서명 인증서 sha - 1 은 안드로이드 스튜 디어 에서 확인 한다 . 좌측 의 gradle 탭 을 선택 하 면 나오 는 트리 중 task > signiningreport 를 선택 한다 . 아래쪽 콘 솔창 출력 텍스트 중 sha 1 에 나오 는 키 를 디버그 서명 난 에 등록 한다 . 이렇게 앱 을 등록 하 면 다음 과정 에서 구성 파일 을 다운로드 한다 . ( google - services . json ) 다운로드 받 은 파일 을 project _ root / app 디렉 토리 아래 로 이동 한다 . 3 . 라이브러리 설정 ( gradle 파일 ) - project > build . gradle 파일 에 추가 한다 . dependencies { . ........... classpath \\' com . google . gms : google - services : 4 . 0 . 0 \\' } - project > app > build . gradle 파일 에 추가 한다 . dependencies { . ........... compile \\' com . google . firebase : firebase - core : 16 . 0 . 0 \\' compile \\' com . google . firebase : firebase - auth : 16 . 0 . 1 \\' compile \\' com . google . android . gms : play - services - auth : 15 . 0 . 1 \\' } apply plugin : \\' com . google . gms . google - services \\' 라이브러리 버전 에 신경 쓰 자 , 버전 을 못 맞춰서 한참 고생 했 다 . ( 버전 이 안 맞 으면 버전 이 안 맞 는다든지 이런 에러 가 나오 는 게 아니 라 \" not found class \" 라든지 , 뭐뭐 가 null 이 라든지 이런 에러 메세지 가 나오 기 때문 에 발견 하 기 어렵 다 . ) 4 . 구글 로그인 연동 중요 한 건 com . google . android . gms . common . signinbutton 이 다 . public class mainactivity extends fragmentactivity implements view . onclicklistener , googleapiclient . o nconnectionfailedlistener { private googleapiclient mgoogleapiclient ; private int rc _ sign _ in = 1000 ; private final string tag = \" tag \"; private textview mstatustextview ; 실행 activity 는 fragmentactivity 여야 한다 . 클릭 이벤트 처리 와 구글 연동 에러 를 처리 하 기 위한 이벤트 는 implements 에 넣 었 다 , 물론 여기 에 넣 지 않 고 메소드 에서 구현 해도 상관없 다 . private void setgooglelogin ( ) { googlesigninoptions gso = new googlesigninoptions . builder ( googlesigninoptions . default _ sign _ in ) . requestidtoken ( getstring ( r . string . default _ web _ client _ id ) ) . requestemail ( ) . build ( ) ; mgoogleapiclient = new googleapiclient . builder ( this ) . enableautomanage ( this , this ) . addapi ( auth . google _ sign _ in _ api , gso ) . build ( ) ; signinbutton signinbutton = ( signinbutton ) findviewbyid ( r . id . sign _ in _ button ) ; signinbutton . setsize ( signinbutton . size _ standard ) ; signinbutton . setscopes ( gso . getscopearray ( ) ) ; findviewbyid ( r . id . sign _ in _ button ) . setonclicklistener ( this ) ; mstatustextview = ( textview ) findviewbyid ( r . id . mstatustextview ) ; } oncreate 함수 에서 호출 하 는 객체 초기 화 메소드 이다 . googlesigninoptions 에서 googleapiclient 를 위한 option 을 지정 한다 . requestidtoken ( getstring ( r . string . default _ web _ client _ id ) ) 에서 지정 한 r . string . default _ web _ client _ id 는 firebase console 에서 다운로드 받 은 google - services . json 내 에 있 다 . mgoogleapiclient 가 핵심 이 다 . 이게 모든 액션 을 처리 한다 . 이하 singinbutton 은 클릭 이벤트 를 걸 었 고 , override 되 는 onclick 함수 에서 click 이벤트 를 처리 해 주 자 . public void onclick ( view view ) { signin ( ) ; } private void signin ( ) { intent signinintent = auth . googlesigninapi . getsigninintent ( mgoogleapiclient ) ; startactivityforresult ( signinintent , rc _ sign _ in ) ; } 로그인 버튼 을 클릭 하 면 구글 에서 제공 하 는 로그인 화면 이 뜬다 . 이 화면 에서 로그인 을 처리 하 면 onactivityresult 함수 를 호출 해 준다 . protected void onactivityresult ( int requestcode , int resultcode , intent data ) { super . onactivityresult ( requestcode , resultcode , data ) ; if ( requestcode == rc _ sign _ in ) { googlesigninresult result = auth . googlesigninapi . getsigninresultfromintent ( data ) ; handlesigninresult ( result ) ; } } private void handlesigninresult ( googlesigninresult result ) { if ( result . issuccess ( ) ) { googlesigninaccount acct = result . getsigninaccount ( ) ; log . i ( tag , \" email : \" + acct . getemail ( ) ) ; log . i ( tag , \" id : \" + acct . getid ( ) ) ; log . i ( tag , \" profile : \" + acct . getphotourl ( ) ) ; log . i ( tag , \" dispname > \" + acct . getdisplayname ( ) ) ; } } onactivityresult 함수 에서 로그인 처리 결과 값 을 받 아 결 과거 성공 이 면 googlesigninresult 객체 로 받 아 googlesigninaccount 객체 로 변환 한다 . 변환 된 객체 에서 필요 한 정보 를 가져온다 .',\n",
       "       'kmozzart cooking ( 이탈리아 요리 ( italian food ) ) 22 시나브로 marsala _ sabayon _ with _ cookie _ and _ local _ stone _ fruit 지바이요네 지바이요네 ( 이탈리아어 : zabajone ) 는 이탈리아 · 피에몬테 의 명물 디저트 이 다 . 프랑스 에서 는 \" 사바 이 욘 \"( 프랑스어 : sabayon ) 라고 한다 . zabaglione 지바이요네 개요 14 세기 의 이탈리아 지바이요네 요리법 이 남 아 있 지만 , 초기 지바이요네 는 노른자 로 걸쭉 하 게 양념 을 한 와인 칵테일 을 가르켰 다 . 이윽고 노른자 의 분량 을 늘려 소스 모양 과 거품 이 조리법 에 변화 가 일어났 다 . 이 기법 은 19 세기 중반 프랑스 에 전해져 , 사바 이 욘 로 세련되 어 갔 다 . 20 세기 에 는 사바이 욘 은 짭짤 한 요리 와 마요네즈 등 계란 소스 와 의 조화 등 에 \\u200b\\u200b 도 응용 되 었 다 . 지바이요네 는 거품 없이 혼합 만 의 크렘 앙글레즈 에 가까운 것 으로 적당히 열 을 가하 지 하 면서 커스터드 모양 으로 부풀린 것 이 었 다 . 달걀노른자 에 설탕 을 넣 고 거품 을 따뜻 하 게 하 면서 , 마르 살라 와인 , 셰리 , 화이트 와인 등 의 주류 를 더 하 여 끓여 커스터드 크림 에서 디저트 로 그대로 먹 는다 . 또한 , 양과자 용 소스 로 티라미수 등 에 이용 할 수 있 다 . 또한 , 만드 는 방법 에 따라 에탄올 이 잔존 하 기 때문 에 아이 에게 줄 때 는 주의 가 필요 하 다 . 또한 롬바르디아 에서 는 파 네 토 네 에 따를 수 있 다 . flavorsgelatoflorence 이탈리아 , 피렌체 의 젤라토 젤라토 ( gelato ) 는 이태리어 로 \" 얼음 \" 이 라는 의미 를 가진 빙과 다 . 발상 은 피렌체 . 과즙 , 과육 , 우유 , 설탕 , 때로 는 커피 나 향초 등 을 섞 은 것 을 얼려 만든 다 . 이탈리아 의 겨울 에 는 빠뜨릴 수 없 는 과자 이 며 , 시칠리아 에서 브리오 슈 에 끼워 먹 을 수 있 다 . italian _ ice _ cream 이탈리아 , 로마 의 \\' 아이스크림 \\' 특징 일반 아이스크림 에 비해 공기 함유량 이 35 % 미만 으로 적 기 때문 에 밀도 가 진하 고 , 맛 에 감칠맛 이 있 다 . 또한 유지방 분 은 4 - 8 % 로 일반 아이스크림 의 유지방 8 % 이상 보다 상대 적 으로 낮 은 열량 이 다 . 따라서 일본 의 우유 및 유제품 의 성분 규격 등 에 관한 아이스크림 이 아닌 아이스 밀크 ( 유지방 3 % ~ 8 % 미만 ) 또는 빙과 로 분류 된다 . 일반 적 으로 과일 계 의 젤라토 는 과즙 에 물 , 설탕 , 안정제 , 계란 흰자 를 가하 여 교반 하 고 , 공기 를 포함 시키 면서 얼려 만든 다 . 그러나 과즙 만 으로 물 을 첨가 하 지 않 고 만드 는 일부 고급 프랑스 레스토랑 이나 이탈리안 레스토랑 , 전문점 ( 파르페 & 레스토랑 하와이 ) 도 있 다 . gianduiotti 장 두 이 오 티 쟌 두야 ( 이탈리아 : gianduja , gianduia ) 는 로스팅 한 너트 류 ( 주로 헤이즐넛 과 아몬드 ) 의 페이스트 와 초콜릿 의 혼합물 이 다 . 제 과 재료 로 사용 된다 . 근원 이 된 것 은 1852 년 에 이탈리아 · 토리노 의 과자 메이커 , 카 화 레 루 사 에 의해 고안 된 초콜릿 사탕 \" 장 두 이 오 티 \\' 이 다 . 이것 은 나폴레옹 정권 하 에서 단속 을 통해 부족 한 카카오 를 보완 하 기 위해 지역 에서 풍부 하 게 생산 된 헤이즐넛 을 섞 은 것 에서 태어났 다 . 쟌 두야 과 장 두 이 오 티 의 이름 은 콤 메디아 델라르테 와 사육제 , 인형극 에 등장 하 는 토리노 피에몬테 주 를 상징 하 는 동명 의 캐릭터 , 쟌 두이 야 ( gianduja ) 에 따르 게 되 었 다 . 제 과 요리법 등 견과 류 의 페이스트 자체 를 \" 쟌 두야 \\' 로 표기 하 고 있 는 것 이 있 는데 , 이것 은 실수 이 다 . sfogliatelle 스 폴리아 텔레 스 폴리아 텔레 ( sfogliatella ) 는 이탈리아 , 나폴리 지방 의 명물 로 구운 과자 다 . 그 이름 은 이탈리아어 로 \" 주름 을 여러 겹 \" 이 라는 의미 를 가진다 . 아말피 지방 의 수도원 이 발상 이 라는 설 이 있 다 . 스 폴리아 텔레 ( sfogliatelle ) 는 복수 형 이 다 . 조개 모양 의 주름 이 여러 층 의 파이 모양 의 반죽 속 에 리코 타 치즈 , 커스터드 크림 과 아몬드 크림 등 을 넣 고 오븐 에 구워 . 매우 딱딱 하 게 소결 되 지만 , 좋 은 맛 . 나폴리 이외 에 도 이탈리아 를 대표 하 는 과자 로 고급 레스토랑 의 디저트 등 에 등장 한다 . monasterosantarosa 발상 스 폴리아 텔레 는 17 세기 아말피 해안 에 접한 살레르노 현 콘카 데이 마리니 의 \" 리마 의 성 로사 수도원 ( conservatorio di santa rosa da lima ) \" 에서 태어났 다 . 그 탄생 은 매우 우연 이 었 다 . 어느 날 수도원 의 주방 에 있 는 양질 의 거친 밀가루 ( semolina ) 가 손상 되 고 있 었 다 . 이걸 발견 한 주방 계 의 수녀 는 그것 을 버리 는 대신 , 건조 과일 , 설탕 , 리몬 첼로 를 소량 씩 첨가 것 이 다 팥소 를 얻 었 다 . 그리고 완성 된 팥 을 감싸 기 위하 여 접 어 파이 반죽 끝 부분 을 이용 하 여 팥소 를 채운 파이 를 고온 의 오븐 에 넣 었 다 . 완성 된 이 과자 는 수녀 들 과 수도원 인근 주민 들 사이 에서 매우 인기 가 있 어 수도원 을 따 서 \\' 산타 로사 ( 성 로사 ) \" 라고 불리 게 되 었 다 . 1818 년 나폴리 인 빠 스 쿠 아레 · 삔 타우 로 이 경위 는 불명 하 면서 그 산타 로사 의 비밀 조리법 을 손 에 넣 었 다 . 그 는 레시피 에 가벼운 어 레인지 를 더한 새로 조개 모양 으로 만드 는 것 을 생각 해 지금 에 이르 게 스폴 리아 테라 를 낳 았 다 . 지금 도 그 의 제과 영업 의 방법 은 바뀌 어 버렸 지 만 , 200 년 전 과 변함없이 나폴리 의 톨레도 거리 에 점포 를 두 고 있 다 . zuccotto _ gattaiola _ 도루 찌 의 추 코토 추 코토 , 즛 콧토 ( 이탈리아 : zuccotto ) 는 이탈리아 의 토스카나 지방 의 도시 피렌체 에서 르네상스 시대 에 탄생 한 둥근 돔 형태 의 세미 프레도 를 이용 한 케이크 이 다 . cupola _ duomo _ 2011 산타 마리아 델 피오레 대성당 의 크 포라 명칭 은 15 - 16 세기 군인 의 돔 형 금속 투구 \" 즛 콧토 \" 또는 \\u200b\\u200b 가톨릭교회 의 성직자 의 반구형 두건 카 롯 타 토스카나 속어 에서 일명 \\' 즛 켓 토 \"( zucchetto ) 에서 유래 했 다 . 즛 콧토 , 즛 켓 토 은 어느 쪽 과 도 주카 ( zucca , 호박 ) 에서 파생 된 단어 이 다 . zuccotto _ aguzzo 추 코토 형 투구 ( zuccotto aguzzo ) 1570 년 경 ( 포 를 리 시립 아 루비 찌 니 무기 박물관 ) 16 세기 중엽 피렌체 에서 건축가 , 조각가 , 화 가 , 군사 기술자 , 연극 디자이너 였 던 베르나르 부 온 타 렌 티 ( ernardo buontalenti ) 가 메디치 를 위해 창작 한 것 으로 되 어 있 다 . 부 온 타 렌 티 얼음 에 질산 을 첨가 식품 냉동 기술 의 발명가 로 알려져 있 다 . 반구형 의 형태 는 경애 하 는 필리포 브루넬 레스 키 의 대표작 이 며 피렌체 의 상징 인 산타 마리아 델 피오레 대성당 의 크 포라 에 공물 로 도 불린다 . catherine _ de _ medicis 카트린 드 메디 시스 프랑스 의 오를레앙 공 앙리 ( 후 앙리 2 세 ) 에 시집 온 메디치 의 카테리나 데 메디치 ( 프랑스어 : catherine de médicis , 1519 년 4 월 13 일 - 1589 년 1 월 5 일 ) 가 과자 장인 과 함께 세미 프레도 프랑스 에 들여온 것 으로 알려져 현대 아이스크림 의 원형 중 하나 가 된다 . 현대 아이스크림 의 차이 는 크림 에 계란 을 제외 유제품 주체 인 것 이 다 . 즛 콧토는 오랫동안 잊혀 지 긴 했 지만 , 1950 년 대 에 피렌체 의 전통 양과자 점 시 에니 ( antica pasticceria sieni ) 가 16 세기 의 제조법 을 복원 하 고 부활 시켰 다 . 피렌체 의 리스 토란 테 와 트라 의 디저트 메뉴 로 등장 하 지만 , 티라미수 와 판나 코타 등 에 비해 제법 이 복잡 하 고 시간 이 걸리 므로 만든 경우 는 적 고 , 또한 집 에서 만들 어 지 는 것 도 비교 적 드물 다 . zuccotto 초콜릿 즛 콧토 제법 은 오븐 에서 빵 디 스 빠 냐 를 굽 고 띠 모양 으로 새겨 , 반구형 형태 의 내부 에 빵 디 스 빠 냐 의 표면 에 구워 색 을 크 포라 의 늑골 에 비유 직선 으로 깔 고 늘 어 놓 는다 . 빵 디 스 빠 냐 에 빈 산토 등 강화 와인 과 아마레 또 , 삼 부 카 , 베 네 디 쿠 틴 , 후 란 보 워즈 , 그 랑 마니 에 와인 등 주류 를 스며들 게 ( 최근 에 는 주류 를 넣 지 않 은 것 도 많 다 ) , 잘 게 다진 헤이즐넛 과 아몬드 등 견과 류 , 과일 설탕 절임 이나 다진 초콜릿 을 넣 은 생크림 단맛 을 붙인 리코 타 치즈 , 요구르트 치즈 등 을 포장 , 빵 디 스 빠 냐 에서 뚜껑 을 덮 고 냉장고 등 에서 얼리 는 형태 에서 꺼내 실온 에서 세미 프레도 ( 반 압축 상태 ) 에 다시 새겨 제공 하 는 가루 설탕 , 코코아 파우더 , 녹인 초콜릿 등 으로 표면 을 장식 할 수 있 다 . gamarelli _ papal _ zucchetto 20050412 교황 흰색 즛 켓 토 본래 의 세미 프레도 의 추 코토 와 는 별도 로 , 이탈리아 의 젤라토 가게 에 는 스펀지 원단 에 달걀 흰자 를 포함 아이스크림 을 채운 추 코토 · 젤라토 ( zuccotto gelato ) 를 두 고 있 는 곳 도 있 다 . semifreddo 세미 프레도 세미 프레도 ( 이탈리아어 : semifreddo 발음 [ semifreddo ] ) 는 반 압축 상태 의 디저트 이 며 , 대개 는 아이스크림 케이크 , 커스터드 , 과일 타르트 를 반 압축 시킨 과자 이 다 . 영어 에서 는 \" harf cold \" 를 의미 한다 . 아이스크림 과 휘핑크림 의 두 부분 을 접착 시키 기 위해 냉동 무스 의 원단 을 사용 한다 . 이탈리아 요리 는 세미 프레도 는 기본 재료 로 아이스크림 이 이용 되 고 있 다 . 스페인 의 과자 비슷 한 것 이 있 는데 , 세미 후리 오 ( semifrío ) 라고 한다 . tira _ mi _ su 티라미수 의 단면 티라미수 ( 이탈리아어 : tiramisù , 베네토 어 : tiramesù [ tiramesu ] ) 는 이탈리아 북부 에서 태어난 치즈 케이크 의 일종 . 어원 의 tirami su ! 는 이탈리아어 로 \" 나 를 끌 어 올려 \" 또 돌 아 섰다 \" 나 를 건강 하 게 \\' 에서 유래 한다 . tiramisu _ fanes 티라미수 만드 는 방법 적당 한 크기 의 형태 에 에스프레소 를 적신 비 스켓 사보이 아 루디 ( 사보이 의 핑거 비스킷 ) 을 깔 아서 그 위 에 마르 살라 와인 · 설탕 과 함께 달걀노른자 를 따뜻 하 게 하 면서 불 을 땠 다 커스터드 소스 \" 지바이요네 \" 라고 마 스카 치즈 를 맞춘 \" 지바이요네 크림 \" 을 흘려 같 은 공정 을 2 - 3 층 반복 형태 를 가득 메운 다음 차 게 굳힌다 . 마무리 는 표면 에 코코아 가루 와 초콜릿 파우더 가끔 에스프레소 원두 를 갈 아 가루 를 뿌려 맛 을 붙인다 . tiramisu 티라미수 의 기원 이 되 었 다고 되 어 크레마 델라 두 켓 사 ( crema della duchessa ) 의 현대식 담 았 다 기타 최근 태어난 새로운 디저트 지만 출생지 내용 은 일부 영토 사이 에서 논란 이 된 바 있 다 . 원료 의 마스 카 는 롬바르디아 의 치즈 , 비 스켓 은 몬트 크림 의 기반 이 되 는 지바이요네 도 피에몬테주 의 향토 디저트 이 다 . 그러나 현대 에 는 다른 주 에서 도 그 원료 를 쉽 게 구할 수 있 고 , 지바 이 요네 도 잘 알려진 크림 이 기 때문 에 생각 이 2 주 에 결정 하 는 것 은 곤란 하 고 , 베니스 또는 트레비 가 아닐까 라고 있 다 . 미국 에서 는 1970 년 대 말 부터 1980 년 대 초 에 걸쳐 붐 이 되 었 다 . 버블 기 당시 는 티라미수 와 파스타 밖 에 취급 하 지 않 는 이탈리아 식당 도 존재 했 을 정도 이 다 . 이후 에 도 지속 적 인 인기 를 유지 하 고 오늘 에 이르 고 있 다 .',\n",
       "       '10 . 책 속 에서 , \\u200b 과거 1938 년 ~ 현재 1953 년 \\u200b ■ ぬっぺっぽう 눗 펫 포 ( 매끈매끈 하 고 굴곡 이 없 는 , 멍청 한 의미 의 \\' 놋페라보 \\' 의 방언 ) - 이즈 伊 豆 반 도 시즈오카 靜 岡 縣 의 산골 마을 . 1938 년 ( 과거 ) 헤비 토 戶 人 마을 ( 18 戶 50 여 명 ) . 1953 년 ( 현재 ) 니리 야마 韮 山 마을 ( 과거 의 헤비 토 마을 이 이름 도 다르 고 원주민 아닌 사람 들 이 있 다 ? ?) \\u200b 그건 데자 뷔 , 즉 旣 視 感 이 라는 것 이 아닐까 . 본 적 이 없 는 풍경 이 낯익 다 . 가 본 적 이 없 는 장소 가 그립 게 여겨진다 --- 그것 은 대체로 뇌 의 속임수 다 . 기억 이 어 지 렵혀져 있 을 뿐 이 다 . 현재 라는 것 은 , 실은 가장 새로운 과거 를 말 한다 . 인식 한 시점 에서 그것 은 이미 약간 의 과거 가 되 는 것 이 다 . 따라서 시간 을 양 적 으로 파악 한다면 無 와 有 의 접점 이 바로 \\' 지금 \\' 이 다 . 수량 적 으로 는 0 이나 마찬가지 다 . 그리고 과거 는 쉬 지 않 고 늘 어 간다 . 미래 는 물론 --- 無 다 . 우리 는 항상 우글우글 증식 하 는 과거 라는 대열 의 선두 에 서 있 는 것 이 다 . 얼굴 을 향한 곳 에 는 아무 것 도 없 다 . 그러 니 미래 예지 같 은 것 이 가능 할 리 도 없 다 . 기시감 이 라는 것 은 그 희미 한 과거 와 조금 더 오래 된 과거 가 어쩌다가 겹칠 뿐 인 것 이 다 . 소위 말 하 는 착각 --- 이 다 . 나 는 세노 에게 그렇게 말 했 다 . ( 상 - p . 35 ) 세키구치 다츠 미 曰 \\u200b \\u200b ※ 쓰야마 30 명 살인 사건 : 1938 년 5 월 , 오카야마현 쓰 야 마 시 가 이 오 · 사카모토 촌락 , 도이 무스 오 ( 당시 21 세 ) , 개조 엽총 과 일본 도로 祖母 를 시작 으로 두 마을 사람 30 명 살해 한 후 에 자살 ※ 아베 사다 阿 部 定 : 1936 년 5 월 , 아베 사다 ( 여관 종업원 ) 가 성교 중 애인 의 목 을 졸라 죽이 고 국부 를 잘라 낸 사건 , 사건 3 일 후 체포 시 자른 국부 를 소지 ※ 라프 카디 오 한 : patrick lafcadio hearn , 그리스 출신 의 신문 기자 , 기행문 작가 , 소설가 , 1890 년 미국 출판사 통신원 으로 일본 에 왔 다가 1896 년 일본 에 귀 화 , 일본 이름 은 고이즈미 야쿠모 , 그 의 작품 < 오소리 > 에서 \\' 재차 의 괴이 \\' 를 다루 고 있 다 . 재차 의 괴 이란 , 괴이 한 일 을 당해 한 번 놀라 도망쳤 다가 , 겨우 안심 해서 한숨 돌렸 을 때 똑같 은 일 이 되풀이 되 어 재차 깜짝 놀란다는 구조 의 괴담 이야기 다 . 괴 이 를 반복 시킴 으로써 숨통 을 끊 는 셈 인데 , 대개 는 서서히 목소리 를 낮추 다가 결말 부분 에서 깜짝 놀라 게 한다는 기술 과 병용 되 는 경우 가 많 다 . 그 경우 는 깜짝 놀라 기 는 하 는 셈 이 고 , 이 수법 이 라면 몇 번 을 되풀이 해도 되 지만 , 한 번 놀라 게 하 고 나 면 다음 에 는 대개 수법 이 들통 나 버리 기 에 쇼크 가 반감 되 고 만다는 약점 도 있 다 . 그래서 괴 이 를 이야기 하 는 효과 적 인 회수 는 첫 번 째 를 포함 한 두 번 이 고 , 그래서 재차 의 괴이 라고 부르 는 것 이 다 . 다만 한 번 위협 을 당했으니 두 번 째 는 없 을 거 라고 , 그렇게 생각 하 게 만들 수 있 다면 세 번 째 도 유효 하 다 . ( 상 - p . 57 ) 요컨대 재차 의 괴이 는 한 번 흐트러뜨린 질서 를 원래 대로 회복 시켜 두 고 뒤집 는다는 , 뒤집기 괴담 이 다 . ( 상 - p . 58 ) ※ 호 ( 封 ) : 視 肉 살 아 있 는 살덩어리 肉 人 , 太歲 당 에 묻혀 있 는 不定 形 의 흐물흐물 한 것 ▷▷▷ 세키구치 다츠 미 의 취재 출장 - 1938 년 의 헤비 토 마을 이 사라지 고 ( 지도 상 에 도 , 마을 주민 들 도 ) . .. 현재 행정 구역 도 니라 야마 마을 로 변해 있 고 , 현 주민 들 은 1938 년 의 주임 들 이 아님 에 도 자신 들 은 그곳 에서 나 서 계속 살 아 왔 다고 말 한다 - 세키구치 동행 인 도지마 ( 향토사 가 ? ) 는 저 들 은 이주민 들 인데 , 그걸 모른다 , 기억 이 조작 된 거 다 \\u200b - 마을 의 중간 에 는 촌장 집 인 사에키 가 저택 이 있 고 \\' 호 封 \\'( 불노 불사 ) 이 라는 요괴 가 산다 라는 설 이 있 다 \\u200b ■ うわん 우완 \" 氣 란 하나 인 것 --- 근원 을 말 합니다 . 근원 이 란 태극 , 태극 에서 兩儀 가 생겨나 고 , 양의 에서 四象 이 생겨나 고 , 사상 에서 八卦 가 생겨나 지요 . 세상 의 모든 것 은 기 의 표현 에 지나 지 않 습니다 . \" ( 상 - p . 271 ) \" ~ 그 혈 은 저희 들 이 말 하 는 \\' 경락 \\' 을 따라 자리 잡 고 있 습니다 . 경락 이 란 인체 의 기 가 흐르 는 길 이 지요 . 경락 에 기 가 고이 면 곧 병 이 됩니다 . 그것 을 틔워 줌 으로써 병 은 낫 고 , 건강 한 삶 을 얻 을 수 있 습니다 . ~ 덧붙여 말 하 자면 대지 의 경락 을 \\' 풍수 \\' 라고 합니다 . ~ . \" ( 상 - p . 272 ) ▷▷▷ 아케미 의 등장 ( 『 광 골 의 꿈 』 에서 사건 중심 인물 ) - 수상 한 약장수 ( 오구니 세이이치 ) 소개 로 약장수 가 된 남자 와 살 고 있 는 아케미 가 ( 개소리 에 작동 하 는 ) 후 최면 에 빠져 계속 자살 을 시도 하 는 무라카미 헤이키 치 를 길 에서 우연히 구조 한다 - 무라카미 는 도쿄 중앙우편국 에서 편지 검열 직 에 있 다 <- 니라 야마 마을 로 송금 되 는 편지 의 소인 과 연결 \\u200b ■ 효 스 베 ひょうすべ ( 갓파 ) 나 는 늘 그렇 듯이 지인 세키구치 라고 만 소개 되 었 다 . 아무래도 교고쿠 도 는 학생 시절 부터 나 를 친구 라고 인정 하 지 않 은 것 같 다 . 그 는 , 친구 분 되 십니까 , 라는 질문 을 받 을 때 마다 친구 가 아니 라 지인 이 라고 부정 했 다 . ~ 그러 면서 아내 쪽 은 , 집 사람 의 친구 이 고 세키구치 군 의 안사람 이 기 도 한 유키에 씨 입니다 . --- 라고 소개 하 니 , 더욱 화 가 난다 . ( 상 - p . 298 ~ 299 ) 교고쿠 도 의 말 에 따르 면 내 언동 은 착각 2 할 , 잘못 2 할 , 거짓 1 할 에 오해 가 5 할 이 라고 한다 . 진실 은 1 할 도 없 다 . ( 상 - p . 416 ) 세키구치 曰 \" 교고쿠 도 씨 의 이야기 로 는 이게 특별히 기억 해야 할 부분 이 라고 하 더군요 . 구속 하 고 , 반복 하 고 , 끊임없이 그걸 되풀이 해서 회원 들 로부터 가치관 뿐 만 아니 라 스스로 생각 할 힘 자체 를 박탈 해 버리 는 거 지요 . 자아 를 훔쳐 가 는 겁니다 . 그것 이야 말 로 --- 종교 의 어떤 수법 이 기 는 하 다고 , 그 는 그렇게 말 했 어요 . \" ( 상 - p . 383 ) 고서점 주인 < 군 시 테이 > 주인 미야무라 가 나오 曰 \" 세상 에 는 말 일세 --- 이상 한 일 이 라곤 아무 것 도 없 다네 , 세키구치 군 . \" ( 상 - p . 447 ) ▷▷▷ 가토 마미코 가 후 최면 상태 임 을 진단 한 추 젠지 - 1933 . 6 . 4 . 가토 마미코 ( 6 세 ) , 할배 가토 다 다 지로 , 철도 창가 부르 며 길 가 다 효소 베 ( 이와타 준 요 ) 목격 - 1952 . 4 . 7 . 가토 마미코 , 아사쿠사 바시 근처 에서 이와타 준 요 목격 ◀ 두 번 째 목격 이 라고 하나 실제로 는 < 길 의 가르침 수 신회 > 회장 이와타 준 요 를 처음 본 것 - 이와타 목격 후 귀가 하 다 오구니 세이이치 를 집 앞 에서 만남 , 약 을 판 후 이틀 에 한 번 꼴 방문 하 던 중 오후 5 시 36 분 ~ 37 분 , 마미코 , 오구니 에 효소 베 ( 2 번 의 목격담 ) 이야기 해줌 ◀ 오구니 , 이걸 이용 해 후 최면 - 1952 . 4 . 8 . 오구니 가 자신 이 모시 는 영매 ( 가 센코 오토메 ) 의 점괘 에서 다미코 의 딸 에 水難 있 다고 . .. 1952 . 4 . 9 . 마미코 의 딸 익사 ( 水難 ) - 딸 을 목욕 시키 던 중 팔 에 경직 와서 딸 익사 , 간 샤쿠 다마 의 후 최면 - 이후 마미코 는 오구니 로부터 영매 를 소개 받 고 그 의 신탁 대로 행동 한다 ▶ ① 이혼 ② 출판사 사표 ③ 할배 다 다 지로 의 < 길 의 가르침 수 신회 > 활동 반대 - \" 그것 을 보 았 기 때문 에 다시 불행 이 되풀이 될 거 라는 강박 관념 을 부추기 기 위해 , 거슬러 올라가 당신 의 기억 을 개찬 한 겁니다 . ~ \" ( 상 - p . 451 ) 마미코 의 대한 교고쿠 도 의 진단 ▶ 다 다 지로 의 기억 ( 1933 . 6 . 4 . 효소 베 목격담 ) 이 잘못 된 게 아니 라 마미코 의 기억 이 잘못 됐 던 것 , 1933 년 의 목격담 은 원래 부터 없 었 던 것 , 삽입 이식 된 것 요괴 효소 베 ( 기억 지배 ) , 간 샤쿠 다마 ( 육체 지배 ) 의 후 최면 - 의문 ⓐ 오구니 세이이치 / 가 센코 오토메 일당 은 왜 가토 마미코 를 노린 걸까 ? ⓑ 영매 가 센 코 는 왜 마미코 의 할배 가토 다 다 지로 의 < 길 의 가르침 수 신회 > 탈퇴 를 바라 는가 ? ⓒ < 길 의 가르침 수 신회 > 는 왜 마미코 의 입교 를 끈질기 게 권유 하 는 걸까 ? ◀◀◀ 이후 밝혀 지 는데 . .. 가토 다 다 지로 가 현 니라 야마 ( 옛 헤비 토 ) 마을 임야 소유주 , 마미코 는 상속인 ■ 와이 라 わいら \\u200b 아츠코 는 그렇게 결론 이 내렸 다 . 다시 말 해서 . 氣 는 눈 에 보이 지 않 는 파동 도 미지 의 에너지 도 아니 다 . 계속 적 인 이미지 트레이닝 과 형식 의 반복 연습 으로 얻 어 지 는 자기 암시 에 의해 , 어떤 일정 한 상황 이나 정보 에 대해 무 의식 적 으로 육체 적 인 반응 이 일어난다 . --- 그것 이 기 의 정체 다 . 이것 은 말 하 자면 placebo effect 같 은 것 이 다 . ( 상 - p . 42 ) ▷▷▷ 영매 사 가 센코 오토메 의 정체 와 그 배후 들 - 가 센코 오토메 : 사라진 헤비 토 마을 의 사에키 가문 의 딸 사에키 후유 ( 얘 도 후 최면 에 걸린 듯 ) 로 확인 - 가 센코 주변 에서 이상 한 단체 들 등장 : < 韓 流 氣道 會 한류 기도회 >\\u200b, < 장수연 명회 > ◀ 한류 ! !! 회장 韓 大人 ! !! . 가 센코 는 < 한류 기도회 > 로부터 도망치 고 \\u200b< 장수연 명회 > 가 구해 주 고 . .. - 하타 류조 의 등장 : 이른 봄 의 사건 『 무당거미 의 이치 』 의 오리 사쿠 가문 과 사돈 가문 인 < 하타 제철 > 사람 ■ 쇼 케라 しょうけら ( 수명 을 줄이 는 벌레 ) \" 그렇 지 않 아요 . 이건 서민 의 계 조직 을 이용 해서 세력 확대 를 꾀한 천태종 을 야유 하 고 있 는 것 일 겁니다 . \" \" 이건 계획 적 인 겁니다 . 의도 적 으로 유행 시킨 거 예요 . 잡다 하 고 두 서 없 는 경신 행사 의 , 표면 상 무 관계 한 事象 을 연결 하 는 건 천태종 뿐 입니다 . 庚申 堂 의 대부분 은 천태 계 지요 . 경신 의 기원 을 적 은 것 도 아마 천태 승일 겁니다 . 산노 일실 신도 의 기원 과 경신 기원 은 디테일 이 매우 비슷 해요 . \" ( 하 - p . 203 ) 천태종 은 중국 천태산 이 본산 , 천태산 은 도교 가 성했 던 산 , 천태종 은 사이 초 가 개조 , 히에이 잔 이 본산 , 경신 관습 이 유래 된 근원지 , 천태종 은 에도 막부 와 밀접 , 덴카이 天 海 승정 僧正 ( 도쿠가와 이에야스 의 측근 ) 도 천태종 승려 , 권력 과 종교 가 유착 해 민간 의 관습 을 유도 , 통제 , 감시 , 일종 의 정보 조작 ※ しし 蟲 시시 무시 : 수명 을 줄이 는 벌레 , シヤ 蟲 시야 무시 , 쇼 키 라 , 쇼 케라 しょうけら ※ < 화 한 삼재도회 > - \\' 피안 \\' : 생사 관장 의 8 신 ( 閻魔 大王 , 帝釋 , 大 將軍 , 行役 , 司命 , 司 祿 , . ..) ※ 불교 의 十王 : 閻魔 大王 , 泰山 府君 ※ 三尸九蟲 : 중국 에서 사람 몸 속 에 사 는 벌레 를 이르 는 말 - 구충 : 기생충 들 - 삼 시 : ① 上 尸 ( 彭 倨 ) : 얼굴 에 주름 , 눈병 , 잇몸 병 ② 中 尸 ( 彭 質 ) : 내장 침범 , 조급증 , 건망증 , 악몽 , 불안 ③ 下 尸 ( 彭 僑 ) : 감정 , 精 - 삼 시 는 庚申 의 날 에 숙주 ( 사람 ) 가 자 는 동안 하늘 로 올라가 司命 神 에게 숙주 의 죄상 을 보 고 한다 . 그 에 따라 숙주 의 명이 사 명신 에 의해 결정 된다 . 삼 시 는 나쁜 보고 를 하 기 에 숙주 의 수명 은 줄어든다 . 숙주 가 죽 어야 삼시 가 유령 으로 빠져 나 가 장례식 의 공물 을 먹 을 수 있 기 때문 이 다 . 이런 이유 로 경신 의 날 밤 에 사람 들 이 모여서 자 지 않 고 노 는 것 이 다 . 중국 에서 는 이 를 守 庚申 . 庚申 은 干支 와 관련 , 불교 보 다는 道敎 의 영향 ※ 庚申 - 종교 가 아닌 관습 , 十干十二支 , 庚申 墓 , 庚申 堂 , < 庚申 緣起 >, < 庚申 經 >, < 庚申 傳 > - 삼 후 : 보 지 않 고 , 말 하 지 않 고 , 듣 지 않 는 원숭이 - 靑 面 金剛 : 제석천 , 비사문천 의 부하 급 , 삼 시충 ( 쇼 케라 ) 퇴치 - 종교 의 요건 : 敎 儀 / 開祖 / 本 存 - 庚申 은 이 세 가지 가 없 으므로 종교 가 아닌 관습 - 五行 : 木 火 土金 水 - 庚申 모임 의 근원 : 히에 이잔 比 叡 山 의 히에 대사 日 枝 大社 . 히에 산노 山 王 7 社 의 神 의 사자 는 원숭이 - 庚申 의 주문 : \\' 안 잔다 잔다 잔다 안 잔다 \\' 후 렴구 가 붙 는 것 들 이 많 다 - 道 祖神 도 조신 : 마을 수호신 , 여행 / 교통안전 의 신 , 촌락 경계 , 갈림길 등 에 비석 , 석상 형태 - 원숭이 : 제석천 의 사자 . 제석천 : 불법 수호 十二天 중 하나 , 天帝 로 도 비유 . 天帝 : 북두 의 紫微 宮 의 최고위 神 - 사쿠 가 미 作 神 : 農神 , 農作 樣 , 음력 2 월 5 일 에 떡 찧 는 절굿공이 소리 듣 고 내려와 농사 일반 을 수호 한 후 음력 10 월 15 일 절굿공이 소리 를 듣 고 돌아간다 - 金剛 : 執 金剛力士 , 金剛 杵 무기 를 지닌 佛 尊 , 전투 적 불 존 . 금강력 사 , 금강야차 , 금강동자 . 나체 의 여인 의 머리카락 을 한 손 에 잡 고 있 는 모습 - 여인 은 쇼 케라 - 荒 神 ( 大黑天 의 原型 ) = 청면금강 => 庚 神 尊 은 삼시 ( 쇼 케라 ) 를 퇴치 , 쇼 케 라는 쓰노 대사 와 통하 고 쓰노 대사 는 대흑천 의 원형 . 서로 섞여 ( 습합 ) 되 어 있 다 . \\' 비틀림 의 신앙 · 습속 \\' - しし 蟲 시시 무시 : 수명 을 줄이 는 벌레 , シヤ 蟲 시야 무시 , 쇼 키 라 , 쇼 케라 しょうけら . しょうけら : 精靈 + 무 시케 라 蟲 루고 -> 精 루고 , 靑 鬼 라 . 염마대왕 : 사람 의 행동 에 따라 수명 을 관장 , 쇼 케 라는 염마대왕 의 동료 ( 인간 수명 을 관장 한다는 측면 ) . 三尸蟲 : 히에 이잔 의 산신 , 겐 산 元 三 대사 , 대흑천 ( = 염마 ) ※ 庚申 에 밤 을 새우 는 이유 는 수명 을 관장 하 는 벌레 ( 시시 무시 ) 를 감시 하 기 위함 경신 의 밤 에 사람 이 잠자 는 동안 벌레 가 나와 하늘 에 ( 염마대왕 ) 보고 하 여 수명 을 조절 - 염마대왕 , 제석천 에 밀 고 , 제석천 의 사자 ( 원숭이 , 申 ) - 경신 의 밤 에 는 회임 않 는다 . 이시카와 고 에 몬 ( 에 도 시대 도적 ) 의 수 태일 이 경신 , 도둑 을 낳 게 된다는 속설 ※ 荒 神 고진 ( 庚申 고신 ) : 일본어 발음 이 유사 - 부뚜막 의 신 : 중국 의 < 抱朴子 > \\' 內篇 6 권 \\', 섣달 그믐 날 부뚜막신 이 하늘 로 올라가 司命 神 에게 죄업 을 밀 고 한다 . ( 庚申 의 시시 무시 와 비슷 한 ) . 그래서 사람 들 이 섣달 그믐 에 밤 을 샌다 ※ 大黑天 - 원래 는 마카 카라 ( 인도 의 전 투신 ) , 피 빨 고 인육 먹 는 야차 의 총대장 , 죽음 신 - < 大日 紀 >, < 仁王 紀 > 에서 는 염마 와 동체 , 명계 의 신 으로 설법 -> 수명 관장 기능 - 중국 에서 는 사원 주방 에 대흑천 을 모심 , 주방 수호신 , 양식 수호신 , 부뚜막신 과 동열 - 일본 민간 신앙 에서 는 福神 ( 7 복신 중 하나 ) : 흑 두건 쓰 고 , 자루 메 고 , 망치 들 고 , 쌀섬 밟 고 ※ 다키니 천 茶 吉 尼 天 - 胎 藏 界 曼茶羅 의 外 金剛 部 院 에 보내 진 여자 악귀 , 6 개월 전 에 사람 의 죽음 을 알 고 그 심장 을 먹 는다 . 따르 는 자 에겐 자유자재 한 힘 을 내려준다 - 일본 에서 는 여우 의 정령 이 라 하 며 이나리 다이묘 진 稻 荷 大明 神 으로 모시 기 도 한다 - 대흑천 에게 는 꼼짝 못 한다 ※ 死刑 - 합법 에 의한 행위 이나 행위 자체 는 살인 이 다 . 인간 이 법 을 이용 살인 하 는 것 이 다 - 합법 의 근거 가 되 는 사회 정의 는 믿 을 수 있 는 건가 ■ 오토 로 시 おとろし 毛 一杯 ( 게 잇 파이 , 털 가득 한 ) , おどろく , 오도 로 오도 로 棘 棘 , 하 치만 신사 의 도리 이 위 에서 하 치만 신사 의 使者 인 비둘기 를 잡 고 있 는 요괴 통제 할 수 없 는 영역 을 통제 하 고 싶 어 지 는 욕구 는 , 통제 할 수 있 는 영역 을 통제 할 수 없 게 되 는 두려움 에 그 뿌리 를 두 고 있 다 . 따라서 사람 은 불 규칙 한 대지 에 규칙 적 으로 길 을 새긴다 . 그래도 모자라 서 지도 에 기록 한다 . 도시 라는 것 은 구현 화 된 관념 이 다 . ( 하 - p . 336 )',\n",
       "       '[ machine learning academy _ part ⅲ . neural networks 최적화 ] 4 . dropout ( overfitting 에 대한 해결책 ) overfitting 에 대한 또 다른 해결책 - dropout overfitting 에 대한 해결책 으로 “ regularization ” 과 “ 지능 적 으로 훈련 데이터 를 늘리 는 방법 ” 에 대해서 살펴보 았 다 . 이번 class 에서 는 신경망 ( neural network ) 에서 overfitting 문제 를 피하 는데 사용 되 는 “ dropout ( 망 부분 생략 ) ” 방법 에 대해 살펴볼 예정 이 다 . regularization 이 error 함수 또는 cost 함수 에 penalty 함수 를 추가 하 고 그 penalty 부분 에 대한 조작 을 통해 결과 를 얻 는 방식 이 라면 , dropout 은 망 자체 를 변화 시키 는 방식 이 기 때문 에 둘 은 근본 적 으로 다르 다 . hidden layer 의 개수 가 많 아 질 경우 의 장단점 ? \\u200b 일반 적 으로 신경망 에서 hidden layer 의 개수 가 많 아 지 면 , 즉 deep neural network 이 되 면 , 더욱 많 은 문제 를 해결 할 수 있 도록 학습 능력 이 좋 아 진다 . 하지만 , 망 의 크기 가 커지 면 커질수록 overfitting 에 빠질 가능 성 이 높 아 지 고 , 신경망 에 대한 학습 시간 도 길 어 지 는 문제 가 있 으며 , 적절 한 결과 를 도출 하 려면 훈련 데이터 의 양 또한 늘려야 한다 . dropout 개요 \\u200b 이렇게 망 의 크기 가 커질 경우 overfitting 문제 를 피하 기 위한 방법 이 dropout 이 며 , 논문 이 발표 된 지 채 10 년 이 넘 지 않 았 다 . dropout 은 아래 의 그림 ( a ) 에 대한 학습 을 할 때 , 망 에 있 는 모든 layer 에 대해 학습 을 수행 하 는 것 이 아니 라 그림 ( b ) 와 같이 망 에 있 는 입력 layer 나 hidden layer 의 일부 뉴런 을 생략 ( dropout ) 하 고 줄어든 신경망 을 통해 학습 을 수행 한다 . 일정 한 mini - batch 구간 동안 생략 된 망 에 대한 학습 을 끝내 면 , 다시 무작위 로 다른 뉴런 들 을 생략 ( dropout ) 하 면서 반복 적 으로 학습 을 수행 한다 . dropout 효과 그럼 이렇게 dropout 을 하 는 이유 는 무엇 이 고 , dropout 은 과연 효과 가 있 을까 ? ① voting 효과 dropout 을 하 는 첫 번 째 이유 는 투표 ( voting ) 효과 때문 이 다 . 일정 한 mini - batch 구간 동안 줄어든 망 을 이용 해 학습 을 하 게 되 면 , 그 망 은 그 망 나름 대로 overfitting 이 되 며 , 다른 mini - batch 구간 동안 다른 망 에 대해 학습 을 하 게 되 면 , 그 망 에 대해 다시 일정 정도 overfitting 이 된다 . 이런 과정 을 무작위 로 반복 을 하 게 되 면 , voting 에 의한 평균 효과 를 얻 을 수 있 기 때문 에 , 결과 적 으로 regularization 과 비슷 한 효과 를 얻 을 수 있 게 되 는 것 이 다 . ② co - adaptation 을 피하 는 효과 또 다른 이유 로 co - adaptation 을 피하 는 효과 를 들 수 있 다 . regularization 에서 살펴본 것 처럼 , 특정 뉴런 의 바이어스 나 가중치 가 큰 값 을 갖 게 되 면 그것 의 영향 이 커지 면서 다른 뉴런 들 의 학습 속도 가 느려 지 거나 학습 이 제대로 진행 이 되 지 못하 는 경우 가 있 다 . 하 지만 dropout 을 하 면서 학습 을 하 게 되 면 , 결과 적 으로 어떤 뉴런 의 가중치 나 바이어스 가 특정 뉴런 의 영향 을 받 지 않 기 때문 에 결과 적 으로 뉴런 들 이 서도 동조 화 ( co - adaptation ) 이 되 는 것 을 피할 수 있 다 . 특정 학습 데이터 나 자료 에 영향 을 받 지 않 는 보다 강건 한 ( robust ) 한 망 을 구성 할 수 가 있 게 되 는 것 이 다 . 이것 은 마치 오랜 시간 동안 지구 상 에 존재 하 는 생명체 들 이 유전자 복제 가 아닌 양성 생식 을 통해 유전자 를 결합 하 고 보다 강인 한 유전자 들 이 자연 의 선택 을 받 아 살아남 는 것 과 마찬가지 이 다 . 참조 논문 정보 dropout 에 대한 논문 은 꽤 있 지만 , 아래 논문 이 설명 이 잘 된 것 같 으니 참고 하 면 좋 을 것 같 다 . 참고 로 공동 저자 들 인 geoffrey hinton 과 yoshua bengio 는 신경망 학습 분야 에서 혁혁 한 연구 성과 를 보이 고 있 는 사람 들 이 다 . dropout : a simple way to prevent neural networks from overfitting 다음 class 에서 는 신경망 학습 에서 overfitting 과 마찬가지 로 문제 가 되 고 있 는 “ 느린 학습 속도 ” 를 다룰 예정 이 다 . 느린 학습 을 활성 화 함수 의 관점 에서 살펴 보 고 , 문제 를 해결 하 기 위한 “ cross - entropy cost function ” 에 대해 살펴볼 예정 이 다 . [ keyword ] dropout , 지능 형 학습 , regularization , overfitting , backpropagation , 역전 파 , sigmoid , cost function , gradient - descent , 뉴 럴 네트워크 , neural network , 머신 러닝 , 기계 학습 , machine learning , 지도 학습 , supervised learning , 강화 학습 , reinforcement learning , 자율 학습 , unsupervised learning',\n",
       "       \"공간 에서 직선 을 방정식 으로 표현 할 수 있 듯이 평면 도 방정식 으로 표현 할 수 있 습니다 . 위 그림 에서 두 점 은 평면 위 의 점 이 고 이 고 은 평면 p 와 수직 인 벡터 입니다 . 여기 서 을 법선 벡터 ( normal vector ) 라고 부릅니다 . 이 평면 p 와 수직 이 므로 와 도 수직 입니다 . 따라서 입니다 . 그러므로 평면 의 벡터 방정식 은 입니다 . － 평면 의 벡터 방정식 － 한 점 을 지나 고 법선 벡터 가 인 평면 의 벡터 방정식 은 일 때 이 다 . 라고 하 면 평면 의 벡터 방정식 에서 을 얻 습니다 . 따라서 이 되 고 이것 을 전개 하 면 이 됩니다 . 간단 하 게 라고 하 면 평면 의 방정식 은 이 됩니다 . － 평면 의 방정식 － 한 점 을 지나 고 법선 벡터 가 인 평면 의 방정식 은 이 다 . 간단 하 게 라 하 면 평면 의 방정식 은 일반 적 으로 의 형태 로 나타낼 수 있 다 . 위 식 을 보 면 평면 의 방정식 은 x , y , z 에 대한 일차식 임 을 알 수 있 습니다 . 만약 평면 이 세 점 a ( a , 0 , 0 ) , b ( 0 , b , 0 ) , c ( 0 , 0 , c ) ( abc ≠ 0 ) 을 지난 다면 다음 과 같이 구할 수 있 습니다 . 주어진 평면 의 법선 벡터 를 이 라 하 면 은 와 수직 이 고 와 수직 입니다 . 즉 , 동시 에 수직 이 죠 따라서 입니다 . 그리고 평면 은 점 a 를 지납니다 . 따라서 평면 의 방정식 은 입니다 . 전개 해서 정리 하 면 이 고 양변 을 abc 로 나누 면 이 나옵니다 . 따라서 다음 을 얻 습니다 . － 정리 1 － 세 점 을 지나 는 평면 의 방정식 은 이 다 . ex 1 ) 한 점 ( 2 , 4 , － 1 ) 을 지나 고 법선 벡터 가 인 평면 의 방정식 을 구하 고 그 그래프 를 그리 시 오 . ( 풀이 ) 한 점 ( 2 , 4 , － 1 ) 을 지나 고 법선 벡터 가 인 평면 의 방정식 은 이 므로 전개 하 면 2 x ＋ 3 y ＋ 4 z ＝ 12 이 다 . 그래프 를 그리 면 아래 와 같 다 . ex 2 ) 세 점 p ( 1 , 3 , 2 ) , q ( 3 , － 1 , 6 ) , r ( 5 , 2 , 0 ) 을 지나 는 평면 의 방정식 을 구하 시 오 . ( 풀이 ) 주어진 평면 의 법선 벡터 를 이 라 하 면 법선 벡터 는 와 에 동시 에 수직 이 므로 이 다 . 주어진 평면 은 점 p 를 지나 므로 평면 의 방정식 은 ex 3 ) 직선 과 평면 4 x ＋ 5 y － 2 z ＝ 18 이 만나 는 점 의 좌표 를 구하 시 오 . ( 풀이 ) 주어진 직선 을 매개변수 형태 로 쓰 면 x ＝ 2 ＋ 3 t , y ＝－ 4 t , z ＝ 5 ＋ t 이 다 . 이것 을 평면 에 대입 하 면 4 ( 2 ＋ 3 t ) ＋ 5 ( － 4 t ) － 2 ( 5 ＋ t ) ＝ 18 이 므로 t ＝－ 2 t ＝－ 2 이면 x ＝－ 4 , y ＝ 8 , z ＝ 3 따라서 교점 의 좌표 는 ( － 4 , 8 , 3 ) 이 다 . ex 3 ) 두 평면 x ＋ y ＋ z ＝ 1 , x － 2 y ＋ 3 z ＝ 1 이 이루 는 각 의 크기 를 구하 시 오 . ( 풀이 ) 두 평면 의 법선 벡터 는 각각 두 평면 에 수직 이 므로 두 평면 이 이루 는 각 의 크기 는 두 법선 벡터 가 이루 는 예각 의 크기 와 같 다 . 따라서 두 평면 이 이루 는 각 의 크기 를 θ 라 하 면 두 평면 의 법선 벡터 는 각각 < 1 , 1 , 1 > , < 1 , － 2 , 3 > 이 므로 직선 과 직선 이 이루 는 각 평면 과 평면 이 이루 는 각 이것 은 두 방향 벡터 가 이루 는 예각 의 크기 와 같 습니다 . 그런데 직선 과 평면 이 이루 는 각 을 구할 떄는 주의 해야 할 점 이 있 습니다 . 위 그림 처럼 평면 의 법선 벡터 과 직선 의 방향 벡터 가 이루 는 각 의 크기 를 θ 라 하 면 직선 과 평면 이 이루 는 각 의 크기 는 가 됩니다 . 따라서 를 이용 해서 cos θ 를 구했 으면 직선 과 평면 이 이루 는 각 의 크기 를 알 기 위해 의 값 을 알 아야 합니다 . 벡터 의 외적 을 이용 하 면 두 평면 의 교선 의 방정식 을 쉽 게 구할 수 있 습니다 . 일단 직관 적 으로 생각 할 수 있 는 사실 이 지만 두 평면 은 두 평면 의 교선 을 포함 합니다 . 따라서 두 평면 의 법선 벡터 를 라고 하 고 교선 의 방향 벡터 를 라고 하 면 교선 과 방향 벡터 는 평행 하 므로 는 에 동시 에 수직 입니다 . 그러므로 교선 의 방향 벡터 는 두 법선 벡터 의 외 적 입니다 . － 정리 2 － 법선 벡터 가 각각 인 두 평면 의 교선 의 방향 벡터 를 라 하 면 이 다 . ex 4 ) 두 평면 x ＋ y ＋ z ＝ 1 , x － 2 y ＋ 3 z ＝ 1 의 교선 의 방정식 을 구하 시 오 . ( 풀이 ) 두 평면 의 법선 벡터 는 각각 < 1 , 1 , 1 > , < 1 , － 2 , 3 > 이 므로 교선 의 방향 벡터 는 한편 두 평면 에 z ＝ 0 을 대입 하 면 x ＋ y ＝ 1 , x － 2 y ＝ 1 이 연립 방정식 을 풀 면 x ＝ 1 , y ＝ 0 이 나온다 . 따라서 교선 은 점 ( 1 , 0 , 0 ) 을 지난다 . 그러므로 교선 의 방정식 은 이 다 . 아래 그림 에서 라고 할 때 점 과 직선 사이 의 거리 d 를 구하 는 방법 은 다음 과 같 습니다 . 위 그림 에 있 는 평면 을 ax ＋ by ＋ cz ＋ d ＝ 0 이 라고 하 면 이 고 는 평면 위 의 점 이 므로 입니다 . 와 이 이루 는 각 의 크기 를 θ 라고 하 면 위 그림 에서 길이 가 d 인 선분 과 이 이루 는 각 의 크기 도 θ 가 됩니다 . 따라서 입니다 . － 정리 3 － 점 과 평면 사이 의 거리 는 이 다 . ex 5 ) 평행 한 두 평면 10 x ＋ 2 y － 2 z ＝ 5 , 5 x ＋ y － z ＝ 1 사이 의 거리 를 구하 시 오 . ( 풀이 ) 두 평면 이 평행 하 기 때문 에 한 평면 위 의 점 을 하나 잡 아서 그 점 과 다른 평면 사이 의 거리 를 구해도 된다 . 10 x ＋ 2 y － 2 z ＝ 5 위 의 점 을 잡 고 이 점 과 평면 5 x ＋ y － z ＝ 1 사이 의 거리 를 구하 면 이 다 . ex 6 ) 꼬인 위치 에 있 는 두 직선 사이 의 거리 를 구하 시 오 . ( 풀이 ) 두 직선 은 꼬인 위치 에 있 으므로 교점 을 갖 지 않 는다 . 따라서 두 직선 l ₁ , l ₂ 를 포함 하 는 평행 한 두 평면 p ₁ , p ₂ 를 만들 수 있 다 . 두 평면 이 평행 하 고 그 평면 은 직선 을 포함 하 므로 두 평면 의 법선 벡터 는 두 직선 의 방향 벡터 와 동시 에 수직 이 다 . 두 직선 의 방향 벡터 는 각각 < 1 , 3 , － 1 > , < 2 , 1 , 4 > 이 므로 법선 벡터 는 따라서 l ₁ 을 포함 하 는 평면 은 점 ( 1 , － 2 , 4 ) 을 지나 므로 그리고 직선 l ₂ 위 의 점 은 ( 0 , 3 , － 3 ) 점 ( 0 , 3 , － 3 ) 과 평면 13 x － 6 y － 5 z － 5 ＝ 0 사이 의 거리 는 두 직선 사이 의 거리 와 같 으므로 구하 면 이 다 . 내용 출처 : calculus 6 e － james stewart p . s : 직선 의 경우 에 는 두 점 을 지나 는 직선 의 방정식 이 공식 화 되 어 있 는데 평면 의 경우 에 는 세 점 을 지나 는 평면 의 방정식 이 공식 화 되 어 있 지 않 습니다 . 그 이유 는 세 점 을 지나 는 평면 의 방정식 을 공식 화 시킨 게 너무 복잡 하 기 때문 입니다 . 실제로 세 점 을 지나 는 평면 의 방정식 은 라고 할 때 이렇게 나옵니다 . 복잡 하 네요 . ... ㄷ ㄷ 삼각형 pqr 의 넓이 를 구하 는 것 도 공식 화 되 지 않 은 이유 는 위 와 같 습니다 . ' 복잡 해서 ' 입니다 . 쓰 는 김 에 삼각형 pqr 의 넓이 도 그 결과 만 쓰 면 이렇게 나옵니다 . 이거 외울 용자 분 계시 나요 ? 위 식 은 벡터 의 외적 을 이용 하 면 모두 유도 할 수 있 습니다 . 심심 하 면 저 공식 유도 해 보 세요 ㅋㅋㅋ\",\n",
       "       '최근 네이버 통 번역 앱 파 파고 에 는 자체 개발 기술 인 네이버 인공 신경망 번역 기술 ( n 2 mt ) 이 적용 되 었 는데요 . 문장 의 전체 의 맥락 을 먼저 이해 하 고 구성 요소 들 을 번역 하 는 n 2 mt 는 기존 일반 번역기 에 적용 되 어 있 는 통계 기반 번역 ( smt ) 보다 2 배 이상 의 품질 이 향상 된 기술 입니다 .',\n",
       "       '허수 의 정의 , 복소수 의 정의 ( 수학 적 의미 측면 에서 ) - 1 편 오랜만 에 글 을 써 봅니다 . ( 사실 포스팅 을 안 한 것 은 아니 지만 모두 비 공개 로 했 습니다 . 요즘 들 어 신중 해 지 고 겁 도 나 더군요 . 보 잘 것 없 는 지식 을 함부로 까발려서 혹시 이웃 들 에게 피해 나 주 지 않 을까 싶 어서요 ) 그리고 금번 포스팅 도 역시 짧 지 않 습니다 . 인쇄 하 시 면 좋 을 듯 싶 네요 허수 . ... 거의 모든 분 들 이 \\' 허수 \\' 를 대하 면 다음 과 같 은 생각 을 떠 올리 실 것 입니다 . \" 도대체 상상 속 의 수 , 실제로 존재 하 지 도 않 는 수 인 허수 가 왜 우리 한테 필요 한 거 지 ? \" \" 그리고 구태여 이 걸 공부 해야 할 이유 가 있 는 것 일까 ? \" 그래서 허수 ( 그리고 실수 와 허수 가 같이 있 는 복소수 ) 에 는 마음 이 가 지 않 게 되 고 , 오로지 시험 만 을 위해 공식 은 물론 이 고 문제 의 패턴 까지 도 외워서 공부 하 게 됩니다 . 당연히 그 결과 는 \\' 매우 비 효율 적 인 공부 \\' 가 되 어 버리 죠 . 비 효율 적 인 공부 란 . ... 공부 에 투입 하 는 시간 은 많 은데 성적 은 안 오르 는 친구 들 있 죠 ? 머리 가 나쁜 것 이 아니 라 비 효율 적 으로 공부 하 기 때문 입니다 . 반대 로 놀 것 다 놀 고 할 것 다 하 는 데 도 성적 은 좋 은 친구 들 도 있 죠 ? 머리 가 좋 은 것 이 아니 라 효율 적 으로 공부 하 기 때문 입니다 . 그럼 . .. 쌤 . .. 효율 적 으로 공부 한다는 것 은 무엇 인가요 ? 라는 질문 을 던지 고 싶 으실 겁니다 . 저 는 이 질문 에 이렇게 답 합니다 . 효율 적 인 공부 란 \\' 몰입 \\' 이 다 ! 그리고 몰입 이란 \\' 마음 이 가 야 \\' 생기 는 것 이 다 ! ( 그 방법 에 대한 저 의 경험 과 견해 는 다른 포스트 에 써 보 겠 습니다 ) \\u200b \\u200b 암튼 \\' 마음 이 가 야 학습 효율 도 오른다 ! \\' 는 것 은 저 의 신념 입니다 . \\u200b 금번 포스팅 이 고등학생 수준 에서 는 조금 어려우 시 겠 지만 . .. 속 는 셈 치 고 끝 까지 읽 어 보 시 죠 . 학문 적 으로 조금 만 깊이 있 게 , 수박 겉 핡 기 식 으로 라도 한 번 구경 이 라도 해 보 고 나오 면 어느덧 허수 와 복소수 에 \\' 마음 이 가 는 \\' 자신 의 변화 를 느끼 실 수 있 으실 겁니다 . 공부 라 생각 하 지 마시 구요 \\u200b \\u200b 예전 에 제 가 교과서 내용 에 충실하 게 쓴 포스팅 은 아래 참조 [ URL ] \\u200b \" 허수 를 알 기 전 에 는 실수 도 없 었 다 . 그저 \\' 수 \\' 만 존재 했었 다 . 없 는 수 , 아무 의미 도 쓸모 도 없 는 수 인 허수 ! 하지만 허수 를 인정 했 기 에 실수 라는 것 이 그 건너편 에 존재 할 수 있 게 되 었 고 , 오늘날 우리 는 실수 와 허수 를 모두 포함 하 여 \\' 수 \\' 라고 부른다 . \\u200b\" \\u200b 1 . 허수 는 방정식 을 풀 다가 발견 하 였 고 , 이 허수 의 발견 으로 방정식 도 더욱 발전 되 었 다 . \\u200b 혹시 무리수 를 누 가 , 어떻게 최초 로 발견 해 내 었 는지 아 시 나요 ? 피타고라스 의 제자 ( 히 파수스 ) 가 피타고라스 의 정리 를 계산 하 다 발견 해 내 었 습니다 . 왜 뜬금 없이 허수 가 아닌 무리수 얘기 가 나오 냐구요 ? 이 포스트 를 다 읽 어 보 시 면 그 이유 를 아 시 게 될 것 입니다 . 다시 무리수 로 돌아가 서 . ..\\u200b 직각삼각형 의 세변 에 관한 공식 인 \\u200b 에서 a 와 b 가 1 이 면 빗변 의 길이 의 제곱 은 2 가 되 겠 죠 ? 이 니깐 요 . 그렇 다면 제곱 이 아닌 빗변 의 길 이 는 얼마 일까요 ? 여러분 은 아주 쉽 게 라고 답 하 실 수 있 습니다 . 그러나 피타고라스 는 자연수 , 정수 , 유리수 외 라는 무리수 의 존재 를 인정 하 지 않 았 기 때문 에 답 을 말 하 지 못했 을 겁니다 . \\u200b 무엇 을 제곱 해야 2 가 나오 는가 ? 즉 2 의 제곱근 은 무엇 인가 ? 과연 존재 나 하 는 수 인가 ? 아마도 머릿속 에 매우 큰 혼란 이 왔 을 것 입니다 . 그렇 다고 회피 할 수 도 없 었 던 이유 는 는 분명 그릴 수 도 있 고 볼 수 도 있 는 숫자 인 것 은 확실 했 기 때문 입니다 . \\u200b \\u200b \\u200b 의 길이 를 선분 으로 그릴 수 있 죠 ? \\u200b 그 들 은 혹시나 2 의 제곱근 을 찾 을 수 도 있 지 않 을까 ? 하 는 심정 으로 분명히 계산 해 보 았 을 것 입니다 . 아래 와 같 은 원시 적 인 방법 으로 말 이 죠 . \\u200b 일단 1 . 3 의 제곱 은 1 . 69 이 므로 아웃 ! 1 . 5 의 제곱 은 2 . 25 이 므로 또 아웃 ! 그렇 다면 2 의 제곱근 은 1 . 3 과 1 . 5 사이 에 있 는 1 . 4 ***** 의 제곱 일텐데 . .. 1 . 4 ² = 1 . 96 1 . 41 ² = 1 . 9881 1 . 414 ² = 1 . 999396 ( 음 . . 점점 더 2 에 가까와 지 고 있 다 . 하지만 아직 2 는 아니 지 . ..) \\u200b - - - 그러나 아무리 계산 해도 끝 을 알 수 가 없 었 습니다 . 1 . 4142135237 ******* \\u200b 훗날 이러 한 고민 속 에 결국 \\u200b 소 숫 점 아래 가 절대로 끝나 지 않 고 ( 무한소수 ) , 숫자 들 간 반복 성 도 없 는 ( 비 순환 ) . .. 이런 소수 를 \\' 무리수 \\' 라고 부르 며 인정 하 게 되 었 습니다 . ( 유리수 는 소 숫 점 아래 가 언젠가 는 끝 이 나 던가 . .. 아니 면 끝 이 없 더라도 일정 한 수 들 이 규칙 적 으로 순환 은 하 는 소수 ) 그리고 이 무리수 도 유리수 와 마찬가지 로 엄연 한 \\' 숫자 \\' 로 인정 하 게 되 었 습니다 . \\u200b 숫자 로 인정 한다는 것 은 덧셈 , 뺄셈 , 곱셈 , 나눗셈 이 가능 하 고 , 교환법칙 , 결합법칙 , 분배법칙 등 대수 의 기본 공리 ( axiom ) 도 적용 가능 함 을 의미 합니다 . 그리고 무리수 를 숫자 로 인정 하 게 됨 으로써 인류 의 수체 계 는 자연수 , 정수 , 유리수 를 넘 어 무리수 로 까지 확장 되 었 습니다 . \\' 수 \\' 라는 점 을 찍 으면 그 전 에 는 빈 점 ( 불연속점 ) 이 있 어 선분 을 완성 시키 지 못했 는데 . . 이제 는 단 한 점 의 빈 점 ( 불연속점 ) 도 없이 완벽 한 연속 선분 을 그릴 수 있 게 된 것 입니다 . 비 순환 무한소수 인 무리수 가 바로 빈 점 이 었 거든요 . 더군다나 실수 체계 에서 가장 많 은 수 도 무리수 입니다 . \\u200b 이러 한 무리수 의 발견 은 피타고라스 정리 덕분 이 었 지만 결국 은 방정식 의 해 를 구한 것 에서 출발 했 다 라고 해도 \\u200b 과언 이 아닙니다 . 를 고민 하 는 것 이 나 . .. 를 고민 하 는 것 이나 같 거든요 . 앞 으로 도 잘 기억 해 두 세요 . .. 방정식 의 해 를 고민 하 는 과정 에서 무리수 의 의미 , 허수 의 의미 등 . . 대수 ( algebra ) 의 발전 이 시작 되 었 다는 사실 을 . .. 곱셈 공식 , 인수 분해 , 조립제법 . . 나아가 페르마 의 정리 까지 도 마찬가지 입니다 . 대수 는 왠만 하 면 방정식 풀 기 위해서 고민 하 다 발전 되 었 죠 . \\u200b 자 . . 그럼 또 다른 방정식 을 고민 해 봅시다 . 의 해 는 무엇 인가요 ? 이 면 되 는 것 이 고 , 그렇 다면 는 무엇 인가요 ? 무엇 을 제곱 해야 - 1 이 나오 나요 ? 이 질문 으로부터 허수 의 발견 이 시작 되 었 습니다 . 방정식 을 풀 다가 허수 라는 개념 을 생각 해 낸 것 이 죠 . 수 의 한계 를 실수 까지 만 인정 한다면 이 방정식 은 근 이 없 는 방정식 이 됩니다 . 그러나 가능 성 을 열 어 둔다면 , 즉 실수 가 아니 더라도 이 방정식 의 해 는 존재 할 수 도 있 다 라고 가능 성 을 열 어 둔다면 . .. 그 해 는 실수 에서 는 존재 하 지 않 는 \\' 거듭 제곱 으로 음수 가 되 는 \\' 수 여야 합니다 . 이 란 수식 을 있 는 그대로 인정 하 는 것 이 죠 . \\u200b 의 해인 도 \\' 수 ( number ) \\' 이 지만 우리 의 감각 으로 인식 할 수 있 는 실수 는 아니 기 때문 에 \\' 허수 ( imaginary number ) \\' 라 부르 게 되 었 습니다 . \\u200b \\ufeff 실제로 허수 가 발견 된 경위 는 아래 와 같 습니다 . \\' 근 의 공식 \\' 이 이 차 방정식 의 일반해 인 것 처럼 삼 차 방정식 의 일반 해도 공식 으로 찾 아 냈 습니다 . 16 세기 말 타르탈리아 라는 사람 이 찾아낸 삼차 방정식 일반해 는 아래 와 같 았 습니다 . \\u200b 일 때 식 좀 복잡 하 죠 ? ^^ 검증 한 번 해 보 죠 \\u200b 일 때 는 ? ( 당연히 1 이 죠 ^^) 위 공식 에 대입 해도 이 나올까요 ? ( ) \\u200b \\u200b \\u200b 맞 네요 ^^ \\u200b 카르다노 라는 동 시대 좀 더 유명 한 수학자 도 이 삼 차 방정식 의 일반해 를 검증 \\u200b 해 보 았 습니다 . \\u200b 라는 삼차 방정식 을 가지 고서 말 이 죠 ( 는 4 라는 사실 을 이미 알 고서 ) 공식 에 대입 했 더니 \\u200b 이 나오 게 되 었 고 \\u200b 을 어떻게 처리 해야 할지 카르다노 는 궁금 했 습니다 . ( 아니 . . 궁금 했 다기 보 다는 타르탈리아 를 괴롭히 고 싶 었 겠 죠 . .. 일반해 를 만들 어 낸 너 는 이 를 어떻게 처리 할 수 있 는지 한 번 두 고 보 겠 다 라는 심정 으로 ) 그래서 카르다노 는 타르탈리아 에게 편지 를 보냈 습니다 . \\u200b 당신 공식 에 집 어 넣 었 더니 이 존재 하 던데 . . 이건 어떻게 하 실 겁니까 ? \\u200b 타르탈리아 의 친구 이 자 동료 였 던 봄 벨리 는 그 편지 를 보 고서 는 카르다노 에게 \\u200b\\' 도 수다 ! \\' 라고 말 했 습니다 . 정확 하 게 는 \\' 실수 처럼 동일 하 게 대우 해도 좋 다 ! \\' 라 한 거 죠 . 이 의미 가 무엇 이 냐면 이나 등 음수 의 제곱근 은 실제로 존재 하 는 실수 는 아니 지만 실수 와 동일 하 게 더 하 고 빼 는 연산 이 가능 한 수 로 취급 할 수 있 지 않 은가 ? 그러면 삼 차 방정식 일반해 는 설명 이 된다 라는 것 이 었 습니다 . 다음 과 같 은 풀이 로 말 이 죠 . \\u200b \\u200b \\u200b 따라서 \\u200b \\u200b 삼 차 방정식 의 일반해 는 \\u200b \\u200b 음수 의 제곱근 \\u200b 을 실수 처럼 취급 하 여 계산 식 과 연산 에 포함 시키 면 방정식 의 해 를 구할 수 있 다 ! 라는 사실 을 알 고 나 서 허수 의 존재 성 은 더욱 부각 되 었 고 , 현재 우리 는 방정식 의 실근 과 허근 이 라는 개념 도 알 게 되 었 습니다 . \\u200b 그리고 비슷 한 시대 페르마 , \\u200b 이후 가우스 등 이 허수 의 개념 을 더 발전 시켜 주 셨 답니다 . \\u200b \\u200b 2 . 허수 도 실수 와 같 은 대접 을 받 는다 . ( 연산 이 가능 하 다 ) \\u200b 위 에서 아주 중요 한 말씀 을 드렸 습니다 . 허수 는 실수 ( real number ) 는 아니 지만 수 ( number ) 로 인정 은 받 는다고 . ... 여기 서 \\' 수 ( number ) \\u200b\\' 로 인정받 는다 \\' 는 뜻 은 실수 처럼 \\' 연산 이 가능 함 \\' 을 우선 의미 합니다 . 덧셈 뺄셈 곱셈 나눗셈 도 다 되 구요 교환법칙 결합법칙 분배법칙 다 됩니다 . 하지만 분수 에서 분모 에 위치 할 수 는 없 구요 ( 어떤 수 를 허수 로 나눈다는 것 은 말 이 안 되 므로 . .. 허수 를 실수 로 나눌 수 는 있 지만 . ..\\u200b \\u200b 실수 를 허수 로 나눌 수 는 없 는 노릇 입니다 . 개념 자체 가 형성 되 지 않 죠 . . 무언가 를 몇 개 로 나눈다는 말 에서 \\' 몇 개 \\' 가 분모 인데 . .. 이 는 0 을 제외 한 실수 만 이 가능 합니다 . 사과 1 개 를 \\u200b \\u200b 명 이 나누 어 먹 는다 ? 말 이 됩니까 ? 그래서 분모 에 허수 가 오 면 켤레 복소수 를 분모 분자 에 동일 하 게 곱해 주 어 분모 를 실수 로 바꾸 는 겁니다 . \\u200b 이렇 듯 허수 도 실수 와 같 은 대접 을 받 는 부분 이 바로 여러분 이 고등 학교 에서 배우 는 내용 들 입니다 . 일단 기본 허수 단위 인 \\u200b 를 라는 기호 로 표시 하 는 것 을 배우 고 난 뒤 이 를 익숙 하 게 하 기 위해 ( 가장 중요 ) , , , ( 역시 중요 ) , , 등 을 연습 합니다 . 관련 계산 문제 들 도 풀 게 하 구요 그리고 나 서 \\u200b , 등 허수 끼리 는 덧셈 뺄셈 도 가능 함 을 알려 줍니다 . 단 , 허수 와 실수 는 더 하 고 뺄 수 없 습니다 . 곱셈 나눗셈 도 연습 시키 죠 ? \\u200b , ( ) 교환법칙 결합법칙 분배법칙 은 스스로 해 보 시 구요 곱셈 공식 에 의 적용 도 가능 함 을 알려 줍니다 . \\u200b \\u200b \\u200b \\u200b 허수 가 실수 처럼 연산 및 공식 적용 이 가능 한 대접 을 받 게 되 면서 부터 수 의 체계 는 걷잡 을 수 없이 확장 되 게 됩니다 . \\u200b 우선 방정식 의 해 가 실수 의 범위 를 벗어나 허수해 ( 허근 ) 까지 확장 되 었 고 , 밑 에서 설명 드리 겠 지만 2 차원 의 복소수 체계 와 결합 되 어 복소 해석 및 미적분학 의 발전 을 이루 어 냅니다 . 또한 복소 함수 는 각종 진동 , 전류 , 파동 , 열 , 자기장 등 우리 자연 에너지 를 나타내 는 핵심 역학 의 토대 가 되 어 줍니다 . 그 뿐 만 이 아닙니다 . 4 차원 체계 의 4 원수 , 8 차원 체계 의 8 원수 라는 벡터 들 도 그 토대 는 허수 라는 개념 을 찾 지 못했 으면 불 가능 한 발견 들 이 었 습니다 . \\u200b 그래서 허수 를 교과 과정 에 포함 시킨 것 이 고 , 여러분 은 다행 스럽 게 도 허수 의 개념 및 연산 , 복소수 의 개념 등 기초 부분 만 \\u200b 익히 시 면 됩니다 . 하지만 이 처럼 좀 더 큰 물 에서 허수 와 복소수 의 의미 를 미리 짚 어 보 고 공부 하 는 것 과 , 그저 눈 앞 에 놓인 개념 과 공식 을 외우 는 것 은 굳이 효율 과 비 효율 을 따지 지 않 더라도 당장 공부 하 실 때 체감 할 수 있 는 \\' 몰입 \\' 의 차이 를 바로 느끼 실 수 있 을 것 입니다 . 숲 을 보 고 나무 를 보 면 산 전체 가 이해 가 되 는 법 이 거든요 . \\u200b \\u200b \\u200b \\u200b 3 . 허수 도 좌표 평면 에 표시 할 수 있 다 . \\u200b 자 . . 이제 슬슬 허수 와 실수 를 같이 엮 는 복소수 체계 로 들어가 려고 합니다 . \\u200b \\u200b 와 같 은 복소수 체계 가 어떻게 탄생 했 느냐 를 알 기 위해서 는 우선 좌표 평면 상 에 허수 를 어떻게 표시 할 수 있 었 는가 ? 를 공부 해야 합니다 . 실수 가 방정식 을 넘 어 함수 로 까지 나아갈 수 있 었 던 것 은 실수 를 구성 하 는 모든 점 은 좌표 평면 상 에 표시 될 수 있 음 을 인정 했 기 때문 이 고 , 특히 일정 패턴 을 보여 주 는 점 들 의 집합 ( 선형 ) 을 해석 할 수 있 게 됨 으로써 ( 해석학 ) 미적분 이 발전 되 어 수학 은 인류 역사 상 최고 의 발전 \\u200b 을 이루 게 되 었 습니다 . \\u200b \\' 좌표 평면 상 에 표시 된다 \\' 는 말 은 특정 한 점 ( 또는 선 ) 에 고유 한 \\' 이름 \\' 이 붙여 진다는 의미 가 있 습니다 . 그냥 점 a , 점 b . .. 이런 이름 말 고 , 더 구체 적 으로 위치 정보 가 들 어 있 는 이름 말 이 죠 . a ( 2 , 3 ) , b ( 5 , 7 ) . . 이런 식 으로 말 이 죠 . 이렇게 위치 정보 가 들 어 있 는 좌표 평면 상 의 이름 은 많 은 유용 한 \\' 해석 \\' 을 가능 하 게 해 줍니다 . 두 점간 거리 도 측정 할 수 있 구요 . ... 두 점 을 선 으로 이 어 . .. 다음 점 c 를 예측 할 수 있 게 도 해 주 구요 . .. 점 을 어떤 패턴 에 의해 이동 ( 변환 ) 시켜 볼 수 도 있 게 되 구요 . .. 기울 기 도 측정 해 보 고 . .. 절편 을 지나 는 점 을 찾 음 으로써 방정식 의 근도 대수 가 아닌 기하학 적 해석 으로 \\u200b 구할 수 있 게 해 줍니다 . 여러모로 유용 하 다는 사실 만 기억 해 두 세요 \\u200b \\u200b \\u200b 좌표 평면 은 차원 의 수 에 따라 축 의 수도 비례 합니다 . 1 차원 인 선 은 축 한 개 ( 선위 의 점 ) 2 차원 인 면 은 축 두 개 ( x 축 , y 축 , 평면 위 의 점 ) \\u200b 3 차원 입체 는 축 세 개 ( x 축 , y 축 , z 축 , 입체 도 형 내 의 점 ) 4 차원 은 ? 이 는 우리 인간 의 감각 으로 도형 화 시킬 수 없 습니다 . 하지만 축 은 4 개 5 차원 은 : 4 차원 도 표현 못 하 는데 . . 하물며 . .. 하지만 역시 축 은 5 개 \\u200b 그리고 자연수 와 정수 뿐 만 이 아니 라 유리수 , 무리수 도 모두 표시 가능 합니다 . 무리수 의 길 이나 표시 에 관해서 는 맨 위 그림 보 시 면 되 겠 죠 ? \\u200b 그런데 . . 허수 . .. 실제로 는 존재 하 지 않 는 허수 는 어디 에 점 을 찍 어야 하 나요 ? 점 이 찍히 는 선 , 면 , 입체 등 은 모두 실수 체계 내 에서 였 는데 . ..\\u200b 여기 서 사고 를 전환 시키 면 됩니다 . \\' 축 \\' 은 실수 에 한정 되 지 않 거든요 \\u200b. 허수 도 \\' 수 \\' 라고 인정 한다면 허수 들 만 찍 을 수 있 는 \\' 허수축 \\' 도 존재 할 수 있 음 을 인정 해야 합니다 . \\u200b 이렇게 허수축 을 인정 하 게 되 면 좌표 평면 상 의 축 은 실수축 과 허수축 두 개 로 대별 할 수 있 게 됩니다 . 그리고 두 축 은 서로 직각 인 90 도 로 해 주 어야 \\u200b 나머지 연산 과 변환 논리 도 성립 할 수 있 습니다 . 허수축 이 실수축 을 기준 으로 90 도 이 어야 하 는 이유 를 좀 더 자세히 설명 드리 자면 . ..',\n",
       "       \"인류 역사 에서 인간 과 가장 오랫동안 함께 해온 동물 은 쥐 다 . 그럼에도 불구 하 고 쥐 는 식량 을 축내 고 질병 을 옮기 는 백해무익 한 동물 로 만 인식 돼 왔 다 . 하지만 과학자 에게 는 쥐 가 다른 어떤 동물 보다 친근 하 게 느껴진다 . 세계 적 인 과학 전문지 인 네이처 의 표지 모델 로 3 차례 나 등장 했 을 정도 다 . 그렇 다면 쥐 가 생물 실험 에 이용 된 것 은 언제 부터 일까 ? 정확 한 기록 은 없 지만 고대 부터 의학 , 생물 , 화학 실험 등 에 동물 을 사용 했 다는 설 이 있 다 . 우리 나라 에서 도 조선 시대 때 변사체 의 독살 여부 를 알 기 위해 사체 를 통해 나온 음식물 을 개 등 에게 먹였 다는 기록 이 있 다 . 쥐 를 실험 에 본격 적 으로 이용 한 시기 는 19 세기 말 로 질병 치료제 의 위험 도와 약효 를 미리 알아보 기 위해서 다 . 실험 용 쥐 는 이제 의학 , 수의학 , 약학 , 농학 , 생물학 등 을 포함 한 생명 과학 전반 에 필수 불가결 한 연구 수단 이 됐 다 . 미국 시사 주간지 뉴스 위크 는 얼마 전 ' 우리 의 세계 를 변화 시킬 10 가지 발명품 ' 을 특집 으로 소개 하 면서 10 대 발명품 에 ' 실험 용 쥐 ' 를 포함 시켰 다 . 왜 쥐 인가 ? 쥐 가 실험동물 로 각광 받 는 것 은 포유류 중 에서 가격 이 싸 다는 점 과 쥐 의 생물학 적 특징 때문 이 다 . 즉 쥐 는 월경 주기 가 4 ∼ 5 일 이 고 임신 기간 은 3 주로 짧 아 번식 이 쉽 다 . 또 분만 후 곧바로 임신 할 수 있 고 한 번 에 5 ∼ 15 마리 의 새끼 를 낳 는다 . 계산 상 으로 1 년 동안 쥐 가 낳 을 수 있 는 새끼 의 수 는 2 만 여 마리 나 된다 . 또 한 세대 의 수명 이 2 ∼ 3 년 이 기 때문 에 그만큼 연구 성과 를 빨리 알 수 있 다 . 개 , 원숭이 , 돼지 등 도 실험동물 로 사용 하 지만 비용 이 많이 들 고 필요 한 연구 성과 를 알 기 까지 시간 도 많이 걸린다 . 뿐 만 아니 라 쥐 는 척추 동물 인데다 dna 의 염기 수 가 30 억 쌍 으로 사람 과 거의 유사 하 다 . 이 는 인간 이 가질 수 있 는 질병 을 쥐 도 앓 을 수 있 다는 것 을 의미 한다 . 또한 20 세기 이후 쥐 에 관한 꾸준 한 연구 로 포유류 중 에선 가장 많 은 정보 가 축적 돼 있 다 . 더구나 반세기 동안 유전자 관련 논문 의 양 이 늘어나 면서 유전자 쥐 를 만드 는 기술 도 발전 했으며 현재 수천 여종 의 유전자 들 을 임의 로 생산 할 수 있 다는 것 이 큰 장점 이 다 . 예 를 들 어 당뇨병 치료 약 개발 을 위해 당뇨병 에 걸린 유전자 쥐 를 이용 할 수 있 다 . 현재 고 혈압 , 간염 , 신장염 , 치주염 , 유방암 등 에 걸린 유전자 쥐 가 300 종이 넘 는다 . 어떤 게 있 나 ? 실험 용 쥐 는 크 게 몸체 가 8 cm 정도 인 조그만 생쥐 ' 마우스 ( mouse ) ' 와 몸체 가 20 cm 정도 인 ' 래트 ( rat ) ' 로 나뉜다 . 쥐 의 주요 생산 · 소 비국 은 미국 과 일본 으로 1 년 에 5 , 000 만 마리 가 사용 된다 . 실험 용 쥐 가운데 ' 근교계 ' 라고 불리 는 쥐 는 20 세대 이상 반복 교배 를 통해 마치 일 란 성 쌍생아 처럼 만든 쥐 이 다 . 이렇게 만든 이유 는 각종 실험 에서 같 은 반응 을 얻 기 위해서 다 . 우리 나라 에서 실험 용 쥐 를 만드 는 회사 로 는 중앙 실험 동물사 , 대한 바 이 오 링크 , 샘 타코 , 바이오 제노 믹스 등 이 있 다 . 국내 에서 연간 실험대 에 오르 는 실험 용 쥐 는 350 만 ∼ 400 만 마리 정도 로 알려져 있 다 . 이런 실험 용 쥐 의 가격 은 천차만별 이 다 . 실험 용 으로 가장 흔히 쓰이 는 icr 마우스 의 경우 마리 당 3 , 000 원 정도 지만 유전자 조작 을 한 쥐 의 가격 은 훨씬 비싸 다 . 털 이 없 으며 면역 기능 도 없 어 이식 및 면역 관련 실험 에 이용 되 는 누드 쥐 의 경우 마리 당 4 만 5 , 000 ∼ 8 만 원 이 다 . 하지만 유전자 조작 쥐 의 품종 과 용도 에 따라 가격 이 500 만 원 을 호가 하 는 경우 도 적 지 않 다 . 유전자 쥐 도 나와 실험 용 쥐 가운데 유전자 쥐 는 쥐 의 dna 를 조작 해 유전자 를 변형 한 것 . 유전자 쥐 가운데 유전자 를 과 발현 시킨 쥐 를 만들 기 위해서 는 우선 생쥐 암놈 과 수놈 의 인공수정 이나 교배 를 통해 수정란 을 만든 다 . 이때 현미경 과 미세 한 주사 바늘 을 이용 해 수정란 속 에 있 는 염색체 에 특정 질환 이 생기 게 하 는 dna 를 삽입 한다 . 이렇게 한 뒤 다시 수정란 을 암놈 자궁 에 착상 시키 고 3 주 가 지난 뒤 태어난 새끼 들 중 실제로 그 유전자 가 삽입 된 질환 이 생긴 쥐 를 분자 생물학 적 방법 으로 찾아내 면 된다 . 유전자 의 기능 을 없앤 쥐 의 생산 은 태아 줄기세포 를 이용 해 훨씬 더 오래 걸리 고 복잡 한 과정 을 거쳐 이루어진다 . 유전자 쥐 는 지적 재산 권 의 대상 이 될 정도 로 산업 적 가치 가 커서 ' 황금 알 을 낳 는 쥐 ' 로 불린다 . 1994 년 미국 에서 는 비만 과 당뇨병 의 원인 인 특정 유전자 를 없앤 쥐 가 탄생 하 자 ' 암 젠 ' 이 라는 유명 제약사 가 이 쥐 의 특허 권 을 2 , 000 만 달러 ( 240 억 원 ) 에 사들였 다 . 일본 의 한 생명 공학 연구소 는 사람 의 특정 암 유전자 를 지닌 유전자 쥐 를 마리 당 40 만 원 에 팔 고 있 다 . 이 쥐 는 신약 의 발암 유해 성 여부 실험 기간 을 5 년 에서 6 개월 로 줄여 준다 . ' 누드 쥐 ' 는 면역 기능 이 완전히 파괴 돼 인간 에게 생긴 암세포 를 키울 때 쓰인다 . 누드 쥐 에서 는 암세포 를 공격 하 는 항체 가 만들 어 지 지 않 기 때문 이 다 . 한국 과학 기술 연구원 ( kist ) 신희섭 박사 팀 은 유전자 를 조작 해 학습 능력 과 기억력 이 더 뛰어난 쥐 를 만들 었 다 . 인간 의 학습 능력 과 기억력 을 향상 시킬 수 있 는 약물 이나 치매 치료제 같 은 뇌 질환 치료제 를 개발 하 기 위해서 였 다 . / 권대 익기 자 dkwon @ hk . co . kr 0 0 공유 기사 저장 한국일보 뉴스 네이버 채널 구독 하 기\",\n",
       "       '원본 보 기 원본 보 기 원본 보 기 伊 도서 병리학 연구소 , 신현세 장인 한지 이용 \\' 카르 툴라 \\' 되살려 한지 , 伊 서 문화재 복원 용도 \\' 적합 \\' 인증 ( 로마 = 연합뉴스 ) 현윤 경 특파원 = 800 년 전 가톨릭 의 성인 인 성 프란체스코 ( 1182 ∼ 1226 년 ) 의 친필 기도문 이 담긴 이탈리아 의 귀중 한 유물 \\' 카르 툴라 \\'( chartula ) 가 우리 전통 종이 인 한지 를 이용 해 복원 됐 다 . 이탈리아 문화부 산하 도서 복원 전문 기관 인 도서 병리학 연구소 ( icpal ) 는 최근 한지 를 이용해 성 프란체스코 의 \\' 카르 툴라 \\' 복원 작업 을 완료 , 이 를 15 일 로마 시내 icpal 본부 에서 선보였 다 . 이탈리아 중부 아시시 의 성 프란치스코 대성당 이 소장 하 고 있 는 카르 툴라 는 평생 빈자 들 과 함께 하 며 청빈 과 겸손 의 삶 을 산 프란체스코 성인 이 선종 2 년 전 인 1224 년 , 그리스도 에게 영감 을 받 고 지 은 \\' 하느님 찬미가 \\' 와 \\' 레오 수사 를 위한 축복 기도문 \\' 을 직접 적 어 넣 은 양피지 로 가톨릭 역사 와 이탈리아 중세사 에서 차지 하 는 가치 가 높 다 . 2001 년 부터 \\' 카르 툴라 \\' 복원 에 착수 한 icpal 은 경남 의령군 에 있 는 신현세 전통 한지 공방 에서 제작 한 전통 한지 를 이용해 카르 툴라 밑 부분 의 손상 부위 를 보강 , 원형 을 되살렸 다 . icpal 은 카르 툴라 를 비롯 해 이탈리아 주요 문화재 5 점 의 복원 에 한지 를 사용 했 다고 밝혔 다 . 현존 하 는 가장 오래 된 채색 신약 성서 본 중 하나 인 6 세기 비잔틴 시대 문화재 인 로사노 복음서 , 16 ∼ 17 세기 작품 으로 추정 되 는 사르데냐 섬 가문 들 의 문장 모음 집 등 의 각 페이지 와 책 등 을 연결 하 는 부분 보강 작업 에 한지 가 쓰였 다 . 우리 전통 종이 한지 가 수 세기 전 서구 의 유물 의 복원 에 사용 된 것 은 유례 가 없 는 일 로 , 한지 세계 화 의 신호탄 이 될 것 으로 기대 된다 . 그 동안 일본 전통 종이 화지 는 50 년 전 피렌체 대홍수 때 손상 된 문화재 복구 에 대거 쓰인 것 을 계기 로 이탈리아 를 비롯 한 서양 의 문화재 복원 에 널리 활용 됐 다 . 반면 , 한지 는 결합성 이 좋 아 보강 작업 이 용이 하 고 , 성질 이 중성 을 띄 어 보존 성 이 우수 하 다는 일반 적 인 평가 에 도 불구 하 고 , 국제 적 인 인지도 가 낮 아 문화재 복원 분야 에서 거의 사용 되 지 않 았 던 것 이 현실 이 다 . 지금 까지 한지 가 세계 적 인 문화재 복원 에 쓰인 알려진 사례 는 교황 요한 23 세 ( 재위 1958 ∼ 1963 년 ) 재단 의 주도 로 이뤄진 교황 요한 23 세 의 지구본 등 극히 소수 에 불과 하 고 , 복원 문화재 도 비교 적 현대 작품 에 국한 돼 있 었 다 . icpal 은 이 와 함께 카르 툴라 복원 에 쓰인 한지 제작자 신현세 장인 의 한지 가 문화재 복원 용도 로 적합 함 을 공식 적 으로 인증 하 고 , 이날 이용준 주이 탈리아 대사 에게 인증서 를 전달 했 다 . 인증 받 은 한지 는 \\' 의령 신현세 전통 한지 1 \\' 과 \\' 의령 신현세 전통 한지 2 \\' 두 종류 다 . icrcpal 은 성분 , 산성도 검사 를 비롯 한 생물학 적 검사 , 물리 화학 적 , 기술 적 검사 등 을 거쳐 문화재 복원 재료 로서 의 한지 의 적합 성 에 합격 점 을 내렸 다 . 한지 가 해외 공인 기관 에서 문화재 복원 용도 로 인증 을 받 은 것 은 사상 처음 이 다 . 고문서 복원 관련 기관 으로 는 이탈리아 는 물론 유럽 을 통틀어 가장 권위 있 는 기관 으로 꼽히 는 icrcpal 의 인증 을 받 는 동시 에 문화재 복원 에 있 어 한지 를 써도 좋 다는 인식 이 전 세계 문화재 복원 업계 에 퍼지 는 셈 이 기 때문 에 한지 의 세계 화 작업 에 탄력 이 붙 을 것 으로 전망 된다 . 이용준 대사 는 \" 한국 의 가장 위대 한 문화유산 중 하나 인 한지 가 전 세계 문화재 복원 분야 의 가장 권위 있 는 기관 중 하나 인 icpal 의 공인 을 받 게 돼 영광 \" 이 라며 \" 한지 가 문화재 복원 분야 에서 보다 폭넓 게 사용 될 수 있 도록 앞 으로 1 년 간 icpal 에서 사용 할 한지 를 한국 대사관 에서 무상 으로 제공 할 것 \" 이라고 약속 했 다 . 마리아 레티치아 세바스 티아니 icpal 소장 은 \" 주 이탈리아 한국 대사관 과 국립 문화재 연구소 등 한국 측 의 헌신 적 인 지원 과 협력 이 없 었 다면 이번 문화재 복원 과 인증 은 가능 하 지 않 았 을 것 \" 이 라며 \" 이탈리아 는 도처 에 문화재 복원 대상 이 널려 있 는 만큼 앞 으로 다양 한 분야 에서 한지 사용 을 확대 할 수 있 을지 검토 할 것 \" 이라고 화답 했 다 . 이날 인증서 전달식 에서 는 신현세 장인 을 비롯 해 외교부 문화 외 교국 배병수 심의 관 , 최맹식 국립 문화재 연구 소장 등 도 자리 를 함께 했 다 경남 의령 에서 50 년 넘 게 한지 제작 에 전념 해 온 신현세 장인 은 \" 이탈리아 의 의미 있 는 문화재 복원 에 내 가 만든 한지 가 쓰여서 큰 보람 을 느낀다 \" 고 소감 을 말 했 다 . 한편 , 지난 달 말 부터 이달 초 에 걸쳐 바티칸 과 이탈리아 북부 티에네 등지 에서 현지 문화재 복원 전문가 들 을 상대 로 한지 활용 법 을 소개 한 박지선 용인 대 문화재 보존 학과 교수 는 \" 한지 에 대한 이탈리아 전문가 들 의 관심 이 생각 보다 뜨거워 깜짝 놀랐 다 \" 며 \" 이번 한지 인증 을 영세 한 국내 한지 산업 을 되돌아보 고 , 도약 시키 는 계기 로 삼 아야 할 것 \" 이라고 말 했 다 . ykhyun 14 @ yna . co . kr',\n",
       "       '원본 보 기 원본 보 기 원본 보 기 손님 초대 할 일 많 은 1 월 . 남녀노소 누구 나 좋 아 하 는 고기 는 새해 를 위한 최고 의 식 재료 다 . 독일 , 헝가리 , 영국 등 세계 각국 의 고기 요리 를 준비 하 면 색다른 분위기 를 연출 하 며 식사 분위기 도 한층 고조 되 지 않 을까 ? 고기 부위 는 좀 더 구하 기 쉬운 재료 로 바꿔 만들 기 도 어렵 지 않 다 . 외국 의 고기 요리 중 대표 적 인 것 이 바로 칠면 조구이 . 구하 기 어려운 칠면조 대신 닭 을 사용 하 면 만들 기 쉽 고 맛 도 담백 하 다 . 오리고기 를 활용 해도 ok ! 닭다리 8 개 , 레몬 2 개 , 다진 마늘 · 꿀 · 올리브 오일 1 큰 술 씩 , 소금 · 후춧가루 · 다진 파슬리 약간 씩 , 샬롯 ( 미니 양파 ) 4 개 , 알 감자 5 개 닭다리 는 흐르 는 물 에 가볍 게 씻 어 물기 를 제거 한다 . 레몬 은 씻 어 한 개 는 모양 을 살려 편 으로 썰 고 , 한 개 는 즙 을 낸다 . 넓 은 볼 에 ② 의 레몬 즙 과 다진 마늘 , 꿀 , 올리브 오 일 , 소금 , 후춧가루 를 넣 어 섞 은 뒤 닭다리 를 넣 고 밑간 한다 . 샬롯 , 알 감자 , 슬라이스 한 레몬 은 올리브 오일 에 살살 버무려 오븐 팬 에 담 고 닭다리 를 올린다 . 200 ℃ 로 예열 한 오븐 에 ③ 을 넣 고 30 분 간 구운 뒤 접시 에 담 는다 . hungary 굴라시 는 헝가리 식 소고기 채소 스튜 다 . 으깬 감자 나 리소토 등 과 함께 먹 으면 더욱 맛있 다 . 소고기 ( 우둔살 등 기름기 적 은 부위 ) 400 g , 그린 빈 5 개 , 마늘 2 쪽 , 감자 · 양파 · 빨간 파프리카 1 개 씩 , 당근 ⅔ 개 , 홀 토마토 통조림 1 캔 , 올리브 오일 1 큰 술 , 카레 가루 1 작 은 술 , 고운 고춧가루 2 작 은 술 , 물 4 컵 , 소금 · 후춧가루 · 다진 허브 약간 씩 소고기 는 2 cm 크기 로 깍 둑 썰 고 , 그린 빈 은 2 cm 길이 로 자르 고 , 마늘 은 편 으로 썬 다 . 감자 와 당근 은 큼직 하 게 잘라 모서리 를 둥글 게 다듬 고 , 양파 도 큼직 하 게 썬 다 . 파프리카 는 씨 를 제거 한 뒤 크 게 썬 다 . 홀 토마토 통조림 의 토마토 는 굵 게 으깬 다 . 깊 은 냄비 에 올리브 오일 을 두르 고 마늘 과 소고기 를 볶 다가 고기 가 노릇 해 지 면 나머지 채소 를 넣 고 볶 는다 . 채소 가 노릇 해 지 면 ③ 의 토마토 와 카레 가루 , 고춧가루 , 물 을 넣 고 끓인다 . 모든 재료 가 뭉근 하 게 익 을 때 까지 끓이 다가 소금 과 후춧가루 로 간하 고 다진 허브 를 뿌린다 . united kingdom 영국 의 대표 요리 중 하나 로 고기 겉 은 바삭 하 고 안 은 육즙 이 살 아 있 다 . 고기 굽 는 시간 은 기호 에 따라 조절 해도 된다 . 단호박 ¼ 개 , 방울 양배추 · 방울토마토 6 개 씩 , 올리브 오일 약간 , 소고기 등심 600 g , 밑간 양념 ( 홀 그레인 머스터드소스 · 우스터소스 2 큰 술 씩 , 다진 마늘 1 큰 술 , 소금 · 후춧가루 · 올리브 오 일 · 다진 로즈메리 약간 씩 ) , 통마늘 2 개 , 소스 ( 밀가루 1 큰 술 , 레드와인 250 ml , 머스터드 1 작 은 술 , 버터 약간 ) 단호박 은 씨 를 제거 해 도톰 하 게 편 으로 썰 고 , 방울 양배추 와 방울토마토 는 올리브 오일 에 살짝 버무린다 . 소고기 는 조리용 실 을 이용 해 모양 을 잡 고 단단 하 게 감 은 뒤 밑간 양념 에 30 분 간 재운다 . 오븐 팬 에 ① 의 채소 와 통마늘 , 소고기 를 올리 고 200 ℃ 로 예열 된 오븐 에서 40 분 간 굽 는다 . 구운 채소 와 고기 를 꺼내 고 오븐 팬 에 남 은 육즙 을 덜 어 낸다 . 팬 에 육즙 을 담 고 밀가루 를 넣 고 볶 다가 레드와인 과 머스터드 를 넣 어 중간 불 에서 끓인 후 불 을 끄 고 버터 를 녹여 소스 를 만든 다 . 그릇 에 구운 소고기 와 채소 를 담 고 소스 를 곁들인다 . united kingdom 고기 소 로 속 을 채운 파이 로 한 개 만 먹 어도 속 이 든든 하 다 . 모양 도 귀여워 테이블 에 놓 으면 포인트 가 된다 . 파이 지 ( 중력분 180 g , 버터 120 g , 소금 2 g , 달걀 1 개 , 물 약간 ) , 필링 ( 불고 깃 감 소고기 ( 다짐 육 ) 400 g , 채 썬 양파 ¼ 개 , 간장 · 다진 파 · 다진 마늘 1 큰 술 씩 , 후춧가루 약간 ) 볼 에 밀가루 를 담 고 깍 둑 썬 차가운 버터 와 소금 을 넣 고 스 크 래퍼 로 잘라 가 면서 고슬고슬 하 게 섞일 때 까지 섞 는다 . ① 에 달걀 을 넣 고 물 로 농도 를 조절 하 며 한 덩어리 가 될 때 까지 반죽 한 뒤 비닐 에 넣 어 냉장고 에서 30 분 간 휴지 시킨다 . 분량 의 필링 재료 를 섞 어 10 분 간 재운 뒤 차가운 팬 에 물 기 가 없 어 질 때 까지 볶 는다 . ② 의 파이 반죽 을 꺼내 3 mm 정도 로 밀 어 머핀 틀 사이즈 로 잘라 담 고 뚜껑 을 만들 어 자른다 . ④ 의 파이 시트 에 볶 아 놓 은 소고기 를 담 고 다시 뚜껑 반죽 을 덮 어 테두리 를 포크 로 찍 어 모양 을 낸다 . 190 ℃ 로 예열 된 오븐 에서 25 분 간 굽 는다 . argentina 아사도 는 소갈비 를 통 으로 숯불 에 굽 는 요리 다 . 베이비 립 을 사용 하 면 먹 기 가 한층 편하 다 . 베이비 립 1 . 5 kg , 밑간 ( 다진 로즈메리 1 큰 술 , 소금 · 후춧가루 · 청주 약간 씩 ) , 바비큐 소스 ( 올리브 오 일 · 양 겨자 · 설탕 · 청주 1 큰 술 씩 , 다진 양파 · 다진 마늘 3 큰 술 씩 , 물 · 시판 용 바비큐 소스 ½ 컵 씩 , 토마토케첩 · 간장 2 큰 술 씩 , 다진 마른 홍고추 1 개 분량 ) , 빨간 파프리카 1 개 , 레몬 , 통마늘 2 개 , 껍질 콩 10 줄기 , 파에야 나 볶음밥 약간 베이비 립 은 찬물 에 1 시간 정도 담가 핏물 을 빼 고 칼집 을 낸다 . 밑간 재료 로 밑간 한 뒤 찜통 에서 15 분 간 찐다 . 냄비 에 올리브 오일 을 두르 고 다진 양파 와 다진 마늘 을 볶 은 후 나머지 재료 를 넣 고 졸여 바비큐 소스 를 만든 다 . 파프리카 는 한 입 크기 로 썰 고 , 레몬 은 웨지 모양 으로 자른다 . 통마늘 은 반 으로 자르 고 , 껍질 콩 은 씻 는다 . 오븐 팬 에 소스 를 바른 베이비 립 , 손질 한 채소 를 넣 고 200 ℃ 로 예열 한 오븐 에 넣 는다 . ④ 를 15 분 정도 구운 뒤 5 분 정도 간격 으로 남 은 바비큐 소스 를 4 ~ 5 번 정도 덧바르 며 굽 는다 . 립 을 접시 에 담 고 구운 채소 와 파에야 나 볶음밥 을 곁들인다 . germany 슈 바인스 학세 는 우리 나라 족발 과 비슷 한 독일 의 돼지고기 요리 다 . 맥주 에 재운 돼지다리 를 구하 기 쉬운 통 삼겹살 이나 목살 로 대신 해 완성 했 다 . 기름기 가 빠져 맛 이 담백 하 고 건강 에 도 좋 다 . 통 삼겹살 800 g , 맥주 소스 ( 물 3 컵 , 맥주 5 컵 , 간장 · 올리고당 ⅓ 컵 씩 , 월계수 잎 4 장 , 통후추 1 큰 술 ) , 감자 1 개 , 통마늘 2 개 , 양배추 피클 약간 , 마늘 소스 ( 마요네즈 3 큰 술 , 레몬 즙 1 큰 술 , 올리고당 2 큰 술 , 소금 · 후춧가루 약간 씩 ) 통 삼겹살 은 찬물 에 2 시간 정도 담가 핏물 을 뺀 뒤 물기 를 닦 는다 . 냄비 에 맥주 소스 의 모든 재료 를 넣 고 우르르 끓인 뒤 통 삼겹살 을 넣 고 30 분 정도 삶 는다 . ② 를 150 ℃ 로 예열 한 오븐 에 넣 고 1 시간 30 분 정도 굽 는다 . 오븐 온도 를 200 ℃ 로 올린 뒤 웨지 모양 으로 자른 감자 와 통마늘 을 함께 넣 고 20 ~ 30 분 정도 겉 을 바삭 하 게 굽 는다 . ④ 의 통마늘 1 개 는 껍질 을 까 고 분량 의 마늘 소스 재료 와 함께 믹서 에 넣 고 간다 . ③ 의 고기 를 먹 기 좋 은 크기 로 자르 고 감자 와 나머지 껍질 벗긴 통마늘 , ⑤ 의 마늘 소스 를 곁들인다 . 기획 · 강현숙 기자 | 사진 · 홍 중식 기자 rex | 디자인 · 김수미 요리 · 김영빈 ( 수라 재 ) 요리 어시스트 · 이정화 김은선',\n",
       "       '[ 토요 판 ] 원본 보 기 ‘ 팔꿈치 로 슬쩍 찌르 다 ’ 는 뜻 ‘ 넛지 ’ 미 교수 책 출간 이후 세계 적 유행 강요 나 제약 않 고 도 행동 변화 유도 명령 · 지시 없이 개인 선택 에 영향 행동 경제학 에 관심 몰려 화장실 파리 스티커 가 대표 적 인 예 녹화 재 생기 디자인 적용 해 대 히트 공공 분야 활용 방안 모색 움직임 미 정부 , 신용카드 개선 에 적용 검토 오류 막 는 데 유용 하 게 쓰일 수 도 ▶ 정재승 카 이스트 ( kaist · 한국과학기술원 ) 바이오 및 뇌 공학 과 교수 . 카 이스트 물리 학과 에서 학부 를 졸업 하 고 박사 를 받 은 뒤 예일대 정신 과 연구원 , 컬럼비아 의 대 정신 과 조교수 등 을 거쳤 다 . < 정재승 의 과학콘서트 >, < 물리학자 는 영화 에서 과학 을 본다 >, < 크로스 >( 공저 ) 등 의 책 을 냈 다 . 신경 과학 적 인 관점 에서 인간 과 사회 의 행동 을 탐구 하 는 연구 를 해 오 고 있 다 . 이 연재물 은 영혼 을 조종 하 는 뇌 의 탐구 를 통해 자연 과학 과 공학 · 인문학 · 사회 과학 이 어떻게 만날 수 있 는가 를 모색 하 려는 시도 다 . 격주 연재 . [ 한겨레 ] 언젠가 미국 실리콘밸리 에서 한 벤처 회사 의 기술 개발 을 총괄 하 고 있 는 최고 기술 경영자 ( cto ) 한 분 을 식사 자리 에서 만난 적 이 있 다 . 그 는 자신 이 한국 의 가전 회사 에 근무 할 때 의 경험 을 샤브샤브 향기 에 실 어 우리 에게 들려 주 었 다 . 그 가 비디오 플레이어 개발 에 참여 하 고 있 던 시절 , 어떤 제품 이 가장 많이 팔리 는지 를 시장 조사 해 보 니 흥미 로운 사실 하나 를 발견 하 게 됐 다 . 가전제품 이 많이 팔리 는 데 에 는 좋 은 성능 이 중요 하 긴 하 지만 , ‘ 할인 마트 나 백화점 진열대 중 에서 어느 위치 에 놓이 느냐 ’ 가 무엇 보다 중요 한 요소 라는 걸 알 게 됐 다는 것 이 다 . 백화점 이나 할인 매장 에 는 다양 한 제품 을 쌓 아 놓 고 팔 다 보 니 , 비디오 플레이어 의 경우 에 도 여러 제품 들 을 포개 어 쌓 아 놓 을 경우 맨 위 에 올려진 제품 이 판매 될 가능 성 이 높 다는 것 이 다 . 생각 해 보 면 , 쌓여 있 는 물건 들 중 에서 맨 아래 제품 을 꺼내 는 수고 로움 을 우리 는 별로 좋 아 하 지 않 는다 . 진열대 에서 눈높이 가 중요 한 건 특별 하 지 도 않 다 . 문제 는 어떻게 해결 할 것 인가 다 . “ 저희 제품 을 맨 위 에 놓아주 세요 ” 라고 할인 마트 점원 에게 부탁 만 할 순 없 는 노릇 이 다 . 묘안 이 없 을까 ? 그래서 그 는 아이디어 를 냈 다고 한다 . 비디오 플레이어 의 위 커버 를 둥그렇 고 볼록 하 게 만들 어 그 위 에 다른 제품 을 올려놓 을 수 없 도록 만든 것 이 다 . 그러면 자신 들 의 제품 이 항상 맨 위 에 놓이 게 될 테 니까 . 그 결과 , 백화점 이나 할인 매장 에서 비디오 를 쌓 아 놓 고 팔 때 자신 들 의 제품 이 항상 맨 위 에 놓이 게 되 었 고 , 덕분 에 매출액 이 두 배 가까이 늘어났 다고 한다 . 성능 은 하나 도 바뀐 것 이 없 는데 말 이 다 . 이 처럼 ‘ 타인 의 선택 을 유도 하 는 부드러운 개입 ’ 을 행동 경제학 에서 는 ‘ 넛지 ’ 라고 부른다 . 이 개념 은 몇 해 전 행동 경제학 이 주목 받 으면서 대한 민국 을 강타 한 바 있 다 . 원래 ‘ 넛지 ’( nudge · 외래어 표기법 에 따르 면 ‘ 너지 ’) 는 ‘ 팔꿈치 로 슬쩍 찌르 다 ’ 라는 의미 였 다 . 그런데 미국 시카고 경영 대학원 의 행동 경제학자 리처드 탈러 와 하버드 로스쿨 의 캐스 선스 타인 교수 가 라는 저서 를 통해 사람 들 에게 어떤 선택 을 금지 하 거나 그 들 의 경제 적 인센티브 를 크 게 변화 시키 지 않 고 도 , 예상 가능 한 방향 으로 그 들 의 행동 을 변화 시키 는 ‘ 자유주의 적 개입 주의 ’ 를 ‘ 넛지 ’ 로 새롭 게 정의 하 고 그것 의 중요 성 을 역설 하 면서 화제 가 됐 다 . 넛지 를 설명 할 때 가장 많이 인용 되 는 예 는 네덜란드 암스테르담 에 있 는 스히폴 국제공항 의 남자 화장실 소변기 일 것 이 다 . 많이 들 들 어 보 셨 을 이곳 의 소변기 에 는 중앙 에 파리 모양 의 스티커 가 붙 어 있 다 . 그러면 남자 들 은 소변 을 볼 때 자연스레 소변기 중앙 에 있 는 파리 모양 스티커 를 맞히 려 노력 하 게 되 고 , 그 결과 소변기 밖 으로 튀 는 소변 의 양 이 파리 그림 을 붙이 기 이전 보다 80 % 나 줄어들 었 다는 것 이 그 설명 이 다 . ( 필자 도 스히폴 공항 에 갔 을 때 제일 먼저 화장실 에 들어가 그 유명 한 소변기 를 사진 찍 은 바 있 다 . 최근 스히폴 공항 의 소변기 에 는 파리 외 에 도 다양 한 동물 스티커 가 붙 어 있 다 . ) “ 한발 다가오 세요 ” 나 “ 아름다운 사람 은 머문 자리 도 아름답 습니다 ” 같 은 표어 를 붙이 거나 캠페인 을 벌이 는 것 보다 , 사람 의 심리 를 이용 해 적절 한 선택 을 유도 하 는 것 을 ‘ 넛지 ’ 라고 부르 는 것 이 다 . 남성 들 의 뇌 에 는 흔히 ‘ 사냥 꾼 의 회로 ’ 라 불리 는 뇌 영역 이 있 어서 , 이렇게 사냥감 을 보여 주 기 만 해도 뭔가 를 조준 해 맞히 려는 성향 이 있 다 . 이 처럼 넛지 의 효과 는 명령 이나 지시 를 내리 지 않 아도 사람 들 의 선택 에 영향 을 줄 수 있 다 . 소변기 에 파리 그림 을 붙이 는 것 은 ‘ 넛지 ’ 지만 , ‘ 파리 그림 을 맞히 시 오 ’ 라고 경구 를 써붙이 는 것 은 넛지 가 아니 라는 얘기 다 . 명령 이나 인센티브 를 이용 한 것 이 아니 라 , 사람 들 의 선택 에 부드럽 게 간섭 하 지만 여전히 개인 에게 선택 의 자유 가 열려 있 는 점 에서 ‘ 자유주의 적 간섭주의 ’ 라고 부른다 . 리처드 탈러 교수 등 은 인간 이 결코 합리 적 인 동물 이 아니 라는 데 에서 ‘ 넛지 의 필요 성 ’ 을 강조 한다 . 만약 인간 이 매우 합리 적 인 동물 이 라면 유용 한 정책 을 만들 고 가격 대 성능 비 가 우수 한 제품 을 만들 면 그 자체 로 선택 을 받 을 것 이 다 . 하지만 인간 은 결코 합리 적 인 동물 이 아니 므로 그 들 의 선택 을 도와 줄 장치 가 필요 하 다 . 게다가 그것 이 강압 적 이 거나 타인 에 의한 것 이 라는 인상 을 주 면 효과 를 제대로 발휘 하 지 못하 기 때문 에 , 넛지 처럼 부드럽 게 개입 하 는 개선책 이 필요 하 다고 설명 한다 . 예 를 들 어 선거일 바로 전날 에 투표 할 의향 이 있 는지 를 물 어 보 면 , 투표 율 이 무려 25 % 나 올라간다는 사실 을 알 게 됐 다 . 게다가 ‘ 이번 선거 는 예년 에 비해 투표 율 이 올라갈 것 으로 예상 됩니다 ’ 라는 뉴스 를 보여 주 는 것 만 으로 실제로 투표 율 이 크 게 올라간다는 연구 결과 도 있 다 . 이것 을 자동차 나 휴대 전화 등 의 특정 제품 에 대한 구매 의사 를 높이 는 데 어떻 게 사용 할 수 있 을까 ? 실제로 이 이슈 에 대해 연구 한 과학자 들 이 있 다 . 그 들 에 따르 면 , 전국 각지 에서 4 만 명 이상 의 사람 들 을 표본 으로 선정 하 여 조사 를 실시 한 결과 “ 향후 6 개월 안 에 새 차 를 구매 할 의사 가 있 습니까 ? ” 라는 간단 한 질문 만 으로 도 구매 율 을 35 % 나 높일 수 있 는 것 으로 밝혀졌 다 . 넛지 의 중요 성 은 아마도 공공 정책 분야 에서 가장 큰 효과 를 발휘 하 리라 예상 된다 . 글로벌 금융 위기 이후 , 미국 의 버락 오바마 대통령 이 넛지 에 관심 을 보이 면서 실제로 넛지 연구자 들 이 오바마 정부 에 합류 해 규제 정보국 에서 일 하 게 되 기 도 했 다 . 특정 한 정책 이나 방침 이 좀 더 나 은 결과 를 가져온다고 생각 되 면 , 민간 의 기업 이나 공공 부문 의 관리자 들 이 넛지 를 이용 해 선택 의 자유 를 존중 하 면서 도 현명 한 선택 을 이끌 어 낼 수 있 을 것 이 다 . 그러 니 최대한 비용 을 덜 들이 고 경제 적 인센티브 를 침해 하 지 않 는 범위 안 에서 어떻게 넛지 를 설계 할 것 인가 가 중요 하 다 . ‘ 넛지 ’ 를 가할 수 있 는 , 이른바 ‘ 선택 설계자 ’ 의 범위 를 공공 의 영역 으로 확대 하 는 것 이 각별히 중요 하 다 . 예 를 들 어 , 오바마 대통령 이 개혁 을 시도 하 고 있 는 신용카드 제도 에 도 넛지 를 적용 해 볼 수 있 다 . 리처드 탈러 교수 는 신용카드 회사 들 이 매년 인쇄물 과 온라인 을 통해 ‘ 1 년 동안 발생 한 모든 요금 ’ 을 항목 별 로 정리 해 합산 한 명세서 를 발송 하 도록 규정 하 는 제도 를 제안 했 다 . 신용 카드 사용 자 들 이 카드 를 쓰 면서 물어야 하 는 비용 을 정확히 알 게 되 면 , 결과 적 으로 나중 에 크 게 손해 보 는 일 이 줄어들 수 있 다는 것 이 다 . “ 내 가 통신 요금 이 이렇게 많 았 어 ? ” 라고 깨달 으면 , 무분별 한 소비 를 줄일 수 있 을 것 이 다 . 세심 한 장치 하나 가 구매 나 사용법 같 은 중요 한 의사 결정 에 크 게 영향 을 미칠 수 있 다는 얘기 다 . “ 죄송 합니다 . 파일 을 첨부 하 는 것 을 깜빡 잊 었 네요 . 다시 보내 드립니다 . ” 이메일 을 사용 하 는 현대인 이 라면 누구 나 한 번 쯤 보냈 을 법 한 메시지 다 . 이 처럼 이메일 에 는 파일 을 첨부 해 보내 주 겠 다고 써 놓 고 , 깜빡 잊 고 그냥 보내 는 경우 들 이 종종 있 다 . 만약 구글 이나 야후 , 한 메일 같 은 이메일 서비스 회사 에서 본문 내용 중 에 ‘ 파일 첨부 ’ 라는 단어 가 들어가 있 는데 파일 을 첨부 하 지 않 은 경우 에 “ 혹시 첨부 해야 할 파일 은 없 습니까 ? ” 라고 메시지 로 알려 주 면 어떨까 ? 이 처럼 넛지 의 가장 매력 적 인 응용 은 디자인 분야 가 아닐까 싶 다 . 이메일 이 아니 더라도 , 인간 들 은 실수 를 저지르 기 마련 이 다 . 그것 도 아주 자주 . ‘ 실수 하 는 동물 ’ 인간 을 위해 , 사용 자 들 이 오류 를 범할 것 을 예상 하 고 제품 이나 서비스 가 알 아서 최대한 ‘ 기술 적 배려 ’ 를 해준다면 얼마나 편리 할까 ? 아마도 미래 는 고객 의 실수 를 예상 하 고 ( 이런 것 을 ‘ 오류 예상 ’ 이라고 부른다 ) , 실수 를 줄여 주 는 스마트 제품 들 이 세상 을 독차지 하 게 될 것 이 다 . 오류 를 예상 하 고 방지 하 는 디자인 이 특별히 새로운 것 은 아니 다 . 예 를 들 어 , 안전벨트 를 착용 하 지 않 으면 경고 음 을 울려 준다거나 , 연료 가 떨어지 면 ‘ 경고 표시 ’( warning sign ) 가 뜬다 거나 하 는 경우 도 여기 에 해당 된다 . 요즘 많 은 자동차 회사 들 은 사고 방지 를 위해 주행 중 에 는 ‘ 내비게이션 시스템 ’ 에 입력 을 할 수 없 게 해 놓 았 다 . 헤드라이트 가 주행 중 에 는 켜 지 고 주행 이 멈추 면 꺼지 도록 자동 스위치 가 장착 된 차 들 도 있 어서 , 밤새 헤드라이트 를 켜 둠 으로써 배터리 가 방전 되 는 낭패 를 없앤 신 형 차 들 도 많 다 . 엔진오일 교환 시기 를 알려 주 는 자동차 는 이제 다 반사 가 되 었 다 . 연료 공급 노즐 의 차별 화 도 ‘ 오류 방지 디자인 ’ 의 한 예 로 볼 수 있 다 . 디젤 연료 를 공급 하 는 노즐 은 너무 커서 휘발유 를 사용 하 는 자동차 의 주입구 에 는 맞 지 않 기 때문 에 휘발유 자동차 에 디젤 연료 를 넣 는 실수 를 저지르 지 않 도록 도와 준다 . 하지만 오류 방지 디자인 을 채택 하 는 속도 는 놀랍 도록 느리 다 . 예 를 들 어 , 아직 도 주 유구 뚜껑 이 자동차 차체 와 연결 돼 있 지 않 은 차 들 이 많이 있 다 . 주 유구 뚜껑 에 그것 과 차체 를 연결 하 는 플라스틱 이나 철 재질 의 끈 이 부착 돼 있 어서 주유 를 끝낸 뒤 뚜껑 을 놔두 고 그냥 가 는 일 이 없 도록 하 는 것 은 누구 나 쉽 게 생각 할 수 있 는 아이디어 지만 , 아직 도 1000 원 도 채 하 지 않 는 이 플라스틱 끈 을 달 지 않 은 차 들 이 많 다는 것 은 이해 할 수 없 는 일 이 다 . 그런데 사람 들 은 왜 이런 실수 를 저지르 는 걸까 ? 심리학자 들 은 이 를 ‘ 완성 후 오류 ’( postcompletion fallacy ) 라고 부른다 . 주 유구 뚜껑 을 잊어버리 고 가 는 것 은 ‘ 완성 후 오류 ’ 에 해당 되 는 전형 적 인 실수 인데 , 사람 들 은 주요 임무 를 끝내 고 나 면 그 이전 단계 들 에 관련 된 사항 들 을 잊 는 경향 이 있 다는 것 이 다 . 완성 후 오류 의 가장 흔한 예 는 현금 자동 인출 기 ( atm ) 에서 현금 을 인출 한 후 에 카드 를 그대로 꽂 아 두 고 가 거나 , 복사 를 끝마친 후 에 복사기 에 원본 을 남겨 두 는 경우 일 것 이 다 . ( the design of everyday things , 1990 ) 의 저자 돈 노먼 에 따르 면 , ‘ 기능 강제 ’( forcing function ) 방식 을 활용 하 면 이런 실수 가 발생 하 지 않 도록 배려 할 수 있 다 . ‘ 기능 강제 ’ 란 원 하 는 것 을 얻 기 위해 먼저 다른 무언가 를 하 게 만드 는 것 을 말 하 는데 , 이미 많 은 제품 들 이 이런 기능 을 활용 하 고 있 다 . 그래서 최근 에 개발 된 현금 자동 인출 기 는 카드 를 삽입 하 고 비밀 번호 를 입력 하 면 카드 를 즉시 돌려줌 으로써 카드 를 놓 고 가 는 실수 를 막 아 주 고 있 다 . 카드 를 먼저 뽑 아야 만 현금 을 인출 할 수 있 다면 , 카드 를 잊 고 가 는 일 이 없 게 된다 . 가장 유능 한 디자이너 는 그것 을 사용 하 는 사람 의 마음 을 읽 는 설계자 이 다 . 인간 이 언제 실수 하 고 제품 을 보 면 어떻게 사용 하 려고 하 는지 이해 해야 만 , 직관 적 으로 쉽 게 사용 하 는 제품 을 디자인 할 수 있 다 . 사용 설명서 가 없 는 제품 일수록 이런 노력 이 더욱 필요 하 다 . 사용자 를 배려 하 는 ‘ 오류 방지 디자인 ’ 을 근사 하 게 만들 기 위해서 는 사용 자 의 오류 를 예상 하 는 실험 이 필수 적 이 다 . 실험 공간 에 제품 을 갖 다 놓 고 , 사용 자 들 이 어떻게 사용 하 는지 를 몰래카메라 를 이용 해 행동 관찰 을 해야 만 정확히 ‘ 오류 예상 ’ 을 할 수 있 다 . 디자이너 가 인지 신경 과학 을 이해 한다면 , 고객 의 작 은 실수 까지 도 놓치 지 않 고 배려 하 려는 최고 의 디자인 을 제공 해 줄 수 있 을 것 이 다 . 정재승 교수 공식 sns [ 페이스북 ] [ 핫 이 슈 ] copyrights ⓒ 한겨레 신문사 , 무단 전재 및 재 배포 금지',\n",
       "       '원본 보 기 ‘ 단 하나 의 알약 ’ 이 었 다 . 비앙카 포겔 ( 55 ) 의 인생 을 뒤바꾼 것 은 탈리도마이드 라는 성분 이 들 어 있 는 콘 테르 간 알약 한 개 였 다 . 1960 년 임신 3 개월 차인 포겔 의 어머니 가 이 약 을 먹 은 뒤 포겔 은 남 들 보다 짧 은 팔 로 태어났 다 . 손 이 어깨 에 달린 아기 를 보 고 사람 들 은 “ 당장 버리 라 ” 고 했 다 . 당시 만 해도 포겔 이 기형아 로 태어난 이유 가 약 에 들 어 있 는 화학 물질 때문 인지 몰랐 고 약 을 판매 한 그 뤼넨 탈 회사 도 , 독일 정부 도 사고 를 인정 하 지 않 았 다 . 그러나 이젠 안다 . 포겔 은 “ 나 는 화학 물질 의 부산물 ” 이 라고 했 다 . 지난 24 일 오전 ( 현지 시간 ) 독일 라인란트팔츠주 의 작 은 도시 진 치히 에서 만난 탈리도마이드 피해자 포겔 은 자신 의 삶 에 대해 이야기 하 면서 계속 울먹거리 며 말 을 잇 지 못했 다 . 팔 이 없 기에 컵 과 그릇 을 입술 로 물 어서 옮기 고 , 발 로 자동차 운전 을 하 는 그 는 이젠 그런 방식 이 익숙 해졌 다 . 하지만 그렇게 하 기 까지 의 과정 은 자신 에게 ‘ 트라우마 ’ 라고 했 다 . “ 생긴 대로 살아남 기 위해 엄청난 노력 이 필요 했 다 ” 는 것 이 다 . 포겔 의 어머니 는 입덧 이 심해 콘 테르 간 약 을 먹 었 다 . 당시 광고 에선 “ 1000 알 을 먹 어도 죽 지 않 는 수면제 의 혁명 ” 이 라고 했 다 . 인체 에 아무런 해 가 없 다고 했 기 때문 에 임신부 가 입덧 을 한다고 하 면 의사 들 도 정확 한 처방 없이 이 약 을 권했 다 . 아이 들 이 먹 을 수 있 도록 음료 형태 로 도 팔렸 다 . 약 의 복 용법 이 어떻게 되 는지 제대로 알려 지 지 않 았 다 . “ 꿀 바른 사탕 처럼 팔렸 다 ” 고 포겔 은 당시 를 설명 했 다 . 역시 탈리도마이드 피해자 인 비어 깃 슬 뢰서 ( 55 ) 의 아버지 는 죽 을 때 까지 죄책감 에서 벗어나 지 못했 다 . 슬 뢰서 의 어머니 가 심한 입덧 으로 힘들 어 하 자 그 의 아버지 는 보다 못 해 당시 다섯 살 인 슬 뢰서 의 언니 가 먹 던 음료 형 콘 테르 간 약 을 어머니 에게 줬 다 . 어머니 는 처음 엔 “ 안 먹 겠 다 ” 고 했 지만 아버지 의 설득 으로 약 을 먹 었 다 . ‘ 반 스푼 ’ 이 었 다 . 슬 뢰서 의 아버지 는 딸 이 기형아 로 태어난 게 자신 이 권한 약 때문 이 라는 사실 을 안 뒤 벽 에 머리 를 박 았 다 . 1961 년 11 월 27 일 독일 신문사 디 벨트 가 처음 약 에 문제 가 있 다고 보도 하 면서 사건 이 알려졌 다 . 며칠 뒤 독일 정부 는 약 판매 를 금지 했 다 . “ 1 년 만 더 일찍 판매 금지 처분 이 내려졌 다면 우리 는 이렇게 태어나 지 않 았 을 거 예요 . ” 포겔 은 한숨 을 쉬 었 다 . 1957 년 처음 판매 되 기 시작 한 콘 테르 간 은 판매 직후 부작용 에 대한 문제점 이 지적 됐 지만 독일 정부 는 빠르 게 조치 하 지 못했 다 . 슬 뢰서 는 “ 처음 엔 피해자 수 가 적 었 기 때문 에 정부 가 의혹 을 무시 하 고 조사 를 제대로 하 지 않 았 다 ” 며 “ 조금 이 라도 더 빨리 금지 처분 을 했 으면 피해자 수 를 줄일 수 있 었 을 텐데 그게 늦 어 져 최종 적 으로 금지 처분 을 했 음 에 도 불구 하 고 엄청나 게 많 은 피해자 가 발생 한 것 ” 이 라고 했 다 . 포겔 은 “ 거대 한 화학 산업 계 의 로비 력 이 강하 고 , 정부 는 기업 을 도와 줬 기 때문 에 약 에 대한 정보 가 수면 아래 로 숨 고 올라오 지 않 았 던 것 ” 이 라고 지적 했 다 . 화학 물질 관리 제도 의 문제 도 있 었 다 . 당시 소련 의 위성국 이 던 동독 에서 는 콘 테르 간 판매 가 허가 되 지 않 았 다 . 허술 한 심사 과정 을 거쳐 허가 를 받 은 서독 에서 만 1 만 명 에 가까운 피해자 가 나왔 다 . 미국 에서 는 프랜시스 올덤 켈시 라는 공무원 이 이 약 허가 를 검토 하 면서 ‘ 사람 에게 는 수면제 효과 를 내 고 동물 실험 에서 는 효과 가 나타나 지 않 았 다 ’ 는 허가 제출 자료 를 이상 하 게 여기 고 허가 를 내주 지 않 아 피해자 가 17 명 에 그쳤 다 . 켈시 는 미국 을 구한 영웅 으로 떠올라 1962 년 존 f 케네디 대통령 으로부터 표창 을 받 았 다 . 그럼에도 독일 정부 와 그 뤼넨 탈 회사 는 아직 까지 콘 테르 간 과 기형아 출산 에 대한 잘못 을 인정 하 지 않 고 있 다 . 검찰 이 그 뤼넨 탈사 를 수사 해서 기소 하 고 , 피해자 부모 들 이 그 뤼넨 탈 을 상대 로 소송 했 지만 유명 변호사 들 을 선임 해 대응 한 그 뤼넨 탈 에 법원 은 무죄 를 선고 했 다 . 태아 에 미치 는 영향 을 제약 회사 가 반드시 검증 토록 하 지 못한 법 의 맹점 이 있 었 기 때문 이 다 . 무죄 판결 이 났 지만 그 뤼넨 탈사 와 정부 는 100 만 마르크 씩 총 200 만 마르크 를 피해자 들 을 위한 지원 기금 으로 냈 다 . 20 년 치 연금 을 지급 하 고 이후 는 정부 가 부담 하 기 로 했 다 . 소송 에서 진 피해자 부모 들 은 이 방 안 에 합의 했 고 , 이후 더 이상 그 뤼넨 탈 에 법 적 인 책임 을 묻 기 어려웠 다 . 인터넷 이 없 어 정보 도 제대로 알 수 없 고 기형아 출산 의 책임 을 부모 에게 떠넘기 는 사회 적 분위기 속 에서 어쩔 수 없 는 결론 이 었 다 . 2012 년 그 뤼넨 탈사 가 피해자 들 과 적극 적 으로 소통 하 지 않 은 부분 에 대해 사과 한 것 이 전부 다 . 포겔 과 슬 뢰서 는 “ 아직 도 정부 와 그 뤼넨 탈 이 사고 를 인정 하 고 사과 하 기 를 기다리 고 있 다 ” 고 했 다 . 피해자 들 의 고통 은 끝 나 지 않 았 다 . 슬 뢰서 가 말 했 다 . “ 저 한테 는 매일 생활 하 는 것 자체 가 문제 를 안 고 사 는 거 예요 . 시장 에 만 가 도 사람 들 과 부딪치 는 게 무섭 고 , 제 가 계산대 앞 에 서 면 사람 들 은 불쌍 한 눈빛 으로 제 물건 을 대신 계산대 에 올려 주 죠 . 높 은 데 있 는 건 남편 이 다 집 어 줘야 하 고요 . 문제 는 절대 끝난 게 아니 죠 . ” 시청 에서 공무원 으로 일 했 던 슬 뢰서 는 어깨 가 아파 일 을 그만뒀 다 . 포겔 도 몸 이 좋 지 않 아 유치원 교사 일 을 그만둘 계획 이 다 . 포겔 은 “ 내 가 좋 아 하 는 승마 도 계속 하 고 싶 지만 몸 이 아파서 할 수 가 없 다 . 나 는 아직 도 울 고 있 다 ” 고 말 했 다 . 2013 년 8 월 에 야 이 들 이 받 는 연금 액수 도 실질 적 으로 생활 에 도움 되 는 수준 으로 올랐 다 . 그 전 까지 는 팔다리 가 모두 없 고 , 장기 도 손상 돼 거의 자발 적 인 생활 을 할 수 없 는 ‘ 장애 정도 심각 ’ 단계 피해자 가 한 달 에 545 유로 ( 약 68 만 원 ) 정도 를 받 았 고 , 2013 년 이후 7000 유로 ( 약 873 만 원 ) 로 높 아 졌 다 . 치료비 등 이 반영 됐 기 때문 이 다 . 포겔 은 “ 피해자 한 사람 한 사람 이 콘 테르 간 때문 에 장애 를 가지 고 살아갈 수 밖에 없 는 사연 을 적 어서 정부 에 제출 하 고 정치인 들 에게 도 요구 했 다 ” 며 “ 이후 정부 가 탈리도마이드 피해자 들 의 삶 에 대한 연구 를 시작 했 다 ” 고 말 했 다 . 그 결과 정부 와 의회 는 한 달 545 유로 로 는 살 수 없 다는 결론 을 내 고 콘 테르 간 피해자 지원 법 을 개정 해 연금 액수 를 높였 다고 했 다 . 현재 이 연금 을 받 고 있 는 피해자 는 2400 명 정도 다 . 독일 에선 가습기 살균제 사태 를 일컬 어 ‘ 한 국판 탈리도마이드 사건 ’ 이 라고 한다 . 포겔 은 한국 사람 들 에게 전하 고 싶 다고 했 다 . “ 기업 은 제품 을 팔 려고 만 하 고 , 정부 는 제대로 관리 하 지 않 고 … . 탈리도마이드 사건 과 가습기 살균제 사태 는 비슷 한 점 이 많 아요 . 그래도 탈리도마이드 사건 이후 독일 이 바뀐 점 은 있 습니다 . 약 의 허가 를 매우 복잡 하 게 하 도록 하 고 , 처방전 이 있 어야 만 약 을 줄 수 있 고 , 복용 법 을 약품 에 기재 해 주 도록 제도 적 개선 을 했 죠 . 지속 적 으로 항의 해서 연금 액수 도 올렸 고요 . 절대 포기 해서 는 안 됩니다 . 갈 길 이 멀 어요 . ”▶ 경향신문 sns [ 트위터 ] © 경향신문 ( [ URL ] ) , 무단 전재 및 재 배포 금지',\n",
       "       \"외부 의 자극 없이 생각 이 흘러가 는 대로 멍하니 있 는 상태 . 요즘 말 로 ' 멍 때린다 ' 고 하 죠 . 그런데 이렇게 멍 하 게 있 을 때 , 기억력 과 창의력 이 더 좋 아 진다는 연구 결과 가 나왔 습니다 . 특정 뇌 부위 들 이 더욱 활성 화 된다는 겁니다 . 조동찬 의학 전문 기자 입니다 . 직장 인 남녀 에게 각각 스마트폰 과 노트북 을 주 고 생소 한 용어 들 을 15 분 동안 검색 하 게 했 습니다 . 곧바로 30 개 단어 가 적힌 종이 를 주 고 1 분 동안 외우 게 한 뒤 얼마나 외웠 는지 적 게 했 습니다 . 이번 엔 스마트폰 과 노트북 을 거두 고 아무 생각 하 지 말 고 이른바 멍 때리 도록 부탁 했 습니다 . 마찬가지 방법 으로 곧바로 기억력 을 측정 해 봤 습니다 . 이때 적 어 낸 단어 의 수 가 심각 한 생각 을 하 고 난 뒤 보다 남녀 모두 4 개 씩 많 았 습니다 . [ 김선민 / 27 세 , 실험 참가자 : 좀 쉬 고 난 다음 에 는 약간 머리 가 비워진 느낌 이 들 어서 첫 번 째 보다 는 조금 더 집중 할 수 있 었 습니다 . ] [ 최진욱 / 27 세 , 실험 참가자 : 멍 때리 라고 하 는 것 보다 스마트 폰 을 할 수 있 게 해 줬 으면 차라리 더 마음 이 편하 지 않 았 을까 . ] 실제로 외국 연구 에서 멍 때리 고 난 후 에 기억력 이 1 . 5 배 정도 높 아 지 는 것 으로 나타났 습니다 . 뇌 에서 기억력 과 판단력 , 창의력 을 담당 하 는 부분 의 독특 한 시스템 과 관련 이 있 습니다 . 집중력 을 발휘 할 때 꺼져 있 다가 멍 때릴 때 켜 지 는 것 으로 밝혀졌 습니다 . 최근 국내 연구 에서 는 치매 환자 에게서 이 특정 뇌 부위 의 활성도 가 떨어져 있 는 것 으로 나타났 습니다 . [ 김정훈 / 연세 의 대 생리학 과 교수 : 수많 은 정보 가운데 나 에게 유익 하 고 도움 이 되 고 내 가 꼭 간직 하 고 싶 은 것 들 이 있 잖아요 . ( 이 특정 뇌 부위 는 ) 그런 것 들 을 선별 하 고 분리 하 고 저장 하 는 그런 기능 을 담당 합니다 . ] 멍 때리 는 것 만 으로 도 정신 의 이완 운동 이 될 수 있 다는 얘기 인데 , 이때 중요 한 건 스마트 폰 이나 컴퓨터 같 은 외부 자극 을 차단 하 는 겁니다 . ( 영상 취재 : 이용한 , 영상 편집 : 박춘배 ) 조동찬 기자 ( dongcharn @ sbs . co . kr ) ☞ 4 · 13 국민 의 선택 … 총선 최신 뉴스 보 기 ※ ⓒ sbs & sbs 콘텐츠 허브 : 무단 복제 및 재 배포 금지\",\n",
       "       '원본 보 기 원본 보 기 원본 보 기 휴면 계좌 , 이른바 비 활동 성 계좌 가 1 억 개 에 달 합니다 . 비 활동 성 계좌 란 1 년 이상 거래 가 없 는 계좌 를 말 합니다 . 그리고 그 안 에 는 14 조 4 천억 원 이 들 어 있 습니다 . 예전 에 통장 만들 어 놓 고 그 안 에 돈 이 있 다는 사실 을 잊어버린 분 이 생각 보다 많 은 겁니다 . \" 나 도 혹시 휴면 계좌 있 나 ? \"\" 예전 에 쓰 던 통장 에 돈 이 남 아 있 나 ? \" 이런 분 들 을 위해 금융 위원회 가 인터넷 으로 휴면 계좌 를 확인 한 뒤 바로 잔고 를 옮길 수 있 는 계좌 통합 관리 서비스 를 내놨 습니다 . 예전 에 는 휴면 계좌 에 남 아 있 는 돈 을 찾 기 위해서 는 직접 은행 까지 찾아가 야 했 는데 , 이제 그럴 필요 가 없 어 진 겁니다 . 단계 별 시행 이 라 아직 모바일 은 안 되 고 액수 제한 도 있 지만 , 소비자 입장 에서 는 확실히 편리 한 서비스 입니다 . 혹시 휴면 계좌 를 찾 다 보 면 예전 기억 이 떠오르 는 아주 오래 된 \\' 옛 통장 \\' 을 만날 수 도 있 습니다 . 현존 하 는 모든 통장 을 볼 수 있 기 때문 입니다 . 금융 위원회 는 \" 수기 로 만든 아주 오래 된 통장 이 라도 은행 이 기록 만 가지 고 있 다면 그 기록 을 볼 수 있 다 \" 고 설명 합니다 . 1960 년 대 , 1970 년 대 에 만든 통장 도 이론 적 으로 는 존재 할 수 있 는 겁니다 . 특히 이 서비스 를 이용 하 면 몇 년 도 에 어느 은행 지점 에서 만들 었 는지 도 볼 수 있 습니다 . 어쩌면 어릴 적 부모 님 과 만든 통장 을 만날 수 도 있 는 겁니다 . 이 질문 을 가장 많이 받 았 습니다 . 금융 위원회 가 계좌 정보 통합 관리 서비스 홈페이지 를 만들 었 습니다 . 포탈 사이트 에서 계좌 정보 통합 관리 서비스 라고 치 거나 , \\' 어 카운트 인포 \\' 라고 쳐도 바로 찾 으실 수 있 습니다 . 주소 는 [ URL ] 홈페이지 에 들어가 면 먼저 약관 동의 를 하 고 , 본인 인증 을 2 번 합니다 . 돈 을 옮기 는 기능 이 있 기 때문 에 본인 인증 이 중요 하 겠 죠 . 공인 인 증서 1 번 , 휴대 전화 인증 1 번 , 이렇게 2 번 을 해야 합니다 . 그러면 바로 계좌 내역 조회 페이지 로 들어갈 수 있 습니다 . 이렇게 본인 인증 을 하 기 때문 에 계좌 비밀 번호 입력 없이 조회 와 이체 가 가능 합니다 . 아침 9 시 부터 밤 10 시 까지 주중 , 주말 관계없이 내 계좌 조회 를 할 수 있 습니다 . 그런데 , 돈 을 옮기 는 건 다릅니다 . 아침 9 시 부터 오후 5 시 까지 만 가능 하 고 , 은행 영업 일 에 만 할 수 있 습니다 . 16 개 국내 은행 에 개설 한 모든 예금 과 신탁 계좌 를 대상 으로 하 다 보 니까 시간 을 24 시간 하 는 것 은 쉽 지 않 았 던 모양 입니다 . 은행 에서 돈 을 옮길 때 는 수수료 가 발생 하 는 게 원칙 입니다 . 예 를 들 어 a 은행 의 휴면 계좌 에 남 아 있 던 5 만 원 을 b 은행 의 월급 통장 으로 옮긴다면 , a 은행 에 수수료 를 줘야 합니다 . 하지만 정부 는 휴면 계좌 정리 를 장려 한다는 차원 에서 내년 말 , 그러니까 2017 년 12 월 31 일 까지 수수료 를 면제 해 주 기 로 했 습니다 . 의외로 이런 질문 을 많이 받 았 습니다 . 비밀 계좌 . 은행 홈페이지 로 들어가 서 개인 인증 을 해도 노출 이 되 지 않 는 계좌 를 말 합니다 . 드물 겠 지만 보통 남편 이나 부인 이 공인 인 증서 넘겨 받 아서 은행 홈페이지 에 접속 해도 못 보 게 하 려는 의도 로 쓰이 기 도 합니다 . 부인 몰래 , 남편 몰래 관리 하 는 비자금 계좌 로 쓰 시 는 분 들 이 제법 있 는 모양 입니다 . 분명히 존재 하 지만 레이더 에 는 잡히 지 않 는다고 해서 \\' 스텔스 계좌 \\', 혹은 \\' 보안 계좌 \\' 라고 불립니다 . 금융 위원회 는 보안 계좌 는 계좌 정보 통합 관리 서비스 에서 노출 되 지 않 는다고 밝혔 습니다 . a 은행 관계자 도 \" 보안 계좌 는 말 그대로 보안 계좌 다 . 본인 이 직접 창구 를 찾아가 서 자신 임 을 인증 해야 거래 를 할 수 있 다는 점 은 변함없 다 \" 라고 강조 했 습니다 . 이런 계좌 있 는 줄 도 모르 는 분 들 이 더 많 을 텐데요 . 안도 의 한숨 을 내쉬 는 분과 아쉬움 의 탄성 을 내 시 는 분 , 어느 쪽 이 더 많 을까요 ? 계좌 조회 를 하 면 은행 별 로 자신 의 계좌 가 모두 펼쳐집니다 . 예 를 들 어 \\' a 은행 , 비 활동 성 계좌 2 건 \\' 활동 성 계좌 3 건 , \\' b 은행 활동 성 계좌 1 건 \\' 처럼 은행 별 로 볼 수 있 습니다 . 상세 조회 를 하 면 자신 이 어느 은행 에서 , 몇 년 도 에 , 어느 동네 무슨 지점 에서 통장 을 만들 었 는지 도 알 수 있 습니다 . 그러 다 보 니 옛날 통장 도 만날 수 있 습니다 . 금융 위원회 는 \" 개설 연도 불문 \" 이라고 합니다 . \" 그 때 내 가 뭐 했 지 ? \" \" 누구 랑 갔었 지 \" \" 이 통장 을 왜 만들 었 더라 \" 라면서 회상 에 잠길 만 한 아주 오래 된 , 혹은 아주 어릴 때 만든 통장 을 만나 실 수 도 있 습니다 . 이 밖 에 도 알 아 두 셔야 할 정보 는 몇 가지 더 있 습니다 . 정부 가 내놓 은 이번 서비스 는 기본 적 으로 휴면 계좌 를 줄여 보 자는 목적 이 강 합니다 . 은행 은 계좌 관리 비용 을 줄일 수 있 고 , 정부 는 휴면 계좌 가 보이스 피싱 같 은 범죄 에 쓰이 는 대포통장 으로 악용 될 가능 성 을 줄여 보 자는 겁니다 . 그러 다 보 니 잔금 을 남기 고 이체 하 는 건 안 됩니다 . 24 만 원 이 들 어 있 으면 24 만 원 을 다 옮기 는 겁니다 . 그리고 그 계좌 는 해지 가 됩니다 . 액수 도 일단 30 만 원 으로 제한 했 습니다 . 내년 4 월 부터 는 50 만 원 이하 계좌 까지 확대 될 예정 입니다 . 이 서비스 가 9 일 오전 9 시 에 시작 됐 습니다 . 시작 하 자마자 접속자 가 몰려 30 분 정도 기다리 신 분 도 계시 고 , 은행 1 ~ 2 곳 과 의 연결 이 안 되 기 도 했 습니다 . \\' 뒤 로 가 기 \\' 를 누르 면 접속 이 끊 어 진다는 불만 도 나왔 습니다 . 하지만 일단 로그인 된 뒤 에 는 아무 문제 없이 진행 이 되 고 있 습니다 . 조만간 접속 에 더 여유 가 생기 고 , 다른 연결 문제 도 해결 될 것 으로 보입니다 . 그런데 이렇게 해서 기대 하 지 않 았 던 수입 이 생기 면 그 돈 으로 뭘 하 시 겠 습니까 . 연말 입니다 . 또 이번 서비스 에 는 휴면 계좌 에서 찾 은 돈 을 서민 금융 진 흥원 에 기부 할 수 있 는 버튼 이 있 습니다 . 이 방법 으로 기부 를 하 면 자동 으로 국세청 연말 정산 간소 화 서비스 에 등록 이 돼 연말 정산 도 받 을 수 있 습니다 . 손 승욱 기자 ( ssw @ sbs . co . kr ) ※ ⓒ sbs & sbs 콘텐츠 허브 : 무단 복제 및 재 배포 금지 ☞ [ 최순 실 국정 농단 청문회 ] 기사 모아 보 기',\n",
       "       \"1999 년 창립 한 여성환경연대 는 에코 페미니즘 의 관점 에서 모든 생명 이 더불 어 평화 롭 게 사 는 녹색 사회 를 만들 기 위해 생태 적 대안 을 찾 아 실천 하 는 환경 단체 입니다 . 환경 파괴 가 여성 의 몸 과 삶 에 미치 는 영향 에 주목 하 여 여성 건강 운동 , 대안 생활 운동 , 교육 운동 , 풀뿌리 운동 등 을 해 오 고 있 습니다 . 이 기자 의 최신 기사 정은경 호소에 도 길 을 떠난다면 이 ' 두 가지 ' 먼저 챙기 세요\",\n",
       "       '9 월 그랑 조 미션 \" 만료 저작물 \" 포스팅 더 보 기 만료 저작물 포스팅 더 보 기 접 기 01 만료 저작물 관련 법 조항 살펴보 기 [ URL ] 02 국내 만료 저작물 [ URL ] 04 저작 권 아카데미 ( 1 ) [ URL ] 05 저작 권 아카데미 ( 2 ) [ URL ] 접 기 이번 포스팅 은 저작 권 걱정 없이 이용 하 기 프로젝트 3 번 째 , 해외 만료 저작물 소개 편 이 다 . 앞서 1 편 과 2 편 에서 는 만료 저작물 법조 항 설명 과 국내 만료 저작물 을 소개 했었 다 . 이번 포스팅 에서 해외 만료 저작물 은 무엇 인지 , 어떻게 이용 해야 하 는지 알아보 자 . 어느덧 우리 사회 는 타인 의 지적 창작물 을 존중 하 고 보호 하 는 사회 분위기 가 조성 되 어 가 고 있 다 . 하 지만 지난 4 년 간 저작 권 침해 로 고소 된 사람 만 25 만 명 에 이른다 . 누차 얘기 했었 지만 모든 저작물 은 창작 과 동시 에 저작 권 이 생겨난다 . 그래서 모든 저작물 은 사전 에 저작 권 자 의 허락 을 얻 어야 이용 할 수 있 다 . 이용자 는 당연히 저작 권 자 를 찾 아야 겠지만 , 찾 는 방법 도 어렵 고 과정 이 복잡 하 다고 느껴져 새로운 2 차 창작물 을 생산 하 기 도 전 에 머리 가 깨진다 . 그렇 다면 저작 권 문제 없이 창작 소재 를 확보 ㆍ활용하기 위해 우리 는 어떤 노력 을 해야 할까 . 앞서 항상 소개 해 온 ccl 표시 가 있 는 저작물 을 활용 하 는 것 도 방법 이 지만 , 보호 기간 이 끝 나 저작 권 이 소멸 된 \\' 만료 저작물 \\' 을 활용 하 는 방법 도 있 다 . 만료 저작물 이란 , 저작 자 의 저작 재산 권 보호 기간 이 만료 된 저작물 로 저작 자 가 사망 후 ( 법 으로 정해진 ) 일정 기간 이 지난 저작물 을 말 한다 . 저작 재산 권 이 만료 된 저작물 은 누구 나 별도 의 이용 허락 이나 승인 절차 없이 자유 롭 게 이용 가능 하 다 . 그렇 다면 여기 서 말 하 는 저작 재산 권 보호 기간 은 무엇 일까 ? 현재 , 우리 나라 저작권법 제 39 조 에 따르 면 저작 재산 권 보호 기간 이 란 저작 권 발생 시점 부터 저작 자 의 사망 후 저작 자 는 물론 저작 권 을 승계 . 상속 할 수 있 는 권리 가 보호 되 는 기간 을 의미 하 며 , 저작물 의 종류 에 따라 세계 각 국 저작권법 에 따라 보호기 간 의 기준 은 다르 다 . 클릭 한 번 으로 전 세계인 과 만날 수 있 는 현 시대 에서 , 누구 나 전 세계 의 만료 저작물 을 사용 할 수 있 다 . 그렇 다면 , 만료 저작물 을 사용 하 기 에 앞서 세계 각 국 의 저작 재산 권 보호 기간 을 알아보 자 . 지난 한 - eu fta 체결 이후 , 우리 나라 저작권법 에서 저작 재산 권 은 「 저작권법 」 제 39 조 부터 제 44 조 까지 에 특별 한 규정 이 있 는 경우 를 제외 하 고 는 저작 자 의 생존 하 는 동안 과 사망 후 70 년 간 존속 한다고 규정 하 고 있 다 . 다른 나라 들 은 어떠 할까 ? 문자 적 및 미술 적 저작물 의 보호 에 관한 베른 조약 에 는 7 조 에서 체약국 에서 최저 한 사후 또는 공표 후 50 년 간 보호 를 의무 로 하 고 있 어 , 대부분 의 나라 들 의 저작권법 에서 저작 재산 권 의 보호 기간 을 저작 자 의 생존 기간 과 사후 50 년 까지 , 혹은 70 년 까지 를 원칙 으로 하 고 있 다 . 저작 재산 권 의 보호 기간 저작 자 의 생존 기간 과 사후 50 년 까지 저작 자 의 생존 기간 과 사후 70 년 까지 아제르바이잔 , uae , 알제리 , 아르메니아 , 앙골라 , 앤티가바부다 , 이라크 , 인도네시아 , 우간다 , 우즈베키스탄 , 우루과이 , 이집트 , 엘살바도르 , 오 만 , 카보베르데 , 가이아 나 , 카자흐스탄 , 카타르 , 캐나다 , 카메룬 , 감비아 , 캄보디아 , 북한 ( 저자 사후 익년 1 월 1 일 부터 계산 ) , 기니 , 기니비사우 , 쿠바 , 키리바시 , 키르기스스탄 , 쿠웨이트 , 그레 나 다 , 케냐 , 코모 로 , 콩고 공화국 , 콩고 민주 공화국 , 사우디 아라비아 , 잠비아 , 자메이카 , 시리아 , 짐바브웨 , 수단 , 수리남 , 스리랑카 , 스와 질랜드 , 적도기니 , 셰 네 갈 , 세인트 크리스토퍼 네 비스 , 세인트루시아 , 솔로몬 제도 , 타이 , 대만 , 타지키스탄 , 탄자니아 , 차드 , 중앙 아프리카 공화국 , 중국 , 튀니지 , 칠레 , 투발 루 , 토고 , 도미니카 공화국 , 트리니다드 토바고 , 통가 , 나미비아 , 니제르 , 일본 ( 영화 는 70 년 ) , 뉴질랜드 , 네 팔 , 바레인 , 아이 티 , 파키스탄 , 파나마 , 바하마 , 파푸아뉴기니 , 파라오 , 바베이도스 , 방글라데시 , 동 티모르 , 피지 , 필리핀 , 부탄 , 브루나이 , 브룬 디 , 베트남 , 베넹 , 벨로루시 , 벨리즈 , 보츠 와 나 , 볼리비아 , 홍콩 , 마카오 , 말라위 , 말리 , 말레이시아 , 미크로네시아 , 남 아프리카 공화국 , 모리셔스 , 모리타니 , 몰디브 , 몰 도버 , 모로코 , 몽골 , 요르단 , 르완다 , 레소토 , 레바논 대한민국 , 아이슬란드 , 미국 ( 법인 저작물 은 95 년 ) , 아르헨티나 , 알바니아 , 안도라 , 이스라엘 , 우크라 이나 , 에콰도르 , 아일랜드 , 영국 ( 주 1 ) , 이탈리아 , 에스토니아 , 오스트리아 , 네덜란드 , 키프로스 , 그리스 , 스웨덴 , 스페인 ( 주 2 ) , 슬로바키아 , 슬로베니아 , 체코 , 덴마크 , 독일 ( 주 3 ) , 헝가리 , 핀란드 , 프랑스 ( 주 4 ) , 불가리아 , 벨기에 , 폴란드 , 포르투갈 , 말타 , 라트비아 , 리투아니아 , 루마니아 , 룩셈부르크 , 호주 , 가 나 , 그 루지 야 , 크로아티아 , 코스타리카 , 싱 가 폴 , 스위스 , 세르비아 , 도미니카 , 터키 , 나이지리아 , 니카라과 , 노르웨이 , 바티칸 , 파라과이 , 브라질 , 부르키나파소 , 페루 , 보스니아 헤르체고비나 , 마케도니아 , 모잠비크 , 모나코 , 몬테네그로 , 리히텐슈타인 , 러시아 이외 에 도 , 멕시코 는 저작 재산 권 보호 기간 을 100 년 , 코트디부아르 는 99 년 , 콜롬비아 는 80 년 을 기준 으로 하 는 데 반해 , 이란 과 예 맨 은 30 년 을 기준 으로 하 고 있 고 , 심지어 저작권법 이 없 는 나라 들 도 있 다 . 또한 50 년 , 70 년 으로 규정 하 고 있 는 국가 들 도 저작물 의 종류 에 따라 기간 이 다를 수 있 으니 이용 할 때 자세히 알아보 는 것 이 좋 다 . ※ 꼭 알 아 두 세요 ※ 외국인 저작물 의 보호 기간 외국인 의 저작물 도 국내 에서 보호 될 때 에 는 내국민대우 의 원칙 에 따라 국내 저작물 과 마찬가지 로 보호 된다 . 따라서 보호 기간 역시 같 다 . 다만 , 저작물 의 본국 에서 보호 기간 이 만료 된 경우 에 는 우리 저작권법 에서 정한 보호 기간 이 만료 되 지 않 았 더라도 국내 에서 보호 가 종료 된다 . 베른 협약 은 보호 기간 은 보호 가 주장 되 는 국가 의 입법 의 지배 를 받 으며 , 그 국가 의 입법 으로 다르 게 규정 하 지 아니하 는 한 , 그 기간 은 저작물 의 본국 에서 정한 기간 을 초과 할 수 없 다고 규정 하 고 있 다 . ( 베른 협약 제 7 조 제 8 항 ) 해외 만료 저작물 이럴 땐 어떡 하 지 ? 궁금 해요 ! 1 . 일본 만화 를 번역 하 여 출판 하 려고 한다 . 일본 작가 a 의 사망 연도 는 1963 년 이 다 . 언제 부터 이용 허락 없이 출판 이 가능 한가 ? 답변 ) 우리 나라 저작권법 은 외국인 의 저작물 의 보호기 간 에 대하 여 ‘ 해당 외국 에서 보호 기간 이 만료 된 경우 에 는 우리 나라 저작권법 에 따른 보호 기간 ( 사후 70 년 ) 을 인정 하 지 아니한다 ’ 고 규정 ( 내국민대우 원칙 의 예외 ) 하 고 있 습니다 . 따라서 일본 의 저작 재산 권 보호기 간 에 따라 이용 허락 없이 출판 가능 한 시기 가 달라질 것 입니다 . 일본 저작권법 ( 제 51 조 ) 에 따르 면 저작 재산 권 보호 기간 은 생존 + 사후 50 년 간 존속 하 는 것 으로 규정 하 고 있 어 , 일본 작가 a 의 작품 은 일본 저작권법 에 따라 2013 년 12 월 31 일 에 만료 되 며 , 우리 나라 에서 도 동일 한 시점 인 2013 년 12 월 31 일 에 만료 되 기 때문 에 2014 년 부터 이용 허락 없이 출판 이 가능 합니다 . 2 . 멕시코 의 저작 권 보호 기간 은 100 년 으로 알 고 있 다 . 멕시코 의 작가 c 의 작품 은 국내 에서 100 년 간 보호 되 는가 ? 답변 ) 멕시코 의 저작 권 보호 기간 이 100 년 이 라고 해서 , 멕시코 작가 c 의 작품 을 우리 나라 에서 100 년 간 보호 하 지 않 고 , 70 년 간 만 보호 가 됩니다 . 이 는 저작 권 관련 국제 조약 ( 세계 저작 권 협약 , 베른 협약 , trips 등 ) 에서 정하 고 있 는 내국민대우 의 원칙 에 따른 것 으로 , 해당 국가 ( 우리나라 ) 에서 외국인 ( 멕시코 ) 의 저작물 을 보호 할 때 , 해당 국가 자국민 의 보호기 간 만큼 만 보호 하 면 되 기 때문 입니다 . 3 . 2012 년 에 미국인 작곡가 d 는 사망 한 지 50 년 이 지났 다 . d 의 음악 을 국내 에서 음반 으로 제작 하 려고 하 는데 , d 의 유족 은 미국 에서 저작 권 보호 기간 이 만료 되 지 않 았 음 을 근거 로 이용 허락 계약 을 요구 하 고 있 다 . 정당 한 요구 인가 ? 답변 ) 미국 의 저작 권 보호 기간 은 70 년 으로 비록 미국 에서 저작 권 보호 기간 이 유효 하 더라도 , 개정 법 시행 일 ( 2013 . 7 . 1 . ) 이전 에 이미 우리 나라 에서 보호 기간 이 만료 되 었 다면 보호 기간 은 연장 되 지 않 습니다 . 따라서 미국 의 저작 권 보호 기간 과 관계없이 우리 나라 에서 자유 롭 게 이용 할 수 있 으며 , d 유족 의 주장 은 정당 하 지 않 습니다 . - 한국 저작 권 위원회 자동 상담 서비스 일부 발췌 - - 고전 문학 저작물 은 저마다 저작 재산 권 보호 기간 이 있 기 때문 에 , 만료 저작물 이 되 기 까지 오랜 기간 을 거쳐야 한다 . 지금 발간 되 어 화제 가 되 는 작품 들 은 후세 에 가 서 나 만료 저작물 로 후손 들 이 이용 가능 하 다 . 그렇 다면 우리 는 어떤 만료 저작물 을 만나 볼 수 있 을까 ? 우리 가 지금껏 가장 쉽 게 해외 만료 저작물 을 접한 것 은 바로 고전 문학 이 다 . 먼저 , 셰익스피어 는 1616 년 4 월 23 일 별세 하 였 기 때문 에 그 의 작품 은 모두 사후 300 여 년 이 지났 다 . 따라서 그 의 작품 들 은 만료 저작물 로서 누구 나 무료 로 이용 할 수 있 다 . 헤밍웨이 ( 1961 년 별세 ) 와 헤르만헤세 ( 1962 년 별세 ) 작품 역시 그렇 다 . 우리 나라 는 한 - eu fta 체결 과 함께 저작 재산 권 보호 기간 이 50 년 에서 70 년 으로 변경 되 었 다는 사실 은 위 에 이야기 를 했었 다 . 이 개 정법 은 2013 년 8 월 1 일 부터 시행 되 었 는데 , 1961 년 에 사망 한 헤밍웨이 의 작품 들 과 1962 년 에 사망 한 헤르만 헤세 와 윌리엄 포크너 의 작품 들 은 개정 법 시행 이전 에 사후 50 년 을 맞 아 현재 , 만료 저작물 ( public domain ) 로서 이용 이 가능 하 다 . - 셜록 홈즈 영국 추리 소설 ‘ 셜록 홈스 ’ 를 현대 적 으로 각색 한 영국 bbc 드라마 ‘ 셜록 ’ 과 미국 할리우드 영화 ‘ 셜록 홈스 ’ 시리즈 는 우리 나라 는 물론 전 세계 에서 흥행 돌풍 을 일으키 며 ‘ 홈스 신드롬 ’ 을 일으켰 다 . 영국 스코틀랜드 출신 추리 소설 작가 코난 도일 ( 1859 ~ 1930 ) 은 1887 년 홈스 를 소설 에 처음 등장 시킨 이후 사망 할 때 까지 관련 시리즈 수십 편 을 남겼 다 . 셜록 홈즈 도 저작 자 사망 70 년 이 지났 기 때문 에 저작권료 를 지불 하 지 않 고 이용 이 가능 하 다 . 단 , 미국 저작권법 은 1923 년 이후 나온 저작물 에 대해 95 년 간 저작 권 을 인정 하 고 있 기 때문 에 미국 에서 는 일부 만 사용 이 가능 하 다 . - 뽀빠이 한 손 으로 시금치 통조림 을 쥐어짜 받 아 먹 는 뽀빠이 를 생각 하 면 추억 에 잠긴다 . 뽀빠이 의 원조 는 만화책 으로 총 3 권 이 있 으며 1991 년 영화 로 도 제작 이 되 었 다 . 뽀빠이 는 한국 에서 는 2009 년 1 월 에 저작 권 보호 기한 인 70 년 이 만료 되 었 다 . 다만 한국 에서 퍼블릭 도메인 으로 풀렸 다는 의미 일 뿐 저작 권 자체 가 소멸 된 것 은 아니 다 . 이 보호 기한 이 설정 되 고 만료 되 는 기준 은 국가 나 지역 마다 다 다르 기 때문 에 아직 까지 보호 받 고 있 는 곳 도 있 다 . 때문 에 캐릭터 자체 의 저작 권 이 만료 된 것 이 지 캐릭터 의 그림 은 그것 을 그린 사람 에게 2 차 저작 권 이 유효 하 다는 것 을 주의 해야 한다 . 즉 다른 사람 이 그린 뽀빠이 를 사용 하 는 것 은 여전히 저작 권 에 위배 되 므로 무료 로 뽀빠이 를 사용 하 고 싶 으면 직접 그려야 한다 . 더불 어 뽀빠이 캐릭터 를 티셔츠 나 엽서 에 인쇄 하 는 것 은 문제 가 없 지만 뽀빠이 란 이름 을 상품 에 사용 하 는 것 은 저작 권 의 영역 이 아니 라 상표 권 의 영역 이 기에 별개 의 문제 이 다 . 1 . 구텐베르크 [ URL ] 프로젝트 구텐베르크 ( project gutenberg ) 는 저작 권 시효 가 만료 된 도서 를 무료 로 이용 할 수 있 도록 제공 하 는 웹 사이트 이 다 . 1971 년 미국인 마이클 하트 ( michael hart ) 가 인류 의 자료 를 모아서 전자 정보 로 저장 하 고 배포 하 는 프로젝트 로 시작 한 것 이 바로 프로젝트 구텐베르크 ( project gutenberg ) 다 . 예전 에 는 html 로 된 내용 을 텍스트 로 이용 할 수 있 다는 것 에서 장점 을 취했 지만 이제 는 다른 유료 전자책 처럼 활용 할 수 가 있 으며 , 저작 권 만료 도서 뿐 아니 라 , 저작 권 자 의 배포 가 동의 된 작품 도 찾 아 볼 수 있 다 . 가장 오래 되 고 활발 한 공공 도서관 프로젝트 기 때문 에 다양 한 언어 서비스 ( 한국어 서비스 는 제공 되 지 않 음 ) 를 제공 하 며 유명 한 작품 들 이 모여 있 다 . 2 . aozora bunko [ URL ] 아오조라 문고 ( 靑空 文庫 , あおぞらぶんこ ) 는 ‘ 일본 어판 구텐베르크 프로젝트 ’ 로 불리 는 일본 의 인터넷 전자 도서관 으로 , 저작 권 이 풀린 문학 작품 을 수집 , 전자 문서 화 해서 인터넷 에 공개 하 고 있 다 . 저자 사후 50 년 이 지난 메이지 , 쇼 와 시대 초기 의 일본 문학 작품 이 그 대부분 을 차지 하 고 있 고 , 일본어 외 문학 작품 의 일본어 번역 작품 도 다수 있 다 . 유명 작가 의 작품 이 모두 갖춰져 있 진 않 지만 그래도 일본어 작품 에 관련 해서 는 충실 하 게 갖춰진 편 이 다 . 3 . 직지 프로젝트 [ URL ] sf 직지 프로젝트 는 1999 년 에 시작 된 한국 sf 고서 전산 화 프로젝트 로 , 2000 년 5 월 5 일 에 마무리 되 었 다 . 삼국유사 , 삼국사기 와 같 은 고전 문학 을 현대어 로 해석 한 텍스트 본도 올라와 있 다 . 4 . 공유 마당 [ URL ] 「 공유 마당 」 에 는 만료 저작물 뿐 만 아니 라 사회 적 보존 가치 가 높 은 민간 보유 저작물 과 공공 콘텐츠 와 같 은 공유 저작물 이 제공 되 고 있 다 . 유럽연합 ( eu ) 전자 도서관 프로젝트 유로피아나 와 협약 을 맺 어 해외 의 만료 저작물 도 찾 아 볼 수 있 다 .',\n",
       "       '[ URL ] 정부 가 sk 텔레콤 의 인구 이동 빅 데이터 를 이용해 코로나 19 의 영향 을 분석 한 자료 를 내놨 다 . 자료 에서 눈여겨볼 만 한 데이터 몇 개 를 추려서 소개 한다 . 이동성 데이터 는 그 자체 가 경제 적 충격 이나 심리 적 충격 을 의미 하 지 는 않 지만 살펴보 면 다양 한 의미 를 추론 해낼 수 있 다 . 분명 한 건 코로나 19 의 충격 과 상처 가 똑같 지 는 않 았 단 점 이 다 지난주 까지 데이터 는 더 할 나위 없이 긍정 적 이 다 . 지난해 와 비교 한 전체 이 동량 추이 를 보 면 발생 4 주 차 주말 인 2 월 29 일 이 동량 이 가장 적 었 다 . 전년 대비 - 41 . 9 %. 그러나 회복 은 빨라서 황금연휴 가 끼 어 있 던 5 월 첫째 주 가 되 면 - 17 % 로 회복 되 었 다 . 지난해 의 83 % 수준 까지 올라선 것 . 세계 가 \\' 표준 \\' 으로 삼 는 우리 의 방역 성공 의 성과 다 . 하지만 회복 추세 는 이태원 클럽 발 재 확산 사태 에 대한 우려 가 커지 며 꺾이 고 만 다 . 지난주 , 이 동량 은 되려 25 % 감소 해버려 3 주 전 인 4 월 중순 수준 으로 회귀 해 버린다 . 통계청 은 \" 클럽 발 재 확산 우려 도 있 었 고 , 지난주 날씨 의 영향 도 있 다 . 지난 주말 에 비 가 오 고 흐렸 기 때문 이 다 . 추세 가 이렇게 꺾인 원인 을 좀 더 정확히 들여다보 려면 이번 주말 데이터 를 봐야 할 것 같 다 \" 고 설명 했 다 . 사태 초기 부터 지금 까지 남성 과 여성 의 이 동량 차이 도 분명 했 다 . 충격 이 가장 컸 던 발생 4 주 차 , 2 월 말 을 기준 으로 보 면 그 차이 는 11 . 1 % p 나 차이 가 났 다 . 이후 로 도 꾸준히 남녀 간 이 동량 차이 는 분명 했 는데 , 완화 된 거리 두기 이후 여성 의 이 동량 이 증가 하 는 추세 는 남성 보다 더 빨랐 다 . 연휴 주간 을 기준 으로 여성 의 이 동량 은 전년 대비 1 . 4 % 감소 하 는 데 그쳐 오히려 남성 ( - 3 . 9 %) 보다 더 빨리 회복 되 었 다 . 안전 의식 에 대한 여성 의 민감 도 가 남성 보다 더 높 은 것 으로 추론 해 볼 수 있 다 . 또 주중 보다 는 나 들 이 수요 가 많 은 주말 의 민감 도 도 같 은 이유 로 컸 다 . 사태 초기 비교 적 이 동량 감소 폭 이 작 던 대구 는 31 번 확진 자 발생 이후 신천지 중심 의 지역 감염 전파 가 확산 하 면서 2 월 말 전년 대비 반 토막 수준 이 된다 . 52 . 6 % 감소 한 것 . 이후 3 주간 40 % 이상 의 이 동량 감소 가 나타난 뒤 꾸준히 회복 되 는 추세 가 확인 된다 . 그런데 더 눈 에 띄 는 이 동량 변화 는 제주 에서 나타났 다 . 그래프 에서 보 듯 제주 의 이 동량 감소 는 절정 이 던 2 월 말 에 - 53 . 7 % 를 기록 해 대구 보다 컸 고 , 이후 로 회복 속도 도 더디 다 . 봄 관광 성수기 인 4 월 이 되 면 - 57 . 3 % 까지 떨어져서 저점 을 기록 한다 . 이 동량 데이터 측정 기준 이 \\' 본인 이 실거 주 하 는 지역 을 벗어나 30 분 이상 다른 지역 을 방문 한 경우 \\' 인 점 을 고려 하 면 제주 의 이 동량 감소 는 \\' 관광 \\' 의 위축 으로 봐도 무방 할 것 이 다 . 역시 관광업 의 비중 이 큰 강원도 의 회복 추세 가 더뎠 던 점 역시 이 같 은 해석 에 무게 를 싣 게 한다 . 대구 와 제주 의 이 동량 이 평소 의 40 % 넘 게 감소 한 기간 만 추려 보 면 , 제주 의 경우 전체 14 주 가운데 85 % 기간 이 해당 하 고 , 대구 의 경우 는 21 % 에 그쳤 다 . 비교 적 코로나 19 타격 이 작 았 던 전라 남북 도 지역 의 이 동량 감소 폭 은 다른 지역 에 비해 크 지 않 았 다 . 코로나 19 의 영향 은 70 대 이상 의 고령 층 이 가장 크 게 받 을 수 밖에 없 다 . 이 동량 데이터 도 이 를 증명 한다 . 전 기간 에 걸쳐서 70 세 이상 고령 층 의 이동 이 가장 많이 줄어든 데이터 가 이 를 입증 한다 . 눈여겨볼 부분 은 20 세 미만 의 이 동량 이 다 . 사태 초기 급증 했 고 , 지난 주말 에 는 \\' 폭 증 \\' 했 다 . 단 한 주 사이 에 전년 대비 76 % 수준 이 던 이 동량 이 120 % 까지 늘 었 다 . 입지 유형 별 데이터 를 살펴보 면 대형 복합 상 가 는 이 동량 감소 폭 이 비교 적 적 고 관광지 나 상업 지역 의 이 동량 감소 폭 이 크 다 . 관광 의 경우 지난주 연휴 에 는 급증 했 다 . 하지만 앞서 언급 했 듯 이 동량 데이터 는 매출 타격 이나 심리 적 충격 의 크기 를 정확히 보여 주 지 는 않 는다 . 앞서 kbs 는 빅 데이터 분석 을 통해 소상 공인 들 의 매출 타격 을 분석 해 보도 한 바 있 다 . 유사 한 추세 를 나타내 는데 , 정확 한 데이터 인 만큼 읽 어 볼 만 하 다 . [ 연관 기사 ]',\n",
       "       'sli 브릿지 와 함께 nvidia titan xp 4 장 이 도착 했 습니다 . titan xp 4 - way sli 를 구성 합니다 . 메인보드 는 asus rampage v extreme 으로 , pic - express 슬롯 4 개 가 장착 되 어 있 어 4 - way sli 를 구성 할 수 있 습니다 . 4 - way sli 를 구성 하 기 위해 원래 사용 하 던 700 w 짜리 파워 를 떼 고 2000 w 짜리 새 파워 로 교체 했 습니다 . 원래 달려 있 던 980 ti 를 떼 고 titan xp 네 장 을 꽂 았 습니다 . sli 브릿지 도 꽂 아 줍니다 . 그래픽 카드 를 주문 할 때 sli 브릿지 도 주문 했었 는데 도착 한 게 4 - way 용 이 아니 라 2 - way 용 브릿지 였 습니다 . 4 slot 이 라고 적혀 있 어서 4 - way 용 일 거 라고 생각 했 는데 아니 었 네요 . .. otl . .. 어쩔 수 없이 메인보드 에 동봉 되 어 있 던 sli 브릿지 를 사용 했 습니다 . 그래픽 전원 선도 파워 로부터 끌 어 와서 네 군데 모두 넣 어 줬 습니다 . 메인보드 에 그래픽 카드 4 장 을 꽂 을 경우 문제 가 발생 합니다 . 우선 은 , 그래픽 카드 가 슬롯 을 두 칸 씩 잡아먹 기 때문 에 다른 pci 슬롯 을 사용 할 수 가 없 습니다 . 사진 에 보이 는 것 처럼 빨간색 pci - express 슬롯 사이 에 있 는 검 은 pci 슬롯 들 을 사용 할 수 없 습니다 . pci - express 슬롯 하나 에 랜 카드 를 꽂 아 쓰 고 있 었 는데 이걸 제거 해야 했 습니다 . 그 보다 더 심각 한 문제 는 마지막 네 번 째 그래픽 카드 를 꽂 을 때 발생 합니다 . 네 번 째 그래픽 카드 를 꽂 기 위해선 메인보드 하단 에 위치 한 단자 들 을 모두 사용 할 수 없 습니다 . 전면 패널 을 연결 하 는 핀 과 rampage 메인보드 에 딸려 오 는 oc 패널 연결 핀 , usb 케이블 연결 핀 , 비프 음 스피커 핀 에 단자 를 꽂 을 수 없 습니다 . 4 - way sli 를 구성 하 려면 이 단자 들 을 모두 포기 해야 합니다 . 케이스 전면 usb 3 . 0 연결 핀 은 다행히 도 다른 곳 에 있 어서 정상 적 으로 사용 할 수 있 고 케이스 전면 의 이어폰 단자 와 마이크 단자 도 영향 을 받 지 않 는 위치 에 있 어서 사용 할 수 있 습니다 만 , 나머지 다른 것 들 , 컴퓨터 본체 전면 패널 의 전원 버튼 , 리셋 버튼 , 하드 램프 , 전원 램프 를 사용 할 수 없 습니다 . asus rampage v 의 oc 패널 도 사용 불 가능 합니다 . 컴퓨터 의 전원 을 켜 거나 리셋 을 하 려면 본 체 뚜껑 을 열 고 메인보드 에 위치 한 전원 버튼 을 눌러야 합니다 . 그러니까 본체 케이스 의 전원 버튼 을 사용 할 수 없 고 컴퓨터 를 끄 고 켤 때 마다 케이스 를 열 어야 합니다 . -_- 4 - way sli 를 사용 하 는 유저 가 거의 없 어서 그런 건지 아니 면 그 정도 의 파워 유저 는 다른 방법 을 찾 을 것 이 라고 생각 했 는지 4 - way sli 구성 의 편의 성 은 별로 고려 하 지 않 은 듯 해 보 입니다 . 또 하나 소소 한 불편 을 얘기 하 자면 , 그래픽 4 장 을 모두 꽂 은 후 다시 그래픽 카드 를 탈거 하 려면 첫 번 째 그래픽 카드 부터 뽑 아야 합니다 . 그래픽 카드 4 장 을 다 꽂 은 상태 에서 는 첫 번 째 그래픽 카드 가 꽂힌 pic - express 슬롯 의 탈착 버튼 만 을 누를 수 있 기 때문 입니다 . cpu 의 쿨러 와 팬 이 대형 이 라서 이 버튼 을 누르 기 위해서 는 cpu 의 팬 을 제거 하 고 일자 드라이버 를 사용 하 여 꾹 눌러 줘야 합니다 . 다행히 cpu 쿨러 까지 제거 할 필요 까진 없 고 팬 만 위 로 빼낸 후 에 작업 이 가능 했 습니다 . 다른 메인보드 에서 는 sli 구성 이 어떨지 모르 겠 네요 . 4 - way sli 구성 시 발생 하 는 불편 함 을 공유 하 기 위해 포스팅 을 올립니다 . 사용 기 는 추후 에 업데이트 하 겠 습니다 . 아래 에 전체 하드웨어 사양 을 정리 하 면서 포스팅 을 마치 겠 습니다 . cpu : intel ( r ) core ( tm ) i 7 - 5960 x cpu @ 3 . 00 ghz main board : asus rampage v extreme ram : g . skill ddr 4 8 gb pc 4 - 19200 x 4 gpu : nvidia titan xp x 4 power : super flower sf - 2000 f 14 hp leadex platinum case : corsair air 240 black',\n",
       "       '코로나 바이러스 감염증 - 19 국내 발생 현황 ( 7 월 29 일 정례 브리핑 ) 질병관리본부 중앙 방역 대책 본부 ( 본부 장 정은경 ) 는 7 월 29 일 0 시 기준 으로 , 국내 발생 신규 확진 자 는 14 명 이 확인 되 었 고 , 해외 유입 사례 는 34 명 이 확인 되 어 총 누적 확진 자수 는 14 , 251 명 ( 해외 유입 2 , 363 명 ) 이 라고 밝혔 다 . 신규 격리 해 제자 는 62 명 으로 총 13 , 069 명 ( 91 . 7 %) 이 격리 해제 되 어 , 현재 882 명 이 격리 중 이 다 . 위 · 중증 환자 는 12 명 이 며 , 사망자 는 0 명 으로 누적 사망자 는 300 명 ( 치명률 2 . 11 %) 이 다 . 【 국내 발생 확진 자 현황 *( 7 . 29 일 0 시 기준 , 1 . 3 일 이후 누계 ) 】 국내 발생 확진 자 현황 - 구분 , 합계 , 지역 별 구분 합계 서울 부산 대구 인천 광주 대전 울산 세종 경기 강원 충북 충남 전북 전남 경북 경남 제주 신규 14 7 1 0 1 0 0 0 0 5 0 0 0 0 0 0 0 0 누계 11 , 888 1 , 249 130 6 , 881 303 179 147 34 45 1 , 129 51 56 159 18 17 1 , 369 110 11 【 해외 유입 확진 자 현황 *( 7 . 29 일 0 시 기준 , 1 . 3 일 이후 누계 ) 】 해외 유입 확진 자 현황 - 구분 , 합계 , 유입 국가 , 확인 단계 , 국적 으로 구성 구분 합계 유입 국가 확인 단계 국적 중국 아시아 ( 중국 외 ) 유럽 아메리카 아프리카 오세 아니 아 검역 단계 지역 사회 내국 인 외국인 신규 34 0 25 1 8 0 0 21 13 12 22 누계 2 , 363 18 1 , 036 523 * 746 35 * 5 1 , 166 1 , 197 1 , 570 793 ( 0 . 8 %) ( 43 . 8 %) ( 22 . 1 %) ( 31 . 6 %) ( 1 . 5 %) ( 0 . 2 %) ( 49 . 3 %) ( 50 . 7 %) ( 66 . 4 %) ( 33 . 6 %) ※ 아메리카 : 미국 8 명 ( 외국인 4 명 ) , 유럽 : 프랑스 1 명 , 아시아 ( 중국 외 ) : 러시아 13 명 ( 12 명 ) , 우즈베키스탄 7 명 ( 4 명 ) , 카자흐스탄 2 명 ( 1 명 ) , 인도 1 명 ( 1 명 ) , 이라크 1 명 , 필리핀 1 명 【 확진 자 관리 현황 *( 7 . 29 일 0 시 기준 , 1 . 3 일 이후 누계 ) 】 확진 자 관리 현황 - 구분 , 격리 해제 , 격리 중 , 위 중증 환자 , 사망자 구분 격리 해제 격리 중 위 · 중증 환자 사망자 7 . 28 . ( 화 ) 0 시 기준 13 , 007 896 12 300 7 . 29 . ( 수 ) 0 시 기준 13 , 069 882 12 300 변동 ( +) 62 ( -) 14 - - * 7 월 28 일 0 시 부터 7 월 29 일 0 시 사이 에 질병관리본부 로 신고 , 접수 된 자료 기준 . ※ 상기 통계 는 모두 추후 역학 조사 과정 에서 변경 될 수 있 음 . 7 월 29 일 ( 12 시 기준 ) 국내 주요 발생 현황 * 은 다음 과 같 다 . * 1 페이지 0 시 기준 통계 , 지자체 자체 발표 자료 와 집계 시점 등 의 차이 로 일부 상이 할 수 있 음 서울 종로구 신명 투자 와 관련 하 여 2 명 이 추가 확진 되 어 누적 확진 자 는 총 12 명 * 이 다 . * ( 구분 ) 지표 환자 1 명 , 지인 등 5 명 , 신명 투자 관련 6 명 서울 시청 확진 자 와 관련 하 여 접촉자 32 명 ( 자 가 격리 17 명 포함 ) 전원 음성 이 었 으며 , 11 층 근무자 164 명 중 51 명 음성 ( 나머지 진행 중 ) , 11 층 수시 방문자 중 검사 희망자 163 명 에 대해서 선제 검사 가 진행 중 이 다 . 부산 러시아 선박 ( petr 1 호 ) 관련 하 여 선박 수리공 1 명 이 추가 확진 되 어 지역 사회 누적 확진 자 는 총 11 명 * 이 다 . * ( 구분 ) 수리공 9 명 , 동거인 · 가족 2 명 7 월 29 일 0 시 기준 , 해외 유입 확진 자 는 34 명 으로 검역 단계 에서 21 명 이 확인 되 었 고 , 입국 후 지역 사회 에서 자 가 격리 중 에 13 명 이 확인 되 었 으며 , 이중 내국인 이 12 명 , 외국인 은 22 명 이 다 . 해외 유입 확진 자 34 명 의 추정 유입 국가 는 아메리카 8 명 ( 미국 8 명 ) , 유럽 1 명 ( 프랑스 1 명 ) , 중국 외 아시아 25 명 ( 러시아 13 명 , 우즈베키스탄 7 명 , 카자흐스탄 2 명 , 인도 1 명 , 이라크 1 명 , 필리핀 1 명 ) 이 다 . - 추정 유입 국가 가 러시아인 13 명 중 12 명 은 지난 7 . 24 일 확진 자 32 명 이 확인 된 부산항 정박 러시아 선박 ( petr 1 호 , 7 . 8 일 입항 ) 에서 추가 확진 된 선원 이 며 , 현재 까지 petr 1 호 관련 누적 확진 자 는 총 44 명 이 다 . 이 보도 자료 는 관련 발생 상황 에 대한 정보 를 신속 투명 하 게 공개 하 기 위한 것 으로 , 추가 적 인 역학 조사 결과 등 에 따라 수정 및 보완 될 수 있 음 을 알려 드립니다 . < 붙임 > 코로나 19 국내 발생 현황 코로나 19 국외 발생 현황 여름휴가 를 위한 코로나 19 예방 3 행 ( 行 ) · 3 ( 禁 ) 수칙 「 감염병 보도 준칙 」 ( 2020 . 4 . 28 . ) < 별첨 자료 >',\n",
       "       \"31 일 부터 ' 청년 우대 형 주택 청약 종합 저축 ' 가입 이 시작 됐 다 . 이번 년 도 가입 대상 은 △ 직 전년 도 신고 소득 이 연소 득 3 천만 원 이하 △ 만 19 세 이상 에서 만 29 세 이하 △ 무주택 세대주 여야 한다 . 다만 병역 증명서 에 의한 병역 이행 기간 이 증명 되 는 경우 현재 연령 에서 병역 이행 기간 ( 최대 6 년 ) 을 빼 고 계산 한 연령 이 만 29 세 이하 인 사람 도 포함 된다 . 가입 을 원한다면 은행 에 방문 해 가입 시 isa ( 개인 종합 자산관리계좌 ) 가 입용 소득 확인 증명서 와 원천 징수 영수증 , 최근 3 개월 내 발급 받 은 주민 등록 등본 , 무주택 확인 각서 , 병역 이행 기간 을 증명 해야 할 경우 에 는 병 적 증명서 를 제출 해야 한다 . isa 가입 용 소득 확인 증명서 와 원천 징수 영수증 은 국세청 홈 텍스 에서 출력 할 수 있 으며 주민 등록 등본 과 병 적 증명서 는 정부 24 에서 신청 할 수 있 다 . 무주택 확인 각서 는 은행 마다 양식 이 달라 미리 확인 하 는 게 좋 다 . 이미 주택 청약 종합 저축 에 가입 한 사람 도 가입 조건 만 충족 하 면 청년 우대 형 청약 통장 으로 전환 할 수 있 다 . 방식 은 기존 통장 해지 후 전환 원금 을 신규 통장 으로 이전 하 는 것 으로 진행 된다 . 전환 하 는 경우 기존 주택 청약 종합 저축 의 납입 기간 , 납입금 액 은 인정 하 지만 전환 원금 은 우대금리 적용 에서 제외 된다 . 즉 , 통장 을 바꾼 뒤 신규 납입금 에 대해서 만 우대 이율 과 이자 소득 비 과세 혜택 이 적용 된다 . 디지털 콘텐츠 팀 multi @\",\n",
       "       \"윈도우 10 에서 우분투 듀얼 부팅 하 기 ( 멀티 부팅 ) - 1 윈도우 10 에서 우분투 듀얼 부팅 하 기 ( 멀티 부팅 ) - 2 상위 포스팅 에서 우분투 usb installer 를 만드셨 다면 , 이제 는 적용 을 할 차례 입니다 . 원래 는 기본 적 으로 usb 를 인식 시킨 후 , 부팅 시 에 bios 에서 잡 아 줘서 자동 적 으로 우분투 usb 에 진입 하 면 되 지만 , window 8 부 터 이상 한 종 특 을 가지 게 되 었 습니다 . 바로 ' fast startup ' & ' secure boot ' 입니다 . 위 과정 때문 에 참 골치 아프 게 과거 에 우분투 를 설치 했었 습니다 . 위 두 과정 을 먼저 무장 해제 시키 고 설치 를 진행 해야 합니다 . 시작 해 보 겠 습니다 . 제 pc 환경 은 다음 과 같 습니다 . os : windows 10 ( 64 - bit ) 빠른 시작 켜 기 해제 1 . 제어판 이 진입 하 여 ' 시스템 및 보안 ' 을 클릭 합니다 . 2 . ' 전원 옵션 ' 진입 3 . ' 전원 단추 작동 설정 ' 진입 4 . ' 현재 사용 할 수 없 는 설정 변경 ' 클릭 5 . ' 종료 설정 ' 란 에 빠른 시작 켜 기 ( 권장 ) 부분 을 체크 해제 합니다 . 변경 내용 저장 . 이렇게 해서 빠른 시작 켜 기 ( fast startup ) 해제 했 습니다 . 안전 한 부트 제거 1 . pc 혹은 노트북 을 종료 합니다 . 전원 을 키 면서 bios 에 진입 합니다 . ( 삼성 노트북 f 2 ) bios 에 진입 하 면 아래 처럼 boot 탭 에 진입 합니다 . 여기 서 저기 체크 되 어 있 는 secure boot 를 enter 로 ' disabled ' 로 설정 해줍니다 . 2 . exit 탭 에서 저장 후 종료 합니다 . 여기 까지 가 듀얼 부팅 혹은 멀티 부팅 을 위한 초기 설정 입니다 . 여기 서 부 터 는 파티션 을 나눠서 나눈 파티션 에 우분투 를 설치 하 도록 하 겠 습니다 . * 파티션 을 나눌 필요 가 없 으신 분 들 이나 , 그냥 윈도우 를 갈 고 거기 에 설치 를 하 시 겠 다는 분 들 은 굳이 따라오 지 않 으셔도 됩니다 . 윈도우 10 에서 파티션 나누 기 1 . 제어판 에 진입 하 여 ' 시스템 및 보안 ' 진입 합니다 . 2 . 아래 관리 도구 에 ' 하드 디스크 파티션 만들 기 및 포맷 ' 클릭 합니다 . 3 . 아래 화면 처럼 구성 된 화면 에서 주 드라이브 를 오른쪽 클릭 하 여 볼륨 축소 를 합니다 . 4 . 축소 할 공간 입력 에 원하 는 만큼 의 공간 을 입력 합니다 . mb 단위 이 기 때문 에 헷갈리 시 다면 , 가장 상단 의 축소 전 전체 크기 와 c : 드라이브 의 gb 용량 을 비교 해 보 시 면 단위 가 적용 이 가능 하 실 겁니다 . 원 하 는 만큼 숫자 를 입력 하 시 고 축소 를 누릅니다 . 5 . 작업 이 완료 되 면 할당 되 지 않 음 으로 원 하 는 만큼 의 용량 이 나오 게 됩니다 . 이렇게 해서 우분투 듀얼 부팅 하 기 준비 작업 이 완료 됩니다 . 다음 포스팅 에서 bios 에서 usb 를 잡 아 주 고 , 설치 를 진행 하 여 듀얼 부팅 을 완료 하 도록 하 겠 습니다 .\",\n",
       "       '머리 가 희끗희끗 한 두 분 이 상담 을 하 러 오 셨 다 . 그 중 한 분 은 오른쪽 발 에 의족 을 착용 하 고 계셨 고 , 조금 의기소침 해 보였 다 . 그 옆 에 는 정체 를 알 수 없 는 비슷 한 연배 의 다른 분 이 함께 오 셨 더랬다 . 장애 우 권익 문제 연구소 에서 법률 지원 을 요청 해 온 사건 이 었 는데 , 의족 을 착용 하 신 지체 장애 인 분 이 사건 의 당사자 였 다 . 머뭇머뭇 하 시 면서 며칠 전 있 었 던 일 을 말씀 해 주 셨 다 . 제 가 제법 좋 은 직장 을 다니 다가 한 십 년 쯤 전 에 직장 에서 오토바이 를 타 고 퇴근 하 는 길 에 택시 랑 부딪혔 어요 . 그 사고 로 제 오른쪽 무릎 윗부분 을 잘라냈 죠 . 말씀 하 시 면서 오른쪽 다리 에 착용 되 어 있 는 의족 을 보여 주 셨 다 . 허리 에 띠 를 하 고 남 아 있 는 다리 부분 에 의족 을 단단히 고정 시킨 모습 이 었 다 . 그 끈 에 는 소켓 형 의 의족 을 볼트 와 너트 처럼 끼워서 착용 하 고 계셨 다 . 한 순간 에 중증 지체 장애인 이 되 다니 정말 속상했 지요 . 그래도 살 아야 하 니 의족 이 좀 익숙 해 지 고 다시 새 직장 을 알아보 면서 여기 취직 하 게 됐 어요 . 새 직장 은 서울 의 한 아파트 종합 관리 주식회사 였 다 . 그 회사 에서 는 이 분 을 서울 소재 어떤 아파트 의 경비원 으로 근무 하 도록 했 다 . 2010 년 도 연말 인데 눈 이 엄청나 게 오 더라고요 . 통상 경비원 은 눈 이 그렇게 많이 오 면 아파트 어린이 놀이터 에 눈 이 쌓이 지 않 도록 구석구석 쓸 어 놓 습니다 . 애 들 이 놀 다가 다치 면 안 되 니까요 . 그런데 어찌나 미끄럽 던지 놀이터 에서 그만 넘어진 거 예요 . 피 가 나 더라고요 . 그것 까진 괜찮 았 는데 하필 이 의족 도 부서지 지 뭡니까 . 그러니까 당사자 는 경비원 으로 제설 작업 을 하 던 중 미끄러져 넘어지 는 사고 를 당했 는데 , 왼쪽 무릎 은 다쳐서 피 가 나 고 , 오른쪽 무릎 의 의족 은 부서진 것 이 었 다 . 의족 이 생각 보다 많이 비싸 서 제 월급 으로 고치 지 를 못 해요 . 그래서 일 하 다 다친 것 이 니 사 고 나 고 한 달 쯤 있 다가 근로복지공단 에 양쪽 무릎 에 대한 산재 신청 ( 요양 급여 신청 ) 을 했 죠 . 보름 정도 지났 나 ? 근로복지공단 에서 연락 이 왔 더라고요 . 황당 하 게 도 ‘ 살 이 붙 어 있 는 멀쩡 한 무릎 만 산재 ’ 라는 거 에요 . 이쪽 은 살 이 아니 고 기계 니까 알 아서 제 돈 주 고 고치 라는 거 죠 . 나란히 붙 어 있 는 무릎 을 ‘ 피부 가 덮 고 있 냐 ? 아니 냐 ? ’ 고 이렇게 차별 하 다니 어 이 가 없 고 억울 했 다고 한다 . 그때 , 옆 에 함께 오 신 분 이 강한 어투 로 입 을 여신 다 . 이런 말 도 안 되 는 게 어디 있 습니까 ? 일 하 다가 다친 거 면 잘 치료 받 게 해줘야 지 살갗 이 없 다고 의족 은 알 아서 고치 라니 . 이런 건 차별 아닙니까 ? 알 고 보 니 그분 은 당사자 와 는 아무 관계 도 아닌 같 은 아파트 주민 이 셨 다 . 오 며 가 며 얼굴 보 고 인사 하 던 사이 인데 , 이런 일 을 당했 다는 것 을 알 고 나 서 같이 분기탱천 하 여 소송 이 라도 불사 하 자고 계속 힘 을 실 어 주 신 분 인 것 이 다 . 같이 ‘ 분기탱천 ’ 하 던 , 오지랖 넓 을 뿐 인 그 사람 법무법인 태평양 과 재단법 인 동천 은 이 사건 을 공익 사건 으로 수임 했 다 . 법 적 으로 산업 재해 로 인정받 으려면 ‘ 신체 ’ 에 ‘ 부상 ’ 을 입 어야 한다 . 결국 이 소송 은 ‘ 의족 파손 ’ 이 ‘ 신체 부상 ’ 으로 법 해석 될 수 있 냐 의 문제 였 다 . 이미 1 심 과 2 심 에서 모두 패소 한 상태 였 기 에 더욱 치밀 한 고민 이 필요 한 사건 이 었 다 . 일단 앞선 판결문 을 검토 해 보 았 다 . 1 심 은 ‘ 의족 ’ 이 란 것 이 뺐 다 끼웠 다 ( 탈 부착 ) 할 수 있 는 것 이 기에 신체 일부 라고 보 기 어렵 다고 했 다 . 2 심 판결문 에 는 한술 더 떠서 ‘ 부상 을 수반 하 지 않 는 의족 만 의 파손 ’ 은 부상 이 아니 라고 했 다 . 당사자 와 함께 오 신 분 은 이 내용 을 설명 하 면서 한껏 열 을 내 셨 다 . 아니 , 변호사 님 ! 무슨 판결 이 이렇 습니까 ? 2 심 판결 에 의하 면 의족 이 부서지 면서 그 주변 살 이 라도 같이 까졌 다면 산업 재해 이 고 , 의족 만 부서진 거 면 산업 재해 가 아니 라는 건가요 ? 정말 이해 가 안 가 요 . 그렇 다 . 이런 판결 은 꼭 바꿔야 한다 ! 용기 가 났 다 . 출산 예정일 을 이틀 남기 고 책상 에서 꼬박 16 시간 동안 공들인 상고이 유보 충서 를 제출 하 면서 이분 들 의 용기 가 재판부 에 꼭 전해 지 기 를 간절히 바랐 다 . 한 사람 의 ‘ 오지랖 ’ 이 수많 은 지체 장애인 의 권리 를 지켰 다 그렇게 1 년 을 넘 게 기다려 마침내 대법원 은 이 사건 원심 판결 을 파 기 환송 했 다 . 대법원 은 원심 판결 의 근거 를 대부분 배척 하 며 ① 산업재 해 보상 보험법 상 ‘ 신체 ’ 를 반드시 생래 적 신체 에 한정 할 필요 는 없 고 , ② ‘ 의족 파손 ’ 을 업무 상 재해 로 보 지 않 을 경우 장애 인 근로자 에 대한 보상 과 재활 에 상당 한 공백 을 초래 하 며 , ③ 신체 탈 부착 여부 를 기준 으로 요양 급여 대상 을 가르 는 것 이 합리 적 이 라고 할 수 없 고 , ④ 의족 파손 을 업무 상 재해 에서 제외 한다면 , 사업자 들 로 하여금 의족 착용 장애 인 들 의 고용 을 더욱 소극 적 으로 만들 우려 가 있 으며 , ⑤ 의족 은 단순히 신체 를 보조 하 는 기구 가 아니 라 신체 의 일부 인 다리 를 기능 적 . 물리 적 . 실질 적 으로 대체 하 는 장치 로 봐야 한다고 판결 한 것 이 다 . 이 대법원 판결 은 2015 년 최우수 판례 에 여러 차례 꼽힐 만큼 사회 적 으로 큰 반향 을 불러일으켰 다 . 감격 스러웠 지만 한편 으로 는 가슴 이 철렁 했 다 . 이 사건 은 애초 에 당사자 가 소송 까지 는 생각 하 지 않 은 사건 이 었 기 때문 이 다 . 사건 초기 당사자 주변 의 대부분 사람 들 이 ‘ 재수 가 없 으려니 하 고 잊 어 ! ’ ‘ 더 안 다친 게 어디 야 ? ’ 라는 식 으로 반응 했 다고 한다 . 그런데 가까운 거리 에서 지켜보 던 한 동네 주민 의 ‘ 오지랖 ’ 이 당사자 에게 는 소송 으로 나서 는 용기 가 되 었 고 , 그 결과 수많 은 다른 지체 장애인 의 권리 도 신장 될 수 있 었 던 것 이 다 . 오지랖 은 귀찮 고 피곤 하 다 . 나 살 기 바쁘 고 빡빡 한 세상 이 라 더욱 그러 하 다 . 하지만 가끔 내 마음 속 에 ‘ 이건 아닌데 ’ 싶 을 때 발동 하 는 ‘ 동조 와 협력 의 오지랖 ’ 이 , 상대방 에게 는 의외로 큰 용기 와 도움 이 될 수 도 있 다 . 갈수록 개인 이 파편 화 되 어 ‘ 각자도생 ’ 이 라는 슬픈 화두 가 관통 하 는 요즘 , 내 주변 누군가 에게 헌사 할 ‘ 연대 의 오지랖 ’ 은 무엇 일지 잠시 생각 해 보 는 것 도 꽤 나 즐거운 상상 일 것 이 다 . 원문 : 조우성 변호사 의 브런치',\n",
       "       '지방 은 사실 반드시 필요 한 영양소 다 . 여러 필수 지방산 은 우리 가 생존 하 는 데 있 어 요긴 한 것 은 물론 , 에너지 의 공급원 으로써 중요 한 역할 을 한다 . 우리 의 조상 들 이 살 았 던 환경 은 지방 을 쉽 게 구할 수 없 는 환경 이 었 을 것 이 다 . 그래서 우리 는 기름진 음식 을 좋아하 고 , 지방 을 잘 소화 시킬 수 있 도록 진화 했 을지 모른다 . 하지만 현대 사회 에 진입 하 면서 산업 화 된 국가 들 을 중심 으로 이것 이 새로운 문제 가 되 고 있 다 . 지방 을 섭취 하 는 것 자체 는 문제 가 없 지만 너무 많 은 지방 을 섭취 하 는 것 , 트랜스 지방 등 좋 지 않 은 지방 을 과량 섭취 하 기 때문 이 다 . 최근 여러 연구 는 지방 과다 섭취 가 단순히 비만 과 성인병 의 원인 일 뿐 아니 라 뇌 에 도 영향 을 미칠 수 있 다는 가설 을 지지 하 고 있 다 . 다만 , 아직 그 기전 까지 완전히 밝혀진 것 은 아니 다 . 루이지애나 주립 대학 의 연구자 들 은 저널 ‘ biological psychiatry ’ 에 발표 한 논문 에서 지방 과다 섭취 가 어쩌면 장내 미생물 에 영향 을 줄 수 있 다는 내용 을 발표 했 다 . 장내 미생물 과 과다 지방 우리 장 속 에 는 매우 많 은 미생물 이 산다 . 개체 수 로 따지 면 우리 몸 의 세포 보다 더 많 을 것 으로 예상 한다 . 매우 다양 한 종류 의 세균 이 우리 몸 과 함께 진화 해 왔 기 때문 에 이 들 이 우리 건강 에 미치 는 영향력 은 매우 크 다 . 최근 연구 들 은 이 미생물 의 역할 이 생각 이상 으로 크 다는 것 을 보여준다 . 이 장내 미생물 이 우리 가 먹 는 음식물 에 많 은 영향 을 받 는다 . 연구 팀 은 이 미생물 들 이 뇌 에 도 영향력 을 행사 한다는 가설 을 세웠 다 . 그리고 이 를 입증 하 기 위해 고지방 식이 를 먹인 쥐 와 일반 식사 를 먹인 쥐 를 비교 했 다 . 고지방 식이 는 우울증 같 은 정신 행동 변화 와 연관 성 이 있 는데 , 실제 쥐 에서 도 이런 반응 을 확인 할 수 있 었 다 . 고지 방식 에 노출 된 쥐 는 불안 , 반복 행동 , 기억력 감퇴 등 의 이상 행동 을 보였 다 . 그리고 이 쥐 에서 추출 한 장내 미생물 을 정상 식사 를 한 쥐 에 투여 했 다 . 그 결과 장내 미생물 을 투여 받 은 쥐 는 비슷 한 형태 의 행동 장애 를 나타냈 다 . 이 미생물 을 투여 받 은 후 쥐 의 체내 에 는 염증 물질 의 농도 가 증가 했 고 , 쥐 의 뇌 에서 도 염증 활동 증가 를 확인 했 다 . 이 를 토대 로 연구 팀 은 고지방 식이 를 한 쥐 가 이상 행동 을 보이 는 것 은 장내 미생물 변화 에 의한 염증 반응 증가 와 이 로 인한 뇌 의 변화 때문 이 라고 주장 했 다 . 이 는 숙주 에 여러 영향력 을 행사 하 는 장내 미생물 역할 에 관한 또 다른 증거 지만 , 사람 에게 도 같 은 메커니즘 이 작용 하 는지 알 기 위해서 는 더 많 은 연구 가 필요 하 다 . 다만 , 고지방 식이 가 숙주 인 사람 에게 는 물론 이 고 , 사람 몸 속 에 공생 하 는 미생물 에게 도 좋 지 않 은 영향 을 미치 리라는 것 은 어느 정도 추정 할 수 있 다 . 참고 journal reference : annadora j . bruce - keller , j . michael salbaum , meng luo , eugene blanchard , christopher m . taylor , david a . welsh , hans - rudolf berthoud . obese - type gut microbiota induce neurobehavioral changes in the absence of obesity . biological psychiatry , 2015 ; 77 ( 7 ) : 607 doi : 10 . 1016 / j . biopsych . 2014 . 07 . 012 [ URL ] 원문 : 고든 의 블로그',\n",
       "       '※ the new yorker 의 「 how to beat writer ’ s block 」 을 번역 한 글 입니다 . 1920 년 , 열 여섯 살 난 그레이엄 그린 은 “ 104 주 동안 의 단조 로움 , 부끄러움 , 정신 적 고통 ” 끝 에 자신 이 다니 던 프 렙 스쿨 인 버크 햄 스테드 를 떠나 겠 다고 결심 했 습니다 . 그 의 아버지 가 학교 의 교장 이 었 기 에 그 는 부모 님 앞 으로 된 자퇴 사유서 를 남기 고 학교 로부터 도망쳤 고 , 얼마 지나 지 않 아 발견 되 었 습니다 . 그 탈출 은 가족 들 에게 매우 충격 적 인 일 이 었 기 에 이 들 은 그 에게 6 개월 간 의 심리 치료 를 받 게 했 습니다 . 이 는 그린 의 남 은 인생 을 극 적 으로 바 꿉니다 . 그 는 지긋지긋 했 던 학교 로부터 해방 돼 휴식 을 취할 수 있 었 고 또한 그 의 작가 로서 의 인생 에 커다란 영향 을 미치 는 습관 을 몸 에 익혔 습니다 . 그것 은 그린 이 자신 의 정신 적 스트레스 를 보다 생산 적 인 방향 으로 보낼 수 있 게 만든 꿈 일기 를 쓰 기 시작 한 것 입니다 . 그린 이 얼마나 많 은 글 을 남겼 는지 아 는 이 라면 그 도 작가 의 벽 ( writer ’ s block ) 으로 고생 한 적 이 있 다는 것 을 믿 기 힘들 겁니다 . 그러나 그 역시 50 대 에 , 스스로 “ 봉쇄 ( blockage ) ” 라고 부른 , 이야기 를 진행 시킬 수 없 거나 심지어 시작 도 할 수 없 는 그런 슬럼프 를 겪 었 습니다 . 그 린 은 꿈 일기 가 자신 을 구해 줄 것 이 라 생각 했 습니다 . 그 는 꿈 일기 가 매우 특별 한 형태 의 글쓰기 라고 믿 었 습니다 . 누구 도 다른 사람 의 꿈 을 볼 수 없 습니다 . 또한 누구 도 명예 훼손 으로 그 내용 을 고발 할 수 없 습니다 . 누구 도 그 내용 이 사실 인지 따지 지 않 으며 , 비 현실 적 인 사건 전개 를 걸 고 넘어지 지 도 않 습니다 . 그린 의 꿈 일기 를 모은 『 나 만 의 세계 ( a world of my own ) 』 의 서문 에서 그린 의 오랜 연인 이 었 던 이본 클로 에 타 는 그린 이 친구 에게 했 던 말 을 이렇게 기록 했 습니다 . 만약 누군가 가 꿈 전체 를 기억 할 수 있 다면 그 는 어떤 다른 세상 의 환상 으로부터 만들 어 지 는 즐거움 을 맛볼 수 있 다 . [ … ] 그 는 자신 에게 박힌 의식 의 바깥 에서 자신 을 찾 는다 . 의식 이 만드 는 불안 에서 벗어날 수 있 었 던 그린 은 다시 글 을 쓸 수 있 었 습니다 . 작가 의 벽 ( writer ’ s block ) 작가 의 벽 은 아마 글쓰기 가 시작 된 이래 존재 했 겠 지만 , 그 단어 를 처음 사용 한 것 은 1940 년 대 정신 과 의사 에드문드 버글 러 였 습니다 . 버글 러 는 약 이 십 년 동안 “ 생산 성 의 신경 성 억제 ” 로 고생 하 는 작가 들 을 연구 했 습니다 . 그 는 왜 그 들 이 창작 을 할 수 없 는지 , 그리고 어떤 방법 으로 이 를 치료 할 수 있 는지 를 찾 으려 했 습니다 . 이런 문제 를 겪 는 작가 들 과 의 몇 번 의 인터뷰 및 수 년 간 의 연구 끝 에 그 는 당시 가장 인기 있 던 이 문제 에 대한 해설 이 틀렸 다는 것 을 발견 했 습니다 . 벽 에 부딪힌 작가 들 은 당시 의 설명 처럼 영감 을 다 써 버리 고 “ 스스로 를 다 소진 한 ” 것 이 아니 었 습니다 . 또한 , 월세 를 내 고 나 면 더 이상 글 이 써 지 지 않 는 현상 을 일컫 는 “ 집 주인 ( landlord ) ” 이론 에서 처럼 외부 의 동기 가 사라졌 기 때문 도 아니 었 습니다 . 그 들 의 재능 이 사라진 것 도 아니 었 고 , 그저 지루 해 게으름 을 피우 는 것 도 아니 었 습니다 . 그렇 다면 , 버글 러 의 답 은 무엇 이 었 을까요 ? 그 는 프로이드 학파 로부터 정신 분석 을 배웠 고 , 그 는 이 를 바탕 으로 이 문제 에 접근 했 습니다 . 프로이드 가 1939 년 만든 저널 인 《 아메리칸 이 마고 ( american imago ) 》 에 1950 년 실린 「 작가 의 벽 은 실재 하 는가 ? 」 라는 글 에서 그 는 작가 는 정신 분석가 와 같 다고 주장 했 습니다 . 그 는 작가 는 “ 무의식 적 으로 자신 내부 의 문제 를 글쓰기 라는 방법 으로 승화 ( sublimation ) 시키 려 노력 하 는 존재 ” 라고 말 했 습니다 . 즉 벽 에 부딪힌 작가 는 실제로 심리 적 으로 벽 에 부딪힌 것 이 며 , 따라서 이 벽 을 없애 기 위해서 는 치료 가 필요 하 다는 것 입니다 . 개인 의 심리 적 문제 를 해결 함 으로써 이 벽 을 없앨 수 있 다는 것 이 지요 . 물론 이런 방법 도 통하 기 만 한다면 괜찮 겠 지요 . 문제 는 이 논리 가 그저 좌절 스러울 정도 로 모호 하 며 수많 은 다른 사실 들 을 가정 한다는 것 이 지요 . 작가 에게 글쓰기 가 승화 의 과정 이 라는 것 을 어떻게 알 수 있 을까요 ? 작가 가 글 을 쓰 지 못하 는 것 이 순전히 심리 적 으로 벽 에 부딪혔 기 때문 이 라는 증거 는 요 ? 무엇 보다 도 , 심리 적 으로 벽 에 부딪혔 다는 것 은 도대체 무슨 뜻 일까요 ? 싱어 와 배 리오스 의 실험 : ‘ 작가 의 벽 ’ 의 네 종류 그러나 버글 러 의 결론 은 정답 에서 멀리 떨어진 것 은 아니 었 던 것 으로 밝혀졌 습니다 . 70 년 대 에서 80 년 대 에 걸쳐 예일 대학 의 심리학자 제롬 싱어 와 마이클 배 리오스 는 작가 의 벽 이 어떤 것 인지 를 더욱 실험 적 인 관점 에서 이해 하 기 위해 노력 했 습니다 . 그 들 은 소설 과 비소설 , 시 와 산문 , 연극 과 영화 시나리오 등 을 쓰 는 다양 한 작가 들 을 뽑 았 습니다 . 그 중 에 는 작가 의 벽 에 부딪힌 이 도 있 었 고 그렇 지 않 은 이 도 있 었 습니다 . 일련 의 기준 을 만족 하 는 이 만 이 작가 의 벽 에 부딪힌 이 로 분류 되 었 습니다 . 곧 , 현재 자신 의 작업 을 전혀 진전 시키 지 못한다는 객관 적 인 증거 를 내 어야 했으며 글 을 쓰 지 못한다는 것 이 어떤 느낌 인지 를 제대로 증언 해야 했 습니다 . 이런 증상 이 3 개월 이상 지속 된 이 들 만 이 기준 을 통과 했 습니다 . 배 리오스 와 싱어 는 한 달 동안 이 들 의 변화 를 추적 했 습니다 . 그 들 을 인터뷰 하 면서 거의 60 개 의 다른 심리 테스트 를 받 게 했 습니다 . 그 들 이 먼저 발견 한 것 은 , 전혀 놀랍 지 않 게 도 , 벽 에 부딪힌 작가 들 은 불행 하 다는 것 입니다 . 자아 비판 을 포함 한 우울증 과 불안증 이 있 었 고 일 에 대한 자부심 이 줄어들 어 있 었 습니다 . 반복 , 자기 의심 , 미루기 , 완벽주의 등 의 강박 증 을 보였 습니다 . 무력감 과 함께 ‘ 고독 회피 ( aversion to solitude ) ’ 증상 을 보였 는데 , 마지막 문제 는 글쓰기 가 혼자 있 는 시간 을 요구 한다는 점 에서 특히 문제 가 되 는 것 이 었 습니다 . 물론 모든 불행 한 작가 들 이 다 똑같 은 방식 으로 불행 하 지 는 않 았 습니다 . 배 리오스 와 싱어 는 이 들 은 네 종류 의 그룹 으로 나누 었 습니다 . 첫 번 째 그룹 은 불안 과 스트레스 를 가장 큰 요인 으로 가진 그룹 입니다 . 이 들 이 글 을 쓰 지 못하 는 이유 는 글쓰기 의 즐거움 을 느끼 지 못하 게 만드 는 감정 적 고통 이 었 습니다 . 를 가장 큰 요인 으로 가진 그룹 입니다 . 이 들 이 글 을 쓰 지 못하 는 이유 는 글쓰기 의 즐거움 을 느끼 지 못하 게 만드 는 감정 적 고통 이 었 습니다 . 두 번 째 그룹 은 분노 와 짜증 으로 다른 이 들 에게 자신 의 불행 을 드러내 는 이 들 이 었 습니다 . 으로 다른 이 들 에게 자신 의 불행 을 드러내 는 이 들 이 었 습니다 . 세 번 째 그룹 은 모든 일 에 무감각 해진 이 들 이 었 습니다 . 해진 이 들 이 었 습니다 . 네 번 째 그룹 은 그저 슬퍼하 는 것 을 넘 어 화 , 분노 , 실망 등 의 강한 부정 적 감정 을 드러내 는 이 들 이 었 습니다 . 배 리오스 와 싱어 는 이러 한 차이 가 필연 적 인 것 임 을 발견 했 습니다 . 곧 , 서로 다른 그룹 의 작가 들 은 서로 다른 이유 로 글 을 쓰 지 못하 게 된 것 이 었 습니다 . 한편 , 모든 벽 에 부딪힌 작가 들 이 공통 으로 겪 는 현상 도 있 었 습니다 . 거의 모든 작가 들 은 동기 의 부족 을 느꼈 습니다 . 또한 의 욕 의 부족 과 함께 글쓰기 의 즐거움 역시 충분히 느끼 지 못했 습니다 . 창 의 력도 부족 했 습니다 . 배 리오스 와 싱어 는 벽 에 부딪힌 이 들 이 “ 긍정 적 이 고 건설 적 인 정신 적 에너지 ” 가 부족 하 다는 사실 을 발견 했 습니다 . 그 들 은 마음 속 에 그림 을 그리 는 능력 또한 부족 했으며 생동감 도 부족 했 습니다 . 또한 긍정 적 인 몽상 에 빠지 거나 실제 꿈 을 꾸 는 일 도 상대 적 으로 드물 었 습니다 . 놀라운 점 은 이런 동기 및 창의력 의 부족 이 각 그룹 에 따라 다르 게 나타났 다는 것 입니다 . 불안 이 문제 였 던 첫 번 째 그룹 은 자신 의 상상력 이 실제로 는 크 게 줄지 않 았 음 에 도 불구 하 고 자신 의 어떤 글 도 쓸 만 하 지 않 다는 그런 과도 한 자아 비판 때문 에 동기 를 잃 었 습니다 . ( 이 말 이 그 들 의 상상력 에 아무 문제 가 없 었 다는 뜻 은 아닙니다 . 그 들 은 여전히 이미지 를 만들 수 있 었 지만 , 새로운 무언가 를 만들 기 보 다는 과거 의 장면 을 반복 하 는 경향 이 있 었 습니다 . ) 때문 에 동기 를 잃 었 습니다 . ( 이 말 이 그 들 의 상상력 에 아무 문제 가 없 었 다는 뜻 은 아닙니다 . 그 들 은 여전히 이미지 를 만들 수 있 었 지만 , 새로운 무언가 를 만들 기 보 다는 과거 의 장면 을 반복 하 는 경향 이 있 었 습니다 . ) 사회 적 으로 적대 적 인 두 번 째 그룹 은 다른 이 의 글 과 자신 의 글 을 비교 하 기 싫 다 는 이유 로 동기 를 잃 었 습니다 . ( 그 들 모두 가 남 의 비판 을 두려워한 것 은 아니 었 습니다 . 어떤 이 는 자신 이 “ 시기 의 대상 ” 이 되 는 것 이 싫 다고 말 했 습니다 . ) 이 들 의 몽상 능력 은 대체로 온전 했 지만 , 이 들 은 그 능력 의 대부분 을 다른 사람 들 과 의 관계 를 상상 하 는 데 사용 했 습니다 . 는 이유 로 동기 를 잃 었 습니다 . ( 그 들 모두 가 남 의 비판 을 두려워한 것 은 아니 었 습니다 . 어떤 이 는 자신 이 “ 시기 의 대상 ” 이 되 는 것 이 싫 다고 말 했 습니다 . ) 이 들 의 몽상 능력 은 대체로 온전 했 지만 , 이 들 은 그 능력 의 대부분 을 다른 사람 들 과 의 관계 를 상상 하 는 데 사용 했 습니다 . 무감각 이 특징 인 세 번 째 그룹 은 창의력 의 감소 가 가장 크 게 나타난 그룹 입니다 . 그 들 은 몽상 을 하 지 못했 습니다 . 또한 자신 만 의 생각 을 떠올리 지 도 못했 고 자신 이 지켜야 하 는 “ 규칙 ” 이 너무 빡빡 하 다고 느꼈 습니다 . 이 들 에게 는 사실 동기 가 거의 존재 하 지 않 았 습니다 . 분노 와 실망 으로 대표 되 는 마지막 네 번 째 그룹 은 외부 의 동기 를 찾 으려는 경향 이 있 었 습니다 . 그 들 은 외부 의 보상 과 관심 을 원했 고 이 에 영향 을 받 았 습니다 . 배 리오스 와 싱어 는 이 들 이 보다 자아도취 적 이 며 그 들 이 가진 나르시시즘 이 그 들 작품 의 특징 이 라는 사실 을 발견 했 습니다 . 그 들 은 자신 이 상상 한 이미지 들 을 밝히 지 않 았 으며 이 를 자신 만 의 것 으로 두 려 했 습니다 . 어떻게 빠져 나올 것 인가 어떤 면 에서 , 배 리오스 와 싱어 의 발견 은 버글 러 의 이론 을 기억나 게 합니다 . 그 들 은 작가 가 벽 에 부딪혔 을 때 느끼 는 여러 현상 들 이 일종 의 정신과 적 인 문제 라는 사실 을 발견 했 습니다 . 마치 불행 한 작가 는 각자 자신 만 의 방식 으로 불행 하 며 , 이 를 회복 하 기 위해서 는 각자 의 감정 적 문제 를 치료 해야 만 하 는 것 처럼 보입니다 . 그러나 배 리오스 와 싱어 는 정신 과 의사 가 아니 라 심리학자 였으며 , 그 들 은 작가 의 벽 을 실험 적 으로 측정 할 수 있 는 방법 으로 계속 연구 하 기 로 마음 먹 었 습니다 . 그 들 은 작가 가 마음 속 에 그리 는 이미지 의 생생 함 과 내용 에 관심 을 가졌 습니다 . 이 들 은 마음 속 에 이미지 를 그리 도록 유도 하 는 단순 한 치료 방법 을 고안 했 습니다 . 배 리오스 와 싱어 는 벽 에 부딪힌 작가 들 에게 일련 의 과정 을 통과 할 경우 다양 한 색깔 을 가진 이미지 를 상상 할 수 있 게 한 실험 에 참여 할 것 을 부탁 했 습니다 . 작가 들 은 어두침침 하 고 조용 한 방 에 앉 아 그 들 에게 마치 꿈 에서 만들 어 진 듯 한 내용 을 상상 하 고 설명 하 게 만드 는 10 개 의 지문 을 들 었 습니다 . 예 를 들 어 , 그 들 은 음악 한 소절 , 혹은 자연 에서 일어날 수 있 는 특별 한 상황 을 시각 화 해야 했 습니다 . 그 후 , 그 들 은 자신 이 지금 해야 하 지만 벽 때문 에 막혀 있 는 일 중 한 가지 를 시각 화 했 고 , 이 와 관련 한 “ 꿈 같 은 경험 ” 을 상상 했 습니다 . 이 치료 는 2 주간 지속 되 었 습니다 . 이 방법 은 어느 정도 성공 적 이 었 습니다 . 치료 에 참가 한 작가 들 의 글쓰기 능력 은 향상 되 었 고 그 들 스스로 도 자신감 과 동기 를 얻 었 습니다 . 이 방법 이 모든 이 들 을 낫 게 한 것 은 아니 지만 , 적어도 창의력 이 고갈 되 었 다고 생각 한 이 들 에게 도 자신 의 창의력 이 남 아 있 다는 것 을 보일 수 있 었 습니다 ( 그린 의 꿈 일기 역시 그린 에게 같 은 일 을 한 것 입니다 ) . 여러 작가 에게 이 치료 는 그 들 이 느끼 는 증상 을 완화 시켰 고 , 치료 가 끝난 뒤 에 도 그 효과 는 계속 되 었 습니다 . 적어도 버글 러 는 부분 적 으로 는 맞 았 던 것 입니다 . 심리 적 인 벽 은 실제로 존재 했 습니다 . 그러나 작가 의 벽 을 이기 기 위해 작가 는 자신 의 감정 적 인 삶 을 바꾸 어야 한다는 버글 러 의 생각 은 틀렸 습니다 . 사실 배 리오스 와 싱어 의 실험 은 그 와 는 정반대 의 것 이 었 습니다 . 즉 창의력 과 관련 된 부분 만 을 건드리 는 것 으로 벽 의 원인 으로 보이 는 불안 을 줄이 고 또 한 자신 감 과 동기 를 키울 수 있 는 것 으로 드러난 것 입니다 . 치료 가 창의력 을 해제 했 다기 보 다는 창의력 훈련 이 일종 의 치료 처럼 작용 한 것 입니다 . 어쩌면 위 의 실험 같 은 직접 적 인 이미지 훈련 만 이 아니 라 모든 종류 의 창의 적 인 일 을 배우 는 것 은 작가 가 벽 을 이기 는 데 도움 을 줄지 모릅니다 . 창조 는 수많 은 실패 를 동반 하 며 , 목표 에 이르 기 전 까지 는 어디 로 가 고 있 는지 모른다 펜 실베 니아 대학 상상력 연구소 과학 소장 이 자 심리학자 이 며 『 타고난 창조자 ( wired to create ) 』 의 공저자 인 스콧 배리 카우프만 은 이렇게 말 합니다 . “ 작가 의 벽 을 만난다면 그저 종이 에 어떤 아이디어 나 지식 등 , 무엇 이건 써 보 는 것 이 도움 이 될 겁니다 . ” 2009 년 카우프만 은 『 창조 적 글쓰기 의 심리학 』 이 라는 책 의 편집 에 참여 했 습니다 . 그 는 그 과정 에서 실수 를 허용 하 는 것 , 그리고 창조성 은 비 선형 적 인 과정 이 라는 것 을 깨닫 는 것 이 작가 의 벽 을 넘 는 데 필수 적 이 라는 사실 을 확신 하 게 됩니다 . “ 나 는 작가 가 글쓰기 과정 에 대한 신뢰 를 가져야 한다고 생각 합니다 . 창조성 은 비 선형 성 과 그 고유 의 연관 된 조합 들 을 필요 로 한다는 사실 을 이해 해야 합니다 . 창조 적 인 사람 들 은 수많 은 시도 와 실패 를 하 며 , 자신 이 목표 에 도달 할 때 까지 는 자신 이 정확히 어디 를 가 고 있 는지 모르 는 경우 가 대부분 입니다 . ” 아마 이 말 이 작가 의 벽 에 대한 연구 에서 얻 을 수 있 는 마지막 메시지 로 보입니다 . 벽 에 부딪힌 작가 는 외적 , 그리고 내 적 비판 에서 잠시 동안 이 라도 벗어나 야 합니다 . 예 를 들 어 글쓰기 라면 , 꿈 일기 는 다른 이 에게 읽히 지 않 을 것 이 라는 사실 때문 에 이 에 적합 한 도구 입니다 . 이러 한 도피 는 작가 에게 불 확실 성 이 주 는 편안 함 을 선사 하 며 , 그 결과 이 들 은 비록 그 상상 이 우스꽝 스럽 고 , 무의미 하 고 , 자신 이 지금 해야 하 는 일 과 무관 한 일 이 라 하 더라도 이 를 상상 할 수 있 는 자유 를 얻 게 됩니다 . 그 린 은 한 때 다음 과 같 은 꿈 을 꾸 기 도 했 습니다 . 나 는 시 경연 대회 에 나가 아래 한 줄 을 썼 다 . ‘ 아름다움 은 죄 를 숭고 하 게 만든 다 . ’ 뒷자리 의 t . s . 엘리엇 이 나 를 비판 했 다 . ‘ 그게 무슨 말 이 지 ? 어떻게 죄 가 숭고 해질 수 있 지 ? ’ 나 는 그 가 턱수염 을 기른 것 을 보 았 다 . 현실 에서 라면 t . s . 엘리엇 이 당신 의 시 를 비판 할 경우 당신 은 자신 의 시 적 재능 을 의심 하 게 되 겠 지요 . 그러나 꿈 에서 는 그 반대 효과 를 만들 었 습니다 . 그 꿈 은 그대로 이야기 의 소재 가 되 었 습니다 . 그리고 적어도 이 이야기 는 , 우리 가 아무리 커다란 벽 에 부딪혔 더라도 여전히 새로운 무언가 ( 비록 그것 이 작 고 바보 같 은 일 이 라도 ) 를 상상 할 수 있 다는 것 을 알려 줍니다 . 원문 : 뉴스 페퍼민트 ( 1 편 / 2 편 )',\n",
       "       '지금 당장 나 를 변화 시키 는 사소 한 실천 의 마법 , 한번 해 보 기 엘리트 과정 거치 면서 소위 많이 배운 사람 일수록 도전 하 지 않 는다는 이야기 가 있 다 . 왜냐하면 , 그 들 은 엘리트 과정 을 밟 으면서 습득 한 지식 을 통해서 합리 적 인 선택 이 무엇 인지 알 고 , 실패 할 수 있 는 확률 이 최대한 낮 은 분야 에 지원 하 는 게 가장 좋 은 선택 이 라는 사실 을 머리 로 알 고 있 기 때문 이 다 . 도전 은 언제나 커다란 실패 라는 위험 요소 를 동반 한다 . 한 번 의 실패 로 그동안 투자 한 시간 과 돈 을 날릴 수 도 있 고 , 아무리 내 가 좋 아 하 는 일 로 가치 를 만들 어 내 는 일 을 하 더라도 인정받 지 못할 수 가 있 다 . 바보 같 은 사람 은 과정 이 즐겁 다고 말 하 지만 , 합리 적 인 사람 은 즐겁 지 않 다고 말 한다 . 어디 까지 이것 은 일반 적 인 사례 중 하나 일 뿐 이 다 . 엘리트 과정 을 거친 사람 이 위험 요소 가 있 는 분야 에 도전 할 수 도 있 고 , 평범 한 사람 이 더 실패 를 두려워해서 도전 하 지 않 을 수 도 있 다 . 다만 , 여기 서 이야기 하 고 싶 은 것 은 사람 은 한 번 해 보 는 사람 과 그렇 지 않 은 사람 으로 나누 어 진다는 것 이 다 . 한번 해 보 는 일 은 굉장히 쉬워 보이 면서 도 굉장히 어려운 일 이 다 . 실패 할 가능 성 이 크 다는 것 을 뻔히 알 면서 도 누가 쉽 게 해 볼 수 있 겠 는가 . 하지만 그렇 다고 해서 마냥 아무것 도 하 지 않 으면 우리 는 아무것 도 바꾸 지 못한다 . 이 세상 에 실패 확률 이 0 % 인 완벽 한 상황 은 없 다 . 그렇게 생각 하 지 않 는가 ? 경영 전문 대학원 , 즉 mba 로 유명 한 미국 밥슨 대학 의 로버트 론스타 트 박사 는 졸업 생 들 의 사업 성공 여부 를 조사 했 다 . 결과 는 실망 스러웠 다 . 사업 에 성공 한 사람 이 10 % 도 되 지 않 았 다 . 열정 을 바쳐 가르쳐온 선생 으로서 좀처럼 납득 할 수 가 없 었 다 . 그러 다 성공 그룹 과 실패 그룹 간 의 차이 를 발견 하 게 됐 다 . 성공 그룹 의 핵심 요인 은 ‘ 행동 ’ 이 었 다 . 그 들 은 ‘ 실제 ’ 사업 을 벌였 다 . 그러면 나머지 90 % 의 사람 들 은 어떻게 대답 했 을까 . 설문 기록 에 의하 면 그 들 다수 는 ‘ 기다리 는 중 ’ 이 라는 표현 을 썼 다 . 우수 한 대학원 에 입학 해 함께 교육 을 받 았 지만 성공 하 지 못한 그룹 은 모든 것 이 완벽 해질 상황 만 을 기다리 고 있 었 던 것 이 다 . – 본문 94 p 이번 에 나 는 제목 부터 상당히 끌리 는 매력 적 인 책 을 만났 다 . 위 사진 에서 볼 수 있 는 < 나 는 고작 한 번 해 봤 을 뿐 이 다 > 책 은 제목 자체 가 우리 독자 에게 어떤 메시지 를 던지 고 있 는 것 같 다 . 고작 한 번 해 본 일 로 잘난 체 한다고 말 할지 도 모르 지만 , 고작 한 번 해 본 일 로 저자 는 책 까지 썼 다 . 놀랍 지 않 은가 ! 책 의 원고 를 쓴다고 해서 그 원고 가 글 로 만들 어 질 확률 은 얼마나 될까 . 그렇 지 않 아도 책 을 읽 지 않 는 사회 가 되 어 가 는 요즘 에 는 웬만 한 콘텐츠 로 책 을 출판 하 는 일 이 어렵 다 . 하지만 작가 는 그냥 한번 해 본 일 을 글 로 꾸준히 남겼 고 , 우연히 만난 사람 을 통해 한 번 글 을 올렸 다가 책 까지 냈 다고 한다 . 이 정도 면 ‘ 천운 을 타고났 다 . ’ 는 말 이 어울린다고 생각 하 는데 , < 나 는 고작 한 번 해 봤 을 뿐 이 다 > 책 을 통해서 저자 의 경험 을 쓴 글 을 읽 어 보 면 그런 운 또한 저자 의 작 은 실천 이 있 었 기 에 가능 했 다 . 알 수 도 있 는 사람 에게 한 번 말 을 걸 어 보 고 , 그러 다 나온 이야기 를 한번 실천 해 본 게 나비 효과 처럼 번진 것 이 다 . 저자 는 그런 작 은 과정 을 ‘ 점 ’ 이라고 말 한다 . 우리 가 거쳐온 모든 과정 이 점 으로 남 아 있 고 , 그 점 이 연결 되 어 길 이 된다고 말 한다 . 어떤 일 이 라도 실패 할 가능 성 은 열려 있 고 , 실패 하 면 조롱 을 받 을 수 도 있 다 . 하지만 한 번 해 보 면 경험 이 사람 을 만날 수 있 게 하 고 , 기회 라는 운 을 만날 수 있 게 해준다 . 미국 의 대표 적 영화 제작사 인 골드윈 픽처스 의 창업자 인 새뮤얼 골드윈 은 “ 행운 이 란 기회 를 알아보 는 감각 이 며 그것 을 이용 하 는 능력 이 다 ” 라고 말 했 다 . 이것 은 과거 의 경험 으로부터 끌어내 는 유추 능력 에서 비롯 된다 . 이 를 통해 ‘ 전 에 도 그랬 으니까 이번 에 도 그럴 수 있 다 ’ 라고 상상 할 수 있 게 된다 . 불 확실 성 에 대한 불안감 이 상대 적 으로 낮 은 데 다 , 과거 의 성공 경험 이 심리 적 후원자 역할 을 한다 . 행동 으로 이어질 확률 이 높 아 질 수 밖에 없 었 다 . 잘 나가 는 사람 들 의 이야기 . 게다가 우연 까지 더 한 이야기 를 들으면 질투 가 생길 법 하 다 . ‘ 왜 나 에게 는 우연 한 기회 가 오 지 않 을까 ? ’ 하 며 말 이 다 . 그러나 많 은 성공 사례 가 증명 하 고 있 다 . 기회 라는 문 은 무수히 작 은 실천 을 통해 마치 우연 인 듯 열린다 . 그래서 작 은 실천 의 시작 , 무엇 이 든 ‘ 한 번 ’ 하 겠 다는 태도 가 중요 하 다 . 엄밀히 말 해 기회 는 오 는 게 아니 라 찾아가 는 것 이 다 . – 본문 70 p 실패 가 무서운 사람 들 에게 < 나 는 고작 한 번 해 봤 을 뿐 이 다 > 의 전반부 는 이렇게 한번 해 보 는 일 의 힘 을 말 하 고 , 중 · 후반부 는 저자 개인 이 겪 은 경험 과 다른 사람 들 의 ‘ 한 번 하 기 ’ 로 성공 한 사례 를 말 한다 . 나 는 책 을 읽 으면서 처음 에 는 ‘ 역시 뭐 든지 해 보 는 게 중요 하 다 ’ 고 생각 했 고 , 뒤 에서 는 하 더라도 무엇 이 필요 한지 알 수 있 었 다 . 때때로 우리 가 한 번 해 보 는 일 은 혼자 의 힘 으로 할 수 있 는 게 아니 라 조언 을 구해야 하 는 일 이 있 다 . 특히 자기 일 을 꾸준히 유지 해 나가 는 데 에 전문가 의 의견 이 대단히 참고 될 수 있 다면 , 우리 는 그 분야 의 전문가 에게 메일 을 보내 어서 한 번 도움 을 요청 하 는 과감 한 행동 이 필요 하 다 . 물론 , 그 과정 에서 는 분명히 거절 을 당할 수 도 있 다 . 저자 는 ‘ 거절 당할 줄 아 는 용기 ’ 가 필요 하 다고 말 하 면서 그 과정 에 는 진정 성 이 필요 하 다고 말 한다 . 단지 ‘ 당신 은 이 분야 에 성공 했으니 , 작 은 도움 을 달 라 ’ 가 아니 라 자신 이 왜 정말 조언 이 필요 하 고 , 도움 이 필요 한지 말 해 보 는 것 이 중요 하 다는 것 이 다 . < 나 는 고작 한 번 해 봤 을 뿐 이 다 > 를 읽 으면서 ‘ 나 는 과연 그렇게 할 수 있 었 을까 ? ’ ‘ 내 가 한 작 은 시도 에서 실패 한 원인 은 뭐 지 ? ’ ‘ 지금 내 가 할 수 있 는 작 은 실천 은 무엇 이 있 을까 ? ’ 는 생각 을 할 수 있 었 다 . 지금 블로그 를 통해 생업 을 유지 하 고 , 내 꿈 을 위해서 지금 실천 할 수 있 는 작 은 일 은 무엇 이 있 을까 ? 책 을 다 읽 은 후 에 ‘ 그래서 나 는 어떻게 하 고 싶 지 ? ’ 이 라는 질문 을 할 수 있 게 해 주 는 책 은 정말 좋 은 책 이 다 . < 나 는 고작 한 번 해 봤 을 뿐 이 다 > 를 읽 은 후 에 나 는 그런 질문 을 할 수 있 었 고 , 내 가 할 수 있 었 을지 도 모르 는 데 하 지 않 은 작 은 실천 과 도전 을 돌이켜 보 며 해야 할 일 을 고민 했 다 . 나 도 실패 는 무섭 다 . 사람 들 이 좋 은 기업 에 취업 하 지 않 고 , 글 을 쓰 면서 먹 고 살 려고 한다면 누구 나 다 걱정 을 한다 . 그게 돈 이 되 겠 냐고 . 아무리 꿈 이 고 , 도전 이 라고 해도 일장춘몽 이 아니 냐고 . 하지만 그렇 다고 해서 한 번 해 보 지 도 않 고 , 가망 이 없 다고 지레짐작 해서 포기 하 고 싶 지 는 않 았 다 . 한번 블로그 에 글 을 쓰 기 시작 했 을 뿐 인데 , 2011 년 도 에 블로거 대상 후보 로 투표 자리 에 오르 기 도 했 고 , 다양 한 sns 활동 을 통해서 더 많 은 책 과 멋진 사람 들 을 만나 기 도 했 다 . 블로그 에 글 을 쓰 지 않 았 다면 이룰 수 없 었 던 일 이 다 . 지금 도 계속 쌓이 는 작 은 점 은 분명히 ‘ 길 ’ 이 되 고 있 다고 생각 한다 . 실패 가 무섭 고 , 목표 를 세우 려고 해도 너무 높 아 망설이 는 사람 에게 이 책 < 나 는 고작 한 번 해 봤 을 뿐 이 다 > 를 소개 해 주 고 싶 다 . 우리 는 그저 한번 해 보 는 것 으로 기회 라는 운 을 잡 을 수 도 있 고 , 새로운 인연 을 통해서 멋진 프로젝트 를 실행 할 수 도 있 다 . 꿈 은 작 은 실천 이 쌓여 이루어지 는 법 이 니까 . 실패 는 누구 에게 나 예외 없이 찾아온다 . “ 우리 는 그 들 의 사운드 가 맘 에 안 든다 . 쇼 비즈니스 업계 내 에서 그 들 에게 장래 는 없 다 ” 고 말 하 면서 레코드 스튜디오 대표 가 걷어찬 그룹 은 역대 최고 의 상업 적 성공 을 거둔 비틀즈 였 다 . 미키 마우스 의 아버지 월드 디즈니 는 ‘ 상상력 이 부족 하 다 ’ 는 이유 로 신문사 에서 해고 당했 다 . 컴퓨터 로 세계 를 바꾼 스티브 잡스 는 자신 이 창업 한 회사 에서 무참히 쫓겨난 적 이 있 다 . 우리 는 그 들 이 세상 에 알려 지 고 나 서 야 비로소 실패 역시 알려졌 다는 데 주목 할 필요 가 있 다 . 성공 의 뒷면 에 는 언제나 실패 가 있 다 . – 본문 215 p 원문 : 노지 의 소박 한 이야기',\n",
       "       '텐서 플로우 0 . 10 + 우분투 16 . 04 + cuda 8 . 0 + 파이썬 3 . 5 설치 이번 글 의 수명 이 길 지 는 않 을 것 으로 보인다 . 텐 서 플로우 는 rc 버전 이 고 , 그래픽 카드 또한 최신 이 고 , 우분투 16 . 04 도 방금 나온 최신 버전 이 고 , 파이썬 도 최신 버전 이 고 . 검증 하 지 않 은 것 들 이 모일 수 있 기 때문 에 설치 과정 에서 수많 은 시행착오 를 거칠 수 밖에 없 었 다 . 최신 이 어서 참고 할 사이트 도 많이 없 다 . 컴퓨터 사양 문제점 1 . 지포스 10 시리즈 는 pascal 방식 으로 제작 되 었 다고 한다 . 그래서인지 cuda 7 . 5 와 연동 하 면 정확도 가 떨어지 는 문제점 이 있 었 다 . 90 % 의 정확도 가 아니 라 10 % 의 정확도 로 나와서 경악 을 금치 못했 다 . 속도 는 무지 빨랐 다 . 2 . 텐 서 플로우 0 . 10 과 cuda 7 . 5 연동 이 잘 되 지 않 았 다 . 처음 에 는 괜찮 았 던 기억 이 있 는데 , 어느 순간 부터 는 충돌 이 발생 하 면서 설치 할 수 없 었 다 . cuda 8 . 0 설치 를 포기 해야 겠 다고 생각 하 면서 하위 버전 설치 에 꽤 나 주력 했었 다 . 3 . cuda 8 . 0 을 사용 하 려면 텐서 플로우 를 바이너리 버전 이 아니 라 소스 코드 버전 으로 설치 해야 한다 . 현재 시점 에서 는 텐서 플로우 0 . 10 에 대한 링크 가 없 어서 바이너리 버전 설치 는 불 가능 했 다 . 당연히 0 . 9 버전 을 설치 하 기 위해서 도 많이 애 를 썼었 다 . 소스 코드 버전 설치 는 컴파일 부터 진행 하 기 때문 에 해야 할 게 무척 많 아 진다 . 공통 사항 1 . 터미널 ( 콘솔 ) 단축키 : ctrl + alt + t 또는 ctrl + alt + f 1 처음 에 터미널 창 을 열 면 항상 ~ 폴더 에서 시작 한다 . ~ 폴더 는 사용 자 의 홈 폴더 를 말 하 고 , 어디 에 있 건 \" cd ~\" 명령 을 통해 항상 홈 폴더 로 이동 할 수 있 다 . 모든 설치 는 터미널 에서 진행 되 기 때문 에 그래픽 화면 이 전혀 사용 되 지 않 는다 . 화면 캡쳐 할 것 이 없 다는 뜻 이 다 . 입력 하 기 가 번거 롭 기 때문 에 본문 에 있 는 명령 을 붙여 넣 는 것 이 쉬울 것 이 다 . 터미널 에서 는 [ ctrl + c , ctrl + v ] 단축키 가 동작 하 지 않 으므로 , 마우스 오른쪽 버튼 메뉴 를 사용 해야 한다 . [ ctrl + alt + f 1 ] 은 그래픽 모드 로부터 완전히 벗어난 형태 의 터미널 을 생성 한다 . 모니터 전체 를 터미널 이 덮 는 모드 를 말 한다 . 이 와 같 은 전체 터미널 모드 는 엔 비디아 드라이버 를 설치 할 때 , 딱 한 번 만 사용 하 고 , 나머지 는 모두 [ ctrl + alt + t ] 를 사용 한다 . 2 . 명령 줄 자동 완성 파일 이름 을 입력 할 때 , tab 키를 누르 면 일치 하 는 파일 이름 을 자동 으로 입력 해 준다 . 파일 이름 을 여러 번 입력 하 기 때문 에 기억 하 면 매우 편리 하 다 . 간혹 동작 하 지 않 을 때 도 있 는데 , 잘 못 된 것 이 아니 라 리눅스 의 환경 문제 이 므로 , 그런 경우 에 는 차분 하 게 파일 이름 을 모두 입력 해야 한다 . 3 . 무한 로그인 에러 해결 방법 [ ctrl + alt + f 1 ] 단축키 를 사용 해서 터미널 로 이동 해서 다시 엔 비디아 드라이버 를 설치 하 면 된다 . 무한 로그인 에러 는 엔 비디아 드라이버 와 의 충돌 과정 에서 발생 하 기 때문 에 다시 설치 하 면 사라진다 . 이 에러 는 상상 을 초월 할 정도 의 유명 한 에러 인데 , 별의별 방법 으로 해결 을 하 려고 노력 했 지만 끝내 하 지 못했었 다 . 이 방법 을 알 고 있 었 다면 , 우분투 설치 횟수 를 25 회 정도 로 막 을 수 도 있 었 다 . 생각 할수록 화 가 난다 . 그래픽 화면 으로 넘어갈 때 는 [ alt + f 7 ] 단축키 . 다만 그 전 에 아래 명령 을 사용 해서 그래픽 모드 를 활성 화 시켜야 한다 . $ sudo service lightdm start 4 . 텍스트 파일 편집 경로 등 을 저장 하 기 위해 텍스트 파일 을 편집 하 게 되 는데 , 이 때 gedit 프로그램 을 사용 한다 . 파일 을 열 거나 저장 할 때 아래 와 같 은 경고 가 뜨 는데 , 설치 와 는 전혀 상관없 다 . 터미널 에서 그래픽 에 접근 하 는 과정 에서 표시 되 는 경고 일 뿐 이 다 . ( gedit : 27848 ) : ibus - warning **: the owner of / home / python - kim / . config / ibus / bus is not root ! ( gedit : 27848 ) : gtk - warning **: calling inhibit failed : gdbus . error : org . freedesktop . dbus . error . serviceunknown : the name org . gnome . sessionmanager was not provided by any . service files ** ( gedit : 27848 ) : warning **: set document metadata failed : metadata : : gedit - spell - enabled 속성 설정 은 지원 하 지 않 습니다 ** ( gedit : 27848 ) : warning **: set document metadata failed : metadata : : gedit - encoding 속성 설정 은 지원 하 지 않 습니다 ** ( gedit : 27848 ) : warning **: set document metadata failed : metadata : : gedit - position 속성 설정 은 지원 하 지 않 습니다 참고 사이트 1 . 성공 사이트 [ URL ] [ URL ] 순서 대로 정리 가 너무 잘 되 어 있 는 외국 사이트 . 텐서 플로우 kr 에 누가 올려놓 은 자료 인데 . . 일단 내 컴퓨터 와 는 궁합 이 너무 잘 맞 았 다 . 2 . 실패 사이트 [ URL ] 이 사이트 의 내용 에 대해서 는 매번 실패 를 했 지만 , crosstool . tlp 파일 을 수정 하 는 부분 만 있 으면 성공 할 거 라고 생각 한다 . 이 방식 은 그래픽 모드 에서 전혀 벗어나 지 않 기 때문 에 설치 된다고 하 면 이 방식 이 훨씬 낫 다 . 설치 명령 과 함께 에러 메시지 도 표시 하 기 때문 에 안심 하 고 진행 할 수 있 는 장점 도 있 다 . 엔 비디아 다운로드 헷갈리 지 않 게 미리 다운로드 받 아서 설치 가능 한 상태 로 만들 어 놓 고 시작 한다 . 순서 가 너무 많 아서 헷갈린다 . 윈도우 와 똑같이 다운로드 한 파일 은 다운로드 폴더 에 저장 된다 . 다운로드 한 파일 을 모두 홈 폴더 로 복사 하 자 . 나 같 은 리눅스 초보 는 홈 폴더 에서 작업 하 는 것 이 좋 다 . 리눅스 공부 는 설치 가 끝난 다음 에 하 도록 하 자 . 파일 복사 는 윈도우 와 동일 한 탐색기 를 사용 하 면 된다 . 1 . 드라이버 다운로드 ( 버전 367 . 44 ) 자신 의 그래픽 카드 에 맞 는 드라이버 를 다운로드 받 아야 한다 . 현재 버전 은 367 . 44 이 고 , linux 64 - bit 버전 이 어야 한다 . 64 비트 버전 이 보이 지 않 으면 , operatiing system 항목 에서 [ show all operating systems ] 메뉴 를 선택 한다 . 쉽 게 실행 할 수 있 도록 실행 모드 를 추가 한다 . 이제 실행 파일 처럼 더블클릭 으로 실행 할 수 있 는 상태 가 된다 . $ chmod + x nvidia - linux - x 86 _ 64 - 367 . 44 . run 2 . cuda 다운로드 ( 버전 8 . 0 rc ) 회원 가입 필수 그림 에 나와 있 는 것 처럼 정확 하 게 우분투 16 . 04 , 64 비트 버전 을 선택 한다 . 파일 을 다운로드 받 아서 설치 하 는 runfile ( local ) 까지 선택 한다 . 이 파일 의 확장자 는 run 이 다 . 현재 시점 에서 는 우분투 에 기본 설치 되 는 gcc 5 . 4 에 대한 패치 파일 이 별도 로 존재 한다 . 이 파일 까지 함께 받 는다 . 파일 2 개 에 대해 한 번 에 실행 권한 을 준다 . $ chmod + x cuda _ 8 . 0 . 27 _ linux . run cuda _ 8 . 0 . 27 . 1 _ linux . run 3 . cudnn 다운로드 ( 버전 5 . 1 library for linux ) 회원 가입 필수 다운로드 한 파일 의 압축 을 풀 고 , 외부 모듈 이 실행 할 수 있 도록 이동 하 고 접근 권한 을 바꾼다 . 압축 을 풀 면 현재 폴더 에 cuda 폴더 를 생성 하 고 그 안 에 파일 을 넣 어 둔다 . 여기 서 는 cuda 8 . 0 을 사용 하 기 때문 에 목표 폴더 이름 에 cuda - 8 . 0 이 들어간다 . 엔 비디아 설치 1 . 드라이버 설치 윈도우 와 같 은 그래픽 환경 에서 이 글 을 볼 것 이 다 . 그렇 다면 [ ctrl + alt + f 1 ] 을 눌러서 터미널 로 이동 한다 . 그래픽 화면 을 종료 하 고 그래픽 카드 를 구동 하 는 드라이버 를 설치 한다 . 드라이버 가 설치 되 면 , 게임 도 할 수 있 고 , 동영상 도 볼 수 있 고 , 그래픽 카드 를 사용 하 는 대부분 의 것 들 을 할 수 있 게 된다 . 내 경우 는 모니터 2 대 를 연결 해서 사용 할 수 있 게 되 었 다 . 드라이버 설치 가 끝나 면 , 컴퓨터 를 껐 다가 켠다 . ( 리부팅 ) 지금 보 는 화면 은 그래픽 화면 이 기 때문 에 터미널 모드 로 들어가 면 , 지금 보 는 설명 을 볼 수 없 다 . 외워도 좋 고 , 안 되 면 종이 에 써 놓 고 터미널 로 입장 하 자 . 드라이버 설치 할 때 여러 번 엔터 키 를 눌러야 한다 . accept 나 yes 와 같 은 긍정 적 인 것 들 만 선택 하 도록 한다 . 6 ~ 7 번 정도 필요 하 다 . $ sudo service lightdm stop $ sudo init 3 $ sudo . / nvidia - linux - x 86 _ 64 - 367 . 44 . run $ sudo reboot 드라이버 파일 에 실행 권한 을 주 지 않 았 다면 , 아래 명령 을 통해서 run 파일 을 구동 할 수 있 다 . 다만 파일 이름 을 자동 으로 완성 할 수 없 기 때문 에 직접 입력 해야 한다 . $ sudo sh nvidia - linux - x 86 _ 64 - 367 . 44 . run 2 . cuda 메인 설치 컴퓨터 가 새로 켜졌 다 . 터미널 모드 로 입장 해야 하 니까 , [ ctrl + alt + t ] 단축키 를 누른다 . 패치 파일 을 포함 한 2 개 파일 을 순서 대로 모두 설치 한다 . 메인 파일 에 만 -- override 옵션 이 붙 는다 . gcc 5 . 3 까지 만 인정 하 기 때문 에 이걸 무시 하 기 위해 추가 하 는 것 이 override 옵션 이 다 . 이걸 수정 하 기 위한 파일 이 패치 파일 이 다 . $ sudo . / cuda _ 8 . 0 . 27 _ linux . run -- override 드라이버 설치 와 마찬가지 로 실행 권한 을 주 지 않 았 다면 , 아래 명령 을 사용 한다 . $ sudo sh cuda _ 8 . 0 . 27 _ linux . run -- override 아래 에 빨간 글자 처럼 입력 한다 . \\' 엔터 \\' 라고 되 어 있 는 항목 은 default 값 을 사용 한다는 뜻 이 다 . 가장 중요 한 항목 은 두 번 째 에 있 는 361 . 77 드라이버 설치 문항 이 다 . yes 라고 입력 하 면 , 앞 에서 설치 한 최신 버전 을 덮 어 쓴다 . sample 은 설치 하 지 않 아도 되 지만 , cuda 가 설치 되 었 는지 sample 을 통해 확인 할 수 있 기 때문 에 설치 하 는 것 이 좋 다 . # - - - - ------------------------- 설치 내용 - - - - - - - - ------------------------- # do you accept the previously read eula ? accept / decline / quit : accept install nvidia accelerated graphics driver for linux - x 86 _ 64 361 . 77 ? ( y ) es / ( n ) o / ( q ) uit : n install the cuda 8 . 0 toolkit ? ( y ) es / ( n ) o / ( q ) uit : y enter toolkit location [ default is / usr / local / cuda - 8 . 0 ] : 엔터 do you want to install a symbolic link at / usr / local / cuda ? ( y ) es / ( n ) o / ( q ) uit : y install the cuda 8 . 0 samples ? ( y ) es / ( n ) o / ( q ) uit : y enter cuda samples location [ default is / home / python - kim ] : 엔터 installing the cuda toolkit in / usr / local / cuda - 8 . 0 . .. missing recommended library : libglu . so . missing recommended library : libx 11 . so missing recommended library : libxi . so missing recommended library : libxmu . so installing the cuda samples in / home / python - kim . .. copying samples to / home / python - kim / nvidia _ cuda - 8 . 0 _ samples now . .. finished copying samples . ============ summary ============ driver : not selected toolkit : installed in / usr / local / cuda - 8 . 0 samples : installed in / home / python - kim , but missing recommended libraries summary 에서 driver 는 설치 되 지 않 은 것 을 볼 수 있 다 . toolkit 은 설치 되 었 지만 , samples 는 설치 되 지 않 은 항목 이 있 다 . 361 . 77 드라이버 를 설치 할 때 , opengl 라이브러리 설치 를 물 어 보 는데 , 우리 는 설치 하 지 않 았 기 때문 에 opengl 샘플 도 설치 하 지 않 았 다는 뜻 이 다 . opengl 은 우분투 에서 그래픽 카드 와 충돌 나기 로 유명 하 다 . 우리 는 자연 스럽 게 설치 를 피했 다 . 3 . cuda 패치 설치 우분투 에 기본 으로 설치 된 gcc 5 . 4 버전 을 위한 패치 파일 을 실행 시킨다 . override 옵션 은 필요 없 다 . 설치 가 너무 간단 해서 신경 써서 입력 할 항목 이 없 다 . $ sudo . / cuda _ 8 . 0 . 27 . 1 _ linux . run 드라이버 설치 와 마찬가지 로 실행 권한 을 주 지 않 았 다면 , 아래 명령 을 사용 한다 . $ sudo sh cuda _ 8 . 0 . 27 . 1 _ linux . run # - - - - ------------------------- 설치 내용 - - - - - - - - ------------------------- # do you accept the previously read eula ? accept / decline / quit : accept enter cuda toolkit installation directory [ default is / usr / local / cuda - 8 . 0 ] : 엔터 installation complete ! installation directory : / usr / local / cuda - 8 . 0 4 . 환경 구성 라이브러리 와 cuda 를 사용 할 수 있 도록 경로 를 추가 한다 . 먼저 환경 파일 을 연다 . $ sudo gedit ~/. bashrc 아래 내용 은 . bashrc 파일 의 마지막 에 추가 한다 . export cuda _ home =/ usr / local / cuda - 8 . 0 export path =/ usr / local / cuda - 8 . 0 / bin ${ path : +:${ path }} export ld _ library _ path =/ usr / local / cuda - 8 . 0 / lib 64 ${ ld _ library _ path : +:${ ld _ library _ path }} 추가 한 내용 을 즉각 반영 한다 . $ source ~/. bashrc 5 . 드라이버 및 cuda 설치 확인 $ nvcc -- version nvcc : nvidia ( r ) cuda compiler driver copyright ( c ) 2005 - 2016 nvidia corporation built on wed _ may __ 4 _ 21 : 01 : 56 _ cdt _ 2016 cuda compilation tools , release 8 . 0 , v 8 . 0 . 26 $ nvidia - smi 터미널 에서 는 깔끔 하 게 출력 이 되 는데 , html 파일 에서 는 깨진다 . 감안 하 고 보 자 . tue aug 30 19 : 59 : 47 2016 + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ------------------------+ | nvidia - smi 367 . 44 driver version : 367 . 44 | | - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - -+----------------------+ | gpu name persistence - m | bus - id disp . a | volatile uncorr . ecc | | fan temp perf pwr : usage / cap | memory - usage | gpu - util compute m . | | = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = + = = = = = = = = = = = = = = = = = = = = = =+======================| | 0 geforce gtx 106 . .. off | 0000 : 01 : 00 . 0 on | n / a | | 33 % 33 c p 8 10 w / 130 w | 257 mib / 6064 mib | 0 % default | + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - -+----------------------+ + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ------------------------+ | processes : gpu memory | | gpu pid type process name usage | | = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ========================| | 0 2733 g / usr / lib / xorg / xorg 227 mib | | 0 3461 g compiz 28 mib | + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ------------------------+ 6 . cuda 샘플 구동 현재 폴더 ( 사용자 홈 ) 에 샘플 폴더 가 설치 되 고 , 이름 은 nvidia _ cuda - 8 . 0 _ samples . 이 폴더 안 에 들어가 면 여러 개 의 폴더 가 보이 는데 , 모두 cuda 로 확인 할 수 있 는 샘플 들 이 다 . 샘플 을 구동 하 는 규칙 은 모두 같 다 . 해당 폴더 로 이동 해서 make 명령 을 입력 하 고 , 생성 된 실행 파일 을 실행 시킨다 . $ cd nvidia _ cuda - 8 . 0 _ samples / 1 _ utilities / bandwidthtest / $ make \"/ usr / local / cuda - 8 . 0 \"/ bin / nvcc - ccbin g ++ - i . ./../ common / inc - m 64 - gencode arch = compute _ 20 , code = sm _ 20 - gencode arch = compute _ 30 , code = sm _ 30 - gencode arch = compute _ 35 , code = sm _ 35 - gencode arch = compute _ 37 , code = sm _ 37 - gencode arch = compute _ 50 , code = sm _ 50 - gencode arch = compute _ 52 , code = sm _ 52 - gencode arch = compute _ 60 , code = sm _ 60 - gencode arch = compute _ 60 , code = compute _ 60 - o bandwidthtest . o - c bandwidthtest . cu \"/ usr / local / cuda - 8 . 0 \"/ bin / nvcc - ccbin g ++ - m 64 - gencode arch = compute _ 20 , code = sm _ 20 - gencode arch = compute _ 30 , code = sm _ 30 - gencode arch = compute _ 35 , code = sm _ 35 - gencode arch = compute _ 37 , code = sm _ 37 - gencode arch = compute _ 50 , code = sm _ 50 - gencode arch = compute _ 52 , code = sm _ 52 - gencode arch = compute _ 60 , code = sm _ 60 - gencode arch = compute _ 60 , code = compute _ 60 - o bandwidthtest bandwidthtest . o mkdir - p . ./../ bin / x 86 _ 64 / linux / release cp bandwidthtest . ./../ bin / x 86 _ 64 / linux / release $ . / bandwidthtest [ cuda bandwidth test ] - starting . .. running on . .. device 0 : geforce gtx 1060 6 gb quick mode host to device bandwidth , 1 device ( s ) pinned memory transfers transfer size ( bytes ) bandwidth ( mb / s ) 33554432 12542 . 1 device to host bandwidth , 1 device ( s ) pinned memory transfers transfer size ( bytes ) bandwidth ( mb / s ) 33554432 12322 . 1 device to device bandwidth , 1 device ( s ) pinned memory transfers transfer size ( bytes ) bandwidth ( mb / s ) 33554432 141467 . 7 result = pass note : the cuda samples are not meant for performance measurements . results may vary when gpu boost is enabled . 7 . cudnn 설치 이건 설치 할 게 없 다 . 다운로드 한 파일 을 압축 을 풀 어서 복사 해서 붙여 넣 기 만 하 면 된다 . 앞 에서 cuda 샘플 을 구동 하 기 위해 샘플 폴더 로 이동 했 기 때문 에 홈 폴더 로 이동 하 는 것 까지 포함 한다 . $ cd ~ $ tar xvzf cudnn - 8 . 0 - linux - x 64 - v 5 . 1 . tgz $ sudo cp cuda / include / cudnn . h / usr / local / cuda - 8 . 0 / include / $ sudo cp cuda / lib 64 / * / usr / local / cuda - 8 . 0 / lib 64 / 텐서 플로우 설치 1 . 파이썬 환경 구축 우분투 16 . 04 에 는 파이썬 2 . 7 과 3 . 5 가 모두 설치 되 어 있 다 . 최신 버전 을 무조건 좋아하 기 때문 에 여기 서 는 3 . 5 버전 을 중심 으로 얘기 한다 . 일단 텐서 플로우 설치 에 사용 할 파이썬 도구 를 설치 한다 . 혹시 라도 이번 명령 이 동작 하 지 않 으면 , 바로 아래 있 는 [ 자바 jdk 설치 ] 를 먼저 진행 하 기 바란다 . 컴퓨터 를 껐 다 켜 게 되 면 , 설치 중 인 정보 가 날아가 서 이번 명령 이 실패 할 수 도 있 다 . 이때 , [ 자바 jdk 설치 ] 가 정보 를 복구 해 줄 수 도 있 다 . 파이썬 3 . 5 $ sudo apt - get install python 3 - pip python 3 - numpy swig python 3 - dev python 3 - wheel 파이썬 2 . 7 $ sudo apt - get install python - pip python - numpy swig python - dev python - wheel 2 . 자바 jdk 설치 텐서 플로우 를 빌 드 하 기 위해 jdk 를 먼저 설치 해야 한다 . bazel 에서 필요 로 한다 . 이 부분 은 파이썬 버전 과 상관 이 없 다 . $ sudo add - apt - repository ppa : webupd 8 team / java $ sudo apt - get update $ sudo apt - get install oracle - java 8 - installer 3 . bazel 설치 bazel 은 구글 내 에서 사용 하 는 프로젝트 를 빌 드 하 기 위한 범용 도구 이 다 . 여기 서 는 텐서 플로우 를 빌 드 하 기 위해 사용 한다 . 이번 명령 이 좀 길기 는 하 지만 , 복사 해서 붙여 넣 기 할 거 니까 빠지 지 않 도록 조심 한다 . 리눅스 명령 에 익숙 하 면 분리 할 수 도 있 는데 , 좀 해 봤 는데 . . 잘 안 됐 다 . 나중 에 고민 하 도록 하 자 . $ echo \" deb [ arch = amd 64 ] [ URL ] stable jdk 1 . 8 \" | sudo tee / etc / apt / sources . list . d / bazel . list $ curl [ URL ] | sudo apt - key add - $ sudo apt - get update && sudo apt - get install bazel $ sudo apt - get upgrade bazel 4 . 텐 서 플로우 소스 코드 다운로드 git 을 설치 한다 . 혹시 설치 되 어 있 다면 , 당연히 건너뛰 어도 된다 . $ sudo apt install git 텐 서 플로우 소스 코드 저 장소 구축 $ git clone - b r 0 . 10 [ URL ] 5 . crosstool 파일 수정 이 부분 이 가장 중요 하 게 생각 된다 . 실제로 이전 에 시도 한 수 없이 많 은 방법 중 에서 이 부분 을 제외 하 면 그다지 다를 것 이 없 었 다 . 그런데 , 동작 하 지 않 았 다 . 수정 할 파일 은 홈 폴더 의 \" tensorflow / third _ party / gpus / crosstool \" 폴더 에 있 는 crosstool . tpl 파일 이 다 . 파일 열기 $ sudo gedit ~/ tensorflow / third _ party / gpus / crosstool / crosstool . tpl 추가 할 내용 cxx _ builtin _ include _ directory : \"/ usr / local / cuda - 8 . 0 / include \" 추가 할 위치 ( 내 경우 엔 67 행 ) cxx _ builtin _ include _ directory : \"/ usr / lib / gcc / \" cxx _ builtin _ include _ directory : \"/ usr / local / include \" cxx _ builtin _ include _ directory : \"/ usr / include \" cxx _ builtin _ include _ directory : \"/ usr / local / cuda - 8 . 0 / include \" <----- 여기 추가 tool _ path { name : \" gcov \" path : \"/ usr / bin / gcov \" } 6 . bazel 환경 구축 먼저 tensorflow 폴더 로 이동한 다음 에 configure 파일 을 실행 시킨다 . 역시 빨간색 으로 처리 된 부분 을 정확 하 게 입력 하 도록 한다 . 파이썬 3 . 5 를 사용 하 기 때문 에 첫 번 째 항목 에서 python 3 이 라고 했 다 . 2 . 7 을 사용 한다면 아무 것 도 입력 하 지 않 으면 된다 . 구글 플랫 폼 의 두 번 째 항목 은 필요 없 기 때문 에 no 라고 입력 했 다 . 마지막 의 그래픽 카드 버전 이 가장 여려 운 데 , 기본 은 3 . 5 와 5 . 2 의 두 가지 다 . 1060 의 경우 6 . 1 로 입력 해야 하 는데 , 다음 주소 를 통해 그래픽 카드 의 버전 숫자 를 찾 을 수 있 다 . ( 그래픽 카드 버전 숫자 찾 기 로 이동 ) $ cd ~/ tensorflow $ . / configure please specify the location of python . [ default is / usr / bin / python ] : / usr / bin / python 3 do you wish to build tensorflow with google cloud platform support ? [ y / n ] n no google cloud platform support will be enabled for tensorflow do you wish to build tensorflow with gpu support ? [ y / n ] y gpu support will be enabled for tensorflow please specify which gcc should be used by nvcc as the host compiler . [ default is / usr / bin / gcc ] : 엔터 please specify the cuda sdk version you want to use , e . g . 7 . 0 . [ leave empty to use system default ] : 엔터 please specify the location where cuda toolkit is installed . refer to readme . md for more details . [ default is / usr / local / cuda ] : usr / local / cuda - 8 . 0 please specify the cudnn version you want to use . [ leave empty to use system default ] : 엔터 please specify the location where cudnn library is installed . refer to readme . md for more details . [ default is / usr / local / cuda - 8 . 0 ] : 엔터 please specify a list of comma - separated cuda compute capabilities you want to build with . you can find the compute capability of your device at : [ URL ] please note that each additional compute capability significantly increases your build time and binary size . [ default is : \" 3 . 5 , 5 . 2 \"]: 6 . 1 . .. info : all external dependencies fetched successfully . configuration finished 7 . 텐 서 플로우 설치 bazel 을 사용 해서 텐서 플로우 를 빌 드 한다 . 빌드 한 결과물 은 / tmp / tensor _ pkg 폴더 에 들어간다 . $ bazel build - c opt -- config = cuda / / tensorflow / tools / pip _ package : build _ pip _ package $ bazel - bin / tensorflow / tools / pip _ package / build _ pip _ package / tmp / tensorflow _ pkg 앞 에서 사용 한 결과물 을 pip 명령 을 통해 설치 한다 . 버전 2 와 버전 3 에서 파일 이름 이 다른데 , 중요 하 지 않 다 . 중요 한 것 은 / tmp / tensorflow _ pkg 폴더 에 있 는 파일 을 사용 해야 한다는 점 이 다 . 이름 을 외울 필요 는 없 다 . tensor 까지 입력 하 고 tab 키 를 누르 면 자동 완성 된다 . 파일 이 1 개 밖에 없 다 . 파이썬 3 . 5 $ pip 3 install / tmp / tensorflow _ pkg / tensorflow - 0 . 10 . 0 rc 0 - py 3 - none - any . whl 파이썬 2 . 7 $ pip install / tmp / tensorflow _ pkg / tensorflow - 0 . 10 . 0 rc 0 - py 2 - none - any . whl 8 . 텐 서 플로우 사용 아쉽 지만 , 우분투 를 재 시동 해야 한다 . 내 경우 는 그랬 다 . 조금 만 참 자 . 컴퓨터 가 새로 켜졌 다면 터미널 에 아래 와 같이 입력 해 보 자 . 파이썬 3 . 5 $ python 3 - c \\' import tensorflow \\' 파이썬 2 . 7 $ python - c \\' import tensorflow \\' 출력 결과 는 아래 와 같이 나와야 한다 . 만약 아무 것 도 출력 되 지 않 았 다면 , 실패 한 것 이 다 . 이 시점 에서 정말 많 은 눈물 을 흘려야 했 다 . 나타나 지 않 았 다면 , 우분투 를 다시 설치 하 는 것 부터 시작 하 면 된다 . 윈도우 는 그대로 둬 도 된다 . i tensorflow / stream _ executor / dso _ loader . cc : 108 ] successfully opened cuda library libcublas . so locally i tensorflow / stream _ executor / dso _ loader . cc : 108 ] successfully opened cuda library libcudnn . so locally i tensorflow / stream _ executor / dso _ loader . cc : 108 ] successfully opened cuda library libcufft . so locally i tensorflow / stream _ executor / dso _ loader . cc : 108 ] successfully opened cuda library libcuda . so . 1 locally i tensorflow / stream _ executor / dso _ loader . cc : 108 ] successfully opened cuda library libcurand . so locally 잘 됐 다면 진짜 코드 로 확인 을 해야 한다 . mnist 예제 를 돌려 보 자 . 파이썬 3 . 5 $ python 3 tensorflow / tensorflow / models / image / mnist / convolutional . py 파이썬 2 . 7 $ python tensorflow / tensorflow / models / image / mnist / convolutional . py 놀랍 게 도 1 시간 걸리 던 예제 가 불과 1 분 만 에 해결 됐 다 . 에러 는 0 . 8 *, 정확 도 99 . 2 % 의 훌륭 한 결과 를 보여 줬 다 . i tensorflow / stream _ executor / dso _ loader . cc : 108 ] successfully opened cuda library libcublas . so locally i tensorflow / stream _ executor / dso _ loader . cc : 108 ] successfully opened cuda library libcudnn . so locally i tensorflow / stream _ executor / dso _ loader . cc : 108 ] successfully opened cuda library libcufft . so locally i tensorflow / stream _ executor / dso _ loader . cc : 108 ] successfully opened cuda library libcuda . so . 1 locally i tensorflow / stream _ executor / dso _ loader . cc : 108 ] successfully opened cuda library libcurand . so locally successfully downloaded train - images - idx 3 - ubyte . gz 9912422 bytes . successfully downloaded train - labels - idx 1 - ubyte . gz 28881 bytes . successfully downloaded t 10 k - images - idx 3 - ubyte . gz 1648877 bytes . successfully downloaded t 10 k - labels - idx 1 - ubyte . gz 4542 bytes . extracting data / train - images - idx 3 - ubyte . gz extracting data / train - labels - idx 1 - ubyte . gz extracting data / t 10 k - images - idx 3 - ubyte . gz extracting data / t 10 k - labels - idx 1 - ubyte . gz i tensorflow / stream _ executor / cuda / cuda _ gpu _ executor . cc : 925 ] successful numa node read from sysfs had negative value ( - 1 ) , but there must be at least one numa node , so returning numa node zero i tensorflow / core / common _ runtime / gpu / gpu _ init . cc : 102 ] found device 0 with properties : name : geforce gtx 1060 6 gb major : 6 minor : 1 memoryclockrate ( ghz ) 1 . 759 pcibusid 0000 : 01 : 00 . 0 total memory : 5 . 92 gib free memory : 5 . 55 gib i tensorflow / core / common _ runtime / gpu / gpu _ init . cc : 126 ] dma : 0 i tensorflow / core / common _ runtime / gpu / gpu _ init . cc : 136 ] 0 : y i tensorflow / core / common _ runtime / gpu / gpu _ device . cc : 838 ] creating tensorflow device ( / gpu : 0 ) -> ( device : 0 , name : geforce gtx 1060 6 gb , pci bus id : 0000 : 01 : 00 . 0 ) initialized ! step 0 ( epoch 0 . 00 ) , 19 . 7 ms minibatch loss : 12 . 054 , learning rate : 0 . 010000 minibatch error : 90 . 6 % validation error : 84 . 6 % . .. . .. step 8400 ( epoch 9 . 77 ) , 7 . 2 ms minibatch loss : 1 . 596 , learning rate : 0 . 006302 minibatch error : 0 . 0 % validation error : 0 . 8 % step 8500 ( epoch 9 . 89 ) , 7 . 2 ms minibatch loss : 1 . 603 , learning rate : 0 . 006302 minibatch error : 0 . 0 % validation error : 0 . 8 % test error : 0 . 8 %',\n",
       "       \"우분투 에 엔 비디아 드라이버 를 설치 하 는 것 이 어렵 지 는 않 다 . 내 가 사용 한 버전 은 ubuntu 데스크 탑 16 . 04 lst 버전 이 다 . 이전 에 설치 과정 에서 로그인 무한 반복 의 쓴 맛 을 본 관계 로 그냥 겁 이 났었 다 . 일단 무한 반복 에 걸리 면 답 이 없 다 . 우분투 를 다시 설치 하 는 것 이 제일 좋 다 . 수많 은 구글링 을 통해 여러 방법 을 시도 했 는데 , 네 경우 에 는 벗어날 수 없 었 다 . 민트 ( mint ) 버전 에 설치 하 고 싶 었 는데 , 어느 순간 부터 cd 로부터 읽 어 오 지 못했 다는 에러 가 뜨 기 시작 해서 패 쓰 . 1 . 엔 비디아 웹 사이트 로부터 드라이버 다운로드 ( 여기 클릭 ) 자신 의 그래픽 카드 에 맞 는 버전 을 선택 한다 . 나 는 큰 맘 먹 고 구입 한 gtx 1060 . 파일 확장자 는 엄청 생소 한 run . 다운로드 한 파일 은 사용 하 기 편하 도록 home 폴더 로 옮기 는 것 이 좋 다 . 우분투 탐색기 를 사용 해서 드래그 앤 드롭 . [ 여기 서부터 외부 사이트 참고 ] [ URL ] 2 . blacklist the modules . open the blacklist . conf file . gedit 텍스트 편집기 로 blacklist . conf 파일 편집 아래 명령 을 실행 시키 려면 터미널 이 있 어야 한다 . 단축키 ctrl + alt + t . sudo gedit / etc / modprobe . d / blacklist . conf 3 . add the following modules in the file . 아래 내용 을 복사 해서 붙여 넣 으면 된다 . 그러나 , 내 경우 에 는 첫 번 째 항목 인 amd 76 x _ edac 는 이미 존재 하 기 때문 에 무시 했 다 . blacklist amd 76 x _ edac # this might not be required for x 86 32 bit users . blacklist vga 16 fb blacklist nouveau blacklist rivafb blacklist nvidiafb blacklist rivatv gedit 프로그램 에서 저장 버튼 누르 고 닫 기 . 저장 ctrl + s . 4 . 엔 비디아 의 모든 패키지 삭제 . 위 에서 열 었 던 터미널 창 에서 입력 sudo apt - get remove -- purge nvidia * 5 . 엔 비디아 드라이버 설치 를 위해서 는 디스플레이 매니저 ( display manager ) 를 종료 해야 함 . 앞 에서 열 어 놓 은 터미널 을 사용 하 면 안 됨 . gui 와 관계 없 는 터미널 생성 . 단축키 ctrl + alt + f 1 . f 1 부터 f 6 까지 사용 할 수 있 다 . ctrl + alt + f 7 은 윈도우 그래픽 화면 으로 이동 한다 . 사용자 아이디 와 암호 를 입력 해야 터미널 사용 이 가능 하 다 . 6 . 디스플레이 매니저 사용 중지 . lightdm 은 우분투 에 최초 설치 된 디스플레이 매니저 . sudo 는 관리자 모드 로 명령 을 실행 한다는 뜻 . sudo service lightdm stop 7 . 처음 에 run 파일 을 home 폴더 에 복사 했 다 . 현재 작업 중 인 터미널 에서 한글 을 입력 하 려면 뭔가 를 설치 해야 한다 . 이 부분 을 피하 려면 , 한글 입력 이 없 게 만들 어야 하 는데 인터넷 파일 은 ' 다운로드 ' 라는 한글 폴더 에 들어간다 . 다운로드 받 은 파일 을 실행 가능 한 상태 로 변경 한다 . chmod + x nvidia - linux - x 86 _ 64 - 361 . 42 . run run 파일 을 실행 한다 . 파일 이름 은 다운로드 받 은 파일 로 변경 한다 . 가장 쉬운 방법 은 n 까지 만 입력 하 고 tab 키를 누르 는 것 이 다 . home 폴더 에 n 으로 시작 하 는 파일 은 하나 밖에 없 다 . sudo . / nvidia - linux - x 86 _ 64 - 367 . 35 . run 8 . 설치 끝 나 면 디스플레이 매니저 를 시작 한다 . sudo service lightdm start 그래픽 으로 전환 ( ctrl + alt + f 7 ) . 컴퓨터 를 껐 다 켜 지 않 아도 동작 한다 . 9 . 설치 완료 및 검사 ctrl + alt + t 눌러서 터미널 창 을 열 고 , 아래 2 개 의 명령 을 입력 한다 . 여기 서 명령어 가 없 다는 등 의 메시지 가 뜨 면 실패 . 첫 번 째 는 텍스트 화면 에서 , 두 번 째 는 그래픽 화면 에서 스펙 을 표시 한다 . nvidia - smi nvidia - settings\",\n",
       "       '4541 . 664 a program analysis : theories and practices 제대로 작동 할 지 를 미리 검증 할 수 없 는 기계설계 는 없 다 . 제대로 서 있 을 지 를 미리 검증 할 수 없 는 건축 설계 는 없 다 . 인공물 들 이 자연 세계 에서 문제 없이 작동 할 지 를 미리 엄밀 하 게 분석 하 는 수학 적 기술 들 은 잘 발달 해 왔 다 . 뉴튼 역학 , 미적분 방정식 , 통계 역학 등 이 그러 한 기술 들 일 것 이 다 . 소프트웨어 에 대해서 는 어떤가 ? 작성 한 소프트웨어 가 제대로 실행 될 지 를 미리 엄밀 하 게 확인 해 주 는 기술 들 은 있 는가 ? 이 에 대한 답 이 프로그램 분석 ( static program analysis ) 기술 이 라는 이름 으로 모여 지 는 기술 들 이 다 . 그 동안 다양 한 이름 으로 다양 한 수준 에서 다양 한 필요 에 맞추 어 불리워 지 는 기술 들 을 모두 포섭 한다 : \" static analysis \", \" abstract interpretation \", \" type system \", \" software model checking \", \" data - flow analysis \", \" program logics and proof system \" 등 . 이 강좌 에서 는 정적 프로그램 분석 기술 들 의 이론 과 실제 를 익힌다 . 이 목표 를 위해서 두 부분 으로 구성 된다 . 강의 중심 lecture - based teaching : 위 의 모든 기술 들 을 아우를 수 있 는 가장 강력 한 틀 인 요약 해석 ( abstract interpretation ) 의 이론 과 실제 를 강의 와 숙제 를 통해서 익힌다 . : 위 의 모든 기술 들 을 아우를 수 있 는 가장 강력 한 틀 인 요약 해석 ( abstract interpretation ) 의 이론 과 실제 를 강의 와 숙제 를 통해서 익힌다 . 문제 중심 problem - based teaching : 문제 ( 숙제 ) 를 중심 으로 프로그램 분석 기술 의 이론 과 실제 를 익힌다 . preliminaries : abstract syntax , semantics , inductive definitions , logics and inference , fixpoints : abstract syntax , semantics , inductive definitions , logics and inference , fixpoints semantic formalisms : natural semantics , structural operational semantics , abstract machine semantics , denotational semantics : natural semantics , structural operational semantics , abstract machine semantics , denotational semantics abstract interpretation : abstraction , concretization , galois connection , correctness , fixpoint algorithms : abstraction , concretization , galois connection , correctness , fixpoint algorithms type - based analysis : monomorphic type system , polymorphic type system , effect system , unification : monomorphic type system , polymorphic type system , effect system , unification constraint - based analysis : set constraints , flow logics , constraint solving : set constraints , flow logics , constraint solving problems : design and development of static analyzers 성적 은 절대 평가 . 출석 100 % 는 필수 . 어쩔 수 없 는 경우 는 반드시 사전 허락 을 받 는다 . wk 1 preliminaries book 5 - 24 , slide 1 wk 2 semantic formalisms i book 25 - 50 , slide 2 slide 3 wk 3 semantic formalisms ii windskel - book slide 4 slide 5 wk 4 abstract interpretation i book 61 - 75 , slide 6 , slide 7 wk 5 abstract interpretation ii slide 8 , slide 9 wk 6 abstract interpretation iii book 74 - 108 , slide 10 - 1 , slide 10 - 1 b , wk 7 exam week mid - term projects wk 8 abstract interpretation iv slide 10 - 1 c wk 9 type - based analysis i slide 13 , slide 14 , slide 15 wk 10 type - based analysis ii slide 16 , slide 17 wk 11 exam week final projects wk * constraint - based analysis & model checking slide 18 , slide 19 , slide 20 , slide 21',\n",
       "       'lebesgue 적분 입문 동연 · 영상 과 함께 배우 는 lebesgue 적분 입문 cited 0 time in web of science cited 0 time in scopus export ris ( endnote ) csv ( excel ) text',\n",
       "       '들어가 며 probability thoery 는 machine learning 을 공부 하 기 전 에 필수 적 으로 이해 해야 하 는 개념 들 중 하나 이 다 . 이 글 에서 는 가장 기본 적 인 확률 개념 에 대해서 는 알 고 있 다고 가정 한다 . 예 를 들 어 independence , joint probability , marginal probability , conditional probability 등 기본 적 인 개념 이나 $ p ( x ) = \\\\ sum _ y p ( x , y ) $ 혹은 $ p ( x , y ) = p ( y | x ) p ( x ) $ 등 자주 사용 되 는 관계 등 에 대해서 는 이미 알 고 있 다고 생각 했 고 , 또한 random variable 등 에 대한 기본 적 인 지식 이 이미 존재 한다고 가정 하 고 글 을 작성 하 였 다 . 만약 이런 개념 들 에 대해 잘 알 지 못한다면 다른 글 이나 강의 등 을 통해 그 개념 들 을 먼저 이해 하 고 글 을 읽 으면 좋 다 . machine learning - probabilistic perspective 이전 글 에서 설명 했 던 머신 러닝 의 개념 을 다시 생각 해 보 자 . 머신 러닝 은 아래 그림 처럼 설명 할 수 있 다 . 이전 글 에서 나 는 머신 러닝 이 주어진 데이터 를 가장 잘 설명 하 는 ‘ 함수 ’ 를 찾 는 알고리즘 을 디자인 하 는 것 이 라 설명 했 다 . 그러나 머신 러닝 은 확률 의 관점 에서 도 설명 이 가능 하 다 . 머신 러닝 을 probability density 를 찾 는 과정 으로 생각 하 는 것 이 다 . 즉 , 함수 를 가정 하 는 것 이 아니 라 확률 분포 를 가정 하 고 , 적절 한 확률 분포 의 parameter 를 유추 하 는 과정 으로 생각 하 는 것 이 다 . 주어진 데이터 가 gaussian distribution 으로 drawn 되 었 다고 가정 하 고 , 데이터 와 현상 을 가장 잘 설명 하 는 mean 과 covariance 를 찾 는 과정 과 비슷 한 것 이 라고 생각 하 면 된다 . 즉 , 앞 에서 설명 한 방식 은 function parameter 를 찾 는 방식 이 라면 , 이제 는 probability density function parameter 를 찾 는 것 으로 바뀌 는 것 이 다 . maximum likelihood estimation ( mle ) 보다 자세 한 설명 을 하 기 에 앞서 , 몇 가지 개념 들 을 소개 하 고 넘어가 도록 하 겠 다 . maximum likelihood estimation ( mle ) 는 random variable 의 parameter 를 estimate 하 는 방법 중 하나 인데 , 오직 주어진 observation , 혹은 데이터 들 만 을 토대 로 parameter estimation 을 하 는 방법 이 다 . 가장 간단 한 예 를 들 어 보 자 . 만약 우리 가 $ p $ 의 확률 로 앞면 이 나오 고 $ 1 - p $ 의 확률 로 뒷면 이 나오 는 동전 을 던져서 $ p $ 를 예측 한다고 생각 해 보 자 . mle 로 $ p $ 를 계산 하 기 위해서 는 간단 하 게 앞면 이 나온 횟수 를 전체 횟수 로 나누 면 된다 . 보다 더 자세 한 설명 을 위해 알려 지 지 않 은 probability density function $ f _ 0 $ 가 있 다고 가정 해 보 자 . 그리고 $ x = ( x _ 1 , x _ 2 , x _ 3 , \\\\ ldots , x _ n ) $ 를 그 확률 로 생성 되 는 observation 이 라 하 자 ( 측정 한 데이터 라고 생각 하 면 된다 ) . 이제 density function 이 다음 과 같이 $\\\\ theta $ 로 parameterize 된 어떤 분포 의 family 라고 가정 해 보 자 . $\\\\{ f ( \\\\ cdot |\\\\ theta ) \\\\}$. 만약 observation $ x $ 가 주어진다면 , $\\\\ theta $ 의 값 만 알 수 있 다면 바로 $ f ( x |\\\\ theta ) $ 의 값 을 계산 할 수 있 는 것 이 다 . 만약 $ f $ 가 가우 시안 이 라면 $\\\\ theta $ 는 mean $\\\\ mu $ 와 covariance $\\\\ sigma $ 일 것 이 고 , bernoulli 라면 $ 0 \\\\ leq p \\\\ leq 1 $ 가 될 것 이 다 . 이렇게 정의 하 게 되 면 likelihood 는 다음 과 같이 정의 할 수 있 다 . $$\\\\ mathcal l ( \\\\ theta ; x _ 1 , x _ 2 , \\\\ ldots , x _ n ) = \\\\ mathcal l ( \\\\ theta ; x ) = f ( x |\\\\ theta ) = f ( x _ 1 , x _ 2 , \\\\ ldots , x _ n |\\\\ theta ) $$ maximum likelihood estimation ( mle ) 는 $\\\\ theta $ 를 estimate 하 는 방법 중 하나 로 , likelihood 를 최대 로 만드 는 값 으로 선택 하 는 것 이 다 . 만약 우리 가 선택 하 는 값 을 $\\\\ hat \\\\ theta $ 라고 적 는다면 , mle 는 다음 과 같 은 방식 으로 값 을 찾 는다 . $$\\\\ hat \\\\ theta = \\\\ arg \\\\ max _\\\\ theta \\\\ mathcal l ( \\\\ theta ; x ) = \\\\ arg \\\\ max _\\\\ theta f ( x |\\\\ theta ) $$ 참고 로 , 만약 observation 이 i . i . d . ( independent and identical distributed ) 하 다면 , $ f ( x |\\\\ theta ) = \\\\ prod _ i f ( x _ i |\\\\ theta ) $ 가 되 며 , 여기 에 log 를 씌우 면 덧셈 꼴 이 된다 . log 는 단조 증가함수 이 므로 , log 를 취했 을 때 최대 값 을 가지 는 지점 과 원래 최대 값 을 가지 는 지점 이 동일 하 고 , 보통 곱셈 보다 덧셈 이 계산 이 더 간편 하 므로 , 많 은 경우 에 likelihood 가 아니 라 log likelihood 를 사용 해 parameter estimation 을 계산 한다 . 다시 원래 얘기 로 돌아가 보 자 . mle 는 가장 간단 한 parameter estimation method 이 지만 , observation 에 따라 그 값 이 너무 민감 하 게 변한다는 단점 을 가지 고 있 다 . 다시 동전 던지 기 를 예 로 들 어 보 자 . 동전 던지 기 는 확률 과정 이 기 때문 에 극단 적 인 경우 로 $ n $ 번 을 던져서 앞면 이 $ n $ 번 이 나올 수 가 있 다 . 이 경우 mle 는 이 동전 은 앞면 만 나오 는 동전 이 라고 판단 해 버린다 . 만약 스팸 필터 를 만드 는데 연속 으로 스팸 이 아닌 메일 이 $ n $ 개 가 들어왔 다고 해서 모든 메일 이 스팸 이 아니 라고 할 수 있 을까 ? maximum a posteriori estimation ( map ) mle 의 단점 을 해결 하 기 위해 maximum a posteriori estimation ( map ) 이 라는 방법 을 사용 하 기 도 한다 . 이 방법 은 $\\\\ theta $ 가 주어지 고 , 그 $\\\\ theta $ 에 대한 데이터 들 의 확률 을 최대 화 하 는 것 이 아니 라 , 주어진 데이터 에 대해 최대 확률 을 가지 는 $\\\\ theta $ 를 찾 는다 . 수식 으로 표현 하 면 다음 과 같 다 . $$\\\\ hat \\\\ theta = \\\\ arg \\\\ max _\\\\ theta f ( \\\\ theta | x ) $$ mle 와 비교 해 map 는 보다 더 자연 스러운 결과 를 얻 게 된다 . mle 로 parameter estimation 을 하 게 되 면 오직 지금 주어진 데이터 만 을 잘 설명 하 는 parameter 값 을 찾 게 된다 . 그러나 앞서 예 를 든 것 처럼 만약 스팸 필터 를 만드 는데 연속 으로 스팸 이 아닌 메일 이 $ n $ 개 가 들어왔 다고 해서 모든 메일 이 스팸 이 아니 라고 할 수 있 을까 ? 우리 가 원 하 는 것 은 지금 까지 들어온 값 에 대해서 만 잘 설명 하 는 것 이 아니 라 보다 더 general 한 무언가 를 원한다 . 여러 paramter 들 중 에서 데이터 가 주어졌 을 때 가장 확률 이 높 은 $\\\\ theta $ 를 고를 수 있 다면 가장 좋 은 결과 를 얻 을 수 있 을 것 이 다 . 하지만 안타깝 게 도 map 를 계산 하 기 위해서 는 $ f ( \\\\ theta | x ) $ 가 필요 하 지만 우리 가 관측 할 수 있 는 것 은 오직 $ f ( x |\\\\ theta ) $ 뿐 이 다 . $ f ( \\\\ theta | x ) $ 를 구하 기 위해서 는 bayes ’ theorem 이 라는 새로운 개념 이 필요 하 다 . bayes ’ theorem bayes ’ theorem 은 $ p ( y | x ) $ 와 $ p ( x | y ) $ 의 관계 를 표현 하 는 식 이 다 . 식 의 꼴 은 매우 간단 하 지만 , 이 theorem 은 많 은 의미 를 가지 고 있 다 . thoerem 은 다음 과 같 다 . $$ p ( y | x ) = { p ( x | y ) p ( y ) \\\\ over p ( x ) } $$ 이때 $ f ( x |\\\\ theta ) $ 를 likelihood , $ f ( \\\\ theta ) $ 를 prior , 그리고 $ f ( \\\\ theta | x ) $ 를 posterior 라고 하 며 각각 은 observation ( likelihood ) , 현상 에 대한 사전 정보 ( prior ) , 주어진 데이터 에 대한 현상 의 확률 ( posterior ) 을 의미 한다 . 이 식이 중요 한 이유 는 우리 가 관측 할 수 있 는 데이터 이외 에 도 데이터 에 대한 적절 한 가정 이 있 다면 관측 한 데이터 만 을 사용 하 는 것 보다 더 우수 한 parameter estimation 을 가능 하 게 하 기 때문 이 다 . 다시 mle 와 map 로 돌아가 보 자 . bayes ’ theorem 을 사용 하 면 map 와 mle 의 관계 를 다음 과 같이 적 을 수 있 다 . $$\\\\ hat \\\\ theta = \\\\ arg \\\\ max _\\\\ theta f ( \\\\ theta | x ) = \\\\ arg \\\\ max _\\\\ theta \\\\ frac { f ( x |\\\\ theta ) f ( \\\\ theta ) }{ f ( x ) } = \\\\ arg \\\\ max _\\\\ theta \\\\ frac {\\\\ mathcal l ( \\\\ theta ; x ) f ( \\\\ theta ) }{ f ( x ) }$$ 이때 , $ f ( x ) $ term 은 $\\\\ theta $ 에 영향 을 받 는 term 이 아니 기 때문 에 다음 과 같이 적 을 수 있 다 . $$\\\\ hat \\\\ theta = \\\\ arg \\\\ max _\\\\ theta \\\\ mathcal l ( \\\\ theta ; x ) f ( \\\\ theta ) $$ 따라서 , 만약 $ f ( \\\\ theta ) $ 를 알 고 있 다면 , mle 가 아니 라 map 를 하 는 것 이 가능 하 다 . 즉 , $\\\\ theta $ 에 대한 assumption 을 사용 해 결과 를 더 향상 시킬 수 있 는 것 이 다 . 예 를 들 어 우리 가 시험 성적 의 gaussian distribution 을 estimation 하 고 있 다고 해 보 자 . 이 경우 mean 은 반드시 시험 점수 범위 안 에 포함 되 어야 하 고 , 그 값 을 벗어날 수 없 다 . 그리고 이전 시험 들 의 성적 을 살펴보 면 그 값 이 대체로 40 ~ 60 점 사이 에 몰려 있 다는 등 의 정보 가 있 다고 가정 해 보 자 . mle 로 는 이런 정보 를 활용 하 는 것 이 불 가능 하 지만 , $ f ( \\\\ theta ) $ 를 가정 하 고 , 이 를 사용 해 map 를 사용 할 수 있 게 된다 . 즉 , 만약 우리 가 데이터 에 대한 적절 한 가정 을 할 수 있 다면 더 나 은 추론 을 하 는 것 이 가능 한 것 이 다 . 이 를 prior 라고 한다 . 만약 우리 가 옳 은 prior 를 선택 하 게 된다면 mle 보다 map 가 좋 겠 지만 , 잘 못 된 prior 를 선택 하 게 된다면 오히려 성능 이 떨어질 수 도 있 다 . 쉽 게 생각 해 prior 는 일종 의 ‘ 선입견 ’ 이 다 . 선입견 으로 사람 을 판단 할 때 더 빠르 게 좋 은 선택 을 할 수 도 있 지만 ( 이 사람 은 xx 씨 에게 추천 을 받 았 으니 좋 은 인재 겠 구나 ) 잘못 된 선입견 으로 인해 나쁜 선택 을 할 수 도 있 다 ( 학교 가 s 대 가 아니 니 일 을 잘 못 하 겠 지 ) . 따라서 map 는 데이터 에 대한 정보 가 아무것 도 없 어도 되 는 mle 와 는 달리 , 데이터 에 대한 좋 은 prior 를 선택 하 는 것 이 매우 중요 하 다고 할 수 있 다 . 참고 로 , prior 가 uniform distribution 이 라면 mle 와 map 는 정확 하 게 같 은 문제 를 푸 는 것 과 같 다 . 정리 하 자면 , bayes ’ theorem 은 더 좋 은 가정 이 있 다면 더 좋 은 유추 를 할 수 있 음 을 보여 주 는 수식 이 다 . 많 은 machine learning technique 들 이 bayes theorem 에 근거 하 여 만들 어 졌으며 , 데이터 관측 과 데이터 에 대한 가정 을 통해 더 정확 한 추론 인 map 를 가능 하 게 만들 어 주 는 강력 한 방법론 이 기 도 하 다 . advanced topic : conjugate prior 보통 prior 는 exponential family 에서 고르 는 경우 가 많 다 . bernoulli , binomial , poisson , gaussian , laplace , gamma , beta distribution 등등 이 exponential family 에 속한다 . exponential family 를 많이 선택 하 는 이유 는 대부분 의 데이터 들 이 이 모양 을 띄 고 있 기 때문 이 기 도 하 며 , 만약 likelihood 가 exponential family 일 때 , prior 를 ‘ 좋 은 ’ exponential family 로 선택 하 게 되 면 posterior 와 prior 가 같 은 family 에 속하 게 되 기 때문 이 다 . 예 를 들 어 likelihood 가 bernoulli 라고 하 면 , prior 를 beta distribution 으로 선택 하 게 되 면 posterior 도 beta distribution 이 되 며 이 를 conjugate prior 라고 한다 . 변경 이력 2014 년 8 월 3 일 : 글 등록 2015 년 2 월 28 일 : 변경 이력 추가 , 구성 변경 및 내용 revise machine learning 스터디 의 다른 글 들',\n",
       "       '들어가 며 information theory 는 섀년 이 라는 걸출 한 천재 가 이룩 해 낸 매우 뛰어난 이론 이 다 . 이 이론 덕분 에 우리 는 이렇게 인터넷 도 할 수 있 고 , 무선 통신 도 할 수 있 는 것 이 다 . 이 이론 덕분 에 불 안정 한 noisy 한 channel 에서 도 유한 한 시간 안 에 우리 가 전달 하 고 싶 은 정보 를 전부 전달 할 수 있 다는 것 을 확신 할 수 있 고 , 이론 적 인 한계 값 까지 도출 이 가능 한 엄청난 이론 이 다 . machine learning 에서 도 이런 information theory 측면 에서 문제 를 바라보 는 경우 가 종종 있 는데 , entropy , mutual information , kl - divergence 등 이 그것 이 다 . 이 글 에서 는 그런 machine learning 의 관점 에서 많이 쓰이 는 기초 적 인 정보 이론 의 개념 들 을 짚 고 넘어가 볼까 한다 . entropy 엔트로피 는 ‘ 정보 ’ 의 단위 라고 할 수 있 다 . 어떤 distibution p ( x ) 에서 generate 되 는 discrete random variable x 가 있 다고 해 보 자 . 이 random variable x 가 전달 할 수 있 는 정보량 은 어떻게 계산 할 수 있 을까 . 여기 에서 ‘ 정보 ’ 란 얼만큼의 bit 가 있 어야 x 에 대한 정보 를 완벽 하 게 얻 을 수 있 는가 로 정의 해 보 자 . 예 를 들 어서 fair 한 동전 던지 기 의 정보량 은 1 이 다 . 한 비트 만 있 으면 반드시 그 동전 던지 기 의 distribution 을 서술 할 수 있 다 . 그러나 만약 fair coin 이 아니 라면 한 면 이 나올 확률 이 다른 면 이 나올 확률 보다 상대 적 으로 더 크 기 때문 에 한 비트 보다 도 더 적 은 정보 를 사용 해 값 을 맞추 는 것 이 가능 해진다 . 이런 정보 의 양 을 entropy 라는 것 으로 정의 하 게 되 는데 , 간단 하 게 생각 하 면 열역학 2 법칙 의 그 엔트로피 와 동일 하 다 . 즉 , 엔트로피 가 커질수록 불 확실 성 이 높 아 지 고 정보량 은 더 많 아 진다 . entropy 는 $ h ( x ) = - \\\\ sum _ x p ( x ) log _ 2 p ( x ) $ 로 정의 가 되 며 , 만약 p ( x ) 가 0 으로 가 면 $\\\\ log _ 2 p ( x ) $ 는 음 의 무한 으로 발산 하 지만 , p ( x ) 가 0 이 되 는 속도 가 더 빠르 기 때문 에 엔트로피 는 0 이 된다 . 그럼 왜 엔트로피 는 이런 꼴 을 하 게 되 는 것 일까 . 만약 우리 가 전체 n 개 의 object 들 이 있 고 , 이 object 들 이 k 개 의 bin 으로 나뉘 어 져 있 다고 해 보 자 . 그리고 i 번 째 bin 에 들어갈 수 있 는 object 의 개수 를 $ n _ i $ 라고 했 을 때 , object 들 이 bin 에 들어갈 수 있 는 permutation 의 개수 는 $ w = \\\\ frac { n ! }{\\\\ prod _ i n _ i ! }$ 와 같 으며 이 를 multiplicity 라고 한다 . 엔트로피 란 이 multiplicity 에 비례 하 는 , 정확히 는 log 를 취한 값 을 엔트로피 라고 하 게 된다 . 즉 entropy h 는 multiplicity w 에 대해 다음 과 같이 표현 된다 . $$ h = \\\\ frac { 1 }{ n }\\\\ ln w = \\\\ frac { 1 }{ n }\\\\ ln n ! - \\\\ frac { 1 }{ n }\\\\ sum _ i \\\\ ln n _ i ! $$ 이때 $\\\\ lim n \\\\ to \\\\ infty $ 라고 해 보 자 , 그러면 우리 는 stirling 근사 를 할 수 있 는데 이 는 $\\\\ ln n ! \\\\ simeq n \\\\ ln n - n $ 으로 주어진다 . 이 를 대입 해서 잘 정리 해 보 면 아래 와 같 은 식 을 얻 을 수 있 다 . $$ h = -\\\\ lim _{ n \\\\ to \\\\ infty } \\\\ sum _ i \\\\ left ( \\\\ frac { n _ i }{ n } \\\\ right ) \\\\ ln \\\\ left ( \\\\ frac { n _ i }{ n } \\\\ right ) = - \\\\ sum _ i p _ i \\\\ ln p _ i $$ 이 는 위 에서 정의 한 엔트로피 의 값 과 일치 한다 . 그런데 이 값 은 discrete 한 random variable 에 대해 정의 된 값 이 고 continous 한 random variable x 에 대해서 는 differencial entropy 라는 정의 할 수 있 다 . 평균값 정리 에 의해서 우리 는 다음 을 만족 하 는 value $ x _ i $ 를 반드시 찾 을 수 있 다 $$ \\\\ int _{ i \\\\ delta }^{( i + 1 ) \\\\ delta } p ( x ) dx = p ( x _ i ) \\\\ delta $$ 엔트로피 는 discrete 한 random variable 에 대한 값 이 었 는데 , 위 식 을 통해 continous variable x 를 위 의 식 을 만족 하 는 $ x _ i $ 로 치환 하 는 방식 으로 quantize 할 수 있 다 . 또한 이런 경우 각 $ x _ i $ 를 관측 할 확률 이 $ p ( x _ i ) \\\\ delta $ 로 계산 되 므로 , 이렇게 했 을 경우 엔트로피 는 아래 와 같이 계산 할 수 있 다 . $$ h _\\\\ delta = -\\\\ sum _ i p ( x _ i ) \\\\ delta \\\\ ln ( p ( x _ i ) \\\\ delta ) = - \\\\ sum _ i p ( x _ i ) \\\\ delta p ( x _ i ) - \\\\ ln \\\\ delta $$ 이때 , 오른쪽 term 은 x 에 대한 값 이 아니 니까 일단 먼저 무시 하 고 , $\\\\ lim \\\\ delta \\\\ to 0 $ 를 취해 보 자 . 이렇게 계산 할 경우 아래 식 이 얻 어 진다 . $$\\\\ lim _{\\\\ delta \\\\ to 0 } h _\\\\ delta = \\\\ lim _{\\\\ delta \\\\ to 0 } -\\\\ sum _ i p ( x _ i ) \\\\ delta \\\\ ln ( p ( x _ i ) \\\\ delta ) = -\\\\ int p ( x ) \\\\ ln p ( x ) dx $$ 이때 , 맨 오른쪽 term 을 differencial entropy 라고 정의 한다 . 즉 , differencial entropy 는 다음 과 같이 정의 된다 . $$ h ( x ) = -\\\\ int p ( x ) \\\\ ln p ( x ) dx $$ 마지막 으로 random variable 이 x , y 두 개 가 있 고 이 둘 의 joint distribution p ( x , y ) 가 있 다고 해 보 자 . 우리 가 알 고 있 는 정보 는 x 의 value 라고 했 을 때 우리 는 y 의 information 의 양 을 계산 할 수 있 을까 ? 이 를 conditional entropy 라고 하 는데 이때 y 에 대해 필요 한 additioanl information 은 $ p ( y | x ) $ 이 며 , x 와 y 의 확률 은 p ( x , y ) 이 므로 conditional entropy 는 아래 와 같이 정의 된다 . $$ h ( y | x ) = - \\\\ int \\\\ int p ( y , x ) \\\\ ln p ( y | x ) dy dx $$ 이 값 은 다음 과 같 은 chain rule 을 항상 만족 시킨다 . $$ h ( x , y ) = h ( y | x ) + h ( x ) $$ kl divergence 어떤 probability distribution p ( x ) 와 p ( y ) 가 있 다고 했 을 때 이 둘 의 차이 , 혹은 distance 를 정의 할 수 는 없 을까 . 예 를 들 어 p ( x ) 라는 우리 가 모르 는 unknown distribution 이 있 을 때 , 우리 가 추측 한 $ p ( \\\\ hat x ) $ 와 true distribution p ( x ) 가 얼마나 차이 나 는지 를 계산 할 수 있 는 방법 은 없 을까 . 만약 우리 가 q ( x ) 를 사용 해서 x 를 transmitting 하 는 coding scheme 을 construct 했 다고 해 보 자 . 그리고 true distribution 을 p ( x ) 였 다고 했 을 때 , q ( x ) 를 사용 하 였을 때 얼마나 더 많 은 정보량 이 필요 할 것 인지 measure 할 수 있 을 것 이 다 . 이 를 kullback - leibler divergence 혹은 kl divergence 라고 하 며 수식 은 아래 와 같 다 . $$ kl ( p \\\\|\\\\| q ) = - \\\\ int p ( x ) \\\\ ln q ( x ) - \\\\ left ( -\\\\ int p ( x ) \\\\ ln p ( x ) dx \\\\ right ) \\\\\\\\ = - p ( x ) \\\\ ln \\\\ left [ \\\\ frac { q ( x ) }{ p ( x ) } \\\\ right ] dx $$ 정확히 얘기 하 면 이 값 은 ‘ distance ’ 가 될 수 는 없 다 . 왜냐하면 distance , 혹은 metric 은 symmetric 해야 하 는데 kl divergence 는 $ kl ( p \\\\|\\\\| q ) eq kl ( q \\\\|\\\\| p ) $ 이 기 때문 이 다 . kl divergence 는 언제나 0 보다 크 거나 같 은데 , 같 은 경우 는 오직 p ( x ) 와 q ( x ) 가 일치 하 는 경우 뿐 이 다 . 이 를 증명 하 기 위해서 는 convexity 컨셉 과 jensen ’ s inequality 를 도입 하 면 쉽 게 증명 이 가능 하 지만 , 여기 에서 는 생 갹 하 도록 하 겠 다 . 중요 한 점 은 , kl divergence 는 두 distribution 의 차이 를 define 할 수 있 는 좋 은 수단 중 하나 라는 것 이 며 , 다시 말 해 원래 true distribution p ( x ) 와 우리 가 estimate 한 q ( x ) 가 얼마나 비슷 한지 를 measure 할 수 있 는 수단 이 라는 점 이 다 . mutual information mutual information 은 두 random variable 들 이 얼마나 mutual dependence 한지 를 measure 하 는 방법 을 의미 한다 . 만약 random variable x 와 y 가 independent 하 다면 joint distribution p ( x , y ) 는 p ( x , y ) = p ( x ) p ( y ) 로 주어지 게 될 것 이 며 , 만약 둘 이 dependent 한 경우 에 는 두 값 이 달라질 것 이 다 . 그렇 다면 만약 true distribution 을 p ( x , y ) 라고 했 을 때 , 새롭 게 우리 가 x 와 y 가 independent 하 다고 estimate 하 고 구한 p ( x ) p ( y ) 와 의 kl - divergence 를 구할 수 있 지 않 을까 ? 당연히 이 값 은 x 와 y 가 independent 할 때 만 0 이 고 그 이외 에 는 항상 0 보다 크 다 . 즉 , 두 random variable 이 얼마나 mutually dependent 한가 , 얼마나 mutual 하 게 information 을 많이 가지 고 있 느냐 를 측정 할 수 있 는 도구 가 되 므로 이 를 mutual information 이 라 한다 . 수식 으로 표현 해 보 면 아래 와 같 다 . $$ i ( x , y ) = kl ( p ( x , y ) \\\\|\\\\| p ( x ) p ( y ) \\\\\\\\ = - \\\\ int \\\\ int p ( x , y ) \\\\ ln \\\\ left ( \\\\ frac { p ( x ) p ( y ) }{ p ( x , y ) } \\\\ right ) dx dy $$ 위 의 값 을 mutual information 이 라 하 며 , 이 값 은 항상 다음 과 같 은 관계 를 만족 시킨다 . $$ i ( x , y ) = h ( x ) - h ( x | y ) = h ( y ) - h ( y | x ) $$ machine learning and information theory entropy 는 주어진 bin 에 얼마나 비슷 한 element 들 이 들 어 있 는지 를 측정 하 는 척도 로 쓰일 수 있 으며 , decision tree 를 learning 하 는 알고리듬 등 에서 도 사용 할 수 있 다 . 또한 kl - divergence 는 두 distribution 과 의 거리 를 의미 하 므로 , density estimation 관점 에서 바라봤 을 때 우리 가 estimate 하 는 distribution 과 원래 true distribution 이 얼마나 유사 한지 , 우리 가 얼마나 잘 density estimation 을 했 는지 evaluation 을 하 는 용도 등 으로 쓰일 수 있 다 . 마지막 으로 mutual information 을 bayes perspective 에서 바라보 게 된다면 , 만약 우리 가 어떤 데이터 x 의 prior p ( x ) 를 관측 하 고 , 새로운 데이터 y 를 관측 해 얻 은 posterior distribution p ( y | x ) 가 있 다고 했 을 때 , mutual information 은 이전 관측 x 를 통해 새로운 관측 y 의 uncertainty 가 얼마나 reduction 되 는지 를 의미 하 게 되 는 것 과 동일 하 다는 것 을 알 수 있 다 . 정보 이론 자체 는 machine learning 과 크 게 관계 가 없 어 보이 지만 , 그 개념 들 은 생각 보다 꽤 많 은 부분 에서 사용 되 게 되 므로 좀 간략 하 게 다루 게 되 었 다 . 추가 : 정보 이론 이 어떻게 머신 러닝 에 유용 하 게 쓰일 수 있 는가 에 대한 lecture 와 book link 들 [ 1 ] , [ 2 ] 변경 이력 2014 년 8 월 19 일 : 글 등록 2014 년 10 월 9 일 : 정보 이론 , 머신 러닝 렉 쳐 및 책 링크 등록 2015 년 2 월 28 일 : 변경 이력 추가 machine learning 스터디 의 다른 글 들',\n",
       "       '들어가 며 최근 machine learning 분야 에서 가장 뜨거운 분야 는 누가 뭐 래도 deep learning 이 다 . 엄청나 게 많 은 사람 들 이 관심 을 가지 고 있 고 , 공부 하 고 응용 하 고 있 지만 , 체계 적 으로 공부 할 수 있 는 자료 가 많이 없 다는 것 이 개인 적 으로 조금 안타깝 다 . 이제 막 각광 받 기 시작 한 지 10 년 정도 지났 고 , 매년 새로운 자료 들 이 쏟아져 나오 기 때문 에 책 이나 정리 된 글 을 찾 기 가 쉽 지 가 않 다 . 그러나 deep learning 은 결국 artificial neural network 를 조금 더 복잡 하 게 만들 어 놓 은 모델 이 고 , 기본 적 인 neural network 에 대한 이해 만 뒷받침 된다면 자세 한 내용 들 은 천천히 탑 을 쌓 는 것 이 가능 하 다고 생각 한다 . 이 글 에서 는 neural network 의 가장 기본 적 인 model 에 대해 다루 고 , model paramter 를 update 하 는 algorithm 인 backpropagation 에 대해서 다룰 것 이 다 . 조금 더 advanced 한 topic 들 은 이 다음 글 에서 다룰 예정 이 다 . 이 글 의 일부 문단 은 이전 글 들 을 참고 하 였 다 . motivation of neural network 이름 에서부터 알 수 있 듯 neural network 는 사람 의 뇌 를 본 따 서 만든 머신 러닝 모델 이 다 ( 참고 : 원래 neural network 의 full name 은 artificial neural network 이 지만 , 일반 적 으로 neural network 라고 줄여서 부른다 ) . 본격 적 으로 neural network 에 대해 설명 을 시작 하 기 전 에 먼저 인간 보다 컴퓨터 가 훨씬 잘 할 수 있 는 일 들 이 무엇 이 있 을지 생각 해 보 자 . 1 부터 10000000 까지 숫자 더하기 19312812931 이 소수 인지 아닌지 판별 하 기 주어진 10000 by 10000 matrix 의 determinant 값 계산 하 기 800 페이지 짜리 책 에서 ‘ 컴퓨터 ’ 라는 단어 가 몇 번 나오 는지 세기 반면 인간 이 컴퓨터 보다 훨씬 잘 할 수 있 는 일 들 에 대해 생각 해 보 자 다른 사람 과 상대방 이 말 하 고자 하 는 바 를 완벽 하 게 이해 하 면서 내 가 하 고 싶 은 말 을 상대 도 이해 할 수 있 도록 전달 하 기 주어진 사진 이 고양이 사진 인지 강아지 사진 인지 판별 하 기 사진 으로 찍 어 보낸 문서 읽 고 이해 하 기 주어진 사진 에서 얼마나 많 은 물체 가 있 는지 세 고 , 사진 에 직접 표시 하 기 컴퓨터 가 잘 할 수 있 는 0 과 1 로 이루어진 사칙 연산 이 다 . 기술 의 발달 로 인해 지금 은 컴퓨터 가 예전 보다 도 더 빠른 시간 에 , 그리고 더 적 은 전력 으로 훨씬 더 많 은 사칙 연산 을 처리 할 수 있 다 . 반면 사람 은 사칙 연산 을 컴퓨터 만큼 빠르 게 할 수 없 다 . 인간 의 뇌 는 오직 빠른 사칙 연산 만 을 처리 하 기 위해 만들 어 진 것 이 아니 기 때문 이 다 . 그러나 인지 , 자연어 처리 등 의 그 이상 의 무언가 를 처리 하 기 위해서 는 사칙 연산 그 너머 의 것 들 을 할 수 있 어야 하 지만 현재 컴퓨터 로 는 인간 의 뇌 가 할 수 있 는 수준 으로 그런 것 들 을 처리 할 수 없 다 . 예 를 들 어 아래 와 같이 주어진 사진 에서 각각 의 물체 를 찾아내 는 문제 를 생각 해 보 자 ( 출처 : 링크 ) . 사람 에게 는 너무나 간단 한 일 이 지만 , 컴퓨터 가 처리 하 기 에 는 너무나 어려운 일 이 다 . 어떻게 어디 부터 어디 까지 가 ‘ tv or monitor ’ 라고 판단 할 수 있 을까 ? 컴퓨터 에게 사진 은 단순 한 0 과 1 로 이루어진 픽셀 데이터 에 지나 지 않 기 때문 에 이 는 아주 어려운 일 이 다 . 그렇 기 때문 에 자연 언어 처리 , 컴퓨터 비전 등 의 영역 에서 는 인간 과 비슷 한 성능 을 내 는 시스템 을 만들 수 만 있 다면 엄청난 기술 적 진보 가 일어날 수 있 을 것 이 다 . 그렇 기 때문 에 인간 의 능력 을 쫓아가 는 것 이전 에 , 먼저 인간 의 뇌 를 모방 해 보 자 라는 아이디어 를 낼 수 있 을 것 이 다 . neural network 는 이런 모티베이션 으로 만들 어 진 간단 한 수학 적 모델 이 다 . 우리 는 이미 인간 의 뇌 가 엄청나 게 많 은 뉴런 들 과 그것 들 을 연결 하 는 시냅스 로 구성 되 어 있 다는 사실 을 알 고 있 다 . 또한 각각 의 뉴런 들 이 activate 되 는 방식 에 따라서 다른 뉴런 들 도 activate 되 거나 activate 되 지 않 거나 하 는 등 의 action 을 취하 게 될 것 이 다 . 그렇 다면 이 사실 들 을 기반 으로 다음 과 같 은 간단 한 수학 적 모델 을 정의 하 는 것 이 가능 하 다 . model of neural network : neuron , synapse , activation function 먼저 뉴런 들 이 node 이 고 , 그 뉴런 들 을 연결 하 는 시냅스 가 edge 인 네트워크 를 만드 는 것 이 가능 하 다 . 각각 의 시냅스 의 중요도 가 다를 수 있 으므로 edge 마다 weight 를 따로 정의 하 게 되 면 아래 그림 과 같 은 형태 로 네트워크 를 만들 수 있 다 . ( 출처 : 위키 ) 보통 neural network 는 directed graph 이 다 . 즉 , information propagation 이 한 방향 으로 고정 된다는 뜻 이 다 . 만약 undirected edge 를 가지 게 되 면 , 혹은 동일 한 directed edge 가 양방향 으로 주어질 경우 , information propagation 이 recursive 하 게 일어나 서 결과 가 조금 복잡 해진다 . 이런 경우 를 recurrent neural network ( rnn ) 이 라고 하 는데 , 과거 데이터 를 저장 하 는 효과 가 있 기 때문 에 최근 음성 인식 등 의 sequencial data 를 처리 할 때 많이 사용 되 고 있 다 . 이번 icml 2015 에서 도 rnn 논문 이 많이 발표 되 고 있 고 , 최근 들 어 연구 가 활발 한 분야 이 다 . 이 글 에서 는 일단 가장 간단 한 ‘ multi layer perceptron ( mlp ) ’ 라는 구조 만 다룰 것 인데 , 이 구조 는 directed simple graph 이 고 , 같 은 layer 들 안 에서 는 서로 connection 이 없 다 . 즉 , self - loop 와 parallel edge 가 없 고 , layer 와 layer 사이 에 만 edge 가 존재 하 며 , 서로 인접 한 layer 끼리 만 edge 를 가진다 . 즉 , 첫 번 째 layer 와 네 번 째 layer 를 직접 연결 하 는 edge 가 없 는 것 이 다 . 앞 으로 layer 에 대한 특별 한 언급 이 없 다면 이런 mlp 라고 생각 하 면 된다 . 참고 로 이 경우 information progation 이 ‘ forward ’ 로 만 일어나 기 때문 에 이런 네트워크 를 feed - forward network 라고 부르 기 도 한다 . 다시 일반 적 인 neural network 에 대해 생각 해 보 자 . 실제 뇌 에서 는 각기 다른 뉴런 들 이 activate 되 고 , 그 결과 가 다음 뉴런 으로 전달 되 고 또 그 결과 가 전달 되 면서 최종 결정 을 내리 는 뉴런 이 activate 되 는 방식 에 따라 정보 를 처리 하 게 된다 . 이 방식 을 수학 적 모델 로 바꿔서 생각 해 보 면 , input 데이터 들 에 대한 activation 조건 을 function 으로 표현 하 는 것 이 가능 할 것 이 다 . 이것 을 activate function 이 라고 정의 한다 . 가장 간단 한 activation function 의 예시 는 들어오 는 모든 input 값 을 더 한 다음 , threshold 를 설정 하 여 이 값 이 특정 값 을 넘 으면 activate , 그 값 을 넘 지 못하 면 deactivate 되 도록 하 는 함수 일 것 이 다 . 일반 적 으로 많이 사용 되 는 여러 종류 의 activate function 이 존재 하 는데 , 몇 가지 를 소개 해 보 도록 하 겠 다 . 편의 상 $ t = \\\\ sum _ i w _ i * x _ i $ 라고 정의 하 겠 다 . ( 참고 로 , 일반 적 으로 는 weight 뿐 아니 라 bais 도 고려 해야 한다 . 이 경우 $ t = \\\\ sum _ i ( w _ i * x _ i + b _ i ) $ 로 표현 이 되 지만 , 이 글 에서 는 bais 는 weight 와 거의 동일 하 기 때문 에 무시 하 고 진행 하 도록 하 겠 다 . - 예 를 들 어 항상 값 이 1 인 $ x _ 0 $ 를 추가 한다면 $ w _ 0 $ 가 bais 가 되 므로 , 가상 의 input 을 가정 하 고 weight 와 bais 를 동일 하 게 취급 하 여도 무방 하 다 . ) sigmoid function : $ f ( t ) = \\\\ frac { 1 }{ 1 + e ^{- t }}$ tanh function : $ f ( t ) = \\\\ frac { e ^ t - e ^{- t }}{ e ^ t + e ^{- t } }$ absolute function : $ f ( t ) = \\\\| t \\\\|$ relu function : $ f ( t ) = max ( 0 , t ) $ 보통 가장 많이 예시 로 드 는 activation function 으로 sigmoid function 이 있 다 . ( 출처 는 위 의 위키 와 같 음 ) 이 함수 는 미분 이 간단 하 다거나 , 실제 뉴런 들 이 동작 하 는 것 과 비슷 하 게 생겼 다는 등 의 이유 로 과거 에 는 많이 사용 되 었 지만 , 별로 practical 한 activation function 은 아니 고 , 실제로 는 relu 를 가장 많이 사용 한다 ( 2012 년 imagenet competition 에서 우승 했 던 alexnet publication 을 보 면 , relu 와 dropout 을 쓰 는 것 이 그렇 지 않 은 것 보다 훨씬 더 우수 한 결과 를 얻 는다고 주장 하 고 있 다 . 이 에 대한 자세 한 내용 은 다른 포스트 를 통해 보충 하 도록 하 겠 다 ) . 참고 로 neuron 을 non - linearity 라고 부르 기 도 하 는데 , 그 이유 는 activation function 으로 linear function 을 사용 하 게 되 면 아무리 여러 neuron layer 를 쌓 는다고 하 더라도 그것 이 결국 하나 의 layer 로 표현 이 되 기 때문 에 non - linear 한 activation function 을 사용 하 기 때문 이 다 . 따라서 이 모델 은 처음 에 node 와 edge 로 이루어진 네트워크 의 모양 을 정의 하 고 , 각 node 별 activation function 을 정의 한다 . 이렇게 정해진 모델 을 조절 하 는 parameter 의 역할 은 edge 의 weight 가 맡 게 되 며 , 가장 적절 한 weight 를 찾 는 것 이 이 수학 적 모델 을 train 할 때 의 목표 가 될 것 이 다 . inference via neural network 먼저 모든 paramter 가 결정 되 었 다고 가정 하 고 neural network 가 어떻게 결과 를 inference 하 는지 살펴보 도록 하 자 . neural network 는 먼저 주어진 input 에 대해 다음 layer 의 activation 을 결정 하 고 , 그것 을 사용 해 그 다음 layer 의 activation 을 결정 한다 . 이런 식 으로 맨 마지막 까지 결정 을 하 고 나 서 , 맨 마지막 decision layer 의 결과 를 보 고 inference 를 결정 하 는 것 이 다 ( 아래 그림 참고 , 빨간 색이 activate 된 뉴런 이 다 ) . 이때 , classification 이 라고 한다면 마지막 layer 에 내 가 classification 하 고 싶 은 class 개수 만큼 decision node 를 만든 다음 그 중 하나 activate 되 는 값 을 선택 하 는 것 이 다 . 예 를 들 어 0 부터 9 까지 손 글씨 데이터 를 ( mnist 라는 유명 한 dataset 이 있 다 ) classification 해야 한다고 생각 해 보 자 . 그 경우 는 0 부터 9 까지 decision 이 총 10 개 이 므로 마지막 decision layer 에 는 10 개 의 neuron 이 존재 하 게 되 고 주 어 진 데이터 에 대해 가장 activation 된 크기 가 큰 decision 을 선택 하 는 것 이 다 . backpropagation algorithm 마지막 으로 이제 weight 를 어떻게 찾 을 수 있 는지 weight paramter 를 찾 는 알고리즘 에 대해 알아보 자 . 먼저 한 가지 알 아 두 어야 할 점 은 activation function 들 이 non - linear 하 고 , 이것 들 이 서로 layer 를 이루 면서 복잡 하 게 얽혀 있 기 때문 에 neural network 의 weight optimization 이 non - convex optimization 이 라는 것 이 다 . 따라서 일반 적 인 경우 에 neural network 의 paramter 들 의 global optimum 을 찾 는 것 은 불 가능 하 다 . 그렇 기 때문 에 보통 gradient descent 방법 을 사용 하 여 적당 한 값 까지 수렴 시키 는 방법 을 사용 하 게 된다 . neural network ( 이 글 에서 는 multi - layer feed - forward network ) 의 parameter 를 update 하 기 위해서 는 backpropagation algorithm 이 라는 것 을 주로 사용 하 는데 , 이 는 단순히 neural network 에서 gradient descent 를 chain rule 을 사용 하 여 단순 화 시킨 것 에 지나 지 않 는다 ( gradient descent 에 대해서 는 이전 에 쓴 convex optimization 글 에서 자세히 다루 고 있 으니 참고 하 면 좋 을 것 같 다 ) . 모든 optimization 문제 는 target function 이 정의 되 어야 풀 수 있 다 . neural network 에서 는 마지막 decision layer 에서 우리 가 실제로 원 하 는 target output 과 현재 network 가 produce 한 estimated output 끼리 의 loss function 을 계산 하 여 그 값 을 minimize 하 는 방식 을 취한다 . 일반 적 으로 많이 선택 하 는 loss 에 는 다음 과 같 은 함수 들 이 있 다 . 이때 우리 가 원 하 는 d - dimensional target output 을 $ t =[ t _ 1 , \\\\ ldots , t _ d ] $ 로 , estimated output 을 $ x =[ x _ 1 , \\\\ ldots , x _ d ] $ 로 정의 해 보 자 . sum of squares ( euclidean ) loss : $\\\\ sum _{ i = 1 }^ d ( x _ i - t _ i ) ^ 2 $ softmax loss : $-\\\\ sum _{ i = 1 }^ d \\\\ bigg [ t _ i \\\\ log \\\\ big ( \\\\ frac { e ^{ x _ i } }{\\\\ sum _{ j = 1 }^ d e ^{ x _ j } }\\\\ big ) + ( 1 - t _ i ) \\\\ log \\\\ big ( 1 - \\\\ frac { e ^{ x _ i } }{\\\\ sum _{ j = 1 }^ d e ^{ x _ j } }\\\\ big ) \\\\ bigg ] $ cross entropy loss : $\\\\ sum _{ i = 1 }^ d [ - t _ i \\\\ log x _ i - ( 1 - t _ i ) \\\\ log ( 1 - x _ i ) ] $ hinge loss : $\\\\ max ( 0 , 1 - t \\\\ cdot x ) $, 이때 $\\\\ cdot $ 은 내적 을 의미 한다 . 상황 에 따라 조금 씩 다른 loss function 을 사용 하 지만 , classification 에 대해서 는 보통 softmax loss 가 gradient 의 값 이 numerically stable 하 기 때문 에 softmax loss 를 많이 사용 한다 . 이렇게 loss function 이 주어진다면 , 이 값 을 주어진 paramter 들 에 대해 gradient 를 구한 다음 그 값 들 을 사용 해 parameter 를 update 하 기 만 하 면 된다 . 문제 는 , 일반 적 인 경우 에 대해 이 paramter 계산 이 엄청 쉬운 것 만 은 아니 라는 것 이 다 . backpropagtaion algorithm 은 chain rule 을 사용 해 gradient 계산 을 엄청 간단 하 게 만들 어 주 는 알고리즘 으로 , 각각 의 paramter 의 grdient 를 계산 할 때 parallelization 도 용이 하 고 , 알고리즘 디자인 만 조금 잘 하 면 memory 도 많이 아낄 수 있 기 때문 에 실제 neural network update 는 이 backpropagtaion 알고리즘 을 사용 하 게 된다 . gradient descent method 를 사용 하 기 위해서 는 현재 parameter 에 대한 gradient 를 계산 해야 하 지만 , 네트워크 가 복잡 해 지 면 그 값 을 바로 계산 하 는 것 이 엄청나 게 어려워진다 . 그 대신 backpropataion algorithm 에서 는 먼저 현재 paramter 를 사용 하 여 loss 를 계산 하 고 , 각각 의 parameter 들 이 해당 loss 에 대해 얼마 만큼 의 영향 을 미쳤 는지 chain rule 을 사용 하 여 계산 하 고 , 그 값 으로 update 를 하 는 방법 이 다 . 따라서 backpropagation algorithm 은 크 게 두 가지 phase 로 나눌 수 가 있 는데 , 하나 는 propagation phase 이 며 , 하나 는 weight update phase 이 다 . propagation phase 에서 는 training input pattern 에서부터 에러 , 혹은 각 뉴런 들 의 변화 량 을 계산 하 며 , weight update phase 에서 는 앞 에서 계산 한 값 을 사용 해 weight 를 update 시킨다 . phase 1 : propagation forward propagation : input training data 로부터 output 을 계산 하 고 , 각 ouput neuron 에서 의 error 를 계산 한다 . ( input -> hidden -> output 으로 정보 가 흘러가 므로 ‘ forward ’ propagation 이 라 한다 . ) back propagation : output neuron 에서 계산 된 error 를 각 edge 들 의 weight 를 사용 해 바로 이전 layer 의 neuron 들 이 얼마나 error 에 영향 을 미쳤 는지 계산 한다 . ( output -> hidden 으로 정보 가 흘러가 므로 ‘ back ’ propagation 이 라 한다 . ) phase 2 : weight update chain rule 을 사용 해 paramter 들 의 gradient 를 계산 한다 . 이때 , chain rule 을 사용 한다는 의미 는 아래 그림 에서 나타내 는 것 처럼 , 앞 에서 계산 된 gradient 를 사용 해 지금 gradient 값 을 update 한다는 의미 이 다 . ( 그림 은 bengio 의 deep learning book ch 6 에서 가져왔 다 . ) 두 그림 모두 $\\\\ frac {\\\\ partial z }{\\\\ partial x }$ 를 구하 는 것 이 목적 인데 , 직접 그 값 을 계산 하 는 대신 , $ y $ layer 에서 이미 계산 한 derivative 인 $\\\\ frac {\\\\ partial z }{\\\\ partial y }$ 와 $ y $ layer 와 $ x $ 에 만 관계있 는 $\\\\ frac {\\\\ partial y }{\\\\ partial x }$ 를 사용 하 여 원 하 는 값 을 계산 하 고 있 다 . 만약 $ x $ 아래 에 $ x ^\\\\ prime $ 이 라는 parameter 가 또 있 다면 , $\\\\ frac {\\\\ partial z }{\\\\ partial x }$ 와 $\\\\ frac {\\\\ partial x }{\\\\ partial x ^\\\\ prime }$ 을 사용 하 여 $\\\\ frac {\\\\ partial z }{\\\\ partial x ^\\\\ prime }$ 을 계산 할 수 있 는 것 이 다 . 때문 에 우리 가 backpropagation algorithm 에서 필요 한 것 은 내 가 지금 update 하 려는 paramter 의 바로 전 variable 의 derivative 와 , 지금 paramter 로 바로 전 variable 을 미분 한 값 두 개 뿐 이 다 . 이 과정 을 output layer 에서부터 하나하나 내려오 면서 반복 된다 . 즉 , output -> hidden k , hidden k -> hidden k - 1 , … hidden 2 -> hidden 1 , hidden 1 -> input 의 과정 을 거치 면서 계속 weight 가 update 되 는 것 이 다 . 예 를 들 어서 decision layer 와 가장 가까운 weight 는 직접 derivative 를 계산 하 여 구할 수 있 고 , 그 보다 더 아래 에 있 는 layer 의 weight 는 그 바로 전 layer 의 weight 와 해당 layer 의 activation function 의 미분 값 을 곱하 여 계산 할 수 있 다 . 이해 가 조금 어렵 다면 아래 의 예제 를 천천히 읽 어 보 기 를 권한다 . 이 과정 을 맨 위 에서 아래 까지 반복 하 면 전체 gradient 를 구할 수 있 고 , 이 gradient 를 사용 해 parameter 들 을 update 할 수 있 다 . 이렇게 한 번 의 iteration 이 진행 되 고 , 충분히 converge 했 다고 판단 할 때 까지 이런 iteration 을 계속 반복 하 는 것 이 feed - forward network 의 parameter 를 update 하 는 방법 이 다 . 이 를 그림 으로 표현 하 면 아래 와 같 다 . ( 출처 : 링크 ) 이렇 듯 backpropagation 은 직접 weight 를 바로 변화 시키 는 것 이 아니 라 오직 error 만 을 보 고 gradient descent method based approach 를 사용 해 error 를 minimize 하 는 방향 으로 계속 weight 를 update 시키 는 것 이 다 . 또한 한 번 error 가 연산 된 이후 에 는 output layer 에서부터 그 이전 layer 로 ‘ 역 으로 ’ 정보 가 update 되 기 때문 에 이 를 backpropagation , 한국어 로 는 역전사 라고 하 는 것 이 다 . stochastic gradient descent gradient 를 계산 했으니 이제 직접 gradient descent 를 써서 parameter 만 update 하 면 된다 . 그러나 문제 가 하나 있 는데 , 일반 적 으로 neural network 의 input data 의 개수 가 엄청나 게 많 다는 것 이 다 . 때문 에 정확 한 gradient 를 계산 하 기 위해서 는 모든 training data 에 대해 gradient 를 전부 계산 하 고 , 그 값 을 평균 내 어 정확 한 gradient 를 구한 다음 ‘ 한 번 ’ update 해야 한다 . 그러나 이런 방법 은 너무나 도 비 효율 적 이 기 때문 에 stochastic gradient descent ( sgd ) 라는 방법 을 사용 해야 한다 . sgd 는 모든 데이터 의 gradient 를 평균 내 어 gradient update 를 하 는 대신 ( 이 를 ‘ full batch ’ 라고 한다 ) , 일부 의 데이터 로 ‘ mini batch ’ 를 형성 하 여 한 batch 에 대한 gradient 만 을 계산 하 여 전체 parameter 를 update 한다 . convex optimization 의 경우 , 특정 조건 이 충족 되 면 sgd 와 gd 가 같 은 global optimum 으로 수렴 하 는 것 이 증명 되 어 있 지만 , neural network 는 convex 가 아니 기 때문 에 batch 를 설정 하 는 방법 에 따라 수렴 하 는 조건 이 바뀌 게 된다 . batch size 는 일반 적 으로 메모리 가 감당 할 수 있 을 정도 까지 최대한 크 게 잡 는 것 같 다 . backpropagation algorithm : example 이전 에 chain rule 로 gradient 를 계산 한다고 언급 했었 는데 , 실제 이 chain rule 이 어떻게 적용 되 는지 아래 의 간단 한 예 를 통해 살펴보 도록 하 자 . 이때 계산 의 편의 를 위해 각각 의 neuron 은 sigmoid loss 를 가지 고 있 다고 가정 하 도록 하 겠 다 . 이때 각각 의 neuron 의 input 으로 들어가 는 값 을 $ in _{ o _ 5 }$, output 으로 나가 는 값 을 $ out _{ h _ 3 }$ 와 같 은 식 으로 정의 해 보 자 ( 이렇게 된다면 in 과 out 은 $ out _{ h _ 3 } = \\\\ sigma ( in _{ h _ 3 })$ 으로 표현 가능 하 다 . - 이때 $\\\\ sigma $ 는 sigmoid function ) . 먼저 error 를 정의 하 자 . error 는 가장 간단 한 sum of square loss 를 취하 도록 하 겠 다 . 우리 가 원 하 는 target 을 $ t $ 라고 정의 하 면 loss 는 $ e = \\\\ frac { 1 }{ 2 }( t _ 5 - out _{ o _ 5 })^ 2 + \\\\ frac { 1 }{ 2 }( t _ 6 - out _{ o _ 6 })^ 2 $ 가 될 것 이 다 ( 1 / 2 는 미분 한 값 을 깔끔 하 게 쓰 기 위해 붙인 상관없 는 값 이 므로 무시 해도 좋 다 ) . 그리고 우리 가 원 하 는 값 들 은 $\\\\ frac {\\\\ partial e }{\\\\ partial w _{ 13 }}, \\\\ frac {\\\\ partial e }{\\\\ partial w _{ 14 }}, \\\\ ldots , \\\\ frac {\\\\ partial e }{\\\\ partial w _{ 46 }}$ 이 될 것 이 다 . 이제 가장 먼저 $\\\\ frac {\\\\ partial e }{\\\\ partial w _{ 35 }}$ 부터 계산 해 보 자 . $$\\\\ frac {\\\\ partial e }{\\\\ partial w _{ 35 }} = \\\\ frac {\\\\ partial e }{\\\\ partial out _{ o _ 5 }} * \\\\ frac {\\\\ partial out _{ o _ 5 }}{\\\\ partial in _{ o _ 5 }} * \\\\ frac {\\\\ partial in _{ o _ 5 }}{\\\\ partial w _{ 35 }}. $$ 즉 , 우리 가 원 하 는 derivative 를 계산 하 기 위해서 는 세 개 의 다른 derivative ( $\\\\ frac {\\\\ partial e }{\\\\ partial out _{ o _ 5 }}, \\\\ frac {\\\\ partial out _{ o _ 5 }}{\\\\ partial in _{ o _ 5 }}, \\\\ frac {\\\\ partial in _{ o _ 5 }}{\\\\ partial w _{ 35 }}$) 를 계산 해야 한다 . 각각 을 구하 는 방법 은 다음 과 같 다 . $\\\\ frac {\\\\ partial e }{\\\\ partial out _{ o _ 5 }}$: error 를 $ e = \\\\ frac { 1 }{ 2 }( t _ 5 - out _{ o _ 5 })^ 2 + \\\\ frac { 1 }{ 2 }( t _ 6 - out _{ o _ 6 })^ 2 $ 라고 정의 했으므로 , $\\\\ frac {\\\\ partial e }{\\\\ partial out _{ o _ 5 }} = out _{ o _ 5 } - t _ 5 $ 이 다 . - 이때 $ out _{ o _ 5 }$ 와 $ t _ 5 $ 는 weight update 이전 propagation step 에서 계산 된 값 이 다 . $\\\\ frac {\\\\ partial out _{ o _ 5 }}{\\\\ partial in _{ o _ 5 }}$: $ o _ 5 $ 는 sigmoid activation function 을 사용 하 므로 $ out _{ o _ 5 } = \\\\ sigma ( in _{ o _ 5 })$ 이 다 . 또한 sigmoid function 의 미분 값 은 $\\\\ frac {\\\\ partial \\\\ sigma ( x ) }{\\\\ partial x } = \\\\ sigma ( x ) ( 1 - \\\\ sigma ( x ) ) $ 으로 주어지 므로 , 이 값 을 대입 하 면 $\\\\ frac {\\\\ partial out _{ o _ 5 }}{\\\\ partial in _{ o _ 5 }} = out _{ o _ 5 } ( 1 - out _{ o _ 5 })$ 가 된다 . - 역시 여기 에서 도 미리 계산 한 $ out _{ o _ 5 }$ 를 사용 한다 . $\\\\ frac {\\\\ partial in _{ o _ 5 }}{\\\\ partial w _{ 35 }}$: $ o _ 5 $ 로 들어온 값 의 총 합 은 앞선 layer 의 output 과 $ o _ 5 $ 로 들어오 는 weight 를 곱하 면 되 므로 $ in _{ o _ 5 } = w _{ 35 } out _{ h _ 3 } + w _{ 45 } out _{ h _ 4 }$ 이 고 , 이것 을 통해 $\\\\ frac {\\\\ partial in _{ o _ 5 }}{\\\\ partial w _{ 35 }} = out _{ h _ 3 }$ 가 됨 을 알 수 있 다 . - $ out _{ h _ 3 }$ 역시 이전 propagation 에서 계산 된 값 이 다 . 따라서 $\\\\ frac {\\\\ partial e }{\\\\ partial w _{ 35 }}$ 의 derivative 값 은 위 의 세 값 을 모두 곱한 것 으로 계산 할 수 있 다 . 그림 으로 표현 하 면 아래 와 같 은 그림 이 될 것 이 다 . 즉 , ‘ backward ’ 방향 으로 derivative 에 대한 정보 를 ‘ propagation ’ 하 면서 parameter 의 derivative 를 계산 하 는 것 이 다 . 마찬가지 방법 으로 $ w _{ 36 }, w _{ 45 }, w _{ 46 }$ 에 대한 derivative 도 계산 할 수 있 다 . 그럼 이번 에 는 그 전 layer 의 paramter 들 중 하나 인 $ w _{ 13 }$ 의 derivative 를 계산 해 보 자 . 이번 에 계산 할 과정 도 위 와 비슷 한 그림 으로 표현 해 보 면 아래 와 같 다 . 그러면 이제 $\\\\ frac {\\\\ partial e }{\\\\ partial w _{ 13 }}$ 을 구해 보 자 . $$\\\\ frac {\\\\ partial e }{\\\\ partial w _{ 13 }} = \\\\ frac {\\\\ partial e }{\\\\ partial out _{ h _ 3 }} * \\\\ frac {\\\\ partial out _{ h _ 3 }}{\\\\ partial in _{ h _ 3 }} * \\\\ frac {\\\\ partial in _{ h _ 3 }}{\\\\ partial w _{ 13 }}.$$ 마찬가지 로 각각 을 구하 는 방법 에 대해 적 어 보 자 . $\\\\ frac {\\\\ partial e }{\\\\ partial out _{ h _ 3 }}$: $ e = \\\\ frac { 1 }{ 2 }( t _ 5 - out _{ o _ 5 })^ 2 + \\\\ frac { 1 }{ 2 }( t _ 6 - out _{ o _ 6 })^ 2 $ 를 $ e = e _{ o _ 5 } + e _{ o _ 6 }$ 로 decompose 하 면 이 미분 식 은 $\\\\ frac {\\\\ partial e _{ o _ 5 }}{\\\\ partial out _{ h _ 3 }} + \\\\ frac {\\\\ partial e _{ o _ 6 }}{\\\\ partial out _{ h _ 3 }}$ 로 쓸 수 있 다 . 각각 의 계산 은 다음 과 같 다 . $\\\\ frac {\\\\ partial e _{ o _ 5 }}{\\\\ partial out _{ h _ 3 }} = \\\\ frac {\\\\ partial e _{ o _ 5 }}{\\\\ partial in _{ o _ 5 }} * \\\\ frac {\\\\ partial in _{ o _ 5 }}{\\\\ partial out _{ h _ 3 }}$ 으로 쓸 수 있 다 . 이 중 앞 의 값 인 $\\\\ frac {\\\\ partial e _{ o _ 5 }}{\\\\ partial in _{ o _ 5 }}$ 은 이미 전 과정 에서 계산 했 던 $\\\\ frac {\\\\ partial e }{\\\\ partial out _{ o _ 5 }}$ 과 $\\\\ frac {\\\\ partial out _{ o _ 5 }}{\\\\ partial in _{ o _ 5 }}$ 의 곱 으로 계산 가능 하 다 . 뒤 의 값 은 $\\\\ frac {\\\\ partial in _{ o _ 5 }}{\\\\ partial out _{ h _ 3 }} = w _{ 35 }$ 이 므로 간단 하 게 계산 할 수 있 다 . $\\\\ frac {\\\\ partial e _{ o _ 6 }}{\\\\ partial out _{ h _ 3 }}$ 도 위 와 같 은 방법 으로 연산 이 가능 하 다 . $\\\\ frac {\\\\ partial out _{ h _ 3 }}{\\\\ partial in _{ h _ 3 }}$: $\\\\ frac {\\\\ partial out _{ o _ 5 }}{\\\\ partial in _{ o _ 5 }}$ 와 같 다 . 따라서 $ out _{ h _ 3 } ( 1 - out _{ h _ 3 })$ 이 다 . $\\\\ frac {\\\\ partial in _{ h _ 3 }}{\\\\ partial w _{ 13 }}$: $\\\\ frac {\\\\ partial in _{ o _ 5 }}{\\\\ partial w _{ 35 }}$ 와 같 다 . 따라서 $ out _{ i _ 1 }$ 이 다 . 이렇게 $\\\\ frac {\\\\ partial e }{\\\\ partial out _{ h _ 3 }}$ 에서 는 앞 에서 계산 했 던 값 들 을 재 활용 하 고 , 아래 의 값 들 은 activation function 과 network 의 topological property 에 맞 는 derivative 를 곱하 는 방식 으로 $\\\\ frac {\\\\ partial e }{\\\\ partial w _{ 13 }}$ 을 구할 수 있 다 . 이렇 듯 backpropagation algorithm 은 forward propagation 을 통해 필요 한 값 들 을 미리 저장 해 두 고 , backward propagation 이 진행 되 면서 위 에서부터 loss 에 대한 derivative 를 하나하나 계산 해 나가 면서 다음 layer 에서 바로 전 layer 에서 계산 한 값 들 과 각 neuron 별로 추가 적 으로 필요 한 derivative 들 을 곱해 나가 면서 weight 의 derivative 를 계산 하 는 알고리즘 이 다 . 이렇게 한 번 전체 gradient 를 계산 한 다음 에 는 learning rate 를 곱하 여 전체 parameter 의 값 을 update 한 다음 , 다시 처음 부터 이 과정 을 반복 한다 . 보통 에러 가 감소 하 는 속도 를 관측 하 면서 ‘ 이 정도 면 converge 한 것 같 다 ’ 하 는 수준 까지 돌린다 . 익숙 해 지 려면 다소 시간 이 걸리 지만 , 개념 적 으로 먼저 ‘ error 를 먼저 계산 하 고 , 그 값 을 아래 로 전달 해 나가 면서 바로 전 layer 에서 계산 한 미분 값 들 을 사용 해 현재 layer 의 미분 값 을 계산 한 다음 , 그 값 을 사용 해 다음 layer 의 미분 값 을 계산 한다 . ’ 라고 개념 만 이해 해 두 고 다시 차근차근 chain rule 을 계산 해 나가 면서 계산 하 면 조금 편하 게 익숙 해 질 수 있 을 것 이 다 . backpropagation algorithm : in practice 실제 backpropagtion 을 계산 해야 한다고 가정 해 보 자 . 편의 상 $ l $ 번 째 hidden layer 를 $ y _ l $ 이 라고 해 보 자 . 이 경우 각 layer 에 대해 backpropagation algorithm 을 위해 계산 해야 할 것 은 총 두 가지 이 다 . loss 를 $ e $ 라고 적 었 을 때 먼저 layer $ l $ 의 parameter $\\\\ theta _ l $ 의 gradient 인 $\\\\ frac {\\\\ partial e }{\\\\ partial w _ l }$ 을 구해야 한다 . 이 값 은 $\\\\ frac {\\\\ partial e }{\\\\ partial w _ l } = \\\\ frac {\\\\ partial e }{\\\\ partial y _{ l } } \\\\ frac {\\\\ partial y _{ l } }{\\\\ partial w _{ l } } $ 을 통해 계산 한다 . 이때 , $\\\\ frac {\\\\ partial e }{\\\\ partial y _{ l } } = \\\\ frac {\\\\ partial e }{\\\\ partial y _{ l + 1 } } \\\\ frac {\\\\ partial y _{ l + 1 } }{\\\\ partial y _{ l } } $ 이 므로 $\\\\ frac {\\\\ partial e }{\\\\ partial y _{ l } }$ 은 바로 전 layer 에서 넘겨 준 $\\\\ frac {\\\\ partial e }{\\\\ partial y _{ l + 1 } }$ 의 값 을 사용 하 여 계산 하 게 된다 . 정리 하 면 실제 계산 해야 하 는 값 은 $\\\\ frac {\\\\ partial y _{ l + 1 } }{\\\\ partial y _{ l }},\\\\ frac {\\\\ partial y _{ l } }{\\\\ partial w _{ l } } $ 두 가지 이 고 , 이 값 들 을 사용 해 $\\\\ frac { e }{\\\\ partial y _{ l }}, \\\\ frac { e }{\\\\ partial w _{ l }}$ 을 return 하 게 된다 . 앞 의 값 은 다음 layer 에 넘겨 줘서 다음 input 으로 사용 하 고 , 두 번 째 값 은 저장 해 두 었 다가 gradient descent update 할 때 사용 한다 . 두 가지 예 를 들 어 보 자 . 먼저 inner product layer 혹은 fully connected layer 이 다 . 이 layer 가 inner product layer 라고 불리 는 이유 는 input $ y _ l $ 에 대해 output $ y _{ l + 1 }$ 이 간단 한 inner product 들 이 모여 있 는 형태 로 표현 되 기 때문 이 다 . 예 를 들 어 $ y _{ l + 1 , i }$ 를 l + 1 번 째 layer 의 i 번 째 node 라고 한다면 , $ y _{ l + 1 , i } = \\\\ sum _{ j } w _{ ij } y _{ l , j }$ 으로 표현 할 수 있 음 을 알 수 있 다 . 그런데 이 값 은 사실 vector $ w $ 와 $ y _{ l }$ 의 inner product 로 표현 됨 을 알 수 있 다 . 그렇 기 때문 에 fully connected layer 를 inner product 라고 부른다 . 다시 본론 으로 돌아와서 inner product 의 output 은 input 과 weight 의 matrix - vector multiplication 인 $ y _{ l + 1 } = w _ l * y _ l $ 으로 표현 할 수 있 다 . 따라서 $\\\\ frac {\\\\ partial y _{ l + 1 } }{\\\\ partial y _{ l }} = w _ l ^\\\\ top $ 이 고 , $\\\\ frac {\\\\ partial y _{ l } }{\\\\ partial w _{ l } } = y _ l $ 이 다 . 이 값 을 통해 실제 return 하 는 값 은 $\\\\ frac {\\\\ partial e }{\\\\ partial y _{ l } } = \\\\ frac {\\\\ partial e }{\\\\ partial y _{ l + 1 } } * w _ l ^\\\\ top $ 와 $\\\\ frac {\\\\ partial e }{\\\\ partial w _{ l } } = \\\\ frac {\\\\ partial e }{\\\\ partial y _{ l + 1 } } * y _{ l } $ 이 된다 . 두 번 째 로 많이 사용 하 는 relu non - linearity 의 gradient 를 계산 해 보 자 . 이때 activation function 은 마치 하나 의 layer 가 더 있 는 것 처럼 생각 할 수 있 다 . 즉 $ y _{ l + 1 } = max ( 0 , y _{ l })$ 로 표현 할 수 있 을 것 이 다 . parameter 는 없 으니까 생략 하 면 만약 $ y _{ l } \\\\ geq 0 $ 라면 $\\\\ frac {\\\\ partial y _{ l + 1 } }{\\\\ partial y _{ l } = 1 } $ 이 고 , 아니 라면 0 이 될 것 이 다 . 따라서 $ y _{ l } \\\\ geq 0 $ 라면 $\\\\ frac {\\\\ partial e }{\\\\ partial y _{ l } } = \\\\ frac {\\\\ partial e }{\\\\ partial y _{ l + 1 } } $ 이 되 고 , 0 보다 작 다면 0 이 될 것 이 다 . 정리 deep learning 을 다루 기 위해서 는 가장 먼저 aritifitial neural network 의 model 에 대한 이해 와 gradient descent 라는 update rule 에 대한 이해 가 필수 적 이 다 . 이 글 에서 는 가장 기초 적 이 라고 생각 하 는 feed - forward network 의 model 을 먼저 설명 하 고 , paramter 를 update 하 는 gradient descent algorithm 의 일종 인 backpropagation 에 대한 개념 적 인 설명 을 다루 었 다 . 조금 어려울 수 있 는 내용 이 니 다른 글 들 을 계속 참고 하 면서 보 면 좋 을 것 같 다 . reference 변경 이력 2015 년 9 월 13 일 : 글 등록 2015 년 9 월 14 일 : 오타 수정 , sgd 내용 추가 등 2015 년 9 월 20 일 : bp in practice 추가 machine learning 스터디 의 다른 글 들',\n",
       "       '구조 방정식 모형 ( 분석 ) 이란 \" 측정 모형 과 이론 모형 을 통해서 모형 간 인과 관계 를 파악 하 는 방정식 모형 \" 을 의미 한다 . 즉 각 모형 들 에 대한 확인 적 요인 분석 을 통해 측정 오 차 가 없 는 잠재 요인 을 발견 하 고 회귀분석 및 경로 분석 으로 잠재 요인 들 을 모형 간 에 인과 적 으로 연결 하 는 방법 이 라고 할 수 있 다 . 즉 \" 구조 방정식 모형 은 인과 분석 을 위해서 요인 분석 과 회귀분석 을 개선 적 으로 결합 한 형태 \" 를 의미 한다 . 구조 방정식 모형 은 영어 로 는 sem ( structural equation modeling ) 이 라고 한다 . 구조 방정식 모형 은 공분산 구조 분석 ( csm : covariance structure analysis ) 이 라고 도 불리우 는데 , 즉 \" 구성 개념 간 의 이론 적 인 인과 관계 와 상관 성 의 측정 지표 를 통한 경험 적 인과 관계 를 분석 할 수 있 도록 개발 된 통계 기법 \" 을 말 한다 . amos 란 analysis of moment structures 의 약자 로 lisrel ( linear structural relations ) , eqs ( equations ) 등 과 함께 구조 방정식 모형 분석 에 자주 사용 되 는 통계 소프트웨어 이 다 . amos 는 temple university 의 james l . arbuckle 교수 에 의해 처음 개발 되 었 으며 , 현재 는 ver . 7 . 0 까지 출시 되 었 다 . 구조 방정식 모델 분석 을 위한 프로그램 으로 가장 처음 개발 되 었 고 가장 많이 쓰이 고 있 는 lisrel 의 경우 , 분석 을 위해 사용 자 가 직접 모형 을 프로그래밍 해야 한다는 단점 이 있 는 반면 , amos 는 gui 를 따르 고 있 어 그래픽 요소 들 을 배치 함 으로써 모형 을 프로그래밍 할 수 있 어 분석 을 보다 용이 하 게 할 수 있 다는 장점 을 가지 고 있 다 . lisrel 은 도스 용 , amos 는 윈도우 용이 라고 생각 하 면 쉽 게 이해 할 수 있 겠 다 . 본인 도 이제 처음 으로 amos 공부 를 시작 하 는 입문 자 이 다 . 여러 amos 관련 사이트 를 돌아다니 다가 amos 의 개요 를 알 기 쉽 게 소개 한 글 을 보 게 되 어 소개 하 고자 한다 . 아래 내용 은 구조 방정식 이해 하 기 ( 사례 분석 ) amos 는 구조 방정식 모형 을 분석 하 기 위한 통계 소프트웨어 다 . 이란 \" 측정 모형 과 이론 모형 을 통해서 모형 간 인과 관계 를 파악 하 는 방정식 모형 \" 을 의미 한다 . 즉 각 모형 들 에 대한 확인 적 요인 분석 을 통해 측정 오 차 가 없 는 잠재 요인 을 발견 하 고 회귀분석 및 경로 분석 으로 잠재 요인 들 을 모형 간 에 인과 적 으로 연결 하 는 방법 이 라고 할 수 있 다 . 즉 \" 구조 방정식 모형 은 인과 분석 을 위해서 요인 분석 과 회귀분석 을 개선 적 으로 결합 한 형태 \" 를 의미 한다 . 구조 방정식 모형 은 영어 로 는 이 라고 한다 . 구조 방정식 모형 은 의 약자 로 lisrel ( linear structural relations ) , eqs ( equations ) 등 과 함께 구조 방정식 모형 분석 에 자주 사용 되 는 통계 소프트웨어 이 다 . amos 는 temple university 의 james l . arbuckle 교수 에 의해 처음 개발 되 었 으며 , 현재 는 ver . 7 . 0 까지 출시 되 었 다 . 구조 방정식 모델 분석 을 위한 프로그램 으로 가장 처음 개발 되 었 고 가장 많이 쓰이 고 있 는 lisrel 의 경우 , 분석 을 위해 사용 자 가 직접 모형 을 프로그래밍 해야 한다는 단점 이 있 는 반면 , amos 는 gui 를 따르 고 있 어 그래픽 요소 들 을 배치 함 으로써 모형 을 프로그래밍 할 수 있 어 분석 을 보다 용이 하 게 할 수 있 다는 장점 을 가지 고 있 다 . lisrel 은 도스 용 , amos 는 윈도우 용이 라고 생각 하 면 쉽 게 이해 할 수 있 겠 다 . 본인 도 이제 처음 으로 amos 공부 를 시작 하 는 입문 자 이 다 . 여러 amos 관련 사이트 를 돌아다니 다가 amos 의 개요 를 알 기 쉽 게 소개 한 글 을 보 게 되 어 소개 하 고자 한다 . 아래 내용 은 mystatistics . net ( [ URL ] ) 이 라는 사이트 에 올려져 있 는 글 이 다 . 1 지금 까지 우리 는 독립 변수 ( independent variable ) 과 종속 변수 ( dependent variable ) 에 익숙 합니다 . 하지만 구조 방정식 모델 에선 독립 변수 와 종속 변수 라는 개념 대신 관측 변수 ( observed variable ) 와 잠재변수 ( latent variable ) 그리고 외생 변수 ( exogenous variable ) 와 내생 변수 ( endogenous variable ) 의 개념 으로 변수 들 이 나타내 어 집니다 . 관측 변수 들 이 ( 설문지 에 해당 하 는 항목 들 ) 모여서 하나 의 잠재변수 를 형성 하 게 되 고 이러 한 잠재변수 들 끼리 외생 변수 와 내생 변수 의 개념 을 가지 고 모델 을 형성 하 게 됩니다 . 외생 변수 는 모델 내 에서 한 번 도 다른 변수 의 결과 가 되 지 않 는 변수 이 며 , 내생 변수 란 최소 한 번 은 모델 내 에서 결과 가 되 어 지 는 모델 입니다 . 약간 은 생소 하 지만 우리 가 사례 들 을 이해 하 기 위해선 꼭 알 아야 될 사항 입니다 ( 참고 로 관측 변수 는 정사각형 이나 직사각형 이 사용 되 며 잠재변수 는 원 으로써 나타내 어 집니다 ) . 그럼 우선 간단히 이러 한 내용 들 이 어떻게 사용 되 는지 알아보 도록 하 겠 습니다 . 예 를 들 어서 외제 자동차 에 대한 이미지 ( car image ) 조사 를 할 경우 다음 과 같 은 항목 들 을 만들 었 습니다 . 만약 에 설문지 내용 이 1 ) 외제 차 bmw 에 대한 디자인 ( design ) 은 어떻 다고 생각 되 십니까 ? 2 ) 외제 차 bmw 에 대한 엔진 의 기능 ( engine ) 어떻 다고 생각 되 십니까 ? 3 ) 외제 차 bmw 에 대한 가격 은 ( price ) 어떻 다고 생각 되 십니까 ? * 1 번 매우 만족 한다 , 2 번 만족 한다 , 3 번 그저 그렇 다 4 불만족 스럽 다 , 5 번 매우 불만족스럽 다 라고 할 때 여기 서 항목 1 , 2 , 3 이 관측 변수 가 되 고 , 이 세 가지 항목 으로 구성 되 는 자동차 에 대한 이미지 가 바로 잠재 변수 가 되 는 것 입니다 . 그래서 아래 와 같 은 모델 로써 만들 어 지 는 것 입니다 . 아주 쉽 죠 ? 그럼 모델 을 하나 더 만들 어 볼까요 ? 두 번 째 예 는 소비자 의 자동차 소비 구매 성향 ( purchase intention ) 에 대해서 만들 어 보 겠 습니다 . 우선 자동차 구매 성향 에 대한 4 가지 의 항목 을 있 다고 가정 해 보 겠 습니다 . 1 ) 나 는 차 에 외제 차 에 대해 관심 ( interest ) 이 많 다 2 ) 나 는 새 차 로 교체 할 시 멋지 고 비싼 차 ( luxury ) 로 구입 할 것 이 다 . 3 ) 나 는 사회 적 지위 ( position ) 에 맞 는 차 를 타 야 된다고 생각 한다 . 4 ) 나 는 안전 한 차 ( safety ) 를 타 고 싶 다 . * 1 번 매우 만족 한다 , 2 번 만족 한다 , 3 번 그저 그렇 다 4 불만족 스럽 다 , 5 번 매우 불만족스럽 다 라고 한다면 역시 항목 1 , 2 , 3 , 4 는 관측 변수 가 되 고 소비 구매 성향 은 잠재변수 가 되 는 것 입니다 . 그래서 이것 을 모델 로 표시 하 면 다음 과 같이 되 겠 죠 ? 그렇 다면 이 두 모델 을 연결 시킬 수 있 겠 죠 ? 그럼 이 두 모델 을 연결 하 면 다음 과 같이 될 것 입니다 . 그래서 외제 차 에 대한 이미지 가 어떻게 자동차 구매 성향 에 영향 을 미치 는가 에 대한 모델 을 간단 하 게 만들 어 봤 습니다 . 이 경우 앞 에서 독립 변수 역할 을 하 는 차 이미지 가 외생 변수 가 되 는 것 이 고 종속 변수 의 역할 을 하 는 소비 구매 경향 이 내생 변수 가 되 는 것 입니다 . ( 두 번 째 모델 에서 x 1 , x 2 , x 3 , x 4 가 y 1 , y 2 , y 3 , y 4 로 바꿨 는데 그것 은 두 번 째 모델 이 종속 변수 로 되 는 관계 로 문자 만 변한 거 지 기본 개념 은 변한 게 없 음 을 알려 드립니다 ) 물론 여기 까지 는 회귀분석 ( regression ) 으로 도 가능 합니다 . 하지만 회귀분석 의 경우 항목 들 에 대한 평균값 을 내 어 하나 의 변수 로 만들 어 주 거나 각각 의 항목 들 을 하나 씩 연결 시켜야 하 는 반면 , 구조 방정식 모델 의 경우 그럴 필요 가 없 으며 특히 이러 한 잠재변수 가 2 개 이상 일 경우 회귀분석 의 경우 각 단계 단계 마다 각각 의 유의 치 를 계산 해야 되 지만 구조 방정식 모델 의 경우 잠재변수 가 2 개 이상 이 라 하 더라도 변수 간 유의 치를 단 한 번 에 볼 수 있 는 장점 이 있 습니다 . 그럼 다음 의 사례 로 가 볼까요 ? 2 첫 번 째 사례 에서 언급 한 것 처럼 , 우리 는 9 개 의 관측 변수 로 4 개 의 잠재변수 를 만든 후 다시 4 개 의 잠재변수 를 두 개 의 독립 변수 와 두 개 의 종속 변수 를 만들 어 그 관계 를 보 도록 하 겠 습니다 . 약간 복잡 해 보이 지만 자세히 보 면 첫 번 째 사례 와 동일 합니다 . 직장 에서 직업 만족도 를 측정 하 기 위한 모델 개발 을 위해 우선 외생 변수 로 는 직장 에서 수입 에 대한 만족도 ( income satisfaction ) 와 직장 내 작업 환경 ( work environment ) 로 지정 하 였 고 , 내생 변수 로 는 직업 만족도 ( job satisfaction ) 와 직장 내 협동심 ( cooperation ) 로 하 였 습니다 . 수입 만족 도 측정 을 위해 두 개 의 아이템 ( x 1 , x 2 ) 을 이용 하 였 고 , 작업 환경 을 측정 하 기 위해 세 개 의 아이템 ( x 3 , x 4 , x 5 ) 을 이용 하 였 습니다 . 직업 만족 도 역시 세 개 의 아이템 ( y 1 , y 2 , y 3 ) 을 이용 하 였 고 , 직장 내 협동심 을 세 개 의 아이템 ( y 4 , y 5 , y 6 ) 을 사용 하 였 습니다 . 이 경우 아래 의 그림 과 같 은 모델 을 만들 수 있 습니다 . 이러 한 경우 x 1 , x 2 , x 3 , x 4 , x 5 들 은 역시 관측 변수 들 로써 잠재변수 ( 수입 만족 도 , 작업 환경 ) 를 구성 하 는 아이템 이 되 는 것 이 며 , y 1 , y 2 , y 3 , y 4 , y 5 , y 6 역시 잠재변수 ( 직업 만족 도 , 직장 내 협동심 ) 를 구성 하 는 관측 변수 가 되 는 것 입니다 . 자 , 그러면 이 모델 을 한번 볼까요 ? 우선 수입 에 대한 만족도 가 직업 만족도 에 대한 영향 을 미치 고 직장 환경 역시 직업 만족도 에 영향 을 미칩니다 . 그리고 직장 환경 은 다시 직장 내 협동심 에 영향 을 미치 며 직업 만족 도 역시 직장 내 협동심 에 영향 을 미치 는 것 으로 나타났 습니다 . 이럴 경우 회귀분석 은 각각 의 변수 들 간 의 유의 치 를 보 지 못합니다 . 예 를 들 어서 수입 만족도 에서 직업 만족 도 까 지만 유의 치 를 볼 수 있 고 그 다음 직업 만족 에서 다시 협동심 으로 가 는 경로 의 유의 치 밖 에 보여 주 지 못합니다 . 하지만 구조 방정식 모델 에서 는 그 모든 경로 의 유의 치 들 을 한꺼번에 보여준답니다 . 특히 작업 환경 에서 협동심 ( work environment -> cooperation ) 으로 가 는 직접 적 경로 와 작업 환경 에서 직업 만족도 를 통한 협동심 ( work environment -> job satisfaction -> cooperation ) 으로 가 는 간접 적 효과 등 을 비교 할 수 있 는 장점 또한 있 습니다 . 지금 까지 전혀 어렵 지 않 으시 죠 ? 그럼 다음 으로 넘어가 볼까요 ? 3 이번 엔 경로 분석 ( path analysis ) 에 대해서 알아보 도록 하 겠 습니다 . 일단 경로 분석 은 축자 모델 ( recursive model ) 과 비 축자 모델 ( non - recursive model ) 로 나뉘 질 수 있 습니다 . 축자 모델 은 변수 간 에 쌍방향 인과관계 ( reciprocal causation ) 나 순환 적 인과 관계 ( feedback loops ) 가 없 는 것 이 고 비 축자 모델 은 이러 한 것 들 이 있 는 것 입니다 . 무슨 소린지 잘 모르 시 겠 다구요 ? 일단 그림 을 보 세요 . 첫 번 째 그림 은 축자 모델 입니다 . 모든 화살표 ( 경로 ) 들 이 오로지 한 방향 으로 만 움직이 고 있 습니다 ( 왼쪽 에서 오른쪽 으로 ) . 즉 순환 적 인과 관계 나 쌍방향 인과 관계 가 없 는 모델 이 바로 축자 모델 이 라 할 수 있 습니다 . 그 다음 은 비 축자 모델 입니다 . 축자 모델 과 다른 점 은 화살표 들 이 서로 주고받 는 것 이 다른 점 입니다 . 다시 말 해서 순환 적 인과 관계 나 쌍방향 인과 관계 가 있 는 모델 이 라고 할 수 있 습니다 . 이런 모델 을 우리 는 비 축자 모델 이 라고 합니다 . 4 다음 은 요인 분석 에 대한 설명 입니다 . 요인 분석 은 크 게 두 가지 로 분류 될 수 있 습니다 . 첫째 는 탐색 적 요인 분석 방법 으로써 주로 spss 등 에서 쓰여 지 는 방법 입니다 . 그리고 나머지 한 가지 는 구조 방정식 모델 에서 쓰여 지 는 확인 적 요인 분석 방법 이 되 겠 습니다 . 첫째 로 탐색 적 요인 분석 의 경우 수많 은 항목 들 을 비슷 한 항목 들 로 줄이 기 위한 방법 으로 주로 varimax 기법 을 통한 eigen value 를 기준 으로 묶여 집니다 . 항목 의 숫자 를 줄이 고 분석 의 효율 성 을 높이 기 위해 쓰여 지 는 방법 이 라고 말씀 드릴 수 있 습니다 . 하지만 중요 한 점 은 이 방법 은 요인 분석 을 하 기 전 에 어떠 한 항목 들 이 서로 묶인 다고 단정 할 수 없 다는 점 입니다 . 다시 말 하 면 수리 적 분석 에 의해 ( 각 성분 들 이 1 개 이상 의 요인 들 로 묶여 지 게 됨 ) 요인 들 이 결정 이 됩니다 . ( 1 ) 탐색 적 요인 분석 ( exploratory factor analysis , 주로 spss 에서 쓰이 는 방법 이 죠 ) 이 에 반해 확인 적 요인 분석 방법 은 탐색 적 요인 분석 과 는 전혀 다른 분석 방법 이 사용 됩니다 . 우선 탐색 적 분석 방법 처럼 요인 들 을 서로 수치 적 결과 에 따라 묶 는 것 이 아니 라 , 이론 적 배경 에 의해서 잠재변수 를 구성 하 는 관측 변수 들 이 이미 지정 되 어 있 다는 점 입니다 . 이 점 이 탐색 적 요인 분석 과 가장 다른 점 이 라고 할 수 있 습니다 . 다시 말 해서 항목 들 이 탐색 적 요인 분석 에 상관없이 , 이미 잠재변수 를 구성 하 는 관측 변수 들 이 이론 적 배경 에 의해 정해져 있 고 그 상황 하 에서 모델 이 만들 어 지 면 분석 되 는 방법 이 라고 할 수 있 습니다 . ( 2 ) 확인 적 요인 분석 ( confirmatory factor analysis , 주로 sem 에서 쓰이 는 방법 이 죠 ) ( 3 ) 고차 요인 분석 ( higher - order factor analysis ) 이 경우 는 확인 적 요인 분석 이 두 번 째 됐 다고 ( 두 번 실시 되 었 다고 ) 보 면 이해 하 기 쉬운 경우 입니다 . 5 이번 에 는 reflective model 과 formative model 에서 알아보 도록 하 겠 습니다 . 일단 reflective model 은 factor view of multidimensional constructs 로 불리 기 도 하 며 , formative model 은 composite view of multidimensional constructs 라고 도 불립니다 . 일단 두 모델 의 모형 은 다음 과 같 습니다 . ( 1 ) reflective model 처음 모델 은 우리 가 지금 까지 얘기 했 던 모델 이 라고 할 수 있 습니다 . ( 2 ) formative model 그런데 두 번 째 모델 은 뭔가 가 좀 다르 죠 ? 맞 습니다 . 화살표 가 첫 번 째 모델 과 반 대로 되 어 있 음 을 알 수 있 습니다 . 바로 처음 모델 은 우리 가 지금 까지 사용 한 reflective model 이 고 , 두 번 째 모델 이 바로 formative model 입니다 . 그럼 저 모델 이 어떻게 다른지 알 아 볼까요 ? 언뜻 보 기 엔 아주 비슷 하 게 보이 지만 큰 차이 가 있 습니다 . 첫 번 째 모델 의 경우 그림 에서 나타난 것 처럼 밑 에 세 개 의 관측 변수 가 위 의 잠재변수 를 형성 합니다 . 예 를 들 어서 toefl 시험 점수 의 경우 이 를 측정 하 는 데 읽 기 ( reading ) , 쓰 기 ( writing ) , 듣 기 ( listening ) 로 구성 되 어 있 으므로 toeel 은 3 가지 관측 변수 의 잠재변수 가 되 는 것 이 죠 . 이 세 가지 변수 들 이 toefl 점수 의 관측 변수 가 되 며 서로 긴밀 하 게 연관 되 어 있 을 뿐 만 아니 라 toefl 은 이 세 가지 변수 들 로써 구성 되 어 있 다는 것 을 뜻 합니다 . 그럼 두 번 째 모델 을 볼까요 ? 위 에 보인 두 번 째 모델 은 유명 한 socio - economic status ( ses ) 모델 입니다 . 여기 선 사람 의 사회 경제 적 지위 ( ses ) 를 수입 수준 ( income level , inc ) , 직업 적 명성 ( occupational prestige , pre ) , 그리고 교육 수준 ( education , eud ) 으로 나누 었 습니다 . 이 모델 에서 는 보 시 다시피 밑 에 있 는 세 개 의 요인 들 이 사람 의 사회 경제 적 지위 를 형성 하 고 있 는 모습 을 보여 줍니다 . 다시 말 해서 세 가지 요인 이 모두 사회 적 지위 에 영향 을 미친다고 보 는 겁니다 . 위 의 것 ( 토플 점수 모델 ) 은 위 의 잠재변수 가 밑 에 있 는 관측 변수 에 영향 을 미치 지만 , 두 번 째 모델 ( ses 모델 ) 은 밑 의 요인 들 이 위 의 변수 에 영향 을 미치 는 겁니다 . 그리고 또 하나 다른 점 은 변수 들 간 의 상관관계 입니다 . 앞서 말 했 듯이 읽 기 , 쓰 기 , 듣 기 는 서로 강하 게 연관 되 어 있 지만 , 두 번 째 경우 수입 수준 과 직업 적 명성 그리고 교육 수준 은 어느 정도 상관 은 있 지만 서로 강하 게 연관 돼 있 지 않 습니다 . 수입 이 높 다고 그 사람 의 교육 수준 이 높 은 것 은 아니 고 직업 이 사회 적 으로 존경 받 는 자리 라고 하 더라도 수입 이 많 은 건 아닌 것 과 비슷 한 이치 입니다 . 또 다른 하나 는 에러 변수 인데 일단 reflective 의 경우 측정 에러 ( measurement ) 가 있 으나 formative 경우 에러 가 존재 하 지 않 습니다 . 왜냐하면 변수 에 영향 을 미치 는 변수 들 이 외생 변수 이 기 때문 입니다 . 이 두 모델 간 의 에러 변수 에 대해선 상당히 복잡 한 설명 이 필요 하 므로 여기 선 생략 하 도록 하 겠 습니다 . 사실 학계 에서 도 이 두 가지 모델 에 대해서 여러 가지 연구 결과 와 학설 이 나오 고 있 지만 ( ses 모델 도 reflective model 로 보 시 는 분 들 도 계십니다 ) , 일단 이런 정도 로 만 아셔도 여러분 이 두 모델 의 개념 을 잡 으시 는데 충분히 도움 이 됐 으리라 생각 합니다 . 6 이번 에 는 두 그룹 이상 의 모델 에서 어떻게 구조 방정식 모델 을 사용 하 는지 알아보 겠 습니다 . 개인 적 으로 multiple group analysis 야 말 로 구조 방정식 의 백미 라고 말씀 드리 고 싶 습니다 . 그 이유 는 이 구조 방정식 모델 안 에 필요 한 많 은 분석 방법 들 이 사용 되 기 때문 입니다 . 주로 남자 나 여자 그룹 , 어떠 한 분류 에 따른 높 은 집단 혹은 낮 은 집단 , 그리고 국가 별 인종 별 등 의 그룹 으로 나누 어서 한 모델 안 에 그룹 간 의 차이 가 없 는지 있 는지 , 있 다면 어느 점 에서 차이 가 나 는지 등 을 알 수 있 습니다 . 제 가 이 분석 방법 전 에 반드시 알려 드리 고 싶 은 점 은 절대로 그룹 분석 시 두 그룹 을 따로따로 돌려서 경로 간 의 크기 를 비교 하 지 말 라는 점 입니다 ( 예 로 베타 나 감마 값 비교 ) . 이건 논리 적 으로 따지 자면 다른 두 수학 시험지 를 다른 두 반 학생 들 에게 보 게 한 후 한 반 이 다른 반 학생 들 과 비교 해서 시험 을 \\' 잘 봤 다 \\' 혹은 \\' 못 봤 다 \\' 하 는 이치 입니다 . 다시 말 해서 논리 적 으로 말 이 전혀 안 되 는 경우 죠 . 우리 가 두 집단 을 비교 하 기 위해선 우선 시험지 가 같 은지 그것 을 확인 하 는 작업 이 필요 한 겁니다 . 이게 그룹 분석 의 가장 중요 한 점 입니다 . 그리고 많 은 논문 에서 무시 되 어 져 왔 던 부분 이 기 도 하 구요 . 예 를 들 어서 아래 와 같 은 두 집단 에서 모델 을 비교 한다고 가정 해 보 겠 습니다 . 우선 우리 가 사례 분석 2 에서 보여준 모델 을 기본 으로 하 죠 . 일단 기본 모델 을 바탕 으로 한국 과 일본 직장인 을 비교 를 한다고 가정 해 보 도록 하 겠 습니다 . 우선 이 분석 방법 을 이용 하 기 위해서 위 와 같 은 두 개 의 그룹 을 만듭니다 . 물론 모델 자체 는 같 지만 한국 직장인 과 일본 직장인 에 관한 데이터 는 각기 다르 므로 같 은 모델 을 기본 으로 두 개 의 그룹 을 만듭니다 . 그 후 에 하 는 절차 가 두 그룹 간 확인 적 요인 분석 하 는 것 입니다 . 그래서 두 그룹 간 관측 변수 와 잠재변수 사이 의 람다 값 이 좋 고 두 그룹 을 제약 했 을 경우 유의 한 차이 가 나 지 않 으면 ( 카이 스퀘어 를 통한 방법 을 통해 ) 다음 단계 인 모델 비교 로 넘 어 가 는 것 입니다 . 이 과정 이 다시 말 해서 두 시험지 가 두 반 학생 에게 똑같 은 다른지 판별 하 는 방법 이 라고 할 수 있 겠 습니다 . 만약 제약 모델 과 원래 모델 이 다르 다면 다음 단계 로 넘어간다 하 더라도 모델 분석 에 의미 가 없 습니다 . 왜냐하면 이미 두 그룹 간 설문지 자체 가 동등 하 지 못하 다고 여겨 지 기 때문 입니다 . 그 다음 은 만약 두 모델 에서 확인 적 요인 분석 을 마쳤 다면 두 모델 간 경로 들 간 에 차이 가 있 는지 없 는지 를 확인 하 는 차례 입니다 . 여기 선 물론 여러 가지 방법 이 있 습니다 . eqs 프로그램 의 경우 lm test 를 통하 여 결과 를 알 수 있 고 , lisrel 이나 amos 의 경우 각각 의 경로 들 을 서로 제약 해서 결과 를 찾아내 는 방법 이 있 습니다 . 위 에 방법 은 사실 머리 가 아플 정도 로 복잡 하 기 때문 에 일단 여기 선 간단 한 개념 만 설명 드렸 습니다 . 물론 아주 자세 한 방법 을 아 는 것 이 중요 하 지만 , 위 에서 간단히 말씀 드린 것 처럼 그룹 분석 의 개념 만 일단 알 아두 셔도 상당 한 도움 이 되 시 리라 믿 습니다 . 7 이 장 에선 그룹 간 constraint model ( 제약 모델 ) 에 대해 잠깐 설명 하 고자 합니다 . 사례 분석 6 에 나왔 던 상황 일 경우 이 경우 가 사용 됩니다 . 기본 적 인 개념 은 두 그룹 간 혹은 한 모델 내 에서 경로 들 을 서로 같 다고 정해 주 는 방법 으로 경로 간 크기 나 그룹 간 경로 들 간 의 차이 를 보 는 방법 이 라고 말씀 드릴 수 있 겠 습니다 . 우선 첫 번 째 모델 과 두 번 째 모델 은 그룹 분석 의 경우 에 수입 만족도 ( income satisfaction ) 와 직장 만족도 ( job satisfaction ) 로 가 는 경로 를 한국 직장 인 그룹 과 일본 직장 인 그룹 간 에 똑같이 제약 을 해 준 경우 입니다 . 이런 제약 을 한 후 카이 스퀘어 값 으로 유의 한 차이 를 검증 합니다 . 그리고 마지막 세 번 째 모델 의 경우 한 모델 안 에서 income satisfaction -> job satisfaction 으로 가 는 경로 와 work environment -> job satisfaction 으로 가 는 경로 들 을 제약 해 주 는 경우 입니다 . 이 와 같 은 제약 모델 을 통해서 우리 는 경로 간 에 유의 한 차이 가 있 는지 없 는지 를 알 수 있 게 되 는 겁니다 . 8 마지막 으로 sem 의 전반 적 인 모델 을 보여 드리 겠 습니다 . 저희 웹 사이트 에 있 는 구조 방정식 모델 예제 에서 실제 해외 논문 에서 발표 된 모델 들 을 찾아보 세요 . 실제 여러분 께서 읽 은 내용 의 모델 들 이 나온답니다 .',\n",
       "       '안녕 하 세요 . 스쿨 오브 웹 의 이상희 입니다 . 이번 강좌 에서 는 파이썬 의 퍼스트 클래스 함수 ( first - class fuction ) 에 대해서 알 아 보 도록 하 겠 습니다 . 퍼스트 클래스 함수 란 프로그래밍 언어 가 함수 ( function ) 를 first - class citizen 으로 취급 하 는 것 을 뜻 합니다 . 쉽 게 설명 하 자면 함수 자체 를 인자 ( argument ) 로써 다른 함수 에 전달 하 거나 다른 함수 의 결과 값 으로 리턴 할 수 도 있 고 , 함수 를 변수 에 할당 하 거나 데이터 구조 안 에 저장 할 수 있 는 함수 를 뜻 합니다 . 조금 어려운 가요 ? 그럼 실습 을 하 면서 설명 을 하 도록 하 지요 . 실습 을 위해서 원 하 는 디렉터리 안 에 \" first _ class _ function . py \" 라는 이름 의 파일 을 하나 만들 든 후 , 다음 의 코드 를 입력 하 여 주 십시오 . first _ class _ function . py # -*- coding : utf - 8 -*- def square ( x ) : return x * x print square ( 5 ) f = square print square print f 파일 을 저장 한 후 , 파일 이 저장 된 디렉터리 에서 터미널 이나 , 커맨드 창 을 열 고 다음 의 명령어 로 파이썬 파일 을 실행 해 봅시다 . $ python first _ class _ function . py 25 위 의 코드 를 보 면 아주 간단 한 함수 \" square \" 를 정의 하 고 호출 하 였 습니다 . 그 다음 에 square 함수 를 \" f \" 라는 변수 에 할당 한 후 에 square 와 f 의 값 을 출력 해 보 았 습니다 . 둘 다 메모리 주소 값 인 0 x 1018 dfe 60 에 저장 된 square 함수 오브젝트 가 할당 되 어 있 는 것 을 볼 수 있 습니다 . 그럼 f 도 진짜 함수 처럼 호출 을 할 수 있 는지 볼까요 . 다음 과 같이 코드 를 수정 하 고 저장 한 다음 에 실행 하 여 주 십시오 . first _ class _ function . py # -*- coding : utf - 8 -*- def square ( x ) : return x * x f = square print f ( 5 ) $ python first _ class _ function . py 25 f ( 5 ) 구문 으로 square 함수 를 호출 한 것 을 볼 수 있 습니다 . 위 에서 언급 했 듯이 프로그래밍 언어 가 퍼스트 클래스 함수 를 지원 하 면 , 금방 해 본 것 처럼 변수 에 함수 를 할당 할 수 있 을 뿐 만 아니 라 , 인자 로써 다른 함수 에 전달 하 거나 , 함수 의 리턴 값 으로 도 사용 할 수 가 있 습니다 . 다음 예제 를 보 면서 설명 을 하 겠 습니다 . 다음 과 같이 코드 를 수정 하 고 저장 한 다음 에 실행 하 여 주 십시오 . first _ class _ function . py # -*- coding : utf - 8 -*- def square ( x ) : return x * x def my _ map ( func , arg _ list ) : result = [ ] for i in arg _ list : result . append ( func ( i ) ) # square 함수 호출 , func == square return result num _ list = [ 1 , 2 , 3 , 4 , 5 ] squares = my _ map ( square , num _ list ) print squares $ python first _ class _ function . py [ 1 , 4 , 9 , 16 , 25 ] my _ map 함수 에 square 함수 를 인자 로 전달 한 후 for 루프 안 에서 square 함수 를 호출 한 것 을 볼 수 있 습니다 . 그런데 밑 에 와 같이 simple _ sqaure 함수 하나 로 문제 를 해결 하 면 되 지 않 냐고 생각 하 시 는 분 들 이 있 으실 겁니다 . 다음 과 같이 코드 를 수정 하 고 저장 한 다음 에 실행 하 여 주 십시오 . first _ class _ function . py # -*- coding : utf - 8 -*- def square ( x ) : return x * x num _ list = [ 1 , 2 , 3 , 4 , 5 ] def simple _ square ( arg _ list ) : result = [ ] for i in arg _ list : result . append ( i * i ) return result simple _ squares = simple _ square ( num _ list ) print simple _ squares $ python first _ class _ function . py [ 1 , 4 , 9 , 16 , 25 ] 옹 ? !?, 더 간단 한 코드 로 같 은 결과 가 나왔 습니다 . 그렇 습니다 . 간단히 함수 하나 만 을 실행 하 고 싶 을 때 는 simple _ square 와 같 은 일반 함수 를 사용 하 여 같 은 결과 를 낼 수 도 있 습니다 . 하지만 , 퍼스트 클래스 함수 를 사용 하 면 이미 정의 된 여러 함수 를 간단히 재 활용 할 수 있 다는 장점 이 있 습니다 . 아래 의 예제 를 다시 보 도록 하 죠 . 다음 과 같이 코드 를 수정 하 고 저장 한 다음 에 실행 하 여 주 십시오 . first _ class _ function . py # -*- coding : utf - 8 -*- def square ( x ) : return x * x def cube ( x ) : return x * x * x def quad ( x ) : return x * x * x * x def my _ map ( func , arg _ list ) : result = [ ] for i in arg _ list : result . append ( func ( i ) ) # square 함수 호출 , func == square return result num _ list = [ 1 , 2 , 3 , 4 , 5 ] squares = my _ map ( square , num _ list ) cubes = my _ map ( cube , num _ list ) quads = my _ map ( quad , num _ list ) print squares print cubes print quads $ python first _ class _ function . py [ 1 , 4 , 9 , 16 , 25 ] [ 1 , 8 , 27 , 64 , 125 ] [ 1 , 16 , 81 , 256 , 625 ] 위 의 예제 와 같이 이미 정의 되 어 있 는 함수 square , cube , quad 와 같 은 여러 개 의 함수 나 모듈 이 있 다고 가정 했 을 때 my _ map 과 같 은 wrapper 함수 를 하나 만 정의 하 여 기존 의 함수 나 모듈 을 수정 할 필요 없이 편리 하 게 쓸 수 가 있 는 겁니다 . 그렇 다면 이번 에 는 함수 의 결과 값 으로 또 다른 함수 를 리턴 하 는 방법 을 살펴보 겠 습니다 . 아주 간단 한 로 깅 함수 를 만들 어 보 겠 습니다 . 다음 과 같이 코드 를 수정 하 고 저장 한 다음 에 실행 하 여 주 십시오 . first _ class _ function . py # -*- coding : utf - 8 -*- def logger ( msg ) : def log _ message ( ) : # 1 print \\' log : \\', msg return log _ message log _ hi = logger ( \\' hi \\') print log _ hi # log _ message 오브젝트 가 출력 됩니다 . log _ hi ( ) # \" log : hi \" 가 출력 됩니다 . $ python first _ class _ function . py log : hi 위 의 # 1 에서 정의 된 log _ message 라는 함수 를 logger 함수 의 리턴 값 으로 리턴 하 여 log _ hi 라는 변수 에 할당 한 후 호출 한 것 을 볼 수 있 습니다 . 그런데 여기 서 특이 한 점 을 볼 수 있 습니다 . msg 와 같 은 함수 의 지역 변수 값 은 함수 가 호출 된 이후 에 메모리 상 에서 사라지 므로 다시 참조 할 수 가 없 는데 , msg 변수 에 할당 됐 던 \\' hi \\' 값 이 logger 함수 가 종료 된 이후 에 도 참조 됐 다는 것 입니다 . 이런 log _ message 와 같 은 함수 를 \" 클로저 ( closure ) \" 라고 부르 며 클로저 는 다른 함수 의 지역 변수 를 그 함수 가 종료 된 이후 에 도 기억 을 할 수 가 있 습니다 . log _ message 가 정말 기억 을 하 고 있 는지 msg 변수 를 지역 변수 로 가지 고 있 는 logger 함수 를 글로벌 네임 스페이스 에서 완전히 지운 후 , log _ message 를 호출 하 여 보 겠 습니다 . 다음 과 같이 코드 를 수정 하 고 저장 한 다음 에 실행 하 여 주 십시오 . first _ class _ function . py # -*- coding : utf - 8 -*- def logger ( msg ) : def log _ message ( ) : # 1 print \\' log : \\', msg return log _ message log _ hi = logger ( \\' hi \\') print log _ hi # log _ message 오브젝트 가 출력 됩니다 . log _ hi ( ) # \" log : hi \" 가 출력 됩니다 . del logger # 글로벌 네임 스페이스 에서 logger 오브젝트 를 지 웁 니다 . # logger 오브젝트 가 지워진 것 을 확인 합니다 . try : print logger except nameerror : print \\' nameerror : logger 는 존재 하 지 않 습니다 . \\' log _ hi ( ) # logger 가 지워진 뒤 에 도 log : hi \" 가 출력 됩니다 . $ python first _ class _ function . py log : hi logger 는 존재 하 지 않 습니다 . log : hi logger 가 지워진 뒤 에 도 log _ hi ( ) 를 실행 하 여 log _ message 가 호출 된 것 을 볼 수 있 습니다 . logger 함수 를 완전히 삭제 한 이후 에 도 log _ message 함수 는 \\' hi \\' 를 기억 하 고 있 는 것 을 확인 했 습니다 . 이런 식 으로 closure 는 여러 가지 로 편리 하 게 쓰여질 때 가 많 은데 , closure 에 대해서 는 다른 강좌 에서 자세히 알 아 보 겠 습니다 . 이번 에 는 조금 더 실용 적 인 예제 를 보 도록 하 겠 습니다 . 다음 과 같이 코드 를 수정 하 고 저장 한 다음 에 실행 하 여 주 십시오 . first _ class _ function . py # -*- coding : utf - 8 -*- # 단순 한 일반 함수 def simple _ html _ tag ( tag , msg ) : print \\'<{ 0 }>{ 1 }<{ 0 }>\\'. format ( tag , msg ) simple _ html _ tag ( \\' h 1 \\', \\' 심플 헤딩 타이틀 \\') print \\'-\\'* 30 # 함수 를 리턴 하 는 함수 def html _ tag ( tag ) : def wrap _ text ( msg ) : print \\'<{ 0 }>{ 1 }<{ 0 }>\\'. format ( tag , msg ) return wrap _ text print _ h 1 = html _ tag ( \\' h 1 \\') # 1 print print _ h 1 # 2 print _ h 1 ( \\' 첫 번 째 헤딩 타이틀 \\') # 3 print _ h 1 ( \\' 두 번 째 헤딩 타이틀 \\') # 4 print _ p = html _ tag ( \\' p \\') print _ p ( \\' 이것 은 패러 그래프 입니다 . \\') $ python first _ class _ function . py 심플 헤딩 타이틀 - - - - - ------------------------- 첫 번 째 헤딩 타이틀 두 번 째 헤딩 타이틀 이것 은 패러 그래프 입니다 . # 1 에서 html _ tag 함수 를 print _ h 1 변수 에 할당 한 후 , # 2 에서 변수 의 값 을 출력 하 니 wrap _ text 함수 오브제 트 가 할당 되 어 있 는 것 을 볼 수 있 습니다 . 그리고 # 3 과 # 4 에서 간단히 문자열 을 전달 하 여 wrap _ text 함수 를 호출 한 것 을 볼 수 있 습니다 . 지금 많 은 분 들 이 복잡 한 wrapper 함수 를 사용 하 지 않 고 도 위 의 simple _ html _ tag 과 같 은 일반 함수 를 사용 하 면 안 되 는가 하 는 의문 을 가지 는 분 들 이 있 으실 겁니다 . 하지만 , html _ tag 와 같 은 higher - order 함수 등 을 이해 해야 뒤 의 강좌 에서 배울 클로저 ( closure ) , 데코레이터 ( decorator ) 또는 제너 레이터 ( generator ) 등 에 대해서 쉽 게 이해 할 수 가 있 습니다 . 데코레이터 와 제너 레이터 등 의 구문 을 사용 하 시 면 이전 과 는 전혀 다른 새로운 차원 의 코딩 을 하 실 수 가 있 습니다 .',\n",
       "       '1 . 객체 지향 프로그래밍 ( oop ) 은 무엇 인가 ? 왜 사용 하 는가 ? 2 . 클래스 와 인 스턴스 ( class and instance ) 3 . 클래스 변수 ( class variable ) 4 . 클래스 메소드 와 스 태 틱 메소드 ( class method and static method ) 5 . 상속 과 서브 클래스 ( inheritance and subclass ) 6 . 매직 메소드 ( magic method ) 7 . 속성 데코레이터 ( property decorator ) - gettes , setters , deleters oop 는 내용 이 조금 많 기 때문 에 다음 과 같이 본 강좌 를 포함 하 여 7 개 의 강좌 로 나눠서 진행 하 도록 하 겠 습니다 . 안녕 하 세요 . 스쿨 오브 웹 의 이상희 입니다 . 이번 강좌 에서 는 객체 지향 프로그래밍 ( object - oriented programming , oop ) 에 대해서 알 아 보 겠 습니다 . 만약 에 코딩 을 할 때 복사 와 붙이 기 를 많이 하 신다면 그 코드 에 는 중복 되 는 코드 가 많 다는 뜻 이 고 , 이런 중복 되 는 부분 은 많 은 문제 를 발생 시키 기 때문 에 필히 최소 화 할 필요 가 있 습니다 . 중복 되 는 코드 는 코딩 의 시간 을 늘릴 뿐 아니 라 , 골치 아픈 버그 를 만들 어 내 고 , 코드 변경 시 수많 은 곳 을 수정 해야 하 는 문제 를 발생 시킵니다 . 그래서 일반 적 으로 이런 중복 된 코드 를 줄이 기 위해서 함수 를 사용 합니다 . 함수 를 사용 하 면 한 번 정의 한 함수 를 필요 한 곳 에서 호출 만 하 면 되 고 , 코드 를 수정 해야 할 때 는 한 곳 만 수정 하 면 됩니다 . oop 역시 함수 와 비슷 하 게 반복 되 는 코드 를 없애 서 코딩 시간 을 줄여 주 며 , 코드 의 관리 를 더 간단 하 게 해줍니다 . 하지만 한 번 사용 하 고 버리 는 불 필요 한 클래스 를 만드 는 것 또한 피해야 한다는 점 을 잊 어서 는 안 됩니다 . 일반 적 으로 프로그램 을 만들 때 항상 염두 에 둬야 할 아주 중요 한 포인트 2 가지 가 있 습니다 . 프로그램 은 특수 한 목적 을 가지 고 데이터 를 처리 하 기 위하 여 만들 어 집니다 . 그런데 복잡 한 데이터 를 수많 은 함수 로 만 처리 하 다 보 면 여러 가지 에러 와 버그 가 발생 하 는 문제점 이 나타납니다 . oop 는 이러 한 문제 를 해결 하 고 복잡 한 데이터 를 조금 더 쉽 게 처리 하 게 도와 줍니다 . 그렇 다면 oop 는 무엇 일까요 ? oop 란 클래스 란 이름 의 블 루 프린트 를 이용 하 여 새로운 데이터 타입 을 만들 어 데이터 와 함수 ( 클래스 안 에서 는 메소드 라고 부름 ) 의 논리 적 그룹 을 만들 어 사용 하 는 것 이 라고 생각 하 시 면 됩니다 . 위키백과 에 oop 에 대한 정의 는 다음 과 같 습니다 . 객체 지향 프로그램 은 왜 사용 하 는가 ? 이번 강좌 에서 는 먼저 어떤 경우 에 클 래스 를 사용 해야 하 는지 에 대해서 알아보 고 , 다음 강좌 부터 는 클래스 의 기능 과 사용법 을 알아보 도록 하 겠 습니다 . 우리 가 좋 아 하 는 게임 의 캐릭터 를 만드 는 예제 를 보 도록 하 죠 . 이름 , 에너지 , 데미지 , 인벤토리 를 가진 간단 한 케릭 터 를 만들 어 보 려고 합니다 . 만약 에 클 래스 를 사용 하 지 않 으면 다음 과 같이 케 릭터 를 정의 할 수 있 을 겁니다 . 원 하 는 디렉터리 에 \" oop . py \" 라는 이름 의 파이썬 파일 을 만든 후 , 다음 의 코드 를 저장 하 여 주 십시오 . oop . py # -*- coding : utf - 8 -*- hero _ name = \\' 아이언맨 \\' hero _ health = 100 hero _ damage = 200 hero _ inventory = [ {\\' gold \\': 500 }, {\\' weapon \\': \\' 레이저 \\'} ] \" 아이언맨 \" 이 라는 이름 을 가진 케릭 터 를 만들 어 봤 습니다 . 그런데 게임 에 케 릭터 가 하나 만 있 으면 안 되 겠 죠 ? 히어로 와 몬스터 케릭 터 를 더 추가 하 겠 습니다 . oop . py # -*- coding : utf - 8 -*- # 히어로 1 hero _ 1 _ name = \\' 아이언맨 \\' hero _ 1 _ health = 100 hero _ 1 _ damage = 200 hero _ 1 _ inventory = [ {\\' gold \\': 500 }, {\\' weapon \\': \\' 레이저 \\'} ] # 히어로 2 hero _ 2 _ name = \\' 데드 풀 \\' hero _ 2 _ health = 300 hero _ 2 _ damage = 30 hero _ 2 _ inventory = [ {\\' gold \\': 300 }, {\\' weapon \\': \\' 장검 \\'} ] # 히어로 3 hero _ 3 _ name = \\' 울버린 \\' hero _ 3 _ health = 200 hero _ 3 _ damage = 50 hero _ 3 _ inventory = [ {\\' gold \\': 350 }, {\\' weapon \\': \\' 클로 \\'} ] # 몬스터 1 monster _ 1 _ name = \\' 고블린 \\' monster _ 1 _ health = 90 monster _ 1 _ damage = 30 monster _ 1 _ inventory = [ {\\' gold \\': 50 }, {\\' weapon \\': \\' 창 \\'} ] # 몬스터 2 monster _ 2 _ name = \\' 드래곤 \\' monster _ 2 _ health = 200 monster _ 2 _ damage = 80 monster _ 2 _ inventory = [ {\\' gold \\': 200 }, {\\' weapon \\': \\' 화염 \\'} ] # 몬스터 3 monster _ 3 _ name = \\' 뱀파이어 \\' monster _ 3 _ health = 80 monster _ 3 _ damage = 120 monster _ 3 _ inventory = [ {\\' gold \\': 1000 }, {\\' weapon \\': \\' 최면술 \\'} ] 누군가 프로그래밍 의 기본 은 복사 와 붙여 넣 기 라고 했 는데 . .. 열심히 복사 해서 붙여 넣 었 습니다 . ㅎ 그런데 위 의 코드 는 누가 봐도 잘 만들 어 진 코드 는 아닌 것 같 네요 . 리스트 를 사용 하 여 조금 더 세련 된 코드 를 만들 어 보 겠 습니다 . oop . py # -*- coding : utf - 8 -*- hero _ name = [ \\' 아이언맨 \\', \\' 데드 풀 \\', \\' 울버린 \\'] hero _ health = [ 100 , 300 , 200 ] hero _ damage = [ 200 , 30 , 50 ] hero _ inventory = [ {\\' gold \\': 500 , \\' weapon \\': \\' 레이저 \\'}, {\\' gold \\': 300 , \\' weapon \\': \\' 장검 \\'}, {\\' gold \\': 350 , \\' weapon \\': \\' 클로 \\'} ] monster _ name = [ \\' 고블린 \\', \\' 드래곤 \\', \\' 뱀파이어 \\'] monster _ health = [ 90 , 200 , 80 ] monster _ damage = [ 30 , 80 , 120 ] monster _ inventory = [ {\\' gold \\': 50 , \\' weapon \\': \\' 창 \\'}, {\\' gold \\': 200 , \\' weapon \\': \\' 화염 \\'}, {\\' gold \\': 1000 , \\' weapon \\': \\' 최면술 \\'} ] 이제 \" 아이언맨 \" 은 인덱스 0 , \" 데드 풀 \" 은 인덱스 1 , \" 울버린 \" 은 인덱스 2 를 사용 하 여 케 릭터 의 데이터 에 엑세스 할 수 가 있 습니다 . 그런데 위 와 같 은 코드 는 쉽 게 버그 를 만들 어 냅니다 . 그 예 를 볼까요 ? # -*- coding : utf - 8 -*- import json hero _ name = [ \\' 아이언맨 \\', \\' 데드 풀 \\', \\' 울버린 \\'] hero _ health = [ 100 , 300 , 200 ] hero _ damage = [ 200 , 30 , 50 ] hero _ inventory = [ {\\' gold \\': 500 , \\' weapon \\': \\' 레이저 \\'}, {\\' gold \\': 300 , \\' weapon \\': \\' 장검 \\'}, {\\' gold \\': 350 , \\' weapon \\': \\' 클로 \\'} ] monster _ name = [ \\' 고블린 \\', \\' 드래곤 \\', \\' 뱀파이어 \\'] monster _ health = [ 90 , 200 , 80 ] monster _ damage = [ 30 , 80 , 120 ] monster _ inventory = [ {\\' gold \\': 50 , \\' weapon \\': \\' 창 \\'}, {\\' gold \\': 200 , \\' weapon \\': \\' 화염 \\'}, {\\' gold \\': 1000 , \\' weapon \\': \\' 최면술 \\'} ] # 히어로 가 죽 으면 호출 되 는 함수 def hero _ dies ( hero _ index ) : del hero _ name [ hero _ index ] del hero _ health [ hero _ index ] del hero _ damage [ hero _ index ] # <--- 개발자 가 실수 로 del hero _ inventory [ hero _ index ] 를 빠뜨렸 네요 . hero _ dies ( 0 ) print hero _ name [ 0 ] print hero _ health [ 0 ] print hero _ damage [ 0 ] print json . dumps ( hero _ inventory [ 0 ] , ensure _ ascii = false ) 파일 을 저장 한 후 , 실행 하 여 보 겠 습니다 . $ python oop . py 데드 풀 300 30 {\" weapon \": \" 레이저 \", \" gold \": 500 } 위 의 코드 와 같이 히어로 의 에너지 가 0 이 되 어 죽 었 을 때 히어로 를 리스트 에서 지우 는 함수 를 추가 했 습니다 . 그런데 개발자 가 실수 로 코드 한 줄 을 넣 지 않 았 다면 \" 데드 풀 \" 이 죽 은 \" 아이언맨 \" 의 레이저 를 사용 하 게 되 는 문제 가 발생 합니다 . 이러 한 문제 는 밑 의 코드 와 같이 각 히어로 의 데이터 를 파이썬 사전 에 넣 어 리스트 로 묶 어서 해결 할 수 있 습니다 . # -*- coding : utf - 8 -*- import json heroes = [ {\\' name \\': \\' 아이언맨 \\', \\' health \\': 100 , \\' damage \\': 200 , \\' inventory \\': {\\' gold \\': 500 , \\' weapon \\': \\' 레이저 \\'}}, {\\' name \\': \\' 데드 풀 \\', \\' health \\': 300 , \\' damage \\': 30 , \\' inventory \\': {\\' gold \\': 300 , \\' weapon \\': \\' 장검 \\'}}, {\\' name \\': \\' 울버린 \\', \\' health \\': 200 , \\' damage \\': 50 , \\' inventory \\': {\\' gold \\': 350 , \\' weapon \\': \\' 클로 \\'}} ] monsters = [ {\\' name \\': \\' 고블린 \\', \\' health \\': 90 , \\' damage \\': 30 , \\' inventory \\': {\\' gold \\': 50 , \\' weapon \\': \\' 창 \\'}}, {\\' name \\': \\' 드래곤 \\', \\' health \\': 200 , \\' damage \\': 80 , \\' inventory \\': {\\' gold \\': 200 , \\' weapon \\': \\' 화염 \\'}}, {\\' name \\': \\' 뱀파이어 \\', \\' health \\': 80 , \\' damage \\': 120 , \\' inventory \\': {\\' gold \\': 1000 , \\' weapon \\': \\' 최면술 \\'}} ] print json . dumps ( heroes , ensure _ ascii = false ) del heroes [ 0 ] print json . dumps ( heroes , ensure _ ascii = false ) $ python oop . py [ {\" inventory \": {\" weapon \": \" 레이저 \", \" gold \": 500 }, \" health \": 100 , \" name \": \" 아이언맨 \", \" damage \": 200 }, {\" inventory \": {\" weapon \": \" 장검 \", \" gold \": 300 }, \" health \": 300 , \" name \": \" 데드 풀 \", \" damage \": 30 }, {\" inventory \": {\" weapon \": \" 클로 \", \" gold \": 350 }, \" health \": 200 , \" name \": \" 울버린 \", \" damage \": 50 }] [ {\" inventory \": {\" weapon \": \" 장검 \", \" gold \": 300 }, \" health \": 300 , \" name \": \" 데드 풀 \", \" damage \": 30 }, {\" inventory \": {\" weapon \": \" 클로 \", \" gold \": 350 }, \" health \": 200 , \" name \": \" 울버린 \", \" damage \": 50 }] 이 방법 을 통해 데이터 핸들링 은 쉬워졌 지만 , 만약 히어로 의 인벤토리 에 여러 가지 아이템 을 가진 가방 이 있 다고 했 을 때 사전 과 리스트 는 중첩 이 되 고 코드 는 더욱 더 복잡 해질 것 입니다 . 또 다른 문제점 으로 는 똑같 은 코드 가 많이 반복 되 는 것 을 볼 수 가 있 습니다 . 이런 경우 가 oop 를 사용 해야 하 는 좋 은 예 입니다 . oop 를 사용 하 여 반복 되 는 코드 를 없애 고 사전 이나 리스트 가 지원 하 지 않 는 상속 과 같 은 클래스 의 기능 을 사용 할 수 가 있 습니다 . 위 에서 클래스 는 새로운 데이터 타입 을 만드 는 블 루 프린트 라고 했 습니다 . 블루 프린트 란 한국 말 로 \" 청사진 \" 이라고 부르 며 건축물 이나 자동차 를 설계 한 도면 입니다 . 자동차 의 모델 을 디자인 하 고 설계 한 블 루 프린트 를 이용 하 여 같 은 모델 의 자동차 를 원하 는 만큼 찍 어 낼 수 있 는 거 죠 . 프로그래밍 의 클래스 도 같 은 개념 입니다 . 위 의 히어로 와 몬스터 또한 같 은 종류 의 데이터 를 가지 고 있 기 때문 에 다음 의 코드 와 같이 클 래스 를 이용 하 여 논리 적 인 집합 으로 묶 을 수 가 있 습니다 . # -*- coding : utf - 8 -*- # class 정의 class character ( object ) : def __ init __( self , name , health , damage , inventory ) : self . name = name self . health = health self . damage = damage self . inventory = inventory def __ repr __( self ) : return self . name # character 클래스 의 오브젝트 생성 heroes = [ ] heroes . append ( character ( \\' 아이언맨 \\', 100 , 200 , {\\' gold \\': 500 , \\' weapon \\': \\' 레이저 \\'})) heroes . append ( character ( \\' 데드 풀 \\', 300 , 30 , {\\' gold \\': 300 , \\' weapon \\': \\' 장검 \\'})) heroes . append ( character ( \\' 울버린 \\', 200 , 50 , {\\' gold \\': 350 , \\' weapon \\': \\' 클로 \\'})) monsters = [ ] monsters . append ( character ( \\' 고블린 \\', 90 , 30 , {\\' gold \\': 50 , \\' weapon \\': \\' 창 \\'})) monsters . append ( character ( \\' 드래곤 \\', 200 , 80 , {\\' gold \\': 200 , \\' weapon \\': \\' 화염 \\'})) monsters . append ( character ( \\' 뱀파이어 \\', 80 , 120 , {\\' gold \\': 1000 , \\' weapon \\': \\' 최면술 \\'})) print heroes # 히어로 리스트 확인 print monsters # 몬스터 리스트 확인 del heroes [ 0 ] # 히어로 리스트 에서 아이언맨 삭제 print heroes # 히어로 리스트 재확인 $ python oop . py [ 아이언맨 , 데드 풀 , 울버린 ] [ 고블린 , 드래곤 , 뱀파이어 ] [ 데드 풀 , 울버린 ] \" character \" 라는 클래스 를 사용 하 여 oop 를 구현 해 보 았 습니다 . 아직 oop 에 대해서 감 이 오 지 않 는 분 들 은 걱정 하 지 마세요 . 이 oop 시리즈 를 모두 읽 으시 면 완벽히 이해 하 시 게 되 실 겁니다 . 😄 객체 지향 프로그램 에 대한 첫 소개 는 여기 까지 하 고 다음 강좌 에서 는 구체 적 인 클래스 사용법 에 대해서 알아보 도록 하 겠 습니다 .',\n",
       "       '안녕 하 세요 . 스쿨 오브 웹 의 이상희 입니다 . 이번 강좌 에서 는 클래스 와 인 스턴스 에 대해서 배우 도록 하 겠 습니다 . \" 파이썬 은 객체 지향 적 프로그래밍 언어 입니다 . 파이썬 의 모든 것 은 오브젝트 입니다 . 문자열 , 리스트 , 함수 , 심지어 모듈 또한 오브젝트 입니다 . ..\" 라고 하 는 얘기 는 귀 가 아프 도록 들으셨을 겁니다 . 그런데 도데체 오브젝트 가 무엇 일까요 ? 오브젝트 란 속성 과 같 은 여러 가지 의 데이터 와 함수 ( 오브젝트 안 에서 는 메소드 라고 부릅니다 . ) 를 포함 한 하나 의 데이터 구조 를 말 합니다 . 또한 파이썬 에서 이 오브젝트 들 은 변수 에 할당 될 수 도 있 고 , 함수 의 인자 로 전달 될 수 도 있 는 퍼스트 클래스 오브젝트 입니다 . 퍼스트 클래스 오브젝트 에 대해서 는 이전 강좌 인 퍼스트 클래스 함수 를 참고 하 여 주 십시오 . 오브젝트 란 ? 오브젝트 란 데이터 를 조금 더 쉽 게 다루 기 위해서 \" 네임 스페이스 \" 라는 것 을 이용 하 여 만든 논리 적 인 집합 입니다 . 학교 에서 학생 들 을 관리 하 기 위해서 학년 을 나누 고 반 을 나누 는 것 처럼 요 . 파이썬 사전 을 만드 는 것 과 클래스 와 모듈 로 데이터 집합 을 만드 는 것 모두 데이터 를 손쉽 게 저장 , 변경 또는 엑세스 할 수 있 도록 오브젝트 를 만드 는 것 입니다 . 네임 스페이스 에 대해서 는 모듈 을 다룰 때 자세히 설명 드리 겠 습니다 . 다음 의 코드 는 형식 만 다를 뿐 모두 논리 적 인 데이터 집합 인 오브젝트 를 만들 어 필요 한 데이터 에 엑세스 하 는 방법 을 보여 주 고 있 습니다 . 원 하 시 는 디렉터리 에 \" oop - 2 . py \" 라는 이름 의 파이썬 파일 을 만들 고 다음 의 코드 를 저장 하 여 주 십시오 . 사전 을 사용 하 는 경우 oop - 2 . py # -*- coding : utf - 8 -*- student = {\\' name \\': \\' 이상희 \\', \\' year \\': 2 , \\' class \\': 3 , \\' student _ id \\': 35 } print \\'{}, {} 학년 {} 반 {} 번 \\'. format ( student [ \\' name \\'], student [ \\' year \\'], student [ \\' class \\'], student [ \\' student _ id \\']) 터미널 이나 커맨드 창 을 여 시 고 \\' oop - 2 . py \\' 가 저장 된 디렉터리 로 이동 하 신 후 , 프로그램 을 실행 하 여 주 십시오 . $ python oop _ 2 . py 이상희 , 2 학년 3 반 35 번 클 래스 를 사용 하 는 경우 oop - 2 . py # -*- coding : utf - 8 -*- class student ( object ) : def __ init __( self , name , year , class _ num , student _ id ) : # 파이썬 키워드 인 class 는 인수 이름 으로 사용 하 지 못 합니다 . self . name = name self . year = year self . class _ num = class _ num self . student _ id = student _ id def introduce _ myself ( self ) : return \\'{}, {} 학년 {} 반 {} 번 \\'. format ( self . name , self . year , self . class _ num , self . student _ id ) student = student ( \\' 이상희 \\', 2 , 3 , 35 ) print student . introduce _ myself ( ) $ python oop _ 2 . py 이상희 , 2 학년 3 반 35 번 모듈 을 사용 하 는 경우 student . py # -*- coding : utf - 8 -*- name = \\' 이상희 \\' year = 2 class _ id = 3 student _ id = 35 oop - 2 . py # -*- coding : utf - 8 -*- import student print \\'{}, {} 학년 {} 반 {} 번 \\'. format ( student . name , student . year , student . class _ id , student . student _ id ) $ python oop _ 2 . py 이상희 , 2 학년 3 반 35 번 위 의 세 가지 예 모두 형식 과 방법 이 조금 다를 뿐 오브젝트 라는 논리 적 집합 을 사용 하 여 똑같 은 데이터 를 출력 하 는 것 을 알 수 있 습니다 . 그럼 이번 에 는 파이썬 의 모든 것 들 이 정말 오브젝트 인지 그리고 그 오브젝트 안 에 는 뭐 가 있 는지 확인 해 볼까요 ? 먼저 문자열 이 정말 오브젝트 인지 확인 해 보 죠 . oop - 2 . py text = \\' string \\' print dir ( text ) 기억 하 세요 ~! dir ( ) 는 파이썬 의 표준 내장 함수 입니다 . 이 함수 는 인자 가 없 을 경우 에 는 모듈 레벨 의 지역 변수 를 , 인자 가 있 을 경우 에 는 인자 ( 오브젝트 ) 의 모든 속성 과 메소드 를 보여 줍니다 . 이 함수 는 디버깅 을 할 때 아주 많이 쓰이 는 중요 한 함수 입니다 . $ python oop - 2 . py [ \\'__ add __\\', \\'__ class __\\', \\'__ contains __\\', \\'__ delattr __\\', \\'__ doc __\\', \\'__ eq __\\', \\'__ format __\\', \\'__ ge __\\', \\'__ getattribute __\\', \\'__ getitem __\\', \\'__ getnewargs __\\', \\'__ getslice __\\', \\'__ gt __\\', \\'__ hash __\\', \\'__ init __\\', \\'__ le __\\', \\'__ len __\\', \\'__ lt __\\', \\'__ mod __\\', \\'__ mul __\\', \\'__ ne __\\', \\'__ new __\\', \\'__ reduce __\\', \\'__ reduce _ ex __\\', \\'__ repr __\\', \\'__ rmod __\\', \\'__ rmul __\\', \\'__ setattr __\\', \\'__ sizeof __\\', \\'__ str __\\', \\'__ subclasshook __\\', \\'_ formatter _ field _ name _ split \\', \\'_ formatter _ parser \\', \\' capitalize \\', \\' center \\', \\' count \\', \\' decode \\', \\' encode \\', \\' endswith \\', \\' expandtabs \\', \\' find \\', \\' format \\', \\' index \\', \\' isalnum \\', \\' isalpha \\', \\' isdigit \\', \\' islower \\', \\' isspace \\', \\' istitle \\', \\' isupper \\', \\' join \\', \\' ljust \\', \\' lower \\', \\' lstrip \\', \\' partition \\', \\' replace \\', \\' rfind \\', \\' rindex \\', \\' rjust \\', \\' rpartition \\', \\' rsplit \\', \\' rstrip \\', \\' split \\', \\' splitlines \\', \\' startswith \\', \\' strip \\', \\' swapcase \\', \\' title \\', \\' translate \\', \\' upper \\', \\' zfill \\'] \" text \" 라는 변수 에 \" string \" 이 라는 6 글자 만 할당 하 였을 뿐 인데 뭐 가 이렇게 많이 출력 되 나요 ? !? 그 이유 는 이렇 습니다 . \" text \" 는 \\' str \\' 이 라는 데이터 타입 이 만들 어 낸 오브젝트 이 며 \\' str \\' 데이터 타입 에 정의 된 모든 속성 과 메소드 를 상속 받 았 기 때문 입니다 . 예 제 를 통해서 몇 가지 만 확인 해 보 겠 습니다 . oop - 2 . py # -*- coding : utf - 8 -*- text = \\' string \\' # text 의 클래스 확인 print text . __ class __ # # text 가 str 의 인 스턴스 오브젝트 인지 확인 print isinstance ( text , str ) # true # 메소드 확인 print text . upper ( ) # string $ python oop _ 2 . py true string text 의 클래스 도 확인 을 해 봤 고 메소드 도 호출 해 봤 습니다 . 함수 나 모듈 도 오브젝트 라고 했 는데 진짜 인지 확인 해 보 도록 하 죠 . oop - 2 . py # -*- coding : utf - 8 -*- def my _ function ( ) : \\'\\'\\' my _ function 에 대한 설명 입니다 ~!\\'\\'\\' pass # my _ function 의 속성 확인 print dir ( my _ function ) , \\' \\' # my _ function 의 docstring 출력 print my _ function . __ doc __, \\' \\' # my _ function 에 새로운 속성 추가 my _ function . new _ variable = \\' 새로운 변수 입니다 . \\' # 추가 된 속성 확인 print dir ( my _ function ) , \\' \\' # 추가 한 속성 값 출력 print my _ function . new _ variable , \\' \\' $ python oop _ 2 . py [ \\'__ call __\\', \\'__ class __\\', \\'__ closure __\\', \\'__ code __\\', \\'__ defaults __\\', \\'__ delattr __\\', \\'__ dict __\\', \\'__ doc __\\', \\'__ format __\\', \\'__ get __\\', \\'__ getattribute __\\', \\'__ globals __\\', \\'__ hash __\\', \\'__ init __\\', \\'__ module __\\', \\'__ name __\\', \\'__ new __\\', \\'__ reduce __\\', \\'__ reduce _ ex __\\', \\'__ repr __\\', \\'__ setattr __\\', \\'__ sizeof __\\', \\'__ str __\\', \\'__ subclasshook __\\', \\' func _ closure \\', \\' func _ code \\', \\' func _ defaults \\', \\' func _ dict \\', \\' func _ doc \\', \\' func _ globals \\', \\' func _ name \\'] my _ function 에 대한 설명 입니다 ~! [ \\'__ call __\\', \\'__ class __\\', \\'__ closure __\\', \\'__ code __\\', \\'__ defaults __\\', \\'__ delattr __\\', \\'__ dict __\\', \\'__ doc __\\', \\'__ format __\\', \\'__ get __\\', \\'__ getattribute __\\', \\'__ globals __\\', \\'__ hash __\\', \\'__ init __\\', \\'__ module __\\', \\'__ name __\\', \\'__ new __\\', \\'__ reduce __\\', \\'__ reduce _ ex __\\', \\'__ repr __\\', \\'__ setattr __\\', \\'__ sizeof __\\', \\'__ str __\\', \\'__ subclasshook __\\', \\' func _ closure \\', \\' func _ code \\', \\' func _ defaults \\', \\' func _ dict \\', \\' func _ doc \\', \\' func _ globals \\', \\' func _ name \\', \\' new _ variable \\' ] 새로운 변수 입니다 . 정말 함수 도 많 은 속성 을 가지 고 있 다는 것 과 임의로 속성 을 추가 할 수 도 있 다는 것 까지 확인 하 였 습니다 . 이제 어느 정도 감 을 잡 으셨으면 클래스 를 사용 하 여 새로운 데이터 타입 을 만들 고 그 데이터 타입 의 인 스턴스 오브젝트 를 만들 어 보 죠 . 회사 에서 직원 들 의 인사 데이터 를 관리 하 기 위한 클래스 를 만들 어 보 겠 습니다 . oop - 2 . py # -*- coding : utf - 8 -*- class employee ( object ) : pass emp _ 1 = employee ( ) emp _ 2 = employee ( ) # emp _ 1 과 emp _ 2 는 다른 메모리 주소 값 을 가진 별개 의 오브젝트 입니다 . print id ( emp _ 1 ) print id ( emp _ 2 ) print # emp _ 1 과 emp _ 2 는 같 은 클래스 의 인 스턴스 인 것 을 확인 합니다 . class _ of _ emp _ 1 = emp _ 1 . __ class __ class _ of _ emp _ 2 = emp _ 2 . __ class __ print id ( class _ of _ emp _ 1 ) print id ( class _ of _ emp _ 2 ) $ python oop _ 2 . py 4303036304 4303221648 4298387440 4298387440 employee 라는 클래스 를 정의 하 고 emp _ 1 , emp _ 2 라는 인 스턴스 를 만들 었 습니다 . 그리고 id ( ) 함수 를 이용 하 여 emp _ 1 과 emp _ 2 가 다른 메모리 주소 값 을 가진 별개 의 오브젝트 라는 것 을 확인 하 였 습니다 . 그리고 둘 다 같 은 클래스 의 인 스턴스 라는 것 도 확인 하 였 습니다 . 이번 에 는 emp _ 1 , emp _ 2 인 스턴스 에 변수 를 추가 하 여 데이터 를 저장 해 보 겠 습니다 . oop - 2 . py # -*- coding : utf - 8 -*- class employee ( object ) : pass emp _ 1 = employee ( ) emp _ 2 = employee ( ) # 인 스턴스 변수 에 데이터 저장 emp _ 1 . first = \\' sanghee \\' emp _ 1 . last = \\' lee \\' emp _ 1 . email = \\' sanghee . lee @ schoolofweb . net \\' emp _ 1 . pay = 50000 emp _ 2 . first = \\' minjung \\' emp _ 2 . last = \\' kim \\' emp _ 2 . email = \\' minjung . kim @ schoolofweb . net \\' emp _ 2 . pay = 60000 # 인 스턴스 변수 데이터 에 엑세스 print emp _ 1 . email print emp _ 2 . email $ python oop _ 2 . py sanghee . lee @ schoolofweb . net minjung . kim @ schoolofweb . net 인 스턴스 에 데이터 를 저장 하 고 엑세스 해 보 았 습니다 . 그런데 위 의 코드 는 잘 못 된 코드 입니다 . 위 의 코드 처럼 인 스턴스 변수 를 하나 하나 수동 으로 할당 하 면 클래스 를 사용 하 는 의미 가 없 습니다 . init 메소드 를 사용 하 여 인 스턴스 를 생성 할 때 필요 한 데이터 를 할당 하 겠 습니다 . 노트 __ init __ 메소드 는 \" 이니셜 라이 져 \" 라고도 부르 고 다른 언어 에서 는 \" 컨스트럭터 \" 라고도 부릅니다 . 이 메소드 는 인 스턴스 가 생성 될 때 자동 으로 호출 되 며 호출 되 는 순간 자동 으로 인 스턴스 오브젝트 를 self 라는 인자 로 받 습니다 . oop - 2 . py # -*- coding : utf - 8 -*- class employee ( object ) : def __ init __( self , first , last , pay ) : self . first = first self . last = last self . pay = pay self . email = first . lower ( ) + \\'.\\' + last . lower ( ) + \\'@ schoolofweb . net \\' emp _ 1 = employee ( \\' sanghee \\', \\' lee \\', 50000 ) emp _ 2 = employee ( \\' minjung \\', \\' kim \\', 60000 ) print emp _ 1 . email print emp _ 2 . email # emp _ 1 의 풀 네임 출력 print \\'{} {}\\'. format ( emp _ 1 . first , emp _ 1 . last ) $ python oop _ 2 . py sanghee . lee @ schoolofweb . net minjung . kim @ schoolofweb . net sanghee lee 클래스 의 장점 을 살려서 간결 한 코드 가 만들 어 졌 습니다 . 그런데 마지막 줄 에 풀 네임 을 출력 한 코드 를 봐 주 십시오 . 이 코드 는 회사 에서 어떤 직원 의 이름 을 물 어 볼 때 , \" 이름 이 뭔가요 ? 퍼스트 네임 , 라스트 네임 의 순서 로 말 해 주 세요 . \" 라고 요청 하 는 것 과 같 습니다 . 100 명 의 직원 의 이름 을 물 어 보 려면 입 좀 아프 겠 습니다 . ㅋ 모든 직원 들 이 \" 이름 이 뭔가요 ? \" 라는 질문 을 받 으면 어떤 형식 으로 대답 해야 하 는지 알 았 으면 좋 겠 네요 . 그렇게 만들 어 보 죠 . ㅎ oop - 2 . py # -*- coding : utf - 8 -*- class employee ( object ) : def __ init __( self , first , last , pay ) : self . first = first self . last = last self . pay = pay self . email = first . lower ( ) + \\'.\\' + last . lower ( ) + \\'@ schoolofweb . net \\' def full _ name ( self ) : return \\'{} {}\\'. format ( self . first , self . last ) emp _ 1 = employee ( \\' sanghee \\', \\' lee \\', 50000 ) emp _ 2 = employee ( \\' minjung \\', \\' kim \\', 60000 ) # emp _ 1 의 풀 네임 출력 print emp _ 1 . full _ name ( ) $ python oop _ 2 . py sanghee lee 처음 클래스 를 사용 하 는 사람 들 이 아주 많이 하 는 실수 가 있 습니다 . 그게 뭐 냐면 , 메소드 를 정의 할 때 \" self \" 인수 를 잊어버리 는 것 입니다 . 그럼 어떻게 될까요 ? 한번 보 죠 . oop - 2 . py # -*- coding : utf - 8 -*- class employee ( object ) : def __ init __( self , first , last , pay ) : self . first = first self . last = last self . pay = pay self . email = first . lower ( ) + \\'.\\' + last . lower ( ) + \\'@ schoolofweb . net \\' def full _ name ( ) : # <--- self 가 없 습니다 . return \\'{} {}\\'. format ( self . first , self . last ) emp _ 1 = employee ( \\' sanghee \\', \\' lee \\', 50000 ) emp _ 2 = employee ( \\' minjung \\', \\' kim \\', 60000 ) # emp _ 1 의 풀 네임 출력 print emp _ 1 . full _ name ( ) $ python oop _ 2 . py traceback ( most recent call last ) : file \" oop - 2 . py \", line 17 , in print emp _ 1 . full _ name ( ) typeerror : full _ name ( ) takes no arguments ( 1 given ) 옹 . .. 파이썬 인 터프 레터 가 뭔가 알 수 없 는 얘기 를 하 네요 . \" typeerror : full _ name ( ) takes no arguments ( 1 given ) \" full _ name 메소드 는 인자 를 안 받 는데 왜 하나 를 줬 냐고 하 네요 . \" emp _ 1 . full _ name ( ) \" 이렇게 아무런 인자 없이 호출 을 했 는데 말 이 죠 . 뭘까요 ? !? 그건 위 에서 도 설명 했 듯이 인 스턴스 의 메소드 를 호출 하 면 인 스턴스 자기 자신 인 \" self \" 가 첫 번 째 인자 로 자동 전달 되 기 때문 입니다 . 다음 예제 를 보 시 면 조금 이해 가 쉬울 겁니다 . oop - 2 . py # -*- coding : utf - 8 -*- class employee ( object ) : def __ init __( self , first , last , pay ) : self . first = first self . last = last self . pay = pay self . email = first . lower ( ) + \\'.\\' + last . lower ( ) + \\'@ schoolofweb . net \\' def full _ name ( self ) : return \\'{} {}\\'. format ( self . first , self . last ) emp _ 1 = employee ( \\' sanghee \\', \\' lee \\', 50000 ) emp _ 2 = employee ( \\' minjung \\', \\' kim \\', 60000 ) # 클래스 를 통해서 full _ name 메소드 호출 print employee . full _ name ( emp _ 1 ) $ python oop _ 2 . py sanghee lee 마지막 행 의 코드 를 보 시 면 클래스 를 통해서 메소드 를 실행 하 였 는데 , 이런 경우 에 는 클래스 는 어떤 인 스턴스 의 메소드 를 호출 해야 하 는지 모르 기 때문 에 대상 이 될 인 스턴스 를 인자 로 전달 해야 합니다 . 사실 \" emp _ 1 . full _ name ( ) \" 를 실행 하 면 백 그라운드 에서 는 \" employee . full _ name ( emp _ 1 ) \" 가 실행 되 는 것 입니다 . 이번 강좌 는 여기 서 마치 고 다음 강좌 에서 \" 클래스 변수 \" 를 공부 하 며 클래스 와 인 스턴스 의 차이점 에 대해서 더 공부 해 보 겠 습니다 .',\n",
       "       '분노 와 폭력 , 사이코패스 의 뇌 과학 글 사이먼 배런 코언 ( simon baron - cohen ) 배런 코언 은 지금 까지 의 공감 능력 을 측정 하 는 검사 지 들 이 이 같 은 공감 의 주요 한 두 구성 요소 ( 인식 과 반응 ) 를 잘 반영 하 지 못한 탓 에 개개인 의 공감 능력 을 정확히 측정 해 내 지 못했 다는 점 을 깨닫 고 직접 질문 문항 을 세밀 하 게 설계 한 공감 지수 ( empathy quotient , eq ) 를 개발 하 였 습니다 . 이 페이지 에서 는 『 공감 제로 』 에 실려 있 는 eq 테스트 중 성인 용 테스트 를 제공 합니다 . 작성 요령 : 아래 는 서술 목록 입니다 . 각 항목 을 매우 주 의 깊 게 읽 고 그 내용 에 동의 하 는 정도 혹은 동의 하 지 않 는 정도 를 응답 란 에 표시 하 여 평가 하 세요 . 응답 에 는 맞 거나 틀린 것 이 없 으며 , 교묘 한 질문 도 없 습니다 . * 결과 에 는 본인 의 점수 와 공감 지수 수준 이 표시 되 며 , 40 문항 중 체크 박스 가 하나 라도 누락 되 면 결과 가 표시 되 지 않 습니다 . 더 자세 한 것 을 알 고 싶 으시 면 책 의 부록 을 참고 해 주 십시오 .',\n",
       "       '리눅스 에서 ssd 를 최대한 활용 해 보 세요 . 여기 , 알 아 둘 필요 가 있 는 정보 를 모아 소개 합니다 . 리눅스 도 상당히 훌륭 하 게 설치 직후 바로 사용 할 수 있 게 됐 습니다 . 하지만 , 최대한 매끄럽 게 움직이 게 하 려면 , 직접 기름칠 하 고 손질 해서 최적 화 해 줘야 할 부분 이 아직 몇 군데 남 아 있 습니다 . 그냥 생각 해 보 면 전원 소비 를 조절 해 주 는 게 가장 먼저 떠오르 지만 , ssd 사용 을 위해 시스템 을 최적 화 하 는 것 도 중요 합니다 . 잘 관리 된 ssd 는 사용 에 더 큰 기쁨 을 가져다 주 니 말 이 지요 . 윈도우 도 xp 때 그랬 지만 , trim 기능 을 켜 주 지 않 으면 데이터 찌꺼기 가 남 아 ssd 의 성능 이 감소 합니다 . ssd 의 처리 방식 과 운영 체제 의 파일 삭제 방식 이 서로 잘 연계 되 지 않 아서 발생 하 는 문제 죠 . 예전 기계식 하드 디스크 에서 는 파일 을 삭제 할 때 실제로 자료 를 지우 지 않 고 위치 를 알려 주 는 연결 만 끊 었 습니다 . 그리고 새 파일 을 저장 할 때 그 위치 에 자료 를 덮어쓰 기 했 죠 . 이렇게 했 던 이유 는 지우 는데 시간 이 걸리 기 때문 입니다 . 파일 지우 느라 기다리 고 , 다시 새 파일 쓰 느라 또 기다리 면 번거롭 겠 지요 . 이 와 는 달리 , 덮어쓰 기 는 그 위 에 바로 쓰 는 거 라 시간 이 추가 적 으로 들 지 않 았 습니다 . 그래서 윈도우 나 리눅스 모두 파일 을 삭제 하 면 , 실제로 지우 지 않 고 연결 만 끊 도록 동작 하 게 되 어 있 습니다 . 그런데 , ssd 는 자료 덮어쓰 기 기능 이 없 습니다 . 실제로 한 번 지우 고 , 빈 자리 에 써 줘야 하 는 셈 이 지요 . 하지만 , 윈도우 xp 나 리눅스 모두 이전 방식 그대로 파일 연결 을 끊 기 만 합니다 . 자료 , 데이터 는 그대로 계속 남 습니다 . 이후 덮 어 쓸 것 을 염두 에 둔 동작 인데 , ssd 는 덮어쓰 기 가 안 되 다 보 니 이 남 은 자료 가 계속 해서 쌓 입니다 . 그렇게 계속 불 필요 한 자료 가 쌓이 다 보 면 , 성능 저하 가 발생 하 기 시작 하 죠 . 그래서 파일 을 지울 때 마다 연결 만 이 아니 라 실제 자료 까지 말끔히 제거 해 주 는 기능 인 trim 기능 이 필요 합니다 . 윈도우 는 윈도우 7 , 8 때 부터 기본 적 으로 trim 기능 이 켜져 있 습니다 . 하지만 리눅스 는 비교 적 최근 까지 도 trim 기능 이 기본 으로 켜져 있 지 않 았 습니다 . 우분투 만 해도 14 . 04 바로 전 버전 ( 우분투 13 . 10 ) 까지 trim 기능 이 꺼져 있 었 습니다 . 당연히 켜져 있 을 거 라 생각 하 고 사용 했 는데 , 꺼져 있 다는 걸 알 고 의외 라는 생각 을 했 습니다 . 우분투 14 . 04 와 리눅스 민트 17 버전 은 ssd 설치 시 자동 으로 trim 이 켜 지 지만 , \" cron \" 작업 으로 이걸 처리 합니다 . 그런데 일정 주기 로 명령 을 실행 하 는 cron 작업 은 대부분 의 경우 trim 기능 을 실행 하 기 에 최적 의 방법 은 아닙니다 . 더군다나 모든 ssd 제품 에서 자동 으로 trim 이 켜 지 는 것 또한 아닙니다 . 때문 에 , 아래 에서 최적 화 된 trim 적용 방법 도 소개 합니다 . 최상 의 성능 을 얻 고 ssd 의 소모 를 최소 화 할 수 있 도록 , 리눅스 시스템 을 위한 이 최적화 방법 들 을 적용 해 보 세요 . 리눅스 , ssd 를 위한 최적화 배포판 업데이트 대부분 의 사람 에게 는 해당 되 지 않 는 문제 겠 지만 , 그래도 언급 할 만 한 가치 는 충분 하 지요 . 프로그램 , 커널 , 파일 시스템 을 비롯 한 여러 부분 에서 항상 최적 의 상태 를 유지 하 려면 , 즐겨 사용 하 는 배포판 의 최신 버전 을 사용 하 는 게 제일 좋 습니다 . 지금 도 지원 되 지만 훨씬 오래 된 버전 ( 우분투 12 . 04 와 같 은 버전 ) 에 계시 다면 , 최신 버전 으로 업그레이드 하 는 게 가장 좋 습니다 ( 14 . 04 와 같 은 버전 ) . 운영 체제 를 좀 더 ssd 친화 적 으로 만들 어 주 는 변화 가 여럿 적용 되 어 있 으니 말 이 지요 . 리눅스 , ssd 를 위한 최적 화 ssd 펌웨어 업데이트 ssd 의 펌웨어 ( ssd 안 에 들 어 있 는 동작 제어 프로그램 ) 를 업그레이드 하 는 것 도 좋 은 생각 입니다 . 업그레이드 하 는 방법 은 제조사 마다 다르 기 때문 에 , 각 ssd 별 로 업그레이드 방법 을 확인 하 셔야 합니다 . 이 때 일부 제품 은 ( 전부 는 아님 ) 리눅스 에서 펌웨어 를 업데이트 할 수 없 다는 사실 을 염두 에 두 셔야 합니다 . 리눅스 대신 , ( 리눅스 라이브 cd 와 비슷 한 ) 특정 부팅 환경 을 사용 하 거나 혹은 윈도우 유틸리티 를 사용 해 업데이트 를 진행 해야 합니다 . 리눅스 , ssd 를 위한 최적 화 ext 4 사용 리눅스 를 새로 설치 하 신다면 , ext 4 파일 시스템 을 사용 하 는 게 제일 좋 습니다 . 가장 많이 사용 되 며 , 가장 안정 적 인 파일 시스템 이 고 , trim 기능 도 지원 합니다 ( 대신 지금 도 여전히 켜 줄 필요 가 있 습니다 . 방법 은 아래 에서 정리 합니다 ) . 그런데 이걸 사용 하 는 게 큰 문제 가 되 지 는 않 을 겁니다 . 대부분 의 배포판 이 ext 4 를 기본 으로 사용 하 고 있 으니 말 이 죠 . 리눅스 , ssd 를 위한 최적화 부팅 시 마운트 옵션 리눅스 는 매번 부팅 할 때 마다 , 다양 한 종류 의 드라이브 를 마운트 하 고 불러 들여서 연결 합니다 . 사용 할 수 있 도록 미리 준비 시켜 두 는 거 죠 . 드라이브 를 사용 할 수 있 게 불러 들이 는 마운트 작업 은 하드웨어 나 필요 에 따라 다양 한 옵션 을 줄 수 있 는데 , 이 중 일부 는 ssd 에 사용 하 기 에 알맞 습니다 . trim 기능 을 켜 고 이런 옵션 을 적용 해 줄 수 있 도록 , 터미널 을 연 뒤 sudo nano / etc / fstab 명령 을 실행 합니다 . 그리고 다음 으로 , 이 파일 에 있 는 목록 에서 실제 ssd 에 있 는 파티션 을 찾 아 보 세요 . 여기 에 있 는 파티션 은 보통 uuid 로 구분 해서 나열 되 어 있 는데 , uuid 는 / dev / sdab 구분 방법 보다 더 정확 합니다 . 혹시 ssd 에 파티션 이 여러 개 있 다면 , blkid / dev / sdab 명령 을 사용 해 uuid 를 확인 할 수 있 습니다 . 여기 서 ab 는 디스크 나 파티션 에 따라서 a 는 a ~ z 로 , b 는 1 - 9 로 환경 에 맞춰 대입 하 시 면 됩니다 . 이제 , 네 번 째 옵션 자리 끝 에 쉼표 로 구분 해서 두 가지 마운트 옵션 을 추가 해 줍니다 . discard 와 noatime 을 말 이 죠 . discard 는 ssd 의 trim 기능 이 파일 이 삭제 될 때 마다 실행 되 도록 해줍니다 . 앞서 위 에서 언급 했 던 것 처럼 , trim 기능 을 사용 하 게 되 면 성능 과 수명 이 향상 됩니다 . 다른 옵션 인 noatime 은 파일 에 마지막 으로 접근 한 시간 을 파일 시스템 에 기록 하 지 않 도록 해줍니다 . 파일 을 수정 한 시간 만 기록 하 게 되 는 셈 이 지요 . 이렇게 마지막 접근 시간 을 기록 하 지 않 게 해 주 면 , ssd 의 소모 를 줄여줄 수 있 습니다 . 파일 에 마지막 으로 접근 한 시간 도 기록 하 려면 쓰 기 작업 이 필요 한데 , 컴퓨터 를 사용 하 면서 접근 하 는 파일 이 상당히 많 기 때문 에 매번 쓰 기 작업 이 일어나 겠 지요 . 반면 에 수정 하 는 파일 은 상대 적 으로 적 을 것 입니다 . 이렇게 수정 을 마치 고 나 면 위 의 스크린 샷 과 같 은 모습 처럼 보일 겁니다 . 이 과정 을 정리 하 면 , 아래 와 같 습니다 . 터미널 을 실행 합니다 . sudo nano / etc / fstab 를 입력 해 fstab 파일 을 엽 니다 . ext 4 를 사용 하 는 모든 파티션 의 네 번 째 옵션 부분 끝 에 discard 와 noatime 을 쉼표 와 함께 추가 합니다 ( 예 : errors = remount - ro , discard , noatime ) . 이 때 , 쉼표 앞뒤 에 결코 공백 이 있 으면 안 됩니다 ! 저장 후 컴퓨터 를 재 시작 합니다 . 혹시 noatime 옵션 을 적용 한 후 일부 프로그램 이 제대로 동작 하 지 않 는다면 ( 마지막 으로 수정 한 시간 보다 마지막 으로 접근 한 시간 이 이전 에 있 는 게 일반 적 으로 는 불 가능 하 니 말 이 지요 ) , noatime 을 relatime 으로 바꿔 주 시 면 됩니다 . relatime 옵션 은 쓰 기 작업 때 마지막 으로 접근 한 시간 과 마지막 으로 수정 한 시간 을 모두 같 은 값 으로 업데이트 하 게 해줍니다 . 두 옵션 에 대한 비교 내용 은 이곳 의 글 을 참고 해 보 세요 . 리눅스 , ssd 를 위한 최적화 스왑 사용 하 지 않 기 ssd 를 사용 할 때 는 스왑 ( swap , 메모리 가 부족 할 경우 사용 하 는 예비 공간 ) 파티션 을 사용 하 지 않 는 것 도 매우 좋 은 방안 입니다 ( 사용 해야 할 심각 한 이유 가 있 지 않 은 한 은 말 이 지요 ) . 스왑 파티션 의 끊임 없 는 읽 기 와 쓰 기 는 분명 ssd 를 상당 한 수준 으로 소모 시킵니다 . 그래도 스왑 파티션 을 정말 사용 해야 겠다는 생각 이 드신 다면 , 가능 한 한 ssd 가 아닌 두 번 째 하드 드라이브 에 위치 시키 는 것 이 낫 습니다 . 물론 , ssd 에 스왑 파티션 을 두 고 싶 은 유혹 이 느껴 지시 겠 지만 ( 지금 까지 사용 해 온 것 중 가장 높 은 성능 을 보이 는 스왑 파티션 이 될 겁니다 ) , 그 속도 는 그 만큼 큰 대가 를 치러야 합니다 . 많 은 사람 이 심각 할 정도 로 많 은 양 의 읽 기 쓰 기 가 발생 하 는 최대 절전 모드 만 끈다면 스왑 파티션 을 추가 해도 괜찮 다고 이야기 합니다 . 하지만 아마 충분 한 수준 이상 의 메모리 를 가지 고 있 어 스왑 파티션 을 사용 하 는 일 이 드물 것 인 데 다가 , 그냥 공간 만 차지 할 겁니다 . 잠재 적 으로 는 ssd 소모 와 수명 단축 을 유발 하 겠 지요 . 그 뿐 만 아니 라 , 처음 부터 설치 시 스왑 파티션 을 추가 하 지 않 는 게 최대 절전 모드 를 끄 는 쉬운 방법 일 겁니다 . 리눅스 , ssd 를 위한 최적화 마무리 글 에서 설명 한 방법 이 리눅스 에서 좀 더 최적 화 된 ssd 경험 을 할 수 있 게 해 줄 겁니다 . 그리고 , ssd 가 여러분 에게 감사 할 겁니다 . 이 최적화 방법 을 적용 하 지 않 았 을 때 보다 몇 년 이나 더 오래 가 면서 말 이 지요 . 요즘 운 이 좋 다는 느낌 이 드신 다면 , 심약 한 사람 에게 는 어울리 지 않 을 훨씬 더 많 은 ssd 관련 최적화 방법 을 연구 해 볼 수 도 있 겠 지요 . 모두 여러분 에게 달렸 지만 , 이 글 에서 설명 한 방법 만 으로 도 ssd 에 충분 할 겁니다 . 대부분 의 다른 비법 이나 방법 은 드러나 는 차이 가 아주 미미 한 사소 한 잔손 질 정도 일 겁니다 . 어떤 ssd 최적화 방법 을 추천 하 고 싶 으신 가요 ? 스왑 파티션 처리 방법 에 대해 어떻게 생각 하 세요 ? 오에스 톡 ( ostalk ) 커뮤니티 게시판 이나 아래 댓글 로 의견 을 남겨 주 세요 !',\n",
       "       '이 페이지 를 보 려면 , 프레임 을 볼 수 있 는 브라우저 가 필요 합니다 .',\n",
       "       'this posting is based on the journal review \" abnormal functional connectivity in children with attention - deficit / hyperactivity disorder by dardo tomasi and nora d . volkow . \" 주의력 결핍 및 과잉 행동 장애 ( attention - deficit / hyperactivity disorder , adhd ) 는 다음 과 같 은 특징 을 보인다 . 주의력 결핍 과 과잉 / 충동 적 인 행동 양상 일 보인다 . 동기 부여 장애 가 동반 된다는 인식 이 증가 되 고 있 다 . 뇌 의 도파민 신경전달물질 분비 에 손상 이 있 다 . adhd 는 pet 연구 에서 reward - motivation pathway ( midbrain , caudate , and ventral striatum ) 의 도파민 신경 전달 이 비 정상 적 인 것 으로 나타났 다 . reward - motivation pathway 의 결함 은 주의력 결핍 과 낮 은 동기 부여 와 관련 이 있 다 [ 1 , 2 ] . 전두엽 피질 의 도파민 부족 은 \\' 주 의 집중 장애 \\' 를 일으킨다고 알려져 있 다 . 도파민 은 대체로 억제 성 신경 전달 물질 이 기 때문 에 , 도파민 시냅스 의 활동 을 증가 시키 는 약물 들 은 다른 많 은 뉴런 들 의 활동 을 감소 시키 고 여러 뇌 부위 에서 의 전체 적 인 활동 을 감소 시킨다 . 뇌 의 전체 적 인 활동 을 감소 시키 는 약물 이 어떻게 각성 과 활동 의 증가 및 집중력 향상 을 이끌 어 내 는지 의아 할 것 이 다 . 이 에 대한 한 가지 설명 은 도파민 의 활동 이 높 아 지 면 뇌 의 \\' 배경 잡음 \\' 이 대부분 감소 되 고 , 따라서 신호 대 잡음 비 가 증가 된다는 것 이 다 . - 생물 심리학 ( 제 6 판 , 시그마 프레스 ) 중 - 또한 , resting state fmri 연구 에서 는 inferior frontal and superior parietal cortices , cingulum , and cerebellum 등 의 영역 에서 bold 신호 의 low frequency fluctuation ( lff ) 값 이 갑소 된 것 으로 밝혀졌 다 . 그렇 다면 adhd 환자 의 parietal cortex 영역 과 anterior cingulum 영역 에서 lff 가 감소 한 것 을 신경 병리학 적 측면 에서 어떻게 이해 할 있 을까 ? [ 3 ] parietal cortex 영역 에서 의 lff 신호 감소 는 adhd 환자 들 에게서 executive - attention 기능 이 떨어져 있 기 때문 으로 이해 할 수 있 다 . 또한 , reward - motivational network 에서 중요 한 역할 을 수행 하 는 anterior cingulum 영역 의 lff 감소 는 adhd 환자 들 이 보상 과 동기 부여 와 관련 된 기능 을 제대로 수행 하 지 못함 으로 해석 할 수 있 다 . tomasi and volkow 는 adhd 에서 나타나 는 비 정상 적 인 functional connectivity density ( fcd ) 가 reward - motivational ( ventral striatum and orbito - frontal cortex ) , attention ( parietal cortex ) , and executive ( dorsal cingulate ) 영역 들 과 관련 이 있 을 것 이 라는 가정 하 에 몇 가지 분석 을 수행 했 다 . 연구 결과 중 에 관심 있 게 본 것 은 , 약물 에 한 번 도 노출 되 지 않 은 ( medication naive ) adhd 환자 의 경우 에 ofc / insula and ventral striatum 영역 의 short - range fcd 가 정상 인 집단 보다 높 다는 것 이 다 . 하지만 , 약물 치료 를 받 은 adhd 환자 와 정상 인 집단 간 의 ofc / insula 와 ventral striatum 영역 의 short - range fcd 는 차이 를 보이 지 않 았 다 . 저자 들 은 이것 을 통해서 \\' adhd 치료 를 위한 stimulant medication 이 reward - motivation 영역 의 short - range fcd 를 회복 시키 는 역할 을 수행 한다 \\' 고 주장 하 고 있 다 . 임상 에서 사용 되 는 중추 신경 자극제 ( medication stimulant ) 는 단기 적 으로 dopamine 등 신경 전달 물질 을 활성 화 시키 고 adhd 에 흔히 수반 되 는 주 의 산만 함 , 과잉 활동 과 충동 성 등 을 감소 시키 고 , 집중력 , 기억력 , 학습 능력 이 전반 적 으로 좋 아 진다고 알려져 있 다 . references : volkow n , wang g , kollins s , wigal t , newcorn j , telang f , et al . ( 2009 ) : evaluating dopamine reward pathway in adhd : clinical implications , jama 302 : 1084 - 1091 . volkow n , wang g , newcorn j , kollins s , wigal t , telang f , et al . ( 2011 ) : motivation deficit in adhd is associated with dysfunction of the dopamine reward pathway . mol psychiatry 16 : 1147 - 1154 . rubia k , halari r , cubillo a , mohammand a , brammer m , taylor e ( 2009 ) : methylphenidate normalises activation and functional connectivity deficits in attention and motivation networks in medication - naive children with adhd during a rewarded continuous performance task . neurophamocology 57 : 640 - 652 .',\n",
       "       'c 언어 공부 법 과 책 추천 last updated : 2018 - 02 - 28 이 글 은 c 언어 를 공부 할 때 헤메 지 않 고 국제 표준 인 정종 ( 正 種 ) c 언어 를 배우 는데 도움 을 주 고자 쓰여졌 다 . 그러 기 위해 알 아야 하 는 용어 나 기반 지식 들 을 살펴보 고 , 추천 도서 인 knk , k & r 에 대해 소개 하 겠 다 . ( 참고 로 여기 에서 제시 하 는 방향 이나 책 이 올바르 고 유일 한 진리 의 길 은 아니 다 . 이 길 은 개인 적 이 고 주관 적 인 견해 가 포함 되 어 있 으니 감안 하 고 보 길 바란다 . ) 2015 년 을 기점 으로 현대 컴퓨팅 환경 에서 c 언어 의 위치 는 거의 밑바닥 에 존재 하 는 기초 언어 이 다 . c 언어 뒤 에 등장 한 프로그래밍 언어 들 은 c 언어 문법 체계 를 따라했 을 정도 로 큰 족적 을 남기 기 도 했 다 . 또한 운영 체제 ( operating system , 이하 os ) 의 설계 및 구현 에 사용 되 었 기 에 시스템 하부 구조 를 배울 때 빠짐없이 등장 하 는 단골손님 이 기 도 하 다 . os , network , c language 이런 연유 로 c 언어 는 전자 전기 기계 관련 이공 계열 의 제 1 외국어 라는 농담 이 있 을 정도 다 . 그래서 대부분 대학교 1 ~ 2 학년 때 c 언어 를 배우 는 경우 가 많 다 . 그렇게 공학 계열 필수 과목 중 에 하나 지만 c 언어 를 잘못 배운 사람 도 꽤 많 은 것 같 다 . 왜냐하면 신입 사원 교육 이나 강의 , 컨설팅 을 가 보 면 c 언어 를 엉뚱 하 게 배운 경우 가 상당히 많 음 을 볼 수 있 었 다 . 비율 로 따지 면 모 그룹 의 신입 사원 은 80 % 이상 이 학부 에서 c 언어 를 잘못 배운 채 입사 했었 다 . 특히 인터넷 카페 나 페북 등 과 같 은 검증 되 지 않 은 곳 에서 소개 하 는 나쁜 교재 나 잘못 된 공부 방법 으로 시작 한 경우 에 는 거의 99 % 개념 을 잘못 잡 아서 초급 에서 헤매 다가 끝내 포기 하 는 경우 가 많 은 것 같 았 다 . ( 인터넷 에 는 좋 은 글 도 많 지만 틀린 글 은 더 많 다 . 안목 이 없 는 초보 때 는 잘못 된 글 을 가려낼 수 없 다 . ) 그런고로 이 글 은 정통파 로 c 언어 를 배우 고자 하 는 학생 들 에게 유용 할 것 같 다 . * 본질 을 다루 기 전 에 문제 제기 부터 다시 해 보 자 . c 언어 를 제대로 배우 지 못했 다는 것 은 구체 적 으로 어떤 것 을 말 하 는 것 일까 ? 아래 질문 에 답 을 하 거나 개념 이라도 확실히 알 고 있 다면 c 언어 를 제대로 배운 것 이 고 아니 라면 기초 가 부실 하 거나 잘못 배운 것 이 다 . ( 아래 질문 들 의 절반 도 모르 겠 다면 c 언어 를 제대로 배운 것 이 라고 할 수 없 다 ) 질문 0 . c 언어 는 언제 , 어디 서 , 누 가 , 무엇 을 위해 만들 었 는가 ? 질문 1 . c 언어 국제 표준 ( iso / iec 9899 ) 은 무엇 이 며 c 99 , c 11 은 무엇 인가 ? 질문 2 . c 언어 의 stdio ( 표준 입출력 ) 는 왜 만들 어 졌 는가 ? 질문 3 . 전처 리기 ( preprocessor ) 가 하 는 일 은 무엇 인가 ? 그리고 왜 만들 어 졌 는가 ? 질문 4 . api 와 abi 는 무엇 인가 ? 질문 5 . 오브젝트 ( object ) 란 무엇 인가 ? ( 객체 지향 의 오브젝트 를 말 하 는 것 이 아님 ) 질문 6 . 링커 ( linker ) 가 하 는 일 은 무엇 인가 ? 질문 7 . call - by - reference , call - by - value 란 무엇 인가 ? ( c 에 왜 call - by - reference 가 없 는지 설명 할 수 있 어야 함 ) 질문 8 . c 언어 의 main 함수 의 return 값 은 왜 int 인가 ? ( void main ( ) 으로 선언 하 면 왜 틀리 는가 ? ) 질문 9 . c 언어 와 c ++ 은 다른 하나 가 부분 집합 인 서브 셋 인가 ? 아니면 둘 은 다른 언어 인가 ? 질문 10 . 하드웨어 제어 에 c 언어 가 사용 되 는 이유 는 무엇 인가 ? 질문 11 . 시퀀스 포인트 ( sequence point ) 가 무엇 인가 ? 질문 12 . side effect 란 무엇 인가 ? 질문 13 . ub ( undefined behavior ) 란 무엇 인가 ? 그럼 질문 은 끝내 고 c 언어 의 특징 을 생각 해 보 자 . 원래 c 언어 는 구구단 이나 별 그리 기 를 하 려고 만든 언어 는 아니 다 . 물론 문법 을 배우 는 와중 에 구구단 을 짤 수 도 있 다 . 하지만 구구단 작성법 을 배우 는 게 c 언어 의 본질 적 인 공부 는 아니 라는 것 이 다 . c 언어 는 low level 과 memory , 운영 체제 ( os ) 등 을 이해 하 거나 작성 하 기 위해 거쳐가 는 관문 이 c 언어 의 본질 이 다 . 구구단 같 은 수치 연산 이나 논리 연산 을 배우 는 것 이 주목적 이 라면 python 이 백배 낫 다고 생각 된다 . 사실 비 전공 자라 면 굳이 c 언어 를 배울 필요 가 없 다 . 오히려 c 언어 대신 에 python 을 공부 하 는 게 훨씬 도움 이 된다 . 왜냐하면 c 언어 는 문법 은 간결 하 지만 그 대신 에 함정 이 많 은 구조 를 가지 고 있 어서 제대로 공부 하 지 않 으면 이런 함정 에서 허우적 대기 십상 이 다 . 문법 만 대충 나열 한 책 들 은 정통파 c 언어 를 제대로 다루 지 않 기 때문 에 더더욱 함정 에 빠질 가능 성 이 높 다 . 비비꼬 아 놓 은 c 언어 문제 풀 이 학습지 책 이나 암기 문제 를 다루 는 책 은 성취 가 점수 로 표시 되 니 뿌 듯 할 수 도 있 다 . 하지만 이 는 사파 의 무공 과 같 아서 운영 체제 ( os ) 라는 본질 의 첫 단추 를 끼울 때 방해 가 될 수 도 있 다 . 무슨 올림피아드 대회 준비 같 은 것 이 아니 라면 이런 이단 사이 비 공부 에 심취 하 지 않 는 편 이 좋 다 . 특히 연산자 우선 순위 를 비비 꼬 아 놓 거나 , 포인터 를 스크류바 처럼 꼬 아 놓 은 문제 들 을 수두룩 하 게 풀 고 있 다면 이미 이단 사이비 에 빠진 것 이 니 조심 하 자 . ( 아래 는 the international obfuscated c code contest 코드 이 다 . 이런 것 은 정통파 배움 과 는 차이 가 있 다 . ) the international obfuscated c code contest - garry . c ( 1995 ) 물론 어떤 길 로 가 든지 간 에 최고봉 에 오르 면 다 부질없 기 는 하 다 . 이 글 에서 제시 하 는 방법 이 아닌 길 로 갔 어도 최고봉 에 오르 는 사람 들 도 많 다 . 하지만 최고봉 에 오르 기 위해 정통파 로 오르 는 것 과 비 정통 으로 오르 는 것 에 는 약간 의 차이 가 있 다 . ( 특히 걸리 는 시간 과 시행착오 횟수 가 크 게 달라질 수 있 다 . ) c 언어 를 배우 기 전 의 기본 지식 ( 이 정도 는 알 아야 면장 이 라도 해 먹 는다 . ) 차례 1 . c 언어 란 무엇 인가 ? 2 . c 언어 표준 문법 3 . c 언어 를 공부 하 는 방법 3 . 1 . c 표준 문서 로 공부 할까 ? 3 . 2 . 구 *, 네 * 버 검색 으로 시작 할까 ? 3 . 3 . it 학원 3 . 4 . 독학 3 . 5 . 그럼 어떻게 배워야 하나 ? 4 . 검증 된 c 언어 책 은 무엇 이 있 는가 ? 5 . c 언어 개발 환경 선택 5 . 1 . gcc 5 . 2 . llvm 의 clang 5 . 3 . 비주얼 스튜디오 6 . 결론 1 . c 언어 란 무엇 인가 ? c 언어 는 1972 년 도 에 unix 운영 체제 ( os ) 의 assembly 코드 작성 을 줄이 기 위해 개발 된 고급 언어 이 다 . 운영 체제 작성 을 위해 개발 되 다 보 니 운영 체제 의 기본 적 이념 과 언어 적 특징 이 섞여 있 다 . 이런 연유 로 운영 체제 를 배울 때 가장 중요 한 것 중 하나 가 c 언어 에 대한 이해도 이 다 . ( 초기 unix 는 ken thompson 이 assembly 로 개발 했으며 이 후 unix 코드 의 대부분 은 c 언어 로 재 작성 되 었 다 . ) c 언어 는 at & t bell labs . 의 dennis ritchie 가 ken thompson , brian kernighan 과 만들 었 고 , 1989 년 도 에 ansi c 승인 을 받 았 다 . ** 켄 톰슨 , 데니스 리치 , 브라이언 커니 한 이 누군지 꼭 기억 하 고 알아보 자 . ( 여기 에 더 해 bill joy , richard stallman 도 알 아 두 면 좋 다 . ) 이 들 을 듣보잡 따위 , 이름 따위 라고 치부 하 면 앞 으로 크 게 되 기 힘들 다 . 2 . c 언어 표준 문법 c 언어 에 도 국제 표준 이 있 나 ? [ 1 ] => 그렇 다 . 현재 쓰이 는 것 은 c 99 , c 11 버전 이 있 다 . ( c 99 는 1999 년 도 표준 , c 11 은 2011 년 도 표준 ) ==> 오래 된 표준 인 ansi c 는 c 89 이 며 2015 년 을 기준 으로 하 면 26 년 이나 지난 너무 옛날 버전 이 다 . 표준 제정 이전 까지 생각 하 면 30 년 도 훌쩍 넘 은 옛날 버전 이 다 . 2015 년 을 기준 으로 하 면 가장 많이 쓰이 는 표준 은 c 99 이 므로 c 99 표준 에 맞춰서 배우 는 것 이 좋 다 . 심지어 최근 의 clang 컴파일러 는 기본 문법 이 c 99 로 바뀌 었 다 . 표준 이 아닌 내용 도 있 나 ? => 그렇 다 . c 언어 는 특히 표준 이 느슨 해서 비 표준 도 많 은 편 이 다 . 일례 로 gcc 의 확장 기능 , 비주얼 스튜디오 의 c 확장 기능 이 있 다 . 이 들 중 에 는 ub ( undefined behavior ) , ib ( implementation defined behavior ) 같 은 것 으로 분류 되 는 부분 도 있 다 . 책 에 나온 내용 은 전부 c 표준 문법 인가 ? => 아니 다 . 아쉽 게 도 c 표준 문법 을 지키 지 않 는 책 들 도 많 다 . 그런 책 들 은 문제 풀 이 식 , 속성 암 기식 을 지향 한다 . 그래서 본인 은 문제 풀 이 식 , 혹은 너무 쉬운 것 만 을 강조 하 는 그림 책 수준 의 c 언어 교재 는 추천 하 지 않 는 편 이 다 . 심지어 그림 으로 쉽 게 풀어쓴 책 들 의 그림 이나 비유 및 표현 은 잘못 된 경우 가 많 았 다 . 표준 을 지키 지 않 으면 어떤 문제 가 있 나 ? => 사고 가 발생 할 수 있 다 . 예 로 회사 에서 컴파일러 를 변경 했 다면 비 표준 으로 작성 해 왔 던 습관 은 큰 사고 를 일으킬 가능 성 이 있 다 . ( 돈 을 다루 는 곳 이 라면 매우 심각 한 문제 가 된다 ) ==> 비 표준 을 쓰 더라도 비 표준 과 표준 의 차이 를 알 고 쓰 거나 , 안 전하 게 conditional directive 를 설정 해뒀 다면 괜찮 다 . ( 실제로 중상 급 이상 이 되 면 비 표준 과 표준 을 자유 롭 게 쓰 면서 ub 나 ib 를 구분 할 수 있 는 레벨 이 된다 ) 그러나 비 표준 인지 혹은 ub 인지 도 모르 면서 되 는 대로 마구 써 대 면 곤란 하 다 . 따라서 일정 레벨 ( 중상 급 이상 ? ) 을 넘어가 기 전 까지 는 표준 에 익숙 해 지 도록 노력 하 는 것 이 좋 다 . 언어 를 배울 때 표준어 부터 배우 지 , 욕설 이나 비속어 , 방언 부터 배우 지 않 는 것 과 같 다 . 미국인 이 한글 을 비속어 , 은어 로 배워서 공식 석상 에서 \" 방가 방가 ~ xx 놈 들 아 \" 이렇게 연설 한다고 생각 해 보 자 . 한마디 로 끔찍 하 다 . 하지만 한국어 에 대해서 체계 적 으로 배우 고 , 활용 하 게 되 면서 경험 이 쌓이 면 공식 석상 에서 사용 하 는 표준어 와 비 공식 적 인 자리 에서 사용 하 는 비표준어 , 비속어 의 차이 에 대해 잘 알 게 되 는 것 과 같 다 . 3 . c 언어 를 공부 하 는 방법 3 . 1 . c 표준 문서 로 공부 할까 ? = 비 추천 c 표준 은 레퍼런스 로 사용 되 는 것 이 므로 학습 용 교재 는 아니 다 . 굳이 비교 하 자면 영어사전 같 은 느낌 ? 영어 사전 으로 단어 를 주구장창 외울 수 는 있 겠 지만 굳이 그런 방식 으로 공부 하 는 게 효율 적 일까 ? 참고 로 아래 는 c 표준 문서 이 다 . 이걸로 공부 하 기 는 쉽 지 않 다 . 그래서 교재 가 필요 한 법 이 다 . c 11 표준 문서 3 . 2 . 구 *, 네 * 버 검색 으로 시작 할까 ? = 비 추천 인터넷 은 정보 의 바다 ! !! 룰루랄라 ~~~ 이렇게 시작 하 는 것 이 바로 최악 이 다 . 이건 검색 을 아예 하 지 말 라는 소리 가 아니 다 . 어느 정도 기초 를 잡 기 전 에 검색 만 으로 해결 하 려는 습관 을 들이 지 말 라는 것 이 다 . goog ** 이나 nav ** 에 는 있 는 내용 은 2 가지 의 큰 문제 가 있 다 . 첫째 는 인터넷 의 블로그 나 지식검색 의 내용 이 올바른지 누가 보장 해 줄 수 있 느냐는 것 이 다 . 물론 고수 들 의 블로그 나 검증 된 사이트 의 문서 ( 예 를 들 어 ibm developerworks ) 는 대부분 오류 가 없 다 . 하지만 고수 들 의 블로그 나 검증 된 사이트 에 는 아쉽 게 도 초급 내용 은 별로 없 다 . 그래서 아 이러 니 하 게 도 인터넷 지식 은 고급 내용 일수록 오류 가 적 고 , 초급 내용 일수록 오류 가 많 다 . 둘째 로 블로그 나 지식검색 의 있 는 내용 은 조각난 지식 들 이 다 . 이 들 은 국소 적 인 내용 을 다루 는 경우 가 많 기 때문 에 중급 레벨 이 되 어 참고 용 으로 볼 때 는 가려운 곳 을 긁 어 주 듯이 좋 을 수 있 다 . 하지만 기초 가 없 을 때 검색 으로 공부 를 시작 하 면 체계 가 없 는 사상누각 이 될 가능 성 이 높 아 진다 . 결국 크리티컬 한 사고 를 치 는 사람 이 될 가능 성 이 높 아 진다 . internet knowledge 용산 에 가 면 다양 한 곳 에서 컴퓨터 부품 을 팔 지만 모르 는 사람 은 뒤통수 맞 기 십상 이 다 . 인터넷 도 안목 이 생긴 뒤 에 는 정보 의 바다 지만 안목 이 없 을 때 는 잘못 된 내용 을 배울 수 도 있 다 . 3 . 3 . it 학원 = 복불복 학원 은 복불복 이 다 . 학원 에 가 서 공부 한 사람 중 에 는 의외 로 제대로 배워온 사람 도 있 고 , 그렇 지 않 은 사람 도 있 다 . 한때 는 비트 컴퓨터 학원 은 꽤 믿 을 수 있 다고 도 했었 다 . ( 지금 은 예전 에 비하 면 . .. 음 . ..) 사실 어느 정도 기본기 가 있 다면 학원 에 가 도 무방 하 다 . 어차피 학교 에서 배운 내용 을 바탕 으로 틀린 내용 을 걸러낼 수 도 있 으니까 . 하지만 생판 초짜 일 때 학원 에 가 면 잘못 된 내용 을 검증 할 기초 지식 이 없 기 때문 에 , 잘 못 된 강사 를 만나 게 되 면 요상한 내용 만 배워 올 수 도 있 다 . 게다가 나쁜 코딩 습관 은 덤 이 다 . 물론 제대로 된 강사 를 만나 면 대박 이 겠 지만 . .. 이 쯤 되 면 확률 에 맡기 는 로또 가 된다 . ( 이건 대학 도 마찬가지 다 . 좋 은 교수 를 만나 면 대박 이 지만 엉터리 교수 를 만나 면 요상한 내용 을 배울 수 있 다 . 그래서 학습 자 는 되도록 이 면 많 은 교습 자 를 만나 고 , 많 은 책 을 읽 는 것 이 좋 다고 생각 된다 . ) 그래서 it 학원 은 복불복 이 다 . 3 . 4 . 독학 = 비 추천 독학 으로 배운 사람 들 의 특징 은 이해 하 지 못한 내용 을 상상 으로 메 꾼 다는 점 이 다 . 물론 매우 스마트 한 사람 은 독학 으로 도 대성 할 수 있 다 . 하지만 나 는 예외 적 인 상황 을 소개 하 려는 것 이 아니 다 . 간혹 독학 해도 성공 할 수 있 다면서 독학 으로 성공 한 유명 프로그래머 , 블 로 거의 이름 을 대 는 학생 들 이 있 다 . 그러면 나 는 되묻 는다 \" 본인 이 그 사람 들 만큼 스마트 한가 ? \" 라고 . .. 여기 서 yes 라고 할 수 있 다면 독학 해라 . 하지만 그렇 지 않 다면 누군가 의 도움 을 받 아라 . 그게 현명 한 선택 이 다 . ( 독학 으로 높 은 수준 에 오른 사람 들 은 독학 을 했 든 누군가 에게 배웠 든 어쨌든 스마트 한 머리 로 잘 할 수 있 는 사람 들 이 다 . 그 사람 들 과 비슷 한 레벨 이 아닌데 평범 한 사람 이 그 사람 이 했 던 방식 을 따라 하 면 실패 할 가능 성 도 높 다 . ) 3 . 5 . 그럼 어떻게 배워야 하나 ? 상책 ( 上策 ) 은 고수 한테 직접 배우 는 것 이 다 . 대학교 라면 뛰어난 교수 밑 에서 공부 하 거나 뛰어난 선배 그룹 에서 낑 겨 들어가 배우 는 거 다 . ( 하 지만 굇수가 도사리 고 있 는 랩 에 잘못 들어가 면 개고생 만 하 고 공부 는 ㅠㅠ ) 대학교 라면 학교 에 평판 이 좋 고 실력 도 좋 은 랩 이 있 을 거 다 . 조금 만 알아보 면 분명히 찾 을 수 있 다 . 학부 생 이 라고 하 더라도 방학 때 든 학기 때 든 랩 에 잔심부름 이 라도 하 면서 공부 하 겠 다고 하 면 내치 는 교수 님 은 없 다 . 내 친다고 하 더라도 열 번 찍 어 안 넘 어 가 는 교수 님 은 없 으니 계속 시도 해 보 길 권장 한다 . 좀 큰 회사 라면 사내 에 소문난 고수 가 한 두 명 은 꼭 있 다 . 아부 를 하 던 선물 공세 를 하 던지 인맥 을 터서 도제식 교육 을 받 는 것 도 좋 다 . 고수 에게 일 주일 에 1 시간 이 라도 핵심 원 포인트 레슨 을 받 는다면 크 게 실력 이 늘 수 있 다 . 하다못해 잡담 을 하 다가 도 고수 에겐 중요 한 키워드 를 얻 을 수 있 고 , 풀리 지 않 는 질문 을 하 면 결정 적 인 원 포인트 를 받 게 된다 . 개인 적 인 견해 지만 고수 에게 받 은 1 시간 원 포인트 레슨 은 적어도 100 시간 의 삽질 을 줄여 준다고 생각 한다 . 중책 은 좋 은 커뮤니티 의 오프 모임 을 이용 하 는 것 이 다 . 자세히 뒤져 보 면 꽤 좋 은 오프 스터디 그룹 이 있 다 . 커널 이 든지 리눅스 든지 열심히 조사 해 봐라 . 거기 가 서 바닥 부터 다지 면 큰 도움 을 받 을 수 있 을 것 이 다 . 하책 은 어쩔 수 없이 독학 , 학원 이 다 . 그 대신 에 좋 은 책 ( knk ) 으로 시작 해야 한다 . 주변 에 대충 물 어 보 고 \" oo 책 좋 냐 ? 쉽 냐 ? \", 혹은 네이버 에 \" c 언어 책 추천 \" 으로 검색 해서 c 언어 책 을 사 면 실패 할 가능 성 이 매우 높 다 . 특히 초급 자 들 끼리 서로 추천 해 주 는 책 은 믿 지 않 는 것 이 좋 다 . ( 실제로 모 코딩 관련 카페 에서 추천 도 서로 올려진 책 목록 중 에 거의 대부분 은 비 표준 이 남발 되 는 좋 지 않 은 책 이 었 다 . ) 예 를 들 어 초급 자 들 은 라면 스프 로 맛 을 낸 것 과 핸드 메이드 로 맛 을 우려낸 차이 를 알 지 못한다 . 그렇 다고 해서 요리 책 에서 초급 자 들 은 맛 을 잘 모르 니 라면 스프 를 쓰 라고 가르치 는 게 올바른 책 은 아니 지 않 는가 ? 책 추천 도 마찬가지 다 . 재밌 고 신나 지만 틀린 내용 이나 편법 을 가르쳐 주 는 책 으로 배워 봐야 무슨 소용 인가 ? 고수 들 의 세계 에서 는 서로 몇 다리 건너 면 알 만 한 사람 들 이 많 아서 공개 적 으로 디스 를 하 지 못한다 . 하지만 왠만 한 고 수분 들 은 다 안다 . 추천 을 많이 받 는 쉬운 책 들 중 에 함정 이 많 다는 것 을 . .. 간혹 국제 표준 준수 보다 쉽 고 신나 게 배우 는 게 중요 하 므로 표준 은 무시 해도 된다고 말 하 는 사람 도 있 다 . 물론 그 말 이 맞 을 수 도 있 다 . 간혹 표준 을 무시 하 고 야매 로 배웠 지만 후일 올바른 표준 을 다시 배워서 옳 은 길 로 가 는 사람 도 있 다 . 하지만 예외 적 인 케이스 를 보 고 그것 이 옳 다고 믿 는 것 은 좋 은 태도 가 아니 다 . 모든 배움 에 는 단계 와 규칙 이 있 다 . 그것 을 무시 해도 성공 하 는 돌연변이 들 이 있 지만 그것 을 일반 화 하 는 것 은 또 다른 오류 다 . 논문 을 써 본 사람 들 은 알 겠 지만 학회 는 논문 의 작성 규약 , 환경 제약 , 리뷰 조건 등 을 타이트 하 게 설정 한다 . 자연 과학 에서 는 시약 조차 도 특정 브랜드 를 사용 하 도록 규제 할 수 도 있 다 . 초보 자 들 에게 이런 규약 은 굉장히 불편 해 보이 지만 시간 이 지나 전문가 가 되 면 굉장히 합리 적 인 규칙 이 라고 생각 을 고쳐 먹 게 된다 . 왜냐하면 저런 규약 들 은 논문 의 재현 성 을 보장 하 기 때문 이 다 . 프로그래밍 에 있 어 표준 도 바로 그런 존재 다 . 표준 을 준 수 하 면 내 가 작성 한 코드 는 다른 플랫폼 에서 도 동일 한 작동 을 보장 할 수 있 다 . 그때 그때 다르 게 작동 하 거나 플랫 폼 이 다르 면 컴파일 이 실패 할 수 도 있 는 코드 는 올바른 코드 도 아닐 뿐 더러 나중 에 같이 일 하 는 사람 들 이 해당 버그 때문 에 고생 할 수 도 있 다 . ( 실제로 표준 을 잘 모르 는 사람 과 일 을 하 면 의외 의 버그 를 만들 어 피곤 한 일 들 이 많이 생기 고 , 전문가 들 은 점점 그런 사람 을 기피 하 게 된다 . 표준 을 지키 지 않 는 사람 은 컨벤션 도 거의 무시 하 거나 고집 만 쎈 경향 이 짙 다 . ) 물론 절대로 타인 과 같이 일 하 지 않 고 그냥 내 컴퓨터 에서 고독 하 게 코딩 을 통해 정신 수련 을 하 겠 다면 표준 따위 무시 해도 상관없 을지 모른다 . 그러나 그런 것 이 아니 라면 국제 표준 에 대해 이해 하 는 것 은 매우 중요 하 다 . 다시 한 번 말 하 지만 비 전공 자 이 며 low level 을 배울 필요 가 없 다면 되 도록 이 면 c 언어 를 배우 지 않 는 방향 으로 공부 하 는 게 좋 다 . 왜냐하면 c 언어 는 문법 은 쉽 지만 문법 구조 에 함정 이 많 은 스타일 이 기 때문 이 다 . 따라서 초급 에서 c 언어 문법 을 배우 기 는 쉽 지만 , 초급 에서 탈피 하 려면 언어 적 인 함정 을 피해 가 는 방법 과 os 레벨 , 하드웨어 레벨 의 지식 을 같이 배워야 하 기 때문 에 제대로 배우 는 게 쉽 지 않 다 . 비전 공자 , 그것 도 처음 시작 하 는 사람 에게 c 언어 를 추천 하 는 사람 이 있 다면 아마도 구렁텅이 에 빠트리 려고 하 는 행동 인지 의심 해 봐라 . 혹은 본인 도 추천 하 는 행동 의 결과 가 뭔지 도 모르 는 레벨 이 거나 . .. tip ! c 언어 에 는 많 은 사람 들 이 어렵 다고 생각 하 는 포인터 ( pointer ) 가 있 다 . 사실 포인터 개념 은 매우 직관 적 이 라 , 어려운 것 은 아니 다 . 하지만 이상 한 c 언어 책 들 이 포인터 를 미친 듯이 꼬 아서 가르치 기 때문 에 오히려 더 어렵 게 포장 되 어 있 다 . 그리고 이런 이상 한 책 들 은 포인터 를 떼 면 마치 c 언어 를 정복 한 것 처럼 호도 하 고 있 다 . 그러나 절대로 아니 다 . 포인터 를 떼 봐야 c 언어 문법 을 이제 막 뗀 초급 자 이 다 . c 언어 포인터 도 모른다면 아직 문법 도 못 뗀 상태 이 다 . 그리고 포인터 는 뒤 에 운영 체제 론 을 배워서 physical memory 와 page , segment 들 이 어떻게 맵 핑 되 는지 공부 해야 내부 구조 가 더 잘 이해 된다 . 따라서 엉성 하 게 포인터 를 비비꼬 아 놓 은 책 을 보 지 말 고 , 차라리 나중 에 운영 체제 론 을 배울 때 그 연관 성 에 대해서 공부 하 는 게 낫 다 . 가끔 보 면 학생 들 중 에 서너 개 씩 중첩 된 포인터 문제 를 풀 면서 머리 를 쥐 어 뜬 는 있 는 경우 를 볼 수 있 는데 , 쓸데없 는 일 이 다 . 4 . 검증 된 c 언어 책 은 무엇 이 있 는가 ? knk , k & r 이 검증 된 책 이 다 . 그 중 에서 knk 로 시작 한 뒤 에 다른 책 을 보 는 것 이 좋 다 . 책 이름 중 에 knk , k & r 은 저자 의 이름 에서 유래 한다 . knk 는 k . n . king 이 고 k & r 은 kernighan & ritchie 에서 유래 한다 . 아래 그림 이 바로 그 책 이 다 . c 언어 책 - knk ( 좌 ) k & r ( 우 ) 4 . 1 . knk knk 의 서명 은 c programming : a modern approach 이 며 c 언어 표준 에 입각 해서 쓰여진 책 이 다 . 이 책 은 전 세계 의 다양 한 고수 들 에 의해서 검증 된 책 이 다 . 현재 2 판 이 나와 있 으며 가장 많이 쓰이 는 c 99 ( 1999 년 표준 ) 에 입각 해서 쓰여져 있 다 . 책 표지 우측 상단 에 보 면 \" covers both c 89 and c 99 \" 라고 쓰여 있 는 것 을 볼 수 있 다 . knk 의 장점 은 표준 을 준 수 하 면서 예제 로 자료 구조 의 내용 을 조금 포함 하 고 있 다는 점 이 다 . 예 제도 상당히 잘 짜여져 있 어서 따라 하 기 에 도 좋 다 . 그림 과 도식 도 이론 적 으로 틀린 부분 이 없 다 . * k . n . king : [ URL ] c 언어 입문서 로 는 knk 만한 것 이 없 으므로 입문 을 제대로 해 보 고 싶 다면 knk 로 시작 하 는 것 을 추천 한다 . 2018 년 을 기준 으로 knk 의 번역 서 는 없 다 . 하지만 영어 가 어렵 게 쓰이 지 않 았 으므로 공개 된 페이지 를 미리 읽 어 봐서 해석 가능 한지 확인 해 보 는 것 도 좋 다 . 4 . 2 . k & r ( tcpl ) k & r 의 서명 은 the c programming language 이 며 c 언어 의 창시자 인 데니스 리치 ( dennis ritchie ) 와 브라이언 커니 한 ( brian kernighan ) 이 저술 한 책 이 다 . ( 책 제목 의 앞 글자 를 따 서 tcpl 이 라고 도 부른다 . ) ansi c ( 1989 년 이전 규칙 ) 의 구식 내용 이 지만 , 짧 은 내용 속 에 나와 있 는 예제 , 연습 문제 들 이 초기 c 언어 의 설계 철학 을 담 고 있 다 . knk 로 기본기 를 다진 뒤 에 k & r 을 읽 고 나 면 자신 도 모르 는 사이 에 c 언어 철학 을 이해 하 게 된다 . 참고 로 k & r 은 공부 를 한다기 보다 는 읽 으면서 행간 에 함의 하 고 있 는 뜻 이 무엇 인지 를 생각 해야 한다 . k & r 은 설명 이 장황 하 거나 많 지 않 기 때문 에 입문 용 은 아니 고 , 오히려 이 책 을 읽 으면서 막힘 이 없 다면 c 언어 의 초급 딱지 를 뗄 만 하 다는 것 으로 이해 하 면 좋 다 . ( k & r 의 내용 만 보 면 지금 컴퓨팅 환경 과 는 많이 다르 기 때문 에 그대로 적용 한다는 생각 은 버려야 한다 . 오히려 현시점 에서 k & r 방식 으로 코딩 하 면 선임 에게 혼날 수 있 다 . ) 이 두 책 을 읽 고 난 뒤 에 다른 c 언어 사파 무공 책 을 보 면 장단점 이 잘 보일 것 이 다 . 다른 책 의 장단점 이 보이 기 시작 한다는 것 은 본인 의 정종 내공 이 깊 어 져서 안목 이 높 아 진 것 을 반증 한다 . 참고 로 고수 세계 에서 는 이 두 책 을 보 지 않 은 c 프로그래머 를 신뢰 하 지 않 는 사람 들 도 많 다 . 왜 그런지는 책 을 통독 해 보 면 자연 스럽 게 알 게 된다 . 그리고 다른 책 을 보 다 보 면 꼭 명심 해야 할 것 이 있 다 . 어떤 책 이 든 틀린 부분 이 있 을 수 있 다 . 하지만 많 은 고수 가 검증 한 책 은 대체 적 으로 틀린 부분 이 적 은 편 이 다 . 네이버 , 다음 같 은 포털 에서 추천 평 이 많 거나 베스트셀러 라고 좋 은 책 이 라는 보장 은 없 다 . 오히려 국내 서 중 에 c 언어 베스트셀러 책 은 문제 가 많 았 다 . 비유 가 잘못 된 경우 도 많 았 고 , 내용 자체 가 표준 을 위반 하 거나 잘못 된 경우 도 많 았 다 . 잘못 된 경우 가 한두 개 가 아니 라 꽤 많 기 때문 에 큰 문제 가 있 다 . 일단 c 99 가 무엇 인지 소개 하 지 않 거나 c 표준 이 생긴 이유 와 역사 가 없 는 책 은 좋 지 않 은 책 일 가능 성 이 높 다 . = 결론 : 검증 된 책 으로 공부 해야 한다 . 인터넷 댓글 , 동아리 선배 가 추천 한 책 보다 고수 들 에게 검증 된 책 을 믿 자 . 물론 필자 의 글 도 의심 해 볼 수 있 다 . 의심 하 면서 knk 책 과 c 표준 에 대해 의심 하 고 조사 한다면 더욱 좋 다 . 그렇게 의심 이 많 은 사람 일수록 진리 에 접근 할 가능 성 이 높 아 진다 . == 위 의 책 만 읽 으면 c 언어 를 끝내 는 것 이 아니 라 올바르 게 시작 했 다는 것 을 말 한다 . c 언어 를 제대로 숙련 시킬 려면 최소한 대여섯 권 이상 의 책 을 봐야 한다 . ( 최소한 대여섯 권 이 다 . 제대로 배울려면 10 권 이상 봐야 한다 . ) 위 의 책 을 정독 하 고 나 면 나쁜 책 을 골라낼 수 있 으니 그 다음 은 여러 책 을 보 면서 틀린 점 을 찾아내 는 것 도 좋 은 경험 이 다 . 4 . 3 . c primer plus 이 외 에 knk 를 구할 수 없 을 경우 대체 가능 한 입문서 로서 c primer plus ( 6 th edition ) 도 있 다 . 이 책 도 c 99 표준 과 c 언어 의 역사 , 표준 의 필요 성 들 을 소개 하 고 있 으며 c 11 도 일부 소개 하 고 있 다 . 책 내용 에서 비 표준 을 남발 하 는 경우 도 없 다 . 다만 예 제 코드 에 몇몇 빠진 부분 이 존재 하 므로 컴파일 에러 가 발생 하 는 경우 라면 출판사 에서 제공 하 는 원래 예제 소스 파일 을 받 아서 비교 해 보 는 것 이 좋 다 . ( 예제 코드 의 빠진 부분 은 원서 와 번역 서 모두 같 다 ) 그리고 이 책 은 번 역서 가 존재 한다 . 번 역서 의 제목 은 \" c 기초 플러스 \" 이 다 . knk 원서 를 보 기 힘들 다면 이 책 을 추천 한다 . 번 역서 를 살펴본 결과 번역 의 품질 은 평범 한 수준 이 고 , 좋 다고 할 정도 는 아니 다 . ( it 업계 에서 왠만 하 면 원서 를 보 는 것 이 좋 다는 것 이 여기 서 도 나타난다 . 그리고 원서 를 보 는 연습 을 해 두 면 장기 적 으로 큰 도움 이 될 수 있 다 . ) c primer plus 6 th edition 4 . 4 . c : a reference manual 만일 knk 나 c primer plus 를 보 고 좀 부족 하 다 싶 으면 harbison & steele 의 c : a reference manual . ( prentice hall ) 을 보 는 것 도 좋 다 . 이 책 은 정리 하 는 목적 으로 보 는 경우 가 많 다 . ( 이 책 도 번역본 이 존재 한다 . ) c : a reference manual . 5 th ed . 4 . 5 . computer systems a programmer \\' s perspective 중급 도서 추천 을 요청 하 는 연락 이 종종 있 어서 또 하나 의 책 을 추가 하 도록 하 겠 다 . 사실 입문 레벨 의 c 언어 공부 법 을 추천 하 는 이 글 에서 중급 서적 , 그것 도 운영 체제 와 관련 이 깊 은 책 을 소개 하 는 게 맞 는지 는 모르 겠 으나 , 일단 소개 를 하 도록 하 겠 다 . 하지만 책 을 사 기 전 에 먼저 도서관 에서 살펴보 고 어느 정도 레벨 인지 확인 하 고 구입 하 면 좋 을 것 같 다 . 앞 에서 언급 했 듯이 c 언어 의 본래 목적 은 운영 체제 ( os ) 와 관련 이 깊 기 때문 에 중급 이상 의 부분 을 공부 하 려면 필히 컴퓨터 시스템 이 라는 종착역 에 가까워 지 게 된다 . 이 를 위해 os ( operating system ) 나 ca ( computer architecture ) , cs 과목 을 공부 해야 하 는데 , os 나 ca 는 코드 구현 부분 보다 는 추상 적 인 개념 을 중시 하 므로 c 언어 의 원리 에 대해 공부 할 때 는 cs ( computer system ) 로 공부 하 는 게 낫 다 . cs 에서 많이 쓰이 는 책 으로 는 csapp 라고 불리 는 computer systems : a programmer \\' s perspective , randal e . bryan 의 책 이 보 기 가 편하 다 . 이 책 은 번역판 이 있 으므로 접근성 도 괜찮 다고 생각 된다 . ( 번역 의 질 은 평균 이상 이 다 . ) computer systems a programmer \\' s perspective by bryant and o \\' hallaron csapp 는 os 와 ca 의 내용 이 조금 씩 소개 되 면서 c 언어 로 구현 된 부분 도 소개 하 고 있 다 . 만일 읽 다가 이해 가 가 지 않 는다면 os , ca 와 연계 된 내용 일 가능 성 이 있 으므로 조급 해 할 필요 는 없 다 . 나중 에 os , ca 를 같이 공부 하 다 보 면 각각 의 과목 들 과 연결 되 어 있 는 부분 이 자연 스럽 게 이해 될 수 있 기 때문 이 다 . 5 . c 언어 개발 환경 선택 이제 공부 할 방법 과 책 이 선정 되 었 다면 개발 환경 을 선택 해야 한다 . c 언어 를 처음 배운다면 컴파일러 는 gcc 나 llvm 의 clang 을 직접 사용 하 는 방향 으로 시작 하 는 것 이 낫 다 . ide 통합 개발 환경 을 사용 하 는 것 은 나중 에 하 는 것 이 좋 다 . 특히 컴파일러 를 직접 명령 행 에서 타이핑 해서 실행 하 는 경험 은 매우 중요 한데 , 이 는 c 언어 뿐 만 아니 라 대부분 의 언어 들 이 작동 하 는 방식 , 즉 프리 프로세싱 , 컴파일 , 링 킹 이 어떻 게 작동 하 는 이해 하 는 데 중요 한 경험 이 되 기 때문 이 다 . 만일 처음 부터 ide 환경 으로 배우 면 ide 환경 이 없 을 때 는 아무것 도 못하 고 , f 5 만 누르 면 뭐 든 뚝딱 만들 어 내 는데 그게 왜 되 는지 이해 하 지 못하 기 도 한다 . 특히 비주얼 스튜디오 ( visual studio ) 는 매우 좋 은 툴 이 지만 초급 딱지 를 떼 고 나 서 c ++ 이나 c # 을 배울 때 사용 하 는 편 이 좋 다 . 특히 컴파일러 , 링커 , 편집기 , 빌드 툴 , 디버거 는 원래 별개 의 프로그램 인데 , ide 로 시작 해서 배우 면 이 들 의 경계 를 잘 몰라서 나중 에 개념 적 으로 혼란 을 겪 는 경우 가 많 다 . 그래서 기초 를 중시 하 는 교수 님 은 비주얼 스튜디오 를 설치 하 는 경우 에 도 메모장 에서 소스 코드 를 타이핑 해서 명령 행 으로 컴파일 하 는 것 을 가르쳐 주 는 경우 도 있 었 다 . 5 . 1 . gcc gnu 의 c 컴파일러 이 다 . 표준 을 잘 지키 는 편 이 다 . 비 표준 의 편리 한 기능 을 제공 하 는데 , gcc 의 비 표준 기능 은 역 으로 표준 에 흡수 되 기 도 했 다 . = linux , unix , windows 등 다양 한 곳 에서 사용 되 므로 여러 운영 체제 에서 프로그래밍 할 때 혼란 을 겪 지 않 는다 . = ms 윈도 에서 해야 만 한다면 vmware 나 virtualbox 에 설치 해 보 는 것 이 더 좋 다 . ( cygwin 도 있 긴 하 지만 추천 하 지 는 않 는다 . ) intel 컴파일러 ( icc ) 도 좋 지만 상용 이 다 . 하지만 회사 는 성능 을 위해서 icc 를 사용 하 는 곳 도 많 다 . 5 . 2 . llvm 의 clang 표준 도 잘 지키 고 최신 컴파일러 기능 도 있 다 . = mac osx 에 탑재 된 컴파일러 가 llvm 기반 의 clang 이 다 . 요샌 linux 에서 도 많이 쓰인다 . 5 . 3 . 비주얼 스튜디오 ( 비 추천 ) 비주얼 스튜디오 의 vc ++ 은 c ++ 기반 이 라서 c 와 c ++ 중 어떤 기능 을 사용 하 는지 헷갈릴 수 있 고 비 표준 도 많 다 . 특히 c ++ 기반 이 라서 c 99 문법 중 일부분 을 지원 하 지 못한다 . ( vc ++ 은 2016 년 기준 으로 아직 도 c 99 표준 을 지원 하 지 못한다 . ) 물론 중급 자 는 vc ++ 을 사용 하 더라도 이런 차이 를 혼동 하 지 않 는다 . 하지만 초급 자 에겐 큰 혼란 을 준다 . 이 는 다른 플랫폼 으로 전환 할 때 도 혼란 을 겪 게 한다 . 간혹 c ++ 은 플러스 가 2 개 나 붙 었 으니 c 의 모든 기능 을 포함 하 는 것 이 아니 냐고 묻 는 사람 들 도 있 다 . ( 그럼 c # 은 + 가 4 개 나 되 는데 c , c ++ 을 모두 포함 하나 ? ??) c ++ 이 탄생 되 던 시기 에 는 분명 ansi - c 와 옛날 문법 체계 를 포함 했었 다 . 1970 ~ 80 년 대 초반 에 c 언어 의 유행 은 너무나 대단 해서 c ++ 이 c 의 문법 체계 를 수용 하 는 것 이 유리 했 기 때문 이 었 다 . 그러나 1999 년 에 승인 된 c 99 표준 이후 로 는 둘 ( c ++, c ) 은 결별 하 여 다른 언어 가 되 었 다 . 게다가 1999 년 c 99 로부터 12 년 뒤 에 발표 된 c 11 ( 2011 년 도 표준 ) 에서 는 c ++ 과 는 점점 더 다른 길 을 걷 고 있 다 . 물론 공통 분모 가 되 는 비슷 한 부분 은 꽤 많 지만 , 틀린 부분 도 꽤 많 기 때문 에 이젠 둘 의 차이 를 정확 하 게 인식 해야 실수 하 지 않 을 수 있 다 . 아직 도 c ++ 이 c 의 수퍼 셋 이 라고 한다면 20 년 도 넘 은 옛날 지식 을 업데이트 하 지 않 은 것 이 다 . 이젠 더 이상 c ++ 은 c 표준 을 포함 하 지 않 는다 . 다시 말 해 c ++ 은 c 의 수퍼 셋 이 아니 다 . ( 다른 말 로 하 면 c 는 c ++ 의 서브 셋 이 아니 다 . ) 둘 의 차이 는 아래 링크 의 글 을 읽 어 보 도록 하 자 . incompatibilties between iso c and iso c ++ [ URL ] 6 . 결론 6 . 1 . c 언어 는 이공 계열 의 제 1 외국어 같 은 녀석 이 다 . 이공 계열 전공 자라 면 꼭 배워야 만 한다 . ( 비 전공 자라 면 오히려 배우 지 않 아도 된다 . ) 6 . 2 . c 언어 책 은 knk ( or c primer plus ) 로 시작 하 고 k & r 로 끝맺 는 것 이 좋 다 . 그러나 이것 이 끝 이 아니 라 시작 임 을 알 아야 한다 . 그리고 이왕이면 harbison & steele 의 c a reference manual 도 보 는 것 이 좋 다 . ( c 99 국제 표준 , 그리고 c 와 c ++ 의 차이점 을 자세히 다루 지 않 는 책 은 던져 버리 는 것 이 좋 다 . 그런 책 은 저자 가 정통 으로 배우 지 않 은 경우 다 . 특히 쉬운 책 만 찾 다가 는 잘못 된 길 로 갈 수 있 다 . ) 6 . 3 . 입문 용 c 언어 개발 환경 은 gcc 나 clang 이 좋 다 . 단 gui ide 환경 부터 쓰 는 것 은 피하 는 것 이 좋 다 . 6 . 4 . 운영 체제 는 linux , unix , macosx , windows 든 상관없 다 . 그러나 리눅스 를 추천 한다 . ( 보통 vmware 나 virtualbox 가상 머신 에 설치 하 는 것 도 좋 다 ) 6 . 5 . 공짜 는 없 다 . 최소한 책 은 사 서 보 자 . ( 책장 에 꼽 아 두 고 계속 읽 어서 완전히 소화 해야 한다 . ) 6 . 6 . 대충 인터넷 검색 으로 배울려고 하 지 말 자 . 나중 에 정통 으로 배운 사람 에게 걸리 면 민폐 프로그래머 된다 . 6 . 7 . 빠르 게 단기 속성 으로 배우 는 게 중요 한 게 아니 다 . 올바르 게 배우 는 것 을 목표 로 삼 아야 만 한다 . 6 . 8 . 의심 해라 . 책 이 든 인터넷 블로그 의 글 이 든 의심 하 자 . 의심 해서 나쁠 것 은 없 다 . 오히려 의심 을 쉽 게 거두 는 것 을 두려워 하 는 것 이 좋 다 . 의심 은 진리 에 접근 하 는 좋 은 방법 이 다 . ( 추신 ) 공짜 로 떠먹여 준다는 태도 를 버려라 . 값어치 가 있 는 것 은 유형 이 든 무형 이 든 손쉽 게 얻 을 수 없 다 . 쉽 거나 공짜 로 얻 을 수 있 는데 값어치 가 높 다 ? ? 그런 건 없 다 . 공짜 , 쉬운 것 만 찾 으면 절대로 발전 하 지 못한다 . 특히 어려운 내용 이 나오 면 바로 포기 하 고 , 쉬운 책 이나 쉬운 설명 만 을 쫓아다니 면 절대로 발전 할 수 없 다 . 어려운 문제 로 고민 하 는 시간 은 공부 에 있 어 필수 다 . 질문 하 는 방법 을 제대로 익혀라 . [ 2 ] 무엇 을 하 려고 했 고 , 어떤 문제 가 발생 했 고 , 자신 이 모르 는 것 이 정확히 무엇 인지 질문 할 수 있 어야 한다 . 밑 도 끝 도 없이 질문 하 거나 문제 를 풀 어 달 라고 하 면 rtfm 이상 의 좋 은 소리 를 듣 지 못할 것 이 다 . 또한 회사 나 학교 의 고수 선배 에게 원 포인트 레슨 을 받 았 으면 하 다 못해 커피 나 간식 이 라도 사 서 감사 를 표 해라 . 그렇 지 않 으면 누가 당신 에게 자신 의 시간 을 쪼개 서 가르침 을 주 겠 는가 ? 고수 일수록 바쁘 고 급여 가 쎄 기 마련 이 다 . 그런 사람 이 당신 을 위해 소모 한 시간 을 돈 으로 환산 해 봐라 . ( 예 를 들 어 시급 25 만 원 짜리 인력 이 당신 을 1 시간 가르쳤 다고 생각 해 보 라 ) 그래서 회사 에서 는 신입 을 뽑 을 때 태도 를 중시 한다 . 그게 바로 발전 가능 성 을 좌우 하 기 때문 이 다 . 비인 부전 ( 非人 不 傳 ) 이 라는 말 이 있 듯이 배우 고자 하 는 사람 이 라면 태도 가 중요 한 법 이 다 . [ 1 ] open standards . [ URL ] [ 2 ] 김정균 . 초보 자 들 이 처음 시작 을 하 는데 필요 한 상식 . [ URL ] * 본 글 의 댓글 중 에 사 적 인 질문 이나 본문 글 과 무관 한 내용 은 정기 적 으로 삭제 하 고 있 습니다 . 댓글 이 너무 많 아서 본 글 을 읽 기 힘들 어 지 기 때문 에 어쩔 수 없이 내린 방법 이 니 양해 해 주 시 기 바랍니다 . * c ++ 에 대한 책 추천 을 하 는 댓글 이 많 아 지 는데 , c ++ 도 c 와 마찬가지 로 modern c ++ 의 표준 인 c ++ 11 , c ++ 14 을 다루 는 책 으로 공부 하 시 면 됩니다 . 대부분 원서 이 며 국내 서 중 에 는 c ++ 11 , c ++ 14 를 다룬 책 은 없 는 것 으로 압 니다 . ( 번역 서 는 몇 권 있 습니다 . ) c ++ 책 목록 은 나중 에 1 만 년 뒤 쯤 에 따로 정리 하 겠 습니다 . ^^',\n",
       "       '리눅스 아재 력 or 할배 력 테스트 이 테스트 는 리눅스 옛날 명령어 만 알 고 있 는지 , 아니면 대체 된 새로운 명령어 도 알 고 있 는지 알려 줍니다 . deprecated 된 옛날 명령어 ( 일명 아재 명령어 or 할배 명령어 ) 만 알 고 있 다면 이제 새로운 명령어 와 기능 들 도 열심히 배우 도록 합시다 . * 사용 방법 아래 명령어 나 기능 중 에 a 가 가장 오래 된 기능 이 고 , 이후 보기 들 ( b , c , d ) 은 대체 된 새로운 기능 이 거나 명령어 입니다 . 예 를 들 어 문항 에서 a , b , c 를 모두 알 고 있 다면 최근 새로운 기능 까지 모두 알 고 있 는 것 입니다 . part 1 : 기초 명령어 , 셸 1 - 1 . 터미널 화면 clear ( or scroll up ) a ) clear b ) 아직 도 화면 을 지우 기 위해 clear 를 타이핑 하 고 있 나요 ? 단축키 하나 로 해결 할 수 있 는데 말 입니다 . 보통 bash 의 기본 입력 모드 인 emacs 모드 에서 는 ctrl - l 이 바로 가능 하 지만 vi 모드 일 경우 ( 즉 set - o vi 세팅 된 경우 ) 라면 bind - m vi - insert \"\\\\ c - l \": clear - screen 설정 이 필요 합니다 . 이 설정 은 . bashrc 같 은 곳 에 넣 어 두 면 됩니다 . = = = = = = = = = ========================= 1 - 2 . bash 로그아웃 a ) exit , logout b ) 로그아웃 할 때 매번 exit 를 친다면 이제 단축 히 하나 로 해결 하 는 게 어떨까 요 ? = = = = = = = = = ========================= 1 - 3 . vim 에서 문서 저장 하 고 종료 하 는 명령 a ) : wq b ) : x c ) zz : wq 만 사용 하 는 분 보다 더 아재 인 분 들 은 습관 적 으로 : wq ! 까지 붙여서 사용 합니다 . 이제 좀 더 최근 명령어 인 zz 를 사용 합시다 . 세 명령어 모두 vi 에 있 었 던 명령어 라고 합니다 . ( 송민철 님 이 알려 주 셨 습니다 . ) 그냥 이 문항 은 별 의미 는 없 고 그냥 재미 로 봐 주 시 기 바랍니다 . = = = = = = = = = ========================= 1 - 4 . shell script 를 읽 어 오 는 명령 ( subshell 실행 이 아님 ) a ) . ~/ module . sh b ) source ~/ module . sh 점 ( dot ) 만 쓰 고 source 를 모르 고 있 다면 마음 은 이미 아재 리 눅 서 입니다 . = = = = = = = = = ========================= 1 - 5 . bash 쉘 에서 수식 계산 하 는 명령어 a ) expr b ) $(...) c ) let expr 은 지금 완전히 사라져서 쓰 지 않 는 명령어 중 에 하나 입니다 . 아직 도 쓰 고 있 다면 . ... 음 새롭 게 다시 공부 하 셔야 합니다 . = = = = = = = = = ========================= 1 - 6 . 일 회 성 으로 죽 지 않 고 백그라운드 로 작동 할 명령어 a ) nohup b ) systemd - run systemd 가 도입 된 뒤 로 는 systemd - run 을 주로 사용 하 게 됩니다 . 더군다나 타이머 를 이용 해서 몇 시간 뒤 에 작업 을 실행 하 게 할 수 도 있 고 , cpu 사용 율 이나 io 사용 율 등 여러 가지 우선 순위 도 조작 할 수 있 습니다 . part 2 : 네트워크 = = = = = = = = = ========================= 2 - 1 . 네트워크 상태 를 확인 하 는 명령어 a ) netstat b ) ss netstat 은 이제 ss 로 대체 되 었 습니다 . 아직 도 netstat 명령 을 사용 한다면 할 배 리 눅 서 를 인증 하 는 셈 입니다 . 어서 빨리 ss 를 사용 하 세요 . ( 심지어 ss 는 훨씬 빠르 답니다 . netstat 는 시스템 에 부담 을 많이 줍니다 . ) = = = = = = = = = ========================= 2 - 2 . 네트워크 인터페이스 및 라우팅 , 설정 관련 명령어 a ) ifconfig , route b ) ip c ) nmcli 몇 년 전 부터 nmcli 를 사용 하 여 네트워크 를 설정 합니다 . / etc 밑 에 있 는 설정 파일 을 직접 에디터 로 수정 하 는 것 은 호랑이 담배 피 던 시절 의 옛날 방식 입니다 . 심지어 과거 에 사용 되 던 방식 은 centos 8 부터 는 아예 deprecated 되 었 습니다 . nmcli 쓰 는 방법 에 익숙 해져야 합니다 . 혹시 network manager 를 꺼야 만 한다는 인터넷 의 옛날 문서 를 보 고 있 다면 . .. 음 이젠 시대 가 바뀌 었 습니다 . = = = = = = = = = ========================= 2 - 3 . 패킷 캡처 명령어 a ) tcpdump b ) wireshark , tshark = = = = = = = = = ========================= 2 - 4 . 네임 서비스 질 의 명령어 a ) nslookup b ) dig 설마 아직 까지 nslookup 만 쓰 고 있 으신 가요 ? part 3 : 서버 애드 민 = = = = = = = = = ========================= 3 - 1 . 레드햇 계열 패키지 설치 명령어 a ) 패키지 가 뭔가요 ? 설치 라면 무조건 make ; make install 로 해결 한다 . b ) rpm c ) yum d ) dnf dnf 는 차세대 방식 이 므로 2016 년 을 기준 으로 아직 은 몰라도 상관 은 없 습니다 . 그러나 yum 은 잘 사용 해야 겠 지요 . 간혹 x 윈도우 를 사용 하 면서 packagekit 와 충돌 나 는 경우 를 해결 하 지 못한다면 당신 은 리눅스 초보 입니다 . = = = = = = = = = ========================= 3 - 2 . 데비안 계열 패키지 설치 명령어 a ) 패키지 가 뭔가요 ? 설치 라면 무조건 make ; make install 로 해결 한다 . b ) dpkg c ) apt - get , apt - cache d ) aptitude d ) apt 아직 도 중간 에 - 를 타이핑 하 기 위 햇 apt - get , apt - cache 를 타이핑 하 시 나요 ? 아예 x 윈도우 에서 패키지 관리 프로그램 을 사용 하 신다고요 ? 실제 실무 환경 에서 는 x 윈도우 를 쓰 지 않 기 때문 에 실무 에서 는 불가 합니다 . = = = = = = = = = ========================= 3 - 3 . 스케줄 러 a ) at , cron b ) anacron c ) systemd . timer 요새 는 cron 보다 는 systemd . timer 를 쓴 답니다 . cron 은 이제 구시대 의 유물 이 되 어 버렸 습니다 . = = = = = = = = = ========================= 3 - 4 . 서비스 제어 명령어 a ) service , update . ..* b ) systemctl service 는 과거 sysv init 구조 에서 사용 하 던 명령어 입니다 . 이제 새로운 리눅스 는 전부 systemd 기반 에서 작동 하 므로 systemctl 명령 을 사용 합니다 . systemctl 외 에 journalctl , loginctl , hostnamectl , timedatectl , localectl , machinectl 등 자 매품 도 있 습니다 . = = = = = = = = = ========================= 3 - 5 . 커널 설정 변경 하 기 a ) sysctl b ) tuned - adm sysctl 로 직접 커널 파라 메터 를 수정 하 는 것 은 이제 옛날 방법 입니다 . 요새 는 dynamic adaptive system tuning daemon 인 tuned 를 사용 하 는 방법 을 씁니다 . = = = = = = = = = ========================= 3 - 6 . 부트 파라 메터 설정 a ) 직접 편집 하 기 b ) grubby vi 로 직접 grub 설정 을 편집 하 는 것 은 위험 합니다 . 이젠 되도록 이 면 grubby 를 쓰 셔야 합니다 . = = = = = = = = = ========================= 3 - 7 . stat 계열 명령어 a ) vmstat , iostat . .. b ) dstat 요샌 python 으로 쉽 게 플러그인 을 만들 어 쓸 수 있 도록 되 어 있 고 , 입맛 에 따라 field 조절 이 가능 한 dstat 도 많이 씁니다 . part 4 : 디스크 관리 = = = = = = = = = ========================= 4 - 1 . 파티션 편집 , 관리 명령어 a ) fdisk b ) cfdisk , sfdisk c ) parted = = = = = = = = = ========================= 4 - 2 . 마운트 / 언마 운트 명령어 a ) mount b ) udisksctl mount 도 여전히 쓰이 지만 좀 더 편리 한 udisksctl 을 써 보 세요 . = = = = = = = = = ========================= 4 - 3 . 마운트 , 파일 시스템 , 블록 장치 조회 명령어 a ) mount , fdisk - l b ) lsblk , blkid , findfs c ) findmnt 마운트 포인트 확인 은 요새 findmnt 쓰 는 거 아 시 죠 ? 이 명령어 처음 본다면 아재 , 혹은 할배 인증 입니다 . 배움 에 는 육체 적 인 나이 보다 새로운 것 을 빠르 게 받아들이 는 정신 적 나이 가 더 중요 한 법 입니다 . 과거 의 기술 만 알 고 새로운 것 이 나왔 는지 찾아보 는 노력 이 없 다면 아무리 어려도 정신 적 인 나이 는 할배 가 됩니다 . 그러나 재미 를 위해 만든 셀프 테스트 이 므로 , 너무 심각 하 게 받아들이 거나 자학 할 필요 는 없 습니다 . 모르 면 새로 배우 면 되 죠 . ^^ 그냥 생각나 는 대로 썼 기 때문 에 나중 에 다른 기능 들 이 추가 될 수 도 있 습니다 . * history 2020 - 10 - 04 4 개 의 파트 로 분할 정리 , 몇 가지 추가 2019 - 10 - 13 systemd - run 추가 2018 - 05 - 10 nslookup , dig , 파티션 편집 , 마운트 / 언마 운트 , 마운트 / 블록 상태 명령어 추가 2016 - 11 - 22 source 와 dot 명령어 의 잘못 된 설명 반영 , vi 명령어 에 대한 잘못 된 설명 반영 ( 송민철 님 의 제보 ) 2016 - 11 - 21 초안',\n",
       "       '처음 파이썬 에 관심 을 가지 게 된 이유 는 크롤러 와 스 크 래퍼 때문 이 었 다 . 이번 에 는 beutifulsoup 를 활용 해 동국 대학교 학식 식단표 를 스 크 래핑 해본다 . ( mac os x , python 3 . 4 . 1 환경 에서 실행 된 내용 임 ) beatifulsoup 설치 user $ pip install beautifulsoup 4 위 의 명령어 를 입력 하 여 beutifulsoup 를 설치 한다 . 스 크 래핑 할 페이지 갖 고 오 기 from bs 4 import beautifulsoup from urllib . request import urlopen html = urlopen ( \\'[ URL ] ) source = html . read ( ) html . close ( ) print ( source ) 우선 beautifulsoup 을 import 하 고 홈페이지 를 얻 어 오 기 위해 urllib 의 urlopen 을 import 해온다 . 그리고 동국 대학교 학식 식단표 페이지 의 주소 를 갖 고 오 도록 urlopen 을 사용 한 뒤 가져온 내용 을 출력 해 보 는 코드 를 짠다 . 위 와 같이 임의 의 파이썬 파일 을 생성 하 고 실행 해 보 면 복잡 한 문자 들 이 나열 되 는 것 을 볼 수 있 다 . 페이지 주소 뒤 에 w , l , j 의 값 을 바꿔 입력 해 보 면 w 와 j 는 메뉴 에 따른 request 값 이 고 , j 는 0 이 면 이번 주 , 1 이 면 다음 주 식단 이 나타나 는 것 을 확인 할 수 있 다 . 지난주 식단 은 볼 수 없 다 ( ? ) import . . html = urlopen ( \\'[ URL ] ) source = html . read ( ) html . close ( ) soup = beautifulsoup ( source , \" lxml \" ) print ( soup ) 아까 프린트 해 보 았 던 source 를 beautifulsoup 에 넣 고 그 내용 을 출력 해 보 면 , 이전 보다 는 정제 된 모습 을 출력 해 주 는 것 을 확인 할 수 있 다 . lxml 을 인자 로 넘겨 주 면 , 해당 페이지 html 파싱 을 lxml parser 로 한다는 것 을 의미 한다 . ( pip install lxml 필요 ) 식단표 테이블 가져오 기 . .. 동국 대학교 식단표 홈페이지 의 소스 를 확인 해 보 면 위 와 같이 식단표 테이블 을 sdetail 이 라는 id 를 가진 div 가 감싸 고 있 음 을 확인 할 수 있 다 . 내게 필요 한 내용 은 식단표 내용 밖에 없 으니 , 이 부분 만 불러오 도록 한다 . import . . html = urlopen ( \\'[ URL ] ) source = html . read ( ) html . close ( ) soup = beautifulsoup ( source , \" lxml \" ) table _ div = soup . find ( id = \" sdetail \" ) tables = table _ div . find _ all ( \" table \" ) menu _ table = tables [ 1 ] trs = menu _ table . find _ all ( \\' tr \\' ) print ( trs [ 2 ] ) beautifulsoup 의 find ( ) 메소드 는 인자 로 넘겨 준 값 의 첫 번 째 결과 값 을 반환 한다 . 페이지 내 에 table 이 많 다면 많 은 테이블 중 에 첫 번 째 테이블 의 내용 만 반환 하 는 것 이 다 . find _ all ( ) 메소드 는 인자 로 넘겨 준 값 의 모든 결과 값 을 리스트 로 반환 한다 . 따라서 위 와 같 은 코드 를 입력 후 파일 을 실행 해 보 면 div 안 의 모든 table 이 출력 됨 을 볼 수 있 다 . 그런데 , 식단표 페이지 의 소스 를 잘 보 면 div # sdetail 안 에 는 table 이 두 개 들 어 있 다 . 식단표 테이블 은 두 번 째 테이블 이 므로 tables [ 1 ] 에 해당 한다 . 식단표 테이블 안 에서 각 줄 별 로 정보 를 가져와 trs 라는 이름 의 list 에 저장 한다 . 이 파일 을 실행 해 보 면 해당 행의 식단 이 표시 되 는 것 을 볼 수 있 다 . import . . html = urlopen ( \\'[ URL ] ) source = html . read ( ) html . close ( ) soup = beautifulsoup ( source , \" lxml \" ) table _ div = soup . find ( id = \" sdetail \" ) tables = table _ div . find _ all ( \" table \" ) menu _ table = tables [ 1 ] trs = menu _ table . find _ all ( \\' tr \\' ) sangrok _ bakban _ lunch = trs [ 8 ] tds = sangrok _ bakban _ lunch . find _ all ( \\' td \\' ) mon = tds [ 3 ] . span . string tue = tds [ 4 ] . span . string wed = tds [ 5 ] . span . string thu = tds [ 6 ] . span . string fri = tds [ 7 ] . span . string print ( mon , tue , wed , thu , fri )',\n",
       "       '지하철 의 수송력 도시 교통수단 으로서 지하철 을 비롯 한 궤도 교통 의 강점 은 수송력 에 있 다 . 그래서 많 은 도시 들 은 규모 가 커지 게 되 면 지하철 신설 을 서두른다 . 버스 나 지상 교통 만 으로 는 도저히 교통량 을 감당 할 수 가 없 기 때문 이 다 . 서울 도 예외 가 아니 라서 산업 화 가 본격 화 되 었 던 6 ~ 70 년 대 교통량 의 급증 으로 도심 도로 는 극심 한 혼잡 에 시달렸 다 . 그래서 서울시 는 1974 년 에 지하철 1 호 선 을 최초 로 개통 했 다 . 이후 에 도 노선 은 꾸준히 증설 되 어 가장 최근 에 개통 한 노선 이 지난해 12 월 개통 한 9 호 선 3 단계 구간 ( 종합운동장역 - 중앙 보훈 병 원역 ) 이 다 . 현재 지하철 은 서울시 교통량 의 약 40 % 를 담당 하 고 있 다 . 또한 도로 혼잡 완화 에 도 크 게 기여 하 고 있 다 . 이 에 따라 이번 호 에서 는 지하철 의 수송력 이 어떻게 결정 되 는지 알아보 자 . 우선 지하철 의 수송력 은 다음 공식 으로 결정 된다 . 여기 서 수송력 은 한쪽 방향 또는 1 시간 당 이 다 . 수송력 = 편성 량수 × 전동차 1 량 의 정원 × 혼잡도 × 시간 당 운행 횟수 편성 량수 ? 지하철 의 가장 큰 특징 은 차량 여러 대 가 연결 되 어 운행 된다는 점 이 다 . 이 는 1 량 단위 로 운행 되 는 버스 와 가장 큰 차이점 이 다 . 그래서 전동차 는 한 번 에 운행 할 때 버스 보다 더 많 은 사람 들 을 실 어 나를 수 있 다 . 물론 버스 도 이 문제 를 극복 하 기 위하 여 2 량 으로 이어진 굴절버스 , 위아래 로 객실 이 있 는 2 층 버스 등 을 도입 한 사례 가 있 으며 국내 에 는 없 지만 외국 에 는 이중 굴절버스 ( bi - articulated bus ) 라고 해서 , 3 량 을 이어서 운행 하 는 버스 도 있 다 . 심지어 는 2 층 버스 가 굴절버스 로 이어진 경우 까지 있 다 . 하지만 역시 전동차 에 는 미치 지 못한다 . 편성 량수 란 전동차 의 운행 단위 인 1 편성 이 몇 량 의 차량 으로 구성 되 었 는지 를 말 하 는 숫자 다 . 국내 지하철 의 편성 량수 는 다음 과 같 다 . 편성 량수 노선 10 서울 1 ~ 4 호 선 8 서울 5 ~ 7 호 선 , 인천 1 호 선 , 부산 1 호 선 , 경 의 중앙선 , 경춘선 6 서울 8 호 선 , 9 호 선 ( 일부 ) , 2 호 선 ( 신정 지선 ) 부산 2 호 선 , 4 호 선 , 대구 1 ~ 2 호 선 , 분당선 , 수인선 , 공항철도 , 신분당선 4 서울 9 호 선 ( 일부 ) , 2 호 선 ( 성수 지선 ) 부산 3 호 선 , 대전 1 호 선 , 광주 1 호 선 서해선 , 경강선 , 1 호 선 광명 셔틀 ( 영등포 - 광명 ) , 경 의 중앙선 ( 일부 ) , 동해선 3 대구 3 호 선 2 우이 신 설선 , 인천 2 호 선 , 의정부 경전철 , 인천 공항 자기부상열차 , 부산 김해경 전철 1 용인 경전철 편성 량수 가 커지 면 , 그 노선 의 수송력 이 높 아 진다 . 실제로 표 를 보 면 , 수요 가 많 은 노선 일수록 편성 수 가 큰 것 을 알 수 있 다 . 서울 지하철 도 수요 가 많 은 1 기 노선 ( 1 ~ 4 호 선 ) 은 10 량 , 상대 적 으로 적 은 2 기 노선 ( 5 ~ 8 호 선 ) 은 8 ~ 6 량 을 쓴다 . 2 기 노선 중 8 호 선 만 6 량 인데 이 는 8 호 선 이 외곽 으로 운행 하 며 노선 이 짧 아서 수요 가 적 을 것 으로 예상 했 기 때문 이 다 . 경전철 의 편성 량수 도 대부분 2 량 인데 이것 역시 수요 가 적 기 때문 이 다 . 아울러 편성 량수 는 대부분 짝수 로 되 어 있 는데 , 이 는 동일 한 설비 를 이중 으로 설치 하 여 , 한 설비 가 고장나 더라도 다른 설비 로 운행 을 계속 할 수 있 게 하 는 전동차 설계 철학 에 기인 한 것 이 다 . 그래서 4 량 전동차 나 8 량 전동차 의 설비 구조 는 좌우 가 대칭 으로 되 어 있 다 . 물론 대구 3 호 선 은 3 량 이 라는 독특 한 형태 이 고 , 용인 경전철 처럼 아예 1 량 으로 되 어 있 는 경우 도 있 다 . 1 량 편성 은 버스 같 은 형태 라고 볼 수 있 겠 다 . 이렇게 편성 량수 를 늘리 면 수송력 이 높 아 질 뿐 만 아니 라 , 기관사 1 인 당 수송 할 수 있 는 승객 수 가 늘어나 므로 인건비 절약 에 도 도움 이 된다 . 다만 편성 량수 를 늘리 면 승강장 길이 도 길 어 져야 하 므로 건설비 와 유지 보수비 가 늘어나 는 문제 가 있 다 . 서울 9 호 선 이나 지방 지하철 의 경우 향후 편성 량수 가 늘어날 것 을 대비 하 여 , 운행 중 인 전동차 의 편성 량수 보다 승강장 길이 를 미리 더 길 게 건설 하 였 다 . 이미 지 어 진 역 에서 승강장 길이 를 늘리 는 것 은 상당 한 대공사 이 기 때문 이 다 . 예 를 들 어 9 호 선 은 현재 4 ~ 6 량 길이 로 운행 중 이 지만 , 승강장 길이 는 8 량 이 다 . 이 와 는 반대 로 승강장 보다 전동차 가 더 긴 경우 도 있 다 . 우리 나라 에서 는 거의 찾아볼 수 없 으나 철도 이용 률 이 높 은 일본 에 는 존재 한다 . 이 경우 에 는 승강장 에 접하 지 않 은 칸 은 문 을 열 지 않 는다 . 승객 은 다른 칸 으로 이동 하 여 내려야 한다 . 이 를 도어 컷 ( door cut ) 이 라고 부른다 . 전동차 의 정원 과 혼잡도 수송력 을 늘리 고 싶 으면 , 전동차 1 칸 의 바닥 면적 을 늘리 는 방법 도 있 다 . 입석 형 전동차 의 특성 상 바닥 면적 이 넓 을수록 더 많 은 사람 들 이 탈 수 있 다 . 실제로 우리 나라 의 중 전철 ( 重電 鐵 ) 전동차 는 대형 과 중형 두 가지 가 있 다 . 서울 지하철 에서 쓰 는 대형 은 길 이 19 . 5 m , 폭 3 . 12 m 이 며 , 지방 지하철 에서 쓰 는 중형 은 길 이 18 m , 폭 2 . 75 m 이 다 . 따라서 대형 전동차 에 사람 들 이 더 많이 탈 수 있 다 . 아울러 이 바닥 면적 에 따라 전동차 의 정원 이 정해진다 . 한편 승용차 나 일반 열차 의 객차 등 에서 말 하 는 정원 과 전동차 의 정원 ( 定員 ) 은 세 는 방식 이 다르 다 . 좌석 형 차량 은 좌석 수만 세어 정원 이 라고 한다 . 5 명 이 앉 을 자리 가 있 는 승용차 는 정원 이 5 명 이 고 , 의자 가 72 개 있 는 무궁화호 객차 는 정원 이 72 명 이 다 . 하지만 , 전동차 는 좌석 뿐 만 아니 라 입석 까지 포함 하 여 정원 이 라고 한다 . 여기 서 좌석 이용객 은 모두 앉 았 을 때 기준 이 지만 , 입석 이용객 숫자 는 전동차 내부 가 꽉 꽉 찬 것 도 아니 고 텅 빈 것 도 아닌 중간 상태 를 기준 으로 한다 . 예 를 들 어 대형 전동차 한 칸 의 정원 은 160 명 이 다 . 계산 방식 은 다음 과 같 다 . 승객 의 탑승 유형 이용 형태 에 따른 분류 분류 의 수 인원 산정 좌석 에 앉 은 사람 7 인석 좌석 6 개 42 명 3 인석 좌석 ( 노약 자석 ) 4 개 12 명 서 있 는 사람 각 좌석 앞 에 선 사람 - 54 명 전동차 중간 에 서 있 는 3 인 그룹 12 그룹 36 명 각 문 앞 에 서 있 는 2 명 문 8 개 16 명 합계 160 명 물론 노약 자석 대신 존재 하 는 휠체어 공간 에 따라 인원수 는 조금 달라질 수 있 다 . 특히 선두 차 는 기관사 운전실 에 승객 이 들어갈 수 없 는 관계 로 정원 은 148 명 이 된다 . 또한 지방 지하철 은 바닥 면적 이 좁 기 때문 에 정원 도 124 명 ( 중간 차 ) , 113 명 ( 선두 차 ) 로 줄어든다 . 현재 서울 지하철 에서 는 전동차 한 칸 의 정원 을 160 명 으로 보 고 , 이 160 명 에 대한 비율 을 혼잡도 라고 한다 . 만약 입석 승객 이 전혀 없이 좌석 만 가득 찬 경우 에 는 54 명 이 탄 것 이 고 , 이때 의 혼잡도 는 34 %( 54 / 160 ) 에 불과 하 게 된다 . 보통 혼잡도 150 % 가 되 도록 지하철 설비 를 준비 하 지만 , 출퇴근 시간 에 는 이 를 훌쩍 넘 는 게 보통 이 다 . 승객 이 빈틈없이 탄 경우 에 는 혼잡도 를 230 % 로 보 며 , 더 이상 탈 수 없 는 수준 이 다 . 160 명 정원 의 차량 에 368 명 이 타 고 있 는 상태 에 해당 된다 . 혼잡도 에 따른 전동차 객실 내 상황 을 정리 하 면 다음 과 같 다 . 수송력 - 운행 횟수 와 운전 시격 을 알 아야 한편 시간 당 수송력 을 계산 하 려면 시간 당 전동차 몇 대 가 운행 하 는지 를 알 아야 한다 . 아울러 이 횟수 는 전동차 의 운전 시격 과 역수 ( 逆數 ) 관계 에 있 다 . 열차 가 1 시간 에 10 대 운행 할 경우 , 1 시간 이 60 분 이 므로 6 분 간격 으로 운행 하 는 것 이 다 . 6 분 이 바로 운전 시격 이 다 . 보통 버스 에서 는 배차 간격 이 라고 도 하 는데 , 지하철 에서 는 운전 시격 이 라고 부른다 . 즉 시간 당 운행 횟수 를 구하 려면 60 을 분 단위 운전 시격 으로 나누 면 된다 . 1 시간 에 6 번 운행 할 때 에 비해 12 번 운행 하 면 당연히 수송력 은 두 배 가 된다 . 이렇게 시간 당 운행 횟수 는 수송력 과 비례 관계 에 있 다 . 반대 로 운전 시격 과 수송력 은 반비례 관계 에 있 다 . 시간 당 운행 횟수 나 운전 시격 모두 소수 가 나올 수 있 다 . 운전 시격 이 8 분 일 경우 시간 당 운행 횟수 는 7 . 5 회 가 되 며 , 시간 당 운행 횟수 가 18 회 라면 운전 시격 은 3 . 3 분 ( 3 분 20 초 ) 이 된다 . 운전 시격 을 평균 할 때 는 둘 을 더 해서 2 로 나누 는 산술 평균 ( 算術 平均 , arithmetic mean ) 이 아니 라 조화 평균 ( 調和 平均 , harmonic mean ) 을 해야 한다는 점 도 주의 할 점 이 다 . 어떤 노선 에 a 역 까지 가 는 열차 가 3 분 간격 으로 운행 되 고 b 역 까지 운행 하 는 열차 가 6 분 간격 으로 함께 운행 된다면 , 이 들 을 합친 평균 적 인 운전 시격 은 ( 3 + 6 ) / 2 = 4 . 5 분 이 아니 라 , ( 3 * 6 ) / ( 3 + 6 ) = 2 분 이 다 . 운행 횟수 로 보 면 3 분 간격 이 시간 당 20 회 , 6 분 간격 이 시간 당 10 회 운행 되 어 , 이 를 합치 면 30 회 운행 으로 시간 당 2 분 간격 이 되 는 것 이 다 . 수송력 을 늘리 고 싶 으면 운전 시격 을 줄이 면 된다 . 하지만 이것 이 쉬운 일 은 아니 다 . 지하철 이 쓰 는 쇠바퀴 는 고무바퀴 에 비해 마찰력 이 적 다 . 그러면 수 송시 에너지 절약 에 는 도움 이 되 지만 대신 제 동거리 가 길 어 진다 . 이 때문 에 열차 끼리 의 간격 을 줄이 는 데 는 한계 가 있 다 . 선로 는 신호 설비 에 따라 일정 간격 으로 나뉘 어 져 있 으며 이 를 폐색 구간 이 라고 한다 . 폐색 구간 길이 와 속도 제한 간격 이 촘촘 할 경우 열차간 간격 을 좁히 는데 도움 이 된다 . 서울 지하철 에서 는 2 호 선 등 에 신 형 신호 체계 를 도입 하 는 방식 으로 이 를 실현 시키 고 있 다 . 현재 서울 지하철 의 노선 별 운전 시격 은 다음 과 같 다 . 서울 시내 구간 기준 이 다 . rh 운전 시격 ( 분 ) 평시 운전 시격 ( 분 ) rh 운행 횟수 ( 회 / 시간 ) 평시 운행 횟수 ( 회 / 시간 ) rh 수송력 증강 비율 1 호 선 3 5 20 12 67 % 2 호 선 2 . 5 5 . 5 24 10 . 9 120 % 2 호 선 ( 성수 순환선 ) 7 10 8 . 6 6 43 % 2 호 선 신 정지선 10 10 6 6 0 % 3 호 선 3 6 . 5 20 9 . 2 117 % 4 호 선 2 . 5 5 . 5 24 10 . 9 120 % 5 호 선 2 . 5 6 24 10 140 % 6 호 선 3 . 5 7 17 . 1 8 . 6 100 % 7 호 선 2 . 5 6 24 10 140 % 8 호 선 4 . 5 8 13 . 3 7 . 5 78 % 출퇴근 시 와 평시 의 운행 횟수 차이 가 가장 큰 노선 은 5 호 선과 7 호 선 으로 무려 2 . 4 배 나 차이 가 난다 . 반면 신 정지선 은 출퇴근 시 와 평시 의 수송력 이 똑같 은데 , 이 는 이 구간 의 수요 가 적 은 편 이 고 신정 차량기지 에 들어가 거나 나오 는 차량 때문 에 , 신 정지선 의 영업 열차 운행 횟수 를 늘리 기 어렵 기 때문 이 다 . 수송력 을 구해 보 자 그러 면 서울 지하철 의 수송력 을 예시 를 들 어 실제로 계산 해 보 자 ( 질문 ) 평일 출근 시간 2 호 선 강남 구간 을 달리 는 잠실 방향 열차 의 평균 혼잡도 가 210 % 이 고 , 열차 의 운전 시격 이 2 . 5 분 이 라면 시간 당 방향 별 수송력 은 얼마 일까 ? ( 답 ) 우선 운전 시격 이 2 . 5 분 이 라면 1 시간 당 운행 횟수 는 60 / 2 . 5 = 24 회 가 된다 . 2 호 선 은 대형 전동차 를 사용 하 며 , 대형 전동차 1 량 의 정원 은 160 명 이 다 . 2 호 선 은 10 량 1 편성 전동차 를 사용 한다 . 따라서 수송력 은 다음 과 같이 계산 된다 . 수송력 = 편성 량수 × 전동차 1 량 의 정원 × 혼잡도 × 시간 당 운행 횟수 = 10 량 / 1 편성 × 160 명 / 량 × 210 % * 24 회 / 시간 = 80640 명 / 시간 / 방향 이렇 듯 지하철 은 1 시간 만 에 8 만 명 이상 을 실 어 나르 는 엄청난 수송력 을 갖 고 있 다 . 지하철 이 없 다면 이 들 승객 이 모두 지상 으로 나오 게 된다 . 그러면 버스 로 는 감당 이 안 되 고 늘어난 자가용 으로 도로는 마비 가 되 어 버리 고 말 것 이 다 . 지하철 계획 과 운영 의 핵심 - 수송력 한편 중요 한 점 은 수송력 이 같 은 상태 에서 수송력 을 구성 하 는 요소 들 을 조절 할 수 있 다는 점 이 다 . 예 를 들 어 편성 량수 를 늘리 면 그만큼 혼잡도 를 낮출 수 있 다 . 9 호 선 전동차 가 초기 4 량 에서 6 량 으로 늘리 는 것 이 바로 이런 이유 다 . 또한 시간 당 운행 횟수 가 절반 으로 줄이 는 대신 편성 량수 를 두 배 로 늘릴 수 있 다 . 8 량 1 편성 열차 가 6 분 간격 으로 운행 하 는 것 과 4 량 1 편성 열차 를 3 분 간격 으로 운행 하 는 것 은 수송력 이 같 다는 뜻 이 다 . 하지만 승객 입장 에서 는 운전 시격 이 줄여 열차 가 자주 오 는 게 좋 다 . 승강장 에서 열차 를 기다리 는 시간 이 줄어들 기 때문 이 다 . 반대 로 운영 사 입장 에서 는 열차 를 자주 운행 시키 면 그만큼 기관사 인건비 가 늘어나 기 때문 에 , 서로 간 에 절충 이 필요 하 다 . 이때 무인 운전 을 하 는 경전철 에서 는 기관사 인건비 가 들 지 않 으므로 승객 편의 를 위해서 작 은 차량 을 자주 운행 하 는 방식 을 쓰 고 있 다 . 경전철 의 편성 량수 가 2 량 정도 로 짧 은 이유 가 여기 에 있 다 . 이렇 듯 수송력 은 열차 운행 의 여러 요소 들 과 연관 을 맺 는 지하철 운영 의 주요 지표 다 . 지금 도 건설 과 운영 단계 에서 최적 의 수송력 배분 을 통해 서비스 수준 을 높이 고 경영 을 개선 하 려는 지하철 운영 사 의 노력 은 계속 되 고 있 다 . * 글 : 한우진 ( 서울 교통 공사 시민 안전 모니터 , 미래 철도 db 운영 자 , 교통 평론가 ) 참고 자료 1 . 노선 별 운전 시격 서울 교통 공사 홈페이지 ( [ URL ] 3 . 혼잡도 관련 사진 출처 및 참고 문헌 - 신성일 , “ 대중교통 카드 를 활용 한 도시 철도 혼잡도 지표 개발 연구 ” , p 10 , 서울 시정 개발 연구원 , 2011 - 김승준 , “ 서울시 지하철 혼잡 비용 산정 과 정책 활용 ” , p 42 , 서울 연구원 , 2014 4 . 중형 전동차 정원 수치 ( 124 명 , 113 명 ) 출처 [ URL ]',\n",
       "       '[ 조영철 기자 ] 죽 은 사람 의 살 아 있 는 기억 을 마주할 때 우주여행 시대 의 상실감 과 소외 [ 조영철 기자 ] ‘ 한국 은 sf 불모지 ’ 타령 은 이제 그만 생각 보다 젊 었 다 . 스물 다섯 살 이 다 . 앳된 얼굴 의 아가씨 가 한국 sf ( 공상 과학 소설 ) 의 부흥 을 기치 로 내건 한국 과학 문학상 중 단편 부문 대상 과 가작 을 동시 에 탔 다니 . 더 놀란 것 은 후천 적 청각 장애 인 이 라는 점 이 었 다 . 인터뷰 신청 을 위해 휴대 전화 로 전화 했 다 문자 메시지 로 답 을 받 으면서 알 게 된 사실 이 었 다 . “ 중학생 때 영어 듣 기 평가 를 준비 하 는데 잘 들리 지 않 아 병원 에 갔 더니 원인 불명 으로 청력 이 상실 됐 다고 그러 더라고요 . 그 후 고주파 소리 는 잘 들리 는데 저 주파 소리 는 들리 지 않 아 사람 의 음성 을 제대로 구별 할 수 없 게 됐 습니다 . 제 음성 도 잘 안 들려 말 이 살짝 어눌 하 게 들리 실 거 예요 . 그래도 상대방 입 모양 을 보 면 의사소통 에 큰 문제 는 없 습니다 . ” 멀쩡 하 던 청력 을 사춘기 소녀 시절 에 상실 했 다는 이야기 를 하 면서 구김살 없 는 웃음 을 짓 는다 . 내면 의 단단 함 이 느껴졌 다 . 탄탄 한 과학 적 상상 력 위 에 수 놓인 비애 의 감수 성 이 어디 서 왔 는지 어슴푸레 알 것 같 았 다 . 청각 장애 가 작품 세계 에 어떤 영향 을 미쳤 는지 물 었 다 . “ 글 을 쓸 때 소수자 의 관점 을 더 깊이 고민 하 고 생각 하 게 됐 습니다 . 제 가 여성 이 자 장애 인 으로서 겪 은 ‘ 소수자 로서 의 삶 ’, 대상 화 되 는 경험 이 있 었 기 때문 에 그런 점 들 을 조심 하 고 있 어요 . 작중 인물 들 이 고유 한 특성 으로 타자 화 , 대상 화 되 거나 평면 적 으로 묘사 되 지 않 도록 신경 쓰 고 있 습니다 . ” 그 는 올해 초 포항 공대 화학 전공 석사 과정 을 졸업 한 과학도 다 . ‘ 유전자 탐침 을 이용 한 바이오센서 ’ 를 만들 었 다고 했 다 . 특허 권 도 신청 할 예정 이 라니 흔한 석사 는 아닌 듯 했 다 . “ 우리 몸 에 병 이 생기 면 특정 단백질 의 농도 가 높 아 져요 . 혈액 에서 그 단백질 이 검출 되 면 어떤 병 에 걸렸 는지 를 알 수 있 어요 . dna 는 합성 이 가능 한데 해당 단백질 에 반응 하 는 dna 를 합성 하 면 그 단백질 탐침 이 가능 하 죠 . 저 는 황열 , 뎅기열 , 치 쿤 구니 야 같 은 열대 전염병 에 걸리 면 농도 가 짙 어 지 는 단백질 을 탐침 할 수 있 는 바이오센서 를 개발 했 습니다 . ” 얼핏 들으면 생물학 영역 같 은데 화학 전공 이 라니 . 양자 가 결합 한 하이브리드 영역 이 라고 했 다 . 실제 그 의 소설 을 읽 어 보 면 화학 뿐 아니 라 뇌 과학 과 우주 여행 , 생체 공학 에 대한 지식 이 잔뜩 등장 한다 . 평소 전공 서적 외 과학 서적 을 많이 탐독 한 결과 라고 했 다 . “ 어릴 때 부터 글쓰기 와 책 읽 기 를 좋아했 고 , 중학생 시절 우연히 과학 책 들 에 빠져 과학 을 전공 하 게 됐 습니다 . 화학 을 택한 건 제 가 실생활 의 화학 물질 과 약물 을 특히 좋 아 했 기 때문 인데 , 물론 다른 과학 분야 도 좋 아 했 어요 . 대학 에 들어가 서 도 틈틈이 과학 과 관련 된 글 을 썼 습니다 . 3 년 전 소설 습작 을 시작 하 면서 자연 스럽 게 과학 소설 을 쓰 게 됐 죠 . 세부 분야 는 다르 다 해도 전체 를 관통 하 는 과학 적 관점 과 사고 방식 이 있 다 보 니 , 그 경험 을 다른 분야 와 관련 된 글 을 쓸 때 도 유용 하 게 활용 하 고 있 습니다 . ” 대상 수 상작 ‘ 관내 분실 ’ 은 사람 뇌세포 속 기억 을 컴퓨터 에 저장 하 는 ‘ 마인드 업 로딩 ’ 이 가능 해진 시대 를 배경 으로 한다 . 기억 을 보관 하 는 도서관 에서 죽 은 엄마 의 기억 이 분실 된 사실 을 알 고 찾아나서 는 딸 의 이야기 다 . 소설 에선 죽 은 사람 의 기억 만 업 로딩 하 지만 ‘ 특이점 이 온다 ’ 의 저자 레이 커즈와일 은 2040 년 무렵 이 면 인간 의 기억 을 기계 에 업 로딩 하 는 일 이 가능 해질 것 이 라고 예측 한 바 있 다 . 가까운 사람 의 기억 이 데이터 로 보존 된다면 그걸 마주 하 는 당신 은 어떤 기분 이 들 까 . 그걸 영혼 이 라고 부를 수 있 을까 . “ 영혼 이 라는 것 은 일종 의 비유 와 같 은 개념 이 고 , 실제로 는 인간 의 뇌 가 작용 함 으로써 나타나 는 물질 적 현상 이 의식 이 자 정신 이 라고 생각 합니다 . 따라서 뇌 의 작용 과 현상 을 완벽 하 게 구현 하 는 데 성공 할 수 있 다면 그것 을 인간 의 정신 과 구분 할 수 없 다고 봐요 . 다만 뇌 를 제외 한 신체 도 인간 의 의식 에 크 게 영향 을 미치 기 때문 에 그런 부분 들 을 어떻게 보정 할 것 인가 에 따른 차이 는 있 을 듯 합니다 . 거기 까지 가 는 과정 이 결코 쉽 지 는 않 을 테 고 , 기술 적 이유 로 구현 에 실패 할 수 도 있 겠 죠 . 소설 속 기술 수준 은 실질 적 구현 으로 가 는 과도기 에 있 다고 생각 하 며 썼 습니다 . 과도기 라 오히려 받아들이 는 사람 들 이 더 혼란 스러워할 것 같 아요 . ” 소설 에서 딸 이 엄마 의 기억 을 찾 으려는 이유 는 자신 도 곧 엄마 가 되 기 때문 이 다 . 자신 을 낳 고 난 뒤 심한 우울증 으로 ‘ 자기 만 의 방 ’ 에 갇혀 살 다 쓸쓸히 죽 은 엄마 의 심리 를 알 기 위해 . 하지만 엄마 의 기억 이 도서관 내부 데이터 에서 분실 됐 다는 사실 이 밝혀 지 고 그것 을 되찾 고자 엄마 의 흔적 을 좇 던 딸 은 비로소 엄마 의 마음 을 이해 하 게 된다 . 마인드 업 로딩 이 가능 해진 미래 과학 기술 자체 보다 그것 에 직면 한 인간 의 심리 적 , 윤리 적 문제 를 짚 어 내 고 우아 하 게 풀어낸 점 이 돋보였 다 . 특히 ‘ 관내 분실 ’ 이 란 독특 한 개념 이 눈길 을 끌 었 다 . “ 예전 에 인터넷 에서 책 을 도서관 밖 보다 안 에서 분실 했 을 때 더 찾 기 어렵 다는 사서 분 의 글 을 인상 깊 게 읽 었 어요 . 그래서 그런 상황 을 일컫 는 개념 이나 용어 가 있 는지 검색 해 봤 는데 없 더라고요 . 그래서 메모 했 던 것 을 제목 으로 먼저 삼 고 그 에 걸맞 은 이야기 를 구성 해 본 건데 다 들 특이 한 상상력 이 라며 좋 아 하 시 더라고요 . ” 5 편 의 가작 가운데 하나 로 뽑힌 ‘ 우리 가 빛 의 속도 로 갈 수 없 다면 ’ 은 sf 에서 익숙 하 게 봤 던 우주여행 기술 이 등장 한다 . 우주선 을 둘러싼 공간 을 4 차원 으로 일 그러 뜨려 거리 를 단축 하 는 워프 항법 , 오랜 여행 시간 을 견디 게 해 주 는 냉동 수면 기술 딥 프리징 , 우주 공간 과 공간 을 연결 하 는 ‘ 고 차원 의 벌레 구멍 ’ 을 통한 웜홀 항 해 . 소설 은 워프 항법 으로 다른 행성 으로 이 주한 가족 과 떨어져 사 는 여성 과학자 안 나 의 이야기 를 다룬다 . 안 나가 가족 과 만나 려고 10 여 년 에 걸쳐 개발 에 매달린 딥 프리징 기술 을 완성 할 무렵 웜홀 이 발견 되 면서 가족 이 있 는 행성 으로 가 는 워프 항로 가 끊기 는 바람 에 이산가족 이 된다 . 그러 자 항로 가 다시 열리 길 기다리 며 자신 이 개발 한 딥 프리징 기술 로 냉동 됐 다 깨어나 길 반복 하 는 슬픈 이야기 다 . 워프 항법 과 웜홀 항해 , 딥 프리징 기술 이 등장 하 는 sf 는 많이 봤 지만 이 들 기술 의 경쟁 관계 에 주목 한 점 이 독특 했 다 . “ 대학원 석사 과정 에서 연구 를 하 면서 많 은 논문 을 읽 었 는데요 . 저 는 센서 를 이용 한 질병 진단 이 라는 확고 하 게 실용 적 인 목적 을 가진 연구 를 하 다 보 니 , 논문 들 이 단지 결과 만 강조 하 는 것 이 아니 라 비용 , 진단 시간 , 보관 기한 등 을 비중 있 게 언급 하 고 있 는 것 에 눈길 이 갔 어요 . 정작 제 가 연구 하 면서 가장 재미있 고 관심 갔 던 부분 과 는 다른 것 들 이 었 죠 . 현대 과학 연구 라는 건 결국 실용 성 과 활용 가능 성 을 끊임없이 증명 해야 하 는구나 하 는 생각 이 들 었 어요 . 그런 생각 들 이 소설 로 직접 연결 됐 다기 보다 , 안 나 의 연구 가 주목 받 고 또 관심 에서 멀 어 지 는 과정 을 쓰 면서 반영 됐 던 것 같 아요 . ” 지난해 연말 수상자 발표 가 났 고 수상 작품집 이 나온 게 3 월 인데 그 는 2 편 의 작품 을 새로 발표 했 다 . 과학 잡지 ‘ 에 피 ’ 에 발표 한 ‘ 원통 안 의 소녀 ’ 와 kaist ( 한국과학기술원 ) 에서 발행 하 는 잡지 에 발표 한 ‘ 감정 의 물성 ’ 이 다 . 전자 는 ‘ 에 어본 ’ 이 라는 나노 봇 을 통해 공기 를 정화 하 는 미래 도시 에서 그것 에 대한 알레르기 로 나노 봇 과 차단 된 원통 안 에서 살아가 는 소녀 의 이야기 다 . 후자 는 인간 의 다양 한 감정 이 농축 된 제품 이 등장 한 미래 사회 에서 기쁨 이나 즐거움 같 은 긍정 적 감정 뿐 아니 라 슬픔 , 분노 같 은 부정 적 감정 을 물성 화 한 제품 이 팔리 는 현상 을 다뤘 다 . 4 편 의 과학 적 소재 가 모두 기발 하 다는 생각 이 들 었 다 . 그러 면서 도 과학 기술 자체 보다 그것 이 초래 할 윤리 적 문제 나 인간 소외 에 초점 을 맞췄 다는 공통점 이 있 었 다 . 그 의 sf 에 대해 우아 하 다거나 섬세 하 다는 표현 을 쓰 는 이유 가 거기 있 다 . 그 가 좋 아 하 는 sf 작가 가 누구 인지 궁금 해졌 다 . “ 옥타비아 버틀러 ( 1947 ~ 2006 · ‘ 킨 ’ ‘ 야생종 ’ ‘ 블러드 차일드 ’ 가 대표작 ) 와 김보영 작가 입니다 . sf 하 면 백인 남성 작가 를 많이 떠올리 는데 버틀러 는 최초 흑인 여성 sf 작가 로 흑인 과 여성 이 라는 소수자 시점 에서 sf 의 지평 을 넓혔 다는 찬사 를 받 았 습니다 . 자신 의 관점 과 정체 성 을 소설 에 적극 적 으로 녹여 내 면서 , 동시 에 ‘ 양가 적 감정 ’, 나쁘 다 좋 다 로 구분 할 수 없 는 복잡 한 심리 를 잘 그려 내 늘 감탄 하 면서 읽 게 됩니다 . 김보영 작가 는 고등학생 때 단편집 인 ‘ 멀리 가 는 이야기 ’ 와 ‘ 진화 신화 ’ 를 처음 읽 고 한국 sf 에 애정 을 갖 게 되 는 계기 를 만들 어 주 신 분 입니다 . 두 분 의 작품 처럼 세계 를 바라보 는 시선 이 냉철 하 면서 도 따뜻 한 여운 이 남 는 작품 을 좋 아 합니다 . ” 김보영 작가 는 한국 과학 문학상 심사 위원 으로서 김 작가 에 대해 “ 문장 과 구성 , 아이디어 , 장르 적 이해 , 과학 적 정밀 함 모두 탁월 하 다 ” 며 “ 신인 이 라 믿 기 어려운 필력 ” 이 라는 찬사 를 보냈 다 . 김 초엽 작가 는 “ 그분 이 계셔서 한국 sf 계 가 정말 다행 이 라고 생각 했 던 분 의 찬 사라 몸 둘 바 를 모를 만큼 기뻤 다 ” 고 했 다 . 김보영 작가 는 출판 전문 격주 간지 ‘ 기획회의 ’ 에 발표 한 ‘ sf 작가 로 산다는 것 ’ 이 라는 기고 문 을 통해 sf 같 은 장르 소설 을 천 대 시 하 는 한국 문학계 를 비판 했 다 . 수십 개 넘 는 문예지 가운데 sf 를 실 어 주 는 곳 이 없 고 , 150 개 넘 는 문학상 중 에서 sf 작품 을 뽑 는 데 가 없 으며 , 전국 25 개 일간지 에 sf 부문 신춘문예 가 하나 도 없 다면서 . 해외 sf 작가 는 우러러 보 면서 몇 십 년 째 ‘ 한국 은 sf 불모지 ’ 라는 말 만 반복 한다는 것 이 다 . “ 신인 작가 이 다 보 니 정확히 문제점 을 짚 어 말씀 드리 기 좀 어렵 네요 . 다만 제 가 이번 공모전 당선 이전 과 이후 에 작품 을 실 은 지면 은 모두 과학 분야 에서 제공 한 것 이 었 습니다 . 제 가 단지 소설 습작 을 하 는 걸 넘 어 ‘ sf 를 써 봐야 겠 다 ’ 고 생각 했 던 것 도 2016 년 한국 과학 문학상 공모전 이 열렸 던 것 을 본 이후 입니다 . 한국 에선 장르 적 이 라는 수식어 가 작품 성 이 좋 지 않 다는 것 과 같 다고 생각 하 는 경향 이 있 는 듯 합니다 . 주류 문학 에선 사실주의 를 강조 하 는데 우리 시대 에 과학 을 떼 놓 고 현실 이 성립 할 수 있 다고 생각 하 는지 묻 고 싶 습니다 . “ 한국 sf 작가 들 은 이런 현실 을 바꾸 고자 한 목소리 를 내 기 시작 했 다 . 지난 연말 ‘ 한국 과학 소설 작가 연대 ’ 가 출범 했 다 . 김 작가 가 운영 이사 를 맡 은 이 단체 에 참여 한 sf 프로 작가 는 41 명 인데 그중 여성 이 남성 보다 많 다고 했 다 . “ sf 가 미래 를 다루 는 작품 이 다 보 니 상대 적 으로 진보 적 인 내용 이 많 아서 그렇 지 않 나 하 는 생각 을 조심 스럽 게 해 봤 습니다 . 디스토피아 를 다룬 작품 도 세상 이 그렇게 되 선 안 된다는 강렬 한 저항 의식 의 산물 이 라고 봐야 합니다 . sf 를 남성 중심 의 장르 라 생각 하 는 주류 문단 의 인식 은 그런 의미 에서 도 잘못 됐 습니다 . ” 김 작가 는 올해 초 부터 국가 지식 재산 위원회 위원 으로 활동 하 고 있 다 . 이 위원회 는 문화 예술 분야 의 저작 권 과 과학 기술 분야 의 특허 권 관련 국가 전략 을 수립 하 고 정부 정책 을 조율 하 는 일 을 하 는데 , 민간 위원 18 명 가운데 1 명 이 김 작가 다 . 그만큼 과학 과 예술 두 분야 에서 전문 성 을 두루 인정받 은 셈 이 다 . 과학 과 예술 의 공통점 과 차이점 에 대한 그 의 생각 이 궁금 했 다 . “ 제 아버지 는 음악 가 세요 . 오카리나 와 드럼 연주 도 하 고 무대 공연 의 음악 감독 을 하 기 도 합니다 . 아버지 와 이야기 하 다 얻 은 결론 은 과학 과 예술 은 모두 세상 에 없 던 것 을 찾아내 는 분야 라는 점 입니다 . 과학 이 예전 에 모르 던 것 을 새로 알아내 거나 세상 에 없 던 것 을 새로 만들 어 내 듯이 예술 역시 기존 에 없 던 것 을 창조 하 고자 혼신 의 노력 을 다 하 잖아요 . 그런 점 에서 작 은 차이 는 크 게 중요 하 지 않 다고 생각 합니다 . ” sf 대중 화 는 영화 나 드라마 제작 과 밀접 한 관련 성 을 갖 는다 . 요즘 할리우드 대작 영화 의 상당수 는 sf 작품 이 다 . 반면 국내 sf 를 극화 하 는 경우 는 드물 다 . sf 불모지 라는 환경 탓 일까 , 아니면 좋 은 sf 작품 이 없 어서 일까 . “ 아마 해외 와 는 다르 게 영화 에 들어가 는 자본 의 차이 , 그리고 문학 계 와 비슷 하 게 현실 기반 의 이야기 를 주로 만드 는 영화 계 의 분위기 때문 이 지 않 을까 싶 은데요 . 한국 관객 에게 널리 사랑 받 았 던 ‘ 인터 스텔라 ’ 나 ‘ 마션 ’ 같 은 영화 는 어마어마 한 투자 가 들어간 작품 이 니 설령 원작 이 있 어도 영화 화 가 힘들 테 고요 . ‘ 지금 이곳 과 는 다른 세계 ’ 를 구현 하 는 데 힘 을 쏟 는 sf 의 특성 상 그동안 은 여러 현실 적 문제 가 있 었 던 게 아닐까 생각 합니다 . ” 그런 상황 에서 ‘ 관내 분실 ’ 의 영화 화 에 관심 을 보이 는 제작사 가 나왔 다는 말 이 들려왔 다 . sf 팬 들 에겐 반가운 소식 이 아닐 수 없 다 . 영화 화 가 결정 되 면 시나리오 작업 에 도 참여 할까 . 추후 작품 으로 어떤 작품 을 구상 중 인지 도 궁금 했 다 . “ 영화 화 가 된다면 러닝 타임 에 맞 게 내용 이 추가 되 고 각색 이 들어가 겠 지만 , 제 가 직접 참여 하 지 는 않 고 제작 하 는 분 들 의 판단 에 맡길 것 같 습니다 . 앞 으로 장편 소설 을 준비 하 면서 틈틈이 단편 을 쓰 려고 해요 . 장편 소설 은 2 편 정도 구상 단계 에 있 습니다 . 하나 는 근 미래 한국 사회 를 배경 으로 감정 을 다루 는 기술 의 도입 을 둘러싸 고 벌어지 는 사회 적 갈등 을 다룹니다 . 다른 하나 는 아주 먼 미래 , 먼 우주 를 배경 으로 인류 의 아종 이 더 복잡 하 게 분기 한 가운데 아종 들 끼리 의 이해 와 공존 을 다뤄 볼까 합니다 . ” 마지막 으로 제 2 의 김 초엽 작가 를 꿈꾸 는 sf 작가 지망 생 들 에게 들려주 고 싶 은 이야기 가 있 느냐고 물 었 다 . 수줍 게 웃 으며 “ 아 , 이건 어려운 질문 이 데요 ” 라고 한참 뜸 을 들이 던 그 는 글쓰기 에 재능 이 없 다는 생각 에 작가 의 꿈 을 포기 했었 다는 이야기 를 들려 줬 다 . “ 제 가 소설 쓰 기 에 도전 한 것 이 3 년 전이 라 말씀 드렸 는데 크 게 2 가지 가 도움 을 줬 습니다 . 글쓰기 에 관심 있 는 주변 사람 들 과 글쓰기 워크숍 을 하 면서 서로 의 글 에 대해 품평 을 나눈 것 입니다 . 그 와중 에 작 법서 를 새로 읽 었 는데 제 가 어릴 적 읽 었 던 작 법서 와 달리 요즘 은 실제 적 도움 을 주 는 내용 이 많 더라고요 . 그것 을 통해 재능 이 없 더라도 열심히 하 면 걸작 은 아니 어도 남 들 이 읽 어 줄 만 한 글 을 쓸 수 있 겠 다는 자신감 을 얻 었 습니다 . 특히 sf 는 글재주 보다 아이디어 로 승부 를 걸 수 있 는 장르 라는 점 에서 많 은 분 의 도전 이 이어졌 으면 좋 겠 습니다 . ”',\n",
       "       'nas 에 있 는 영화 는 어떻 게 tv 로 재생 을 하 시 는지 궁금 합니다 .',\n",
       "       '구글 이 딥 러닝 강의 를 무료 로 공개 했 다 . 강의 는 유다 시티 에서 볼 수 있 다 . 유다 시티 는 온라인 공개 강좌 ( massive open online course , mooc ) 서비스 다 . 주로 실무 교육 프로그램 을 제공 하 는 데 집중 하 고 있 다 . 이번 에 공개 한 딥 러닝 강의 는 ‘ 머신 러닝 ‘ 강의 전 에 듣 는 일종 의 예습 자료 다 . 수업 은 빈센트 반 호크 구글 수석 과학자 가 직접 진행 한다 . 빈센트 반 호크 수석 과학자 는 현재 구글 딥 러닝 인프라스트럭처 팀 을 이끌 고 있 는 매니저 이 기 도 하 다 . 구글 의 딥 러닝 강의 는 크 게 4 가지 로 나뉜다 . 먼저 머신 러닝 과 딥 러닝 의 개념 을 배우 고 기본 용어 를 알려준다 . 그 다음 딥 뉴 럴 네트워크 와 cnn ( convolutional neural networks , 나선 형 신경망 ) 을 각각 배울 수 있 다 . 모델링 에 대한 단원 도 있 다 . 각 단원 에선 10 - 30 개 정도 의 유튜브 강의 를 보여준다 . 강의 분량 은 1 - 3 분 정도 로 짧 다 . 개념 을 잘 이해 했 는지 확인 하 기 위해 퀴즈 도 제공 한다 . 유다 시티 는 딥 러닝 강의 를 듣 고 이해 하 기 위해 일 주일 에 평균 6 시간 씩 필요 하 며 , 약 3 개월 간 의 시간 이 걸릴 것 이 라고 설명 했 다 . 강의 는 모두 영어 로 진행 되 며 자막 은 따로 제공 되 지 않 는다 . 만약 구글 의 머신 러닝 기술 ‘ 텐서 플로우 ’ 에 관심 있 는 사용 자 라면 이번 강의 를 들어도 좋 다 . 강의 속 에 나오 는 예제 나 과제 대부분 이 텐서 플로우 로 진행 되 기 때문 이 다 . 딥 러닝 강의 홈페이지 에서 ‘ 소프트웨어 와 툴 ’ 에 접속 하 면 강의 용 텐서 플로우 예제 파일 을 받 을 수 있 다 . 딥 러닝 강의 는 유다 시티 계정 만 있 으면 바로 접속 할 수 있 다 . 하지만 제대로 이해 하 기 위해서 는 미리 알 아야 하 는 개념 과 기술 이 있 다 . 먼저 이 강의 는 최소 2 년 이상 프로그래밍 경력 이 있 는 사람 에게 적합 하 다 . 파이썬 언어 에 익숙 한 개발자 라면 더 쉽 게 이해 할 수 있 다 . 깃 과 깃 허브 사용법 을 알 아야 한다 . 숙제 자료 를 깃 허브 에서 받 아야 하 기 때문 이 다 . 기본 적 인 머신 러닝 개념 , 특히 ‘ 지도 학습 ( supervised learning ) ’ 에 대해서 는 미리 알 고 들으면 좋 다 . 이 외 에 도 통계 , 선형 대수학 , 미적분 에 대한 지식 도 알 고 있 어야 한다 . 유다 시티 는 유료 강의 프로그램 ‘ 나 노디 그리 ’ 에 대한 관심 을 끌 기 위해 무료 강의 를 내놓 고 있 다 . 현재 머신 러닝 나노 디 그리 과정 을 들으려면 한 달 에 199 달러 , 우리 돈 약 23 만 원 을 내 야 하 며 , 6 개월 에서 1 년 정도 시간 을 투자 해야 강의 를 완주 할 수 있 다 . 무료 강의 는 짧 으면 1 주일 , 길 게 는 3 달 분량 으로 제공 된다 . 조지 아 공과 대학교 도 유다 시티 를 통해 인공지능 강의 를 무료 로 올린 바 있 다 .',\n",
       "       '데이터 분석 을 잘 하 기 위한 방법론 중 에서 드류 콘웨이 ( drew conway ) 의 데이터 과학 벤 다이어 그램 ( the data science venn diagram ) 을 가장 많이 인용 한다 . 데이터 과학 ( data science ) 이 라는 용어 가 적절 한지 에 대해서 는 이견 이 많 지만 , 아래 그림 이 좋 은 분석 결과물 을 만들 기 위한 좋 은 접근 방법 이 라는 데 동의 한다 . < 그림 출처 : the culture of big data > 통계학 을 전공 한 입장 에서 위 의 3 가지 영역 중 가장 어려움 을 느낀 부분 은 hacking skills , 즉 개발 이 다 . 개발 지식 의 필요 성 을 깨닫 고 나서 는 해당 영역 을 잘 알 기 위해서 노력 하 였 고 , 여전히 그 과정 에 있 다 . 왜 개발 이 필요 한가 ? 데이터 분석 을 하 면서 가장 좌절감 이 들 때 는 분석 결과 가 보고서 에서 끝나 고 세상 에 아무런 변화 나 영향 을 주 지 못할 때 다 . 분석 보고서 를 쓰 고 실무자 들 과 회의 를 하 면 , 매우 전형 적 인 반응 은 “ 아주 흥미 롭 네요 ” , “ 재미있 게 잘 봤 습니다 ” , “ 분석 결과 가 매우 인상 적 입니다 ” 가 대부분 이 다 . 이후 추가 적 인 실행 은 없 고 , 세상 은 전혀 바뀌 지 않 는다 . 수 많 은 재미 있 고 인상 적 인 분석 보고서 는 회의실 책상 위 에서 지적 여흥 에 그치 고 만 다 . 실행 이 빠진 데이터 분석 에서 탈피 하 기 위해서 는 실행자 를 설득 하 는 것 이 가장 좋 은 방법 이 다 . “ 안 된다 ” , “ 못 한다 ” 라는 개발 실무 부서 의 대답 을 극복 하 기 위해서 는 최소한 그 들 과 이야기 가 통해야 한다 . 안 되 면 왜 안 되 는지 , 못 하 면 왜 못 하 는지 물 어 보 고 함께 해결 방안 을 찾 을 수 있 어야 한다 . 분석 을 기획 한 입장 에서 개발 지식 을 약간 이 라도 알 고 있 으면 해결 방안 을 찾 는데 큰 도움 이 된다 . “ 나 는 분석 을 담당 하 였으니 구현 은 너희 가 알 아서 해라 ” 는 태도 로 는 아무것 도 바뀌 지 않 는다 . 개발 조직 을 움직이 기 어렵 다면 직접 실행 할 수 도 있 다 . 분석 결과 가 세상 에 영향 을 미치 도록 구현 하 는 작업 은 생각 보다 재미있 다 . 직접 무언가 만들 어서 의도 대로 작동 하 고 결과 를 확인 하 는 즐거움 이 크 다 . 과정 의 재미 도 있 지만 , 무엇 보다 통계학 보다 시작 이 쉽 다 . 단언 하 건대 , 개발 공부 를 시작 하 는 것 이 ‘ 통계학 입문 ’ 을 다시 수강 하 는 것 보다 쉽 다 . 결국 , 실행력 을 확보 하 기 위해서 개발 공부 가 필요 하 다 . 어떻게 시작 할까 ? 대학교 에서 개발 을 어떻게 가르치 는지 살펴보 니 , 모두 cs 101 과목 에서 시작 한다 . cs 101 은 대부분 하나 의 프로그래밍 언어 를 정해서 핵심 적 인 문법 과 이 를 통한 문제 해결 과정 을 가르친다 . 한마디 로 좋 은 언어 를 기본 적 인 수준 에서 공부 하 는 것 으로 개발 공부 를 시작 한다 . 이 과정 을 통해서 컴퓨터 로 할 수 있 는 일 이 무엇 이 고 , 이 를 어떻게 코드 로 표현 하 고 생각 해야 하 는지 공부 한다 . 우선 이 과정 을 따르 자 . 첫 번 째 언어 는 ? 첫 번 째 언어 로 어떤 것 이 좋 은지 다른 주장 들 이 많 은데 , 파이썬 ( python ) 을 추천 한다 . 파이썬 은 데이터 분석 을 하 기 에 부족 함 이 없 는 패키지 들 을 쓸 수 있 고 , 범용 성 이 좋 아 분석 이외 의 일반 적 인 개발 에 도 유용 하 다 . 특유 의 간결 한 문법 을 장점 으로 꼽 는 사람 도 많 다 . 데이터 분석 을 위해서 r 을 많이 공부 하 지만 , 개발 공부 를 시작 하 기 에 적합 한 언어 는 아니 다 . 참고 : python as a first language 프로그래밍 10 년 하 기 ( teach yourself programming in ten years ) 라는 글 에서 언어 선택 에 대해 3 가지 조언 을 하 는데 아래 와 같 다 . 옆 에 있 는 친구 가 쓰 는 걸 써라 . 간단 한 언어 를 선택 해라 . ( c ++, java 는 너무 복잡 하 다 ) 인터랙티브 모드 를 사용 하 는 것 이 좋 다 . 그러므로 파이썬 을 선택 한다 . 무슨 책 을 볼까 ? 프로그래밍 에 많 은 경험 이 없 고 , 특히 파이썬 을 잘 모른다면 cs 101 교재 수준 의 책 을 사 서 보 는 것 이 좋 다 . 통계학 전공 자 의 경우 에 는 r 을 조금 안다고 어려운 개발 교재 부터 시작 하 면 중도 에 포기 할 가능 성 이 높 다 . 다 내려 놓 고 기초 부터 보 자 . 아래 의 몇 권 을 추천 한다 . 이외 에 도 좋 은 입문서 가 많 다 . 그러나 반드시 “ 파이썬 하루 에 마스터 하 기 ” 류 는 피한다 . 어차피 다른 책 을 또 봐야 하 기 때문 에 시간 낭비 다 . ide 는 무엇 을 쓸까 ? ide 란 프로그래밍 을 편하 게 할 수 있 도록 도와 주 는 소프트웨어 다 . 초심자 가 처음 부터 복잡 한 ide 를 쓰 면 많 은 기능 에 질릴 수 있 다 . 하지만 좋 은 도구 를 잘 골라서 익숙 해 지 면 앞 으로 범할 시행착오 를 많이 줄일 수 있 다 . 추천 하 는 ide 는 pycharm edu 버전 이 다 . 교육 용 으로 나와서 예제 를 따라 하 기 좋 고 , 초심자 가 쓰 기 에 부담 없 다 . 너무 간략 한 기능 이 싫 다면 pycharm community 버전 을 사용 한다 . ide 선택 은 개인 의 취향 에 따라 다르 므로 좋 아 하 는 방식 이 있 다면 마음대로 정해 도 좋 다 . 공부 를 계속 하 다 보 면 더 좋 은 환경 을 접할 기회 가 많 아 지 고 스스로 자신 에게 맞 는 개발 환경 을 꾸미 게 된다 . 초보 탈출 다음 에 는 ? 위 에서 소개 한 책 이나 교육 과정 을 잘 따라 공부 한다면 기본 적 인 프로그래밍 이 가능 해진다 . 아마도 무언가 를 만들 어 보 고 싶 다는 생각 이 들 고 , 공부 를 시작 하 기 전 에 는 궁금 하 지 않 았 던 것 들 이 생겼 을 것 이 다 . 무엇 을 만들 어 볼까 ? 데이터 분석 을 위해서 개발 공부 를 시작 했 다면 , 파이썬 으로 데이터 분석 을 시작 해 보 는 것 이 좋 다 . r 도 있 는데 굳이 파이썬 으로 분석 을 할 필요 가 있 을지 의문 이 들 지만 , 나중 에 실행 단계 를 위해서 는 파이썬 으로 데이터 를 다루 는 경험 을 해 보 는 것 이 좋 다 . 우선 데이터 를 다루 는 방법 에 대해서 는 아래 책 들 을 참 고 한다 . 실제 분석 예시 를 그대로 따라 하 는 것 도 많 은 도움 이 된다 . 캐 글 ( kaggle ) 의 ‘ getting started with python : kaggle ’ s titanic competition ’ 을 참고 할 수 있 다 . 타이타닉 문제 로 여러 개 의 튜토리얼 글 이 있 으므로 언어 와 분석 방법론 을 서로 비교 해 보 는 것 도 유용 하 다 . 캐 글 의 deep learning tutorial 도 재미있 는데 , aws 를 활용 하 는 방법 이 간략 하 게 소개 되 어 있 다 . 주된 방법 은 ‘ using convolutional neural nets to detect facial keypoints tutorial ’ 링크 로 대체 되 어 있 는데 , 따라 하 면 되 긴 된다 . 튜토리얼 을 따라 할 때 경계 할 점 은 분석 방법론 을 제대로 이해 하 지 못하 고 그냥 코드 만 복사 하 는 일 이 다 . 알고리즘 을 제대로 이해 하 지 못하 고 따라 하 는 튜토리얼 은 나중 에 도움 이 되 지 않 는다 . 튜토리얼 과 유사 한 자신 만 의 문제 를 찾 아 대입 해 보 면서 고민 하 는 과정 이 꼭 필요 하 다 . 프로그래머 의 위기 지학 김창준 ( @ cjunekim ) 님의 ‘ 프로그래머 의 위기 지학 ’ 이 라는 글 을 보 면 프로그래머 가 무엇 을 만들 어야 하 는지 에 대한 좋 은 대답 을 얻 을 수 있 다 . 실생활 에서 느낀 불편 함 을 그냥 지나치 지 않 고 , 아 는 기술 로 이 를 개선 할 수 있 는지 고민 해본다 . 거창 한 패키지 나 어플리케이션 을 만들 지 않 더라도 소소 한 개발 로 도움 이 되 는 무언가 를 만들 수 있 다 . 데이터 분석 도 마찬가지 인데 , 처음 부터 세상 이 깜짝 놀랄 통찰 을 발견 하 지 않 아도 된다 . 평소 에 느끼 던 사소 한 궁금증 을 그냥 넘기 지 않 고 데이터 로 확인 하 려는 시도 를 하 는 것 이 좋 은 시작 이 다 . 뻔한 결과 를 얻 었 더라도 , 데이터 로 그 뻔 함 을 드러냈 으니 그것 만 으로 도 족하 다 . 좋 은 질문 없이 , 시류 에 따라 흉내내 기 만 반복 하 는 것 보다 는 실생활 의 사소 함 에서 시작 하 는 분석 이 공부 에 더 도움 이 된다 . 파이썬 을 더 잘 하 고 싶 다면 ? 더 많 은 경험 을 하 다 보 면 얼마나 모르 는 게 많 은지 깨닫 게 된다 . 이제 입문서 가 아니 라 더 깊 은 내용 을 담 은 책 을 공부 할 필요 가 있 다 . learning python . 기존 에 알 던 것 을 복습 하 고 , 아주 자세 한 부분 을 공부 하 기 에 적합 하 다 . 입문서 에서 빠르 게 넘어가 는 부분 을 잘 설명 하 고 있 기 때문 에 기존 에 궁금 하 던 부분 이 많이 해소 된다 . 1600 페이지 나 되 기 때문 에 종이 책 을 사 는 것 은 말리 고 싶 다 . 킨들 ( kindle ) 에디션 을 사 거나 oreilly 에서 pdf 버전 을 사 는 게 낫 다 . 같 은 저자 가 비슷 한 분량 으로 programming python 이 라는 후 속편 을 썼 다 . fluent python . 많이 어렵 다 . 초심자 입장 에서 처음 보 는 개념 들 이 많이 나오 는데 천천히 공부 하 면 재미있 다 . 옆 에서 물 어 보 고 알려 줄 수 있 는 개발자 가 있 을 때 공부 하 길 추천 한다 . 저자 가 브라질 사람 이 라서 그런지 인코딩 관련 설명 이 매우 상세 하 다 . 비동기 처리 에 대한 부분 이 특히 흥미 로운데 , asyncio 에 대해서 비교 적 상세 하 게 설명 한다 . 그 외 에 도 파이썬 을 넘어선 많 은 주제 들 이 나온다 . 추가 로 공부 할 좋 은 책 들 을 많이 소개 하 고 있 다 . effective python : 59 specific ways to write better python . 아주 실용 적 이 다 . 바로 써먹 을 수 있 는 예제 들 로 구성 되 어 있 다 . 잘 구분 하 지 못했 던 개념 에 대해서 잘 설명 하 고 있 다 . 실질 적 인 문제 를 예시 로 많이 들 기 때문 에 이해 하 기 편하 다 . 예상 보다 쉽 다 . 프로그래밍 언어 외 에 공부 할 것 은 ? 파이썬 을 이 정도 로 공부 하 다 보 면 , 파이썬 이 문제 가 아니 라는 것 을 깨닫 는다 . 프로그래밍 언어 하나 로 는 다 설명 할 수 없 다는 것 을 알 게 된다 . 추가 로 알 아야 할 것 이 참 많 다 . 영어 당연 하 지만 굳이 영어 를 언급 하 는 이유 는 번역본 읽 기 를 포기 했 기 때문 이 다 . 세상 어딘가 에서 누군가 가치 있 는 생각 을 해냈 다면 , 그 사람 은 모국어 가 무엇 이 든 상관없이 가장 먼저 영어 로 그 생각 을 적 어서 퍼트린 다 . 이런 생각 들 이 책 으로 정리 되 려면 한참 의 시간 이 걸리 고 , 그것 들 이 다시 번역 되 는 시간 은 더 길 다 . 게다가 운 이 나쁘 면 절대로 번역 되 지 않 는 책 도 있 다 . 수 많 은 웹 문서 는 언급 할 필요 도 없 다 . 번역 의 품질 도 문제 인데 , 꽤 많 은 기술 서 는 번역본 이 더 어렵 다 . 번 역서 가 없 을 때 만 원서 를 보 는 것 이 좋 은 전략 같 지만 , 그 번거 로움 을 생각 하 면 번 역서 를 아예 고려 하 지 않 는 것 이 효율 적 이 다 . 번 역서 가 있 는지 없 는지 확인 하 고 , 번역 품질 이 괜찮 은지 알아보 고 나 서 책 을 읽 는 데 는 꽤 많 은 노력 이 들어간다 . 게다가 번역 서 읽 기 를 포기 하 면 반대 로 원서 독해 시간 이 짧아진다 . 처음 에 는 익숙 해 지 는데 시간 이 걸리 지만 , 약간 의 시간 이 흐르 면 매우 수월 해진다 . 게다가 기술 서 는 문장 구조 나 어휘 가 아주 쉽 다 . 좋 은 개발자 가 되 려면 영어 로 된 기술 서 를 빨리 읽 는 능력 이 필요 하 다 . git 요즘 은 데이터 분석가 들 도 깃 ( git ) 을 쓴다 . 심지어 대부분 의 r 패키지 들 도 깃 헙 ( github ) 을 통해 공유 된다 . 학교 숙제 도 깃 헙 으로 공유 하 고 제출 한다 . 수 많 은 오픈 소스 프로젝트 도 깃 을 통해 만들 어 지 고 , 배포 된다 . 꼭 알 아야 한다 . 모르 면 할 수 있 는 것 이 갈수록 적어진다 . 깃 이 뭐 하 는 건지 일단 try git 으로 연습 한다 . 깃 헙은 가이드 에서 기본 개념 을 익힌다 . 뭔지 알 게 되 었 다면 , pro git 을 읽 어 본다 . 그리고 모든 코드 는 깃 으로 관리 한다 . 리눅스 특별 한 경우 를 제외 하 면 , 대부분 의 개발 은 리눅스 ( linux ) 환경 이 편하 다 . 많 은 개발자 들 이 맥 을 쓰 는 이유 는 맥 os 가 리눅스 와 상당 부분 유사 하 기 때문 이 다 . 개발 을 하 면서 사용 할 많 은 도구 들 은 대부분 리눅스 환경 하 에서 먼저 만들 어 진다 . 또 리눅스 에 는 도구 가 풍부 하 다 . 리눅스 를 깊이 있 게 이해 하 지 못하 더라도 command line interface 에 익숙 해질 필요 가 있 다 . 아래 책 을 추천 한다 . the linux command line : a complete introduction . 리눅스 에 대한 깊이 있 는 이해 보다 는 어떻게 하 면 잘 써먹 을지 에 대해서 설명 한다 . 당장 복잡 한 거 공부 하 지 않 고 cli 환경 에 익숙 해 지 고 싶 다면 적당 한 책 이 다 . 오픈 소스 프로젝트 가 생긴 이유 를 잘 설명 하 고 있 다 . 리눅스 , 윈도우즈 를 장난감 에 비유 한 설명 도 아주 인상 적 이 다 . 리눅스 에 상당 한 관심 이 생겼 다면 , 집 에서 노 는 컴퓨터 에 우분투 데스크 탑 버전 을 설치 해 보 는 것 도 좋 다 . 가지 고 놀 면서 공부 하 다 보 면 빨리 익숙 해진다 . 테스트 주도 개발 테스트 주도 개발 ( test - driven development ) 은 개발자 와 함께 일 하 면서 가장 놀란 개념 중 에 하 나다 . 처음 에 는 매번 코드 를 작성 할 때 마다 테스트 케이스 를 만들 고 테스트 코드 를 작성 하 는 일 이 참 무의미 하 게 느껴진다 . 하지만 프로젝트 가 오래 진행 되 고 연관 된 모듈 이 많 아 지 기 시작 하 면 테스트 가 없 는 상황 에서 무언가 수정 하 는 일 은 거의 불 가능 하 다 . 지금 은 테스트 없이 개발 을 진행 하 는 것 이 무서울 정도 다 . 실용 적 인 의미 에서 는 테스트 가 훌륭 한 보안 장치 역할 을 하 지만 실제로 는 그 이상 의 의미 가 있 다 . 해야 할 일 을 미리 생각 하 고 범위 를 정해서 조금 씩 진행 하 면 큰 그림 이 그려지 고 전체 프로젝트 가 완성 된다 . 이 과정 이 테스트 덕분 에 아주 부드럽 게 진행 된다 . 짧 은 글 로 표현 하 기 어려운데 , 아래 책 을 꼭 읽 어 보 고 실천 한다 . 훌륭 한 개발자 와 짝 프로그래밍 ( pair programming ) 을 할 기회 가 있 다면 많이 배울 수 있 다 . test driven development : by example . 개발 관련 서적 중 에서 아주 감명 깊 게 읽 은 책 중 에 하 나다 . 기술 서 를 읽 고 감동 할 수 도 있 다 . 기술 서 라고 말 하 기 도 어려운데 , 어떻게 테스트 주도 개발 을 하 는지 풍부 한 예시 로 설명 한다 . 사상 서 라고 표현 하 는 게 맞 을 것 같 다 . 초반 에 는 자바 코드 , 후반 에 는 파이썬 코드 가 있 는데 코드 가 쉬워서 읽 기 에 부담 없 다 . 분량 도 아주 적 다 . 꼭 읽 기 를 추천 한다 . 작 게 시작 하 고 빠르 게 만들 기 , 그것 을 반복 하 기 짝 프로그래밍 을 하 는 개발자 ( @ alankang ) 덕분 에 배운 또 한 가지 놀라운 개념 이 다 . 몇 개 의 문장 으로 정리 하 기 에 는 참 많 은 내용 이 있 지만 , 특히 인상 적 인 점 은 거대 한 계획 을 세우 지 않 고 작 게 시작 한다는 점 이 다 . 소위 설계 라는 것 을 크 게 하 지 않 고 , 필요 에 의해서 시작 한다 . 결과물 을 밀어내 는 방식 이 아니 라 수요 에 의해서 끌어당기 는 방식 으로 일 한다 . 이런 작 은 과정 을 반복 하 면서 개발 을 하 면 매우 생산 적 이 다 . 짧 은 문장 으로 만 표현 하 면 참 별 거 없 지만 , 이런 생각 으로 실제 개발 프로젝트 를 수행 해 보 면 그 놀라움 을 느낄 수 있 다 . 애자일 개발 론 ( agile software development ) 의 일부 인데 , 아직 애자일 을 이야기 할 정도 로 이해 가 깊 지 않 다 . 사상 을 이해 하 는 것 이 중요 하 다 . 어떤 부분 에서 는 기술 보다 어떤 원칙 으로 일 을 진행할 것 인지 가 결과물 에 더 큰 영향 을 미친다 . 이 부분 은 더 공부 할 부분 이 다 . 자료 구조 와 알고리즘 조금 어려운 기술 서 를 읽 다 보 면 , 항상 저 두 단어 가 반복 해서 등장 한다 . 몰라도 당장 무언가 만드 는데 지장 은 없 지만 , 항상 궁금 하 다 . 공부 하 는데 상당히 오래 걸리 고 노력 도 많이 필요 한 주제 지만 , 한 번 은 봐야 할 부분 이 다 . 좋 은 책 을 찾 느라 상당히 고생 했 는데 , 아래 책 이 가장 추천 할 만 하 다 . 아직 다 읽 지 못했 는데 , 새로운 알고리즘 이 나올 때 마다 상당히 놀라 고 있 다 . 똑똑 한 사람 참 많 다 . algorithms . 자 바로 알고리즘 과 자료 구조 를 설명 한다 . 파이썬 으로 설명 한 좋 은 알고리즘 책 은 아직 못 찾 았 다 . 자바 예제 를 감안 하 더라도 읽 기 에 무리 없 다 . 초반 에 는 자바 문법 을 가르치 는데 상당 분량 을 할애 하 므로 큰 문제 없 다 . 이 책 과 항상 비교 되 는 책 이 ‘ introduction to algorithms ’ 인데 서평 이나 목차 등 을 감안 하 여 최종 적 으로 링크 한 책 을 골랐 다 . 아마도 알고리즘 관련 해서 는 다른 책 을 읽 지 않 을 테 니 최대한 좋 은 책 을 골라서 한 권 만 제대로 보 는 것 이 좋 다 . 갈림길 개발 공부 가 재미있 어 지 면 , 두 가지 고민 이 생긴다 . 지금 유행 하 는 최신 기술 들 을 공부 하 고 적용 해서 좋 은 사례 를 만들 고 싶 다는 생각 이 든다 . 혹은 아직 잘 모르 는 기본 지식 을 더 공부 하 고 싶 기 도 하 다 . 둘 다 하 는 게 맞 지만 , 현실 적 으로 시간 이 부족 하 다 . 게다가 경험 이 적 다는 것 은 큰 장애 요소 다 . 지금 까지 소개 한 책 을 아무리 잘 이해 해도 경험 많 은 훌륭 한 개발자 들 과 함께 일 하 면서 배울 수 있 는 것 은 항상 그 이상 이 다 . 이런 사람 들 은 이미 알 고 있 는 것 이 많 은데 , 이런 과정 을 생략 하 고 최신 의 무엇 을 살펴보 는 게 시기상조 라는 생각 이 든다 . 통계학 공부 를 주로 했 던 사람 이 개발 공부 를 해서 무언가 더 좋 은 것 을 만들 려면 , 두 지식 을 함께 쓸 수 있 는 방향 이 이상 적 이 다 . 이런 융합 이 일어나 기에 적합 한 곳 은 아마도 잘 변하 지 않 는 기본 지식 이 아닐까 싶 다 . 게다가 개발 관련 지식 은 하루 가 다르 게 확장 된다 . 지금 이 를 모두 습득 하 려고 노력 하 기 에 는 통계 공부 할 시간 이 없 다 . 유행 을 따르 지 않 고 앞 으로 도 중요 한 개념 을 먼저 공부 하 는 것 이 맞 다는 생각 이 든다 . 언제나 강조 해도 지나침 이 없 는 것 은 기본 이 중요 하 다는 점 이 다 .',\n",
       "       \"만 29 세 이하 만 가입 할 수 있 는 ' 고 금리 통장 ' 의 정체 ? by 김 유라 2018 . 01 . 23 읽 음 스크랩 좋 아요 읽 음 스크랩 [ URL ] url 복사 url 을 길 게 누르 면 복사 하 실 수 있 습니다 . 저작권자 ©( 주 ) 폴트 무단 전재 및 재 배포 금지\",\n",
       "       'contents 1 사회 과학 에서 의 구조 방정식 2 확인 적 요인 분석 ( cfa , confirmatory factor analysis ) 3 구조 방정식 ( sem , structural equation modeling ) 4 intercept , group , starting value , fitting function , invariance 4 . 1 intercept 4 . 2 group 4 . 3 starting value 4 . 4 fitting function 4 . 5 invariance 5 예제 1 6 예제 2 7 참고 자료 을 따라 해 본 거 다 . lavaan 는 \" latent variable analysis ( 잠재 변수 분석 ) \" 의 약자 다 . 잠재 변수 란 , 관측 변수 로부터 추정 되 어 진 추상 적 개념 의 변수 를 말 한다 . 구조 방정식 의 변수 들 에 대한 설명 은 를 참고 하 자 . lavaan package tutorial 을 따라 해 본 거 다 . lavaan 는 \" latent variable analysis ( 잠재 변수 분석 ) \" 의 약자 다 . 잠재 변수 란 , 관측 변수 로부터 추정 되 어 진 추상 적 개념 의 변수 를 말 한다 . 구조 방정식 의 변수 들 에 대한 설명 은 여기 를 참고 하 자 . edit ] 1 # [ URL ] 측정 오 차 대부분 사회 과학 에서 사용 하 는 변수 는 측정 오 차 가 존재 잠재변수 ( latent variable ) 을 사용 측정 의 구성 타당 도 사회 과학 에서 사용 하 는 개념 은 대체로 추상 적 개념 확인 적 요인 분석 ( confirmatory factor analysis ) 을 사용 인과 모형 이론 에서 가정 한 개념 들 간 의 인과 관계 구조 방정식 모형 ( structural equation model ) 을 사용 edit ] 2 # holzingerswineford 1939 데이터 로 하 는데 , 이 데이터 에 대한 설명 은 를 참고 하 면 된다 . 데이터 로 하 는데 , 이 데이터 에 대한 설명 은 여기 를 참고 하 면 된다 . library ( \" lavaan \") data ( holzingerswineford 1939 ) str ( holzingerswineford 1939 ) > library ( \" lavaan \") > data ( holzingerswineford 1939 ) > str ( holzingerswineford 1939 ) \\' data . frame \\': 301 obs . of 15 variables : $ id : int 1 2 3 4 5 6 7 8 9 11 . .. $ sex : int 1 2 2 1 2 2 1 2 2 2 . .. $ ageyr : int 13 13 13 13 12 14 12 12 13 12 . .. $ agemo : int 1 7 1 2 2 1 1 2 0 5 . .. $ school : factor w / 2 levels \" grant - white \",..: 2 2 2 2 2 2 2 2 2 2 . .. $ grade : int 7 7 7 7 7 7 7 7 7 7 . .. $ x 1 : num 3 . 33 5 . 33 4 . 5 5 . 33 4 . 83 . .. $ x 2 : num 7 . 75 5 . 25 5 . 25 7 . 75 4 . 75 5 6 6 . 25 5 . 75 5 . 25 . .. $ x 3 : num 0 . 375 2 . 125 1 . 875 3 0 . 875 . .. $ x 4 : num 2 . 33 1 . 67 1 2 . 67 2 . 67 . .. $ x 5 : num 5 . 75 3 1 . 75 4 . 5 4 3 6 4 . 25 5 . 75 5 . .. $ x 6 : num 1 . 286 1 . 286 0 . 429 2 . 429 2 . 571 . .. $ x 7 : num 3 . 39 3 . 78 3 . 26 3 3 . 7 . .. $ x 8 : num 5 . 75 6 . 25 3 . 9 5 . 3 6 . 3 6 . 65 6 . 2 5 . 15 4 . 65 4 . 55 . .. $ x 9 : num 6 . 36 7 . 92 4 . 42 4 . 86 5 . 92 . .. > model <- \" visual =~ x 1 + x 2 + x 3 textual =~ x 4 + x 5 + x 6 speed =~ x 7 + x 8 + x 9 \" fit <- cfa ( model , data = holzingerswineford 1939 ) summary ( fit , fit . measures = true ) > summary ( fit , fit . measures = true ) lavaan ( 0 . 5 - 15 ) converged normally after 35 iterations number of observations 301 estimator ml minimum function test statistic 85 . 306 degrees of freedom 24 p - value ( chi - square ) 0 . 000 model test baseline model : minimum function test statistic 918 . 852 degrees of freedom 36 p - value 0 . 000 user model versus baseline model : comparative fit index ( cfi ) 0 . 931 tucker - lewis index ( tli ) 0 . 896 loglikelihood and information criteria : loglikelihood user model ( h 0 ) - 3737 . 745 loglikelihood unrestricted model ( h 1 ) - 3695 . 092 number of free parameters 21 akaike ( aic ) 7517 . 490 bayesian ( bic ) 7595 . 339 sample - size adjusted bayesian ( bic ) 7528 . 739 root mean square error of approximation : rmsea 0 . 092 90 percent confidence interval 0 . 071 0 . 114 p - value rmsea <= 0 . 05 0 . 001 standardized root mean square residual : srmr 0 . 065 parameter estimates : information expected standard errors standard estimate std . err z - value p ( >| z |) latent variables : visual =~ x 1 1 . 000 x 2 0 . 554 0 . 100 5 . 554 0 . 000 x 3 0 . 729 0 . 109 6 . 685 0 . 000 textual =~ x 4 1 . 000 x 5 1 . 113 0 . 065 17 . 014 0 . 000 x 6 0 . 926 0 . 055 16 . 703 0 . 000 speed =~ x 7 1 . 000 x 8 1 . 180 0 . 165 7 . 152 0 . 000 x 9 1 . 082 0 . 151 7 . 155 0 . 000 covariances : visual ~~ textual 0 . 408 0 . 074 5 . 552 0 . 000 speed 0 . 262 0 . 056 4 . 660 0 . 000 textual ~~ speed 0 . 173 0 . 049 3 . 518 0 . 000 variances : x 1 0 . 549 0 . 114 x 2 1 . 134 0 . 102 x 3 0 . 844 0 . 091 x 4 0 . 371 0 . 048 x 5 0 . 446 0 . 058 x 6 0 . 356 0 . 043 x 7 0 . 799 0 . 081 x 8 0 . 488 0 . 074 x 9 0 . 566 0 . 071 visual 0 . 809 0 . 145 textual 0 . 979 0 . 112 speed 0 . 384 0 . 086 > library ( semplot ) sempaths ( fit , what =\" std \", edge . label . cex = 0 . 6 , sizeman = 5 , sizelat = 5 , curve = 0 . 4 ) library ( qgraph ) qgraph . lavaan ( fit , layout =\" tree \", titles = f , vsize . man = 5 , vsize . lat = 5 , filetype =\"\", include = 4 , curve =- 0 . 4 , edge . label . cex = 0 . 6 ) 아래 와 같이 표현 할 수 있 으나 , 없 어 질 함수 라고 함 . edit ] 3 # politicaldemocracy 데이터 를 사용 한다 . 를 참 고 한다 . 데이터 를 사용 한다 . p oliticaldemocracy 에 대한 설명 은 여기 를 참 고 한다 . library ( \" lavaan \") data ( politicaldemocracy ) model <- \" # measurement model ind 60 =~ x 1 + x 2 + x 3 dem 60 =~ y 1 + y 2 + y 3 + y 4 dem 65 =~ y 5 + y 6 + y 7 + y 8 # regressions dem 60 ~ ind 60 dem 65 ~ ind 60 + dem 60 # residual correlations y 1 ~~ y 5 y 2 ~~ y 4 + y 6 y 3 ~~ y 7 y 4 ~~ y 8 y 6 ~~ y 8 \" fit <- sem ( model , data = politicaldemocracy ) summary ( fit , standardized = true ) > summary ( fit , standardized = true ) lavaan ( 0 . 5 - 15 ) converged normally after 68 iterations number of observations 75 estimator ml minimum function test statistic 38 . 125 degrees of freedom 35 p - value ( chi - square ) 0 . 329 parameter estimates : information expected standard errors standard estimate std . err z - value p ( >| z |) std . lv std . all latent variables : ind 60 =~ x 1 1 . 000 0 . 670 0 . 920 x 2 2 . 180 0 . 139 15 . 742 0 . 000 1 . 460 0 . 973 x 3 1 . 819 0 . 152 11 . 967 0 . 000 1 . 218 0 . 872 dem 60 =~ y 1 1 . 000 2 . 223 0 . 850 y 2 1 . 257 0 . 182 6 . 889 0 . 000 2 . 794 0 . 717 y 3 1 . 058 0 . 151 6 . 987 0 . 000 2 . 351 0 . 722 y 4 1 . 265 0 . 145 8 . 722 0 . 000 2 . 812 0 . 846 dem 65 =~ y 5 1 . 000 2 . 103 0 . 808 y 6 1 . 186 0 . 169 7 . 024 0 . 000 2 . 493 0 . 746 y 7 1 . 280 0 . 160 8 . 002 0 . 000 2 . 691 0 . 824 y 8 1 . 266 0 . 158 8 . 007 0 . 000 2 . 662 0 . 828 regressions : dem 60 ~ ind 60 1 . 483 0 . 399 3 . 715 0 . 000 0 . 447 0 . 447 dem 65 ~ ind 60 0 . 572 0 . 221 2 . 586 0 . 010 0 . 182 0 . 182 dem 60 0 . 837 0 . 098 8 . 514 0 . 000 0 . 885 0 . 885 covariances : y 1 ~~ y 5 0 . 624 0 . 358 1 . 741 0 . 082 0 . 624 0 . 296 y 2 ~~ y 4 1 . 313 0 . 702 1 . 871 0 . 061 1 . 313 0 . 273 y 6 2 . 153 0 . 734 2 . 934 0 . 003 2 . 153 0 . 356 y 3 ~~ y 7 0 . 795 0 . 608 1 . 308 0 . 191 0 . 795 0 . 191 y 4 ~~ y 8 0 . 348 0 . 442 0 . 787 0 . 431 0 . 348 0 . 109 y 6 ~~ y 8 1 . 356 0 . 568 2 . 386 0 . 017 1 . 356 0 . 338 variances : x 1 0 . 082 0 . 019 0 . 082 0 . 154 x 2 0 . 120 0 . 070 0 . 120 0 . 053 x 3 0 . 467 0 . 090 0 . 467 0 . 239 y 1 1 . 891 0 . 444 1 . 891 0 . 277 y 2 7 . 373 1 . 374 7 . 373 0 . 486 y 3 5 . 067 0 . 952 5 . 067 0 . 478 y 4 3 . 148 0 . 739 3 . 148 0 . 285 y 5 2 . 351 0 . 480 2 . 351 0 . 347 y 6 4 . 954 0 . 914 4 . 954 0 . 443 y 7 3 . 431 0 . 713 3 . 431 0 . 322 y 8 3 . 254 0 . 695 3 . 254 0 . 315 ind 60 0 . 448 0 . 087 1 . 000 1 . 000 dem 60 3 . 956 0 . 921 0 . 800 0 . 800 dem 65 0 . 172 0 . 215 0 . 039 0 . 039 > library ( semplot ) sempaths ( fit , what =\" std \", edge . label . cex = 0 . 6 , sizeman = 5 , sizelat = 5 , curve = 0 . 4 , edge . color =\" black \" ) edit ] 4 # edit ] 4 . 1 # model <- \" # three - factor model visual =~ x 1 + x 2 + x 3 textual =~ x 4 + x 5 + x 6 speed =~ x 7 + x 8 + x 9 # intercepts x 1 ~ 1 x 2 ~ 1 x 3 ~ 1 x 4 ~ 1 x 5 ~ 1 x 6 ~ 1 x 7 ~ 1 x 8 ~ 1 x 9 ~ 1 \" fit <- cfa ( model , data = holzingerswineford 1939 , meanstructure = t ) summary ( fit , fit . measures = true ) library ( semplot ) sempaths ( fit , what =\" std \", edge . label . cex = 0 . 6 , sizeman = 5 , sizelat = 5 , curve = 0 . 4 , edge . color =\" black \" ) edit ] 4 . 2 # model <- \" # three - factor model visual =~ x 1 + x 2 + x 3 textual =~ x 4 + x 5 + x 6 speed =~ x 7 + x 8 + x 9 \" fit <- cfa ( model , data = holzingerswineford 1939 , group =\" school \") summary ( fit , fit . measures = true ) edit ] 4 . 3 # model <- \" # three - factor model visual =~ x 1 + 0 . 5 * x 2 + c ( 0 . 6 , 0 . 8 ) * x 3 textual =~ x 4 + start ( c ( 1 . 2 , 0 . 6 ) ) * x 5 + a * x 6 speed =~ x 7 + x 8 + x 9 \" fit <- cfa ( model , data = holzingerswineford 1939 , group =\" school \") summary ( fit , fit . measures = true ) starting value 가 0 . 5 * x 2 같이 상수 로 주 어 질 수 있 다 . 또한 c ( 0 . 6 , 0 . 8 ) 와 같이 벡터 로 group 별 로 starting value 를 따로 줄 수 있 다 . starting value 가 0 . 5 * x 2 같이 상수 로 주 어 질 수 있 다 . 또한 c ( 0 . 6 , 0 . 8 ) 와 같이 벡터 로 group 별 로 starting value 를 따로 줄 수 있 다 . edit ] 4 . 4 # hs . model <- \\' visual =~ x 1 + x 2 + x 3 textual =~ x 4 + x 5 + x 6 speed =~ x 7 + x 8 + x 9 \\' fit <- cfa ( hs . model , data = holzingerswineford 1939 , group = \" school \", group . equal = c ( \" loadings \")) summary ( fit ) group . equal 에 loadings 대신 다음 과 같 은 것 들 이 올 수 있 다 . intercepts : the intercepts of the observed variables means : the intercepts / means of the latent variables residuals : the residual variances of the observed variables residual . covariances : the residual covariances of the observed variables lv . variances : the ( residual ) variances of the latent variables lv . covariances : the ( residual ) covariances of the latent varibles regressions : all regression coefficients in the model if you omit the group . equal argument , all parameters are freely estimated in each group ( but the model structure is the same ) . group . equal 에 loadings 대신 다음 과 같 은 것 들 이 올 수 있 다 . if you omit the group . equal argument , all parameters are freely estimated in each group ( but the model structure is the same ) . but what if you want to constrain a whole group of parameters ( say all factor loadings and intercepts ) across groups , except for one or two parameters that need to stay free in all groups . for this scenario , you can use the argument group . partial , containing the names of those parameters that need to remain free . for example : fit <- cfa ( hs . model , data = holzingerswineford 1939 , group = \" school \", group . equal = c ( \" loadings \", \" intercepts \"), group . partial = c ( \" visual =~ x 2 \", \" x 7 ~ 1 \")) edit ] 4 . 5 # library ( semtools ) measurementinvariance ( hs . model , data = holzingerswineford 1939 , group = \" school \") edit ] 5 # library ( lavaan ) > str ( ch 9 . ex 1 ) \\' data . frame \\': 8 obs . of 5 variables : $ attitude : int 2 3 3 4 4 4 4 5 $ loyalty : int 2 3 3 4 4 5 4 5 $ price : int 4 4 3 3 2 2 1 1 $ quality : int 2 3 2 3 3 4 3 5 $ design : int 2 3 4 2 5 3 2 4 > ch 9 . ex 1 attitude loyalty price quality design 1 2 2 4 2 2 2 3 3 4 3 3 3 3 3 3 2 4 4 4 4 3 3 2 5 4 4 2 3 5 6 4 5 2 4 3 7 4 4 1 3 2 8 5 5 1 5 4 > path . model <- \" + # regressions + attitude ~ price + quality + design + loyalty ~ attitude + + # residual covariances + price ~~ quality + price ~~ design + quality ~~ design + \" > path . example <- lavaan ( path . model , data = ch 9 . ex 1 , auto . var = t , auto . fix . first = t , fixed . x = f ) > summary ( path . example ) lavaan ( 0 . 5 - 15 ) converged normally after 43 iterations number of observations 8 estimator ml minimum function test statistic 1 . 718 degrees of freedom 3 p - value ( chi - square ) 0 . 633 parameter estimates : information expected standard errors standard estimate std . err z - value p ( >| z |) regressions : attitude ~ price - 0 . 382 0 . 133 - 2 . 869 0 . 004 quality 0 . 459 0 . 159 2 . 883 0 . 004 design 0 . 063 0 . 109 0 . 579 0 . 562 loyalty ~ attitude 1 . 064 0 . 135 7 . 906 0 . 000 covariances : price ~~ quality - 0 . 688 0 . 440 - 1 . 563 0 . 118 design - 0 . 313 0 . 431 - 0 . 725 0 . 468 quality ~~ design 0 . 234 0 . 355 0 . 660 0 . 509 variances : attitude 0 . 097 0 . 048 loyalty 0 . 106 0 . 053 price 1 . 250 0 . 625 quality 0 . 859 0 . 430 design 1 . 109 0 . 555 > summary ( path . example , fit . measures = t ) lavaan ( 0 . 5 - 15 ) converged normally after 43 iterations number of observations 8 estimator ml minimum function test statistic 1 . 718 degrees of freedom 3 p - value ( chi - square ) 0 . 633 model test baseline model : minimum function test statistic 40 . 609 degrees of freedom 10 p - value 0 . 000 user model versus baseline model : comparative fit index ( cfi ) 1 . 000 tucker - lewis index ( tli ) 1 . 140 loglikelihood and information criteria : loglikelihood user model ( h 0 ) - 36 . 520 loglikelihood unrestricted model ( h 1 ) - 35 . 662 number of free parameters 12 akaike ( aic ) 97 . 041 bayesian ( bic ) 97 . 994 sample - size adjusted bayesian ( bic ) 62 . 535 root mean square error of approximation : rmsea 0 . 000 90 percent confidence interval 0 . 000 0 . 481 p - value rmsea <= 0 . 05 0 . 641 standardized root mean square residual : srmr 0 . 021 parameter estimates : information expected standard errors standard estimate std . err z - value p ( >| z |) regressions : attitude ~ price - 0 . 382 0 . 133 - 2 . 869 0 . 004 quality 0 . 459 0 . 159 2 . 883 0 . 004 design 0 . 063 0 . 109 0 . 579 0 . 562 loyalty ~ attitude 1 . 064 0 . 135 7 . 906 0 . 000 covariances : price ~~ quality - 0 . 688 0 . 440 - 1 . 563 0 . 118 design - 0 . 313 0 . 431 - 0 . 725 0 . 468 quality ~~ design 0 . 234 0 . 355 0 . 660 0 . 509 variances : attitude 0 . 097 0 . 048 loyalty 0 . 106 0 . 053 price 1 . 250 0 . 625 quality 0 . 859 0 . 430 design 1 . 109 0 . 555 > summary ( path . example , standardized = t ) lavaan ( 0 . 5 - 15 ) converged normally after 43 iterations number of observations 8 estimator ml minimum function test statistic 1 . 718 degrees of freedom 3 p - value ( chi - square ) 0 . 633 parameter estimates : information expected standard errors standard estimate std . err z - value p ( >| z |) std . lv std . all regressions : attitude ~ price - 0 . 382 0 . 133 - 2 . 869 0 . 004 - 0 . 382 - 0 . 498 quality 0 . 459 0 . 159 2 . 883 0 . 004 0 . 459 0 . 497 design 0 . 063 0 . 109 0 . 579 0 . 562 0 . 063 0 . 078 loyalty ~ attitude 1 . 064 0 . 135 7 . 906 0 . 000 1 . 064 0 . 942 covariances : price ~~ quality - 0 . 688 0 . 440 - 1 . 563 0 . 118 - 0 . 688 - 0 . 663 design - 0 . 313 0 . 431 - 0 . 725 0 . 468 - 0 . 313 - 0 . 265 quality ~~ design 0 . 234 0 . 355 0 . 660 0 . 509 0 . 234 0 . 240 variances : attitude 0 . 097 0 . 048 0 . 097 0 . 132 loyalty 0 . 106 0 . 053 0 . 106 0 . 113 price 1 . 250 0 . 625 1 . 250 1 . 000 quality 0 . 859 0 . 430 0 . 859 1 . 000 design 1 . 109 0 . 555 1 . 109 1 . 000 > library ( qgraph ) warning message : 패키지 ‘ qgraph ’ 는 r 버전 3 . 0 . 3 에서 작성 되 었 습니다 > qgraph . lavaan ( path . example , layout =\" spring \", + vsize . man = 8 , + vsize . lat = 8 , + filetype =\"\", + include = 4 , + curve =- 0 . 4 , + edge . label . cex = 0 . 6 ) 브랜드 에 대한 태도 ( attitude ) 에 영향 을 주 는 요인 은 가격 ( price ) , 품질 ( quality ) , 외형 ( design ) 인데 , 가격 은 낮 을 수록 좋 다 . ( - 0 . 5 ) 품질 는 좋 을 수록 좋 다 . ( 0 . 5 ) 외형 은 별로 관계 가 없 다 . ( 0 . 08 ) 충성 도 ( royalty ) 는 브랜드 에 대한 태도 가 영향 을 주 는 요인 이 다 . ( 0 . 94 ) 참고 : [ URL ] 문서 를 보 고 함 . edit ] 6 # [ URL ] ## not run : ## the industrialization and political democracy example # example from lavaan : : sem help file : require ( \" lavaan \") ## bollen ( 1989 ) , page 332 model <- \\' # latent variable definitions ind 60 =~ x 1 + x 2 + x 3 dem 60 =~ y 1 + y 2 + y 3 + y 4 dem 65 =~ y 5 + equal ( \" dem 60 =~ y 2 \")* y 6 + equal ( \" dem 60 =~ y 3 \")* y 7 + equal ( \" dem 60 =~ y 4 \")* y 8 # regressions dem 60 ~ ind 60 dem 65 ~ ind 60 + dem 60 # residual correlations y 1 ~~ y 5 y 2 ~~ y 4 + y 6 y 3 ~~ y 7 y 4 ~~ y 8 y 6 ~~ y 8 \\' fit <- sem ( model , data = politicaldemocracy ) # plot standardized model ( numerical ) : qgraph . lavaan ( fit , layout =\" tree \", vsize . man = 5 , vsize . lat = 10 , filetype =\"\", include = 4 , curve =- 0 . 4 , edge . label . cex = 0 . 6 ) # plot standardized model ( graphical ) : qgraph . lavaan ( fit , layout =\" tree \", vsize . man = 5 , vsize . lat = 10 , filetype =\"\", include = 8 , curve =- 0 . 4 , edge . label . cex = 0 . 6 ) # create output document : qgraph . lavaan ( fit , layout =\" spring \", vsize . man = 5 , vsize . lat = 10 , filename =\" lavaan \") ## end ( not run ) edit ] 7 # [ URL ] --> semplot example 구조 방정식 에 대한 설명 , 히든 그레이스 구조 방정식 에 대한 설명 , 히든 그레이스 [ URL ] [ URL ] [ URL ] [ URL ] r 구조 방정식 . zip [ URL ] [ URL ] [ URL ] [ URL ] \\ufeff',\n",
       "       \"[ 과학 기자 의 문화 산책 ] ‘ 도 ( 道 ) ’ 를 깨달 은 로봇 이 게임 에 나타났 다 블리자드 신작 ' 오버 워치 ' 의 등장인물 들 - 블리자드 제공 도 를 깨우친 로봇 수도승 , 불구 가 돼 로봇 속 에 이식 된 뒤 한 차원 더 높 은 인간 성 을 갖 게 된 사이보그 … . 어느 공상 과학 ( sf ) 소설 이나 영화 속 이야기 가 아니 다 . ‘ 스타크래프트 ’ ‘ 월드 오브 워크래프트 ’ 로 유명 한 미국 게임 제작사 ‘ 블리자드 ’ 는 이전 까지 미디어 에 등장 한 인공지능 ( ai ) 과 사이보그 , 로봇 에 대한 오마주 를 한 데 버무려 ‘ 오버 워치 ’ 라는 게임 으로 완성 했 다 . 에피소드 ' 천상 의 피조물 ' 에 등장 하 는 도 를 깨달 은 로봇 ru - 4 - 영화 ' 인류 멸망 보고서 ' 中 제공 ● 인공지능 , 인간 의 스승 이 되 다 2012 년 개봉 한 옴니버스 식 영화 ‘ 인류 멸망 보고서 ’ 의 한 에피소드 인 ‘ 천상 의 피조물 ’ 에 는 깨달음 을 얻 은 ai 로봇 ‘ ru - 4 ’ 가 등장 한다 . 이 에피소드 의 원작 은 바로 sf 작가 박성환 의 ‘ 레디메이드 보살 ’. ru - 4 가 부처 인지 반신반의 하 는 스님 들 과 로봇 을 점검 하 러 온 엔지니어 와 의 간극 이 이 이야기 의 백미 다 . 결국 인간 은 ru - 4 가 인류 에게 장기 적 으로 위협 이 될 것 으로 보 고 해 체하 려고 한다 . ai 와 인간 사이 의 간극 은 오버 워치 의 애니메이션 ‘ 심장 ’ 에서 도 그대로 재현 된다 . 인간 과 로봇 의 조화 를 주장 하 는 ai 로봇 선지자 ‘ 몬 다타 ’ 가 인간 에게 암살 당하 게 되 고 , 로봇 과 인간 사이 의 관계 는 급격 하 게 냉각 된다 . 1999 년 개봉 한 영화 ‘ 매트릭스 ’ 에서 처럼 인간 과 ai 사이 의 전쟁 이 일어난 뒤 화해 의 분위기 속 에서 발발 한 사건 인 만큼 여파 는 더 충격 적 이 다 . 도 를 깨우친 인공지능 로봇 ' 젠 야타 ' - 블리자드 코리아 제공 이쯤 에서 몬 다타 와 함께 ru - 4 의 오마주 라 할 수 있 는 게임 캐릭터 로봇 수도승 ‘ 젠 야타 ’ 를 소개 한다 . “ 꿈 에서 나 는 나비 였 소 ” 라는 대사 를 던지 는 젠 야 타 는 영혼 의 존재 를 믿 고 , 인간 과 로봇 이 공존 하 는 미래 를 꿈꾼다 . 그리고 그 는 과거 인간 이 었 던 사이보그 ‘ 겐지 ’ 의 정신 적 인 스승 이 된다 . 겐지 는 인간 시절 큰 부상 을 입 은 뒤 정신 을 사이보그 에 이식 하 고 한 단계 더 높 은 인간 성 을 갖 게 된 것 으로 묘사 된다 . 사이보그 가 된 직후 에 는 자신 의 모습 을 받아들일 수 없 었 지만 젠야 타 를 만나 게 되 면서 새로운 신체 에 적응 하 게 되 고 , 사이보그 가 된 뒤 에 도 자신 이 온전히 인간 의 영혼 을 갖 고 있 음 을 믿 게 된다 . 인간 의 신체 를 사이보그 로 교체 함 으로써 인간 성 을 얻 게 되 는 겐지 의 모습 은 만화 ‘ 에덴 ’ 의 등장인물 ‘ 소피아 테 오도 레스 ’ 에서 찾 을 수 있 다 . 천재 해커 이 지만 자신 의 육체 에 대한 자각 이 없 던 그녀 는 마흔 의 나이 에 자신 의 몸 을 사이보그 로 바꾼 뒤 새롭 게 얻 는 감각 을 통해 자기 자신 과 자신 을 둘러싼 세계 를 새롭 게 인지 하 게 된다 . 인간 의 정신 을 사이보그 에 이식 한다는 소재 의 대명사 는 ‘ 공각 기동대 ’ 이 지만 , 새로운 육체 를 통해 얻 게 되 는 감각 에 대한 묘사 는 ‘ 에덴 ’ 이 더 한 걸음 나 서 있 다고 본다 . 인간 에서 사이보그 가 된 ' 겐지 ' 와 , 만화 ' 에덴 ' 속 캐릭터 ' 소피아 '. 둘 의 공통점 은 사이보그 가 된 이후 에 예전 보다 더 높 은 인간 성 을 얻 었 다는 것 이 다 . - 블리자드 , 만화 에덴 제공 ● 2016 년 의 시대 정신 은 ai 인가 오버 워치 는 흔히 총싸움 게임 이 라 부르 는 fps ( 1 인칭 슈팅 게임 ) 중 하이퍼 fps 장르 에 속한다 . 초능력 이나 미래 의 신 기술 이 등장 하 는 fps 게임 을 하이퍼 fps 라고 하 는데 , 세계 적 으로 ‘ 대세 ’ 로 는 보 기 어려운 장르 다 . 국내 에서 도 별로 인기 가 없 는 장르 다 . 국내 에서 나 해외 에서 나 인기 가 좋 은 건 ‘ 서든 어택 ’ 이나 ‘ 콜 오브 듀티 ’ 같 은 현대전 배경 의 게임 이 다 . 그런데 헐리우드 블록버스터 처럼 거대 자본 이 투입 된 만큼 많 은 사람 들 을 끌 어 모아야 하 는 블리자드 가 하이퍼 fps 를 신작 으로 내놓 았 다 . 그리고 그 이야기 의 중심 에 는 ai 와 인간 사이 의 갈등 이 있 다 . ai 에 대한 이야기 가 앞 으로 대세 가 될 것 이 란 예측 이 블리자드 에게 있 었 던 것 이 아닐까 . 그리고 그 예측 은 지금 까지 잘 맞 아 들어가 고 있 다 . 노자 ( 老子 ) 는 “ 도 ( 道 ) 를 보이 지 도 않 고 , 형체 도 없 으며 언어 로 서술 할 수 도 없 다 ” 며 “ 도 를 도라 한다면 도 가 아니 다 ” 라는 말 을 남겼 다 . 알 파고 와 이세돌 9 단의 첫 대국 에서 알 파고 가 둔 ‘ 엉뚱 한 수 ’ 는 사실 인간 이 이해 할 수 없 던 ‘ 신 의 한 수 ’ 였 다 . 어쩌면 ‘ 오버 워치 ’ 가 묘사 한 ai 로봇 들 은 인간 보다 앞서 도 를 깨달 은 이 들 의 모습 을 그린 것 은 아닐까 .\",\n",
       "       \"1 . 관정 1 차 , 2 차 는 서류 이 고 학점 , 영어 성적 및 자기 소개서 와 연구 계획서 를 기반 으로 평가 한다고 한다 . 자기 소개서 및 연구 계획서 는 나중 면접 때 도 꼭 물 어 보 기 때문 에 정성 을 들여 작성 하 는 것 이 좋 다 . 1 차 합격 2 차 합격 최종 합격 2 . 국비 3 . 아산 미국 대학원 을 준비 하 면서 가장 신경 쓰이 는 부분 은 아무래도 학비 일 것 이 다 . 내 가 진학 하 는 하버드 의 경우 학비 는 . .. 어마 무시 하 다 . 이것 보다 더 끔찍 한 학비 는 듀크 였 는데 , 1 년 에 학비 만 $ 51 , 480 이 다 . ( [ URL ] 나 은 곳 은 미네소타 대학 인데 , 1 년 에 $ 25 , 120 으로 그나마 싼 편 이 다 . ( [ URL ] 어마 무시 한 학비 속 에서 , 석사 과정 은 학비 를 지원 해 주 지 도 않 기 때문 에 . .. 외부 장학금 을 노리 는 것 이 최선 이 다 . 이번 포스팅 에서 는 학비 의 상당 부분 을 보조 하 는 장학금 에 대하 여 이야기 해 보 고자 한다 . - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ------------------------- 외부 장학금 의 경우 잘 알려진 것 으로 는 kfas , fulbright , 관정 , 국비 , 그리고 의 생명 분야 의 아산 이 있 다 . 내 가 지원 한 장학금 은 관정 , 아산 이 다 . 관정 의 경우 생물 통계학 에 대한 학위 과정 이 명확 하 게 표시 되 어 있 지 않 은데 , 관정 교육 재단 에서 답변 한 내용 에 따라 ' 통계학 ' 으로 지원 하 였 다 . ( [ URL ] 지원 할 수 있 는 대학 들 은 아래 와 같 다 . 그 후 3 차 면접 은 관정 이 종환 교육 재단 건물 에서 진행 되 었 다 . 이곳 은 내 가 살 고 있 던 기숙사 와 바로 마주 보 는 건물 이 었 다 . ... 그것 도 모르 고 대학 생활 을 했 다 . 편하 게 이 곳 에 도착 하 는 방법 은 1 . 1 호 선 탑 승시 : 종로5가역 에서 하차 -> 종로 08 버스 2 . 4 호 선 탑 승시 : 혜화 역 에서 하차 -> 종로 08 버스 이 다 . 종로 08 번 버스 를 타 고 홈플러스 앞 에서 내리 면 된다 . 길 이 네비 에 안 찍힌 다면 ' 장면 가옥 ' 을 찍 고 오 면 된다 . 면접 때 는 자기 소개 / 연구 능력 및 자질 ( 학부 에서 석사 로 올라가 는 데 , 연구 를 잘 할 수 있 겠 습니까 ? ) / 자기 소개서 & 연구 계획서 기반 질문 ( 나 는 왜 경영학 에서 수학 복수 전공 했 니 ? ) / 유학 을 가 고자 하 는 이유 / 포부 이렇게 다섯 가지 를 물 어 보 셨 다 . 결론 적 으로 는 최종 합격 하 였 다 . 마지막 면접 을 준비 하 기 전 까지 는 많이 떨렸 는데 , 막상 면접 을 보 고 나 니 후련 했 다 . 아직 장학 증서 수여식 을 가 지 않 아 어떤 부분 이 어필 되 었 는지 는 모르 겠 지만 , ' 공부 를 하 겠 다는 의지 ' 가 가장 중요 했 던 것 이 아닌가 싶 다 . 국비 의 경우 여러 분야 로 지원 할 수 있 는 것 이 나누 어 져 있 으며 , 나 는 공공복지 분야 로 지원 하 였 다 . 국비 장학생 의 경우 자신 의 전공 에 맞 는 분야 를 선택 해야 하 는데 , 생물 통계학 의 경우 세부 전공 에 따라서 생물학 으로 , 공공복지 로 , 또는 빅 데이터 로 선택 할 수 있 다 . 나 의 경우 는 공공복지 를 선택 했 다 . 우선 하버드 의 생물 통계학 과 는 보건 대학원 에 소속 되 어 있 기 때문 이 기 도 하 고 , 들리 는 소문 에 따르 면 자연 과학 과 기반 산업 의 경쟁 률 이 훨씬 높 다고 들 었 기 때문 이 다 . 하버드 나 mit 물리학 박사 과정 을 이길 자신 이 없 기 도 했 다 . .. ㅋㅋ ㅋㅋ 공공복지 분야 , 특히 맞춤 형 웰 니스 케어 로 분야 를 선택 한 만큼 그 분야 에 맞추 어서 자기 소개서 와 연구 계획서 를 작성 하 였 다 . 근데 서류 에서 탈락 하 였 다 . 들리 는 소문 에 는 경쟁 률 이 30 : 1 을 넘어갔 다고 하 는데 . . 빡세 기 도 하 고 주변 의 사례 를 보 면 이미 대학원 에 합격 한 사람 보다 는 , 아직 대학원 에 합격 하 지 않 은 사람 을 위주 로 선발 하 는 듯 하 다 . 국비 장학금 을 들 고 박사 과정 에 어 플라이 하 면 합격 확률 이 더 높 아 지 니까 . .. 아산 은 서류 탈락 해서 별로 도울 말 은 없 지만 , 아산재단 의 의생 명장 학금 의 경우 신입 학생 뿐 만 아니 라 재학 생 도 뽑 기 때문 에 아무래도 신입 학생 이 경쟁 에서 밀릴 가능 성 이 높 다고 생각 한다 . 특히 나 석사 과정 으로 입학 하 는 나 는 연구 경력 이 거의 없 기 때문 이 다 . .. 나중 에 논문 많이 쓰 고 지원 해야 겠 다 . - - - - - - - - - - - - - - - - - - - - - - - - - - ------------------------- 어차피 장학 재단 에서 받 는 장학금 은 중복 수혜 가 안 되 기 때문 에 한 군데 만 되 면 좋 겠 다고 생각 했 는데 정말 한 군데 만 되 었 다 . 다행 이 다 . .. 학비 걱정 을 크 게 덜 었 고 , 이제 열심히 공부 할 준비 만 하 면 될 듯\",\n",
       "       '[ 김범준 의 인간 관계 의 물리학 ] ⑫ 성과 이름 ‘ 영자 의 전성시대 ’ 는 길 어야 30 년 # 문학 작가 들 중 에 도 필명 을 쓰 는 분 들 이 있 다 . 우리 나라 에서 현재 활동 하 는 문학 작가 들 의 이름 을 모아서 이름 의 다양 성 을 일반인 과 비교 해 봤 다 . 독자 도 예상 할 수 있 듯이 작가 의 이름 이 일반인 보다 더 다양 했 다 . 본명 과 다른 필명 을 쓰 는 남성 작가 는 약 6 . 4 %, 여성 작가 는 12 % 정도 라는 결과 를 얻 었 다 . 홍보 포스터 . 영화사 토호 · 코믹스 웨이브 필름 제공 북적이 는 삼겹살 집 에서 큰 목소리 로 “ 김 사장 님 ! ” 하 고 외쳐 보 라 . 장담 은 못 하 지만 , 아마도 적어도 몇 분 은 고개 를 돌려 쳐다볼 것 이 분명 하 다 . 남산 에서 돌 던지 면 김 서방 이 맞 는다는 것 도 마찬가지 얘기 다 . 김 씨 가 워낙 많 아 인구 의 20 % 를 넘 기 때문 이 다 . “ 김 대통령 ” 이 라 하 면 전직 대통령 중 누구 를 말 하 는지 다시 되물 어야 한다 . 우리 나라 성씨 는 다양 하 지 않 아 성만 으로 는 누군지 알 기 어렵 다 . 성씨 와 함께 이름 을 얘기 해야 “ 아 , 그분 ! ” 하 고 누구 인지 알 수 있 는 것 이 우리 나라 다 . 인터넷 에서 “ 김 교수 ” 로 는 나 를 찾 을 수 없 지만 , “ 김범준 교수 ” 를 검색 하 면 내 가 보인다 . 성씨 가 다양 하 지 않 은 우리 사회 에서 한 사람 을 다른 사람 과 구별 하 려면 당연히 이름 은 다양 해야 한다 . 우리 나라 를 제외 한 절대다수 의 외국 은 다르 다 . 오바마 , 트럼프 등 미국 대통령 은 굳이 이름 을 얘기 하 지 않 고 성씨 만 으로 도 누구 를 지칭 하 는지 쉽 게 안다 . 성씨 가 다양 한 서양 에서 는 성만 으로 도 사람 을 구별 할 수 있 을 때 가 많 아 굳이 이름 이 다양 할 필요 는 없 다 . 기독교 가 과거 인구 의 절대다수 의 종교 였 던 나라 들 에서 는 지금 도 여전히 예수 의 제자 나 성인 의 이름 을 딴 이름 이 많 다 . 내 가 아 는 ‘ 피터 ’( peter , 예수 의 제자 베드로 ) 만 여럿 이 다 . 우리 나라 의 성씨 와 이름 에 대한 과학 연구 분야 에선 나 와 공동 연구자 들 이 세계 적 권위자 임 이 분명 하 다 . 놀랄 필요 전혀 없 다 . 이 연구 를 하 는 과학자 가 극히 드물 어 누구 나 권위 자기 때문 이 다 . 이 글 을 읽 는 독자 가 지금 이 라도 이 분야 에 관심 을 가져 연구 를 시작 한다면 세계 에서 열 손가락 에 들 수 있 다 . 그림 1 . 1500 년 대 부터 현대 까지 우리 나라 이름 의 분포 꼴 은 거의 변하 지 않 았 다 . 일직선 을 따라 줄어드 는 지수 함수 꼴 이 다 . 우리 나라 만 이런 가 는 꼬리 를 보여준다 . 김범준 제공 성 이 적 어 이름 이 다양 한 한국인 우리나라 통계청 에서 발표 한 사람 들 의 성씨 목록 에서 관심 이 시작 됐 다 . 김 · 이 · 박 의 순서 로 가로축 에 각 성씨 의 등수 를 , 세로축 에 는 그 성씨 를 가진 사람 의 수 를 그래프 로 그리 면 어떤 모습 이 될까 궁금 했 다 . 이런 식 으로 그래프 를 그려 보 는 시도 는 무척 흔하 다 . 여러 도시 를 인구 에 따라 등수 를 매겨 그리 거나 , 셰익스피어 희곡 을 모아 등장 한 영어 단어 의 빈도 를 가지 고 등수 를 매겨 그래프 로 그리 면 , 두터운 꼬리 를 가진 모습 ( 지난번 연재 글 , “ 부 의 편중 을 줄이 는 방법 ” 참조 ) 이 나온다 . 우리 나라 성씨 는 달랐 다 . 지수 함수 꼴 로 줄어들 어 가 는 꼬리 를 보여준다 ( ) . 재밌 게 도 우리 나라 만 이렇 다 . 대부분 의 다른 나라 의 성씨 분포 는 두터운 꼬리 를 가진다 . 우리 나라 는 정말 독특 하 다 . 과거 의 성씨 분포 도 궁금 했 다 . 과거 가 어땠 는지 어떻게 알 수 있 을까 . 연구원 들 과 함께 이 주제 를 “ 성씨 의 고고학 ” 이 라 불렀 다 . 선조 들 은 오랜 기간 집안 의 역사 를 체계 적 으로 정리 하 고 기록 해 후손 에게 물려줬 다 . 바로 , 족보 다 . 물론 한 집안 족보 의 남성 은 성씨 가 모두 같 지만 , 족보 에 는 그 집안 에 시집 온 여성 의 이름 도 함께 담겨 있 다 . 족보 에 수록 된 며느리 들 의 정보 를 추적 하 면 , 과거 특정 시기 의 성씨 의 정보 를 알 수 있 다 . 조선 초 에서 현재 에 이르 기 까지 , 시대 별 성씨 분포 는 지금 과 같 았 다 ( ) . 500 년 전 에 도 우리 나라 성씨 분포 는 지수 함수 를 따라 줄어드 는 꼴 이 었 다 . 간단 한 수학 모형 을 적용 해 성씨 분포 를 설명 할 수 도 있 었 다 . 모형 과 이론 을 통하 면 관찰 된 현상 의 원인 을 추적 하 는 데 큰 도움 이 된다 . 행성 이 타원 궤도 를 따른다는 관찰 은 , 뉴턴 의 법칙 에 의해 잘 설명 된다 . 나아가 뉴턴 의 법칙 은 다른 모양 의 궤도 도 가능 하 다는 것 을 알려준다 . 마찬가지 다 . 고안 한 모형 을 통해 , 우리 나라 의 독특 한 성씨 분포 의 원인 을 찾 을 수 있 었 다 . 아버지 와 다른 성씨 를 아들 이 새로 만드 는 것 이 거의 불 가능 한 전통문화 가 명확 한 그 이유 다 . 일단 모형 을 완성 하 면 , 다른 것 도 살펴볼 수 있 다 . 모형 에서 아들 이 다른 성씨 를 새롭 게 만드 는 것 이 일정 확률 로 가능 하 다고 가정 하 면 , 다른 여러 나라 와 같 은 두터운 꼬리 를 가진 성씨 분포 가 얻 어 졌 다 . 그림 2 . 우리 나라 여성 이름 의 유행 곡선 . 가장 널리 유행 했 을 때 를 가로축 의 0 으로 , 그때 의 빈도 를 세로축 의 1 로 하 고 , 여러 이름 을 평균 냈 다 . 이름 의 유행 은 약 30 년 정도 지속 된다 . 김범준 제공 관심 의 폭 을 넓혀 성 이 아닌 이름 을 자세히 연구 하 기 도 했 다 . 성 씨 는 바꾸 지 못하 니 사람 들 은 보통 이름 을 가지 고 자신 을 다른 이 와 구별 한다 . 이름 도 옷차림 과 마찬가지 로 유행 을 탄다 . 이름 이나 옷 이나 , 우리 는 누구 나 다른 이 와 구별 되 면서 도 너무 다르 지 는 않 은 것 을 주로 택한다 . 나 처럼 둔감 한 사람 은 눈치채 기 어려워도 , 아마도 옷차림 의 유행 은 매해 달라지 고 있 을 거 다 . 올해 유행 은 작년 과 비슷 하 지만 10 년 전 과 는 확연히 다르 다 . 그럼 , 이름 은 어느 정도 의 시간 을 가지 고 유행 이 변할까 . 여러 이름 을 모아 평균 곡선 을 그려 살펴봤 다 ( ) . 처음 등장 한 이름 은 시간 이 지나 면서 점점 널리 쓰이 게 되 고 , 가장 유행 한 시점 을 지나 면 그 빈도 가 시간 에 따라 줄어든다 . 이름 유행 에 관련 된 시간 도 계산 해 봤 다 . 한 세대 인 30 년 정도 다 . 할머니 나 어머니 세대 에 유행 했 던 이름 을 따라 딸 의 이름 을 정하 는 것 은 외국 에서 는 몰라도 우리 나라 에서 는 아주 드문 일 이 다 . 이름 의 유행 지속 시간 이 30 년 이 라는 결과 가 그럴듯해 보이 는 이유 다 . 그림 3 . ‘ 순 ’, ‘ 자 ’, ‘ 숙 ’, ‘ 희 ’ 로 끝 나 는 여성 이름 의 빈도 의 변천 . 일본식 성명 강요 로 40 년 대 ‘ 자 ’ 로 끝 나 는 이름 의 비율 이 급격히 증가 했 고 해방 후 천천히 감소 했 다 . 창씨개명 은 ‘ 순 ’ 을 줄이 고 ‘ 자 ’ 를 확연히 늘렸 다 . ‘ 순 ’, ‘ 자 ’, ‘ 숙 ’, ‘ 희 ’ 의 차례 로 유행 한 이름 이 변했 다 . 김범준 제공 여성 의 이름 을 모아 20 세기 초 이후 이름 의 다양 성 이 어떻게 변했 는지 도 살펴봤 다 . 1940 년 대 에 들 어서 여성 이름 의 다양 성 이 급격히 줄어들 었 고 1950 년 대 이후 이름 의 다양 성 이 다시 이전 의 수준 을 천천히 회복 했 다 . 1940 년 대 의 다양 성 감소 의 원인 을 당시 의 유행 이름 을 보 면 쉽 게 알 수 있 었 다 . 바로 , 일제 에 의해 강제 된 일본식 성명 강요 로 일본식 이름 을 사람 들 이 많이 썼 기 때문 이 었 다 ( ) . 일제 치하 를 살 았 던 , 이제 는 돌아가 신 아버지 께 일본식 성명 강요 에 대해 여쭤본 적 이 있 다 . 종이 에 적 어 주 신 메모 가 지금 도 내 게 있 다 . 우리 나라 가 독립 하 지 못했 다면 지금 내 성씨 는 ‘ 김 ’ 이 아닌 ‘ 金 岩 ( 가 나이 와 ) ’ 다 . 필명 으로 다양 한 작가 명 최근 에 도 이름 에 대한 연구 를 한 것 이 있 다 . 본명 이 아닌 가명 으로 활동 하 는 연예인 이 많 다 . 문학 작가 중 에 도 필명 을 쓰 는 분 들 이 있 다 . 이미 활동 하 고 있 는 작가 와 본명 이 같 은 경우 , 새로 활동 을 시작 하 는 작가 중 에 는 필명 을 본명 과 다르 게 하 는 작가 가 있 을 수 있 다 . 우리 나라 에서 현재 활동 하 는 문학 작가 들 의 이름 을 모아서 이름 의 다양 성 을 일반인 과 비교 해 봤 다 . 작가 중 서로 다른 이름 이 몇 개 나 있 는지 를 세 고 , 동수 의 일반인 에게서 발견 되 는 서로 다른 이름 의 수 와 비교 해 보 는 간단 한 방법 을 썼 다 . 독자 도 예상 할 수 있 듯이 작가 의 이름 이 일반인 보다 더 다양 했 다 . 본명 과 다른 필명 을 쓰 는 남성 작가 는 약 6 . 4 %, 여성 작가 는 12 % 정도 라는 결과 를 얻 었 다 . 서로 다른 이름 의 숫자 를 비교 한 결과 여서 , 작가 중 누가 필명 을 쓰 는지 는 전혀 알 수 없 지만 , 본명 과 다른 필명 을 쓰 는 작가 가 얼마나 있 는지 는 알 수 있 었 다 . 호기심 으로 시작 한 연구 , 혹은 호기심 으로 추동 된 연구 ( curiosity - driven research ) 라는 얘기 가 있 다 . 노벨 상 을 받 기 위해서 나 , 남 들 이 첫 손 으로 꼽 는 저명 한 학술지 에 논문 을 출판 하 기 위해서 나 , 공학 적 이용 이나 경제 적 가치 를 목표 로 해서 가 아니 라 , 그냥 궁금 해서 시작 한 연구 라는 뜻 이 다 . 오늘 소개 한 우리나라 성씨 와 이름 에 대한 연구 가 사실 이런 연구 다 . 내 연구 그룹 에서 는 또 , 학회 추동 연구 ( conference - driven research ) 라는 얘기 도 재밌 게 하 곤 한다 . 과학 분야 의 학회 에서 는 진행 중 인 연구 를 미완성 상태 에서 발표 하 기 도 한다 . 논문 이 완결 되 기 전 에 다른 과학자 의 비평 을 들 을 좋 은 기회 다 . 학회 에 참석 하 려면 발표 내용 을 요약 한 초록 을 학회 일 한참 전 에 제출 해야 한다 . 연구 의 주제 는 정해졌 고 대강 의 결과 는 있 지만 , 초록 을 제출 하 는 시점 에 아직 결론 이 확실 하 지 않 을 때 가 , 부끄럽 지만 간혹 있 다 . 이럴 때 는 초록 을 제출 하 고 나 서 학회 날짜 가 다가오 면 본격 적 으로 연구 를 서두르 게 되 는데 , 바로 이런 연구가 “ 학회 추동 ” 연구 다 . 이번 연재 글 에서 우리 그룹 의 신조어 가 만들 어 졌 다 . 바로 “ 칼럼 추동 연구 ( column - driven research ) ” 다 . 다가오 는 칼럼 마감 일 에 맞춰 부랴부랴 데이터 를 수집 하 고 모형 을 만들 어 계산 하 는 일 이 잦 았 다 . 3 c 중 첫 번 째 c 인 호기심 추동 연구 로 시작 했 지만 , 결국 은 세 번 째 c 인 칼럼 추동 연구 로 변질 하 여 진행 된 적 이 많 았 다 . 궁금 한 것 많 은 교수 의 칼럼 추동 연구 에 발맞춰 함께 서둘러 준 이대경 , 이송 섭 , 양 성규 연구원 에게 깊 은 고마움 을 전한다 . ‘ 김범준 의 인간 관계 의 물리학 ’ 연재 를 마친다 .',\n",
       "       '활용 사례 내용 공 적 마스크 재고 현황 알림 서비스 공 적 마스크 판매처 · 판매 현황 ( 건강 보험 심사 평가 원 ) , 공 적 마스크 판매처 정보 제공 서비스 ( 한국 정보 화 진 흥원 ) 를 활용 해 약국 별 코로나 19 방역 공 적 마스크 재고 현황 을 제공 함 으로써 국민 비상사태 대응 및 편의 성 제고 미세먼지 정보 앱 대기 정보 데이터 ( 한국환경공단 , 기상청 등 ) 와 gps 기술 을 융합 하 여 실시간 으로 지역 별 미세먼지 농도 정보 를 업데이트 하 여 호흡기 질환 을 예방 할 수 있 도록 정보 제공 대중교통 도착 시간 알림 서비스 지하철 정보 서비스 , 실시간 도착 정보 ( 국토 교통부 , 서울특별시 ) , 버스 노선 · 도착 정보 조회 서비스 ( 경기도 ) 등 을 활용 하 여 대중교통 이용자 의 대기 시간 감소 병원 · 약국 정보 서비스 병원 정보 서비스 ( 건강 보험 심사 평가 원 ) 를 통해 주변 병원 의 위치 와 진료 정보 등 을 제공 주차장 정보 앱 자치 구별 주차장 현황 ( 국토 교통부 , 서울특별시 ) 을 활용 하 여 주변 의 주차장 위치 와 요금 등 을 한 곳 에 모아서 제공 화장품 정보 제공 앱 화장품 원료 및 성분 정보 ( 식품 의 약 품안 전처 ) 데이터 를 활용 · 가공 하 여 소비자 가 화장품 성분 을 쉽 게 이해 하 고 적합 한 화장품 을 합리 적 으로 구매 할 수 있 도록 도움 제공',\n",
       "       '정책 의 외부 효과 ( policy externalities ) 염재호 ( 고려대 학교 행정학 과 교수 ) 일반 적 으로 정책 이론 에서 외부 효과 를 이야기 할 때 에 는 개인 이나 시장 의 합리 적 행위 가 의도 하 지 않 은 결과 를 나타낼 때 이 를 보정 하 기 위해 정부 의 개입 을 정당 화 하 는 논거 로 이해 한다 . 시장 실패 의 대표 적 현상 으로서 개인 의 의도 하 지 않 은 행위 가 사회 에 부정 적 인 결과 를 초래 하 게 될 때 부정 적 외부 효과 ( negative externality ) 라고 한다 . 예 를 들 어 공해 의 문제 나 공 유재 의 비극 에서 나타나 는 현상 은 대표 적 인 부정 적 외부 효과 이 다 . 반면 에 연구 개발 과 같 은 경우 는 긍정 적 외부 효과 ( positive externality ) 로서 개인 의 의도 하 지 않 은 행위 가 공공 의 이익 을 증진 시키 는 결과 를 초래 한다 . 이 두 경우 모두 개인 이나 시장 의 합리 적 행위 에 만 맡겨 두 면 전체 적 인 합 으로서 공공 성 이 제약 되 거나 비 효율 적 으로 나타나 기 때문 에 정부 의 적극 적 인 개입 이 필요 하 다는 논거 를 제공 하 게 된다 . 하지만 이 처럼 개인 이나 시장 에서 합리 적 인 행위 의 결과 로 나타나 는 외부 효과 뿐 아니 라 정부 가 추진 하 는 정책 에 도 외부 효과 가 종종 나타나 게 된다 ( bown & crowley , 2006 ) . 따라서 정책 현상 을 연구 하 는데 있 어서 이 에 대한 체계 적 인 분석 과 대안 이 필요 하 다 . 정책학 에서 는 효율 적 인 정책 결정 을 하 기 위해 다양 한 분석 기법 들 과 수단 들 이 논의 되 고 있 다 . 제한 된 자원 과 환경 의 제약 하 에서 가장 바람직 하 고 합리 적 인 정책 을 만들 기 위해 정책 결정자 들 은 고심 하 게 된다 . 정책학 자 들 도 정책 분석 론 과 정책 평가 론 등 에서 가급적 이 면 합리 적 인 정책 수단 을 마련 하 기 위한 다양 한 이론 적 논의 를 제공 하 고 있 다 . 하지만 합리 적 정책 선택 이 언제나 합리 적 인 정책 결과 를 갖 고 오 는 것 은 아니 다 . 정책 은 살 아 있 는 유기체 와 같 아서 아무리 합리 적 인 방법 으로 정책 을 선택 했 다고 하 더라도 정책 이 집행 되 고 운영 되 는 과정 에서 다양 하 게 변화 하 게 된다 . 심지어 전혀 의도 하 지 않 은 결과 가 나타나 기 도 하 고 처음 에 는 반대 도 심하 고 효율 성 이 떨어지 는 것 같 은 정책 이 환경 의 변화 에 의해 매우 바람직 한 결과 를 나타내 기 도 한다 . 이러 한 정책 의 변형 및 변화 에 대한 현상 은 다양 한 분석 을 통해 접근 할 수 있 다 . 가장 대표 적 으로 나타나 는 현상 은 1970 년 대 에 논의 된 합리 적 인 정책 결정 이 반드시 기대 하 던 정책 집행 이 이루어지 지 않 아 나타나 는 정책 집행 의 문제 였 다 . pressman 과 wildavsky 에 의해 제기 된 정책 결정 과정 에서 다양 한 참여 자 가 정책 결정 에 참여 하 게 될 때 소위 참여 자 사이 에 나타나 는 거 부점 ( veto point ) 으로 인해 정책 집행 이 정책 결정 에서 의도 한 결과 를 나타내 지 못 하 는 것 이 다 ( pressman & wildavsky , 1973 ) . 하지만 이 와 못지않 게 정책 의 효율 성 과 효과 성 을 생각 할 때 문제 가 되 는 것 은 합리 적 이 라고 생각 했 던 정책 이 의도 하 지 않 은 다양 한 결과 를 초래 하 게 되 는 정책 의 외부 효과 문제 이 다 . 이것 은 정책 이 사회 의 문제 를 해결 하 기 보다 는 오히려 새로운 문제 를 발생 시키 는 역효과 를 나타내 고 비 효율 을 증대 시키 는 현상 으로 나타나 게 된다 . 최근 한국 에서 나타난 몇 가지 사례 는 눈여겨 볼 만 하 다 . 첫 번 째 사례 : 과학 기술 연구 개발 의 pbs 제도 pbs 제도 는 정부 가 연구 개발 의 효과 성 을 높이 기 위해 프로젝트 중심 의 연구 지원 시스템 을 도입 한 것 이 다 . 원래 는 정부 출연 연구소 에 대해 정부 가 예산 배정 을 하 고 , 연구소 별 로 연구 주제 를 정하 고 연구 개발 사업 을 추진 하 던 것 에서 이 처럼 변하 게 된 것 은 나름 대로 의 합리 성 을 갖 고 있 었 다 . 즉 국가 연구 개발비 에 있 어서 정부 와 민간 의 투자 비율 이 역전 되 면서 정부 의 연구 개발비 의 효율 성 을 높이 기 위한 합리 적 인 방 안 으로 제시 된 것 이 다 . 연구 개발 에 있 어서 정부 출연 연구소 의 자율 성 을 일부 제약 하 게 되 지만 정부 출연 연구소 의 연구 에 활력 을 불어넣 고 연구 의 경쟁력 을 강화 하 겠 다는 것 이 다 . pbs 제도 를 통해 정부 는 출연 연구소 에 경상비 에 해당 하 는 일정 액수 만 예산 으로 지원 을 하 고 나머지 는 기업 과 대학 과 정부 출연 연구소 가 연구 개발 프로젝트 에 경쟁 적 으로 참여 하 여 정부 의 연구비 를 수주 하 는 방식 이 다 . 이것 은 한편 으로 는 출연 연구소 가 연구원 들 의 개별 적 인 연구 성과 보다 는 정부 의 연구 개발 정책 목표 에 부합 하 는 연구 에 집중 할 수 있 도록 유도 하 고 , 다른 한편 으로 는 민간 및 대학 의 연구자 들 과 경쟁 을 통해 정부 출연 연구소 연구원 들 의 연구 성과 를 높이 겠 다는 것 이 다 . 하지만 이러 한 정책 의 외부 효과 는 연구비 를 배정 하 는 정부 부처 공무원 들 의 영향력 이 강화 되 는 결과 를 초래 했 다 . 프로젝트 를 발주 하 는 각 부처 의 사무관 들 이 연구 의 세부 적 인 과제 까지 관여 하 고 결정 하 게 됨 으로써 연구 개발 정책 의 관료제 화 를 더욱 촉진 시키 게 되 었 다 . 부처 에서 는 다양 한 분야 별 연구 프로젝트 를 관장 해야 하 기 때문 에 엄청난 인원 이 필요 하 게 되 고 , 이 에 따른 행정 관리 비용 이 급증 하 게 된다 . 한편 출연 연구소 의 소장 들 은 각 부처 로부터 더 많 은 연구비 를 수주 하 기 위해 부처 와 의 협의 등 에서 많 은 정치력 을 요구 받 게 되 었 다 . 또한 정부 출연 연구소 의 연구 가 장기 적 인 관점 의 연구 보다 는 단기 적 인 프로젝트 중심 의 연구 가 되 어서 출연 연구소 의 연구 방향 의 일관 성 이나 정체 성 의 문제 가 제기 되 기 도 한다 . 물론 pbs 제도 가 초래 한 긍정 적 인 측면 도 있 지만 , 결국 매우 혁신 적 이 고 합리 적 인 정책 이 집행 과정 에서 왜곡 되 고 변질 되 어서 부정 적 인 외부 효과 로 나타나 기 도 하 는 것 이 다 ( 길 종백 외 , 2009 ) . 두 번 째 사례 : 감사 의 나비 효과 몇 년 전 모 대학 의 연구비 영수증 이 부적절 하 게 보 고 되 었 다는 감사 지적 사항 이 언론 에 크 게 보도 되 었 다 . 총 약 삼 천만 원 의 영수증 이 연구 와 관련 이 없 는 영수증 이 전체 연구비 영수증 에 포함 되 었 다는 것 이 다 . 이 를 두 고 언론 에서 는 정부 에서 지원 하 는 연구비 가 유용 되 고 있 고 연구 관리 가 허술 하 고 세금 이 새 고 있 다고 크 게 질책 을 하 며 보도 를 했 다 . 이렇게 되 면 당연히 해당 대학 은 연구비 영수증 의 관리 를 보다 꼼꼼 하 게 하 기 위해서 연구 관리 시스템 을 강화 하 게 된다 . 연구비 영수증 을 체크 하 는 직원 을 두 세 명 산학 협력 단 에 고용 하 여 이 를 관리 하 게 하 는데 이 과정 에서 관료 제 의 역기능 이 두드러진다 . 교수 들 이 쓰 는 연구비 의 영수증 이 교수 카드 만 쓰 게 되 어 있 어서 은행 에서 그 명세 가 자세히 나옴 에 도 불구 하 고 영수증 을 별도 로 제출 하 여 관리 하 게 된다 . 심지어 연구비 로 구입 한 서적 은 표지 앞뒤 면 을 복사 하 고 isbn 번호 까지 적 어서 제출 해야 한다 . 산학 협력 단 관리 직원 들 이 서적 이 연구 에 필요 한 것 인지 아닌지 를 직접 평가 하 기 도 한다 . 더 나아가 연구 회의 는 대학 에서부터 반경 몇 km 이내 의 식당 에서 이루어진 것 만 인정 하 는 대학 도 있 다고 한다 . 하지만 이러 한 연구비 관리 강화 정책 은 합리 적 인 것 처럼 보인 지만 실제로 는 매우 비합리 적 인 정책 이 된다 . 앞 의 예도 일 년 에 약 삼 천억 정도 의 연구비 를 집행 하 는 대학 에서 나온 결과 인데 삼 천만 원 정도 의 영수증 제출 의 착오 나 오류 는 비율 로 보 면 0 . 01 % 에 해당 하 는 극히 미미 한 것 이 다 . 하지만 이 를 해결 하 기 위해 관리 하 는 행정 직원 을 두 세 명 고용 하 게 되 면 연 약 일 억 원 에 가까운 연봉 이 지출 되 게 된다 . 그러 한 현상 은 해당 대학 에 국한 되 는 것 이 아니 고 전국 에서 연구 를 수행 하 는 백여 개 에 해당 되 는 대학 에서 그러 한 방식 으로 연구비 를 관리 하 게 되 면 수십 억 에 달하 는 행정 관리 비용 이 증대 된다 . 물론 이것 은 교수 나 조교 들 이 부담 하 게 되 는 행정 비용 을 제외 하 고 순수 하 게 연구비 관리 를 위해 추가 로 고용 된 인력 에 드 는 비용 만 을 고려 한 것 에 불과 하 다 . 결국 감사 에 의해 추진 된 철저 한 연구비 관리 는 마치 나비효과 와 마찬가지 로 의도 하 지 않 게 엄청난 행정 비용 과 번문욕례 라고 하 는 다양 한 외부 효과 를 나타내 게 된다 . 과연 이런 정책 대응 이 효과 적 이 고 바람직 한 것 인가 ? 세 번 째 사례 : 벤처 기업 육성 정책 첨단 기술 이 고부 가 가치 를 낳 고 국가 의 장기 적 인 경쟁력 을 강화 한다는 측면 에서 정부 가 벤처 기업 육성 을 적극 적 으로 추진 한 적 이 있 다 . 벤처 기업 이 기술 을 갖 고 있 지만 이 를 상업 화 하 는 데 많 은 자본 이 필요 하 기 때문 에 정부 가 적극 적 으로 지원 하 여 육성 한다는 것 이 었 다 . 많 은 기술력 을 가진 사람 들 이 벤처 기업 을 만들 었 고 , 대학 에서 도 이공 계 교수 들 이 벤처 기업 에 투신 하 기 도 했 다 . 하지만 이러 한 정부 의 정책 은 오히려 벤처 기업 의 육성 을 저해 했 다는 비판 을 받 고 있 다 . 벤처 기업 은 미국 의 실리콘 밸리 에서 나타난 것 처럼 기본 적 으로 시장 에서 위험 성 을 감수 하 고 엄청난 수익 이 나타날 가능 성 을 전제 로 해서 투자가 들 이 과감 하 게 투자 하 는 메커니즘 을 갖 고 있 다 . 따라서 투자가 나 사업가 모두 엄청난 위험 성 을 전제 로 하 고 동시 에 엄청난 책임감 에 시달리 면서 사업 을 운영 하 게 된다 . 하지만 정부 에서 이 처럼 안정 적 인 자본 을 제공 하 게 되 면 벤처 사업가 들 은 쉽 게 도덕 적 해이 에 빠지 게 된다 . 즉 사업 의 효과 보다 는 정부 지원 을 확보 하 기 위해 더욱 많 은 노력 을 들인다 . 벤처 기업 은 위험 성 과 불 확실 성 을 전제 로 한 것 이 기에 치열 한 시장 의 경쟁 에서 살아남 아야 하 는데 정부 의 관료 가 부족 한 정보 로 이 를 판단 하 여 지원 한다는 것 은 결국 벤처 기업 의 창의 적 이 고 도전 적 인 정신 을 저해 하 고 정부 지원 을 확보 하 기 위한 정치 적 게임 이 되 는 결과 를 초래 한다 . 비슷 한 예 는 프랑스 의 전자 산업 육성 에서 정부 의 정책 지원 이 얼마나 비 효과 적 이 었 는가 하 는 사례 에서 이미 잘 나타났 다 ( zysman , 1977 ) . 이 처럼 정책 의 외부 효과 는 다양 하 게 나타난다 . 물론 정책 을 결정 할 때 미래 의 결과 에 대해 사전 적 으로 파악 하 고 미래 의 조건 들 을 모두 고려 하 는 것 은 불 가능 하 다 . 특히 사회 현상 을 다루 는 정책 의 경우 는 미래 의 특성 이 불 확실 성 ( uncertainty ) 과 복잡 성 ( complexity ) 과 개인 과 조직 의 반응 성 ( reactivity ) 으로 인해 전혀 의도 하 지 않 은 방향 으로 전개 될 수 있 다 . 또한 과학기술정책 이나 금융정책 , 교육 정책 처럼 그 효과 에 대한 비용 의 판단 이 쉽 지 않 거나 두드러지 지 않 는 경우 에 많 은 정책 의 부정 적 외부 효과 가 숨겨져 있 는 것 이 사실 이 다 . 따라서 정책 연구 에서 는 현재 미시 적 인 차원 에서 효율 성 만 을 고려 하 여 정책 을 분석 하 는 것 에서부터 보다 거시 적 이 고 종합 적 인 차원 에서 정책 분석 을 해야 한다 . 정책 결정 을 하 는 과정 에서 기존 에 는 실시 하 지 않 던 환경영향평가 나 교통 영향 평가 와 같이 사전 평가 작업 이 일부 시행 되 고는 있 지만 보다 광범위 한 정책 의 외부 효과 에 대한 연구 와 분석 이 필요 하 다 . 정책 결정 과정 에서 의 합리 성 과 단기 적 관점 에서 의 효율 성 이 장기 적 으로 얼마나 많 은 행정 비용 과 시민 의 부담 을 증대 시키 는가 는 imf 외환 위기 , 신용카드 정책 , 펀드 정책 , kiko 정책 등 에서 이미 경험 한 바 가 크 다 . 정책학 이 사회 의 비 효율 을 줄이 고 다양 한 사회 적 문제 를 해결 하 는 응용 학문 이 라고 한다면 이러 한 정책 의 외부 효과 에 대한 연구 는 더욱 심도 있 게 추진 되 어야 할 것 이 다 . 참고 문헌 길 종백 · 정병걸 · 염재호 . ( 2009 ) . 정부 출연 연의 대리 문제 와 pbs 의 한계 . 「 한국 조직학 회보 」 , 6 ( 2 ) : 179 - 202 . pressman , jeffrey l . & aaron wildavsky ( 1973 ) implementation ( berkeley , ca : university of california press ) bown , chad p . & meredith a . crowley ( 2006 ) \" policy externalities : how us antidumping affects japanese exports to the eu , \" european journal of political economy , vol . 20 , no . 3 . zysman , john ( 1977 ) political strategies for industrial order : state , market , and industry in france ( berkeley , ca : university of california press )',\n",
       "       '8 . 1 레드라인 문제 레드라인 은 케임브리지 와 보스턴 을 연결 하 는 지하철 노선 이 다 . 저자 는 켄달 스퀘어 에서 레드라인 을 타 고 사우스 스테이션 까지 간 다음 니드햄 으로 가 는 통 근선 으로 갈 타 났 다 . 러시아워 때 레드라인 은 평균 매 7 ~ 8 분 간격 으로 운행 했 다 . 역 에 도착 하 면 플랫폼 에서 기다리 는 승객 수 를 기초 로 다음 기차 가 도착 할 때 까지 걸리 는 시간 을 추정 했었 다 . 승객 이 별로 없 다면 직전 기차 를 놓쳤으니 7 분 정도 기다려야 하 고 , 승객 이 어느 정도 있 다면 기차 가 곧 도착 할 것 이 다 . 하지만 승객 이 너무 많 다면 기차 운행 에 문제 가 있 을 것 이 라 생각 하 고 나가 서 택시 를 탔 다 . 이 장 의 코드 는 [ URL ] 얻 을 수 있 고 데이터 를 모으 는 데 에 는 [ URL ] 사용 하 였 다 . 8 . 2 모델 모델링 규칙 을 만들 어 보 자 . 우선 , 승객 은 동일 한 확률 로 도착 하 고 , 이 때 분당 승객 수 가 임의 의 비율 인 상수 $\\\\ lambda $ 인 포 아송 프로세스 를 따른다고 하 자 . 반면 기차 도착 은 포아 송 프로세스 가 아니 다 . 기차 가 7 ~ 8 분 마다 노선 끝 에서 출발 하 여도 캔 달 스퀘어 에 도착 하 는 시간 은 3 분 에서 12 분 까지 다양 하 다 . 기차 시간 간격 에 대한 데이터 수집 을 위해 [ URL ] 데이터 를 참고 하 여 5 일 간 매일 오후 4 시 에서 6 시 까지 의 켄달 스퀘어 근처 의 15 개 의 도착 내역 을 기록 하 였 다 . 그 후 연달 아 도착 하 는 기차 간격 의 시간 을 계산 하 여 z 라고 하 였 다 . 하지만 4 시 에서 6 시 까지 의 분포 와 한 승객 이 도착 하 였을 때 임의 의 시간 에서 관찰 한 분포 는 상당히 다를 것 이 다 . 왜냐하면 승객 이 도착 할 시각 은 시간 간격 이 짧 은 경우 보다 큰 경우 에 도착 할 확률 이 더 높 기 때문 이 다 . 이런 종류 의 관측자 편향 은 많 은 상황 에서 나타난다 . 학생 들 은 대부분 큰 강의실 에 있 기 때문 에 강의실 들 이 실제 보다 더 크 다고 생각 한다 . 항공기 승객 들 은 보통 만석 인 비행기 에 타 기 때문 에 비행기 가 실제 보다 만석 일 경우 가 많 다고 생각 한다 . 각각 의 경우 , 실제 분포 에서 가져온 값 은 실제 값 의 비율 보다 오버 샘플링 된다 . 레드 라인 예제 에서 도 , 실제 관측 결과 보다 시간 간격 이 두 배 정도 크 다 . 이 를 이용 하 여 실제 시간 차 의 분포 가 주 어 졋을 때 승객 들 이 보 는 시간 간격 의 분포 를 계산 할 수 있 다 . def biaspmf ( pmf ) : new _ pmf = pmf . copy ( ) for x , p in pmf . items ( ) : new _ pmf . mult ( x , x ) new _ pmf . normalize ( ) return new _ pmf 1 2 3 4 5 6 7 8 9 def biaspmf ( pmf ) : new _ pmf = pmf . copy ( ) for x , p in pmf . items ( ) : new _ pmf . mult ( x , x ) new _ pmf . normalize ( ) return new _ pmf pmf 는 실제 분포 고 , new _ pmf 는 편향 된 분포 다 . 각 값 에 대하 여 x 에 의해 나온 확률 을 곱 한다 . 8 . 3 대기 시간 y 로 사용 할 대기 시간 은 승객 이 도착 하 고 다음 기차 가 도착 하 는 사이 의 시간 이 다 . x 는 경과 시간 이 다 . 이전 기차 가 도착 하 고 승객 이 도착 한 사이 의 시간 이 다 . 이 를 zb = x + y 라고 정의 하 여 보 자 . zb 의 분포 가 주어지 면 y 의 분포 를 계산 할 수 있 다 . 앞 의 예 에서 , 5 분 일 때 의 zb 는 1 / 3 의 확률 을 , 10 분 에 대해서 는 2 / 3 의 확률 을 가진다 . 5 분 간격 일 때 임의 의 시간 에 도착 한 경우 , y 는 0 에서 5 분 사이 의 균등 분포 를 따른다 . 만약 10 분 간격 이 ㄹ 때 도착 했 다면 y 는 0 에서 10 사이 의 균등 분포 를 따를 것 이 다 . 따라서 전체 분포 는 각 간격 의 확률 이 곱해진 균등 분포 의 혼합 형태 다 . 다음 함수 는 zb 의 분포 를 사용 한 y 의 분포 를 구한다 . def pmfofwaittime ( pmf _ zb ) : metapmf = thinkbayes . pmf ( ) for gap , prob in pmf _ zb . items ( ) : uniform = makeuniformpmf ( 0 , gap ) metapmf . set ( uniform , prob ) pmf _ y = thinkbayes . makemixture ( metapmf ) return pmf _ y def makeuniformpmf ( low , high ) : pmf = thinkbayes . pmf ( ) for x in makerange ( low = low , high = high ) : pmf . set ( x , 1 ) pmf . normalize ( ) return pmf def makerange ( low , high , skip = 10 ) : return range ( low , high + skip , skip ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def pmfofwaittime ( pmf _ zb ) : metapmf = thinkbayes . pmf ( ) for gap , prob in pmf _ zb . items ( ) : uniform = makeuniformpmf ( 0 , gap ) metapmf . set ( uniform , prob ) pmf _ y = thinkbayes . makemixture ( metapmf ) return pmf _ y def makeuniformpmf ( low , high ) : pmf = thinkbayes . pmf ( ) for x in makerange ( low = low , high = high ) : pmf . set ( x , 1 ) pmf . normalize ( ) return pmf def makerange ( low , high , skip = 10 ) : return range ( low , high + skip , skip ) 그리고 이 분포 를 계산 하 는 과정 을 캡슐 화 하 기 위해 waittimecalculator 라는 클래스 를 만들 었 다 . class waittimecalculator ( object ) : def __ init __( self , pmf _ z ) : self . pmf _ z = pmf _ z self . pmf _ zb = biaspmf ( pmf ) self . pmf _ y = self . pmfofwaittime ( self . pmf _ zb ) self . pmf _ x = self . pmf _ y 1 2 3 4 5 6 7 8 class waittimecalculator ( object ) : def __ init __ ( self , pmf _ z ) : self . pmf _ z = pmf _ z self . pmf _ zb = biaspmf ( pmf ) self . pmf _ y = self . pmfofwaittime ( self . pmf _ zb ) self . pmf _ x = self . pmf _ y pmf _ z 는 z 의 비 편향 분포 이 다 . pmf _ zb 는 승객 들 이 본 시간 간격 의 편향 분포 이 다 . pmf _ y 는 대기 시간 의 분포 이 다 . pmf _ x 는 경과 시간 의 분포 로 , 대기 시간 의 분포 와 동일 하 다 . 그 이유 는 x = zp – y 이 기 때문 에 x 의 분포 는 0 부터 zp 까지 의 균등 분포 이 다 . 그 결과 로 z 의 평균 은 7 . 8 분 , zb 의 평균 은 8 . 8 분 이 다 . y 의 평균 은 , 4 . 4 분 이 다 . 8 . 4 대기 시간 예측 내 가 플랫폼 에 도착 했 을 때 10 명 이 대기 하 고 있 는 것 을 봣다 . 그러면 다음 기차 가 도착 할 때 까지 얼마나 기다려야 할까 ? 일단 문제 를 쉬운 형태 로 만든 뒤 확장 하 도록 하 자 . 실제 분포 z 가 있 고 승객 도착 비율 $ \\\\ lambda $ 가 분당 2 명 이 라는 것 을 알 고 있 다고 가정 하 자 . 할 수 있 는 건 다음 과 같 다 . z 의 분포 를 사용 해서 승객 이 보 는 기차 시간 간격 zp 의 사전 분포 를 계산 하 자 . 지난 기차 로부터 의 경과 시간 x 에 대한 분포 추정 을 위해 승객 수 를 사용 할 수 있 다 . 마지막 으로 y = zp – x 관계 를 사용 해서 y 의 분포 를 구한다 . 먼저 승객 수 를 계산 하 기 전 에 zp , x , y 의 분포 를 캡슐 화 하 는 waittimecalculator 를 생성 한다 . wtc = waittimecalculator ( pmf _ z ) 1 2 wtc = waittimecalculator ( pmf _ z ) pmf _ z 는 시간 간격 에 대해 주 어 진 분포 다 . 다음 은 x 의 사후 분포 와 y 의 예측 분포 를 캡슐 화 하 는 elapsedtimeestimator 를 만든다 . ete = elapsedtimeestimator ( wtc , lam = 2 . 0 / 60 , num _ passengers = 15 ) class elapsedtimeestimator ( object ) : def __ init __( self , wtc , lam , num _ passengers ) : self . prior _ x = elapsed ( wtc . pmf _ x ) self . post _ x = self . prior _ x . copy ( ) self . post _ x . update ( ( lam , num _ passengers ) ) self . pmf _ y = predictwaittime ( wtc . pmf _ zb , self . post _ x ) 1 2 3 4 5 6 7 8 9 10 11 ete = elapsedtimeestimator ( wtc , lam = 2 . 0 / 60 , num _ passengers = 15 ) class elapsedtimeestimator ( object ) : def __ init __ ( self , wtc , lam , num _ passengers ) : self . prior _ x = elapsed ( wtc . pmf _ x ) self . post _ x = self . prior _ x . copy ( ) self . post _ x . update ( ( lam , num _ passengers ) ) self . pmf _ y = predictwaittime ( wtc . pmf _ zb , self . post _ x ) lam 은 초당 승객 수 로 나타내 는 승객 도착 비율 , 그리고 num _ passengers 는 관측 된 승객 수이 다 . prior _ x 와 post _ x 는 경과 시간 의 사전 분포 와 사후 분포 다 . pmf _ y 는 대기 시간 의 예측 분포 다 . elapsed 는 가설 분포 를 나타내 는 suite 이 다 . class elapsed ( thinkbayes . suite ) : def likelihood ( self , data , hypo ) : x = hypo lam , k = data like = thinkbayes . evalpoissonpmf ( lam * x , k ) return like 1 2 3 4 5 6 7 class elapsed ( thinkbayes . suite ) : def likelihood ( self , data , hypo ) : x = hypo lam , k = data like = thinkbayes . evalpoissonpmf ( lam * x , k ) return like 우도 의 hypo 는 마지막 기차 이후 경과 시간 이 고 , data 는 lam 과 승객 수 의 튜플 이 다 . 이렇게 계산 된 우도 는 주어진 도착 비율 lam 에 대해 시간 x 에 k 대가 도착 할 확률 이 다 . 여기 서 는 포아 송 분포 를 사용 하 여 계산 하 였 다 . def predictwaittime ( pmf _ zb , pmf _ x ) : pmf _ y = pmf _ zb - pmf _ x removenegatives ( pmf _ y ) return pmf _ y 1 2 3 4 5 def predictwaittime ( pmf _ zb , pmf _ x ) : pmf _ y = pmf _ zb - pmf _ x removenegatives ( pmf _ y ) return pmf _ y pmf _ zb 는 기차 간 의 간격 분포 고 , pmf _ x 는 관측 된 승객 수 에 따른 경과 시간 분포 다 . y = zb – x 이 므로 다음 을 구할 수 있 다 . pmf _ y = pmf _ zb - pmf _ x 1 2 pmf _ y = pmf _ zb - pmf _ x 결과 에 는 음수 에 대한 경우 가 포함 되 어 있 는데 , removenegatives 는 이 를 제거 해 버리 는 기능 을 한다 . def removenegatives ( pmf ) : for val in pmf . values ( ) if val < 0 : pmf . remove ( val ) pmf . normalize ( ) 1 2 3 4 5 6 def removenegatives ( pmf ) : for val in pmf . values ( ) if val & lt ; 0 : pmf . remove ( val ) pmf . normalize ( ) 8 . 5 도착 비율 추정 지금 까지 는 우리 가 간격 분포 와 승객 도착 비율 을 안다는 가정 에서 문제 를 해결 하 였 다 . 여기 서 승객 도착 비율 은 모르 는 상태 를 생각 하 여 보 자 . 막 보스턴 으로 이사 를 와서 승객 도착 비율 을 모른다고 하여보 자 . 따라서 플랫폼 에 도착 하 는 날 마다 시간 과 대기 승객 수 를 기록 하 였 다고 해 보 자 . 다음 은 5 일 간 의 데이터 이 다 . k 1 y k 2 17 4 . 6 9 22 1 . 0 0 23 1 . 4 4 18 5 . 4 12 4 5 . 8 11 k 1 은 도착 했 을 때 의 대기 승객 수 , y 는 분 단위 대기 시간 , k 2 는 대기 하 는 동안 도착 한 승객 수이 다 . $ \\\\ lambda $ 의 사후 분포 를 계산 하 여 보 자 . arrivalrate 는 $\\\\ lambda $ 에 대한 가설 을 나타내 는 suite 이 다 . 가설 은 $ \\\\ lambda $ 의 값 이 며 , 데이터 는 대기 시간 y 와 도착 한 승객 수 k 의 쌍 이 다 . class arrivalrate ( thinkbayes . suite ) : def likelihood ( self , data , hypo ) : lam = hypo y , k = data like = thinkbayes . evalpoissonpmf ( lam * y , k ) return like 1 2 3 4 5 6 7 class arrivalrate ( thinkbayes . suite ) : def likelihood ( self , data , hypo ) : lam = hypo y , k = data like = thinkbayes . evalpoissonpmf ( lam * y , k ) return like class arrivalrateestimator ( object ) : def __ init __( self , passenger _ data ) : low , high = 0 , 5 n = 51 hypos = numpy . linspace ( low , high , n ) / 60 self . prior _ lam = arrivalrate ( hypos ) self . post _ lam = self . prior _ lam . copy ( ) for k 1 , y , k 2 in passenger _ data : self . post _ lam . update ( ( y , k 2 ) ) 1 2 3 4 5 6 7 8 9 10 11 class arrivalrateestimator ( object ) : def __ init __ ( self , passenger _ data ) : low , high = 0 , 5 n = 51 hypos = numpy . linspace ( low , high , n ) / 60 self . prior _ lam = arrivalrate ( hypos ) self . post _ lam = self . prior _ lam . copy ( ) for k 1 , y , k 2 in passenger _ data : self . post _ lam . update ( ( y , k 2 ) ) 8 . 6 결합 불 확실 성 만약 분석 시 입력 값 중 하나 라도 불 확실 한 것 이 있 다면 다음 과 같 은 프로세스 를 고려 할 수 있 다 . 불 확실 한 변수 의 결정 값 을 기반 으로 한 분석 을 구현 한다 . 불 확실 변수 값 의 분포 를 계산 한다 . 변수 의 각 값 에 대해 분석 을 실행 한 후 예측 분포 의 셋 을 설정 한다 . 변수 의 분포 에 가중치 를 주 어 예측 분포 의 혼합 을 계산 한다 . 1 , 2 는 앞 에서 설명 하 였 고 여기 서 는 3 , 4 를 처리 하 여 보 자 . class waitmixtureestimator ( object ) : def __ init __( self , wtc , are , num _ passengers = 15 ) : self . metapmf = thinkbayes . pmf ( ) for lam , prob in sorted ( are . post _ lam . items ( ) ) : ete = elapsedtimeestimator ( wtc , lam , num _ passengers ) self . metapmf . set ( ete . pmf _ y , prob ) self . mixture = thinkbayes . makemixture ( self . metapmf ) 1 2 3 4 5 6 7 8 9 10 class waitmixtureestimator ( object ) : def __ init __ ( self , wtc , are , num _ passengers = 15 ) : self . metapmf = thinkbayes . pmf ( ) for lam , prob in sorted ( are . post _ lam . items ( ) ) : ete = elapsedtimeestimator ( wtc , lam , num _ passengers ) self . metapmf . set ( ete . pmf _ y , prob ) self . mixture = thinkbayes . makemixture ( self . metapmf ) 일반 적 으로 시스템 의 응답 값 이 선형 이 아닌 경우 변동 성 을 포함 하 는 것 은 중요 하 다 . 8 . 7 의사 결정 분석 여기 까지 진행 했 으면 , 대기 시간 의 플랫 폼 의 승객 수 를 사용 하 여 대기 시간 의 분포 를 예측 할 수 있 다 . 그렇 다면 언제 기차 를 기다리 는 것 을 멈추 고 택시 를 잡 으로 가 야 할까 ? 아직 여유 시간 이 15 분 있 다고 가정 해 보 자 . 이러 한 경우 num _ passengers 함수 로 y 가 15 분 이상일 확률 을 알 수 있 을 것 이 다 . 8 . 4 의 분석 을 사용 하 면 된다 . 하지만 , 대기 시간 이 긴 경우 는 드물 어서 분석 내용 이 빈도 에 민감 해 지 는데 , 빈도 를 추정 하 는 것 이 어렵 다 . 가진 데이터 는 1 주일 치 뿐 이 고 , 관측 했 던 가장 긴 대기 시간 이 15 분 이 다 . 대기 시간 이 더 긴 경우 에 는 정확 하 게 추정 할 수 가 없 다 . 하지만 기존 관측 내용 을 토대 로 최소한 대략 적 인 추정 은 할 수 있 다 . 1 년 간 3 개 의 주요 장기 대기 시간 이 있 다고 추정 하 여 보 자 . 하지만 이 관측 은 편향 적 이 다 . 긴 관측 이 많 은 승객 에게 영향 을 끼치 므로 더 관측 하 기 가 쉽 다 . 그러므로 이 관측 은 z 가 아니 라 zb 를 샘플 로 사용 하 여야 한다 . 관측 한 시간 차 gap _ times 를 사용 해서 220 개 의 시간 차 샘플 을 만들 고 , 이 샘플 의 pmf 를 계산 한다 . n = 220 cdf _ z = thinkbayes . makecdffromlist ( gap _ times ) sample _ z = cdf _ z . sample ( n ) pmf _ z = thinkbayes . makepmffromlist ( sample _ z ) 1 2 3 4 5 n = 220 cdf _ z = thinkbayes . makecdffromlist ( gap _ times ) sample _ z = cdf _ z . sample ( n ) pmf _ z = thinkbayes . makepmffromlist ( sample _ z ) 이제 pmf _ z 를 편향 시킨 뒤 샘플 을 고르 고 30 , 40 , 50 분 의 대기 시간 을 추가 하 자 . cdf _ zp = biaspmf ( pmf _ z ) . makecdf ( ) sample _ zb = cdf _ zp . sample ( n ) + [ 1800 , 2400 , 3600 ] 1 2 3 cdf _ zp = biaspmf ( pmf _ z ) . makecdf ( ) sample _ zb = cdf _ zp . sample ( n ) + [ 1800 , 2400 , 3600 ] 다음 kde 로 pdf 를 추정 하 고 이 를 pmf 로 바꾼다 . pdf _ zb = thinkbayes . estimatedpdf ( sample _ zb ) xs = makerange ( low = 60 ) pmf _ zb = pdf _ zb . makepmf ( xs ) 1 2 3 4 pdf _ zb = thinkbayes . estimatedpdf ( sample _ zb ) xs = makerange ( low = 60 ) pmf _ zb = pdf _ zb . makepmf ( xs ) 마지막 으로 zb 의 분포 를 비 편향 화 해서 z 의 분포 를 구하 고 , 이 를 사용 해서 waittimecalculator 를 생성 한다 . pmf _ z = unbiaspmf ( pmf _ zb ) wtc = waittimecalculator ( pmf _ z ) 1 2 3 pmf _ z = unbiaspmf ( pmf _ zb ) wtc = waittimecalculator ( pmf _ z ) 이제 장기 대기 시간 의 확률 을 계산 하 여 보 자 . def problongwait ( num _ passengers , minutes ) ete = elapsedtimeestimator ( wtc , lam , num _ passengers ) cdf _ y = ete . pmf _ y . makecdf ( ) prob = 1 - cdf _ y . prob ( minute * 60 ) 1 2 3 4 5 def problongwait ( num _ passengers , minutes ) ete = elapsedtimeestimator ( wtc , lam , num _ passengers ) cdf _ y = ete . pmf _ y . makecdf ( ) prob = 1 - cdf _ y . prob ( minute * 60 ) 8 . 8 토의',\n",
       "       '10 . 1 변이 가설 여기 서 는 변이 가설 ( variability hypothesis ) 을 다루 고자 한다 . 최근 수업 에서 cdc 의 행동 위험 요인 감시 시스템 에서 미국 의 남녀 성인 이 키 를 직접 입력 한 데이터 를 살펴보 았 다 . 데이터 셋 에 는 15507 명 의 남성 과 254722 명 의 여성 의 응답 내용 이 들 어 있 었 다 . 남성 의 평균 키는 178 cm 이 고 여성 의 평균 키 는 163 cm 이 다 . 남성 의 표준편차 는 7 . 7 cm 이 고 여성 은 7 . 3 cm 이 다 . 표준편차 를 평균 으로 나눈 변동 계수 ( coefficient of variation , cv ) 를 계산 해 보 면 남성 은 0 . 0433 , 여성 은 0 . 0444 이 다 . 이 데이터 셋 이 변이 가설 을 증명 하 기 에 는 빈약 하 다고 결론 내릴 수 없 으나 베이지안 방법 을 사용 하 여 결론 을 더 명확 하 게 만들 수 있 다 . 우선 간단 한 구현 내용 에서 시작 하 자 . 하지만 이 구현 내용 은 1000 개 이하 의 데이터 셋 에서 만 동작 한다 . 로그 변환 하 에서 확률 을 계산 하 려면 전체 데이터 셋 을 스케일 변환 을 해야 하 지만 , 계산 속도 가 느려질 것 이 다 . abc 로 알려져 있 는 근사 베이지안 계산 을 통해 속도 를 높일 것 이 다 . 코드 는 [ URL ] 를 참고 한다 . 10 . 2 평균 과 표준편차 가우 시안 분포 의 변수 인 평균 과 표준편차 를 9 장 과 동일 한 방식 으로 추정 할 것 이 다 . 먼저 각 평균 mu 와 표준편차 sigma 의 쌍 과 이 쌍 이 나타날 확률 의 연결 인 height 스윗 을 정의 하 도록 하 자 . class height ( thinkbayes . suite , thinkbayes . joint ) : def __ init __( self , mus , sigmas ) : thinkbayes . suite . __ init __( self ) pairs = [ ( mu , sigma ) for mu in mus for sigma in sigmas ] thinkbayes . suite . __ init __( self , pairs ) 1 2 3 4 5 6 7 8 class height ( thinkbayes . suite , thinkbayes . joint ) : def __ init __ ( self , mus , sigmas ) : thinkbayes . suite . __ init __ ( self ) pairs = [ ( mu , sigma ) for mu in mus for sigma in sigmas ] thinkbayes . suite . __ init __ ( self , pairs ) mus 는 가능 한 mu 의 연속 들 이 고 , sigmas 도 sigma 값 의 연속 이 다 . 이 들 은 모두 균등분포 이 다 . 이 에 대한 우도 함수 는 쉽 다 . mu 와 sigma 가 주어졌 을 때 특정 값 x 의 우도 를 계산 할 수 있 다 . class height : def likelihood ( self , data , hypo ) : x = data mu , sigma = hypo like = thinkbayes . evalgaussianpdf ( x , mu , sigma ) return like 1 2 3 4 5 6 7 8 class height : def likelihood ( self , data , hypo ) : x = data mu , sigma = hypo like = thinkbayes . evalgaussianpdf ( x , mu , sigma ) return like 이 문제 의 가장 어려운 부분 은 mus 와 sigmas 의 범위 를 고르 는 일 이 다 . 범위 가 너무 작 으면 중요 한 확률 값 들 을 지나칠 수 도 있 고 , 범위 가 너무 크 면 연산 능력 을 낭비 하 게 될 것 이 다 . 따라서 고전 적 인 방법 을 사용 하 였 다 . 이 를 위해 표준편차 를 사용 할 것 이 다 . 만약 n 개 의 샘플 을 이용 한 평균 과 표준편차 의 추정 치가 $\\\\ mu , \\\\ sigma $ 라면 , 이 들 의 표준 오 차 는 $ s / \\\\ sqrt { n }, s / \\\\ sqrt { 2 ( n - 1 ) } $ 이 다 . def findpriorranges ( xs , num _ points , num _ stderrs = 3 . 0 ) : n = len ( xs ) m = numpy . mean ( xs ) s = numpy . std ( xs ) stderr _ m = s / math . sqrt ( n ) mus = makerange ( m , stderr _ m ) stderr _ s = s / math . sqrt ( 2 * ( n - 1 ) ) sigmas = makerange ( s , stderr _ s ) return mus , sigmas 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def findpriorranges ( xs , num _ points , num _ stderrs = 3 . 0 ) : n = len ( xs ) m = numpy . mean ( xs ) s = numpy . std ( xs ) stderr _ m = s / math . sqrt ( n ) mus = makerange ( m , stderr _ m ) stderr _ s = s / math . sqrt ( 2 * ( n - 1 ) ) sigmas = makerange ( s , stderr _ s ) return mus , sigmas 이 들 을 이용 하 여 범위 를 만드 는 함수 는 다음 과 같 다 . def makerange ( estimate , stderr ) : spread = stderr * num _ stderrs array = numpy . linspace ( estimate - spread , estimated + spread , num _ points ) return array 1 2 3 4 5 def makerange ( estimate , stderr ) : spread = stderr * num _ stderrs array = numpy . linspace ( estimate - spread , estimated + spread , num _ points ) return array 10 . 3 갱신 이제 스윗 을 갱신 하 여 보 자 . mus , sigmas = findpriorranges ( xs , num _ points ) suite = height ( mus , sigmas ) suite . updateset ( xs ) print suite . maximumlikelhood ( ) 1 2 3 4 5 mus , sigmas = findpriorranges ( xs , num _ points ) suite = height ( mus , sigmas ) suite . updateset ( xs ) print suite . maximumlikelhood ( ) 보통 같 은 데이터 를 두 번 사용 하 면 허위 이 긴 하나 , 이 경우 에 는 괜찮 다 . 사전 분포 의 범위 에서 매우 작 은 값 들 에 대해서 계산 하 지 않 기 위해 데이터 를 선택 하 엿 다 . 실제로 는 사전 분포 는 균등 분포 이 지만 필요 없 는 값 들 은 모두 무시 하 자 . 10 . 4 cv 의 사후 분포 cv 의 분포 계산 을 위해 mu 와 sigma 의 쌍 을 만들 자 . def coefvariation ( suite ) : pmf = thinkbayes . pmf ( ) for ( mu , sigma ) , p in suite . items ( ) pmf . incr ( sigma / mu , p ) return pmf 1 2 3 4 5 6 def coefvariation ( suite ) : pmf = thinkbayes . pmf ( ) for ( mu , sigma ) , p in suite . items ( ) pmf . incr ( sigma / mu , p ) return pmf 나중 에 thinkbayes . pmfprobgreater 를 사용 해서 남자 가 여자 보다 변이성 이 높 을 확률 을 계산 할 수 있 다 . 하지만 고려 해야 할 문제 가 있 다 . 데이터 셋 의 크기 가 커질 수록 소수점 의 제한 으로 계산 문제 가 생긴다 . 데이터 셋 에 높 은 극단 값 이 포함 되 면 아웃 라이어 로 작용 하 여 계산 이 올바르 게 되 지 않 을 것 이 다 . 10 . 5 언더 플로 앞 의 데이터 셋 에서 100 개 의 값 을 선택 하 여 분석 하 였 다면 오류 없이 분석 이 될 것 이 지만 , 1000 개 의 값 을 이용 해서 프로그램 을 돌리 면 오류 메시지 를 보 게 될 것 이 다 . 문제 는 우도 계산 에서 너무 작 은 값 들 이 계속 적 으로 곱해 져서 0 에 수렴 해 버리 게 된다 . 이런 경우 를 언더 플로 ( underflow ) 라고 한다 . 한 가지 해결 방법 은 매번 갱신 하 거나 100 개 를 다시 돌려서 정규 화 하 는 것 이 다 . 하지만 속도 가 매우 느릴 것 이 다 . 더 나 은 대안 으로 는 로그 로 변환 하 여 우도 를 계산 하 는 것 이 다 . 로그 로 변환 하 였 기 때문 에 곱하 는 대신 더 하 는 것 으로 변경 된다 . pmf 는 log 를 제공 한다 . class pmf def log ( self ) : m = self . maxlike ( ) for x , p in self . d . iteritems ( ) : if p : self . set ( x , math . log ( p / m ) ) else : self . remove ( x ) 1 2 3 4 5 6 7 8 9 10 class pmf def log ( self ) : m = self . maxlike ( ) for x , p in self . d . iteritems ( ) : if p : self . set ( x , math . log ( p / m ) ) else : self . remove ( x ) 가장 높 은 확률 m 을 찾 은 뒤 모든 확률 을 이것 으로 나누 어 가장 높 은 확률 을 1 이 되 도록 정규 화 한다 . 따라서 로그 화 된 확률 의 최대 값 은 0 , 나머지 는 음수 를 갖 게 된다 . 만약 확률 이 0 인 데이터 가 있 으면 이 는 제거 해 버린다 . 로그 화 된 pmf 는 update , updateset , normalize 를 사용 하 면 결과 가 엉뚱 하 게 나올 것 이 므로 사용 하 면 안 된다 . 대신 logupdate 와 logupdateset 을 사용 하 자 . class suite : def logupdateset ( self , dataset ) : for data in dataset : self . logupdate ( data ) def logupdate ( self , data ) : for hypo in self . values ( ) : like = self . loglikelihood ( data , hypo ) self . incr ( hypo , like ) 1 2 3 4 5 6 7 8 9 10 11 class suite : def logupdateset ( self , dataset ) : for data in dataset : self . logupdate ( data ) def logupdate ( self , data ) : for hypo in self . values ( ) : like = self . loglikelihood ( data , hypo ) self . incr ( hypo , like ) 로그 우도 를 사용 한 뒤 에 는 다시 exp 를 사용 해서 원래 대로 되돌리 자 . class pmf : def exp ( self ) : m = self . maxlike ( ) for x , p in self . d . iterietms ( ) : self . set ( x , math . exp ( p - m ) ) 1 2 3 4 5 6 7 class pmf : def exp ( self ) : m = self . maxlike ( ) for x , p in self . d . iterietms ( ) : self . set ( x , math . exp ( p - m ) ) 10 . 6 로그 우도 class height : def loglikelihood ( self , data , hypo ) : x = data mu , sigma = hypo loglike = scipy . stats . norm . logpdf ( x , mu , sigma ) return loglike 1 2 3 4 5 6 7 8 class height : def loglikelihood ( self , data , hypo ) : x = data mu , sigma = hypo loglike = scipy . stats . norm . logpdf ( x , mu , sigma ) return loglike 다음 은 전체 갱신 프로세스 를 실행 하 는 코드 이 다 . suite . log ( ) suite . logupdateset ( xs ) suite . exp ( ) suite . normalize ( ) 1 2 3 4 5 suite . log ( ) suite . logupdateset ( xs ) suite . exp ( ) suite . normalize ( ) 하지만 여전히 느리 다 . 10 . 7 약간 의 최적화 가우 시안 의 로그 를 씌울 때 각 데이터 에 의존 하 지 않 는 값 들 을 따로 분리 하 여 미리 계산 하 고 의존 성 이 있 는 최소한 의 데이터 만 반복 하 여 계산 하 도록 하 였 다 . 반복 적 으로 걔 산 되 는 값 을 캐시 에 저장 하 여 다시 사용 하 도록 하 였 다 . 10 . 8 근사 베이지안 계산 ( abc ) 하지만 이렇게 일일이 계산 하 지 않 고 근사 베이지안 ( approximate bayesian compuation ) 방법 을 사용 할 수 있 다 . abc 는 특정 데이터 셋 의 우도 가 다음 과 같 을 때 사용 된다 . 큰 데이터 셋 의 경우 로 매우 작 아서 로그 변환 이 어려운 경우 계산 비용 이 많이 들 어서 최적화 를 해야 할 경우 사실 이 문제 에서 는 특정 값 의 집합 을 볼 확률 에 대해서 는 관심 이 없 고 , 관측 평균 과 분산 에 관심 이 있 다 . 만약 원래 분포 가 가우 시안 이 라고 가정 하 면 이미 샘플 통계 에서 분포 를 정확히 찾아낼 수 있 기 때문 에 보다 효과 적 으로 답 을 알아낼 수 있 다 . 사실 앞 에서 설명 한 것 이 바로 그것 이 다 . def logupdatesetabc ( self , data ) : xs = data n = len ( xs ) m = numpy . mean ( xs ) s = numpy . std ( xs ) for hypo in sorted ( self . values ( ) ) : mu , sigma = hypo stderr _ m = sigma / math . sqrt ( n ) loglike = evalgaussianlogpdf ( m , mu , stderr _ m ) stderr _ s = sigma / math . sqrt ( 2 * ( n - 1 ) ) loglike += evalgaussianlogpdf ( s , sigma , stderr _ s ) self . incr ( hypo , loglike ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def logupdatesetabc ( self , data ) : xs = data n = len ( xs ) m = numpy . mean ( xs ) s = numpy . std ( xs ) for hypo in sorted ( self . values ( ) ) : mu , sigma = hypo stderr _ m = sigma / math . sqrt ( n ) loglike = evalgaussianlogpdf ( m , mu , stderr _ m ) stderr _ s = sigma / math . sqrt ( 2 * ( n - 1 ) ) loglike += evalgaussianlogpdf ( s , sigma , stderr _ s ) self . incr ( hypo , loglike ) 10 . 9 로버스 트 추정 이제 아웃 라이어 를 처리 하 는 방법 을 알아보 자 . 4 분위 범위 를 사용 해 볼 수 있 다 . 좀 더 일반 화 시켜 중간값 을 중심 으로 범위 p 내 의 범위 만 을 사용 해 볼 수 있 다 . def medianipr ( xs , p ) : cdf = thinkbayes . makecdffromlist ( xs ) median = cdf . percentile ( 50 ) alpha = ( 1 - p ) / 2 ipr = cdf . value ( 1 - alpha ) - cdf . value ( alpha ) return median , ipr 1 2 3 4 5 6 7 8 9 def medianipr ( xs , p ) : cdf = thinkbayes . makecdffromlist ( xs ) median = cdf . percentile ( 50 ) alpha = ( 1 - p ) / 2 ipr = cdf . value ( 1 - alpha ) - cdf . value ( alpha ) return median , ipr 이제 가우 시안 cdf 를 사용 하 여 ipr 을 sigma 의 추정 값 으로 변화 하 여 범위 내 의 분포 를 계산 할 수 있 다 . def medians ( xs , num _ sigmas ) : half _ p = thinkbayes . standardgaussiancdf ( num _ sigmas ) - 0 . 5 median , ipr = medianipr ( xs , half _ p * 2 ) s = ipr / 2 / num _ sigmas return median , s 1 2 3 4 5 median , ipr = medianipr ( xs , half _ p * 2 ) s = ipr / 2 / num _ sigmas return median , s 이 를 logupdatesetabc 에 적용 하 도록 한다 . 10 . 10 누가 변이성 이 높 은가 ? num _ sigmas = 1 일 때 cv 의 사후 분포 를 보 았 다 . 남성 의 평균 은 0 . 0410 , 여성 은 0 . 0429 이 다 . 따라서 여성 이 변이성 이 높 다고 볼 수 있 다 . 하 지만 num _ sigmas = 2 를 사용 하 면 남성 이 더 높 다는 결론 을 볼 수 있 다 . 남성 이 작 은 쪽 에 치우친 경우 가 많 은데 num _ sigmas 를 높일 수록 극단 값 의 비중 이 높 아 지 기 때문 이 다 . 10 . 11 토의 abc 에 대한 두 가지 해석 방법',\n",
       "       '3 . 1 주사위 문제 상자 안 에 4 , 6 , 8 , 12 , 20 면체 주사위 가 들 어 있 다고 해 보 자 . 상자 에서 임의 로 주사위 하나 를 집 어서 던졌 더니 6 이 나왔 다면 , 이 경우 각 주사위 를 선택 했 을 확률 은 어떻게 될까 ? 문제 를 이렇게 접근 하 여 보 자 . 가설 을 나타내 자 . 데이터 를 나타내 자 . 우도 함수 를 작성 하 자 . 가설 은 다음 과 같이 나타내 어 보 자 . suite = dice ( [ 4 , 6 , 8 , 12 , 20 ] ) 1 2 suite = dice ( [ 4 , 6 , 8 , 12 , 20 ] ) 그리고 정수 1 부터 20 까지 를 사용 하 여 데이터 를 나타내 자 . class dice ( suite ) : def likelihood ( self , data , hypo ) : if hypo < data : return 0 else : return 1 . 0 / hypo 1 2 3 4 5 6 7 class dice ( suite ) : def likelihood ( self , data , hypo ) : if hypo & lt ; data : return 0 else : return 1 . 0 / hypo 주사위 를 굴려 나온 값 이 주사위 가 가지 는 눈 보다 크 다면 발생 할 수 없 는 일 이 므로 우도 는 0 이 다 . 그렇 지 않 다면 각 주사위 가 가지 는 눈 의 수 에 대한 확률 을 가지 도록 하 자 . 주사위 를 굴려 6 이 나온 경우 를 적용 하 는 코드 는 다음 과 같 다 . suite . update ( 6 ) 1 2 suite . update ( 6 ) 각 주사위 의 사후 확률 분포 는 다음 과 같 다 . 4 0 . 0 6 0 . 3921568627450979 8 0 . 2941176470588235 12 0 . 19607843137254896 20 0 . 11764705882352941 1 2 3 4 5 6 4 0 . 0 6 0 . 3921568627450979 8 0 . 2941176470588235 12 0 . 19607843137254896 20 0 . 11764705882352941 만약 몇 번 더 던져서 6 , 8 , 7 , 7 , 5 , 4 가 나왔 다면 다음 과 같이 적용 함 for roll in [ 6 , 8 , 7 , 7 , 5 , 4 ] : suite . update ( roll ) 1 2 3 for roll in [ 6 , 8 , 7 , 7 , 5 , 4 ] : suite . update ( roll ) 그 후 사후 확률 분포 는 다음 과 같 다 . 4 0 . 0 6 0 . 0 8 0 . 9432484536722127 12 0 . 055206128061290875 20 0 . 001545418266496554 1 2 3 4 5 6 4 0 . 0 6 0 . 0 8 0 . 9432484536722127 12 0 . 055206128061290875 20 0 . 001545418266496554 8 면제 주사위 를 굴렸 을 확률 이 94 % 로 가장 높 다 . 코드 는 [ URL ] 에서 받 을 수 있 다 . 3 . 2 기관차 문제 프레드릭 모스 텔러 ( frederick mosteller ) 이 제시 한 기관차 문제 라는 것 이 있 다 . 각 철도 에 는 이 를 지나가 는 기관차 에 1 부터 n 까지 의 순서 로 번호 를 붙인다 . 어느 날 60 호 기관차 를 보 았 다 . 이 때 이 철도 에 는 몇 개 의 기관차 가 지나가 는지 추측 해 보 자 . 관측 결과 에 따르 면 , 이 철도 에 는 60 개 이상 의 기관차 가 있 다는 것 을 알 수 있 다 . 하지만 얼마나 더 많 을까 ? 베이지안 추론 법 에 따르 면 이런 문제 는 2 단계 로 해결 한다 . 데이터 를 보 기 전 에 n 에 대해서 알 고 있 는 것 이 무엇 인가 ? n 에 어떤 값 이 주어졌 을 때 관측 한 데이터 ( 60 호 기관차 ) 의 우도 는 어떻게 되 는가 ? 첫 번 째 질문 은 사전 확률 을 , 두 번 째 는 우도 를 묻 고 있 다 . 사전 확률 을 추정 하 기 는 어려운 일 이 라 , 간단 한 가정 으로부터 시작 해 보 도록 하 자 . 일단 기관차 의 수 가 1 부터 1000 까지 일 상황 이 이 있 고 이 들 은 동일 한 확률 이 라고 가정 하 자 . hypos = xrange ( 1 , 1001 ) 1 2 hypos = xrange ( 1 , 1001 ) 이제 우도 를 작성 해 보 도록 하 자 . 주사위 의 경우 와 비슷 하 다 . class train ( suite ) : def likelihood ( self , data , hypo ) : if hypo < data : return 0 else : return 1 . 0 / hypo 1 2 3 4 5 6 7 class train ( suite ) : def likelihood ( self , data , hypo ) : if hypo & lt ; data : return 0 else : return 1 . 0 / hypo 60 호 기관차 가 지나갔 으므로 이제 갱신 을 하여보 자 . suite = train ( hypos ) suite . update ( 60 ) 1 2 3 suite = train ( hypos ) suite . update ( 60 ) 출력 하 기 에 는 값 이 너무 많 긴 하 지만 가장 높 은 가능 성 은 n 이 60 일 경우 이 다 . 썩 좋 아 보이 는 답 은 아니 지만 확률 상 최고 치 를 고르 자고 한다면 60 이 최선 일 것 이 다 . 만약 사후 확률 분포 의 평균 을 계산 해 보 면 어떻게 될까 ? def mean ( suite ) : total = 0 for hypo , prob in suite . items ( ) : total += hypo * prob return total 1 2 3 4 5 6 def mean ( suite ) : total = 0 for hypo , prob in suite . items ( ) : total += hypo * prob return total 사실 은 pmf 에서 도 비슷 한 메서 드 를 제공 한다 . print suite . mean ( ) 333 . 41989326371095 1 2 3 4 print suite . mean ( ) 333 . 41989326371095 평균 은 333 정도 로 나왔 다 . n 의 가능 성 을 1000 까지 로 생각 하 였을 때 오차 ( 위험 ) 를 최소 화 하 고자 한다면 333 을 선택 해야 할 것 이 다 . mean squared error ( mse ) 와 연결 되 는 개념 이 다 . 코드 는 [ URL ] 에서 받 을 수 있 다 . 3 . 3 사전 확률 로 할 수 있 는 것 기관차 문제 를 해결 하 기 위해서 는 임의 적 인 가설 을 여러 개 만들 어 보 아야 한다 . 우리 는 1000 개 까지 만 을 고려 하 였 지만 어떤 사람 은 그 보다 적 게 , 혹은 많 게 생각 할 수 도 있 을 것 이 다 . 이러 한 가정 에 민감 하 게 반응 하 는지 살펴보 아야 한다 . 1 부터 1000 까지 의 범위 라고 하 였을 때 는 그 사후 확률 의 평균 은 333 이 었 지만 , 상한 이 500 이 라면 평균 은 207 이 고 상한 이 2000 이 라면 그 평균 은 552 일 것 이 다 . 따라서 우리 가 사용 한 추론 은 썩 좋 지 않 은 상황 이 다 . 이러 한 경우 우리 는 두 가지 방법 으로 더 진행 할 수 있 다 . 데이터 를 더 확보 할 것 배경 지식 을 더 확보 할 것 데이터 가 더 많 다면 사후 확률 의 평균 또한 수렴 하 는 경향 을 보일 것 이 다 . 예 를 들 어 60 호 기관차 이후 에 30 , 90 번 기관차 도 보 았 다고 해 보 자 . for data in [ 60 , 30 , 90 ] : suite . update ( data ) 1 2 3 for data in [ 60 , 30 , 90 ] : suite . update ( data ) 그 후 에 사후 확률 의 평균 은 다음 과 같이 변화 한다 . 상한 사후 평균 500 152 1000 164 2000 171 3 . 4 사전 확률 의 대안 배경 지식 을 더 많이 수집 하 는 방법 도 있 다 . 1000 대 의 기관차 를 운영 한다는 가정 은 별로 합리 적 이 지 않 다거나 , 철도 회사 의 목록 을 찾 을 수 있 을지 도 모른다 . 기관차 운송 분야 의 전문가 와 인터뷰 를 할 수 도 있 다 . 혹은 로버트 액스 텔 ( robert axtell ) 의 멱 법칙 에 따라 회사 규모 에 따르 는 분포 를 생각 해 볼 수 도 있 다 . 멱 법칙 은 주어진 규모 의 회사 크기 는 규모 의 분포 의 역수 라는 뜻 이 다 . $$ pmf ( x ) \\\\ propto ( \\\\ frac { 1 }{ x })^ a $$ a 는 보통 1 에 가깝 게 설정 되 는 매개변수 이 다 . 멱 법칙 을 적용 하 여 사전 확률 을 다음 과 같이 만들 수 있 다 . class train ( dice ) : def __ init __( self , hpos , alpha = 1 . 0 ) : pmf . __ init __( self ) for hypo in hypos : self . set ( hypo , hypo **(- alpha ) ) self . normalize ( ) 1 2 3 4 5 6 7 class train ( dice ) : def __ init __ ( self , hpos , alpha = 1 . 0 ) : pmf . __ init __ ( self ) for hypo in hypos : self . set ( hypo , hypo * * ( - alpha ) ) self . normalize ( ) 동일 한 방식 으로 사전 확률 을 계산 해 보 면 , 사후 확률 은 그 선택 값 에 대하 여 민 감도 가 낮 아 지 게 된다 . 또한 n 이 700 보다 큰 경우 는 거의 대부분 이 제거 될 수 있 다 . 앞 의 30 , 60 , 90 의 관측 값 을 사용 한 경우 사후 확률 의 평균 값 변화 는 다음 과 같이 차이 가 거의 없 어 지 는 것 을 볼 수 있 다 . 상한 사후 평균 500 131 1000 133 2000 134 코드 는 [ URL ] 에서 받 을 수 있 다 . 3 . 5 신뢰구간 지금 까지 는 결과 를 단일 점 으로 추정 하 였 다 . 이러 한 점 추정 에 는 보통 평균 , 중간값 , 최대 우도 값 을 사용 한다 . 하지만 구간 을 사용 할 수 도 있 다 . 구간 은 보통 미 확인 값 이 어느 구간 내 에 올 확률 이 90 %( 혹은 다른 확률 ) 인 구간 의 상한 값 과 하한 값 을 의미 한다 . 이것 을 신뢰 구간 이 라고 한다 . 신뢰 구간 을 계산 하 는 간단 한 방법 은 사후 분포 확률 을 더 한 후 그 값 이 5 %, 95 % 에 해당 하 는 값 을 기록 하 는 것 이 다 . 즉 5 분위 , 95 분위 값 이 다 . thinkbayes 에서 분위 값 을 계산 하 는 함수 를 제공 한다 . def percentile ( pmf , percentage ) : p = percentage / 100 . 0 total = 0 for val , prob in pmf . items ( ) : total += prob if ( total >= p ) : return val 1 2 3 4 5 6 7 8 def percentile ( pmf , percentage ) : p = percentage / 100 . 0 total = 0 for val , prob in pmf . items ( ) : total += prob if ( total & gt ; = p ) : return val 다음 은 이 를 사용 하 는 예제 이 다 . interval = percentile ( suite , 5 ) , percentile ( suite , 95 ) print interval 1 2 3 interval = percentile ( suite , 5 ) , percentile ( suite , 95 ) print interval 앞 의 멱 법칙 과 3 개 관측 값 을 사용 한 예제 의 경우 90 % 신뢰구간 은 ( 91 , 243 ) 이 다 . 이 는 여전히 얼마나 많 은 기관차 가 있 는지 확신 할 수 없 다는 것 을 보여준다 . 3 . 6 누적 분포 함수 앞 의 코드 는 분위 수 를 계산 하 는 데 반복 적 으로 값 과 확률 을 더 하 여 계산 하 였 다 . 만약 여러 번 반복 해서 계산 해야 한다면 누적 분포 함수 나 cdf 를 사용 하 는 것 이 훨씬 효율 적 이 다 . cdf 는 분포 에 대한 정보 를 가진다는 면 에서 pmf 와 동일 하 고 , 서로 변환 하 는 것 이 가능 하 다 . 하 지만 cdf 는 분위 수 를 조금 더 효율 적 으로 계산 할 수 있 다 . thinkbayes 에서 는 누적 분포 함수 를 나타내 는 cdf 를 제공 한다 . cdf 를 만들 려면 다음 과 같이 하 자 . cdf = suite . makecdf ( ) 1 2 cdf = suite . makecdf ( ) 또한 cdf 는 percentile 이 라는 함수 를 제공 한다 . interval = cdf . percentile ( 5 ) , cdf . percentile ( 95 ) 1 2 interval = cdf . percentile ( 5 ) , cdf . percentile ( 95 ) 3 . 7 독일 탱크 문제 2 차 세계 대전 에서 영국 은 독일 탱크 의 장비 생산량 을 추정 하 는 데 통계 분석 기법 을 사용 햇 다 . 각 탱크 의 섀시 와 엔진 의 시리얼 번호 를 포함 한 장부 및 수리 기록 을 확보 한 것 이 다 . 기록 을 분석 해 보 니 시리얼 번호 는 제조자 에 따라 할당 되 어 있 고 , 탱크 의 유형 은 100 개 의 숫자 블록 으로 이루어져 있 는데 각 블록 숫자 는 순서 대로 증가 하 긴 하 지만 각 블록 의 모든 자리 가 사용 된 것 은 아니 다 . 따라서 독일 탱크 생산량 추정 은 100 개 의 숫자 를 포함 하 는 블록 범위 내 에서 기관차 문제 로 생각 할 수 있 다 . 결과 는 도출 한 내용 이 대부분 맞 았 다고 한다 . 3 . 8 토의 베이지안 ( bayesian , 베이즈 주의자 ) 가 선행 분포 를 택하 는 방법 은 두 가지 가 있 는데 , 하나 는 문제 의 배경 지식 을 가장 잘 표현 은 선행 분포 를 고르 는 방법 이 다 . 이 는 선행 분포 가 정보 적 이 라고 한다 . 이 경우 에 는 사람 들 이 서로 다른 배경 지식 을 사용 하 거나 해석 할 수 있 다는 점 이 문제 로 지적 된다 . 즉 주관 적 인 것 이 다 . 다른 하나 는 비 정보 적 선행 분포 로 관측 된 데이터 만 을 신뢰 하 도록 다른 제약 을 최소한 으로 줄이 는 것 이 다 . 때로 는 추정량 에 대한 최소한 의 선행 정보 를 나타내 도록 고유 한 선행 분포 를 정의 할 수 도 있 다 . 비 정보 적 선행 분포 는 조금 더 객관 적 이 긴 하 지만 , 저자 는 선행 분포 를 선호 한다 . 첫 번 째 이유 로 , 베이지안 분석 은 모델 판단 에 기반 하 여 이루 어지 느 데 , 선행 분포 를 선택 하 지 않 더라도 전체 분석 자체 가 거의 주관 적 으로 이루어지 기 때문 이 다 . 또한 데이터 가 아주 많 거나 아니 면 아주 적 거나 극단 적 으로 속하 게 되 는 경향 이 있 는데 , 데이터 가 많 은 경우 문제 가 되 지 않 지만 데이터 가 적 은 경우 배경 지식 을 사용 하 는 것 은 매우 큰 차이 를 나타낸다 . 따라서 객관 성 을 유지 하 는 것 보다 는 알 고 있 는 모든 지식 을 쏟 아 넣 어야 할 것 이 다 .',\n",
       "       \"[ 뉴스 의 행간 ] 구로 콜 센터 집단 감염 , 기로 에 선 수도 권 서울 구로 콜 센터 와 관련 된 코로나 19 확진 자 숫자 가 서울 · 경기 · 인천 지역 에 85 명 이상 으로 확인 되 면서 수도 권 에 비상 이 걸렸 습니다 . 구로 콜 센터 근무 직원 은 700 명 에 달하 고 최초 확진 판정 을 받 은 직원 과 같 은 11 층 에 근무 하 는 직원 은 207 명 입니다 . 확진 자 들 은 서울 과 경기 지역 에 고르 게 거주 하 고 있 어 거주지 인근 과 대중교통 에서 바이러스 를 전파 했 을 가능 성 이 제기 되 고 있 습니다 . < 구로 콜 센터 집단 감염 , 기로 에 선 수도 권 >, 이 뉴스 의 행간 을 살펴보 겠 습니다 . 1 . ' 깜깜 이 ' 집단 감염 증가 서울 에서 감염원 이 확인 되 지 않 은 집단 감 염지 가 증가 하 고 있 습니다 . 서울시 에 따르 면 현재 종로구 노인 복지 회관 집 담 감염 은 감염원 이 밝혀졌 지만 은평 성모병원 14 명 과 성동구 주상 복합 아파트 13 명 은 감염원 이 확인 되 지 않 은 상태 입니다 . 여기 에 구로 콜 센터 80 여 명 이 추가 됐 습니다 . 당국 의 역학 조사 가 이뤄져야 하 지만 구로 콜 센터 에서 최초 확진 판정 을 받 은 노원구 거주 여성 은 최초 감염자 가 아닐 가능 성 이 높 습니다 . 감염원 을 못 찾 는 집단 감염 이 증가 한다는 것 은 본격 적 지역 사회 감염 으로 접 어 든다는 의미 입니다 . 확진 자 의 수 가 갈수록 많 아 지 는 데 다 2 차 , 3 차 감염 이 늘어나 기 때문 에 최초 감염원 을 조사 하 는 데 어려움 이 따릅니다 . 구로 콜 센터 건 은 신천지 와 관련 된 집단 감염 을 제외 하 면 가장 규모 가 큰 집단 감염 입니다 . 수도 권 대 규모 확산 의 기로 에 서 있 다고 볼 수 있 습니다 . 2 . 대중교통 은 안전 한가 구로 콜 센터 에 출근 하 는 직원 들 의 거주지 는 서울 과 경기 , 인천 에 넓 게 퍼져 있 습니다 . 대부분 은 지하철 이나 버스 등 대중교통 을 이용 해 출퇴근 했 습니다 . 구로 콜 센터 인근 에 는 지하철 1 호 선 구로 역과 1 ~ 2 호 선 신도림역 이 있 습니다 . 수도 권 서남 부과 서울 을 연결 하 는 교통 의 요지 로 유동 인구 가 많 습니다 . 지하철 이나 버스 를 통한 대량 감염 우려 가 나오 는 이유 입니다 . 하지만 전문가 들 은 대중교통 에서 의 대량 감염 은 가능 성 이 높 지 않 다고 말 하 고 있 습니다 . 파악 된 코로나 19 집단 감염 경로 를 보 면 신천지 교회 나 구로 콜 센터 등 의 경우 좁 은 공간 에 모여 끊임없이 말 을 했 다는 공통점 이 있 습니다 . 상대방 의 침방울 이 내 코 나 입 에 들어가 는 일 은 거의 없 습니다 . 대부분 바이러스 침방울 이 튀긴 물체 , 예 를 들 면 손잡이 등 을 내 손 으로 만진 뒤 이 손 으로 내 코 나 입 을 만지 면서 감염 되 는 사례 가 대부분 입니다 . 그런데 출퇴근 지하철 의 경우 사람 들 은 거의 말 은 안 하 고 휴대폰 만 봅니다 . 코로나 19 사태 이후 에 는 대부분 마스크 를 착용 해 적막감 이 흐릅니다 . 재택근무 도 증가 해 유동 인구 도 줄 었 습니다 . 현재 까지 대중교통 에서 의 집단 감염 이 보 고 된 사례 도 없 습니다 . 대중교통 을 통한 일부 감염 을 배제 할 수 는 없 지만 구로 콜 센터 나 신천지 교회 같 은 상황 은 나타나 지 않 을 것 이 란 것 이 전문가 들 의견 입니다 . 지금 은 조심 은 하 되 서로 를 믿 고 대중교통 을 이용 해야 합니다 . 3 . 사회 적 약자 는 더 위험 하 다 구로 콜 센터 집단 감염 으로 다른 지역 콜 센터 사례 도 관심 이 쏠리 고 있 습니다 . 대구 시내 에 는 56 곳 의 콜 센터 에서 8600 여 명 이 근무 하 고 있 습니다 . 대구 달서구 성당동 삼성전자 콜 센터 직원 5 명 이 확진 판정 을 받 아 동료 직원 259 명 이 자 가 격리 중 입니다 . 통계청 에 따르 면 콜 센터 및 텔레마케팅 서비스업 종사자 는 전국 982 곳 에 7 만 6225 명 입니다 . 서울 341 곳 , 경기 195 곳 , 인천 46 곳 중 전체 의 60 % 가 수도 권 에 몰려 있 습니다 . 실제 는 이 보다 훨씬 많 은 것 으로 추산 됩니다 . 2017 년 한국 노동 연구원 연구 결과 콜 센터 종사자 수 는 40 만 명 에 달했 습니다 . 지금 은 사회 적 거리 두기 가 불 가능 한 사회 적 약자 에 대한 대책 이 필요 한 상황 입니다 . 콜 센터 노동자 들 은 다닥다닥 붙 어서 일 하 고 있 고 , 끊임없이 얘기 해야 해서 감염 에 취약 한 상황 입니다 . 그리고 비정규직 이 어서 아파도 쉴 수 없 습니다 . 콜 센터 노동자 의 경우 당일 날 연차 를 쓰 면 감점 사유 로 성과급 에 반영 이 되 기 때문 에 아파도 쉬 지 않 고 출근 을 하 는 경우 가 많 습니다 . 구로 콜 센터 확진 자 도 오후 4 시 에 이상 을 느꼈 지만 오후 6 시 까지 일 하 고 퇴근 했 습니다 . 재택근무 등 사회 적 거리 두기 가 가능 한 사람 은 정규직 이 거나 , 상대 적 으로 좋 은 직장 에 다니 는 사람 들 입니다 . 감염 확산 을 막 기 위해서 라도 사회 적 약자 에 대한 배려 와 대책 이 필요 한 시점 입니다 . open @ newstof . com 최근 글 보 기 김준일 2001 년 부터 언론인 으로 활동 하 며 주로 사회 , 정치 , 미디어 분야 의 글 을 썼 다 . 현재 뉴스 톱 대표 를 맡 고 있 다 . 저작권자 © 뉴스 톱 무단 전재 및 재 배포 금지\",\n",
       "       '큰 사진 보 기 ▲ 교황 인노켄티우스 10 세 의 초상 디에고 벨라스케스 \\' 교황 인노켄티우스 10 세 의 초상 \\' 로마 도리아 팜 필리 미술관 ⓒ 디에고 벨라스케스 관련 사진 보 기 큰 사진 보 기 ▲ 교황 인노켄티우스 10 세 의 초상 ( 부분 ) 디에고 벨라스케스 \\' 교황 인노켄티우스 10 세 의 초상 \\'( 부분 ) 로마 도리아 팜 필리 미술관 ⓒ 박용 은 관련 사진 보 기 큰 사진 보 기 ▲ 지상 낙원 얀 브 뤼 헬 \\' 지상 낙원 \\' 로마 도리아 팜 필리 미술관 ⓒ 박용 은 관련 사진 보 기 큰 사진 보 기 ▲ 불 의 은유 ( 부분 ) 얀 브 뤼 헬 \\' 불 의 은유 \\'( 부분 ) 로마 도리아 팜 필리 미술관 ⓒ 박용 은 관련 사진 보 기 큰 사진 보 기 ▲ 새덫 과 스 케 이터 가 있 는 겨울 풍경 피터 브 뤼 헬 2 세 \\' 새덫 과 스 케 이터 가 있 는 겨울 풍경 \\' 로마 도리아 팜 필리 미술관 ( 오스트리아 빈 \\' 미술사 박물관 \\' 에 있 는 아버지 피터 브 뤼 헬 의 작품 의 모작 같 습니다 . ) ⓒ 박용 은 관련 사진 보 기 큰 사진 보 기 ▲ 산 루이지 데이 프란체 시 성당 로마 \\' 산 루이지 데이 프란체 시 성당 \\' - 다른 성당 들 보다 훨씬 많 은 사람 들 이 입구 에 모여 있 습니다 . ⓒ 박용 은 관련 사진 보 기 큰 사진 보 기 ▲ 성 마태오 의 소명 카라바조 \\' 성 마태오 의 소명 \\' 로마 , 산 데이지 루이 프란체 시 성당 - 그림 속 의 빛 과 성당 창 을 통해서 들어온 빛 이 같 은 방향 임 을 알 수 있 습니다 . ⓒ 박용 은 관련 사진 보 기 큰 사진 보 기 ▲ 성 마태오 의 소명 ( 부분 ) 카라바조 \\' 성 마태오 의 소명 \\' ( 부분 ) 로마 , 산 루이지 데이 프란체 시 성당 - 자신 을 가리키 는 예수 를 의아 한 듯 바라보 는 마태오 . 가장 왼쪽 의 돈 을 세 고 있 는 젋은이와 그 위 의 안경 쓴 이 도 물욕 에 빠져 있 기 는 마태오 와 마찬가지 입니다 . ⓒ 박용 은 관련 사진 보 기 큰 사진 보 기 ▲ 성 마태오 와 천사 카라바조 \\' 성 마태오 와 천사 \\' 로마 , 산 루이지 데이 프란체 시 성당 ⓒ 박용 은 관련 사진 보 기 큰 사진 보 기 ▲ 성 마태오 와 천사 카라바조 \\' 성 마태오 와 천사 \\' - 가톨릭 측 으로부터 거절 당한 원래 의 그림 인데 세계 2 차 대전 때 발생 한 화재 로 소실 되 어 현재 는 흑백 사진 으로 만 남 아 있 습니다 . ⓒ 위키피디아 이미지 관련 사진 보 기 큰 사진 보 기 ▲ 성 마태오 의 순교 카라바조 \\' 성 마태오 의 순교 \\' 로마 , 산 루이지 데이 프란체 시 성당 ⓒ 박용 은 관련 사진 보 기 ( * 2 - 4 로 이어집니다 . ) ○ 편집 ㅣ 최유진 기자 황금빛 으로 장식 된 화려 한 붉 은 벨벳 의자 에 한 노인 이 앉 아 있 습니다 . 부드러운 흰색 레이스 의상 에 어깨 엔 붉 은 색 케이프 를 두르 고 붉은색 모자 를 쓴 노인 은 , 오른손 약지 에 황금 반지 까지 끼 고 있 어서 한 눈 에 도 고위 성직자 란 것 을 알 수 있 습니다 . 그런가 하 면 , 찌푸린 미간 과 다듬 지 않 은 수염 , 붉 은 기 가 짙 은 얼굴빛 에 무섭 기 까지 한 강렬 한 시선 , 그리고 꽉 다문 입 과 앞 으로 약간 굽힌 자세 는 고집 세고 성질 고약 한 영감 님 처럼 보입니다 . 이 영감 님 은 과연 누구 일까요 ? 그렇 습니다 . 그 는 \\' 교황 인노켄티우스 10 세 \\' 입니다 . 스페인 바로크 미술 의 거장 , 디에고 벨라스케스 의 작품 입니다 . 앞서 언급 했 듯이 17 세기 초 카라바조 의 화풍 은 전 유럽 에 엄청난 폭풍 을 몰 고 왔 나 봅니다 . 벨라스케스 역시 초기 에 는 중간 단계 를 생략 한 어두운 조명 아래 인물 과 사물 을 사실 적 으로 묘사 했 던 \\' 테 네 브리 즘 ( tenebrism , 어두운 방식 ) \\' 에 매료 되 어 수많 은 인물화 를 남 깁니다 . 하지만 그 의 사실 성 은 시간 이 지날수록 카라바조 와 는 조금 씩 차이 를 보이 게 되 는데 먼저 그림 의 대상 이 달랐 습니다 . 벨라스케스 의 그림 의 주인공 들 은 대부분 당시 생존 해 있 던 인물 들 이 었 죠 . 특히 왕족 이나 귀족 같 은 권력 층 뿐 만 아니 라 시녀 나 난쟁이 , 물장수 , 노예 , 광대 같 은 하층민 도 그림 의 주인공 으로 등장 합니다 . 그리고 그 들 한 명 한 명 에게 모두 인격 을 가진 실존 인물 로서 의 사실 성 을 부여 하 죠 . 벨라스케스 는 거기 서 한 단계 더 나아갑니다 . 그 는 카라바조 와 같 은 연극 적 인 조명 이나 렘브란트 와 같 은 심리 적 느낌 이 들어간 빛 이 아니 라 실제 우리 눈 이 지각 하 는 빛 으로 인물 을 묘사 합니다 . 그리고 정밀 묘사 로서 의 사실 성 이 아니 라 물감 자국 이 그대로 남 아 있 는 자유 로운 붓질 에 의한 , 말 하 자면 200 년 후 인상파 에서 나 발견 할 수 있 는 진보 된 의미 의 \\' 현실 성 \\' 을 추구 합니다 . 이상 화 된 인물 묘사 에서 탈피 한 것 이 죠 . 자 , 이제 벨라스케스 의 \\' 인노켄티우스 10 세 의 초상 \\' 을 다시 봅니다 . 이상 화 된 이전 의 초상화 들 에선 볼 수 없 었 던 새로운 시도 들 로 인해 첫 부분 에 나열 했 던 고집 세고 성질 고약 한 영감 님 의 특징 들 이 눈 에 들어옵니다 . 실제로 일중독 에 , 고집 스럽 고 성급 한 성격 이 었 던 인노켄티우스 10 세 가 살 아 있 는 것 같 습니다 . 인노켄티우스 10 세 도 이 그림 을 보 고 처음 엔 너무 현실 적 인 자신 의 모습 이 못 마땅 했으나 , 나중 에 는 \" 지극히 생생 하 다 \" 며 칭찬 을 아끼 지 않 았 다고 합니다 . 그런 걸 보 면 ( 역사 에서 부정 적 인 평가 와 는 별개 로 ) 괜히 교황 은 아닌가 봅니다 . 어쨌든 벨라스케스 는 이후 18 세기 의 고 야 , 19 세기 의 마네 와 인상주의 , 심지어 20 세기 의 피카소 와 프란시스 베이컨 같 은 수많 은 작가 들 에게 영감 을 준 \\' 화가 중 의 화가 \\'( 마네 의 편지 중 ) 라는 평가 까지 받 게 됩니다 . 벨라스케스 를 만나 고 나 니 \\' 도리아 팜 필리 미술관 \\' 에서 의 숙제 를 다 한 것 같 아서 나머지 그림 들 은 슬슬 스쳐 지나갑니다 . 그 도 그럴 것 이 원래 궁전 이 었 던 곳 을 미술관 으로 꾸민 탓 에 그림 들 이 궁전 주인 들 의 컬렉션 처럼 배치 되 어 전문 미술관 처럼 한 그림 에 집중 하 기 가 쉽 지 도 않 았 습니다 . 아 , 물론 벨라스케스 의 그림 은 한 방 에 따로 전 시실 을 마련 해서 집중 적 으로 감상 할 수 있 게 합니다 . 그렇게 명작 들 을 스치 듯 둘러보 고 있 는데 그만 내 눈 을 의심 하 고 말 았 습니다 . 그것 은 브 뤼 헬 때문 이 었 습니다 . 근래 에 내 상상 력 을 자극 하 는 작가 들 이 있 습니다 . 알브레히트 뒤러 , 아르킴볼도 , 히에로니무스 보스 , 그리고 브 뤼 헬 . 그런데 그 중 에 브 뤼 헬 이 전혀 예상 치 못한 순간 에 내 앞 에 나타난 것 입니다 . 작 은 화폭 에 확대경 을 대 고 보 아야 할 만큼 세밀 하 게 묘사 된 소품 들 이나 동식물 들 . 그런가 하 면 등장인물 은 어딘지 모르 게 비 현실 적 입니다 . 그러 다 보 니 그림 전체 가 비 현실 적 상상 의 세계 처럼 느껴집니다 . 이후 미친 듯이 브 뤼 헬 만 찾 았 습니다 . 한 작품 한 작품 온 신경 을 다 해 보 고 또 보 았 죠 . 그림 에 말 그대로 코 를 박 고 가까이 봅니다 . 그것 은 경이 와 탄식 의 연속 이 었 습니다 . 그런데 , 한 가지 이상 한 점 이 있 습니다 . 분명 내 가 알 고 있 는 브 뤼 헬 의 화풍 이 긴 한데 정말 브 뤼 헬 의 그림 이 맞 나 하 는 의문 이 듭니다 . 이런 그림 들 을 브 뤼 헬 의 화집 에서 본 기억 이 나 지 않 았 습니다 . 그런데 명패 를 보 니 \\' j . breughel \\' 이라고 적혀 있 습니다 . 순간 요즘 말 로 \\' 멘붕 \\' 이 살짝 오 려고 합니다 . 나와 당신 이 알 고 있 는 플랑드르 의 풍속화 가 브 뤼 헬 은 \\' 피터 브 뤼 헬 ( pieter brueghel ) \\' 인데 도대체 이 사람 은 누구 일까요 ? 급하 게 아이패드 를 꺼내 구글링 을 합니다 . 그러 자 금세 \\' 얕 은 \\' 지식 의 한계 가 드러납니다 . 그 는 피터 브 뤼 헬 의 둘째 아들 \\' 얀 브 뤼 헬 \\' 이 었 습니다 . 첫 아들 \\' 피터 브 뤼 헬 2 세 \\' 도 유명 한 화가 라고 합니다 . 심지어 얀 브 뤼 헬 의 아들 \\' 얀 브 뤼 헬 ( 2 세 ) \\' 도 역시 화가 라고 합니다 . 정말 가족 끼리 다 해 먹 은 셈 이 지요 . 그러 다 보 니 브 뤼 헬 일가 의 그림 들 중 에 는 아직 까지 정확히 누구 의 것 인지 모르 는 작품 들 도 있 다고 합니다 . 이곳 \\' 도리아 팜 필리 미술관 \\' 에서 제 가 찾 은 브 뤼 헬 일가 의 작품 은 12 , 13 편 정도 입니다 . 대부분 \\' 얀 브 뤼 헬 \\' 의 작품 이 었 는데 얀 브 뤼 헬 1 세 인지 2 세 인지 는 명확 하 지 않 습니다 . 제목 들 만 소개 하 면 \\' 성모자 와 동물 들 \\', \\' 에 덴 동산 과 아담 의 창조 \\', \\' 불 의 은유 \\', \\' 물 의 은유 \\', \\' 공기 의 은유 \\', \\' 땅 의 은유 \\' 등 입니다 . 그리고 피터 브 뤼 헬 의 작품 , \\' 나폴리 만 의 전투 \\' 와 \\' 새덫 과 스 케 이터 가 있 는 겨울 풍경 \\' 도 발견 했 는데 , \\' 겨울 풍경 \\' 은 아무래도 오스트리아 빈 의 \\' 미술사 박물관 \\' 에 있 는 아버지 피터 브 뤼 헬 의 작품 을 아들 피터 브 뤼 헬 이 모방 한 것 같 아 보 입니다 . 그런데 아무려면 어떻 습니까 ? 나 에게 이곳 \\' 도리아 팜 필리 미술관 \\' 에서 만난 브 뤼 헬 일가 의 작품 들 은 생애 첫 여행 의 깜짝 선물 이나 마찬가지 인데 말 입니다 . 브 뤼 헬 일가 의 작품 들 이후 티치아노 의 \\' 세례 요한 의 목 을 든 살로메 \\', 조반니 벨리니 의 \\' 할례 \\', 안니발레 카라치 의 \\' 이집트 로 의 도주 \\', 그리고 필리포 리피 의 또 다른 \\' 수태 고지 \\' 등 수많 은 명작 들 을 안타깝 게 스쳐 지나 고 \\' 도리아 팜 필리 미술관 \\' 에서 나오 니 로마 의 초겨울 햇살 이 눈 부십니다 . 이제 다시 이탈리아 인 들 이 얼마나 카라바조 를 사랑 하 는지 확인 하 러 갈 시간 입니다 . 목적지 는 \\' 산 루이지 데이 프란체 시 성당 ( chiesa di san luigi dei francesi ) \\' 입니다 . 7 차 십자군 원정 을 주도 했 던 프랑스 왕 루이 9 세 를 기리 기 위해 건립 된 \\' 산 루이지 데이 프란체 시 성당 \\' 앞 에 는 지금 까지 봐왔 던 다른 성당 들 과 달리 많 은 사람 들 이 모여 있 습니다 . 처음 엔 단지 이곳 이 관광객 많 기 로 유명 한 \\' 나보나 광장 \\' 과 \\' 판테온 \\' 사이 에 있 어서 그런 줄 알 았 습니다 . 그런데 그게 아니 었 습니다 . 성당 문 을 열 고 들어가 보 니 중앙 제단 왼쪽 에 수많 은 사람 들 이 모여 있 습니다 . 나 는 단번에 그 들 이 모두 나와 같 은 목적 으로 이 성당 에 왔 다는 사실 을 직감 했 습니다 . 그것 은 카라바조 때문 이 었 습니다 . 모두 이 성당 의 \\' 콘 타 렐 리 예배당 \\' 을 장식 하 고 있 는 카라바조 의 \\' 성 마태오 \\' 연작 세 편 을 보 기 위해 온 것 이 었 습니다 . 수많 은 사람 들 속 에서 먼저 왼쪽 에 있 는 \\' 성 마태오 의 소명 \\' 을 봅니다 . 마태 복음서 의 저자 로 알려져 있 는 성 마태오 는 원래 로마 를 위해 일 하 는 세금 관리 였 습니다 . 재물 에 대한 욕심 이 특히 강했 던 그 는 그 욕심 을 채우 기 위해 수단 과 방법 을 가리 지 않 았 다고 합니다 . 그래서 창녀 나 죄인 과 같이 천 대 받 는 부류 였 던 세리 가 되 어 부당 한 방법 으로 돈 을 거두어들였 죠 . 그런 마태오 ( 성경 에서 는 제자 가 되 기 전 의 마태오 를 레위 라고 합니다 ) 가 16 세기 베네치 아인 복장 을 한 채 한 무리 의 사람 들 과 함께 술집 에 있 습니다 . 그 들 은 돈 을 세 고 있 었 던 것 같 습니다 . 그때 전통 적 차림 의 예수 가 베드로 와 함께 나타나 누군가 를 가리키 며 말 합니다 . \" 나 를 따르 라 . \" 갑작스러운 부름 에 놀란 마태오 는 돈 을 세 던 것 도 잊어버리 고 \\' 저 말 입니까 ? \\' 하 는 어리둥절 한 표정 으로 예수 를 바라봅니다 . 성경 의 한 구절 을 묘사 한 이 그림 은 바로크 미술 과 카라바조 의 예술 정신 이 절묘 한 조화 를 이루 고 있 는 작품 입니다 . 우선 일반 적 인 성화 와 달리 예수 가 화면 의 중앙 에 위치 해 있 지 않 습니다 . 물론 작품 의 주인공 이 성 마태오 이 니 만큼 그럴 수 도 있 지만 , 예수 는 화면 가장 오른쪽 위치 에 , 카라바조 특유 의 어두운 배경 속 에서 , 그것 도 몸 대부분 이 성 베드로 에게 가려져 있 습니다 . 머리 위 의 윤광 ( nimbus : 성인 들 의 성화 상 머리 뒷부분 에 둥근 광채 를 그린 것 ) 이나 손 동작 이 아니 면 누구 인지 알아보 기 힘들 정도 죠 . 신성 을 일상 적 이 고 사실 적 으로 재현 하 려 했 던 카라바조 의 정신 이 잘 드러납니다 . 반면 에 작품 의 주인공 인 성 마태오 에게 는 빛 이 비추 고 있 습니다 . 그런데 그 빛 은 그림 속 에 묘사 된 빛 만 이 아닙니다 . 그림 속 의 빛 의 방향 은 실제 성당 의 창 으로부터 들어오 는 빛 의 방향 과 일치 합니다 . 현실 의 빛 과 허구 의 빛 이 조화 를 이루 고 있 는 것 입니다 . 그림 의 빛 과 자연 의 빛 , 그리고 어둠 속 을 살아가 던 마태오 를 깨닫 게 하 는 신 의 빛 이 기 도 한 그 빛 은 감상자 들 에게 도 가상 과 현실 의 절묘 한 교차 를 통해 무언 의 가르침 과 특별 한 감동 을 줍니다 . 앞서 \\' 성 이그나치오 디 로욜라 성당 \\' 천장화 에서 보 았 던 바로크 미술 의 특징 이 지요 . 그런데 그림 을 계속 보다 보 니 저 사람 이 정말 성 마태오 가 맞 을까 하 는 의문 이 듭니다 . 그러면 , 주변 상황 에 는 아랑곳없이 고개 를 숙인 채 돈 만 열심히 세 고 있 는 화면 제일 왼쪽 의 젊은이 는 누구 란 말 인가 ? 그리고 안경 을 쓰 고 돈 세 는 모습 만 바라보 고 있 는 사람 은 또 누구 인가 ? 그 들 모두 사실 깨닫 기 전 의 성 마태오 를 상징 하 는 것 은 아닐까 ? 아니면 저 들 모두 물욕 에 사로잡힌 현실 의 인간 들 을 상징 하 는 것 은 아닐까 ? 여러 의문 들 이 연달 아 일어납니다 . 카라바조 는 정말 우리 에게 많 은 고민 을 안겨 주 는 문제 적 화가 가 분명 합니다 . 이제 중앙 의 \\' 성 마태오 와 천사 \\' 를 봅니다 . 의자 에 한 쪽 무릎 을 얹 고 무언가 를 열심히 쓰 고 있 는 마태오 . 그 위 에 천사 가 나타나 신 의 말 을 전하 고 있 습니다 . 문맹 이 었 던 성 마태오 에게 천사 가 영감 을 주 어 복음서 를 쓰 게 했 다는 일화 를 표현 한 이 그림 은 두 명 의 인물 만 으로 굉장히 매력 적 인 장면 을 보여 줍니다 . 그런데 카라바조 는 원래 이 그림 에서 글자 도 모르 는 무지몽매 한 모습 으로 성 마태오 를 묘사 하 려 했 다고 합니다 . 다리 를 꼬 고 앉 아 관람객 쪽 으로 뻗 은 더러운 발 , 농민 처럼 보이 는 지극히 평범 한 얼굴 , 거기 다가 천사 가 쥐 어 주 는 펜 에 손 을 맡기 고 수동 적 으로 복음서 를 써 내려가 는 모습 은 분명 성당 측 이 원했 던 성인 의 모습 은 아니 었 을 것 입니다 ( 이 첫 번 째 그림 은 이탈리아 의 한 부자 가 구입 했으나 세계 2 차 대전 때 발생 한 화재 로 소실 되 어 현재 는 흑백 사진 으로 만 남 아 있 다고 합니다 ) . 결국 로마 가톨릭 측 으로부터 \\' 점잖 지 못하 다 \\' 는 이유 로 거절 당한 카라바조 는 새롭 게 아카 데 믹 하 고 드라마틱 한 장면 을 연출 하 게 됩니다 . 붉 은 색 옷 을 입 은 성 마태오 와 하얀색 의 천사 는 어둡 고 검 은 배경 위 에 극 적 인 명암 과 색채 대비 를 이루 고 있 습니다 . 그런가 하 면 방금 천상 에서 내려온 듯 한 천사 의 움직임 과 비스듬히 몸 을 돌려 천사 를 바라보 는 성 마태오 의 불 안정 한 자세 는 절묘 한 조화 를 이루 어 마치 연극 의 한 장면 처럼 생동감 있 어 보 입니다 . 비록 가톨릭 의 제약 에 자신 의 뜻 을 굽힌 작품 이 긴 하 지만 그 제약 마저 저토록 아름답 게 수용 한 카라바조 . 왜 그 가 이탈리아 인 들 의 사랑 을 받 는지 알 것 같 습니다 . 마지막 으로 오른쪽 에 있 는 \\' 성 마태오 의 순교 \\' 를 봅니다 . 시리아 와 동방 의 페르시아 에서 선교 에 힘쓰 던 마태오 는 에티오피아 에서 칼 에 찔려 순교 합니다 . \\' 포폴로 성당 \\' 에서 보 았 던 \\' 성 베드로 의 순교 \\' 장면 처럼 십자가 형상 으로 누워 있 는 성 마태오 . 하늘 에서 내려온 천사 는 그 에게 순교 를 뜻 하 는 종려나무 가지 를 건네 고 있 습니다 . 그리고 역시 성당 창 을 통해 들어온 빛 이 그런 마태오 를 비춰 주 고 있 습니다 . 성 마태오 를 부른 것 도 , 그 를 천상 의 성인 으로 구원 한 것 도 , 바로 하늘 의 빛 이 란 뜻 이 겠 지요 . 바로크 미술 의 지향 을 선도 적 으로 보여준 카라바조 의 천재 성 에 말 그대로 감탄 을 금할 수 없 습니다 . 그런데 그 느낌 은 나 만 가진 게 아닌가 봅니다 . 카라바조 를 만나 기 위해 몰려온 수많 은 사람 들 . 발 디딜 틈 도 없이 빽빽 하 게 모인 , 그래서 좋 은 위치 에서 제대로 된 그림 감상 을 할 수 도 없 는 상황 이 지만 , 그 들 의 표정 하나하나 에 는 숨길 수 없 는 찬탄 과 감동 이 가득 합니다 . 그 와중 에 타인 에 대한 작 은 배려 도 잊 지 않 습니다 . 다른 사람 들 을 위해 최대한 말 을 아끼 는 것 은 물론 이 고 , 셔터 소리 를 내 지 않 고 플래시 를 터뜨리 지 않 고 촬영 하 는 것 도 당연 합니다 . 뒷사람 이 먼저 카메라 를 들 고 있 는 것 을 발견 하 면 \\' sorry ( 미안 해요 ) \\' 하 며 살짝 비켜 주 기 도 합니다 . 카라바조 의 예술 정신 이 이런 방식 으로 수백 년 을 거쳐 사람 들 과 함께 생생 하 게 살아왔 구나 하 는 생각 에 다시 소름 이 돋 습니다 . 이렇게 많 은 이 들 이 오로지 3 편 의 그림 을 보 기 위해 찾 아 오 고 있 다는 사실 이 부럽 기 도 합니다 . 그런가 하 면 무시 못 할 우리 의 예술 작품 들 도 , 이 처럼 많 은 사람 들 과 함께 호흡 하 고 있 는가 하 는 안타까움 도 듭니다 . 카라바조 의 감동 을 가슴 깊이 간직 한 사람 들 과 함께 성당 을 나섭니다 . 그리고 그 들 의 흐름 대로 발길 을 옮깁니다 . 이내 수많 은 사람 들 이 모인 탁 트인 광장 이 나타납니다 . 어제 만났 던 바로크 미술 의 또 다른 거장 , 베르니니 가 만든 세 개 의 멋진 분수 가 나란히 서 있 는 , 로마인 들 이 가장 사랑 하 는 \\' 나보나 광장 ( piazza navona ) \\' 입니다 .',\n",
       "       '햇빛 이 들 지 않 거나 습기 가 많 은 곳 등 에서 발생 하 는 곰팡이 . 곰팡이 는 제거 하 지 않 으면 번지 기 쉬우므로 , 발견 즉시 제거 해야 하 는데요 . 벽지 곰팡이 제거 방법 을 유한 락스 가 알려 드립니다 .',\n",
       "       '옥류관 . ...! 북한 에서 가장 유명 한 식당 으로 명성 이 자자 한 이 곳 . 평양냉면 마니아 들 에게 옥류관 의 냉면 은 죽 기 전 꼭 한 번 맛보 고 싶 은 음식 으로 꼽힌다 . 출처 최지연 기자 그러나 웬만 한 기회 아니 고서 야 찾아가 맛볼 수 없 는 가깝 고 도 먼 ( 멀 다고 하 면 안 되 겠 지만 ) 이름 이 기 도 하 다 . 특히 지난 4 월 남북 정상 회담 이후 옥류관 냉면 이 중요 한 심볼 로 떠오르 면서 ‘ 진짜 옥류관 냉면 맛 ’ 에 대한 관심 은 더욱 커졌 다 . 그리고 지난 6 일 드디어 그 유명 한 옥류관 냉면 을 먹 어 볼 기회 가 생겼 다 . mbc 에서 ‘ 옥류관 서울 1 호 점 ’ 이 라는 타이틀 의 스페셜 방송 을 준비 하 면서 팝업 스토어 를 열 어 제작 발표회 겸 시식회 를 마련 한 덕분 이 다 . 장소 가 무려 인천 공항 제 2 청사 였으나 판문점 이나 dmz , 임 진각 이 아닌 것 이 어디 냐는 마음 이 었 다 . 옥류관 냉면 을 먹 을 수 있 다는데 인천 공항 쯤 이 야 ! 출처 최지연 기자 물론 옥류관 서울 1 호 점 이 실제로 생기 는 것 도 아니 고 , 옥류관 의 냉면 을 공수 해 오 는 것 도 아닐 텐데 ‘ 어떤 방식 으로 옥류관 냉면 의 맛 을 보여 줄 것 이 냐 ’ 는 의문 이 있 었 다 . 옥류관 출신 셰프 출동 ? 옥류관 에서 알 아 온 레시피 ? 아니면 옥류관 에서 먹 어 본 기억 을 되살려서 최대한 비슷 하 게 재현 한 걸까 ? 그러나 기대 를 품 고 참석 한 제작진 간담회 에서 는 뜻밖 의 배신감 ( ? ) 과 충격 을 맛보 게 됐 다 . ( 왼쪽 부터 ) 김보람 pd , 임정식 셰프 , 김재영 pd 출처 최지연 기자 q . ‘ 옥류관 서울 1 호 점 ’ 의 기획 의도 는 ? 한반도 평화 무드 에 관련 된 아이템 을 준비 하 면서 시작 하 게 됐 습니다 . 4 월 평양 공연 단 소식 에서 가장 화제 됐 던 게 옥류관 만찬 이 었 는데 , 냉면 철 도 아닌데 사람 들 이 냉면 집 에 줄 을 서 서 다 들 옥류관 얘기 를 했 거든요 . 남북 관계 를 재밌 게 풀어낼 소재 가 아닌가 싶 었 고요 . 냉면 을 매개 로 한반도 의 미래 와 평화 에 대해 얘기 하 려고 준비 했 습니다 . ( 김보람 pd ) 출처 최지연 기자 은유 이 자 염원 같 은 것 입니다 . 옥류관 서울 1 호 점 이 서울 에 생긴다는 건 남북 관계 가 좋 아 졌 다는 반증 이 될 수 있 는 거 니까요 . 그런 미래 를 꿈꾸 고 있 기 때문 에 상징 적 으로 택하 게 됐 습니다 . 옥류관 의 맛 을 재현 하 겠 다는 건 단순히 음식 의 의미 보다 는 시대 적 인 흐름 을 옥류관 이 라는 장소 와 냉면 이 라는 음식 을 통해 되짚 어 보 겠 다는 의미 가 있 습니다 . ( 김재영 pd ) 출처 최지연 기자 q . 실제 옥류관 냉면 맛 을 어떻게 재현 했 나 ? 제 가 냉면 만드 는 사람 으로서 저 도 옥류관 냉면 을 먹 어 본 적 은 없 고요 . 옥류관 다녀오 신 분 들 에게 얘기 를 들 어 보 면서 최대한 옥류관 냉면 을 그대로 재현 하 려고 했 습니다 . ( 임정식 셰프 ) 먹 어 본 적 없 고요 . ...? 재밌 는 점 은 옥류관 냉면 이 계속 변화 하 고 있 다고 합니다 . 10 년 전 과 지금 이랑 북한 사회 가 변하 고 있 다는 반증 이 기 도 하 고요 . 북한 최고 지도자 의 입맛 도 좀 달라지 지 않 았 나 싶 습니다 . 10 년 전 에 도 가 보 시 고 , 이번 에 도 다녀오 신 분 이야기 를 들 어 보 니 예전 보다 냉면 자체 의 간 도 세 지 고 , 신맛 도 세 지 고 비주얼 도 화려 해졌 다고 들 었 습니다 . 그런 이야기 를 듣 고 ( 팝업 스토어 의 레시피 를 ) 준비 해 봤 습니다 . ( 임정식 셰프 ) 출처 최지연 기자 q . 임정식 셰프 가 재현 한 옥류관 냉면 은 진짜 옥류관 냉면 과 얼마나 비슷 한가 ? 저 도 외국 에서 들어온 지 얼마 되 지 않 아서 냉면 이 어제 완성 됐 습니다 . 아직 까지 저 만 테스트 한 상태 입니다 . ( 임정식 셰프 ) 저희 셋 다 옥류관 냉면 을 먹 어 보 지 못했 거든요 . 취재 하 면서 들 은 얘기 로 는 10 년 사이 에 맛 이 확실히 달라졌 다는 증언 을 확인 할 수 있 었 지만 그 이후 로 심층 취재 는 하 지 못했 습니다 . ( 김재영 pd ) 그러니까 그냥 임정식 셰프 의 냉면 이 라는 뜻 . ...☆ 출처 최지연 기자 결국 이날 ‘ 옥류관 서울 1 호 점 ’ 을 표방 한 팝업 스토어 에서 먹 은 옥류관 st 냉면 은 진짜 옥류관 냉면 과 비슷 한지 아무 도 확인 해 줄 수 없 다는 얘기 였 다 ! ! 출처 최지연 기자 물론 냉면 맛 이 아니 라 그 안 에 담긴 스토리 가 중요 하 다지만 아쉬운 마음 을 감출 수 는 없 었 다 . 현장 에서 나온 질문 들 도 대부분 ‘ 옥류관 냉면 맛 을 어떻게 재현 했 는지 ’ 에 대한 것 이 었 으니 이런 실망감 은 우리 뿐 만 이 아니 었 을 것 이 다 . 적어도 먹 어 는 보 고 만든 줄 . .. 과연 옥류관 냉면 을 먹 어 본 적 없 는 셰프 가 만든 옥류관 냉면 . .. 을 어떻게 설명 해야 할까 . 학창 시절 과학 상상 화 그리 기 가 이런 느낌 이 었 던가 . 사극 고증 과 비교 해야 할까 . 뜬금없 지만 직접 먹 어 본 레드 벨벳 등 남 한 예술단 멤버 들 이 라도 나타나 서 먹 어 보 고 이 냉면 과 옥류관 냉면 의 싱크로 율 을 비교 해 줘야 하 는 거 아닐까 싶 은 생각 까지 들 었 다 . 출처 최지연 기자 어쨌든 옥류관 냉면 을 직접 먹 어 본 사람 의 말 을 듣 고 최선 을 다 해서 재현 한 ! 임정식 셰프 의 옥류관 st 냉면 은 이날 두 종류 나 공개 됐 다 . 하나 는 통일 냉면 입니다 . 옥류관 냉면 을 조사 해서 재현 한 것 으로 , 육수 에 동치미 국물 을 타 서 신맛 밸런스 를 맞췄 습니다 . 또 하나 는 평화 냉면 인데 , 현재 서울 에서 유행 하 는 고기 국물 베이스 로 만들 었 습니다 . ( 임정식 셰프 ) ( 왼쪽 부터 ) 평화 냉면 , 통일 냉면 출처 최지연 기자 이 중 우리 가 맛본 것 은 통일 냉면 이 다 . 옥류관 의 dna 가 얼마나 섞여 있 는 지 는 모르 겠 지만 그래도 막상 먹 기 전 엔 설렜 던 것 이 사실 . 모든 취재진 이 냉면 을 서빙 받 자마자 카메라 를 드 는 진풍경 이 펼쳐졌 다 . 그렇게 어렵사리 맛본 임정식 셰프 의 옥류관 스타일 냉면 은 한반도기 가 꽂힌 위풍당당 한 모습 으로 등장 했 다 . 식초 와 겨자 는 없이 냉면 단 품 ! 출처 최지연 기자 처음 국물 만 마셨 을 땐 깊 은 육수 맛 이 느껴졌 지만 끝 맛 이 살짝 비린 듯 했 는데 , 면 과 함께 먹 다 보 니 그 느낌 은 완전히 사라졌 다 . 또 기존 평양냉면 맛 집 에서 먹 던 맛 보다 는 확실히 새콤 하 고 간 이 있 었 다 . 짭조름 하 고 새콤 한 동치미 국물 맛 이 어느 정도 느껴 지 면서 도 끝 맛 은 살짝 매콤 한 기운 이 감돌 았 다 . 그럼에도 전체 적 으로 깔끔 하 다는 인상 이 다 . 출처 최지연 기자 출처 최지연 기자 독특 한 점 은 방울토마토 가 들 어 있 었 다는 건데 ‘ 냉면 에 웬 방울토마토 야 ? ’ 싶 으면서 도 식초 와 는 다른 느낌 의 새콤 함 을 준다는 인상 이 었 다 . 이 맛 은 평양냉면 과 함흥냉면 그 사이 어딘가 . .. 일까 . 물론 옥류관 과 상관 없이 정말 맛있 었 기 때문 에 그릇 은 말끔 하 게 비웠 다 . 출처 최지연 기자 임정식 셰프 의 통일 냉면 은 이번 스페셜 방송 을 위해 준비 한 레시피 지만 , 취재 종료 후 현장 시 식단 의 반응 을 참고 해 정식 메뉴 출시 를 고민 해 볼 계획 이 라고 한다 . 통일 냉면 을 기다리 는 시 식단 출처 강효진 기자 언젠가 진짜 ‘ 옥류관 서울 1 호 점 ’ 이 개장 한다면 이날 의 냉면 도 재 평가 받 을 날 이 오 지 않 을까 싶 다 . 출처 최지연 기자 비록 ‘ 옥류관 냉면 을 먹 어 본 적 없 다 ’ 는 pd 들 이 지만 , 이번 ‘ 옥류관 서울 1 호 점 ’ 스페셜 방송 에 는 평양냉면 에 대한 여러 가지 흥미 로운 정보 들 을 담아낼 수 있 었 다고 한다 . 출처 최지연 기자',\n",
       "       \"기획 아카이브 는 50 + 세대 가 새로운 미래 를 준비 하 기 위해 꼭 알 아야 할 온갖 정보 를 정리 해 차곡차곡 쌓 아 두 는 기획 콘텐츠 입니다 . 창업 지원 관련 정보 를 소개 하 는 마지막 글 입니다 . 이전 글 에서 서울시 와 정부 설립 창업 지원 기관 및 프로그램 , 웹 사이트 를 소개 했 습니다 . 이 글 에서 는 소상 공인 , 즉 점포 창업 을 위한 서울시 및 정부 의 지원 정보 와 여성 을 위한 창업 지원 정보 를 정리 합니다 . 1 . 소상 공인 창업 지원 ① 서울 특별시 자영업 지원 센터 서울시 의 소 상공 인 지원 을 전담 하 는 기관 입니다 . 창업 준비 부터 성장 , 폐업 과 재기 에 이르 기 까지 소상 공인 의 전 사업 주기 별 종합 지원 을 시행 하 는 곳 입니다 . 서울 특별시 자영업 지원 센터 의 사업 을 포함 해 서울시 의 소 상공 인 지원 프로그램 을 확인 하 기 위해서 는 이 센터 에서 운영 하 는 세 개 의 사이트 를 기억 해야 합니다 . 소상 공인 종합 지원 포털 , 서울 특별시 소 상공 인 아카데미 , 그리고 서울시 소 상공 인 정보 광장 입니다 . 소상 공인 종합 지원 포털 서울 특별시 자영업 지원 센터 는 기관 홈페이지 를 겸해 각종 소 상공 인 지원 정보 를 모아 놓 은 포털 을 운영 하 고 있 습니다 . 서울시 를 비롯 해 정부 부처 가 시행 하 는 각종 창업 지원 사업 정보 , 자영업 지원 센터 에서 시행 하 는 모든 사업 정보 를 이곳 에서 확인 할 수 있 습니다 . 농수산물 가격 정보 , 서울시 물가 정보 , 소 상공 인 입찰 공고 , 도매 시장 정보 등 도 제공 합니다 . 소상 공인 종합 지원 포털 ( 클릭 ) 서울 특별시 소 상공 인 아카데미 서울시 자영업 지원 센터 는 소 상공 인 창업 및 사업 운영 과 관련 된 온 · 오프라인 교육 을 시행 하 고 있 습니다 . 센터 의 모든 교육 프로그램 과 관련 된 정보 는 서울 특별시 소 상공 인 아카데미 에서 확인 할 수 있 습니다 . 서울 특별시 소 상공 인 아카데미 ( 클릭 ) 서울시 소 상공 인 정보 광장 소상 공인 과 관련 된 각종 정보 를 모아 놓 은 아카이브 입니다 . 소상 공인 창업 및 사업 운영 관련 최신 뉴스 와 간행물 을 확인 할 수 있 습니다 . 사업 계획 수립 , 경영 성 과 분석 , 손익 분기점 계산 등 을 직접 체험 할 수 있 는 서비스 도 제공 합니다 . 서울시 소 상공 인 정보 광장 ( 클릭 ) ② 서울 신용 보증 재단 담보 는 부족 하 지만 대출 이 필요 한 소기업 및 소상 공인 에게 보증 서비스 를 제공 하 는 기관 입니다 . 창업 후 1 년 이내 의 서울 지역 소상 공인 , 업종 전환 과 사업장 이전 등 경영 개선 이 필요 한 소상 공인 을 대상 으로 창업 자금 특별 보증 , 사업장 임차 자금 특별 보증 등 맞춤 형 보증 상품 을 운용 합니다 . 서울시 중소기업 육성 자금 등 의 융자 사업 도 시행 합니다 . 본래 의 보증 및 자금 지원 사업 뿐 아니 라 소기업 및 소 상공 인 종합 지원 기관 으로 사업 영역 을 확대 하 고 있 습니다 . 앞서 소개 한 서울 특별시 자영업 지원 센터 의 운영 도 서울 신용 보증 재단 이 맡 고 있 습니다 . 서울 신용 보증 재단 ( 클릭 ) ③ 소 상공 인 시장 진흥 공단 정부 가 운영 하 는 소 상공 인 종합 지원 기관 입니다 . 교육 , 컨설팅 , 고용 보험료 지원 , 마케팅 지원 , 소 상공 인 정책 자금 융자 , 특성 화 시장 및 상인 육성 등 소 상공 인 창업 및 사업 운영 과 관련 된 모든 영역 에 걸쳐 지원 사업 을 시행 합니다 . 또한 , 공단 에서 는 ' 소 상공 인 마당 ' 이 라는 소 상공 인 종합 포털 을 운영 합니다 . 지원 사업 정보 , 상권 정보 , 각종 조사 · 연구 자료 , 최신 소식 등 을 모아 제공 합니다 . 앞서 소개 한 서울시 소 상공 인 관련 사이트 들 과 더불 어 소 상공 인 지원 관련 정보 가 집결 하 는 허브 라고 할 수 있 습니다 . 소 상공 인 시장 진흥 공단 ( 클릭 ) 소 상공 인 마당 ( 클릭 ) ④ 상권 정보 서비스 서울시 에서 는 ' 우리 마을 가게 상권 분석 서비스 ' 라는 웹 사이트 를 운영 합니다 . 43 개 의 생활 밀착 업종 을 선별 한 뒤 서울시 가 보유 하 고 있 거나 외부 기관 과 협력 해 확보 한 상권 관련 빅 데이터 를 활용 해 업종 별 로 다양 한 상권 관련 정보 를 제공 하 는 사이트 입니다 . 창업 위험 지표 , 업종 별 · 지역 별 상권 관련 지표 , 매출 트렌드 , 인구 현황 등 의 정보 를 편리 하 게 확인 할 수 있 습니다 . 소 상공 인 진흥 공단 에서 도 ' 상권 정보 ' 라는 이름 의 사이트 를 운영 합니다 . 상권 분석 , 경쟁 분석 , 입지 분석 , 수익 분석 으로 카테고리 를 나눠 소 상공 인 창업 및 사업 운영 과 관련 해 알 아 두 어야 할 필수 정보 를 제공 합니다 . 우리 마을 가게 상권 분석 서비스 ( 클릭 ) 상권 정보 ( 클릭 ) 2 . 여성 창업 지원 아직 그 수 와 다양 성 측면 에서 충분 한 상황 은 아니 지만 , 여성 을 대상 으로 특화 된 창업 지원 기관 과 프로그램 도 존재 합니다 . 특히 , 서울시 에서 는 공예 · 디자인 업종 여성 창업자 를 지원 하 는 여성 창업 플라자 와 서울 여성 공예 센터 를 운영 하 고 있 습니다 . 서울시 여성 발전 센터 에서 운영 하 는 여성 창업 보육 센터 , ( 재 ) 여성 기업 종합 지원 센터 여성 창업 보육 센터 와 같이 여성 에게 창업 공간 을 지원 하 는 곳 도 기억 해 두 세요 . ① 여성 창업 플라자 공예 · 디자인 업종 여성 창업자 를 지원 합니다 . 창업 상담 부터 사무 공간 지원 , 판로 개척 까지 종합 지원 을 시행 하 며 , 선발 업체 가 후발 업체 를 지원 하 는 창업 순환 시스템 을 지향 합니다 . 지하철 3 호 선 도곡 역사 내 에 있 습니다 . 서울 특별시 동부여 성 발전 센터 가 운영 합니다 . 여성 창업 플라자 ( 클릭 ) ② 서울 여성 공예 센터 더 아리 움 여성 공예 인 의 창작 과 창업 을 지원 하 는 기관 입니다 . 공예 창업 맞춤 형 지원 프로그램 을 운영 하 며 매년 2 ~ 3 월 경 입주 기업 을 모집 합니다 . 점포 형 창업 실 , 코 워킹 스페이스 , 사진 스튜디오 등 의 시설 을 갖추 고 있 습니다 . 오픈 강좌 , 예술 시장 등 의 행사 도 수시로 열립니다 . 노원구 옛 서울 북부 지방 검찰청 을 리모 델 링 한 건물 을 사용 하 고 있 습니다 . 서울 여성 공예 센터 ( 클릭 ) 서울 여성 공예 센터 점포 형 창업 실 ( 출처 : love . seoul . go . kr ) ③ 여성 발전 센터 여성 창업 보육 센터 서울시 에 는 여성 일자리 정책 실행 기관 인 여성 발전 센터 5 개소 가 운영 되 고 있 습니다 . 이 중 동부 · 남부 · 북부 센터 에서 여성 창업 보육 센터 를 운영 합니다 . 예비 여성 창업자 와 창업 초기 여성 기업인 에게 사무 공간 , 창고 , 회의실 , 휴게실 등 의 공간 을 지원 하 고 , 컨설팅 과 교육 등 의 보육 서비스 도 지원 합니다 . 여성 창업 보육 센터 라는 명칭 아래 시행 되 는 것 은 아니 지만 , 서부 와 중부 센터 에서 도 나름 의 창업 지원 서비스 를 제공 합니다 . 동부 ( 클릭 ) 남부 ( 클릭 ) 북부 ( 클릭 ) 서부 ( 클릭 ) 중부 ( 클릭 ) 센터 별 여성 창업 보육 센터 개요 ( 출처 : [ URL ] ④ ( 재 ) 여성 기업 종합 지원 센터 한국 여성 경제 인 협회 가 운영 하 는 여성 기업 및 여성 창업 지원 기관 입니다 . 매년 여성 청 업경 진 대회 를 개최 하 고 , 서울 을 포함 한 전국 15 개 광역 시도 에서 창업 보육 센터 를 운영 하 고 있 습니다 . 창업 2 년 이내 의 여성 기업 및 예비 여성 창업자 에게 1 년 간 사무 공간 과 컨설팅 , 판로 개척 등 을 지원 합니다 . 센터 에서 운영 하 는 여성 기업 종합 정보 포털 에서 각종 지원 사업 공고 를 확인 할 수 있 습니다 . 여성 기업 종합 정보 포털 ( 클릭 ) 지금 까지 세 번 에 걸쳐 50 + 세대 가 알 아 두 면 좋 을 창업 지원 관련 정보 를 정리 했 습니다 . 각 기관 이나 프로그램 별 세부 정보 까지 는 소개 하 지 못했 습니다 . 창업 에 관심 있 는 분 이 라면 , 우선 이러 한 지원 기관 이 존재 한다는 사실 을 파악 하 는 1 차 자료 로 활용 하 시 기 바랍니다 . 민간 영역 의 정보 를 제외 하 고 서울시 와 정부 관련 정보 만 정리 해도 이렇게 많 은 창업 지원 기관 과 프로그램 이 존재 합니다 . 현실 적 으로 모든 기관 에 관심 을 두 고 빠짐 없이 지원 정보 를 체크 하 는 것 은 어렵 겠 지만 , 적어도 글 에서 소개 한 주요 기관 ( ex . 서울 창업 허브 ) 이나 정보 가 모이 는 포털 사이트 ( ex . k - 스타트업 ) 정도 만 즐겨찾기 에 추가 해 놓 아도 , 꼭 필요 한 지원 정보 를 뒤늦 게 접하 는 사태 는 피할 수 있 습니다 . 다음 글 에서 는 50 + 세대 가 취업 · 일자리 정보 를 편리 하 게 확인 및 검색 할 수 있 는 온라인 소스 를 정리 해 소개 합니다 . 기획 아카이브 글 목록 ( 클릭 )\",\n",
       "       '01 . 대회 정보 홈페이지 , 포스터 등 을 통해 대회 오픈 정보 를 확인 할 수 있 습니다 . 02 . 서비스 가입 / 대회 참가 카카오 계정 으로 로그인 , 아레나 서비스 가입 후 참가 가능 합니다 . 03 . 모델 링 / 분석 데이터 를 다운로드 하 여 모델링 , 분석 을 진행 합니다 . 04 . 제출 예측 한 성능 이 가장 좋 은 버전 으로 결과물 을 제출 합니다 . 05 . 대회 마감 최종 제출 결과물 및 채점 대상자 를 확인 합니다 . 06 . 채점 제출 한 결과물 을 바탕 으로 심사 기준 에 따라 평가 를 진행 합니다 .',\n",
       "       '좀 더 보 기 편한 깃 북 버전 의 나만 의 웹 크롤러 만들 기 가 나왔 습니다 ! 이번 가이드 는 가이드 3 편 ( selenium 으로 무적 크롤러 만들 기 ) 의 확 장편 입니다 . 아직 selenium 을 이용 해 보 지 않 은 분 이 라면 먼저 저 가이드 를 보 고 오 시 는 걸 추천 합니다 . headless chrome ? 머리 없 는 크롬 ? headless 라는 용어 는 ‘ 창 이 없 는 ’ 과 같 다고 이해 하 시 면 됩니다 . 여러분 이 브라우저 ( 크롬 등 ) 을 이용 해 인터넷 을 브라우징 할 때 기본 적 으로 창 이 뜨 고 html 파일 을 불러오 고 , css 파일 을 불러와 어떤 내용 을 화면 에 그러 야 할지 계산 을 하 는 작업 을 브라우저 가 자동 으로 진행 해줍니다 . 하지만 이 와 같 은 방식 을 사용 할 경우 사용 하 는 운영 체제 에 따라 크롬 이 실행 이 될 수 도 , 실행 이 되 지 않 을 수 도 있 습니다 . 예 를 들 어 우분투 서버 와 같 은 os 에서 는 ‘ 화면 ’ 자체 가 존재 하 지 않 기 때문 에 일반 적 인 방식 으로 는 크롬 을 사용 할 수 없 습니다 . 이 를 해결 해 주 는 방식 이 바로 headless 모드 입니다 . 브라우저 창 을 실제로 운영 체제 의 ‘ 창 ’ 으로 띄우 지 않 고 대신 화면 을 그려 주 는 작업 ( 렌더링 ) 을 가상 으로 진행 해 주 는 방법 으로 실제 브라우저 와 동일 하 게 동작 하 지만 창 은 뜨 지 않 는 방식 으로 동작 할 수 있 습니다 . 그러면 왜 크롬 ? 일전 가이드 에서 phantomjs ( 팬텀 ) 라는 브라우저 를 이용 하 는 방법 에 대해 다룬 적 이 있 습니다 . 팬텀 은 브라우저 와 유사 하 게 동작 하 고 javascript 를 동작 시켜 주 지만 성능 상 의 문제점 과 크롬 과 완전히 동일 하 게 동작 하 지 는 않 는다는 문제점 이 있 습니다 . 우리 가 크롤러 를 만드 는 상황 이 대부분 크롬 에서 진행 하 고 , 크롬 의 결과물 그대로 가져오 기 위해서 는 브라우저 도 크롬 을 사용 하 는 것 이 좋 습니다 . 하지만 여전히 팬텀 이 가지 는 장점 이 있 습니다 . webdriver binary 만 으로 추가 적 인 설치 없이 환경 을 만들 수 있 다는 장점 이 있 습니다 . 윈도우 기준 크롬 59 , 맥 / 리눅스 기준 크롬 60 버전 부터 크롬 에 headless mode 가 정식 으로 추가 되 어서 만약 여러분 의 브라우저 가 최신 이 라면 크롬 의 headless 모드 를 쉽 게 이용 할 수 있 습니다 . 크롬 버전 확인 하 기 크롬 버전 확인 은 크롬 브라우저 에서 chrome : / / version / 로 들어가 확인 할 수 있 습니다 . 이 와 같이 크롬 버전 이 60 버전 이상 인 크롬 에서 는 ‘ headless ’ 모드 를 사용 할 수 있 습니다 . 크롬 드라이버 ( chromedriver ) 업데이트 크롬 버전 이 올라감 에 따라 크롬 을 조작 하 도록 도와 주 는 chromedriver 역시 함께 업데이트 를 진행 해야 합니다 . [ URL ] 위 링크 에서 latest release 옆 크롬 드라이버 를 선택 해 os 별로 알맞 은 zip 파일 을 받 아 압축 을 풀 어 줍시다 . 기존 코드 수정 하 기 크롬 의 헤드 리스 모드 를 사용 하 는 방식 은 기존 selenium 을 이용 한 코드 와 거의 동일 합니다만 , 몇 가지 옵션 을 추가 해 줘야 합니다 . 기존 에 webdriver 를 사용 해 크롬 을 동작 한 경우 아래 와 같 은 코드 를 사용 할 수 있 었 습니다 . 1 2 3 4 5 6 7 8 9 10 11 from selenium import webdriver driver = webdriver . chrome ( \\' chromedriver \\' ) driver . get ( \\'[ URL ] ) driver . implicitly _ wait ( 3 ) driver . get _ screenshot _ as _ file ( \\' naver _ main . png \\' ) driver . quit ( ) 위 코드 를 동작 시키 면 크롬 이 켜 지 고 파이썬 파일 옆 에 naver _ main . png 라는 스크린 샷 하나 가 생기 게 됩니다 . 이 코드 는 지금 까지 우리 가 만들 었 던 코드 와 큰 차이 가 없 는 걸 확인 해 보 세요 . 하지만 이 코드 를 몇 가지 옵션 만 추가 해 주 면 바로 headless 모드 로 동작 하 게 만들 어 줄 수 있 습니다 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from selenium import webdriver options = webdriver . chromeoptions ( ) options . add _ argument ( \\' headless \\' ) options . add _ argument ( \\' window - size = 1920 x 1080 \\' ) options . add _ argument ( \" disable - gpu \" ) driver = webdriver . chrome ( \\' chromedriver \\' , chrome _ options = options ) driver . get ( \\'[ URL ] ) driver . implicitly _ wait ( 3 ) driver . get _ screenshot _ as _ file ( \\' naver _ main _ headless . png \\' ) driver . quit ( ) 위 코드 를 보 시 면 chromeoptions ( ) 를 만들 어 add _ argument 를 통해 headless 모드 인 것 과 , 크롬 창 의 크기 , 그리고 gpu ( 그래픽 카드 가속 ) 를 사용 하 지 않 는 옵션 을 넣 어 준 것 을 볼 수 있 습니다 . 제일 중요 한 부분 은 바로 options . add _ argument ( \\' headless \\') 라는 부분 입니다 . 크롬 이 headless 모드 로 동작 하 도록 만들 어 주 는 키워드 에요 . 그리고 크롬 창 의 크기 를 직접 지정 해 준 이유 는 , 여러분 이 일반 적 으로 노트북 이나 데스크 탑 에서 사용 하 는 모니터 의 해상도 가 1920 x 1080 이 기 때문 입니다 . 즉 , 여러분 이 일상 적 으로 보 는 것 그대로 크롬 이 동작 할 거 라는 기대 를 해 볼 수 있 습니다 ! 마지막 으로 는 disable - gpu 인데요 , 만약 위 코드 를 실행 했 을 때 gpu 에러 ~ 가 난다면 -- disable - gpu 로 앞 에 dash ( -) 를 두 개 더 붙여 보 세요 . 이 버그 는 크롬 자체 에 있 는 문제점 입니다 . 브라우저 들 은 cpu 의 부담 을 줄이 고 좀 더 빠른 화면 렌더링 을 위해 gpu 를 통해 그래픽 가속 을 사용 하 는데 , 이 부분 이 크롬 에서 버그 를 일으키 는 현상 을 보이 고 있 습니다 . ( 윈도우 크롬 61 버전 까지 는 아직 업데이트 되 지 않 았 습니다 . 맥 61 버전 에 는 해결 된 이슈 입니다 . ) 그리고 driver 변수 를 만들 때 단순 하 게 chromedriver 의 위치 만 적 어 주 는 것 이 아니 라 chrome _ options 라는 이름 의 인자 를 함께 넘겨 줘야 합니다 . 이 chrome _ options 는 chrome 을 이용 할 때 만 사용 하 는 인자 인데요 , 이 인자 값 을 통해 headless 등 의 추가 적 인 인자 를 넘겨 준답니다 . 자 , 이제 그러면 한 번 실행 해 보 세요 . 크롬 창 이 뜨 지 않 았 는데도 naver _ main _ headless . png 파일 이 생겼 다면 여러분 컴퓨터 에서 크롬 이 headless 모드 로 성공 적 으로 실행 된 것 이 랍니다 ! headless 브라우저 임 을 숨기 기 headless 모드 는 cli 기반 의 서버 os 에서 도 selenium 을 통한 크롤링 / 테스트 를 가능 하 게 만드 는 멋진 모드 지만 , 어떤 서버 들 에서 는 이런 headless 모드 를 감지 하 는 여러 가지 방법 을 쓸 수 있 습니다 . 아래 글 에서 는 headless 모드 를 탐지 하 는 방법 과 탐지 를 ‘ 막 는 ’ 방법 을 다룹니다 . ( 창 과 방패 , 또 새로운 창 ! ) 아래 코드 의 test _ url 은 [ URL ] 인데요 , 이곳 에서 headless 모드 가 감춰졌 는지 아닌지 확인 해 볼 수 있 습니다 . user agent 확인 하 기 headless 탐지 하 기 가장 쉬운 방법 은 user - agent 값 을 확인 하 는 방법 입니다 . 일반 적 인 크롬 브라우저 는 아래 와 같 은 user - agent 값 을 가지 고 있 습니다 . 1 mozilla / 5 . 0 ( macintosh ; intel mac os x 10 _ 12 _ 6 ) applewebkit / 537 . 36 ( khtml , like gecko ) chrome / 61 . 0 . 3163 . 100 safari / 537 . 36 하 지만 headless 브라우저 는 아래 와 같 은 user - agent 값 을 가지 고 있 습니다 . 잘 보 시 면 ‘ headlesschrome / ~~’ 와 같이 ‘ headless ’ 라는 단어 가 들어가 있 는 걸 확인 할 수 있 습니다 ! 1 mozilla / 5 . 0 ( x 11 ; linux x 86 _ 64 ) applewebkit / 537 . 36 ( khtml , like gecko ) headlesschrome / 60 . 0 . 3112 . 50 safari / 537 . 36 headless 탐지 막 기 따라서 기본 적 으로 갖 고 있 는 user - agent 값 을 변경 해 줘야 합니다 . 이것 도 위 에서 사용 한 chrome _ options 에 추가 적 으로 인자 를 전달 해 주 면 됩니다 . 위 코드 를 약간 바꿔 아래 와 같이 만들 어 보 세요 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from selenium import webdriver test _ url = \\'[ URL ] options = webdriver . chromeoptions ( ) options . add _ argument ( \\' headless \\' ) options . add _ argument ( \\' window - size = 1920 x 1080 \\' ) options . add _ argument ( \" disable - gpu \" ) options . add _ argument ( \" user - agent = mozilla / 5 . 0 ( macintosh ; intel mac os x 10 _ 12 _ 6 ) applewebkit / 537 . 36 ( khtml , like gecko ) chrome / 61 . 0 . 3163 . 100 safari / 537 . 36 \" ) driver = webdriver . chrome ( \\' chromedriver \\' , chrome _ options = options ) driver . get ( test _ url ) user _ agent = driver . find _ element _ by _ css _ selector ( \\'# user - agent \\' ). text print ( \\' user - agent : \\' , user _ agent ) driver . quit ( ) 이제 여러분 의 headless 크롬 은 일반 적 인 크롬 으로 보일 거 랍니다 . 플러그인 개수 확인 하 기 headless 탐지 하 기 크롬 에 는 여러분 이 따로 설치 하 지 않 아도 추가 적 으로 플러그인 몇 개 가 설치 되 어 있 답니다 . pdf 내장 리더 기 같 은 것 들 이 죠 . 하 지만 headless 모드 에서 는 플러그인 이 하나 도 로딩 되 지 않 아 개수 가 0 개 가 됩니다 . 이 를 통해 headless 모드 라고 추측 할 수 있 답니다 . 아래 자바 스크립트 코드 를 통해 플러그인 의 개수 를 알아낼 수 있 습니다 . 1 2 3 if ( navigator . plugins . length === 0 ) { console . log ( \" headless 크롬 이 아닐까 ? ?\" ); } headless 탐지 막 기 물론 이 탐지 를 막 는 방법 도 있 습니다 . 바로 브라우저 에 ‘ 가짜 플러그인 ’ 리스트 를 넣 어 주 는 것 이 죠 ! 아래 코드 와 같이 javascript 를 실행 해 플러그인 리스트 를 가짜 로 만들 어 넣 어 줍시다 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from selenium import webdriver test _ url = \\'[ URL ] options = webdriver . chromeoptions ( ) options . add _ argument ( \\' headless \\' ) options . add _ argument ( \\' window - size = 1920 x 1080 \\' ) options . add _ argument ( \" disable - gpu \" ) options . add _ argument ( \" user - agent = mozilla / 5 . 0 ( macintosh ; intel mac os x 10 _ 12 _ 6 ) applewebkit / 537 . 36 ( khtml , like gecko ) chrome / 61 . 0 . 3163 . 100 safari / 537 . 36 \" ) options . add _ argument ( \" lang = ko _ kr \" ) driver = webdriver . chrome ( \\' chromedriver \\' , chrome _ options = options ) driver . get ( \\' about : blank \\' ) driver . execute _ script ( \" object . defineproperty ( navigator , \\' plugins \\', { get : function ( ) { return [ 1 , 2 , 3 , 4 , 5 ] ;},});\" ) driver . get ( test _ url ) user _ agent = driver . find _ element _ by _ css _ selector ( \\'# user - agent \\' ). text plugins _ length = driver . find _ element _ by _ css _ selector ( \\'# plugins - length \\' ). text print ( \\' user - agent : \\' , user _ agent ) print ( \\' plugin length : \\' , plugins _ length ) driver . quit ( ) 위 와 같이 js 로 navigator 객체 의 plugins 속성 자체 를 오버 라 이 딩 해 임의 의 배열 을 반환 하 도록 만들 어 주 면 개수 를 속일 수 있 습니다 . 단 , 출력물 에서 는 plugin length 가 여전히 0 으로 나올 거 에요 . 왜냐하면 사이트 가 로딩 될 때 이미 저 속성 이 들어가 있 기 때문 이 죠 : ’( 그래서 우리 는 좀 더 다른 방법 을 뒤 에서 써볼 거 에요 . 언어 설정 headless 탐지 하 기 여러분 이 인터넷 을 사용 할 때 어떤 사이트 를 들어가 면 다 국어 사이트 인데 도 여러분 의 언어 에 맞 게 화면 에 나오 는 경우 를 종종 보 고 , 구글 크롬 을 써서 외국 사이트 를 돌아다니 면 ‘ 번역 해 줄까 ? ’ 하 는 친절 한 질문 을 종종 봅니다 . 이 설정 이 바로 브라우저 의 언어 설정 이 랍니다 . 즉 , 여러분 이 선호 하 는 언어 가 이미 등록 되 어 있 는 것 이 죠 . headless 모드 에 는 이런 언어 설정 이 되 어 있 지 않 아서 이 를 통해 headless 모드 가 아닐까 ‘ 추측 ’ 할 수 있 습니다 . headless 탐지 막 기 headless 모드 인 것 을 감추 기 위해 언어 설정 을 넣 어 줍시다 . 바로 add _ argument 를 통해 크롬 에 전달 해 줄 수 있 답니다 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 from selenium import webdriver test _ url = \\'[ URL ] options = webdriver . chromeoptions ( ) options . add _ argument ( \\' headless \\' ) options . add _ argument ( \\' window - size = 1920 x 1080 \\' ) options . add _ argument ( \" disable - gpu \" ) options . add _ argument ( \" user - agent = mozilla / 5 . 0 ( macintosh ; intel mac os x 10 _ 12 _ 6 ) applewebkit / 537 . 36 ( khtml , like gecko ) chrome / 61 . 0 . 3163 . 100 safari / 537 . 36 \" ) options . add _ argument ( \" lang = ko _ kr \" ) driver = webdriver . chrome ( \\' chromedriver \\' , chrome _ options = options ) driver . get ( test _ url ) driver . execute _ script ( \" object . defineproperty ( navigator , \\' plugins \\', { get : function ( ) { return [ 1 , 2 , 3 , 4 , 5 ] }})\" ) driver . execute _ script ( \" object . defineproperty ( navigator , \\' languages \\', { get : function ( ) { return [ \\' ko - kr \\', \\' ko \\']}})\" ) user _ agent = driver . find _ element _ by _ css _ selector ( \\'# user - agent \\' ). text plugins _ length = driver . find _ element _ by _ css _ selector ( \\'# plugins - length \\' ). text languages = driver . find _ element _ by _ css _ selector ( \\'# languages \\' ). text print ( \\' user - agent : \\' , user _ agent ) print ( \\' plugin length : \\' , plugins _ length ) print ( \\' languages : \\' , languages ) driver . quit ( ) 단 , 출력물 에서 는 language 가 빈 칸 으로 나올 거 에요 . 왜냐하면 사이트 가 로딩 될 때 이미 저 속성 이 들어가 있 기 때문 이 죠 : ’( 그래서 우리 는 좀 더 다른 방법 을 뒤 에서 써볼 거 에요 . webgl 벤더 와 렌 더러 headless 탐지 하 기 여러분 이 브라우저 를 사용 할 때 webgl 이 라는 방법 으로 그래픽 카드 를 통해 그려지 는 방법 을 가속 을 한답니다 . 즉 , 실제로 디바이스 에서 돌아간다면 대부분 은 그래픽 가속 을 사용 한다는 가정 이 기반 인 셈 이 죠 . 사실 이 방법 으로 차단 하 는 웹 사이트 는 거의 없 을 거 에요 . 혹여나 gpu 가 속 을 꺼 둔 브라우저 라면 구별 할 수 없 기 때문 이 죠 . 위 코드 에서 사용 해 준 disable - gpu 옵션 은 사실 이 그래픽 가속 을 꺼주 는 것 이 에요 . 따라서 이 부분 을 보완 해 줄 필요 가 있 습니다 . headless 탐지 막기 가장 쉬운 방법 은 크롬 이 업데이트 되 길 기대 하 고 disable - gpu 옵션 을 꺼 버리 는 것 이 지만 , 우선 은 이 옵션 을 함께 사용 하 는 방법 을 알려 드릴게요 . 위 에서 사용 한 script 실행 방법 을 또 써 볼 것 이 랍니다 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 from selenium import webdriver test _ url = \\'[ URL ] options = webdriver . chromeoptions ( ) options . add _ argument ( \\' headless \\' ) options . add _ argument ( \\' window - size = 1920 x 1080 \\' ) options . add _ argument ( \" disable - gpu \" ) options . add _ argument ( \" user - agent = mozilla / 5 . 0 ( macintosh ; intel mac os x 10 _ 12 _ 6 ) applewebkit / 537 . 36 ( khtml , like gecko ) chrome / 61 . 0 . 3163 . 100 safari / 537 . 36 \" ) options . add _ argument ( \" lang = ko _ kr \" ) driver = webdriver . chrome ( \\' chromedriver \\' , chrome _ options = options ) driver . get ( test _ url ) driver . execute _ script ( \" object . defineproperty ( navigator , \\' plugins \\', { get : function ( ) { return [ 1 , 2 , 3 , 4 , 5 ] }})\" ) driver . execute _ script ( \" object . defineproperty ( navigator , \\' languages \\', { get : function ( ) { return [ \\' ko - kr \\', \\' ko \\']}})\" ) driver . execute _ script ( \" const getparameter = webglrenderingcontext . getparameter ; webglrenderingcontext . prototype . getparameter = function ( parameter ) { if ( parameter === 37445 ) { return \\' nvidia corporation \\'} if ( parameter === 37446 ) { return \\' nvidia geforce gtx 980 ti opengl engine \\';} return getparameter ( parameter ) ;};\" ) user _ agent = driver . find _ element _ by _ css _ selector ( \\'# user - agent \\' ). text plugins _ length = driver . find _ element _ by _ css _ selector ( \\'# plugins - length \\' ). text languages = driver . find _ element _ by _ css _ selector ( \\'# languages \\' ). text webgl _ vendor = driver . find _ element _ by _ css _ selector ( \\'# webgl - vendor \\' ). text webgl _ renderer = driver . find _ element _ by _ css _ selector ( \\'# webgl - renderer \\' ). text print ( \\' user - agent : \\' , user _ agent ) print ( \\' plugin length : \\' , plugins _ length ) print ( \\' languages : \\' , languages ) print ( \\' webgl vendor : \\' , webgl _ vendor ) print ( \\' webgl renderer : \\' , webgl _ renderer ) driver . quit ( ) 위 코드 에서 는 webgl 렌 더러 를 nvidia 회사 와 gtx 980 ti 엔 진인 ‘ 척 ’ 하 고 있 는 방법 입니다 . 하 지만 webgl print 구문 에서 는 여전히 빈 칸 일 거 에요 . 이 역시 이미 사이트 로딩 시 속성 이 들어가 있 기 때문 이 에요 . headless 브라우저 숨기 는 방법 다 함께 쓰 기 위 에서 사용 한 방법 중 user - agent 를 바꾸 는 방법 외 에 는 사실 모두 javascript 를 이용 해 값 을 추출 하 고 오버 라 이 딩 하 는 방식 으로 바꿔 보 았 습니다 . 하지만 번번히 결과물 이 빈 칸 으로 나오 는 이유 는 driver . execute _ script 라는 함수 자체 가 사이트 가 로딩 이 끝난 후 ( onload ( ) 이후 ) 실행 되 기 때문 입니다 . 즉 , 우리 는 우리 가 써준 저 js 코드 가 사이트 가 로딩 되 기 전 실행 되 어야 한다는 것 이 죠 ! 사실 기본 크롬 이 라면 사이트 가 로딩 되 기 전 js 를 실행 하 는 extension 들 을 사용 할 수 있 어요 . 하 지만 headless 크롬 에서 는 아직 extension 을 지원 하 지 않 습니다 : ’( 그래서 차선책 으로 mitmproxy 라는 proxy 프로그램 을 사용 해 볼 거 에요 . mitmproxy 사용 하 기 진행 하 기 전 앞서 만들 었 던 모든 js 코드 가 들 어 있 는 content . js 를 아래 처럼 만들 어 주 세요 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 const cdp = require ( \\' chrome - remote - interface \\' ); const useragent = \\' mozilla / 5 . 0 ( x 11 ; linux x 86 _ 64 ) applewebkit / 537 . 36 ( khtml , like gecko ) chrome / 60 . 0 . 3112 . 50 safari / 537 . 36 \\' cdp ( async function ( client ) { const { network , page } = client ; await page . enable ( ) ; await network . enable ( ) ; await network . setuseragentoverride ( { useragent }); }); object . defineproperty ( navigator , \\' languages \\' , { get : function ( ) { return [ \\' ko - kr \\' , \\' ko \\' ]; }, }); object . defineproperty ( navigator , \\' plugins \\' , { get : function ( ) { return [ 1 , 2 , 3 , 4 , 5 ] ; } }); const getparameter = webglrenderingcontext . getparameter ; webglrenderingcontext . prototype . getparameter = function ( parameter ) { if ( parameter === 37445 ) { return \\' intel open source technology center \\' ; } if ( parameter === 37446 ) { return \\' mesa dri intel ( r ) ivybridge mobile \\' ; } return getparameter ( parameter ) ; }; [ \\' height \\' , \\' width \\' ]. foreach ( property => { const imagedescriptor = object . getownpropertydescriptor ( htmlimageelement . prototype , property ) ; object . defineproperty ( htmlimageelement . prototype , property , { . .. imagedescriptor , get : function ( ) { if ( this . complete && this . naturalheight == 0 ) { return 20 ; } return imagedescriptor . get . apply ( this ) ; }, }); }); const elementdescriptor = object . getownpropertydescriptor ( htmlelement . prototype , \\' offsetheight \\' ); object . defineproperty ( htmldivelement . prototype , \\' offsetheight \\' , { . .. elementdescriptor , get : function ( ) { if ( this . id === \\' modernizr \\' ) { return 1 ; } return elementdescriptor . get . apply ( this ) ; }, }); 우선 mitmproxy 를 pip 로 설치 해 주 세요 . 1 pip install mitmproxy 그리고 proxy 처리 를 해 줄 파일 인 inject . py 파일 을 만들 어 주 세요 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 from bs 4 import beautifulsoup from mitmproxy import ctx with open ( \\' content . js \\' , \\' r \\' ) as f : content _ js = f . read ( ) def response ( flow ) : if flow . response . headers [ \\' content - type \\' ] ! = \\' text / html \\' : return if not flow . response . status _ code == 200 : return html = beautifulsoup ( flow . response . text , \\' lxml \\' ) container = html . head or html . body if container : script = html . new _ tag ( \\' script \\' , type = \\' text / javascript \\' ) script . string = content _ js container . insert ( 0 , script ) flow . response . text = str ( html ) ctx . log . info ( \\' successfully injected the content . js script . \\' ) 이제 터미널 에서 아래 명령어 로 mitmproxy 서버 를 띄워 주 세요 . 1 mitmdump - p 8080 - s \" inject . py \" 이 서버 는 크롤링 코드 를 실행 할 때 항상 켜져 있 어야 해요 ! 이제 우리 크롤링 코드 에 add _ argument 로 proxy 옵션 을 추가 해 주 세요 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 from selenium import webdriver test _ url = \\'[ URL ] options = webdriver . chromeoptions ( ) options . add _ argument ( \\' headless \\' ) options . add _ argument ( \\' window - size = 1920 x 1080 \\' ) options . add _ argument ( \" disable - gpu \" ) options . add _ argument ( \" user - agent = mozilla / 5 . 0 ( macintosh ; intel mac os x 10 _ 12 _ 6 ) applewebkit / 537 . 36 ( khtml , like gecko ) chrome / 61 . 0 . 3163 . 100 safari / 537 . 36 \" ) options . add _ argument ( \" proxy - server = localhost : 8080 \" ) driver = webdriver . chrome ( \\' chromedriver \\' , chrome _ options = options ) driver . get ( test _ url ) print ( driver . page _ source ) user _ agent = driver . find _ element _ by _ css _ selector ( \\'# user - agent \\' ). text plugins _ length = driver . find _ element _ by _ css _ selector ( \\'# plugins - length \\' ). text languages = driver . find _ element _ by _ css _ selector ( \\'# languages \\' ). text webgl _ vendor = driver . find _ element _ by _ css _ selector ( \\'# webgl - vendor \\' ). text webgl _ renderer = driver . find _ element _ by _ css _ selector ( \\'# webgl - renderer \\' ). text print ( \\' user - agent : \\' , user _ agent ) print ( \\' plugin length : \\' , plugins _ length ) print ( \\' languages : \\' , languages ) print ( \\' webgl vendor : \\' , webgl _ vendor ) print ( \\' webgl renderer : \\' , webgl _ renderer ) driver . quit ( ) 하지만 사실 이 코드 는 정상 적 으로 동작 하 지 않 을 거 에요 . 헤 드리스 모드 를 끄 면 잘 돌아가 지만 헤 드리스 모드 를 켜 면 정상 적 으로 동작 하 지 않 아요 . 바로 ssl 오류 때문 입니다 . 크롬 에서 ssl 을 무시 하 도록 만들 수 있 고 , 로컬 의 http 를 신뢰 가능 하 도록 만들 수 도 있 지만 아직 크롬 headless 모드 에서 는 지원 하 지 않 습니다 . 정확히 는 아직 webdriver 에서 지원 하 지 않 습니다 . 결론 아직 까지 는 크롬 headless 모드 에서 https 사이트 를 ‘ 완전히 사람 처럼 ’ 보이 게 한 뒤 크롤링 하 는 것 은 어렵 습니다 . 하지만 곧 업데이트 될 크롬 에서 는 익스텐션 사용 기능 이 추가 될 예정 이 기 때문 에 이 기능 이 추가 되 면 복잡 한 과정 없이 js 를 바로 추가 해 진짜 일반 적 인 크롬 처럼 동작 하 도록 만들 수 있 으리라 생각 합니다 . 사실 서버 입장 에서 위 와 같 은 요청 을 보내 는 경우 처리 를 할 수 있 는 방법 은 js 로 헤 드리스 유무 를 확인 하 는 방법 이 전부 입니다 . 즉 , 서버 입장 에서 도 ‘ 식별 ’ 은 가능 하 지만 이 로 인해 유의미 한 차단 은 하 기 어렵 습니다 . 현재 로서 는 useragent 값 만 변경 해 주 어도 대부분 의 사이트 에서 는 자연 스럽 게 크롤링 을 진행할 수 있 으리라 생각 합니다 . reference',\n",
       "       '재테크 목적 으로 적금 과 예금 상품 많이 비교 하 시 죠 ? 기본 적 으로 매월 일정 한 금액 을 입금 하 는 적금 은 경제 활동 을 시작 하 는 분 께 많이 권해 드립니다 . 예금 은 일정 한 기간 동안 은행 에 목돈 을 맡기 는 방식 이 기 때문 에 경제 활동 을 막 시작 한 분 보다 는 큰 금액 을 은행 에 맡기 고 안정 적 으로 금리 ( 상품 에 따라 변동 금리 예금 도 있 습니다 . ) 우대 에 따라 이자 를 받 고자 하 는 분 께 적합 한 상품 입니다 . 적금 과 예금 으로 목돈 을 만들 고 더 큰 돈 으로 키우 기 위해서 두 금융 상품 의 특징 을 아 는 것 이 재테크 의 첫 걸음 일 텐데요 . 예 로 적금 과 예금 의 금리 가 똑같이 4 % 라고 할지라도 최종 금융 상품 만기 시 이자 금액 은 달라지 기 때문 입니다 . 적금 도 정기 적 금과 자유 적 립식 적금 등 으로 나누 어 지 고 , 예금 도 고정 금리 , 변동 금리 등 다양 한 상품 이 존재 하 는데요 . 가장 기본 적 인 적금 과 예금 의 차이 만 간단 하 게 짚 어 보 겠 습니다 . 예금 과 적금 , 정확 하 게 어떤 종류 가 있 나 ? 예금 이란 ? 예금 이 란 일정 기간 을 정해 놓 고 자신 의 돈 을 은행 에 맡기 는 것 을 말 하 는데 , 예금 방법 에 따라 보통 예금 , 당좌 예금 , 별단 예금 , 정기예금 등 으로 나누 어 집니다 . 예금 은 일정 금액 , 예 를 들 어 1 억 원 을 예금 한다면 , 1 억 을 한 번 에 은행 에 넣 고 정해진 기간 동안 중도 에 찾 지 않 고 두 면 만기일 에 정해진 이자 수익 을 얻 는 형태 입니다 . 그럼 예금 별 특징 을 살펴보 겠 습니다 . 보통 예금 입출금 이 자유 롭 고 , 가입 대상 이나 예치금 액 , 예치기 간 에 제약 이 없 습니다 . 당좌 예금 예금자 의 요구 에 따라 예금액 의 일부 또는 전부 를 언제 든지 지급 받 는 예금 입니다 . 주로 개인 이 아닌 기업 이 대상 이 며 , 은행 이 예금자 를 대신 해 수표 나 어음 으로 입출금 을 대행 해 주 어 예금자 의 비용 과 노력 을 절약 시켜 주 는 예금 으로 이자 나 저축 을 목적 으로 하 기 보다 자금 의 보관 과 지급 위탁 이 주목적 입니다 . 정기예금 예금자 가 일정 기간 을 정하 여 금액 을 맡기 고 기간 만료일 까지 환급 을 받 지 않 는 기한부 예금 입니다 . 위 의 예금 중 에 일반인 들 이 주로 가입 하 는 것 은 보통 예금 과 정기예금 입니다 . 보통 예금 은 입출금 하 는 통장 으로 , 정기예금 은 종잣돈 마련 통장 으로 이용 하 고 있 습니다 . 적금 이란 ? 적금 은 은행 에 일정 금액 을 일정 기간 낸 다음 찾 는 방법 으로 정기 적금 과 각종 부금 으로 나눌 수 있 습니다 . 정기 적금 정해진 기간 동안 일정액 을 매월 적립 하 고 만기일 에 약정금 액 을 지급 받 는 것 입니다 . 각종 부금 정기 적 금과 비슷 하나 일정 회차 이상 부금 을 내 면 일정 금액 을 융자 받 을 수 있 는 권리 를 줍니다 . 자유 적금 자유 적금 이란 매월 의무 납입 액 제한 없이 자유 롭 게 적립 하 는 정기 적금 입니다 . 정기예금 과 정기 적금 의 결정 적 인 차이 는 ? 만기 시 이자 지급 에 대한 차이 정기예금 이자와 정기 적금 이자 는 계산 방법 이 다릅니다 . 예 를 들 어 정기예금 이자 연 4 % 는 실제로 도 연 4 % 이 지만 , 정기 적금 이자 연 4 % 의 실질 이 자율 은 그 절반 수준 인 2 % 입니다 . 이런 차이 는 정기예금 은 은행 에 원금 을 가입 기간 동안 미리 예치 하 기 때문 에 전체 가입 기간 동안 연 이자 가 적용 되 지만 , 정기 적금 은 원금 에 해당 하 는 돈 을 모으 기 위해 매달 일정 금액 을 납입 하 는 것 이 기 때문 에 매달 내 는 납입 액 마다 이자 적용 이 달라 정기 적금 의 실질 이자 율 이 원래 이 자율 과 다른 현상 이 나타납니다 . 실제 사례 를 통해 정기 적 금과 정기예금 의 차이 를 알 자 ! 1 년 에 1 , 200 만 원 씩 저축 하 는 두 사람 이 있 습니다 . a 는 매달 100 만 원 씩 적금 을 해서 1 년 동안 1 , 200 만 원 을 모았 고 , b 는 1 월 1 일 신년 을 맞 아 1 , 200 만 원 을 예금 했 습니다 . 적금 과 예금 의 금리 가 똑같이 3 % 라면 , 이 둘 의 이자 는 각각 얼마 일까요 ? ( 이자 소득세 제외 ) 답 은 , a 는 원금 1 , 200 만 원 을 넣 고 이자 19 만 5 , 000 원 을 받 습니다 . b 는 원금 1 , 200 만 원 에 넣 고 이자 36 만 원 을 받 습니다 . 똑같 은 3 % 의 금리 ( 금리 는 은행 에 예치 하 거나 적립 하 는 돈 에 따라붙 는 이자 를 산정 할 때 쓰임 ) 인데 , 왜 이런 결과 가 나왔 는지 자세히 설명 해 보 겠 습니다 . 정기 적금 은 1 월 에 100 만 원 을 내 면 3 % 금리 이율 이 12 월 내내 적용 받 지만 , 2 월 에 는 100 만 원 을 내 면 3 % 이율 이 11 개월 만 적용 받 게 되 고 , 3 월 에 100 만 원 을 내 면 3 % 이율 이 10 개월 만 적용 받 게 됩니다 . 이런 식 으로 마지막 달 내 는 100 만 원 은 한 달 동안 만 금리 의 영향 을 받 게 됩니다 . 금리 는 3 % 이 지만 정작 원금 대비 1 . 625 % 의 수익 을 받 게 됩니다 . 정기예금 은 같 은 금액 의 목돈 을 한 번 에 입금 을 하 면 , 예금 기간 내내 목돈 을 금리 의 영향 에 둘 수 있 게 됩니다 . b 의 예시 를 보 면 3 % 금리 를 12 개월 적용 하 는 셈 입니다 . 적금 과 예금 의 차이 로 본 올바른 재테크 방법 은 ? 적금 으로 목돈 을 모으 는 것 이 가장 중요 합니다 . 이후 만기 된 적금 금액 은 그대로 예금 으로 옮겨 이자 혜택 을 받 습니다 . 이렇게 꾸준히 적금 을 예금 으로 옮기 는 방법 을 반복 하 다 보 면 어느새 목표 한 목돈 숫자 가 찍힌 통장 을 보 며 흐뭇 해 할 날 이 올 것 입니다 . 적금 과 예금 의 차이 , 확실히 아셨 죠 ? ibk 기업 은행 과 함께 목돈 마련 쉽 게 하 시 길 바랍니다 . 목돈 모으 는 첫 걸음 ! ibk 기업 은행 적금 / 예금 상품 보 기',\n",
       "       '라인 웍스 에서 는 electronic health record ( 이하 ehr ) 데이터 를 이용 하 여 다양 한 머신 러닝 프로젝트 를 진행 하 고 있 습니다 . 이번 글 에서 는 의료 인공지능 개발 프로젝트 의 성능 개선 을 위해 사용 한 lightgbm 알고리즘 과 수많 은 feature 를 줄이 기 위한 feature selection 방법 을 소개 합니다 . 추가 로 , mdwalks exi 에서 선보였 던 deep learning 을 사용 한 mimic - iii 30 일 이내 재 입원 예측 모델 ( [ URL ] lightgbm 사용 모델 의 성능 을 비교 해 보 겠 습니다 . * 이번 글 은 라인 웍스 여름 인턴 프로그램 에 참여 한 이 서호 님 의 아이디어 와 실험 내용 을 바탕 으로 작성 되 었 습니다 . 1 . 들어가 기 mimic - iii 모델 구축 에 사용 한 데이터 는 mimic - iii 데이터베이스 입니다 . ehr 데이터 중 거의 유일 하 게 공개 된 다년간 의 중환자 입원 기록 으로 , 46 , 520 명 환자 들 의 58 , 976 건 의 입원 정보 를 포함 하 고 있 습니다 . mdwalks exi 로 구축 한 30 일 재 입원 예측 모델 ( [ URL ] 동일 한 데이터 를 사용 했 습니다 . * mimic - iii 데이터베이스 에 대한 상세 정보 는 공식 페이지 ( [ URL ] 참조 하 세요 . * mimic - iii 데이터베이스 를 세팅 하 는 방법 은 라인 웍스 블로그 글 ( [ URL ] 참조 하 세요 . lightgbm lightgbm 은 microsoft 에서 발표 하 고 제공 하 는 오픈 소스 그래 디언 트 부스 팅 결정 트리 프레임워크 입니다 . 기존 의 그래 디언 트 부스 팅 결정 트리 프레임워크 의 경우 고차원 변수 가 포함 된 큰 데이터 에서 정확도 와 효율 성 이 떨어지 는 경향 이 있 는데 , 이런 단점 을 gradient - based one - side sampling ( goss ) 과 exclusive feature bundling ( efb ) 라는 두 가지 기술 을 이용 하 여 보완 한 프레임워크 입니다 . * 자세 한 내용 은 아래 링크 를 참고 하 세요 . * 관련 논문 ( [ URL ] * lightgbm documentation ( [ URL ] 2 . 데이터 전처리 mimic - iii 데이터 에 는 수십 개 의 테이블 이 있 습니다 . 실제 모델 에 사용 하 기 엔 너무 많 은 양 이 라 의료 전문가 들 의 조언 을 얻 어 가장 중요 하 다고 생각 하 는 일부 테이블 을 우선 으로 선정 하 여 사용 하 였 습니다 . 사용 한 데이터 는 다음 과 같 습니다 . 환자 방문 정보 방문 유형 , 이전 방문 횟수 , 입원 기간 , 중환자실 이용 기록 등 환자 기본 정보 나이 , 성별 등 진단 해당 방문 에서 환자 가 진단 받 은 내역 874 개 진단 코드 ( 전체 데이터 에서 100 회 이상 사용 된 코드 ) 의료 행위 해당 방문 에서 수행 된 의료 행위 내역 258 개 의료 행위 코드 ( 전체 데이터 에서 100 회 이상 사용 된 코드 ) 의약품 해당 방문 에서 처방 받 은 의약품 내역 366 개 의약품 코드 ( 전체 데이터 에서 1 , 000 회 이상 사용 된 코드 ) lab 검사 해당 방문 에서 검사 한 검사 내역 154 개 lab 검사 코드 ( 전체 데이터 에서 1 , 000 회 이상 사용 된 코드 ) 각종 이벤트 ( 투여 , 배출 , 차트 등등 ) 2 , 956 개 이벤트 코드 코드 와 범주 형 데이터 는 one - hot encoding 하 였 고 , 수치 형 데이터 는 normalization ( 표준 화 ) 하 지 않 고 사용 했 습니다 . 모델 에 입력 된 최종 feature 는 총 4 , 903 개 입니다 . 46 , 520 명 의 환자 를 5 fold 로 나누 어 cross validation 을 수행 하 였 고 , 전체 방문 데이터 는 총 58 , 976 건 으로 각 fold 별 로 11 , 794 / 11 , 860 / 11 , 818 / 11 , 687 / 11 , 817 건 으로 나누 었 습니다 . 3 . 실험 결과 위 에서 처리 한 데이터 를 이용 하 여 lightgbm 모델 을 학습 시켰 습니다 . 그리고 모델 간 의 성능 비교 를 위해 mdwalks exi 에서 사용 했 던 “ neural network ( deep learning ) 모델 ” 과 lightgbm 과 같 은 tree 형 모델 이 지만 다른 ensemble 모델 을 사용 하 는 “ random forest 모델 ” 을 추가 로 학습 하 였 습니다 . 그리고 각 모델 별 로 30 일 이내 재 입원 여부 를 예측 해 보 았 습니다 . 예 측력 평가 에 사용 한 metric 은 auroc 입니다 . 모델 별 결과 는 다음 과 같 습니다 . lightgbm 이 모든 fold 에서 neural network 와 random forest 보다 좋 은 성능 을 보여 주 고 있 습니다 . 4 . feature selection 을 통한 성능 개선 feature importance neural network 와 달리 tree 형 모델 에서 는 모델 이 어떤 feature 를 중요 하 게 보 는지 에 대한 정보 ( feature importance ) 를 쉽 게 얻 어 낼 수 있 습니다 . lightgbm 도 이 를 쉽 게 추출 하 도록 구현 이 되 어 있 습니다 . 위 에서 학습 된 lightgbm 모델 의 feature importance 을 추출 해 상위 10 개 만 그래프 로 그려 보 았 습니다 . importance 가 가장 높 은 feature 는 “ icu ( 중환자실 ) 입원 기간 ( length of stay in icu ) ” 입니다 . 비슷 한 feature 인 “ 전체 입원 기간 ( length of stays ) ” 도 10 위 안 에 포함 되 어 있 습니다 . 나이 ( age ) 와 사망 여부 ( dead ) 가 2 위 와 3 위 를 차지 하 고 있 고 , 이전 365 일 간 방문 횟수 ( visit count of last 365 day ) , 이전 180 일 간 방문 횟수 ( visit count of last 180 day ) 도 포함 되 어 있 습니다 . 즉 , 이전 에 도 병원 에 방문 을 많이 했 다면 앞 으로 도 방문 할 가능 성 이 높 다고 유추 해 볼 수 있 습니다 . drg _ mortality 와 drg _ severity 는 청구 비용 을 나타내 는 feature 인데 , 많 은 비용 이 청구 되 었 을 수록 재 입원 가능 성 이 높 을 것 이 란 판단 도 가능 할 것 같 습니다 . 특정 진단 코드 와 차트 검사 코드 도 포함 되 어 있 습니다 . 사람 이 이해 할 수 있 는 방향 으로 모델 이 잘 학습 되 었 다고 볼 수 있 겠 습니다 . 이번 엔 feature importance 값 자체 를 보 겠 습니다 . 전체 값 들 의 간단 한 통계 수치 는 다음 과 같 습니다 . 전체 수 : 4 , 903 4 , 903 평균 : 1 . 2033 1 . 2033 분산 : 94 . 4078 94 . 4078 최소 값 : 0 0 최대 값 : 347 . 4 347 . 4 중앙값 : 0 중앙값 이 0 이 라는 점 이 눈 에 띕니다 . feature 중 50 % 이상 의 importance 가 0 이 라는 얘기 입니다 . 확인 을 해 보 았 더니 857 개 를 제외 하 고 나머지 82 % 에 해당 하 는 4 , 046 개 feature 의 importance 가 모두 0 이 었 습니다 . 모델 이 이렇게 많 은 feature 를 중요 하 지 않 다고 판단 했 다면 , 굳이 모든 feature 들 을 사용 할 필요 가 없 어 보 입니다 . feature 일부 를 제거 하 여 학습 하 면 계산 량 과 메모리 사용량 을 줄이 고 더 빠르 게 학습 결과 를 도출 할 수 있 을 것 으로 예상 됩니다 . feature selection feature selection 은 성능 에 더 많 은 영향 을 주 는 feature 를 우선 적 으로 선택 하 여 학습 하 는 방법 입니다 . 상위 몇 개 혹은 몇 % 를 선택 하 는 방법 , 반복 적 으로 하위 feature 를 제거 해 나가 는 방법 등 다양 한 방법 이 존재 합니다 . 우선 lightgbm 모델 에서 feature importance 가 0 인 값 만 제거 하 여 실험 해 보 았 습니다 . 성능 에 는 큰 영향 을 주 지 않 았 지만 , 전체 중 82 % 의 무 의미 한 feature 의 값 이 제거 되 었 기 때문 에 lightgbm 이 학습 해야 하 는 feature 의 수 가 줄어들 면서 학습 속도 가 3 배 이상 향상 했 습니다 . 이번 에 는 학습 된 lightgbm 의 feature importance 를 이용 하 여 선택 된 feature 를 neural network 모델 에 도 적용 하 여 실험 해 보 았 습니다 . neural network 는 hidden layer 때문 에 feature importance 를 쉽 게 추출 할 수 없 으므로 다른 모델 의 feature 정보 를 이용 하 면 성능 을 더 올릴 수 있 지 않 을까 하 는 생각 이 었 습니다 . 그 결과 , 기존 neural network 모델 의 auroc 는 0 . 7242 ± 0 . 0092 feature selection 이 적용 된 neural network 모델 의 auroc 는 0 . 7363 ± 0 . 0181 로 성능 이 1 % 증가 하 였 습니다 . lightgbm 의 성능 ( 0 . 7444 ± 0 . 0123 ) 에 는 미치 지 못하 지만 , 4 배 이상 의 학습 속도 향상 은 물론 성능 까지 개선 되 는 효과 를 볼 수 있 었 습니다 . 5 . 마치 며 이번 글 에서 는 재 입원 예측 에 lightgbm 알고리즘 을 적용 하 고 neural network 모델 과 성능 을 비교 해 보 았 습니다 . 추가 로 tree 모델 의 장점 이 라 할 수 있 는 feature importance 를 이용 해 유의미 한 feature 를 추출 하 고 neural network 에 적용 해 보 았 습니다 . lightgbm 적용 을 통해 gradient boosting 모델 의 학습 속도 와 성능 의 향상 을 확인 할 수 있 었 고 , 간단 한 neural network 모델 에 비해 lightgbm 모델 이 재 입원 예측 에선 더 좋 은 성능 을 보임 을 확인 했 습니다 . 또한 , gradient boosting 모델 의 feature importance 를 이용 하 여 neural network 등 다른 모델 들 의 예측 성능 까지 향상 시킬 수 있 음 을 알 게 되 었 습니다 . 라인 웍스 에서 는 ehr 데이터 를 포함 한 의료 분야 에서 사용 되 는 다양 한 데이터 를 이용 한 머신 러닝 연구 를 계속 진행 하 고 있 습니다 . 저희 와 함께 연구 를 진행할 머신 러닝 엔지니어 를 모시 고 있 습니다 . 자세 한 내용 은 채용 공고 ( [ URL ] 확인 해 주 세요 .',\n",
       "       '패키지 인덱스 인덱스 정보 를 업데이트 : / etc / apt / sources . list sudo apt - get update 설치 된 패키지 업 그래 이드 : sudo apt - get upgrade sudo apt - get dist - upgrade 패키지 설치 sudo apt - get install 패키지 이름 패키지 재설 치 apt - get -- reinstall install 패키지 이름 패키지 삭제 : sudo apt - get remove 패키지 이름 sudo apt - get -- purge remove 패키지 이름 패키지 소스 코드 다운로드 sudo apt - get source 패키지 이름 sudo apt - get build - dep 패키지 이름 패키지 검색 sudo apt - cache search 패키지 이름 패키지 정보 보 기 sudo apt - cache show 패키지 이름 / var / cache / apt / archive / last modified : 2009 . 06 . 25 apt - get ( advanced packaging tool ) 은 우분투 ( ubuntu ) 를 포함 안 데비안 ( debian ) 계열 의 리눅스 에서 쓰이 는 팩 키 지 관리 명령어 도구 입니다 . 우분투 에 는 gui 로 되 어 있 는 시 냅 틱 꾸러미 관리자 도 있 기 는 하지만 이런 저런 개발 관련 패키지 를 설치 할 때 는 커맨드 기반 인 apt - get 이 더 편하 기 도 합니다 . sudo 는 superuser 권한 으로 실행 하 기 위함입니다 . apt - get 은 인덱스 를 가지 고 있 는데 이 인덱스 는 에 있 습니다 . 이곳 에 저장 된 저 장소 에서 사용 할 패키지 의 정보 를 얻 습니다 . 설치 되 어 있 는 패키지 를 모두 새 버전 으로 업 그래이 드 합니다 . 의존 성 검사 하 며 설치 하 기 설정 파일 은 지우 지 않 음 설정 파일 까지 모두 지움 위 에서 받 은 소스 코드 를 의존 성 있 게 빌드 apt 를 이용 해서 설치 된 deb 패키지 는 에 설치 가 됩니다 .',\n",
       "       'python decorator ( 데코레이터 ) python 으로 작성 된 opensource 의 코드 들 을 보 다 보 면 , 아래 와 같이 @ 로 시작 하 는 구문 들 을 볼 수 있 다 . @ decorator _ def function ( ) : print \" what is decorator ? \" decorator 를 한마디 로 얘기 하 자면 , 대상 함수 를 wrapping 하 고 , 이 wrapping 된 함수 의 앞뒤 에 추가 적 으로 꾸며질 구문 들 을 정의 해서 손쉽 게 재 사용 가능 하 게 해 주 는 것 이 다 . ( 무슨 말 이 야 ? ) decorator 는 어떤 경우 에 쓰 는 건가 ? 코딩 을 하 다 보 면 종종 이런 경우 가 있 다 . 메인 구문 이 있 고 , 여기 에 부가 적 인 구문 을 추가 하 고 싶 을 때 말 이 다 . 그리고 이 부가 적 인 구문 을 반복 해서 사용 하 고 싶 은 경우 도 있 다 . 이때 부가 적 인 ( 그리고 반복 적 인 ) 작업 을 decorator 로 선언 해서 자유 롭 게 사용 이 가능 하 다는 것 이 다 . 처음 엔 이해 가 잘 안 가 지만 , 막상 사용 하 다 보 면 굉장히 쉽 다는 것 을 느낄 수 있 다 . 예 를 들 어 아래 와 같 은 함수 가 있 다고 생각 해 보 자 . def main _ function ( ) : print \" main function start \" \" main function start \" 라는 문장 을 출력 하 는 , 매우 간단 한 함수 이 다 . 만약 , 이 함수 에 추가 적 인 작업 들 을 더 넣 고 싶 다면 ? 예 를 들 어 , 해당 문장 을 출력 하 기 전 과 후 에 날짜 와 시간 을 출력 하 고 싶 다면 ? 간단히 생각 하 면 아래 와 같이 하 면 될 것 이 다 . import datetime def main _ function ( ) : print datetime . datetime . now ( ) print \" main function start \" print datetime . datetime . now ( ) 이 예제 만 놓 고 보 면 , 매우 간단 한 함수 이 고 특별히 복잡 하 게 추가 할 게 없 는 작업 이 기 때문 에 , 이렇게 해도 큰 무리 는 없 다 . 그런데 만약 이 와 같 은 패턴 의 함수 가 여러 번 있 다면 어떨까 ? def main _ function _ 1 ( ) : print \" main function 1 start \" def main _ function _ 2 ( ) : print \" main function 2 start \" def main _ function _ 3 ( ) : print \" main function 3 start \" . .... x 100 번 . . 그리고 여기 에 도 각 함수 의 문장 이 출력 되 기 전 과 후 에 시간 을 출력 하 고 싶 다면 ? import datetime def main _ function _ 1 ( ) : print datetime . datetime . now ( ) print \" main function 1 start \" print datetime . datetime . now ( ) def main _ function _ 2 ( ) : print datetime . datetime . now ( ) print \" main function 2 start \" print datetime . datetime . now ( ) def main _ function _ 3 ( ) : print datetime . datetime . now ( ) print \" main function 3 start \" print datetime . datetime . now ( ) . ... x 100 번 반복 되 는 구문 이 많 아 지 다 보 니 점점 소스 가 지저분 해 지 며 , 원래 main 함수 의 가독성 도 떨어진다 . ( 코드 가 변태 적 으로 변함 을 볼 수 있 다 . ) 지금 예문 은 메인 과 추가 구문 이 한 줄 밖에 안 되 기 때문 에 매우 간단 하 지만 , 실제 코딩 할 때 의 상황 을 생각 해 보 면 문제 는 더욱 심각 해 진다 . 이럴 경우 에 decorator 구문 을 사용 해 보 자 . decorator 를 사용 해 보 자 아래 의 예제 는 위 의 변태 코드 에 decorator 를 적용 한 것 이 다 . import datetime def datetime _ decorator ( func ) : def decorated ( ) : print datetime . datetime . now ( ) func ( ) print datetime . datetime . now ( ) return decorated @ datetime _ decorator def main _ function _ 1 ( ) : print \" main function 1 start \" @ datetime _ decorator def main _ function _ 2 ( ) : print \" main function 2 start \" @ datetime _ decorator def main _ function _ 3 ( ) : print \" main function 3 start \" . .... x 100 번 decorator 함수 를 재 사용 함 으로써 , main 함수 에 대한 가독성 과 직관 성 이 훨씬 좋 아 진 것 을 볼 수 있 다 . 그리고 같 은 패턴 을 여러 번 사용 하 더라고 간단히 @ 를 붙이 면 끝 이 므로 사용 도 간편 하 다 . decorator 선언 된 부분 을 자세히 설명 하 면 , 먼저 decorator 역할 을 하 는 함수 를 정의 하 고 , 이 함수 에서 decorator 가 적용 될 함수 를 인자 로 받 는다 . python 은 함수 의 인자 로 다른 함수 를 받 을 수 있 다는 특징 을 이용 하 는 것 이 다 . decorator 역할 을 하 는 함수 내부 에 또 한 번 함수 를 선언 ( nested function ) 하 여 여기 에 추가 적 인 작업 ( 시간 출력 ) 을 선언 해 주 는 것 이 다 . nested 함수 를 return 해 주 면 된다 . 마지막 으로 , main 함수 들 의 앞 에 @ 를 붙여 decorator 역할 을 하 는 함수 를 호출 해 준다 . 그러면 끝 - 그렇 다 . 생각 보다 어렵 지 않 다 . 노파심 에 이야기 하 면 , decorator 가 꾸며 주 는 기능 이 라고 해서 대상 함수 의 수행 중간 에 끼어드 는 구문 은 할 수 없 다 . decorator 는 원래 작업 의 앞 뒤 에 추가 적 인 작업 을 손쉽 게 사용 가능 하 도록 도와 주 는 역할 이 라는 것 이 다 . 위 예 제 는 함수 를 이용 한 decorator 를 구현 한 것 이 고 , class 형태 로 도 구현 이 가능 하 다 . class 형태 로 decorator 를 사용 해 보 자 . decorator 를 class 로 사용 하 고 싶 다면 아래 와 같이 __ call __ 함수 로 decorator 형식 을 정의 해 주 면 된다 . class 의 __ call __ 함수 로 정의 해 주 는 게 nested 함수 형식 으로 정의 한 것 보다 더 깔끔 해 보인다 . import datetime class datetimedecorator : def __ init __( self , f ) : self . func = f def __ call __( self , * args , ** kwargs ) : print datetime . datetime . now ( ) self . func ( * args , ** kwargs ) print datetime . datetime . now ( ) class mainclass : @ datetimedecorator def main _ function _ 1 ( ) : print \" main function 1 start \" @ datetimedecorator def main _ function _ 2 ( ) : print \" main function 2 start \" @ datetimedecorator def main _ function _ 3 ( ) : print \" main function 3 start \" my = mainclass ( ) my . main _ function _ 1 ( ) my . main _ function _ 2 ( ) my . main _ function _ 3 ( )',\n",
       "       'python 3 . 2 에서 concurrent . futures 모듈 이 추가 되 었 습니다 . 이 모듈 은 멀티 스레드 와 멀티 프로세스 에 대한 고 수준 api 를 포함 하 고 있 으며 스레드 풀 / 프로세스 풀 기반 의 동작 을 기본 적 으로 지원 합니다 . 파이썬 제약 : gil python 은 두 개 이상 의 스레드 가 동시 에 실행 될 때 두 개 이상 의 스레드 가 하나 의 자원 을 동시 에 액세스 할 때 발생 할 수 있 는 문제점 을 방지 하 기 위해 gil ( global internal lock ) 이 라는 것 을 도입 했 습니다 . 즉 , 스레드 가 실행 될 때 , 프로그램 내 의 리소스 전체 에 락 이 걸립니다 . 결국 python 구현 에서 는 동시 에 몇 개 의 스레드 가 실행 이 되 던 간 에 gil 에 의해서 한 번 에 하나 의 스레드 만 실행 됩니다 . 멀티 스레드 의 경우 문맥 교환 ( context switch ) 에 필요 한 리소스 까지 고려 하 면 단일 스레드 보다 성능 이 떨어지 게 되 는 것 을 확인 할 수 있 습니다 . gil 은 아주 오래 전 부터 파이썬 의 약점 으로 지적 받 았 습니다 . gil 때문 에 멀티 스레드 를 통한 분산 처리 는 파이썬 내 에서 의미 가 없 으며 , 분산 처리 를 통해 성능 의 이익 을 보 려면 멀티 프로세스 를 사용 해야 합니다 . 하지만 프로세스 를 추가 로 생성 하 는 것 은 os 입장 에서 는 매우 비용 이 많이 드 는 일 이 며 , 특히 윈도우 환경 에서 는 어지간히 커다란 작업 이 아니 면 프로세스 생성 에 드 는 시간 이 가장 큰 병목 이 될 가능 성 이 있 습니다 . concurrent . futures 모듈 concurrent . futures 모듈 은 별도 규격 의 스레드 객체 를 작성 하 지 않 고 함수 호출 을 객체 화 하 여 다른 스레드 나 다른 프로세스 에서 이 를 실행 할 수 있 게 해줍니다 . 이때 중심 역할 을 하 는 것 이 executor 클래스 입니다 . executor 클래스 는 다시 threadpoolexecutor 와 processpoolexecutor 로 나뉘 는데 두 클래스 의 차이 는 동시 성 작업 을 멀티 스레드 로 처리 하 느냐 , 멀티 프로세스 로 처리 하 느냐 만 있 지 거의 동일 한 기능 을 제공 합니다 . future executor 를 이용 한 동시 성 처리 는 호출 해야 할 함수 와 그 에 전달 될 인자 들 을 executor 에 넘겨 주 는 것 으로 시작 되 는데 , executor 의 해당 메소드 는 다른 스레드 의 리턴 을 기다릴 필요 가 없 으므로 바로 리턴 하 게 됩니다 . 이 때 리턴 되 는 객체 가 future 객체 이 며 , 이 객체 의 상태 를 조사 하 여 완료 여부 를 확인 하 거나 , 해당 객체 내 작업 이 완료 되 기 를 기다리 거나 혹은 미리 콜백 을 넘겨 놓 아 둘 수 도 있 습니다 . executor executor 객체 는 풀 기반 으로 작업 을 관리 합니다 . 초기 화 시 에 몇 개 의 worker 가 사용 될 것 인지 를 정해 주 면 전달 되 는 작업 들 을 큐 에 넣 고 worker pool 에서 사용 가능 한 worker 로 하여금 작업 을 처리 하 게 합니다 . submit ( fn , * args , ** kwargs ) 함수 fn 에 대해 주 어 진 인자 들 을 전달 하 여 실행 할 수 있 는 future 객체 를 리턴 합니다 . 해당 함수 는 호출 즉시 스케줄링 됩니다 . with threadpoolexcutor ( max _ workers = 1 ) as executor : future = executor . submit ( pow , 323 , 1235 ) print ( future . result ( ) ) map ( func , * iterables , timeout = none ) 일반 함수 map 과 동일 하나 , 각 호출 은 병렬 적 으로 일어납니다 . 만약 타임아웃 값 이 지정 된 경우 , 맵 핑 작업 이 완료 되 지 않 은 호출 이 있 으면 timeouterror 가 일어납니다 . 입력 데이터 와 동작 함수 를 짝 지어서 바로 스케줄링 하 도록 합니다 . map ( ) 함수 는 이터 레이터 를 리턴 하 는데 , 이 는 각 개별 작업 이 동시 에 실행 된 후 , 먼저 종료 된 작업 부터 내놓 는 리턴 값 을 내놓 게 됩니다 . shutdown ( wait = true ) executor 에게 종료 시그널 을 보냅니다 . 시그널 을 받 은 executor 는 실행 중 및 대기 중 인 모든 future 에 대해 리소스 를 정리 합니다 . shutdown 후 에 submit 이나 map 을 호출 하 면 런타임 에러 가 발생 합니다 . 만약 wait 값 이 true 로 정해 지 면 진행 및 대기 중 이 던 작업 이 종료 된 후 에 shutdown 이 일어나 고 , 그 때 까지 해당 함수 는 리턴 을 보류 하 게 됩니다 . 만약 강제 shutdown 을 피하 고 싶 다면 with 구문 내 에서 사용 합니다 . import shutil with threadpoolexcutor ( max _ workers = 4 ) as e : e . submit ( shutil . copy , \\' src 1 . txt \\', \\' dest 1 . txt \\') e . submit ( shutil . copy , \\' src 2 . txt \\', \\' dest 2 . txt \\') e . submit ( shutil . copy , \\' src 3 . txt \\', \\' dest 3 . txt \\') e . submit ( shutil . copy , \\' src 4 . txt \\', \\' dest 4 . txt \\') 예 제 아래 는 0 . 1 초 마다 처리 해야 할 데이터 를 수집 하 고 이 를 멀티 프로세스 에서 처리 하 는 예제 입니다 . from concurrent . futures import processpoolexecutor from time import sleep def process ( * args ) : result = # 입력 받 은 인자 들 을 처리 한다 . .. time . sleep ( 1 ) print ( result ) def main ( ) : exe = processpoolexecutor ( max _ workers = 4 ) as exe : while true : cont , x = collect _ arguments ( ) if not cont : break if x : exe . submit ( process , * x ) else : sleep ( 0 . 1 ) exe . shutdown ( wait = true ) if __ name __ == \"__ main __\": main ( ) 위 코드 는 일종 의 데몬 으로 다음 과 같이 동작 합니다 . 매 입력 된 데이터 를 처리 하 는 함수 는 process ( ) . 이 함수 는 처리 가 끝나 면 1 초간 대기 했 다가 결과 를 화면 에 출력 . 최대 4 개 까지 의 프로세스 를 사용 할 수 있 도록 executor 를 생 성 데이터 를 수집 하 여 계속 진행 할 것 인지 여부 를 확인 하 고 , 진행 한다면 수집 된 값 들 을 처리 하 도록 executor 에게 요청 무한 루프 내 에서 도 약간 텀 을 줌 더 이상 처리 하 지 않 는다면 루프 에서 빠져 나오 는데 , 이 때 executor 는 아직 실행 되 고 있 는 작업 들 이 있 으면 이 들 이 완료 될 때 까지 기다린 후 종료 프로그램 종료 여기 서 중요 한 부분 은 if __ name __ == \"__ main __\": 부분 인데 , 자식 프로세스 에서 실행 되 는 worker 는 작업 에 필요 한 함수 정보 를 얻 기 위해서 본 파일 을 import 하 게 됩니다 . 따라서 __ main __ 모듈 과 그렇 지 않 은 모듈 의 행동 양식 이 구분 되 어야 합니다 . 그리고 반드시 __ main __ 모듈 은 있 어야 하 기 때문 에 repl 환경 에서 는 멀티 프로세스 코드 를 실행 할 수 없 습니다 . 간단 하 게 말 해 멀티 프로세스 를 실행 하 기 위해선 해당 파일 을 직접 적 으로 실행 해야 합니다 . 다른 파일 에서 호출 하 는 형식 으로 진행 하 면 예상 치 않 게 동작 할 수 도 있 습니다 . ( 현재 확인 한 바 로 는 shutdown ( ) 나 wait ( ) 이 없 으면 전체 가 실행 이 되 긴 합니다 . 근데 shutdown ( ) 나 wait ( ) 이 존재 하 면 shutdown ( ) 나 wait ( ) 등 이 동작 하 지 않 고 해당 부분 에서 멈춥니다 . ) 만약 분산 처리 와 같이 worker 가 처리 해 준 작업 의 결과 들 을 다시 메인 스레드 에서 넘겨 받 아 사용 하 려면 다음 예제 에서 확인 할 수 있 습니다 . from concurrent import futures total _ result = 0 with futures . threadpoolexecutor ( max _ workers = 4 ) as exe : fs = exe . map ( process , list ( range ( 1 , 10000 , 1000 ) ) ) for done in futures . as _ completed ( fs ) : result = done . result ( ) print ( result ) total _ result += result print ( total _ result ) executor 의 map ( ) 메소드 는 처리 용 함수 와 입력 값 의 집합 을 이용 해서 한꺼번에 작업 을 생성 합니다 . 그리고 future 의 집합 을 리턴 하 는데 , as _ completed 함수 는 작업 들 을 기다리 면서 , 집합 내 에서 종료 된 것 들 부터 차례 로 이터레이션 해줍니다 . 위 예 제 는 개별 로 요청 을 확인 하 는 예제 이 고 , 아래 는 요청 한 작업 전체 를 기다리 다가 한꺼번에 처리 하 는 예제 입니다 . with futures . threadpoolexecutor ( max _ workers = 10 ) as exe : fs = exe . map ( process , arguments ) ( done , not _ done ) = futures . wait ( fs , timeout = 2 ) total _ result = sum ( [ f . result ( ) for f in done ] ) 주 의 점 concurrent . futures 모듈 로 멀티 프로세스 를 사용 할 때 주의 해야 할 점 은 객체 를 생성 한 후 하나 의 객체 를 여러 프로세스 에서 접근 하 지 않 도록 해야 합니다 . 만약 하나 의 객체 에 여러 프로세스 가 접근 할 경우 ssl error decryption failed or bad record mac 가 발생 하 게 됩니다 . from concurrent . futures import processpoolexecutor def concurrent ( list ) : for i in list : query = \\' insert into test ( id ) values ( { 0 })\\'. format ( list [ i ] ) cursor . execute ( query ) conn . commit ( ) db = database ( ) cursor , conn = db . connect ( ) # 입력 된 정보 를 바탕 으로 db 연결 을 하 여 cursor , connection 을 반환 해 주 는 함수 가 있 다고 가정 _ list = [ \\' 1 \\',\\' 11 \\',\\' 111 \\',\\' 1111 \\',\\' 11111 \\',\\' 111111 \\'] pool = processpoolexecutor ( max _ workers = 4 ) pool . map ( concurrent , _ list ) # 실행 시 ssl error decryption failed or bad record mac 에러 발생 아래 와 같이 여러 프로세스 가 각자 의 객체 를 갖 도록 코딩 해야 합니다 . from concurrent . futures import processpoolexecutor def concurrent ( list ) : cursor , conn = db . connect ( ) # 각 프로세스 마다 다른 데이터베이스 객체 생성 for i in list : query = \\' insert into test ( id ) values ( { 0 })\\'. format ( list [ i ] ) cursor . execute ( query ) conn . commit ( ) db = database ( ) _ list = [ \\' 1 \\',\\' 11 \\',\\' 111 \\',\\' 1111 \\',\\' 11111 \\',\\' 111111 \\'] pool = processpoolexecutor ( max _ workers = 4 ) pool . map ( concurrent , _ list )',\n",
       "       \"url ( 퍼센트 ) 인코딩 이 란 ? url 인코딩 은 퍼센트 인코딩 이 라고 도 불리 며 url 에 문자 를 표현 하 는 문자 인코딩 방법 입니다 . 알파벳 이나 숫자 등 몇몇 문자 를 제외 한 나머지 는 1 바이트 단위 로 묶인 16 진수 로 인코딩 하 는 방식 입니다 . 불곰 → url encode % eb % b 6 % 88 % ea % b 3 % b 0 왜 해야 하 는가 get 방식 을 통해 http 요청 을 할 때 쿼리 파라미터 가 붙 는 경우 가 생기 는데 url 은 ascii 코드 값 만 사용 됩니다 . 이 쿼리 파라미터 에 한글 이 포함 될 경우 , ascii 코드 만 으로 표현 을 할 수 없 어서 인코딩 을 진행 해야 합니다 . 호출 하 는 api 마다 쿼리 파라미터 에 한글 문자 그대로 를 지원 하 는 경우 도 있 지만 그렇 지 않 은 경우 도 있 으므로 미리 인코딩 을 거친 형식 으로 전송 하 는 것 이 바람직 합니다 . url encode 파이썬 에서 는 내장 함수 로 urllib 라는 패키지 를 사용 해 url 인코딩 을 진행할 수 있 습니다 . from urllib import parse url = parse . urlparse ( '[ URL ] query = parse . parse _ qs ( url . query ) result = parse . urlencode ( query , doseq = true ) print ( query ) print ( result ) # {' name ': [ ' 불곰 '], ' params ': [ ' 123 ']} # name =% eb % b 6 % 88 % ea % b 3 % b 0 ¶ ms = 123 parse . parse _ qs 로 쿼리 스트링 을 분리 시켜 dict 타입 으로 만든 다음 , parse . urlencode ( 쿼리 스트링 ( dict 타입 ) , doseq = value 에서 리스트 형태 를 유지 할 지 여부 ) 를 통해 쿼리 스트링 ( 파라미터 ) 를 인코딩 합니다 . 만약 doseq 옵션 을 false 로 설정 하 면 아래 와 같이 추출 이 됩니다 . result = parse . urlencode ( query ) # doseq 의 기본 값 은 false print ( result ) # name =% 5 b % 27 % eb % b 6 % 88 % ea % b 3 % b 0 % 27 % 5 d ¶ ms =% 5 b % 27123 % 27 % 5 d # name =[' 불곰 ']¶ ms =[' 123 '] 를 인코딩 한 결과 와 동일 만약 튜플 에 담긴 변수 를 인코딩 하 고 싶 은 경우 가 있 는데 위 와 동일 하 게 urlencode ( ) 를 사용 하 면 됩니다 . query = [ ( ' name ', ' 불곰 '), ( ' params ', 123 ) ] result = parse . urlencode ( query , doseq = true ) print ( result ) # name =% eb % b 6 % 88 % ea % b 3 % b 0 ¶ ms = 123 만약 변형 할 때 , 인코딩 charset 을 지정 하 고 싶 은 경우 , urlencode 에 encode 옵션 값 을 지정 하 면 됩니다 . result = parse . urlencode ( query , encoding =' utf - 8 ', doseq = true ) print ( result ) # name =% eb % b 6 % 88 % ea % b 3 % b 0 ¶ ms = 123 단순 한 문자열 을 인코딩 또는 디 코딩 을 하 고 싶 은 경우 아래 와 같이 다른 함수 를 사용 하 여 진행 할 수 있 습니다 . from urllib import parse text = ' 불곰 ' enc = parse . quote ( text ) dec = parse . unquote ( enc ) print ( enc ) print ( dec ) # % eb % b 6 % 88 % ea % b 3 % b 0 # 불곰 urllib 위 에서 는 url 인코딩 을 하 는 방법 만 설명 했 는데 urllib 를 간략 하 게 설명 하 는 것 이 좋 아 보여서 아래 에서 설명 합니다 . from urllib import parse url = parse . urlparse ( '[ URL ] print ( url ) # parseresult ( scheme =' https ', netloc =' brownbears . tistory . com ', path ='', params ='', query =' name = 불곰 ¶ ms = 123 ', fragment ='') urlparse 함수 에 url 을 진행 하 면 타입 으로 위 와 같이 결과 가 반환 됩니다 . urlparse 에서 나오 는 결과 는 아래 와 같이 세분 화 할 수 있 습니다 . from urllib import parse # scheme : / / username : password @ host : port / path ; params ? query # fragment parse _ result = parse . urlparse ( '[ URL ] print ( parse _ result ) print ( parse _ result . scheme ) print ( parse _ result . username ) print ( parse _ result . password ) print ( parse _ result . hostname ) print ( parse _ result . port ) print ( parse _ result . netloc ) print ( parse _ result . path ) print ( parse _ result . params ) print ( parse _ result . query ) print ( parse _ result . fragment ) # parseresult ( scheme =' https ', netloc =' brownbear : 123 @ 127 . 0 . 0 . 1 : 8080 ', path ='/ path ', params =' params ', query =' name = 불곰 ¶ ms = 123 ', fragment =' id 1 ') # https # brownbear # 123 # 127 . 0 . 0 . 1 # 8080 # brownbear : 123 @ 127 . 0 . 0 . 1 : 8080 # / path # params # name = 불곰 ¶ ms = 123 # id 1 속성 scheme : http , https , ftp , smtp 등등 스키마 username : 사용 자 명 password : 비밀 번호 hostname : 호스트 명 port : 포트 번호 netloc : 네트워크 정보 path : 경로 params : url 파라미터 query : 쿼리 스트링 fragment : fragment 식별자 url 에서 쿼리 스트링 만 분리 하 는 방식 은 위 에서 설명 한 parse . parse _ qs 와 parse . parse _ qsl 이 있 습니다 . 둘 의 차이 는 반환 타입 이 dictionary 인지 list 인지 의 차이 입니다 . from urllib import parse # scheme : / / username : password @ host : port / path ; params ? query # fragment parse _ result = parse . urlparse ( '[ URL ] a = parse . parse _ qs ( parse _ result . query ) b = parse . parse _ qsl ( parse _ result . query ) print ( a ) print ( b ) # {' name ': [ ' 불곰 '], ' params ': [ ' 123 ']} # [ ( ' name ', ' 불곰 '), ( ' params ', ' 123 ')]\",\n",
       "       '안녕 하 세요 . [ 예민 한 ux 디자인 / 총 25 시간 인강 ] 전민수 입니다 . 지난 20 년 간 ui / ux 강의 와 컨설팅 을 하 면서 수집 했 던 해외 자료 를 저 혼자 만 공유 하 기 에 아까워 브런치 를 통해 공유 하 고자 합니다 . 많 은 관심 바랍니다 . nicole said 의 ui . ux 디자이너 가 되 기 위한 7 단계 전문 번역 한 글 입니다 . 최근 , 저 는 많 은 분 들 로부터 비슷 한 질문 을 받 고 있 습니다 . 어떻게 하 면 ui / ux 분야 로 들어갈 수 있 나요 ? 저 는 프로그래머 / 마케팅 매니저 / 소셜 미디어 전략 담당자 인데 디자인 에 대해 더 알 고 싶 습니다 . 어디 서 시작 하 면 될까요 ? 좋 은 디자인 인지 나쁜 디자인 인지 어떻게 하 면 알 수 있 나요 ? 디자이너 가 되 려면 무엇 이 필요 한가요 ? “ 어떻게 시작 할까 ” 이 질문 은 제 가 처음 커리어 를 시작 했 던 시절 이 떠오르 게 합니다 . 7 년 전 , 저 는 처음 디자인 업무 를 맡 아 일 을 시작 했 던 첫 날 이 생각납니다 . imac 에 텅 빈 포토샵 파일 을 열 어 놓 고 멍하니 앉 아 있 었 죠 ( 당시 저 는 윈도우 유저 였 거든요 ) . 저 는 방금 제 상사 가 간략 하 게 설명 해 준 내용 이 무엇 인지 이해 해 보 려고 노력 하 고 있 었 습니다 . 어떻게 시작 해야 할지 전혀 알 수 없 었 어요 . 완전 머리 가 새 하얘진 상태 였 습니다 . 그 일 을 시작 하 기 전 , 저 는 막 멀티미디어 전공 학위 를 가지 고 대학 을 갓 졸업 한 상태 였 습니다 . 그러 니 제 가 디자인 에 대해 뭐 알 이유 가 있 었 겠 습니까 ? 대학교 에서 는 실무 디자인 에 대해 전혀 저 에게 알려준 것 이 없 었 습니다 . 대부분 의 대학 과정 은 이론 을 가르치 며 , 가끔 어도비 와 같 은 디자인 툴 을 사용 하 는 방법 정도 를 가르치 는 정도 입니다 . 하지만 그걸 론 충분 하 지 않 죠 – 전혀 요 . 스스로 연습 하 며 공부 하 는 것 이 여러분 을 보다 나 은 디자이너 가 되게 해 줄 유일 한 방법 입니다 . 스스로 공부 하 며 7 년 의 시간 을 보낸 지금 , 저 는 디자인 선생 님 이 기 도 하 고 국제 컨퍼런스 에 연사 로 나가 기 도 합니다 . 여러분 이 반드시 알 아야 할 첫 번 째 는 타고날 필요 가 없 다는 것 입니다 . 우리 는 디자이너 가 되 기 위해 태어난 특별 한 창조물 도 아니 고 예술 성 을 타고나 지 도 않 았 습니다 . 디자인 은 배우 는 것 입니다 . 디자인 은 문제 를 해결 하 는 것 이 죠 . 지속 적 으로 문제 를 찾 고 그 에 대한 해결책 을 만들 어 내 는 작업 입니다 . 디자인 에 는 여러 분야 가 있 습니다 . ui , ux , 제품 디자인 , 그래픽 디자인 , 인터랙션 디자인 , 정보 설계 등등 아주 다양 합니다 . 더 관심 이 가 는 분야 를 찾 는 것 부터 시작 해 보 세요 . 이제 는 가장 일반 적 인 타입 인 , 인터페이스 와 경험 을 조합 한 ui 와 ux 디자이너 에 초점 을 맞춰서 디자이너 가 되 는 방법 을 살펴보 겠 습니다 . 1 . ui 원칙 에 익숙 해 지 기 디자인 을 연습 하 기 전 , 여러분 이 먼저 해야 하 는 것 은 디자인 원칙 을 배우 는 것 입니다 . 이 를 통해 여러분 은 디자인 의 세계 로 들어설 수 있 으며 “ 창의 적 으로 ” 생각 하 기 시작 할 수 있 을 것 입니다 . 디자인 의 심리 적 측면 에 대해 배우 게 될 텐데 , 가령 왜 그렇게 하 면 더 좋 아 보이 는지 , 왜 그렇게 하 면 실패 하 는지 등 을 배울 것 입니다 . 다음 은 여러분 이 반드시 알 아야 할 기본 적 인 원칙 입니다 . 1 ) 색 : 색상 관련 용어 , 기본기 , 색채 심리학 2 ) 균형 : 대칭 과 비대칭 principles of design : balance 3 ) 대비 : 대비 효과 를 이용 한 정보 구조 화 , 계층 구조 만들 기 , 포커스 만들 기 4 ) 타이포그래피 : 폰트 선택 하 고 , 웹 에서 읽 기 쉬운 텍스트 만들 기 5 ) 일관 성 : 가장 중요 한 원칙 . 직관 적 이 고 유용 한 디자인 은 여기 서 시작 됩니다 . 여기 에 가시 면 좋 은 ui 디자인 을 하 기 위해 해야 할 것 과 하 지 말 아야 할 것 을 알 수 있 습니다 . 2 . ux 창작 프로세스 배우 기 그 다음 으로 알 아야 할 것 은 창작 프로세스 입니다 . ui / ux 디자인 은 창의 적 인 사람 은 모두 밟 아 나갈 수 있 는 구체 적 인 단계 로 구성 된 프로세스 입니다 . 프로세스 는 크 게 발견 , 정의 , 개발 , 실행 네 가지 단계 로 구성 됩니다 . 더블 다이아몬드 는 이러 한 디자인 프로세스 를 보여 주 는 간단 한 비주얼 맵 입니다 . 발견 바로 여기 가 프로젝트 의 시작 입니다 . 이 단계 에서 디자이너 는 리서치 를 시작 하 고 , 영감 을 얻 고 , 아이디어 를 모읍니다 . 정의 정의 를 내리 는 단계 로 , 디자이너 는 발견 단계 에서 뽑 은 아이디어 를 구체 적 으로 정의 합니다 . 여기 서 명확 하 고 창의 적 인 개요 가 만들 어 집니다 . 개발 솔루션 이나 컨셉 이 만들 어 지 고 , 프로토타입 을 만들 고 , 테스트 하 는 과정 을 반복 하 는 단계 입니다 . 이 단계 에서 겪 는 시행착오 는 디자이너 가 아이디어 를 개선 하 고 정제 하 는 데 도움 이 됩니다 . 실행 최종 단계 는 실행 하 는 단계 로 , 프로젝트 가 최종 적 으로 끝나 고 , 생산 되 어 출시 됩니다 . 제 가 쓴 다른 글 , “ 성공 적 인 웹 사이트 디자인 을 위한 5 단계 ” 도 읽 어 보 세요 . 3 . 디자인 을 보 는 눈 기르 기 디자인 원리 를 아 는 것 은 아주 훌륭 한 일 이 지만 , 때로 는 그것 으로 충분 하 지 않 기 때문 에 좋 은 디자인 과 나쁜 디자인 을 알아보 는 눈 과 디자인 의 강점 과 약점 을 알아보 는 눈 을 길러야 합니다 . 디자인 을 보 는 눈 을 기르 는 가장 효과 적 인 방법 은 영감 을 주 는 작업 물 을 많이 보 는 것 입니다 . 텅 빈 캔버스 를 열 고 멍 하 니 바라보 며 30 분 을 보내 기 전 에 , 리서치 를 해야 창작 이 가능 하 다는 것 을 알 아야 합니다 . 생각 만 으로 는 아이디어 가 나오 지 않 습니다 . 여러분 만 의 작업 을 시작 하 기 위해서 는 먼저 다른 디자인 을 봐야 합니다 . 특히 초심자 라면 더욱 그렇 습니다 . 포트폴리오 웹 사이트 를 많이 찾아보 세요 그러 니 다른 디자이너 는 무엇 을 하 는지 dribble 에서 찾아보 다가 , 예쁜 디자인 이나 진행 중 인 프로젝트 와 관련 된 무언가 를 보 게 되 면 , 노트 에 저장 하 고 어떤 점 이 좋 았 는지 적 어 두 세요 . 스크린 샷 을 해둘 수 도 있 습니다 . 이렇게 하 면 여러분 만 의 디자인 을 시작 하 는 데 영감 을 주 는 디자인 컬렉션 을 만들 수 있 습니다 . 다음 은 제 가 주로 영감 을 얻 는 사이트 입니다 . onepagelove . com 여러분 에게 영감 을 줄 한 페이지 짜리 웹 사이트 awwwards . com 디자인 능력 을 뽐낼 수 있 는 어워드 웹 사이트 dribbble . com 작업 물 을 공유 하 는 디자이너 들 의 커 뮤 니 pttrns . com 모바일 디자인 패턴 컬렉션 uimovement . com 매일 올라오 는 영감 을 주 는 최고 의 ui 디자인 4 . 디자인 글 매일 읽 기 디자인 에 스스로 더 익숙 해 지 는 가장 좋 은 방법 은 매일 몇 편 의 글 을 읽 어 보 는 것 입니다 . 매일 디자인 뉴스 와 블로그 를 보 는 습관 을 기르 세요 . 새로운 트랜드 나 사용 사례 나 튜토리얼 등 을 발견 할 수 있 는 수 백만 의 글 이 온라인 에 있 습니다 . 우리 는 그 글 을 찾 기 만 하 면 됩니다 . 다른 사람 의 경험 을 통해 배우 는 것 보다 더 좋 은 것 은 없 습니다 . 그러 니 한 잔 의 커피 와 함께 medium 이나 smashing magazine 에서 영감 을 주 는 글 을 읽 는 것 으로 하루 를 시작 해 보 세요 . 아침 에 새로운 것 을 배우 면 생각 이 넓 어 지 고 그날 창의력 을 발휘 할 여력 이 생길 것 입니다 . 그 다음 에 는 하루 중 에 시간 이 남 을 때 마다 더 글 을 읽 어 보 기 위한 쉬 는 시간 을 가져 보 세요 . 휴식 을 가지 는 것 은 창의력 에 있 어서 매우 중요 합니다 . 특히 무언가 에 막힌 것 같 고 생산 적 이 지 못하 다고 느낄 때 는 더 그렇 습니다 . 그런 글 을 볼 수 있 는 웹 사이트 를 여러분 이 쓰 는 브라우저 에 북마크 해 두 거나 디자이너 의 뉴스 레터 를 구독 해 보 세요 . 다음 은 제 가 디자인 과 관련 해 소식 을 얻 는 블로그 와 뉴스 웹 사이트 입니다 . [ URL ] [ URL ] [ URL ] [ URL ] [ URL ] 5 . 페이크 프로젝트 디자인 해 보 기 연습 을 계속 하 면 잘 하 게 됩니다 . 그리고 우리 는 경험 이 없 으면 클라이언트 나 일 을 얻 어 낼 수 없 다는 것 을 알 고 있 습니다 . 그런데 , 일 이나 프로젝트 없이 어떻게 연습 을 할 수 있 나요 , 그렇 죠 ? 하지만 , 스스로 연습함 으로 이 싸이클 을 깨 고 들어갈 수 있 습니다 . 재미 로 페이크 프로젝트 ( fake project ) 를 만들 어 보 세요 ! dribble 엔 페이크 프로젝트 가 가득 합니다 . facebook material design by kevin mccarthy 이미 이용 하 고 있 는 웹 사이트 나 앱 을 골라서 다시 디자인 해 보 세요 . 개선 의 여지 가 있 다고 생각 하 는 부분 이 라면 무엇 이 든 좋 습니다 . 아니면 여러분 만 의 앱 아이디어 를 디자인 해 볼 수 도 있 습니다 . 이렇게 하 다 보 면 디자인 포트폴리오 가 만들 어 지 고 , 디자인 을 연습 할 수 있 게 됩니다 . 6 . 최신 웹 디자인 툴 배우 기 세상 에 는 수 많 은 디자인 툴 이 존재 하 지만 , 전부 다 배울 필요 는 없 습니다 . 가장 좋 은 것 몇 가지 를 알아보 고 , 거기 서 가장 좋 아 하 는 것 을 선택 해서 , 최신 기능 과 트렌드 를 항상 업데이트 하 세요 . 다음 은 요즘 제 가 디자인 프로세스 에서 사용 하 고 있 는 최신 툴 입니다 . sketch for interface design figma for collaborative interface design balsamiq for low fidelity wireframing adobe xd for interface design and prototyping marvel app for making mockups interactive invision app for prototyping and collaboration 7 . 멘토 를 얻 고 멘토 가 되 세요 디자인 을 배우 는 또 다른 훌륭 한 방법 은 , 디자인 멘토 를 찾 거나 도움 이 필요 한 디자이너 친구 들 을 도와 주 세요 . 이 들 은 여러분 이 배우 는 프로세스 의 속도 를 높여 줄 것 입니다 . 이런 동료 디자이너 들 은 여러분 의 작업 물 을 리뷰 해 줄 수 도 있 고 코멘트 를 해 줄 수 도 있 습니다 . 또한 자신 의 경험 을 통해 배운 팁 이나 요령 을 공유 해 줄 수 도 있 습니다 . 그러 니 가 서 다른 디자이너 에게 메일 을 쓰 고 , 질문 하 고 , 고민 거리 를 나눠 보 세요 . 또한 저 는 지난 몇 년 간 디자인 과 프론트엔드 개발 을 가르치 면서 제 가 생각 했 던 것 보다 더 많 은 것 을 배웠 습니다 . 사람 들 과 디자인 에 대해 대화 를 시작 할 준비 가 되 었 다면 , 여러분 이 멘토 가 될 수 도 있 고 다른 사람 에게 디자인 을 가르칠 수 도 있 습니다 . 디자인 을 다양 한 관점 에서 보 는 방법 을 배우 게 될 것 이 며 전혀 생 각지 도 못했 던 피드백 이나 질문 을 받 게 될 것 입니다 . 디자인 에 대해 다른 사람 들 과 대화 를 나누 다 보 면 언제나 여러분 의 마인드 는 “ 브레인 스톰 ” 모드 로 들어가 게 되 어 디자인 에 더 많 은 관심 을 가지 게 되 는 자신 을 발견 하 게 될 것 입니다 . 감사 합니다 . 추천 ui / ux 교육 안내 [ 스터디 ] ux 디자인 원칙 스터디 2 기 5 월 13 일 ( 수 ) - 6 월 12 일 ( 금 ) , 매우 수 , 금 / 오후 8 시 - 10 시 / 총 10 회 / 교재 p 1 , 159 [ 강좌 ] ux 디렉터 양성 과정 9 기 모집 5 월 7 일 ( 목 ) ~ 6 월 30 일 ( 화 ) 매주 화 , 목 오후 7 시 30 분 - 10 시 30 분 [ 인강 ] 예민 한 ux 디자인 모집 평생 수강 , 총 25 시간',\n",
       "       \"파워 포인트 강의 를 하 다 보 면 평소 에 다루 지 않 던 기능 들 에 대해서 도 관심 을 가져야 할 때 가 있 다 . 내 경우 pdf 로 전환 되 는 문서 작업 의 비중 이 높 기 때문 에 새로운 문서 나 웹 페이지 등 으로 전환 되 는 효과 를 잘 쓰 지 않 는 편 이 지만 한쪽 에서 는 파워 포인트 를 활용 해서 개체 를 움직이 거나 다른 문서 들 을 불러오 고 발표 자리 에서 보여야 하 는 작업 들 이 필요 할 때 가 있 다 . 대표 적 으로 상대방 의 반응 을 바로 바로 이끌 어 내 야 하 는 수업 때 이런 기능 이 필요 하 지 않 을까 싶 은데 , 몇 달 전 마무리 된 파워 포인트 온라인 강의 교안 작업 에서 비슷 한 기능 을 다뤘 어서 여기 에 도 간단 하 게 작업 방식 을 남겨 본다 . 1 . 큰 그림 부터 완성 한다 온라인 강의 자료 는 ' 각 지역 의 특산물 ' 을 주제 로 제작 했 다 . 각 지역 을 클릭 하 면 해당 되 는 특산물 들 이 우선 박스 형태 로 떠오르 는 구성 이 다 . 이렇게 애니메이션 이나 링크 를 넣 는 경우 에 도 최종 적 인 구성 을 완성 해 놓 고 배치 하 면 나중 엔 이미지 위 에 기능 을 하나 더하 는 것 이 기 때문 에 큰 혼란 없이 자료 를 제작 할 수 있 다 . 이건 복잡 한 애니메이션 의 경우 에 도 해당 된다 . 완 성본 을 미리 만들 어 놓 고 실행 순서 를 익힌다 . 이렇게 이미지 를 구성 해 놓 고 나 면 그 다음 에 정보 를 연결 하 는 건 좀 더 쉬워진다 . 실습 자료 에서 는 [ 각 지역 을 클릭 하 면 ] [ 박스 가 나타난다 ] 구조 를 가지 고 효과 를 적용 했 다 . 파워 포인트 에서 는 이런 작업 을 진행할 때 순서 를 반 대로 적용 한다 . 1 . 박스 를 나타나 게 한다 각 박스 를 클릭 한 후 [ 애니메이션 ] 에서 ' 나타나 기 ' 와 관련 된 옵션 을 선택 한다 . 개체 클릭 후 애니메이션 적용 하 기 2 . 어떻게 하 면 박스 를 나타나 게 할지 정한다 ( 트리거 ) 각 지역 을 표시 하 는 원형 의 마커 들 을 클릭 하 면 애니메이션 이 나타나 도록 옵션 을 지정 해 보 자 . 트리거 는 애니메이션 이 나타나 게 하 는 방아쇠 다 . 애니메이션 이 적용 된 박스 를 선택 한 후 [ 애니메이션 ] -[ 트리거 ] 를 선택 하 고 어떤 개체 를 클릭 하 면 애니메이션 이 나타날 지 를 지정 해 준다 . 애니메이션 적용 된 개체 를 클릭 해야 트리거 가 활성 화 된다 * 이때 선택 되 는 개체 들 은 번호 로 표시 가 되 는데 , 어떤 개체 를 클릭 할 지 모르 겠 다면 [ 홈 ] -[ 선택 ] -[ 선택 창 ] 을 열 어 보 자 . 슬라이드 를 구성 하 고 있 는 개체 들 의 이름 과 순서 들 이 나열 되 어 있 다 . 이곳 에서 확인 하 거나 수정 한 개체 이름 을 가지 고 트리거 를 적용 할 개체 를 선택 한다 . 선택 창 에서 원 하 는 개체 의 이름 을 확인 한다 . 편집 도 가능 하 다 . 2 . 클릭 하 고 싶 게 만들 기 포털 사이트 광고 배 너 들 에서 나올 만 한 말 이 지만 , 이 는 파워 포인트 슬라이드 에서 도 해당 된다 . 특히 사용 자 가 보 기 에 는 아무 의미 도 없 는 텍스트 들 이 나열 된 링크 보다 는 , 사용 자 가 한 번 씩 은 클릭 해 보 고 싶 은 버튼 을 만들 어서 슬라이드 에 배치 하 는 것 도 좋 은 방법 이 다 . 내 경우 에 는 위 에서 보 는 것 처럼 투명도 가 적용 된 원 을 여러 개 겹쳐 그렸 지만 , 꼭 이 방법 이 아니 더라도 버튼 을 디자인 하 는 방법 은 얼마 든지 많 다 . 적절 한 링크 를 아래 에 삽입 했으니 참고 하 고 만들 어 보 자 . 내 가 원 하 는 버튼 을 만들 어서 위 처럼 트리거 를 적용 하 면 눌리 는 대로 바뀌 는 슬라이드 를 얻 을 수 있 다 . [ URL ] 3 . 실행 메뉴 를 이용 하 기 이런 기능 들 은 사용 자 가 중간 에서 자료 를 컨트롤 하 므로 흔히 인터랙티브 로 설명 되 는 기능 들 이 다 . 파워 포인트 기준 으로 는 애니메이션 삽입 과 파워 포인트 간 의 슬라이드 전환 , 웹 사이트 나 다른 파일 을 열 게 만드 는 기능 들 이 있 다 . 이 중 같 은 파워 포인트 파일 안 에서 다른 슬라이드 로 넘어가 게 하 는 기능 은 [ 삽입 ] -[ 링크 ] -[ 실행 ] 에 있 다 . 다른 슬라이드 나 프로그램 을 여 는 등 의 옵션 등 을 가지 고 슬라이드 내부 를 넘 어서 다른 공간 의 자료 들 도 슬라이드 에 날 것 으로 삽입 할 수 있 다 . ( 물론 굉장히 날 것 이 라 실행 되 는 데 시간 이 꽤 오래 걸리 는 작업 들 도 있 다 . 웹 사이트 를 실행 했 을 때 가 대표 적 으로 , 이 를 프레젠테이션 에 활용 할 때 는 반드시 미리 웹 사이트 를 불러오 는 데 들어가 는 시간 을 확인 하 자 . 그냥 내 가 미리 열 어 놓 은 웹 페이지 로 바로 넘어가 는 게 더 빠를 수 도 있 다 . ) ' 실행 ' 메뉴 의 위치 를 확인 하 자 . 이미지 상단 의 리본 메뉴 에 있 다 4 . 웹 페이지 디자인 을 참고 하 자 링크 나 실행 기능 들 을 통해 인터랙티브 한 기능 을 접했 다고 해도 정작 디자인 으로 는 어떻게 슬라이드 를 완성 해야 할지 고민 이 될 수 도 있 겠 다 . 내 경우 에 는 지도 이미지 와 특산물 을 선택 했 을 때 나오 는 페이지 의 디자인 을 아예 다르 게 만들 어서 분위 를 전환 하 는 방법 을 썼 다 . 타이틀 표현 만 앞장 과 비슷 하 게 하 고 이미지 를 사진 으로 채웠 다 . 그리고 이 과정 을 거친 이미지 들 은 아래 처럼 전환 되 도록 했 다 . 그럼 좀 더 복잡 한 이미지 들 이나 페이지 를 구성 할 떄는 어떤 방법 을 써야 할까 ? 링크 나 트리거 를 훨씬 잘 다루 고 있 는 웹 페이지 들 을 참고 하 라고 추천 하 고 싶 다 . 아래 링크 는 아예 웹 페이지 컨셉 으로 구성 한 슬라이드 를 만드 는 유투 브 영상 이 다 . 짧 은 내용 이 라 스치 듯 보 기 에 도 좋 다 . 특히 슬라이드 왼쪽 에 배치 된 디자인 은 navigation 이 라고 해서 슬라이드 나 ui / ux 에서 사용 자 들 이 길 을 잃 지 않 게 하 는 역할 을 하 고 있 다 . ( 구글 에서 navigation ui design 이 라고 만 검색 해도 참고 할 디자인 들 을 많이 얻 을 것 이 다 . [ URL ] 파워 포인트 에서 개체 간 의 연결 하 고 사용 자 의 참여 도 를 끌어올리 는 인터랙티브 한 디자인 들 은 얼마 든지 다양 한 방식 으로 응용 할 수 있 지만 , 그 기본 기능 은 애니메이션 - 트리거 - 실행 정도 의 단순 한 구조 를 가지 고 있 다 . ( 대부분 완성 본 만 만들 어 놓 으면 그 뒤 는 단순 반복 이 다 . ) 그러 니 필요 한 기능 이 생겼 을 땐 망설이 지 말 고 시도 해 보 길 바랍니다 : ) *' 생존 형 파워 포인트 디자인 법 ' 은 여러분 들 의 도움 이 필요 한 콘텐츠 입니다 . 디자인 개선 이 필요 한 슬라이드 나 텍스트 를 제보 해 주 세요 . * 개선 된 자료 는 구체 적 인 내용 과 사항 을 편집 하 여 브런치 에 포스팅 됩니다 . ( 원본 내용 은 어떤 방향 으로 든 그대로 공개 되 지 않 습니다 . ) * 작가 프로필 의 ' 작가 에게 제안 하 기 ' 나 페이스북 메시지 , 브런치 의 댓글 을 이용 해 주 세요 : )\",\n",
       "       'alphago 에 적용 된 딥 러닝 에 대해 조금 상세 하 게 적 어 보 고자 한다 . alphago 의 전체 알고리즘 이 궁금 하 신 분 들 은 내 가 작성 한 \\' alphago 알고리즘 요약 \\' 슬라이드 를 참고 하 시 기 바란다 . 이 슬라이드 를 먼저 읽 는 것 이 본 글 이해 에 도움 이 된다 . ( 슬라이드 와 이 글 은 모두 alphago 의 nature 논문 \" mastering the game of go with deep neural networks and tree search \" 을 분석 한 내용 임 ) [ URL ] alphago 알고리즘 의 전체 골격 을 이루 는 monte carlo tree search ( 이하 mcts ) 는 대부분 의 바둑 ai 또는 각종 보드 게임 ai 에 보편 적 으로 사용 하 는 알고리즘 이 다 . 한마디 로 특별 하 지 않 다 . 그 대신 alphago 는 tree search 를 높 은 승률 로 제한 된 시간 내 탐색 하 기 위해 딥 러닝 ( deep learning ) 과 강화 학습 ( reinforcement learning ) 알고리즘 을 사용 했 다 . alphago 에서 사용 된 딥 러닝 알고리즘 은 convolutional neural networks ( 이하 convnet ) 이 다 . convnet 은 이미지 인식 ( recognition ) 등 에 가장 대표 적 으로 사용 되 고 있 으며 , 매년 ilsvrc 등 을 통해 인식 정확도 가 개선 되 고 있 다 . alphago 는 kgs 의 2 천 9 백만 기보 를 convnet 으로 학습 하 여 , p ( a | s ) 즉 , 어떤 상태 ( status , s ) 에서 의 다음 수 를 둘 위치 ( action , a ) 확률 분포 를 구해 낸다 . 어찌 보 면 정석 의 패턴 을 익히 는 것 이 라고 볼 수 있 다 . 이것 을 sl policy network 이 라고 부른다 . ( 논문 에서 지 은 이름 ) 즉 , 사람 의 기보 에서 배운 가능 성 을 최대 화 하 는 방향 으로 학습 한다 . maximize likelihood of human action 혼동 하 지 말 아야 할 점 은 convnet 에 학습 할 기보 이미지 를 그냥 입력 하 는 것 이 아니 라 기보 를 한 지점 당 11 가지 특징 ( 이하 feature ) 을 갖 는 데이터 로 변환 하 여 넣 는다 . 11 가지 특징 은 해당 지점 의 돌 색깔 ( 내 돌 , 상대방 돌 , 빈 곳 등 ) 등 인데 이 11 가지 feature 를 표현 하 는 차원 은 총 48 차원 이 다 . 11 가지 feature 상세 내역 그래서 19 x 19 x 48 차원 의 행렬 ( tensor ) 데이터 가 convnet 으로 입력 되 어 학습 된다 . 그런데 이 를 그대로 입력 하 지 않 고 값 이 0 인 행렬 을 높이 , 넓이 4 만큼 덧붙여 ( zero padding ) 23 x 23 x 48 행렬 로 최종 입력 데이터 로 변환 하 여 넣 는다 . 그 다음 은 일반 적 인 convnet 아키텍처 에 따라 학습 ( training ) 을 시킨다 . 학습 의 목적 함수 는 p ( a | s ) 이 다 . convnet 아키텍처 ( sl policy network ) 그리고 5 x 5 x 48 컨 볼루 션 ( convolution ) 필터 ( kernel ) 192 개 를 먹인다 . 그러 면 19 x 19 x 192 feature map 이 나오 고 여기 에 2 만큼 zero padding 을 해서 21 x 21 x 192 로 바꾼 다음 , 3 x 3 x 192 필터 192 개 를 또 먹인다 . 이런 과정 을 2 ~ 12 레이어 까지 반복 한다 . 이 는 convnet 의 feed foward 방식 이 다 . 컨 볼루 션 연산 예시 이런 sl policy network 에 기보 를 얼마나 학습 시켰 나 보 면 . .. kgs 6 ~ 9 단의 160 , 000 경기 로 부 터 29 , 400 , 000 위치 정보 를 뽑 아서 학습 했 다 . 이 는 한 경기 당 약 184 가지 의 바둑 돌 의 위치 정보 를 뽑 은 셈 이 다 . 이것 이 정확히 첫 수 부터 184 수 까지 인지 아니 면 184 가지 모양 을 뽑 은 것 인지 는 알 수 없 다 . ( 즉 , 논문 에서 언급 이 없 음 ) 어쨌든 , 첫 번 째 convnet 으로 alphago 가 학습 하 고자 한 것 은 최대한 사람 의 기보 에 따른 현재 상태 에서 의 다음 수 를 둘 위치 이 다 . 또한 주목 할 점 은 policy network 의 작 은 정확 도 개선 이 라도 alphago 전체 승률 개선 에 많 은 영향 을 미친다고 한다 . sl policy network 정확 도 개선 에 따른 alphago 승률 sl policy network 를 조금 더 개선 하 고자 기 학습 된 sl policy network ( convnet ) 을 복사 해서 이 를 강화 학습 ( reinforcement learning ) 한다 . 이렇게 추가 적 으로 학습 된 convnet 을 rl policy network 라고 부른다 . ( 논문 에서 지 은 이름 ) rl policy network 은 승리 하 면 + 1 , 패배 하 면 - 1 의 reward score 를 부여 하 는 강화 학습 을 하 는데 , p ( a | s ) 확률 을 구하 도록 학습 한다 . 보통 강화 학습 에서 는 현재 상태 ( s ) 와 행동 ( a ) 에 따라 최대 미래 reward 를 주 는 \\' value 함수 \\' 를 근사 하 는데 , 여기 서 는 \\' policy gradient 강화 학습 \\' 방식 으로 직접 p ( a | s ) 를 구한다 . 즉 , policy gradient 알고리즘 을 사용 한 이유 는 policy network 가 value 함수 가 아닌 확률 을 구하 는 목적 이 기 때문 이 다 . reward score ( z _ t ) 의 기대 값 이 최대 화 되 는 방향 으로 학습 한다 . maximize expected outcome 그렇 다면 , 승리 여부 에 따라 reward 를 준다는데 누구 랑 승부 를 겨룰 까 ? 바로 또 다른 policy network 이 다 . 즉 , alphago 자신 과 self - play 하 는 것 이 다 . 이렇게 학습 된 rl policy network 이 sl policy network 과 싸워서 80 % 더 승리 한다고 한다 ! 착점 을 찾 는 policy network 다음 , 해당 착점 에 따른 승률 을 예측 하 는 이른바 value network 를 학습 한다 . value network 는 앞서 policy network ( convnet ) 의 아키텍처 와 동일 하 고 마지막 층 만 확률 이 아닌 예측 값 을 구하 도록 바꾼다 . 그 다음 실제 reward score ( z ) 와 value network 의 예측 값 사이 의 mean squared error ( mse ) 를 최소 화 하 는 방향 으로 학습 한다 . minimize mse 이미 완료 된 게임 ( ksg 기보 ) 으로 value network 을 학습 시키 면 과 적 합 ( overfitting ) 이 발생 하 는데 , 이 는 하나 의 돌 위치 에 따라 이후 위치 들 이 강하 게 연관 되 어 있 는 반면 , 최종 예측 값 은 게임 내 전체 에서 하나 의 값 으로 공유 되 기 때문 이 다 . 즉 , 돌 하나 의 위치 가 승부 에 어떤 영향 을 미치 는지 학습 하 기 어렵 다 . 결국 , value network 는 새로운 착점 을 생성 한다기 보다 단지 ksg 기보 결과 를 기억 하 는 역할 만 하 게 된다 . 이 문제 를 해결 하 기 위해 rl policy network 끼리 self - play 를 통해 자체 기보 를 생성 하 고 이 데이터 ( 약 3 천만 착점 ) 로 value network 를 학습 시켜서 과 적 합 문제 를 해결 한다 . 각 network 의 성능 비교 alphago 에 적용 된 딥 러닝 의 과정 을 종합 하 면 아래 그림 과 같 다 . alphago 의 deep neural networks 학습 pipeline 이제 policy network 과 value network 으로 monte carlo tree search 를 하 면 alphago 가 완성 된다 !',\n",
       "       '카카오 ai 리포트 vol 01 . 수 정본 ( revised ) 으로 업데이트 합니다 . 이 같 은 과정 도 논의 가 활발 해 지 는 데 작 은 도움 이 됐 으면 합니다 . 저희 리포트 내용 에 대해 상세 하 게 의견 주 신 모든 분 들 께 감사 드립니다 . 저희 는 관련 부분 에 대해 외부 전문가 감수 등 확인 작업 을 진행 하 고 반영 했 습니다 . [ 수정 사항 ] 1 ) 기존 본문 에 1957 년 프랭크 로젠블라트 ( frank rosenblatt ) 가 제안 한 퍼셉트론 ( perceptron ) 을 본격 적 인 인공 신경망 ( artificial neural network ) 연구 의 시작 으로 보 는 견해 를 반영 했 습니다 . 다만 이 에 앞서 맥쿨 록과 월터 ( mcculloch and walter ) 의 1943 년 논문 [ 2 ] 에서 이미 인공 신경망 개념 이 제시 됐 다고 합니다 . 2 ) ai winter 의 시기 에 대해서 도 다양 한 견해 가 있 습니다 . 저희 는 당초 1970 년 대 이후 ai 연구 열기 가 수그러들 었 고 , 2010 년 무렵 까지 큰 성과 가 없 었 다고 전했 고 , 1990 년 대 인터넷 보급 이후 빅 데이터 시대 가 열리 게 됐 다고 봤 습니다 . 다만 ai winter 가 1986 년 에 끝났으며 1990 년 대 는 ai 가 아니 라 인터넷 의 시대 였 다는 해석 도 제기 됐 습니다 . 감수 결과 , 연구자 들 이 바라보 는 ai 연구 방향 을 요약 하 면 ai 컨셉 의 등장 ( 부흥 ) , 방법 론 의 부재 ( 본문 에서 의 \\' 논리 설계 의 어려움 \\', 겨울 ) , 머신 러닝 컨셉 의 등장 ( 부흥 ) , 성능 ( 정확도 ) 의 한계 ( 겨울 ) , 딥 러닝 / 빅 데이터 의 등장 ( 부흥 , 현재 ) 으로 정리 할 수 있 다는 의견 을 주 셨 습니다 . 이 에 대한 타임 라인 은 자료 [ 27 ] 을 참고 하 면 좋 을 것 같 습니다 . 3 ) 기존 본문 에 ‘ ai 란 생명체 의 이 같 은 지적 활동 을 인공 적 으로 흉내내 는 것 이 다 . ’ 내용 은 책 [ 10 ] 의 내용 을 인용구 없이 제시 했 습니다 . 검토 결과 , 본문 의 앞뒤 맥락 상 불 필요 하 여 삭제 했 습니다 . 4 ) 기존 본문 에 ibm 의 ‘ 딥 블루 ’ 를 ‘ if then rule ’ 기반 한 프로그램 으로 소개 한 부분 을 탐색 알고리즘 기반 으로 만든 ai 프로그램 으로 수정 했 습니다 . 5 ) 뇌 의 신경망 으로 신호 가 전달 되 는 방식 에 대한 설명 은 오해 의 여지 가 있 어 수정 했 습니다 . 감수 신 정규 ( jshin @ lablup . com ) 현 소속 : 래 블 업 대표 , 한양 대학교 erica 컴퓨터 공학 과 겸임 교수 경력 : google developer expert 머신 러닝 분야 연구 분야 : 복잡 계 뇌 과학 , 기계 학습 및 행위 자 기반 모형 최 예림 ( yrchoi @ kgu . ac . kr ) 현 소속 : 경기 대학교 산업 경영 공학 과 교수 경력 : 네이버 랩스 연구원 연구 분야 : 데이터 사이언스 , 머신 러닝 / 딥 러닝 , 휴먼 모델링 카카오 는 ai 에 대한 사회 적 관심 을 높이 는 동시 에 , 다양 한 논의 의 재료 로 ai 가 쓰일 수 있 기 를 소망 하 며 월간 으로 준비 중 입니다 . 카카오 도 ai 기반 서비스 와 비즈니스 를 준비 하 지만 , 기술 생태계 를 키우 고 사회 를 바꾸 는 것 은 모두 의 몫 이 기 때문 입니다 . 카카오 는 현안 을 나누 고 지혜 를 모으 는데 조금 이 라도 거들 겠 습니다 . 2017 년 3 월 14 일 공개 된 이번 리포트 는 다음 세 가지 내용 으로 구성 되 어 있 습니다 . 01 . ai 기술 개발 의 역사 , 머신 러닝 과 딥 러닝 ( 이번 글 ) 02 . ai 규제 동향 및 법 적 , 윤리 적 쟁점 03 . 로봇 윤리 의 변천사 2017 년 ai 컨퍼런스 소개 ai 관련 팟캐스트 소개 카카오 ai 리포트 vol . 1 전체 글 다운 받 기 내용 중간 의 [ ] 는 뒷부분 에 설명 및 관련 문헌 의 소개 내용 이 있 음 을 알리 는 부호 입니다 . 예 를 들 어 , [ 1 ] 에 대한 설명 은 \\' 설명 및 참고 문헌 \\' 의 첫 번 째 에 해당 합니다 . \" 90 년 대 와 2000 년 대 초 아무 도 신경망 ( neural network ) 을 주제 로 논문 을 쓰 려고 하 지 않 았 어요 . 성과 가 나 지 않 는다는 이유 였 죠 . 학생 들 에게 논문 을 쓰 게 하 려면 손목 을 비틀 어야 할 지경 이 었 습니다 . \" 2014 년 겨울 캐나다 몬트리올 에서 열린 지능 정보 처리 시스템 학회 ( neural information processing systems , nips ) . 요 슈 아 벤 지오 ( yoshua bengio ) 몬트리올 대 교수 가 지난 시절 의 고충 을 털어놓 았 다 . 인공 신경망 ( artificial neural network ) 개념 은 이미 1940 년 대 부터 제기 된 내용 이 었 지만 , 2000 년 대 까지 ai 연구 에서 큰 성과 를 보여 주 지 못했 다 . 오래 된 개념 이 고 , 성과 도 없 다는 이유 로 모든 학회 나 저널 에서 논문 게재 를 거절 하 곤 했 다 . 1987 년 이후 해 마다 겨울 에 nips 학회 에 참석 했 던 전문가 들 은 이른바 ai 기술 의 겨울 ( ai winter ) 이 었 던 오랜 시절 을 함께 돌아봤 다 . 얀 레 쿤 ( yann lecun ) 뉴욕 대 교수 , 제프리 힌튼 ( geoffrey hinton ) 토론 토대 교수 , 앤드류 응 ( andrew ng ) 스탠퍼드 대 교수 등 지금 은 ‘ ai 사 대 천 왕 ’ 으로 꼽히 는 이 들 모두 그 시절 춥 고 어려운 시기 를 거쳤 다 . 현재 레 쿤 교수 는 페이스북 , 힌튼 교수 는 구글 , 응 교수 는 바이두 에서 ai 핵심 기술 개발 을 위해 모셔 간 상태 다 . 벤 지오 교수 는 ibm , 구글 등 과 공동 연구 를 하 고 있 다 [ 1 , 2 ] . ( 왼쪽 부터 ) yann lecun , geoff hinton , yoshua bengio , andrew ng , at nips 2014 , 출처 : andrew ng \\' s facebook 인공지능 이 란 ? 2016 년 알 파고 와 이세돌 의 바둑 대결 이후 ai 붐 이 일 고 있 지만 , 전 세계 적 으로 이미 중요 한 기술 연구 분야 가 된지 오래 다 . ai 에 대해서 막연 하 게 sf 영화 에 등장 하 는 가상현실 을 상상 하 지만 , 우리 는 이미 실생활 의 많 은 부분 에서 ai 기술 을 접하 고 있 다 . 로봇 청소기 , 스마트폰 으로 촬영 한 사진 의 스타일 을 변경 해 주 는 어플리케이션 , 온라인 게임 플레이 에 등장 하 는 npc ( non player character ) 등 이 그것 이 다 . sf 영화 와 소설 속 에서 등장 하 는 ai 란 과연 무엇 을 의미 하 며 , 어떻게 우리 의 생활 속 에서 이용 되 고 있 는 기술 로 발전 하 였 을까 ? 지능 이 란 인간 뿐 아니 라 동물 을 포함 해 생명체 들 은 다양 한 의사 결정 을 필요 로 한다 . 예컨대 굶주린 반려 견 에게 두 명 이 각각 먹 을 것 을 내밀 며 오 라고 손짓 하 는 상황 을 상상 해 보 자 . 반려 견 은 누가 주 는 먹이 를 먹 을지 판단 하 고 행동 해야 한다 . 반려 견 은 현재 의 상황 , 즉 시각 과 후각 을 자극 하 는 먹 을 것 과 자신 이 굶주린 상황 에 대해서 인식 한다 . 그리고 두 사람 이 자신 에게 안전 하 게 먹이 만 줄 것 인지 , 해 를 끼칠 지 , 과거 의 경험 , 혹은 다른 요인 을 통해서 판단 하 고 행동 할 것 이 다 . 지능 은 이 처럼 주어진 환경 에서 추론 하 고 결정 하 고 행동 하 는 것 을 의미 한다 . 앞 의 반려 견의 사례 처럼 지적 활동 은 다양 한 요소 들 을 포함 하 고 있 다 . 코넬 대학 의 로버트 스턴버그 ( robert sternberg ) [ 3 ] 교수 는 지능 이 다음 과 같이 세 가지 요소 로 구성 되 어 있 다는 분류 모델 을 제시 했 다 . 첫째 , 분석 적 ( analytic ) 으로 문제 를 해결 하 기 위해 필요 한 사항 들 을 분석 하 는 능력 . 둘째 , 통합 적 ( synthentic ) 으로 새로운 정보 와 과거 의 정보 를 통합 적 으로 고려 하 여 창의 적 ( creative ) 결론 에 도달 하 는 능력 . 셋째 , 실용 적 ( practical ) 으로 결론 에 따른 실제 행동 을 취하 는 것 . [ 지능 활동 ] 상황 파악 - 입력 된 정보 를 바탕 으로 현 상태 를 파악 추론 및 판단 - 상황 을 바탕 으로 어떤 결론 에 도달 반응 혹은 행동 - 도달 한 결론 에 맞 게 행동 인간 지능 을 흉내 내 려는 인공지능 ai 연구 는 “ 인간 의 지적 활동 을 기계 도 할 수 있 을까 ? ” 라는 의문 에서 출발 했 다 . 영국 의 천재 수학자 인 앨런 튜링 ( alan turing ) 은 0 과 1 을 이용 해서 복잡 한 계산 을 수행 할 수 있 다는 것 을 입증 했 다 . 이것 이 바로 계산 기계 ( computer ) 의 시초 가 되 었 다 . 튜링 이 1950 년 에 발표 한 논문 \" computing machinery and intelligence ” [ 4 ] 에서 튜링 의 일대기 를 그린 영화 제목 과 같 은 “ the imitation game ” 을 주제 로 기계 가 인간 의 지능 을 흉내 ( imitation ) 낼 수 있 는 조건 을 제시 했 다 . 튜링 이 고안 한 방법 은 다음 과 같 다 . 판 별자 인 인간 c 가 기계 a 가 하 는 답변 과 인간 인 b 가 하 는 답변 을 구별 하 지 못한다면 , 기계 a 는 인간 의 지능 을 가지 고 있 는 것 이 아닐까 라고 결론 낼 수 있 다는 것 이 다 . 이것 을 튜링 테스트 ( turing test ) 라고 부르 고 , 기계 의 지능 여부 를 판단 하 는 방식 으로 여전히 사용 되 고 있 다 . 1982 년 개봉 영화 \\' 블레이드 러너 \\' 에서 안드로이드 로봇 인 \\' 레이첼 \\' 을 튜링 테스트 하 는 장면 이 와 같이 지능 적 인 기계 를 만드 는 엔지니어 링 및 과학 으로서 ai 가 학문 연구 의 한 분야 로 자리 잡 게 된 것 은 1956 년 다트머스 ai 컨퍼런스 ( dartmouth artificial intelligence conference ) [ 5 ] 에서 존 매카시 ( john mccarthy ) 가 ai 를 ‘ 기계 를 인간 행동 의 지식 에서 와 같이 행동 하 게 만드 는 것 ’ 으로 최초 로 정의 하 면서 부터 이 다 . 다트머스 ai 컨퍼런스 참석 한 인공지능 연구 의 선구자 들 왼쪽 부터 , john mccarthy , marvin minsky , allen newell , hebert a . simon 인공지능 의 역사 ai 가 처음 등장 한 다트머스 컨퍼런스 는 복잡 계 이론 , 언어 처리 , 신경망 , 입력 신호 처리 , 창의 적 사고 분야 의 다양 한 전문가 들 이 참여 한 학술 대회 였 다 . 당시 카네기 멜론 대학 소속 이 던 앨런 뉴웰 ( allen newell ) 과 허버트 a . 사이먼 ( herbert a . simon ) [ 6 ] 은 세계 최초 의 ai 프로그램 인 논리 연산 가 ( logic theorist ) 를 선보였 다 . 논리 연산 가 는 최초 로 기계 가 논리 적 추론 ( logical reasoning ) 을 할 수 있 다는 것 을 보여 주 었 다 . 당시 , 논리 연산 가 는 1903 년 알프레드 노스 화이트헤드 ( alfred north whitehead ) 와 버트런드 러셀 ( bertrand russell ) 이 쓴 ‘ 수학 원리 ’( principia mathematica ) 두 번 째 장 에 등장 한 52 개 의 정리 ( theorem ) 중 38 개 를 증명 해 보였 다 . 논리 연산 가 는 이후 ai 연구 에 영향 을 주 는 중요 한 개념 들 을 제시 해 주 었 다 [ 7 ] . 세계 최초 의 ai 프로그램 , 논리 연산 가 ( logic theorist ) 첫째 , 추론 을 통한 탐색 . 논리 연산 가 는 공리 ( axiom ) 로 부 터 수학 적 정리 를 이끌 어 내 기 위해서 , 공리 로 부 터 출발 해 발생 가능 한 대체 , 교환 , 분리 의 경우 들 을 모두 찾 아 가 는 방법 을 사용 하 였 다 . 둘째 , 경험 적 방법론 ( heuristics ) 도입 . 발생 가능 한 추론 들 이 다양 할 경우 나무 의 가지 가 너무 많 아 질 수 있 어서 모든 경우 를 검색 하 는 것 은 비 효율 적 임 을 깨달 았 다 . 여기 서 경험 적 방법론 을 도입 하 여 효율 성 을 높여 주 었 다 . 머신 러닝 에서 특징 설계 ( feature engineering ) 가 이런 역할 을 해 준다 . 셋째 , 정보 보처 리 언어 ( ipl , information processing language ) 개발 . 프로그램 처리 를 상징 적 으로 표현 한 언어 인 ipl 은 이후 존 매카시 ( john mccarthy ) 가 만든 리습 ( lisp ) 프로그래밍 언어 의 기초 가 되 었 다 . 스탠포드 와 다트머스 , mit 교수 를 역임 한 매카시 교수 는 ai 란 용어 를 1955 년 ‘ 지능 이 있 는 기계 를 만들 기 위한 과학 과 공학 ’ 이 라는 논문 에서 처음 기술 했 다 . 리습 ( lisp ) 은 ai 연구 에서 논리 적 흐름 을 상징 적 으로 표현 하 는 중요 한 프로그래밍 언어 로 활용 되 었 다 . 탐색 과 추론 의 시대 논리 연산 가 ( logic theorist ) 에서 제안 된 탐색 과 추론 방법 은 초기 ai 연구 에 중요 한 개념 들 을 제시 했 다 . 해결 할 할 문제 에 대해서 기계 가 수행 할 일 들 을 상황 별 로 대응 하 는 방식 , 이게 바로 탐색 ( 대응 ) 과 추론 ( 상황 파악 ) 의 알고리즘 이 다 . 이 알고리즘 은 흔히 ‘ if then ’( 가령 ~ 하 면 , ~ 한다 ) 이 라고 도 하 는데 , 예 를 들 면 다음 과 같 다 . [ if then rule ] if 어떤 것 이 날 아 다닌다 . then 어떤 것 은 새 다 . 즉 , ‘ if - then rule ’ 은 컴퓨터 가 논리 적 으로 정보 를 처리 할 수 있 도록 원칙 ( rule ) 을 제공 해 줘서 답 을 찾 아 가 는 과정 이 다 . 미로 를 찾 는 알고리즘 이나 , 체커 게임 ( checkers ) 을 하 는 알고리즘 을 개발 하 는 것 등 이 ‘ if - then rule ’ 을 통해 해결 할 수 있 는 대표 적 인 문제 들 이 다 . 미 로 찾 기 예제 [ 미 로 찾 기 알고리즘 예시 ] 그림 과 같이 왼쪽 상단 의 입구 에서 오른쪽 하단 의 입구 로 찾아가 는 미로 가 주어졌 을 때 길 을 어떻게 찾 을 수 있 을까 ? 아래 와 같 은 룰 을 설정 해서 미로 를 찾 을 수 있 다 . step 1 ( 현재 위치 저장 ) if 현재 의 위치 가 갈림길 ( 길 이 2 가지 이상 인 경우 ) 이 면 then 위치 를 기억 한다 . step 2 ( 이동 ) 지나온 길 을 제외 하 고 길 이 남 아 있 는 않 은 경우 까지 아래 를 반복 한다 . if 이동 할 길 이 있 으면 then 길 이 있 는 방향 으로 이동 한다 . 이동한 길 은 기억 한다 . if 지나 온 길 만 남 은 경우 step 3 로 넘어간다 . step 3 ( 갈림길 로 되돌 아 가 기 ) step 1 에서 기억 한 위치 로 돌아가 서 이전 에 가 지 않 은 길 로 되돌 아 간다 . 알고리즘 으로 문제 를 해결 하 는 시대 의 대표 적 인 두 가지 방법 은 ‘ 깊이 우선 탐색 ’( depth first search ) 과 ‘ 너비 우선 탐색 ’( breadth first search ) 이 있 다 . 깊이 우선 탐색 이란 현재 주어진 문제 에서 발생 가능 한 상황 들 중 한 가지 를 선택 해 깊이 있 게 해결 방법 까지 분석 해 가 는 방법 이 다 . 위 에서 예제 로 제시 한 미 로 찾 기 알고리즘 은 깊이 우선 탐색 의 예 이 다 . 이 에 비해 너비 우선 탐색 은 문제 에서 발생 가능 한 모든 상황 을 고려 하 며 가능 성 을 넓혀 나가 는 것 이 다 . 이렇게 알고리즘 을 통한 ai 연구 의 성과 는 인간 체스 게임 챔피언 과 컴퓨터 체스 프로그램 과 대결 로 이어지 게 된다 . 1997 년 ibm 에서 만든 ‘ 딥 블루 ’( deep blue ) 는 당시 세계 챔피언 인 러시아 의 카스파로프 ( kasparov ) 와 의 체스 경기 에서 승리 하 게 된다 [ 8 ] . 이 처럼 초기 ai 기술 연구 는 컴퓨터 가 주어진 문제 를 해결 할 수 있 도록 인간 이 직접 룰 을 지정 해 주 는 방식 으로 진행 됐 다 . 문제 해결 방법 을 논리 적 으로 설계 하 고 컴퓨터 가 수행 할 수 있 도록 프로그래밍 하 면 지능 을 발전 시킬 수 있 을 것 으로 기대 했 다 . 하지만 다양 한 데이터 를 종합 해서 추론 하 는 좀 더 복잡 한 문제 는 ‘ 논리 설계 의 어려움 ’ 으로 시도 조차 하 지 못하 게 되 었 다 . 이런 한계 속 에 1970 년 이후 ai 연구 열기 가 사그라들 면서 , 일명 ai 의 겨울 ( ai winter ) 이 시작 됐 다 [ 9 , 10 ] . 시간 이 흘러 서서히 ai 연구 에 반전 의 기회 가 찾아오 고 있 었 다 . 1990 년 대 인터넷 이 보급 되 기 시작 하 면서 웹 상 에 방대 한 정보 가 쏟아졌 다 [ 11 ] . 또한 , 이렇게 생성 되 는 정보 를 대용량 으로 보관 할 수 있 는 하드 디스크 ( hdd ) 의 가격 이 급격 하 게 낮 아 졌 다 [ 12 ] . 이른바 ‘ 빅 데이터 ’ 시대 가 시작 된 것 이 다 . 머신 러닝 ( machine learning ) , 기계 가 스스로 학습 한다 . ai 연구 의 1 차 붐 시대 는 ‘ if - then rule ’ 을 활용 한 탐색 과 추론 을 통한 지능 향상 이 목적 이 었 다 . 디지털 화 된 지식 과 정보 가 빠르 게 늘어나 는 시대 에 는 컴퓨터 에 지식 을 반영 하 면 , 지능 을 향상 시킬 수 있 지 않 을까 라는 아이디어 가 생겨났 다 . 이렇게 등장 한 ai 가 전문가 시스템 ( expert system ) 이 다 . 가령 , 의학 분야 의 전문가 인 의사 들 은 의학 관련 전문 지식 을 통해 환자 를 진단 하 고 치료 하 는 결정 을 하 게 된다 . 전문가 시스템 도 이러 한 접근 방법 에서 고안 되 었 다 . 전문가 시스템 은 지식 기반 ( knowledge base ) 에 지식 과 정보 를 저장 하 고 , 추론 엔진 ( inference engine ) 에서 기존 의 지식 을 통해 새로운 지식 을 추론 하 는 두 가지 시스템 으로 구성 된다 . 전문가 시스템 은 1970 년 대 처음 고안 되 어서 1980 년 대 크 게 유행 하 게 된다 . 궁금 한 질문 에 대해서 답 을 할 수 있 는 컴퓨터 시스템 을 만들 수 있 을까 ? 이 질문 에 답 하 고자 전문가 시스템 을 기반 으로 개발 된 ibm 왓슨 ( watson ) 은 2011 년 미국 의 퀴즈쇼 제 퍼디 ( jeopardy ) 에 출연 해 인간 챔피언 들 을 이기 고 우승 을 차지 한다 . ibm 의 watson 프로그램 의 jeopardy 경기 , 왼쪽 ken jennings , 오른쪽 brad rutter 단순히 책 을 보 는 것 과 , 책 속 의 내용 을 이해 하 는 것 은 다르 다 . 막 한글 을 깨우친 아이 에게 칸트 ( immanuel kant ) 의 ‘ 순수 이성 비판 ’ 책 을 읽 도록 하 면 어떻게 될까 ? 즉 , 컴퓨터 에게 지식 을 저장 하 는 것 과 컴퓨터 가 그 지식 을 이해 하 는 것 은 완전히 다른 영역 이 다 . 이 를 해결 하 기 위해 등장 한 것 이 바로 ‘ 머신 러닝 ’ 이 다 . 보통 인간 은 어떤 문제 를 해결 한 경험 을 토대 로 그 다음 에 등장 하 는 문제 를 이전 보다 개선 된 방법 으로 해결 하 려고 노력 하 게 된다 . 머신 러닝 은 경험 적 으로 문제 를 해결 하 는 방법 을 컴퓨터 에 적용 한 것 이 다 . 컴퓨터 에게 특정 과제 ( t , task ) 를 해결 하 면서 그 성과 를 측정 ( p , performance measure ) 하 는 경험 ( e , experience ) 을 하 게 한다 . 그야말로 기계 를 학습 시켜 과제 ( t ) 수행 에 대한 측정 ( p ) 이 개선 되 도록 지속 적 경험 ( e ) 을 수행 하 는 구조 다 [ 13 ] . 예 들 들 면 , 야구 경기 승리 전략 을 학습 하 는 머신 러닝 프로그램 을 가정 해 보 자 . 여기 서 과제 ( t ) 는 야구 경기 를 승리 하 는 것 . 성과 측정 ( p ) 은 득점 을 많이 하 고 실점 을 최소 화 하 는 것 즉 , 득 - 실 차이 를 최대 로 하 는 것 이 될 것 이 다 . 여기 서 의 경험 ( e ) 은 실제 야구 경기 를 수행 하 는 것 이 다 . 프로그램 은 경기 에서 발생 하 는 다양 한 상황 인 투수 의 방어 율 , 그 날 의 컨디션 , 수비 능력 , 타자 의 타율 , 주루 능력 등 수 많 은 조건 에 따라서 경험 ( e ) 을 훈련 하 게 된다 . 머신 러닝 에서 사용 하 는 3 가지 학습 방법 [ 14 ] 지도 학습 ( supervised learning ) 지도 학습 은 입력 된 데이터 에 대한 판단 결과 가 명확히 주어진 경우 사용 하 는 방법 이 다 . 아이 들 이 사물 을 하나 씩 익혀 나가 는 과정 을 보 면 , 사물 을 실제 접하 기 전 에 그림책 을 먼저 보 는 경우 가 많 다 . 한 아이 가 자동차 종류 에 대한 그림책 을 보 면서 승용차 , 버스 , 트럭 에 대해서 알 게 되 었 다 . 이제 밖 에 나가 서 지나가 는 차 들 을 보 면서 , “ 이건 승용차 , 저건 버스 ” 라고 배운 지식 을 활용 하 게 된다 . 갑자기 도로 에 견인차 가 지나가 게 되 면 , 아이 는 이전 에 배운 트럭 과 는 다른 모습 을 보 면서 “ 저건 트럭 인가요 ? ” 하 고 묻 게 될 것 이 다 . 비지 도 학습 ( unsupervised learning ) 비지 도 학습 은 입력 된 데이터 에 대한 판단 결과 가 명확 하 게 주 어 지 지 않 은 경우 사용 한다 . 답 이 정해져 있 지 않 기 때문 에 하나 의 결과 를 도출 할 수 없 기에 주로 군집 분류 ( clustering ) 에 사용 하 는 방법 이 다 . 가령 , 서울 로 출퇴근 하 는 사람 들 의 이동 경로 데이터 만 을 알 고 있 는 경우 , 기계 가 스스로 학습 하 면서 이 들 의 사 는 지역 , 출근 지역 을 구분 하 게 된다 . 군집 분류 예제 중 하나 는 아이리스 ( iris data set ) 꽃 분류 문제 다 [ 15 ] . 아 이리스 꽃 분류 문제 는 150 개 의 꽃 이미지 를 꽃받침 ( sepal ) 의 길이 와 폭 , 꽃잎 ( petal ) 의 길이 와 폭 등 네 가지 특징 을 이용 해서 총 세 종류 의 꽃 ( iris setosa , iris versicolour , iris virginica ) 으로 군집 분류 하 는 것 이 다 . ( 실제 데이터 에 는 꽃 종류 이름 이 주어져서 지도 학습 으로 도 사용 되 지만 , 특징 만 가지 고 꽃 의 종류 를 군집 분류 하 는 비지 도 학습 으로 많이 사용 된다 . ) 지도 학습 은 입력 된 자료 a 에 대해서 a 이 다 라는 답 ( label ) 을 주 고 a 가 a 임 을 알 수 있 도록 스스로 학습 하 는 것 이 다 . 이 에 비해 비지 도 학습 은 a 와 b 의 두 가지 입력 된 자료 가 있 는데 이 둘 이 a 인지 b 인지 모르 고 단지 둘 의 차이 를 스스로 학습 해서 ‘ 다르 다 ’ 라고 군집 분류 하 는 것 이 다 . 강화 학습 ( reinforcement learning ) 강화 학습 이란 주어진 문제 의 답 이 명확히 떨어지 지 는 않 지만 , 결과 에 따라서 보상 ( reward ) 과 손실 ( penalty ) 이 주어진다면 이 를 통해 보상 을 최대 화 하 는 방향 으로 진행 하 도록 모델 을 학습 하 는 방식 이 다 . 입력 된 데이터 에 대한 답 이 명확 하 게 주 어 지 지 않 는다는 점 에서 비지 도 학습 과 유사 하 지만 , 결과 를 통해 피드백 을 받 아 이 를 학습 에 반영 한다는 것 이 기존 의 학습 방식 과 다르 다 . 강화 학습 은 주로 게임 을 플레이 하 거나 전략 적 인 판단 을 통해 방향 을 설정 할 때 활용 되 는 방식 이 다 . 강화 학습 으로 해결 할 수 있 는 쉬운 예제 를 들 면 ‘ 퐁 ’ 게임 을 학습 하 는 경우 를 생각 할 수 있 다 . 퐁 게임 은 양쪽 의 바 ( bar ) 를 상하 로 움직이 면서 공 을 받 아 내 는 게임 이 다 . 공 을 받아치 지 못하 면 상대방 이 득점 을 하 게 된다 . 머신 러닝 으로 퐁 게임 을 학습 하 는 경우 플레이 결과 에 따라서 받 게 되 는 보상 ( reward ) 이 주어지 게 된다 . 기계 학습 은 이렇게 주어진 보상 을 프로그램 이 최대 로 달성 할 수 있 도록 이루어지 게 된다 [ 16 ] . 강화 학습 방법 으로 학습 가능 한 pong game 특징 설계 가 필요 한 머신 러닝 빅 데이터 시대 가 도래 하 고 svm ( support vector machine ) , rbm ( restricted boltzmann machine ) 같 은 방법 론 이 발전 하 면서 머신 러닝 은 ai 연구 분야 를 주도 하 게 된다 . 하지만 , 머신 러닝 의 발전 에 도 한계 가 있 었 는데 바로 ’ 특징 설계 ’( feature engineering ) 의 문제 다 . 가령 머신 러닝 을 이용 해 사람 얼굴 이미지 인식 을 하 는 경우 검 은 색 은 머리 고 , 눈 은 동그랗 고 , 얼굴 의 윤곽 은 이미지 의 밝기 차이 로 구분 하 는 등 각각 의 특징 을 통해 다른 사물 과 사람 얼굴 을 분류 하 게 된다 . 일반 적 으로 볼 수 있 는 사람 들 의 얼굴 로 학습 을 진행 한 기계 에 녹색 으로 페이스 페인팅 ( face painting ) 을 한 사진 을 입력 한다면 우리 는 금방 사람 의 얼굴 이 라고 생각 하 지만 , 기계 는 사전 에 분류 된 얼굴색 의 특징 과 다르 기 때문 에 분류 에 실패 하 게 된다 . 머신 러닝 분류 성능 은 사전 에 정의 된 특징 ( feature ) 과 특징 의 중요 성 을 나타내 는 가중치 ( weight ) 를 어떻 게 주 는냐 에 따라 좌우 된다 . 이렇게 특징 을 사전 에 정의 하 는 것 은 학습 하 고자 하 는 영역 ( domain ) 마다 다르 게 나타난다 . 머신 러닝 성능 을 높이 기 위해서 이미지 , 영상 , 음성 , 텍스트 등 각각 의 도메인 별로 특징 설계 는 어려운 과제 중 하나 였 다 . 리처드 코엘료 ( richert coelho ) 가 기술 한 책 ‘ building machine learning systems with python ’ 에서 ‘ 특징 설계 ’ 에 관한 챕터 를 보 면 , \" 잘 선택 된 특징 으로 만든 간단 한 알고리즘 이 그다지 잘 선택 되 지 못한 특징 의 최신 알고리즘 보다 좋 은 결과 가 나온다 \" 고 하 고 있 다 . 결국 머신 러닝 성능 은 얼마나 효과 적 인 특징 을 찾아내 느냐 에 따라 달려 있 다고 할 수 있 다 . 따라서 머신 러닝 으로 학습 을 할 경우 데이터 의 영역 ( domain ) 에 따라서 데이터 의 특징 설계 를 할 수 있 는 전문가 들 이 필요 하 다 . 딥 러닝 ( deep learning ) 인간 뇌 의 정보 처리 방식 을 흉내 낸다 2012 년 ‘ 이미지 넷 ’( imagenet ) 의 이미지 인식 경연 대회 에서 ai 연구 분야 의 흐름 을 바꾸 는 일 이 벌어졌 다 . 이미 지넷 은 인터넷 의 각 이미지 에 이름표 를 달 아 주 는 크 라 우드 소 싱 프로젝트 다 . 2010 년 부터 ‘ imagenet large scale visual recognition challenge ’( ilsvcr ) [ 17 ] 라는 경연 대회 를 통해 전 세계 의 연구 그룹 들 이 각자 의 이미지 인식 기술 을 겨루 고 있 다 . 대회 중 의 한 분야 는 이미지 인식 을 통해 1000 개 의 사물 을 구분 하 는 것 이 다 . 참여 팀 들 은 알고리즘 기술 을 통해 하나 의 이미지 에 다섯 개 의 사물 명칭 ( label ) 을 제시 하 고 이 를 평가 하 여 정확도 를 측정 한다 . 2012 년 도 대회 에서 토론토 대학교 의 제프리 힌튼 교수 팀 의 ‘ supervision ’ 은 ‘ large , deep convolutional neural network ’ 이 라는 알고리즘 을 이용 해 이미지 를 인식 했 다 . 딥 러닝 알고리즘 의 일종 인 cnn 을 사용 한 힌튼 교수 팀 은 기존 의 방법론 을 뛰어넘 는 혁신 적 인 성과 를 보여 주 었 다 . 2011 년 도의 1 위 팀 과 2 위 팀 의 오류 률 차이 는 1 위 ( 25 . 7 %) 와 2 위 ( 31 . 0 %) 에서 2012 년 도 \\' supervision \\' 은 16 . 4 % 로 2 위 팀 의 26 . 1 % 와 의 큰 차이 로 우승 하 게 된다 [ 18 , 19 ] . 인간 의 뇌 는 뛰어난 정보 처리 시스템 이 다 . 시각 , 후각 , 촉각 , 청각 , 미각 등 다양 한 감각 기관 으로 입력 된 정보 를 종합 적 으로 판단 해 즉각 적 인 반응 을 내놓 게 된다 . 수 많 은 뉴런 들 의 연결 로 구성 되 어 있 는 뇌 의 구조 를 ‘ 신경망 \\'( neural network ) 이 라고 한다 . 하나 의 뉴런 은 다양 한 뉴런 들 과 연결 되 어 있 고 , 시냅스 ( synapse ) 를 통해 신호 를 주 고 받 으며 정보 를 전달 하 게 된다 . 뉴런 에 임계 치 ( threshold ) 이상 의 신호 가 입력 되 면 , 그 뉴런 은 활성 화 ( activation ) 되 면서 시냅스 를 통해 신호 를 전달 하 고 임계 치 를 넘 지 않 은 경우 뉴런 이 활성 화 되 지 않 아 신호 가 전달 되 지 못한다 . 딥 러닝 은 뇌 의 정보 전달 방식 과 유사 하 게 신경망 구조 를 여러 층 으로 깊이 ( deep ) 있 게 구성 하 여 학습 을 진행 하 는 것 이 다 . deep neural network 구조 [ 20 ] 가령 여러 사진 에서 고양이 이미지 를 인식 하 는 학습 을 진행 한다고 가정 해 보 자 [ 21 ] . 기존 머신 러닝 방법 론 에서 는 특징 설계 를 통해서 다른 동물 과 고양이 의 얼굴 을 잘 구분 할 수 있 는 특징 을 사전 에 추출 ( feature extraction ) 하 고 추출 된 특징 을 바탕 으로 분류 하 며 학습 을 진행 한다 . 하지만 , 딥 러닝 은 정보 를 구분 할 수 있 는 최소한 의 단위 , 이미지 의 경우 픽셀 데이터 를 입력 하 면 , 입력 된 값 과 출력 된 결과물 의 오 차 가 최소 화 되 는 방향 으로 네트워크 가 스스로 학습 한다 . 중간 에 특징 추출 과정 이 사라지 고 입력 과 출력 의 데이터 만 주 어 지 면 학습 을 할 수 있 기 때문 에 ‘ end to end ’( e 2 e ) 학습 이 라고 도 부른다 . ‘ 인공 신경망 ’( artificial neural network ) 의 역사 는 1940 년 대 까지 거슬러 올라 간다 . 프랭크 로젠블라트 ( frank rosenblatt ) 코넬 대 교수 는 입력 신호 를 연산 해서 출력 하 는 퍼셉트론 ( perceptron ) 이 라는 개념 을 1957 년 에 제시 했 다 . 퍼셉트론 은 비 선형 연산 에 대해선 작동 하 지 않 는 한계 로 금방 잊혀졌 지만 , 1980 년 대 퍼셉트론 을 다층 구조 ( multi - layer ) 로 연결 하 면 , 비 선형 연산 도 가능 하 다는 사실 이 발견 됐 다 . 그러나 다시 ‘ ai 겨울 \\' 동안 관련 연구 에서 완전히 배제 됐 다 . 당시 에 는 어쩔 수 없 는 시대 적 한계 가 있 었 다 . 첫째 , 층 을 깊이 ( deep ) 있 게 쌓 아야 ai 의 성능 이 개선 되 지만 , 계산 할 양 이 많 아 지 게 되 고 이 는 당시 의 컴퓨팅 능력 으로 극복 하 기 힘든 한계 였 다 . 둘째 , 층 이 깊 어 진다는 것 은 층간 의 연결 변수 들 이 증가 한다는 것 을 의미 하 는데 이 는 학습 을 통해 찾 아야 할 미지수 가 늘어나 는 것 을 의미 한다 . 우리 는 중학교 때 , 변수 가 두 개 x , y 인 연립 방정식 에 대해서 배운다 . 즉 두 개 의 변수 를 찾 기 위해선 두 개 의 방정식 이 필요 한 것 처럼 찾 아야 할 변수 가 늘어날수록 입력 해야 할 데 이타 가 많이 필요 하 다 . 시간 이 약 이 되 었 을까 ? 2000 년 대 에 이 두 가지 문제 가 해결 되 기 시작 한다 . 빅 데이터 시대 를 맞이 하 여 데이터 는 넘쳐나 기 시작 했 고 , 컴퓨터 h / w 의 성능 개선 뿐 아니 라 병렬 연산 , gpu 연산 등 의 방법 이 등장 하 면서 연산 속도 가 극 적 으로 개선 되 었 다 . 2012 년 힌튼 교수 팀 ‘ supervision ’ 이 사용 한 모델 은 65 만 개 의 뉴런 과 6000 만 개 의 변수 , 6 억 3000 만 개 의 네트워크 연결 로 구성 되 었 다 . 딥 러닝 ( deep learning ) ‘ deep ’ 의 의미 는 ? 딥 러닝 ( deep learning ) 의 ‘ deep ’ 은 다양 한 측면 의 의미 를 가지 고 있 다 . 대부분 의 ai 연구자 들 에게 는 인공 신경망 의 은닉 층 ( hidden layer ) 이 2 개 층 이상 인 경우 deep ( 깊 은 ) 이 라고 생각 한다 . 이러 한 정의 는 2 개 층 이상 으로 신경망 을 구성 할 때 , 성공 적 인 학습 과 예측 을 수행 한다는 것 을 의미 한다 . 실제 2012 년 ‘ supervision ’ 팀 이 사용 한 신경망 은 7 개 의 은닉 층 을 가지 고 있 었 다 . 최근 이미지 인식 연구 에서 마이크 로 소프트 연구 팀 ‘ resnet ’ 모델 은 무려 150 개 의 은닉 층 을 사용 해서 예측 정확도 를 높였 다 ( 오류 율 3 . 57 %)[ 22 ] . 또 다른 의미 로 딥 러닝 ( deep learning ) 은 ‘ 심화 학습 ’ 을 뜻 하 기 도 한다 . 인공 신경망 학습 에서 는 인간 이 수행 하 는 특징 설계 가 필요 치 않 기 때문 에 기계 가 스스로 입력 된 데이터 의 특징 을 찾 기 위한 학습 과정 을 거친다 . 이러 한 과정 을 심화 학습 이 라고 표현 할 수 있 다 . 인공 신경망 연구 가 ai 의 겨울 을 끝내 고 새로운 도약 의 시기 를 맞이 할 수 있 었 던 이유 는 데이터 , 연결 , 하드웨어 개선 등 여러 가지 변수 가 함께 새로운 시대 를 열 었 기 때문 이 다 . 인공지능 기술 의 현재 우리 는 2016 년 이세돌 을 이긴 알 파고 를 ai 의 대명사 로 생각 하 고 있 다 . 딥 러닝 방법 론 이 ai 연구 에서 뛰어난 성과 를 보이 기 시작 한 이후 다양 한 분야 에서 인간 지능 에 도달 했 거나 혹은 인간 을 뛰어넘 는 ai 들 이 출연 하 고 있 다 . 인간 을 넘어서 는 ai 시대 가 오 고 있 다 . 최근 카네기 멜론 대학 연구 팀 에서 만든 ai 프로그램 은 ‘ 텍사스 홀덤 포커 게임 ’ 에서 세계 챔피언 을 이겼 다 [ 23 ] . 텍사스 홀덤 게임 은 미국 에서 가장 많이 즐기 는 포커 게임 으로 매년 수십억 원 의 상금 이 걸린 세계 대회 가 열리 고 있 다 . 포커 는 운 이 승패 를 좌우 하 는 경향 이 크 다 . 하지만 텍사스 홀덤 포커 대회 는 여러 번 의 경기 를 통해 가장 많 은 게임 칩 을 획득 한 참가자 가 우승 하 는 방식 이 다 . 즉 , 한 번 의 게임 승패 보다 전체 적 인 게임 운영 전략 이 중요 한 요소 로 작용 한다 . 이기 는 게임 의 베 팅 을 높이 고 지 는 게임 의 베 팅 을 낮추 는 식 의 전략 적 판단 이 필요 한 것 이 다 . 이러 한 게임 에서 ai 가 세계 챔피언 을 이겼 다는 것 은 특정 분야 의 전략 적 의사 결정 까지 도 일정 수준 을 뛰 어 넘 었 다는 의미 다 . 페이스북 에 사진 을 올려 보 면 , 얼굴 을 자동 으로 인식 , 이 사람 이 맞 는지 물 어 보 며 자동 태그 하 는 기능 을 경험 할 수 있 다 . 페이스북 이 2014 년 에 선보인 딥 페이스 ( deepface ) 라는 기술 로 사진 에서 사람 을 인식 해 누구 인지 알려 주 는 서비스 다 . 2015 년 구글 은 페이스 넷 ( facenet ) 이 라는 얼굴 인식 시스템 을 발표 했 는데 연구 결과 99 . 96 % 의 인식 률 을 보여 준다고 한다 . 인간 이 사진 을 보 고 사람 을 구분 하 는 정확도 가 평균 적 으로 97 . 53 % 임 을 감안 하 면 인간 보다 훨씬 높 은 수준 을 달성 한 것 이 다 . 특히 , 인간 의 경우 사진 이 흐리 거나 , 조명 이 너무 밝 거나 어둡 거나 , 사진 의 각도 가 달라지 게 되 면서 얼굴 의 일부분 만 보이 는 경우 오류 를 범하 기 쉽 지만 , ai 는 대부분 높 은 정확도 로 얼굴 을 인식 하 고 있 다 [ 24 , 25 ] . 당뇨 망막 병증 ( diabetic retinopathy , dr ) 은 당뇨병 의 합병증 으로 발생 하 는 병 으로 망막 의 미세 혈관 손상 으로 실명 에 이르 게 되 는 병 이 다 . 전 세계 적 으로 발생 하 는 실명 의 원인 중 가장 높 은 비중 을 차지 하 고 있 는 질병 이 다 . 초기 에 진단 된 dr 은 치료 를 통해서 악화 를 막 을 수 있 다 . 기존 에 고도 로 훈련 된 안 과 전문의 들 이 망막 을 스캔 한 사진 을 직접 관찰 하 면서 진단 했 다 . 구글 연구 팀 은 2016 년 11 월 ai 가 97 ~ 98 % 수준 으로 dr 을 진단 할 수 있 다는 논문 을 발표 했 다 . 구글 은 ai 를 훈련 시키 기 위해서 수년 간 미국 전역 의 병원 에서 약 12 만 개 의 안구 이미지 를 분석 했 다 . 이 기술 은 dr 의 초기 진단 을 좀 더 쉽 고 편하 게 이용 할 수 있 게 해 주 면서 많 은 환자 들 을 치료 할 수 있 을 것 으로 기대 되 고 있 다 [ 26 ] . 우리 가 인지 하 지 못한 사이 이미 많 은 분야 에서 ai 는 인간 에 가깝 거나 인간 을 넘어서 는 능력 을 보이 고 있 다 . 1997 년 도 에 ai 와 경쟁 하 여 체스 를 이긴 마지막 인간 이 러시아 의 카스파로프 ( kasparov ) 였 다면 , 바둑 을 이긴 마지막 인간 은 이세돌 이 될 것 이 다 . 이미 다양 한 분야 에서 인간 의 감각 기관 중 시각 , 청각 을 대체 하 기 위해 ai 가 사용 되 어 인간 수준 의 지각 능력 을 보여 주 고 있 다 . 또한 , 복잡 한 계산 과 전략 적 추론 에서 조차 도 인간 의 능력 을 넘어서 고 있 다 . 앞 으로 우리 는 ‘ 카카오 ai 리포트 \\' 를 통해 다양 한 분야 의 ai 사례 들 을 소개 할 예정 이 다 . 글 | 정수헌 noah . jung @ kakaocorp . com 천체 물리학자 가 되 기 를 꿈꾸 며 물리학 을 공부 했 다 . 하지만 금융 분석 에 더욱 흥미 를 느끼 고 증권사 에서 퀀트 애널리스트 로 일 했 다 . 한때 모바일게임 개발 도 하 고 다양 한 경험 을 쌓았 다 . 지금 은 ai 기술 을 대중 들 에게 쉽 게 전달 하 기 위해 고민 하 고 있 다 . [ 1 ] 참고 : [ URL ] [ 2 ] 논문 : mcculloch and walter ( 1943 ) : a logical calculus of the ideas immanent in nervous activity [ 3 ] 논문 : sternberg , r . j . ( 1985 ) : beyond iq : a triarchic theory of human intelligence [ 4 ] 논문 : a . m . turing ( 1950 ) computing machinery and intelligence . mind 49 : 433 - 460 [ 5 ] 참고 : [ URL ] [ 6 ] 참고 : 사이먼 은 78 년 노벨 경제학 상 수상 가 이 고 뉴웰 은 수학자 로서 사이먼 의 제자 [ 7 ] 참고 : [ URL ] [ 8 ] 참고 : [ URL ] [ 9 ] 책 : russell , norvig . artificial intelligence a modern approach 3 rd edition . prentice hall , 2010 . [ 10 ] 책 : 마쓰오 유타카 . 인공지능 과 딥 러닝 . 동아 엠앤비 . 2016 . [ 11 ] 책 : abbate , janet . inventing the internet , cambridge : mit press , 1999 . [ 12 ] 참고 : harddisk cost / mb - hdd 저장 공간 당 가격 [ URL ] [ 13 ] 책 : mitchell , t . machine learning . mcgraw hill , 1997 . [ 14 ] 참고 : 앤드류 응 교수 , 스탠퍼드 강연 . [ URL ] [ 15 ] 참고 : [ URL ] [ 16 ] 참고 : [ URL ] [ 17 ] 참고 : [ URL ] [ 18 ] 참고 : 2012 년 이미지 넷 결과 , [ URL ] [ 19 ] 논문 : imagenet classification with deep convolutional neural networks - krizhevsky et al . 2012 . nips [ 20 ] 참고 : deep neural network 구조 . [ URL ] [ 21 ] 참고 : 구글 의 icml 2012 년 이미지 인식 발표 자료 . [ URL ] [ 22 ] 참고 : [ URL ] [ 23 ] 참고 : [ URL ] [ 24 ] 참고 : [ URL ] [ 25 ] 참고 : 2016 년 기준 이미지 인식 률 , facebook deepface ( 97 . 35 %) 인간 ( 97 . 53 %) google ( 99 . 96 % ) [ 26 ] 참고 : [ URL ] [ 27 ] 참고 : [ URL ] deep learning - the past , present and future of artificial intelligence [ 27 ]',\n",
       "       '* 본 글 은 \" 국내 인문 / 사회 과학 대학원 진학 \" 을 고민 하 는 분 들 을 위한 글 입니다 . * 본 글 은 직장 을 다니 며 석사 과정 을 마치 고 , 박사 과정 에 있 는 저 의 개인 적 인 경험 이 담긴 글 로 , 100 % 모든 전공 에 일반 화 시킬 수 없 음 을 미리 알려 드립니다 . 오늘 은 대학원 지원 시 제출 하 는 \" 연구 계획서 \" 는 어떻게 작성 해야 하 는지 , 그리고 어떤 면접 질문 을 준비 해야 할지 에 대해 이야기 하 려고 합니다 . 연구 계획서 는 무엇 인가요 ? 대학원 지원 을 할 때 가장 중요 한 것 은 입학 원서 도 , 공인 어학 성적표 도 아닌 \" 연구 계획서 \" 입니다 . 그런데 막상 \" 연구 계획서 \" 라고 하 면 뭔가 어려울 것 같 고 , 논문 같 은 걸 써야 하 는 건지 , 뭐 라고 써야 할지 난감 합니다 . 저 역시 도 그랬 고요 . 하지만 타이틀 이 \" 연구 계획서 \" 일 뿐 , 취업 준비 와 전혀 다를 게 없 기 때문 에 어렵 게 생각 하 지 않 으셔도 됩니다 . 대학원 지원 을 취업 이 라고 생각 하 신다면 , 연구 계획서 or 자기 소개서 , 학업 계획서 는 취업 자기 소개서 라고 생각 하 시 면 될 것 같 아요 . 하지만 . . 취업 준비 할 때 이력서 와 자기 소개서 를 작성 할 때 에 도 머리 를 부여잡 고 , 여러 날 밤 을 지새우 며 힘들 어 했 던 기억 , 다 들 있 으시 지요 ? 우리 가 취업 하 려는 의지 는 가득 하 지만 그 마음 과 열정 , 지금 까지 의 경험 들 을 자기 소개서 에 어떻게 녹여 써야 하 는지 어려웠 던 만큼 , 대학원 지원 을 할 때 에 도 공부 에 대한 열정 은 있 지만 , 이 열정 과 의지 를 어떻게 연구 계획서 에 표현 해야 할지 어려울 수 있 습니다 . 연구 계획서 를 작성 하 기 전 , 왜 우리 가 연구 계획서 를 작성 해야 하 는지 , 대학 에서 는 왜 지원자 들 에게 연구 계획서 를 받 는지 그 이유 를 알 아야 하 겠 지요 ? 연구 계획서 는 교수 들 이 대학원생 을 선발 하 는 기준 이 됩니다 . 석사 과정 혹은 박사 과정 에 지원 하 는 학생 이 우리 학과 에 대해 얼마나 알 고 있 는지 , 연구 에 대한 열정 이 있 는지 , 앞 으로 해당 학문 분야 에 기여 하 는 연구 를 할 수 있 는지 를 연구 계획서 를 통해 판단 하 는 것 이 죠 . 그리고 이 연구 계획서 는 서류 전형 이후 면접 전형 때 에 도 활용 이 되 는 중요 한 자료 가 됩니다 . 회사 면접 에서 면접 관 들 이 이력서 와 자기 소개서 를 보 고 면접 을 보 듯이 , 학교 에서 교수 님 들 은 입학 원서 와 연구 계획서 를 보 고 면접 을 보 기 때문 이 지요 . 그러 니 연구 계획서 가 대학원 지원 에 얼마나 중요 한지 아 시 겠 지요 ? 저 역시 석사 지원 을 위해 연구 계획서 를 쓰 려고 할 때 처음 엔 어떻게 써야 할지 너무 어려웠 습니다 . 모니터 에 연구 계획서 워드 파일 을 켜 놓 고 1 ~ 2 시간 동안 멍 - 하 니 바라 만 보 고 있 기 도 했 습니다 . 도대체 어디 서부터 어떤 이야기 를 써야 할지 모르 겠 더라고요 . 그래서 인터넷 으로 많 은 글 들 을 찾아보 고 , 또 주위 에 대학원 에 다니 는 언니 오빠 들 에게 조언 을 구해 가 며 연구 계획서 를 작성 했 던 기억 이 납니다 . 그리고 박사 과정 의 연구 계획서 까지 . . 두 번 의 연구 계획서 를 쓰 다 보 니 이제 는 연구 계획서 를 어떻게 써야 할지 어느 정도 알 게 된 것 같 네요 . 오늘 의 핵심 은 제 가 알 게 된 , 연구 계획서 작성 방법 입니다 . 서론 이 길 었 지요 ? 그럼 바로 본론 으로 넘어가 보 겠 습니다 : ) 연구 계획서 의 예 위 의 연구 계획서 는 저희 학교 는 아니 고 , 다른 학교 의 연구 계획서 입니다 . 이렇게 항목 을 미리 나눈 연구 계획서 도 있 고 , 아예 항목 이 없이 백지 로 인 적 사항 란 만 있 는 연구 계획서 가 있 습니다 . 하지만 꼭 들어가 야 할 내용 들 은 비슷비슷 합니다 . 위 의 연구 계획서 를 보 시 면 크 게 1 ) 자기 소개 , 2 ) 진학 동기 , 3 ) 수학 및 연구 계획 . 이렇게 세 가지 항목 으로 나눠져 있 네요 . 항목 들 을 보 니 어떤 생각 이 드 시 나요 ? 저 는 딱 보 자마자 . . 취업 할 때 의 자기 소개서 항목 과 비슷 하 다는 생각 이 들 었 는데 , 여러분 도 비슷 한 생각 을 하 셨 는지 모르 겠 네요 . 만약 항목 이 나뉘 어 있 다면 이렇게 항목 에 맞춰서 작성 을 하 시 면 되 고 , 그렇 지 않 다면 본인 스스로 서론 - 본론 - 결론 틀 을 정해 놓 고 작성 을 하 시 면 됩니다 . 그럼 , 연구 계획서 를 작성 하 려면 어떤 내용 을 적 어야 하 는지 공부 를 해야 겠 지요 ? 무엇 을 공부 해야 하 는지 에 대해 이야기 해 보 겠 습니다 . 연구 계획서 작성 전 분석 해야 할 것 들 1 . 지원 하 고자 하 는 학교 , 전공 , 분야 에 대해 분석 하 자 . 우리 가 이력서 와 자기 소개서 를 작성 할 때 가장 먼저 하 는 것 이 무엇 인가요 ? 바로 기업 분석 과 직무 분석 이 지요 ? 연구 계획서 를 작성 하 기 전 에 도 마찬가지 로 본인 이 지원 하 는 학교 와 전공 에 대한 분석 이 필요 합니다 . 기본 적 인 여러분 이 지원 하 려는 학교 와 학과 홈페이지 는 꼭 방문 하 시 길 바랍니다 . 저 는 홈페이지 에 나와 있 는 내용 을 몇 번 이나 읽 어 보 았 던 것 같 아요 . 특히 학부 전공 과 석사 전공 이 다르 다면 더더욱 이 부분 을 유심히 살펴보 아야 하 죠 . 학사 과정 에 는 어떤 교과목 이 있 고 , 석 / 박사 과정 에 는 어떤 교과목 들 이 있 는지 , 내 가 석사 과정 에 들어가 면 어떤 과목 들 을 공부 하 고 싶 은지 생각 하 면서 읽 어 보 세요 . 코스 웍 동안 몇 학점 을 수강 해야 하 는지 , 내 가 어떤 과목 을 수강 하 면 좋 을지 미리 간단 하 게 그림 을 그릴 수 있 거든요 . 보통 석사 코스 웍 은 2 년 이 지만 , 학과 마다 다를 수 있 으니 교과 과정 과 내규 에 대해서 도 살펴보 시 길 추천 합니다 . 2 . 교수 님 의 연구 분야 를 분석 하 자 . 또 보 아야 하 는 것 은 교수 소개 페이지 입니다 . 바로 \\' 지도 교수 \\' 를 선택 하 기 위해서 이 지요 . 대학원 에 대해 조금 이 라도 고려 해 보 신 분 이 라면 , 그리고 주위 에 대학원생 이 있 다면 \\' 지도 교수 \\' 에 대한 이야기 를 많이 들 어 보 셨 을 겁니다 . 대학원 생활 을 좌지우지 할 수 있 는 여러 요소 들 중 가장 강력 한 파워 를 가지 고 있 는 사람 , 가장 중요 한 사람 이 바로 \\' 지도 교수 님 \\' 입니다 . 이공 계열 같 은 경우 , 대학원 을 지원 하 기 전 에 지도 를 희망 하 는 교수 님 에게 메일 을 보내 거나 , 직접 찾아가 뵙 는 것 이 거의 필수 라고 하 더라고요 . 하지만 인문 / 사회 과학 의 경우 필수 인 곳 도 있 고 , 아닌 경우 도 있 습니다 . 저희 학과 같 은 이 컨 택 과정 이 필수 는 아니 었 어요 . 하지만 미리 교수 님 께 이메일 로 석사 과정 에 관심 이 있 고 , 이런 공부 를 하 고 싶 은데 , 이 학과 에서 어떤 공부 를 할 수 있 는지 여쭤 보 는 것 도 나쁘 지 는 않 겠 지요 ? ^^ 어찌 되 었 든 석사 과정 을 시작 하 면 학생 이 \\' 지도 교수 \\' 를 선택 하 기 때문 에 지원 하 는 학과 의 교수 님 들 이 어떤 연구 를 하 셨 는지 꼭 알 아 봐야 합니다 . ( \\' 지도 교수 \\' 를 학생 이 선택 하 는 것 인지 , 교수 님 께 선택 되 는 것 인지 . . 그 애매 한 경계 에 있 는 경우 도 있 겠 지만 요 ^^;) 지도 교수 님 은 잘 선택 해야 합니다 . 교수 님 에 따라서 앞 으로 여러분 들 이 대학원 에서 공부 하 고 , 연구 하 는 방향 이 잡히 게 되 거든요 . 만약 교수 님 의 연구 분야 와 자신 의 연구 방향 , 연구 주제 가 너무 다르 다면 많이 힘들 수 도 있 어요 . 그래서 지도 교수 님 을 선택 하 기 전 , 교수 님 의 연구 동향 에 대해서 도 많이 공부 를 해 두 시 면 훨씬 편합니다 . 지원 전 에 할 수 있 는 가장 쉬운 방법 은 학과 홈페이지 를 활용 하 는 것 입니다 . 각 학과 마다 교수 님 들 의 소개 페이지 에 는 교수 님 들 이 어떤 학교 를 졸업 하 셨 고 , 어떤 분야 에 대해 연구 를 하 셨 는지 자세 하 게 나와 있 어요 . 교수 님 이 어떤 논문 을 발표 하 셨 는지 보 시 면 각각 교수 님 들 의 관심 분야 , 연구 주제 를 좀 더 빠르 게 이해 할 수 가 있 겠 지요 ? 이런 내용 을 보 며 , 자신 이 공부 하 고 싶 은 분야 를 한 번 생각 해 볼 수 있 고 , 이 부분 이 결국 연구 계획서 에 들어가 게 될 겁니다 . 그럼 , 연구 계획서 에 는 어떤 내용 이 들어가 야 하 나요 ? 연구 계획서 는 대학원생 으로서 앞 으로 석사 / 박사 과정 을 통해 학문 을 연구 할 자세 가 되 어 있 는가 를 보여 주 는 것 입니다 . 당연히 학과 , 학문 분야 에 대한 관심 도 가 어느 정도 인지 나타나 야 겠 지요 . 앞서 서 조사 한 학과 의 특성 , 교수 님 들 의 연구 방향 들 을 이 연구 계획서 에 작성 하 시 는 것 입니다 . 학과 에 대해서 , 교수 님 들 의 연구 분야 에 대해 조사 하 다 보 면 , 학과 가 추구 하 는 학문 분야 에 대해 어느 정도 공부 를 하 시 게 되 고 , 더불 어 내 가 어떤 공부 / 연구 를 하 고 싶 은지 에 대한 방향 도 잡히 게 됩니다 . 연구 계획서 를 준비 하 면서 추후 연구 하 고 싶 은 분야 에 대해 공부 를 하 시 게 되 는 거 지요 : ) 앞 에서 항목 이 구분 된 연구 계획서 내용 을 보여 드렸 는데요 . 항목 이 없 다고 하 더라도 걱정 하 실 필요 가 없 습니다 ~. 연구 계획서 는 크 게 3 가지 의 질문 에 대한 답 이 들어가 면 되 니까요 : ) 1 ) 대학원 지원 이유 , 그리고 나 의 관심 분야 와 내 가 지원 하 는 학교 , 학과 가 추구 하 는 학문 분야 가 어떤 관련 이 있 는가 ? ( 서론 ) 이 부분 은 자기 소개서 의 지원 동기 와 도 비슷 하 지요 . 어떻 게 보 면 쉬워 보이 지만 어떻 게 보 면 또 어려울 수 있 는 부분 입니다 . 우리 나라 의 수많 은 대학 중 에서 왜 이 학교 를 , 그리고 왜 이 전공 을 선택 했 는지 에 대해 명확 하 게 적 을 수 있 어야 하 기 때문 입니다 . ( 취업 자기 소개서 에서 도 지원 동기 가 제일 어려웠 는데 . . 마찬가지 네요 ㅎㅎ ) 초반 에 이 부분 을 잘 작성 하 셔야 지만 뒤 의 내용 도 흐름 에 맞 게 작성 하 실 수 있 을 겁니다 . 그리고 면접 전형 에서 도 기본 적 으로 물 어 보 는 질문 이 지원 동기 이 기 때문 에 , 오랜 시간 고민 을 해 보 시 고 작성 하 시 길 바랍니다 . 2 ) 대학원 에서 나 는 구체 적 으로 어떤 연구 를 하 고 싶 은가 ? ( 본론 ) 이렇게 연구 하 고 싶 은 분야 를 정했 다면 , 앞 으로 의 코스 웍 기간 동안 어떤 연구 를 하 고 싶 은지 작성 하 시 면 됩니다 . 이 부분 을 초반 에 얼마나 심혈 을 기울여 작성 하 셨 는지 에 따라서 , 앞 으로 대학원 생활 의 나침반 이 될 수 가 있 습니다 . ( 물론 , 연구 계획서 와 석사 과정 중 연구 방향 이 달라질 수 도 있 습니다 . ) 기본 적 으로 일반 대학원 은 2 년 의 코스 웍 동안 석사 공부 를 하 게 되 는데요 . 이 시간 동안 어떤 공부 를 하 고 , 어떤 연구 를 하 고 싶 은지 그 방향 을 작성 하 시 면 됩니다 . 앞부분 에서 지원 동기 와 관심 분야 에 대해 잘 작성 하 셨 다면 , 이 부분 은 어렵 지 않 으실 거 예요 . 서론 의 내용 과 일관 성 있 게 적 어 주 시 면 됩니다 . 학과 와 연구 분야 의 특성 을 고려 하 셔서 작성 해 보 세요 . 3 ) 대학원 졸업 이후 의 계획 은 어떠 한가 ? ( 결론 ) 대학원 졸업 이후 의 계획 입니다 . 2 년 뒤 여러분 이 어떤 일 을 하 고 있 을지 , 어떤 모습 일지 앞 으로 의 비전 을 적 어 주 세요 . 물론 이때 적 은 그대로 이루어지 지 않 을 수 도 있 지만 , 내 가 석사 공부 를 하 는 이유 가 무엇 이 었 는지 곰곰이 생각 해 보 시 고 , 졸업 이후 의 계획 을 적 어 주 시 면 좋 겠 지요 . 다시 현업 으로 돌아가 전문 성 을 갖추 고 , 연구 한 부분 을 실제로 현장 에 적용 시켜 볼 수 도 있 겠 고요 . 이후 국내 혹은 국외 박사 과정 을 준비 하 실 수 도 있 겠 지요 ? 적어도 이 연구 계획서 를 쓰 다 보 면 앞 으로 대학원 에서 어떤 공부 를 할 것 인지 감 이 오 기 때문 에 , 계속 대학원 에 지원 을 해서 공부 를 하 는 게 맞 을지 , 그냥 필드 에서 커리어 를 쌓 을지 스스로 답 을 내릴 수 도 있 습니다 . 실제로 제 친구 중 한 명 은 제 가 대학원 공부 하 는 것 을 보 고 자기 도 대학원 공부 를 해 보 고 싶 다고 하 더라고요 . 그래서 제 가 그러 며 위 와 같 은 방법 으로 일단 연구 계획서 를 써 보 라고 했 는데 , 일 주일 정도 조사 하 고 , 분석 하 고 , 연구 계획서 를 작성 해 보 더니 자신 은 공부 로 전문 성 을 갖 는 것 보다 일 을 하 면서 전문 성 을 키우 는 것 이 더 맞 을 것 같 다고 생각 해서 . . 대학원 진학 을 포기 하 기 도 했 답니다 . 오히려 친구 는 회사 에서 인정받 는 직원 이 되 었 어요 ! 이렇게 연구 계획서 를 비롯 한 필요 한 서류 들 을 제출 하 셨 다면 , 중간 에 서류 전형 이 있 을 수 도 있 고 , 서류 전형 이 따로 없 다면 바로 면접 전형 이 진행 이 됩니다 . 전공 마다 면접 스타일 은 다 다르 기 때문 에 제 이야기 가 도움 이 될 수 도 , 전혀 도움 이 되 지 않 을 수 도 있 을 것 같 습니다 . 하지만 대부분 공통 적 으로 면접 전형 에서 물 어 보 는 내용 들 은 비슷비슷 하 지 않 을까 싶 습니다 . q . 자기 소개 q . 대학원 지원 이유 q . 해당 전공 을 선택 한 이 휴 q . 대학원 에서 어떤 연구 를 하 고 싶 은지 q . 그 분야 에 대해 얼마나 알 고 있 는지 q . 대학원 졸업 후 의 계획 은 어떠 한지 q . ( 직장인 이 라면 ) 회사 와 공부 를 병행 하 는 게 힘들 지 는 않 을지 q . 만약 지도 교수 가 회사 를 그만두 고 학업 에 몰두 하 면 좋 겠 다고 한다면 어떻게 할 것 인지 정말 기본 적 인 질문 들 인데요 . 적어도 이 정도 의 질문 에 대해서 는 어려움 없이 대답 하 실 수 있 도록 준비 해 가 시 면 좋 겠 지요 ? 결국 대학원 지원 준비 도 취업 준비 와 다르 지 않 다는 생각 이 듭니다 . 먼저 나 에 대해 분석 하 고 , 내 가 지원 하 고자 하 는 학교 와 전공 , 연구 분야 에 대해 분석 하 고 , 나 와 그 분야 가 얼마나 매칭 하 는지 , 내 가 대학원 에서 어떤 연구 를 하 고 싶 은지 큰 그림 을 그려 보 는 . . 이 일련 의 과정 들 을 한 번 해 보 신다면 대학원 진학 을 해야 할지 말 아야 할지 , 그 고민 에 대한 답 을 찾 으실 수 있 을 거 라고 생각 합니다 . 마지막 으로 , 회사 다니 는 분 들 중 , 이런 질문 을 하 시 는 분 들 이 많이 계세요 . \" 직장 과 학업 을 병행 하 고 싶 은데 , 회사 다니 면서 대학원 을 다닐 수 있 을까요 ? \" 사실 대답 은 학교 와 전공 에 따라 다르 다는 것 입니다 . 직장 인 분 들 중 회사 를 그만두 고 대학원 을 다니 고 싶 은 분 들 도 계시 겠 지만 반면 에 학비 나 경력 단절 등 을 걱정 해서 일 과 학업 을 병행 하 고자 하 는 분 들 도 많이 계시 겠 지요 ? 저 역시 도 그랬 으니까요 . 그래서 꼭 대학원 지원 하 시 기 전 에 , 저녁 에 도 수업 이 어느 정도 개설 이 되 는지 , 토요일 에 수업 이 개설 이 되 는지 , 하루 정도 연차 를 내 고 학교 를 다닐 수 있 는지 이런 현실 적 인 부분 을 꼭 고려 하 시 기 바랍니다 ! 일 과 학업 병행 이 가능 한지 여부 를 알아볼 수 있 는 것 은 최근 2 - 3 년 동안 지원 하 고자 하 는 학과 의 시간표 를 확인 해 보 는 것 입니다 . 어떤 학교 는 포털 사이트 에 로그인 을 해야 강의 시간표 를 볼 수 있 지만 , 또 어떤 학교 는 학교 홈페이지 에서 바로 강의 시간표 를 쉽 게 조회 할 수 있 습니다 . 정말 대학원 에서 공부 를 하 고 싶 다면 , 이렇게 많 은 정보 를 찾아보 는 노력 은 필요 하 다고 생각 합니다 . 저 역시 이렇게 시간표 를 분석 하 면서 , 우리 학교 에서 회사 다니 면서 공부 할 수 있 겠 구 나 라고 판단 을 했 으니까요 . ^^ 오늘 의 글 도 \" 국내 인문 / 사회 과학 일반 대학원 \" 을 준비 하 시 는 분 들 에게 조금 이나마 도움 이 되 기 를 바랍니다 . : )',\n",
       "       '안녕 하 세요 . universtiy of california , san diego 에서 political science 을 전공 해 멀티 캠퍼스 와 과학 기술 정보 통신부 가 주관 하 는 인공지능 자연어 처리 교육 과정 을 통해 파이썬 , 인공지능 자연어 처리 , 챗 봇 서비스 기획 을 처음 접하 게 된 이준형 입니다 . 교육 과정 을 마무리 하 면서 자연어 처리 프로젝트 에 관해 글 로 남기 고 싶 어 이 글 을 쓰 게 되 었 습니다 . 우선 , 멀티 캠퍼스 교육 과정 을 통해 각각 의 다른 전공 과 배경 을 가지 고 있 는 6 명 의 팀원 이 만나 자연어 처리 와 bert 를 활용 한 챗 봇 서비스 를 구현 이 라는 공통 된 관심사 를 바탕 으로 서울시 2030 청년 정책 챗 봇 서비스 프로젝트 를 기획 하 게 되 었 습니다 . 챗 봇 서비스 를 위해 다양 한 알고리즘 과 자연어 처리 기술 등 을 비전 공자 로서 공부 하 면서 많 은 어려움 이 있 었 지만 다양 한 컨 퍼 러스 ( etri , korquad 1 . 0 등 ) 를 참가 하 면서 지식 을 늘릴 수 있 었 습니다 . 그리고 마지막 과정 이 끝난 뒤 , 두 가지 좋 은 소식 을 얻 게 되 었 습니다 . 첫 번 째 는 저희 팀 에서 준비 했었 던 etri openapi 공모전 에서 장려상 수상 하 게 되 었 습니다 . 12 월 중 에 있 는 etri ai tech concert 나눔 이 라는 행사 에서 프로젝트 발표 연락 이 왔 고 , 팀원 모두 가 열심히 한 프로젝트 에 좋 은 결과 가 나와서 정말 기뻤 습니다 . 두 번 째 로 는 멀티 캠퍼스 최종 프로젝트 발표 에서 저희 팀 이 최우 수상 을 받 게 되 었 습니다 . 더 많 은 노력 을 쏟 은 팀 도 많이 있 었 는데 운 좋 게 기대 이상 의 평가 를 받 게 되 었 습니다 . 이상 저 의 대한 소개 와 프로젝트 의 취지 를 마치 고 , 어떻게 서울시 2030 청년 정책 봇 을 구현 했 는지 소개 해 드리 겠 습니다 . 1 . 프로젝트 개요 1 . 1 프로젝트 전체 개요 서울시 챗 봇 팀 이 개발 한 ‘ 청년 정책 봇 ’ 은 시나리오 기반 이 아닌 딥 러닝 기반 의 챗 봇 서비스 다 . etri 에서 개발 한 korbert 를 통해 언어 처리 모델 을 대신 하 고 , 형태소 분석 api 를 통해 질문 문장 에 대한 의도 를 분석 하 였 다 . 카카오 에서 배포 한 khaii 형태소 분석기 적용 을 통해 구문 분석 정확도 를 향상 을 확인 할 수 있 었 다 . 또한 , 위키 qa api 를 통해 일반 적 인 질 의 응답 을 위한 기능 을 추가 했 다 . 현재 상용 화 된 챗 봇 서비스 의 대부분 은 미리 구성 된 시나리오 ( flowchart ) 를 따라가 는 방식 을 활용 하 며 , 자연어 처리 기술 은 신뢰도 가 낮 아 사용 되 지 않 고 있 다 . 그 에 반해 , ‘ 청년 정책 봇 ’ 은 cdqa 파이프라인 을 접목 해 유사 도 높 은 문서 를 언어 처리 모델 에 적용 하 는 방식 으로 접근 해 신뢰도 를 높일 수 있 었 다 . 기존 빌더 를 통해 , 상용 화 된 서비스 대비 두 가지 장점 이 있 다 . 첫 번 째 장점 은 딥 러닝 모델 에 따른 발전 가능 성 으로 써 etri korbert 의 지속 적 인 개선 에 따라 청년 정책 봇 의 기계 독해 성능 도 같이 개선 된다는 것 이 다 . 두 번 째 장점 은 서비스 지속 가능 성 으로 써 cdqa 파이프라인 에 기반 해 주기 적 인 웹 크롤링 을 통해 데이터 추가 가 가능 하 기 때문 에 소프트웨어 유지 보수 에 필요 한 자원 을 최소 화 할 수 있 다는 것 이 다 . 청년 정책 챗 봇 을 통해 cdqa 파이프라인 과 etri bert 모델 을 활용 해 기존 의 데이터 인풋 제한 을 극복 하 고 기계 독해 에 대한 설루 션 을 제시 할 수 있 었 다 . 1 . 2 프로젝트 기획 배경 및 목표 멀티 캠퍼스 자연어 처리 교육 과정 을 통해 만나 게 된 6 명 이 bert 모델 을 활용 한 챗 봇 구현 이 라는 공통 된 관심사 를 바탕 으로 이번 프로젝트 에 참여 했 다 . 프로젝트 일정 과 유사 한 시기 에 한국 전자 통신 연구원 ( etri ) 에서 배포 한 자연어 처리 api 를 활용 한 사례 를 찾 는 공모전 이 있 어 해당 프로젝트 의 전반 적 인 구성 은 공모전 과 같 은 방향 으로 진행 했 다 . 프로젝트 기획 을 위한 사전 연구 단계 에서 etri 공공 인공지능 포털 을 접하 게 되 었 고 , 한국어 처리 가 가능 한 챗 봇 구현 에 있 어서 open api 는 중요 한 개발 가이드라인 으로 활용 할 수 있 었 다 . 해당 플랫폼 에서 제공 되 는 모델 과 학습 데이터 는 짧 은 개발 기간 에 적합 한 프로젝트 의 방향 성 을 설정 하 는 데 중요 한 기반 이 되 었 고 , 본 공모전 을 통해 ‘ 서울시 챗 봇 팀 ’ 은 자체 적 으로 개선 된 챗 봇 프레임워크 를 시민 생활 과 밀접 한 서울시 청년 정책 도메인 에 적용 및 구현 을 시도 할 수 있 었 다 . 많 은 사용 자 를 대상 으로 하 는 챗 봇 플랫 폼 개발 에 있 어서 etri open api 가 제공 하 는 높 은 정확도 의 모델 , 서버 신뢰도 , 확장 가능 성 에 기반 해 서비스 를 기획 부터 구현 까지 목표 를 달성 할 수 있 었 다 . 2 . 프로젝트 현황 2 . 1 챗 봇 시장 분석 챗 봇 은 사용 자 가 질문 하 면 기계 가 대답 하 는 질 의 응답 으로 구성 된 프로그램 이 다 . 대화 주제 에 는 일반 주제 ( general ) 와 특정 주제 ( domain ) 로 나누 어 질 수 있 고 , 응답 방식 은 검색 모델 ( retrieval - based ) 과 생 성 모델 ( generative ) 로 접근 할 수 있 다 . 모든 주제 에 답변 을 자동 으로 생성 해 대답 을 하 는 것 은 이상 적 이 지만 현실 적 으로 구현 이 어렵 다 . 따라서 특정 주제 에 대해 미리 구성 된 시나리오 기반 의 챗 봇 빌더 를 통해 상용 화 가 되 고 있 다 . 이러 한 문제 를 해결 하 고자 , 시나리오 기반 이 아닌 문서 탐색 과 구문 분석 을 통해 내용 을 실시간 으로 추출 하 는 방식 으로 질의 응답 을 구현 했 다 . 따라서 특정 주제 에 대하 여 문서 데이터 를 정의 했 고 , 이 에 기반 한 질 의 응답 이 가능 하 도록 했 다 . 그 결과 , cdqa 파이프라인 을 통해 서울시 청년 정책 에 관한 질 의 응답 시스템 을 구축 하 게 되 었 다 . 2 . 2 기존 챗 봇 빌더 와 의 차별 점 현재 상용 화 된 챗 봇 서비스 의 대부분 ( 구글 다이얼로그 플로우 , 카카오 i 오픈 빌더 ) 은 미리 구성 된 시나리오 ( flowchart ) 만 을 따라가 는 한계점 을 가지 고 있 다 . 반면 청년 정책 봇 은 etri api 를 기반 으로 한 bert 딥 러닝 활용 모델 을 적용 했 다 . 복합 추론 기반 의 자연어 처리 결과 를 바탕 으로 사용 문맥 에 따라 달라지 는 의미 를 파악 하 고 탁월 한 답변 을 제공 하 는 유연 한 대화 모델 을 생성 할 수 있 었 다 . 청년 정책 봇 구성 에 포함 된 cdqa 파이프라인 에 는 크 게 두 가지 장점 이 있 다 . - 확장 및 지속 가능 성 : 기계 독해 기능 면 에서 , 언어 처리 모델 에 대한 추가 적 인 학습 이 필요 하 지 않 아 자동 화 를 달성 하 기 쉽 다 . 청년 정책 의 경우 서울시 홈페이지 에 대한 주기 적 인 웹 크롤링 을 통해 수정 된 부분 만 데이터베이스 에 추가 하 면 되 기 에 소프트웨어 유지 보수 에 필요 한 자원 을 최소 화 할 수 있 다 . - 딥 러닝 모델 에 따른 발전 가능 성 : 기계 독해 태 스 크 를 위한 bert 언어 처리 모델 의 성능 은 지속 적 으로 발전 되 고 있 다 . bert 의 경량 화 모델 로 대체 할 경우 연산 에 필요 한 시간 을 단축 할 수 있 을 뿐 더러 etri api 를 통해 모델 사용 을 대신 하 기 때문 에 업데이트 에 따라 연산 능력 을 향상 할 수 있 다 . 2 . 2 사용 된 etri api 종류 및 활용 방안 챗 봇 아키텍처 를 구성 하 는 요소 에 는 언어 처리 모델 , 형태소 분석기 와 같이 독립 적 인 주요 성분 이 존재 한다 . 하지만 컴퓨팅 자원 이 제한 적 이 기 때문 에 자체 적 인 언어 처리 모델 구축 에 큰 어려움 이 있 었 다 . 그래서 한국어 자연어 처리 연구 분야 를 이끄 는 etri 엑소 브레인 연구 진 에서 공개 한 api 를 통해 해당 요소 들 을 대체 함 으로 이 를 해결 할 수 있 다고 판단 했 다 . 2019 년 10 월 기준 으로 한국어 자연어 처리 데이터 셋 ( korquad ) 을 활용 한 모델 정확 도 리더 보드 에서 etri exobrain 팀 의 korbert 모델 이 ( em 87 . 76 과 f 1 95 . 02 ) 평가 기준 으로 1 위 를 차지 하 였 다 . gpu 와 같 은 컴퓨팅 리소스 가 제한 되 어 있 기 때문 에 한국어 처리 에 독보 적 인 모델 을 api 를 통해 ‘ 서울시 챗 봇 팀 ’ 이 제작 한 챗 봇 아키텍처 에 적용 해 볼 소중 한 기회 가 되 었 다 . 또한 위키백과 qa api 를 통해 챗 봇 의 본 주제 에 벗어난 일반 대화 에 대한 답변 처리 를 하 는 방향 으로 활용 하 였 다 . etri api 활용 을 통해 시간 소요 를 대폭 감소 할 수 있 었 고 프로젝트 의 전반 적 인 구성 과 완성도 부분 에 초점 을 맞출 수 있 었 다 . etri 에서 제공 되 는 모델 은 향후 성능 개선 과 프로젝트 태 스 크 에 맞 게 튜닝 할 때 비교 의 기준치 로 도 활용 될 예정 이 다 . 서울시 정책 질의 응답 챗 봇 아키텍처 2 . 3 질 의 응답 챗 봇 아키텍처 및 동작 과정 기계 독해 태 스 크 에 최적 화 된 etri bert 언어 처리 모델 을 기반 으로 챗 봇 서비스 를 구현 한다 . 사용자 가 입력 한 문장 에 대해 기계 독해 단계 에서 진행 되 는 토큰 임 베 딩 ( token embedding ) 단계 에 는 한 번 의 인풋 에 512 개 이상 의 단어 가 들어간 문단 을 처리 하 지 못하 는 제한 이 있 다 . 이 에 따라 roberta ( doc to sentences ) 와 같 은 모델 등 이 존재 하 지만 , 사용 자 의 질문 시 에 질문 과 가장 유사 도 가 높 은 문서 와 문단 을 호출 하 는 cdqa ( closed - domain question answering ) 도메인 특정 파이프라인 을 접목 함 으로써 자료 입력 크기 의 제한 문제 를 해결 했 다 . 서울시 청년 정책 에 관련 된 사용자 의 질문 이 들어오 면 , etri 형태소 분석 api 를 활용 하 여 명사 와 동사 를 세부 적 으로 추출 하 게 되 고 , 구문 분석 결과 를 바탕 으로 구축 되 어 있 는 문서 데이터 로부터 핵심 단어 를 찾 는 tf / idf 알고리즘 을 활용 해 유사 도 가 가장 높 은 문서 와 문단 을 선택 하 게 된다 . 마지막 으로 , 질문 에 대한 답 일 가능 성 이 가장 큰 문단 을 메신저 채널 을 통해 출력 함 으로써 챗 봇 이 동작 하 는 구조 로 설계 되 었 다 . 도메인 특정 질의 응답 을 위한 파이프라인 구성 cdqa 는 크 게 문서 검색 을 진행 하 는 retriever 와 기계 독해 를 진행 하 는 reader 두 가지 부분 으로 나누 어 져 있 다 . 메신저 채널 을 통해 , 사용자 로부터 질문 이 들어왔 을 때 질문 을 etri 형태소 api 를 활용 해 명사 와 동사 를 추출 했 고 tf / idf 와 bm 25 알고리즘 중 하나 를 선택 해서 해당 질문 과 가장 유사 도 가 높 은 문서 를 선택 하 게 된다 . 단어 빈도 에 있 어서 bm 25 알고리즘 은 tf / idf 보다 특정 값 으로 수렴 하 고 , 불 용어 가 검색 점수 에 영향 을 덜 미친다는 장점 이 있 다 . 특히 , 문서 의 평균 길이 ( avgdl ) 를 계산 에 사용 함 으로써 문서 의 길이 가 검색 점수 에 영향 을 덜 미치 는 강점 이 있 어 bm 25 알고리즘 을 통해 문서 유사 도 측정 을 하 였 다 . 챗 봇 에 활용 된 메인 함수 cdqa 파이프라인 구성 단계 는 아래 와 같 다 . 코사인 유사 도 계산 을 통해 , 주어진 질문 과 가장 유사 한 문서 및 문장 을 선택 한다 . reader 부분 에서 선택 된 문서 와 질문 을 korbert api 에 전송 한다 . etri korbert api 를 활용 해 문서 에 대한 질문 을 추론 하 여 json 형식 으로 반환 한다 . 위 와 같 은 과정 을 통해 질문 에 가장 적합 한 답 을 추론 하 게 된다 . 결과 적 으로 , 메신저 채널 에서 는 사용 자 의 질문 에 가장 알맞 은 답변 을 출력 하 여 질 의 응답 태 스 크 를 수행 할 수 있 으며 , 시스템 상 에서 는 답변 이 추출 된 문장 에 대한 정보 와 답변 에 대한 정확도 를 포함 하 고 있 다 . 챗 봇 에 활용 된 메인 함수 동작 원리 및 구조 사용 자 의 질문 이 content 변수 로 함수 에 입력 ⤋ etri 형태소 분석기 로 구문 분석 된 질문 과 db 문서 중 유사 도 가 있 는지 , 함수 에 처음 들어온 케이스 인지 판단 ⤋ best _ idx _ scores 값 에 따라 9 미만 의 값 일 경우 해당 리스트 ( 카테고리 별 정책 목록 ) 를 반환 ⤋ best _ idx _ scores 값 이 9 이상 일 경우 유사 도 가 있 는 문서 를 선택 하 고 본 함수 로 재 입력 ⤋ 함수 에 두 번 째 들어온 경우 db 문서 에 대한 유사 도 계산 ( 0 에서 최대 20 ) 을 통해 가장 높 은 스코어 를 받 은 문장 이 질문 과 함께 etri korbert 모델 로 전달 ⤋ 유사 도 값 이 1 미 만 일 경우 etri wikiqa api 를 통해 답변 반환 3 . 프로젝트 개발 결과 3 . 1 결과물 데모 및 대화 흐름 예시 데모 버전 입력 예 시문 : “ 청년 금융 정책 알려줘 ” “ 면접 을 위한 정장 무료 로 대여 하 고 싶 어 ” “ 희망 두 배 청년 통장 지원 대상 알려줘 ” 4 . 기대 효과 4 . 1 상용 화 및 확장 가능 성 롯데 홈 쇼핑 챗 봇 서비스 프로젝트 에 참여 하 신 분과 의 대화 를 통해 현재 상용 화 된 챗 봇 서비스 의 대부분 은 이미 짜인 시나리오 ( flowchart ) 를 따라가 는 방식 을 활용 하 며 , 자연어 처리 기술 은 신뢰도 가 낮 아 사용 되 지 않 는다는 것 을 알 게 되 었 다 . 예 를 들 어 , 제품 카탈로그 를 보여 주 거나 영업시간 을 알려 주 는 챗 봇 은 간단 한 버튼 이나 빠른 답변 기능 , 또는 좋 은 선택지 를 통해 만드 는 것 이 더욱 편리 하 다 . 하 지만 lg 전자 챗 봇 프로젝트 매니저 는 지난 10 월 에 열린 kt 넥스 알 빅 데이터 콘퍼런스 발표 를 통해 장기 적 으로 는 ‘ 사람 같 은 ’ 챗 봇 이 각광 받 을 전망 이 라고 밝혔 다 . 챗 봇 의 전반 적 인 개발 방향 은 스크립트 에 기반 한 기술 에서 ( scripted chatbots ) , 의도 인식 ( intent recognizers ) 및 가상 도우미 ( virtual agents ) 를 거쳐 자연 스러운 대화 가 가능 한 방향 ( human - like advisor ) 으로 나아가 고 있 다 . 챗 봇 이 고객 서비스 및 응대 에 대한 역할 을 하 기 위해서 는 실제 대화 를 하 는 듯 한 자연어 처리 기술 이 필수 이 고 고도 화 된 챗 봇 개발 을 위해서 는 풍부 한 사용자 경험 , 객체 인식 , 개인 화 등 의 기술 이 추가 적 으로 필요 하 다 . 사용자 의 발화 의도 에 기반 해 특정 주제 에 대해 답변 의 줄 수 있 는 closed - domain qa 챗 봇 아키텍처 는 자연 스러운 대화 를 위한 챗 봇 설계 에 밑바탕 이 될 것 이 다 . 본 etri 공모전 을 위해 , 개발 한 청년 정책 챗 봇 은 closed - domain qa 파이프라인 과 etri bert 언어 처리 모델 을 활용 해 인풋 의 길 이 제한 을 극복 하 고 기계 독해 에 대한 설루 션 을 제시 할 수 있 었 다 . 챗 봇 서비스 사용 을 위해 , 별도 의 기기 나 어 플 을 설치 해야 하 는 번거 로움 이 없이 카카오톡 이나 텔레 그램 과 같 은 사용 자 친화 적 메신저 플랫 폼 을 사용 할 수 있 도록 구성 하 였을 뿐 만 아니 라 클라이언트 의 요청 에 따라 공공 정책 에 대한 질 의 응답 뿐 만 아니 라 민원 처리 에 관한 자료 를 제공 할 수 있 다 . 또한 , 자주 묻 는 질문 을 챗 봇 을 통해 가장 적절 한 질문 에 대한 답 을 출력 해 주 는 방식 으로 작동 한다면 사람 대응 이 필요 한 고객 상담 수요 를 줄이 는 효과 가 나타날 것 으로 예상 한다 . 기계 독해 에 특화 된 챗 봇 을 통해 사용 자 가 필요 로 하 는 알맞 은 정책 을 알려 주 고 정보 를 얻 을 수 있 는 웹 사이트 연계 해 정책 에 대한 시민 의 관심 에 부응 할 수 있 을 것 이 다 . 4 . 1 추가 연구 를 위한 참고 문헌 목록 이동헌 , 박 천음 , 이창기 , 박소윤 , 임 승 영 , 김명지 , 이주열 . ( 2019 ) . bert 를 이용 한 한국어 기계 독해 . 한국 정보 과 학회 학술 발표 논문집 , 557 - 559 . 임 승 영 , 김명지 , 이주열 . ( 2018 ) . korquad : 기계 독해 를 위한 한국어 질의 응답 데이터 셋 . 한국 정보 과 학회 학술 발표 논문집 , 539 - 541 . alberti , chris , kenton lee , and michael collins . \" a bert baseline for the natural questions . \" arxiv preprint arxiv : 1901 . 08634 ( 2019 ) . devlin , jacob , et al . \" bert : pre - training of deep bidirectional transformers for language understanding . \" arxiv preprint arxiv : 1810 . 04805 ( 2018 ) . yang , wei , et al . \" end - to - end open - domain question answering with bertserini . \" arxiv preprint arxiv : 1902 . 01718 ( 2019 ) . yang , yi , wen - tau yih , and christopher meek . \" wikiqa : a challenge dataset for open - domain question answering . \" proceedings of the 2015 conference on empirical methods in natural language processing . 2015 . 이 글 을 마치 며 , 서울 시정책 봇 프로젝트 에 궁금 한 점 은 ljh 0113 m @ gmail . com / 자세 한 코드 내용 은 [ URL ] 참고 바랍니다 .',\n",
       "       \"auto ( 자전 ) 더하기 fiction ( 허구 ) , 오토 픽션 ( autofiction ) 이란 무엇 인가 . 세르주 두 브 로브스키 의 에 의해 본격 적 으로 문학 계 에 던져진 이 신조어 는 문학 계 에 많 은 논쟁 들 을 불러일으켰 다 . 필립 르 죈 이 제시 한 자서전 의 규약 ( le pacte autobiographie ) 9 칸 중 ‘ 있 을 수 없 는 ' 케이스 , 즉 , case aveugle 로 비 어 있 는 그 칸 을 채우 는 장르 즉 , 소설 도 자서전 도 아니 며 , 소설 이 자 자서전 이 되 는 새로운 장르 가 탄생 하 게 된 것 이 다 . 진정 성 과 허구성 이 라는 공존 할 수 없 는 두 가지 요소 가 공존 하 는 이 문제 적 장르 는 장르 자체 의 정당 성 에 대한 논쟁 에서부터 , 해당 장르 적 당위 성 을 허구성 에 초점 을 맞추 어야 하 는가 , 자전 성 에 초점 을 맞추 어야 하 는가 에 대한 논쟁 들 과 같 은 수많 은 논쟁 들 을 낳 게 된다 . 진실 이 아니 면서 도 거짓 은 아닌 , 거짓 이 면서 도 진실 인 오토 픽션 의 애매 성 , 여기 에서 오토 픽션 의 현대 성 을 찾아볼 수 있 다 . 자전 성 과 허구 성 의 명확 한 관계 가 허물어지 는 이 애매 성 은 자아 의 타자 성 , 언어 의 불 환원성 , 재현 의 불 가능 성 을 담 고 있 다 . 언어 , 즉 , 시니피앙 은 항상 지시 하 는 대상 , 시니피에 에 정확 하 게 도달 하 지 못하 고 그 밑 으로 미끄러질 수 밖에 없 다 . 그렇 기 때문 에 직접 적 으로 , 실제로 경험 한 것 이 라 해도 그 장면 을 있 는 그대로 재현 하 는 것 은 불 가능 한 것 이 다 . 물론 기억 의 한계 와 도 같 은 현실 적 인 제약 에 의한 것 이 기 도 하 지만 언어 로 무엇 인가 를 재현 한다는 것 은 기본 적 으로 왜곡 이 뒤따를 수 밖에 없 고 또한 그 언어 를 사용 하 는 개인 에 의한 은폐 와 기억 의 부분 적 인 부재 가 불가피 하 게 동반 되 기 때문 에 언어 를 통해 무엇 인가 를 있 는 그대로 재현 해 낸다는 것 은 사실 상 불 가능 한 환상 에 지나 지 않 는다고 할 수 있 을 것 이 다 . 또한 자아 의 타자 성 , ‘ 내 가 나 를 모르 면 누가 나 를 아 는가 ? ’ 우리 는 나 라는 주체 와 자아 간 의 간극 을 부정 하 고 나와 관련 된 진리 와 경험 의 절대자 는 나 라고 생각 하 곤 한다 . 하지만 우리 는 우리 의 얼굴 을 직접 적 으로 볼 수 없 다는 것 을 알 고 있 다 . 우리 가 우리 의 얼굴 을 보 기 위해서 는 거울 이 라는 수단 을 통하 거나 , 혹은 타자 가 나 를 바라보 는 그 눈 을 통해서 우리 는 우리 의 얼굴 을 보 게 된다 . 다 들 한 번 씩 그런 경험 이 있 을 것 이 다 . 거울 로 보 는 나 의 얼굴 과 사진 을 통해 보 는 나 의 얼굴 이 이질 적 으로 느껴진 그런 경험 . 결국 우리 는 자아 를 매개체 를 통해 볼 수 없 기 때문 에 그 모습 에 는 반드시 왜곡 이 포함 될 수 밖에 없 다 . 결국 , 내 가 아 는 나 의 진실 이란 어느 정도 진실 지만 서도 동시 에 거짓 일 수 밖에 없 다는 것 이 다 . 나 에 대한 완벽 한 진실 의 글 이 란 것 은 있 을 수 없 고 , 모든 내 가 나 에 대해 쓰 는 글 은 필연 적 으로 허구 를 동반 한다 . 오토 픽션 에서 보여 주 는 거짓 을 동반 한 진실 은 무엇 을 의미 하 는가 ? 그것 은 ‘ 과거 의 유령 들 의 흔적 을 그대로 쫓아가 며 ’ 얻 은 진실 이 아닌 내 가 획득 해 나가 는 나 의 진실 이 다 . 세르주 두 브 로브스키 는 어머니 의 죽음 으로 인한 상실 을 치료 하 기 위해 오랫동안 정신 분석 상담 치료 를 받 았 는데 , 두 브 로브스키 의 치료사 는 두 브 로브스키 에게 침대 옆 에 노트 를 두 고 꿈 에서 기억나 는 내용 들 을 모두 받 아 적 는 방법 을 치료 방법 으로 제시 했 다 . 이렇게 자신 의 무 의식 을 쓰 고 관찰 하 는 과정 에서 두 브 로브스키 는 자신 의 상실 이 치유 되 는 것 을 느꼈 고 , 이 를 통해 자기 자신 에 대한 글쓰기 가 정신 분석 치료 과정 과 유사 하 다는 것 을 알 게 되 었 다 . 이 과정 에서 탄생 한 작품 이 최초 의 오토 픽션 이 다 . 즉 , ‘ 내 ’ 가 나 자신 의 치료 과정 에 있 어서 누구 보다 도 좋 은 분석가 가 될 수 있 다는 것 이 다 . 나 자신 에 대해 글 을 쓰 는 동안 우리 는 내 가 아 는 나 의 진실 을 획득 해 나가 게 되 고 이 진실 을 획득 해 나가 는 과정 이야말로 ‘ 나 ’ 의 아픔 , 상실 , 고통 을 치유 할 수 있 게 되 는 것 이 기에 오토 픽션 의 진실 은 나 를 치유 하 는 진실 이 다 . 그렇 다면 오토 픽션 은 어떻게 써야 하 는가 ? 오토 픽션 에 는 한 가지 지켜야 하 는 규약 이 존재 한다 . a = n = p 의 일치 , auteur ( 저자 ) , narrateur ( 서술자 ) , personne ( 주인공 ) 이 동일 한 정체 성 을 유지 해야 한다는 것 이 다 . 오토 픽션 은 두 브 로브스키 에서 콜로 나 , 르 카름 , 다리외세크 와 같 은 연구자 들 을 거치 며 새롭 게 정의 되 고 그 범위 를 확장 시켜 왔 지만 작가 의 실제 정체 성 을 고수 하 는 a = n = p 는 여전히 오토 픽션 을 규정 하 는 규약 으로 여겨 지 고 있 다 . 현존 하 는 오토 픽션 의 대표 적 인 작품 들 로 는 바르트 의 ( 롤랑 바르트 가 쓴 롤랑 바르트 ) , 사르트르 의 ( 말 ) , 콜레트 의 ( 여명 ) , 프루스트 의 ( 잃어버린 시간 을 찾 아서 ) 등 을 꼽 을 수 있 다 . 현재 오토 픽션 의 주 된 논의 는 물론 허구 성 의 문제 , 즉 , “ 자기 허구 화 ” ( la fabulation de soi ) 장치 를 사용 하 여 새로운 인격 과 실존 을 가공 하 는 것 을 과연 오토 픽션 으로 볼 수 있 는가 , 또 어디 까지 그 범위 를 한정 할 수 있 는가 하 는 문제 일 것 이 다 . 그러나 이 와 관련 된 논의 는 조금 뒤 로 밀 어 놓 기 로 하 고 , 나 는 오토 픽션 의 허구성 이 지니 는 자전 적 글쓰기 의 매력 에 대해서 논하 고 싶 다 . 오토 픽션 의 허구성 이 지니 는 가장 큰 매력 은 허구 라는 그늘 아래 저자 가 강박 적 인 자기 검열 과 변명 에서 조금 은 자유 로워질 수 있 다는 것 이 다 . 자기 자신 에 대한 진실 의 글 을 쓴다는 것 은 그 어떤 누구 에게 도 상당히 부담 스러운 일 이 아닐 수 없 을 것 이 다 . 그래서 대부분 자전 적 문학 작품 들 은 자기 방어 적 인 변명 과 거짓말 로 그 장르 의 가치 를 떨어트리 게 되 고 마 는 슬픈 결말 을 맺 게 되 는 듯 하 다 . 자전 적 문학 작품 의 대표작 인 루소 의 < 회고록 > 과 같 은 작품 을 예 로 생각 해 보 자 . 루소 는 진실 을 고백 한다는 그 무서운 사실 에 과하 게 매몰 된 듯 하 다 . 자신 의 과오 에 대한 구차 한 변명 과 자기 위로 로 점철 된 이 거짓말 의 기록 은 소설 보다 도 더 소설 에 가까웠 던 터 라 루소 가 진실 이 라 우기 고 있 는 ‘ 픽션 ’ 으로 평가 받 고 있 다 . 그러나 역설 적 으로 우리 는 오히려 소설 의 허구 에서 저자 의 자전 적 진실 을 더 자주 발견 하 기 도 한다 . 나 의 열 성 에 도 불구 하 고 나 는 1935 년 이전 에 는 나오 지 않 으리라 , 1930 년 경 이 되 면 그 들 은 안타까워 하 기 시작 하 고 서로 이렇게 중얼거릴 것 이 다 . “ 그 사람 은 시간 을 무척 잡아먹 는군 . 25 년 동안 이나 먹여살려 왔 는데 아무 일 도 안 해 놓 다니 ! 그 사람 의 책 도 읽 어 보 기 전 에 우리 가 먼저 죽 지나 않 을까 ? ” 그러면 나 는 1913 년 의 목소리 로 “ 여보세요 , 아직 좀 더 공부 할 시간 을 주 어야죠 . ” 라고 대답 하 리라 위 는 사르트르 의 소설 에 삽입 된 구절 이 다 . ( 한국 에 는 이 작품 이 자서전 으로 알려져 있 는데 갈리마르 에서 출판 당시 이 작품 은 roman ( 소설 ) autobigraphique ( 자전 적 ) 로 분류 되 었 기 때문 에 이 는 잘못 알려진 사실 이 다 . ) 사르트르 가 꾸며낸 이 허구 의 ' 말 들 ' 은 현실 의 시공간 속 에서 실제로 발화 되 었 을 사르트르 의 실제 의 ' 말 들 ' 보다 더 진실 에 가까이 서 있 는 듯 보인다 . 거짓 이 라는 가 면 뒤 에서 비로소 진실 을 말 할 수 있 게 되 는 것 . 이것 이 오토 픽션 의 허구 만 이 가질 수 있 는 매력 이 다 . 독자 와 저자 사이 에 거짓 이 라는 한 겹 의 얇 은 베일 을 두름 으로서 비로소 저자 는 거추장스러운 거짓 을 벗 어 던지 고 자신 의 헐벗 은 몸 을 온전히 보여 줄 수 있 게 되 는 것 이 다 . 두 번 째 독자 의 입장 에서 , 거짓 인지 진실 인지 경계 가 애매 한 이 오토 픽션 은 읽 는 사람 으로 하여금 이것 이 진실 인가 아닌가 를 추리 하 게 만드 는 색다른 재미 또한 제공 한다 . 글 을 읽 는 내내 독자 역시 진실 에서 도 허구 에서 도 자유 롭 다 . 진실 이 라 믿 고 싶 은 부분 만 을 진실 이 라 믿 으면 되 고 허구 라 믿 고 싶 은 부분 은 허구 라 믿 으면 된다 . 여기 에선 무엇 이 실제로 일어났 던 진실 인지 아닌지 를 구분 하 는 건 중요 한 문제 가 아니 다 . 그걸 판단 하 는 것 은 독자 의 몫 이 다 . 오토 픽션 은 저자 와 독자 가 살 아 숨 쉬 며 의미 를 만들 어 가 는 생동 적 인 장르 다 . 나 의 글 들 또한 어떤 것 은 진실 이 고 어떤 것 은 진실 이 아니 다 . 내 가 말 하 는 나 는 세상 에 존재 하 는 나 일 수 도 있 고 , 아닐 수 도 있 고 내 경험 이 라 우기 는 것 이 나 의 것 일 수 도 아니 면 다른 누군가의 것 일 수 도 있 다는 것 을 밝힌다 . 나 는 나 를 좀 더 객관화 하 고자 , 또 소설 이 주 는 재미 를 조금 더 살리 고 싶 어서 의문 의 서술자 를 사용 했 다 . 나 는 주인공 이 누군지 에 대한 작 은 힌트 들 을 여기저기 에 숨겨 두 었 는데 이 글 을 읽 을 누군가 가 이 를 찾 으면서 재미있 어 했 으면 좋 겠 다 . 또 말 하 는 서술자 는 내 친구 일 수 도 , 내 애인 일 수 도 , 전혀 모르 는 제 3 자 일 수 도 있 지만 저자 이 자 주인공 인 나 일수 도 있 다 . 나 역시 도 저 서술자 가 누군지 는 모른다 . 나 는 내 가 나름 제일 잘 안다고 생각 하 는 사람 이 겪 은 얘기 들 을 이 글 을 읽 을 누군가 와 나누 고 싶 을 뿐 , 나머지 는 글 을 읽 을 누군가 의 몫 이 다 .\",\n",
       "       '버팀목 전세 대출 - 무조건 받 아 놓 고 봐야 하 는 이유 04 화 버팀목 전세 대출 - 무조건 받 아 놓 고 봐야 하 는 이유 현재 글 국가 복지 대출 - 바보 아저씨 의 경제 이야기 ( 본 글 은 \" 바보 아저씨 경제 이야기 \" 저자 가 2 권 을 집필 하 면서 브런치 에 단독 으로 기고 하 는 글 입니다 . 무단 전재 및 글 아이디어 도용 을 금지 합니다 . ) 본 글 은 1 ) 버팀목 전세 대출 - 무조건 받 는 이유 는 ? 2 ) 취직 하 면 내 돈 한 푼 없이 전 세구 하 는 비법 ( 대 기업 , 공무원 , 공기업 직장 인 편 ) 3 ) 취직 하 면 내 돈 한 푼 없이 전 세구 하 는 비법 ( 중소기업 직장인 , 청년 창업자 편 ) 4 ) 전 세구 할 때 필독 - 전세 사기 안 당하 는 방법 5 ) 주택 청약 저축 - 집 없 어도 , 집 있 어도 무조건 드 는 이유 는 ? 6 ) 디딤돌 대출 - 무조건 받 으셔야 합 니 당 ! 6 편 으로 연재 되 는 글 입니다 . 버팀목 전세 대출 - 무조건 받 아 놓 고 봐야 하 는 이유 - 사회 초년생 및 직장 인 분 들 은 무조건 꼭 ! 읽 어 보 고 가 세요 . 지난 글 에서 디딤돌 대출 에 관해 다루 었 는데요 . 오늘 은 약속 한 데 로 요 . 버팀목 전세 대출 에 관해 다루 어 보 겠 습니다 . 사실 은행 대출 창구 에서 일 하 는 분 들 이 가장 싫 어 하 는 업무 가 디딤돌 , 버팀목 전세 기금 대출 입니다 . 왜냐면 하 러 오 시 는 손님 들 대부분 이 젊 고 초년생 이 많 고 그래서 설명 해야 할 부분 이 많 고 안내 해야 할 부분 이 많 고 이 에 따른 제반 행정 업무 가 많 은데 이 에 반해 대 출금액 은 상대 적 으로 소액 이 많 기 때문 입니다 . 은행원 입장 에서 기금 대출 을 바라보 지 않 고 고객 의 입장 에서 왜 버팀목 전세 대출 을 무조건 받 아야 하 는지 설명 드려 보 겠 습니다 . 집 을 살 때 디딤돌 대출 도 마찬가지 고 전세 를 구할 때 버팀목 대출 도 마찬가지 로 일단 금리 가 매우 저렴 합니다 . 국가 에서 복지 개념 으로 만들 어 놓 은 대출 이 기 때문 입니다 . 저렴 한 이유 는 대 출금액 의 90 % 는 국가 에서 ( 주택 금융 공사 ) 지급 보증 을 해 주 기 때문 입니다 . 즉 , 대출 받 은 사람 이 망해도 . 은행 은 대출 내준 금액 의 90 % 를 국가 에서 지급 보장 을 받 기 때문 입니다 . 버팀목 전세 대출 의 경우 는 소득 이 없 어도 대출 이 나옵니다 . 주택 금융 공사 에서 무소득 자 도 3 천만 원 까지 지급 보증 을 해 주 기 때문 입니다 . ( 대출 가능 금액 은 이론 상 33 , 333 , 333 원 입니다 . ) ( 버팀목 3 , 333 80 %, 청년 맞춤 형 전세 7 , 000 90 %, 카 뱅 청년 전세 7 , 000 90 %) 따라서 난 \" 백수 인데 \", \" 난 소득 이 없 는데 \", \" 난 학생 인데 \", \" 난 신림동 고시 생 인데 \" 이러 면서 어영부영 막연히 대출 이 안 되 는 줄 알 고 대출 을 못 받 는 사람 들 이 많 습니다 . 그런데 디딤돌 과 다르 게 버팀목 전세 대출 은 소득 이 없 어도 대출 이 나간다는 거 꼭 명심 하 셔야 합니다 . 그럼 상세 적 으로 알아보 기 위해 제 가 만든 버팀목 전세 대출 가능 금액 을 표 로 정리 해 드리 고 설명 을 시작 하 겠 습니다 . ( 2020 년 5 월 18 일 기준 ) 버팀목 전세 대출 연봉 수준 별 대출 한도 ( 2020 년 5 월 18 일 금리 인하 반영 ) 만약 내 가 만 25 세 이상 이 며 , 단독 세대주 자격 을 만들 어서 전세 대출 을 받 아 전입 신고 를 한다고 가정 하 는 경우 , 소득 이 없 어도 4 , 700 만 원 짜리 전세 를 들어가 면서 내 돈 1 , 400 만 원 만 들 고 3 , 300 만 원 대출 을 받 아 전세 를 들어갈 수 있 습니다 . 월 이자 는 57 , 750 원 수준 에 불과 하 죠 . 이거 엄청나 게 싼 이 자율 입니다 . 버팀목 전세 대출 은 상환 조건 이 일시 상환 입니다 . 무슨 뜻 이 냐면 전세살이 2 년 동안 대출 원금 을 갚 을 필요 가 없 다는 뜻 입니다 . 그냥 주구장창 2 년 동안 이자 6 만 원 만 내 고 살 면 된다는 뜻 이 죠 . 그리고 대출 연장 시기 가 되 면 계속 연장 해서 최대 10 년 까지 저렇게 이자 만 내 면서 살 수 있 다는 뜻 입니다 . 그럼 원금 은 언제 갚 냐구요 ? 네 원금 을 왜 갚 을까요 ? 전세금 은 은행 에서 그냥 내준 거 라고 생각 하 시 면 됩니다 . 이자 는 10 년 동안 갚 지 않 아도 되 는 이사 나올 때 집 주인 한테 받 아서 은행 에 줘 버리 면 그 만인 돈 이 라고 생각 하 시 면 됩니다 . 뭐 여유 가 되 시 면 중도 상환 수수료 가 없 으니 원금 을 꾸준히 상환 하 셔도 상관 은 없 습니다 . ( 단 2 년 마다 연장 시 원금 10 % 이상 상환 없이 그대로 연장 하 시 면 금리 가 아주 조금 씩 오릅니다 . ) 만약 연봉 2 , 200 만 원 을 받 고 계신 싱글 족 이 시 라면 본인 돈 3 , 600 만 원 을 들 고 버팀목 전세 대출 8 , 000 만 원 을 받 아서 1 . 2 억 짜리 아파트 나 오피스텔 거주 가 가능 합니다 . 들어가 는 월 이자 는 175 , 000 원 에 불과 합니다 . 전세 대출 모르 고 어줍잖 게 반 전세 구하 면 5000 / 40 정도 는 지불 해야 하 겠 죠 ? 그런데 버팀목 전세 대출 을 받 으면 월 주거비 용 이 1 / 3 수준 으로 줄어듭니다 . 그래서 자격 이 되 면 무조건 받 고 보 는 게 임자 인 대출 이 버팀목 전세 대출 입니다 . 만약 수도 권 에 거주 중 이 고 결혼 을 앞둔 신혼 부부 인데 남편 은 연봉 6 , 000 만 원 , 신부 는 연봉 4 , 500 만 원 이 라면 부부 합산 소득 이 초과 되 서 대출 을 받 을 수 없 다고 생각 하 겠 죠 ? 그런데 방법 은 있 습니다 . 일단 아 내분 을 혼인 신고 전 에 단독 세대 주로 만든 다음 2 . 70 % 금리 로 1 . 2 억 최대 대출 을 일단 받 은 다음 . 나중 에 혼인 신고 를 해서 같이 사 시 면 됩니다 . 편법 이 지만 이건 불법 도 아니 고 . 실제로 저렇게 전세 대출 받 아서 나중 에 혼인 신고 하 고 사 는 경우 도 참 많 습니다 . 대출 내 는 시점 에 만 소득 기준 , 세대주 기준 만 충족 하 면 대출 은 무조건 나갈 수 있 는 거 거든요 . 이런 방식 으로 수도 권 2 억 전세 를 구하 면서 1 . 2 억 대출 을 받 으면 월 이자 는 27 만 원 을 은행 에 내 시 면 됩니다 . 표 를 보 시 면 아 시 겠 지만 . 버팀목 전세 대출 은 연봉 2200 만 원 이상 만 되 어도 지방 최대 대출 한도 인 8 , 000 만 원 까지 대출 이 나옵니다 . 수도 권 최대 한도 인 1 . 2 억 원 을 받 으시 려면 연봉 3 , 000 만 원 이 조금 넘 으셔야 하 겠 죠 . 그런데 지방 연봉 2200 만 원 , 수도 권 연봉 3 , 000 만 원 은 사실상 왠만 한 중견 기업 이상 다니 시 는 분 들 이 라면 누구 나 해당 되 는 연봉 조건 입니다 . 따라서 운 이 좋 게 지금 이 블로그 에 들어오 셔서 이 글 을 보 신 분 들 이 라면 누구 나 해당 되 면 버팀목 전세 대출 은 무조건 받 으시 라고 말씀 드립니다 . 주변 에 회사 동료 나 친구 친척 들 중 에 자격 이 되 는 데 모르 고 고액 월세 살 이 를 하 고 계신 분 들 에게 도 알려 무조건 버팀목 전세 대출 을 받 으시 라고 권해 드립니다 . 연봉 수준 이 거의 한도 끝 에 걸리 고 대출 도 최대 인 1 . 2 억 을 받 아도 월 부담 이자 는 27 만 원 에 불과 합니다 . 수도 권 거주자 에 월세 시 라면 요새 500 / 35 원룸 매물 없 죠 . 1000 / 45 이상 1000 / 60 이런 매물 이 흔합니다 . 그것 도 10 평 원룸 수준 주거 로 말 이 죠 . 지금 이라도 늦 지 않 으셨으니 대출 최대 로 받 아 더 낮 은 이자 로 주거 환경 개선 하 시 길 바랍니다 . 버팀목 대출 은 빨리 알 고 자격 맞춰서 빨리 빼먹 어야 되 는 국가 가 만든 복지 성 대출 이 라는 거 잊 지 마세요 . 게티 이미지 뱅크 만약 집 주인 이 전세 대출 받 아서 입주 하 는 걸 싫 어 한다면 ? 일반 전세 대출 과 다르 게 버팀목 전세 대출 은 집 주인 에게 미리 사전 고지 할 필요 가 없 습니다 . 추후 통 지만 해줘도 되 는 부분 인데요 . 뭐 나중 에 오해 와 분쟁 을 피하 려면 처음 부터 공인 중개사 한테 매물 을 구할 때 전세금 의 얼마 까지 \" 버팀목 전세 대출 \" 을 받 아서 입주 할 꺼 다 . 그게 가능 한 매물 을 구해 달 라 . 고 하 시 면 됩니다 . 하지만 여태껏 은행 창구 에서 대출 을 보 면서 버팀목 전세 대출 낸다고 계약 취소 하 겠 다는 집 주인 은 본 적 이 없 습니다 . 계약 취소 하 면 계약금 2 배 집 주인 이 물어내 야 하 거든요 . ^^ 이런 거 권 한다고 은행 은 좋 을 게 사실 없 습니다 . 일 만 많 아 지 구요 . 그런데 알려야 할 껀 알려야 하 기 에 포스팅 을 합니다 . 아파트 , 오피스텔 , 다 가구 원룸 할 것 없이 . 85 제곱미터 ( 전용 26 평 ) 이 하 면 버팀목 전세 대출 을 가능 합니다 . 신림동 , 노량진 원룸 전세 도 버팀목 으로 가능 합니다 . 꼭 명심 하 세요 ! [ 버팀목 전세 대출 연봉 별 대출 한도 상 세표 ] 버팀목 전세 대출 연봉 별 대출 한도 상세 ( 연봉 3000 ~ 3500 만 원 ) 버팀목 전세 대출 연봉 별 대출 한도 상세 ( 연봉 4000 ~ 5000 만 원 ) [ 중소기업 전세 대출 1 억 , 버팀목 전세 대출 7000 만 원 + 신용 대출 3000 만 원 받 을 경우 월 이자 수준 ] 중소기업 전세 대출 1 억 , 버팀목 전세 대출 7000 만 원 + 신용 대출 3000 만 원 받 을 경우 월 이자 수준 ( 본 글 은 \" 바보 아저씨 경제 이야기 \" 저자 가 2 권 을 집필 하 면서 브런치 에 단독 으로 기고 하 는 글 입니다 . 무단 전재 및 글 아이디어 도용 을 금지 합니다 . ) [ 버팀목 전세 대출 , 중소기업 전세 대출 진행 방법 - 문의 를 많이 주 셔서 대출 진행 방법 알려 드립니다 . ] 1 ) 전 세집 대략 적 인 주소 , 평수 , 전세금 규모 를 먼저 알아봅니다 . 2 ) 마음 에 들 면 그 집 바로 계약 을 바로 하 지 마세요 . 3 ) 먼저 은행 에 가 서 전세 대출 한도 를 알아봅니다 . 처음 은행 갈 때 필요 지참 서류 - 재직 증명서 - 근로 소득 원천 징수 영수증 ( 없 으면 급여 명세서 + 급여 통장 ) 중소기업 취업 청년 이 면 - 소속 기업 의 사업자 등록증 ( 사본 ) - 고용 보험 피보험 자격 이력 내 역서 ( 피보험자 용 ) - 소속 기업 이 발급 한 국세청 기준 주 업종 코드 확인 자료 ( 홈 택스 출력 화면 등 ) 청년 창업자 이 면 - 중소기업 진흥 공단 , 신용보증기금 또는 기술보증기금 에서 청년 창업 관련 보증 또는 대출 을 지원 받 은 내역 서 이렇게 구비 해서 은행원 한테 전세금 100 % 다 되 는지 , 70 % 되 는지 얼마 까지 되 는 지 알아봅니다 . 100 % 다 나오 거나 , 전세 대출 + 내 돈 맞 는다고 생각 되 면 은행원 한테 대출 서류 알려 달 라고 하 세요 4 ) 그 이후 에 전 세집 을 계약 합니다 . 5 ) 계약서 , 계약금 이 체영 수증 , 대출 서류 구비 해서 은행 에 다시 가 서 대출 신청서 를 씁니다 . 6 ) 그 이후 에 는 은행원 이 날짜 맞춰서 전화 주 고 , 잔금 날 전세금 입금 해 줍니다 . 7 ) 은행 에서 이사 후 전입 한 거 , 실제 거주 하 는 거 방문 조사 나옵니다 . 전세 대출 하 러 은행 와리 가리 2 ~ 3 번 해야 되 는 게 빡 치 는 거 요 . 그거 말 많 아서 2019 년 9 월 ~ 10 월 부터 는 모바일 / 인터넷 으로 가 심사 조회 다 하 고 은행 딱 1 번 가 서 서류 쓰 고 디딤돌 / 전세 대출 나오 게 변경 중 입니다 . [ URL ] 기금 e 든 든 홈페이지 : 2019 년 10 월 부터 인터넷 으로 전세 대출 - 사전 접수 가능 합니다 . [ 주택 도시 기금 2020 년 변동 사항 ] 1 ) 서울시 신혼 부부 전세 연봉 8000 만 원 -> 9700 만 원 상향 2 ) 방제 시설 없 는 고시원 거주자 -> 5000 만 원 전세금 100 % 지원 3 ) 신혼 부부 전세 대출 한도 - 수도 권 2 . 0 억 -> 2 . 2 억 상향 - 지방 1 . 6 억 -> 1 . 8 억 상향 - 전세 대출 기간 10 년 -> 1 자녀 당 2 년 씩 늘 어서 -> 최장 20 년 까지 유지 가능 4 ) 신혼 부부 디딤돌 대출 한도 - 2 . 4 억 -> 2 . 6 억 상향 본 글 은 1 ) 버팀목 전세 대출 - 무조건 받 는 이유 는 ? 2 ) 취직 하 면 내 돈 한 푼 없이 전 세구 하 는 비법 ( 대 기업 , 공무원 , 공기업 직장 인 편 ) 3 ) 취직 하 면 내 돈 한 푼 없이 전 세구 하 는 비법 ( 중소기업 직장인 , 청년 창업자 편 ) 4 ) 전 세구 할 때 필독 - 전세 사기 안 당하 는 방법 5 ) 주택 청약 저축 - 집 없 어도 , 집 있 어도 무조건 드 는 이유 는 ? 6 ) 디딤돌 대출 - 무조건 받 으셔야 합 니 당 ! 6 편 으로 연재 되 는 글 입니다 . 2020 년 중소기업 / 버팀목 / 신혼 부부 / 전세 대출 연봉 별 최대 한도 ( 꼭 같이 읽 어 보 세유 . ..) [ 추가 글 ] 버팀목 전세 대출 - 퇴사 하 면 ? 이직 하 면 ? 신용 등급 ? 대 출한 도 ? 첫 월급 ? 세대주 ? 언제 신청 ? 연봉 초과 하 면 ? 등등 완벽 ! a / s 해 드립니다 . 버팀목 전세 대출 - 무소득 자 안 해 주 는 은행원 한테 일침 놓 은 글 바보 아저씨 의 경제 이야기 시리즈 ( 일반 인 자비 출판 -> 6 위 경제 베스트셀러 ) 전세 대출 1 대 교주 의 교지 , ,, ( 敎旨 : \" 월세 노예 해방 을 선언 하 노라 \") [ URL ] [ 바보 아저씨 의 경제 이야기 저자 주요 faq 공유 ] 중소기업 전세 대출 연봉 35 , 034 , 500 원 입니다 . 될까요 ? 은행원 은 소득 어떻게 판단 해요 ? [ URL ] 버팀목 신혼 부부 전세 대출 한도 차이 , 신한은행 1 . 1 억 , 기업 은행 1 . 6 억 왜 이렇게 차이 가 나 는 거 죠 ? 연봉 4900 만 원 신혼 부부 입니다 [ URL ] 전세 대출 원룸 다 가구 , 왜 은행 에서 잘 안 해 주 나요 ? 되 는 건가요 ? 안 되 는 건가요 ? ( 실제로 되 는데 , , , 은행원 재량 거절 입니다 . ) [ URL ] 중소기업 청년 전세 자금 대출 은 조건 만 맞 으면 다 되 나요 ? [ URL ] 중소기업 전세 대출 , 주거 용 오피스텔 전세 1 억 안전 한가요 ? [ URL ] 중소기업 전세 대출 연봉 , 작년 2800 , 올해 3600 , 연말 정산 안 했 는데 대출 가능 할까요 ? [ URL ] 전세 자금 대출 , 연봉 3000 만 원 + 신용 대출 8000 만 원 가능 할까요 ? [ URL ] 신혼 부부 전세 대출 , 남편 1500 + 아내 3000 + 대출 1 . 8 억 있 어요 가능 한가요 ? [ URL ] 무직자 전세 대출 , 4 대 보험 없 는 직장 인데 전세 대출 가능 한가요 ? [ URL ] 전세 대출 무소득 자 다 빌려 주 나요 ? 누가 무소득 자 를 해 주 나요 ? 말 이 안 됩니다 . [ URL ] 중소기업 전세 대출 , 1 억 법인 전세 인데 가능 할까요 ? [ URL ] 신혼 부부 전세 대출 vs 디딤돌 대출 , 충 주사 는 30 대 공무원 이 에요 . 가능 할까요 ? [ URL ] 중소기업 전세 대출 , 회사 지역 말 고 다른 지역 에서 대출 가능 한가요 ? [ URL ] 보금자리 론 , 심사 기간 이 얼마나 걸려요 ? 계약금 날리 는 거 아닌가요 ? [ URL ] 월세 1 달 후 전세 계약 이 가능 할까요 ? 중소기업 전세 대출 인천 송도 입니다 . [ URL ] 신혼 부부 생애 첫 주택 마련 대출 , 연체 기록 해제 6 등급 인데 받 을 수 있 나요 ? [ URL ] 전세 대출 + 신용 대출 , 연봉 2400 만 원 직장인 이 에요 . 1 억 가능 할까요 ? [ URL ] 정부 전세 자금 지원 ? 나오 나요 ? 지인 이 지원 대상 이 아니 래요 . [ URL ] 청년 전세 대출 전월세 지원 어떤 게 있 나요 ? 연봉 3000 + 대출 3000 + 신용 등급 7 등급 입니다 . [ URL ] 중소기업 청년 전세 대출 , 연봉 2800 , 대출 470 , 등급 6 ~ 7 , 전세 1 . 1 억 가능 할까요 ? [ URL ] 전세 자금 대출 , 와이프 몰래 숨겨둔 대출 1080 만 원 있 어요 . 가능 할까요 ? 연봉 5000 , 대출 5000 [ URL ] 중소기업 전세 대출 이직 , 이 직 후 연봉 3700 입니다 . 이 직 전 급여 인정 가능 한가요 ? [ URL ] 전세 자금 대출 , 하나 은행 , 연봉 6000 , 부채 6500 , 미혼 입니다 . 한도 가 얼마 까지 가능 할까요 ? [ URL ] 전 세대 출문 의 , 24 살 , 보증금 700 / 월세 84 살 아요 . 대출 2800 있 는데 전세 대출 가능 할까요 ? [ URL ] 부모 님 집 전세 대출 가능 할까요 ? 중소기업 청년 전세 대출 , 25 살 , 부모 님 주택 2 층 에 전세 들어가 려 합니다 . [ URL ] 중소기업 취업 청년 전월세 보증금 대출 , 개인 사업 회사 , 30 살 , 법인 번호 가 없 어요 . 가능 한가요 ? [ URL ] lh 주택공사 전 세대 출도 깡통 전세 사 기 당할 수 있 나요 ? [ URL ] 버팀목 전세 대출 , 매매 가 1 . 70 억 / 선순위 1 . 2 억 / 전세 7500 만 원 안전 한가요 ? [ URL ] 건물 근저당 , 건물 13 억 , 융자 1 . 8 억 , 선순위 7 억 , 전세 1 . 7 억 들어가 도 안 전할까요 ? [ URL ] 건물 25 억 , 근저당 11 억 , 보증금 8 . 5 억 , 원룸 전세 9500 만 원 안전 할까요 ? [ URL ] 중소기업 전세 대출 , 건물 43 억 / 34 세대 / 채권 19 억 / 보증금 19 억 안전 한가요 ? [ URL ] 전 세집 들어가 려고 하 는데 융자 가 있 어요 . 전세 2 . 3 억 / 융자 3 억 안 전할까요 ? [ URL ] 신혼집 전세 대출 , 매매 가 전세 가 차이 가 없 습니다 . 안 전할까요 ? [ URL ] 중소기업 전세 대출 직후 , 집 주인 집 매매 하 면 ? 14 일 전세 대출 , 15 일 집 매도 합니다 . 전세금 안전 한가요 ? [ URL ] 중소기업 청년 전세 대출 , 전세 1 억 인데 , 8000 / 20 반 전세 계약 도 가능 할까요 ? [ URL ] 법인 전세 임대차 계약 , 법인 보증 보험 , 법인 전세 특약 [ URL ] 회사 보유 분 미등기 전세 계약 질문 합니다 . [ URL ] 한 달 생활비 팩 폭 자취 한 달 생활비 팩 트 폭격 , 숨 만 쉬 어도 70 ~ 80 만 원 [ URL ] 한국 빈부 격차 의 원인 빈부 격차 의 원인 , 대한민국 헬 조선 의 현실 [ URL ] 바보 아저씨 의 경제 이야기 “ 앞 만 보 며 바보 처럼 정말 열심히 인생 을 살 았 는데 , , , 돌이켜 보 니 정말 딱 , 바보 서민 이 되 어 있 더라 . ..\" 부디 다른 분 들 은 저 보다 , 지금 보다 더 나 은 , 삶 을 위한 지혜 를 찾 으시 길 간절히 바랍니다 . ” ( 바보 아저씨 의 헬 조선 현실 생 존기 , 현실 생존 지침서 - babo uncle green book ver 1 . 0 ) [ 바보 아저씨 온라인 기고 인기 글 더 보 기 ] 2019 년 현실 경제 키워드 6 개 , 바보 아저씨 의 현실 경제 이야기 중소기업 청년 전세 대출 - 1 억 전세 , 월 이 자 10 만 원 , 꿈 같 은 국가 복지 대출 부부 연봉 2000 만 원 , 2 억 아파트 대출 이 가능 하 다 ? ( ltv dti dsr 계산법 ) ( 신혼 부부 전세 , 신혼 부부 내 집 마련 다음 경제 분야 최고 글 입니다 . - 5 대 은행 시중 은 행원 의 글 ) 취직 하 고 내 돈 한 푼 없이 1 억 전세 구하 는 방법 2020 년 중소기업 / 버팀목 / 신혼 부부 / 전세 대출 연봉 별 최대 한도 ( 일반 회사 와 은행 을 모두 경험 한 , 저자 만 이 가진 독특 한 시선 으로 풀어내 는 , 너무나 공감 되 는 생활 경제 이야기 , 자 영업자 - 사회 초년생 - 직장인 - 결혼 증여 - 노후 부동산 - 경제 관념 등 사회 계층 을 총 망라 만 그동안 알 지 못했 던 생활 경제 비법 알차 게 담겨 있 는 마법 같 은 책 , 바보 아저씨 의 바보 경제학 , 바보 아저씨 의 경제 이야기 ! ) 온라인 ( 다음 , 네이버 ) 기 고 10 개월 만 에 구독자 20 , 000 명 , 조 회수 500 만 을 돌파 한 생활 경제 의 정석 ! 경제 칼럼니스트 바보 아저씨 의 경제 이야기 ( 누구 나 살 면서 꼭 ! 겪 게 되 는 누구 나 공감 되 는 생활 경제 이야기 가 1 권 , 2 권 총 600 페이지 분량 으로 방대 하 게 집대 성 되 어 있 다 . ) 바보 아저씨 의 경제 이야기 ( 일반 인 자비 출판 -> 6 위 경제 베스트셀러 ) 온라인 기고 10 개월 만 에 구독자 20 , 000 명 , 조 회수 500 만 을 돌파 한 생활 경제 , 바보 아저씨 의 경제 이야기 경제 / 경영 베스트셀러 순위 ( 2019 년 2 월 기준 ) 바보 아저씨 의 경제 이야기 비하인드 [ URL ]',\n",
       "       '버팀목 전세 대출 - 무소득 자 안 해 주 는 은행 그러 지 마세요 . 청년 맞춤 형전 월세 대출 , 중소기업 청년 전세 대출 - 퇴사 하 면 ? 이직 하 면 ? 신용 등급 ? 대 출한 도 ? 첫 월급 ? 세대주 ? 언제 신청 ? 연봉 초과 하 면 ? 등등 a / s 해 드립니다 . ( 본 글 은 \" 바보 아저씨 경제 이야기 \" 책 내용 \" 버팀목 전세 대출 무조건 \", \" 취직 하 면 내 돈 한 푼 없이 1 억 전세 구하 는 방법 \" 글 내용 을 바탕 으로 작성 된 글 입니다 . ) 중소기업 전세 대출 ( 1 억 월 이 자 10 만 원 ) - 중소기업 , 중견 기업 버팀목 전세 대출 ( 1 억 월 이 자 20 만 원 ) - 공무원 , 대 기업 , 전문직 , 학생 , 무소득 자 안녕 하 세요 . 바보 아저씨 입니다 . 지난 번 포스팅 했 던 위 의 중소기업 전세 대출 , 버팀목 전세 대출 관련 해서 문의 가 너무 많 아서 감당 이 안 되 고 있 어요 . 그래서 이렇게 a / s 글 을 올리 게 되 었 습니다 . 아래 내용 은 중소기업 전세 / 버팀목 전세 / 신혼 부부 전세 / 일반 전세 대출 관련 , 주요 부가 적 인 내용 정리 글 입니다 . 실제 대출 을 진행 하 시 다가 궁금 하 고 걸리 는 부분 많 은 부분 해소 되 시 리라 생각 됩니다 . 참고 하 세용 ! 중소기업 전세 대출 , 버팀목 전세 대출 . 신혼 부부 전세 대출 , 일반 전세 대출 실행 - 세부 업무 총 정리 편 lh 임대 아파트 , 행복 주택 , 일반 아파트 , 오피스텔 , 원룸 , 투 룸 , 쓰리 룸 , 다 세대 , 주택 , 빌 라 다 똑같 습니다 . 당첨 또는 집 을 자유 롭 게 고르 세요 . 그 다음 아래 순서 대로 전세 대출 을 고르 시 면 됩니다 . [ 주택 도시 기금 2020 년 변동 사항 ] 1 ) 서울시 신혼 부부 전세 연봉 8000 만 원 -> 9700 만 원 상향 2 ) 방제 시설 없 는 고시원 거주자 -> 5000 만 원 전세금 100 % 지원 3 ) 신혼 부부 전세 대출 한도 - 수도 권 2 . 0 억 -> 2 . 2 억 상향 - 지방 1 . 6 억 -> 1 . 8 억 상향 - 전세 대출 기간 10 년 -> 1 자녀 당 2 년 씩 늘 어서 -> 최장 20 년 까지 유지 가능 4 ) 신혼 부부 디딤돌 대출 한도 - 2 . 4 억 -> 2 . 6 억 상향 [ 전세 대출 고르 는 순서 ] 1 ) 연봉 3500 만 원 - 중소기업 청년 전세 대출 ( 80 %~ 100 %)( 1 억 / 1 . 2 % / 월 이 자 10 만 원 ) ( 맞벌이 5000 만 원 ) 2 ) 연봉 5000 만 원 - 버팀목 전세 대출 ( 70 %) ( 1 억 이상 / 2 . 3 %~ 2 . 9 %) 2 - 1 ) 일반 버팀목 전세 대출 : 만 25 세 이상 전세금 1 . 2 억 까지 가능 2 - 2 ) 청년 버팀목 전세 대출 ( 만 19 세 ~ 25 세 미만 ) -- 단독 세대주 : 전세금 5000 만 원 중 3500 만 원 최대 대출 가능 ( 1 . 2 %~ 1 . 8 %) -- 일반 세대주 : 전세금 7000 만 원 중 5000 만 원 최대 대출 가능 ( 1 . 8 %~ 2 . 4 %) 2 - 3 ) 청년 버팀목 전세 대출 ( 만 25 세 ~ 34 세 이하 ) -- 단독 / 일반 세대주 : 전세금 7000 만 원 중 5000 만 원 최대 대출 가능 ( 1 . 8 %~ 2 . 4 %) 3 ) 연봉 6000 만 원 - 신혼 부부 전세 대출 ( 80 %) ( 2 억 이상 / 2 . 00 %) 4 ) 연봉 7000 만 원 - 청년 전월세 대출 ( 90 %) ( 7000 만 원 / 2 . 80 %) 5 ) 연봉 9700 만 원 - 지자체 신혼 부부 전세 대출 지원 알아보 기 ( 예 , 서울시 연봉 9700 만 원 이하 2 억 대 출 가능 ) 6 ) 연봉 높 은 경우 - 일반 은행 전세 대출 ( 70 ~ 80 %) ( 2 억 이상 / 3 ~ 4 ~ 5 % 금리 ) ( 위 에서 1 ~ 2 ~ 3 ~ 4 번 대출 : 우리 은행 , 국민은행 , 기업 은행 , 농협 은행 , 신한은행 5 개 은행 에서 취급 하 고 금리 다 똑같 습니다 . / 5 번 서울시 전세 대출 : 국민 / 신한 / 하나 ) 위 에서 6 번 대출 : 소득 이 초과 되 거나 유 주택 자 인 경우 은행 가 서 문의 하 시 면 됩니다 . 무소득 : 2 / 4 번 ( 버팀목 3 , 333 , 청년 맞춤 형 전세 7 , 000 , 카 뱅 청년 전세 7 , 000 ) 취업 : 1 / 2 / 4 번 결혼 : 1 / 3 / 5 번 미혼 : 1 번 해 보 고 안 되 면 -> 2 번 / 4 번 / 6 번 중 하나 쓰 세염 신혼 부부 : 1 번 해 보 고 안 되 면 -> 3 번 / 5 번 / 6 번 중 하나 쓰 세염 [ 전세 대출 한도 승인 전 계약 부터 할 경우 ] 집 놓칠까 봐 정 급하 면 \" 전세 대출 불가 시 계약금 반환 \" 특약 거시 구요 . 그런데 . ... - 집 융자 많 아서 전세 대출 거절 도 있 지만 - 본인 신용 등급 문제 로 거절 나 는 경우 도 있 어요 . <- 계약금 잘못 하 면 날 립니 다 . 조심 하 세요 . [ 전세 대출 받 는 초 간단 순서 ] 1 ) 전 세집 구경 만 ( 계약 하 지 마세요 ) 2 ) 은행 가 서 전세 대출 한도 + 내 돈 되 는지 확인 ( 소득 서류 지참 ) 3 ) 그 이후 에 계약 하 고 계약금 이체 하 고 은행 다시 가 서 대출 신청서 쓰 는 거 에 용 4 ) 잔금 날 이상 없이 전세금 나옵니다 . ( 계약 부터 하 지 말 고 은행 가 서 한도 부터 확인 하 시 라는 뜻 입니다 . ) 전세 대출 하 러 은행 와리 가리 2 ~ 3 번 해야 되 는 게 빡 치 는 거 요 . 그거 말 많 아서 2019 년 9 월 ~ 10 월 부터 는 모바일 / 인터넷 으로 가 심사 조회 다 하 고 은행 딱 1 번 가 서 서류 쓰 고 디딤돌 / 전세 대출 나오 게 변경 중 입니다 . [ URL ] 기금 e 든 든 홈페이지 - 인터넷 으로 전세 대출 - 사전 접수 가능 합니다 . [ 전세 대출 소득 인정 서류 ] 국가 에 신고 한 소득 이 있 어야 합니다 . - 직장인 : 원천 징수 영수증 ( 또는 급여 명세서 + 급여 통장 ) - 사업자 : 소득 금액 증명 원 국가 에 신고 한 실제 발생 한 소득 이 있 어야 해요 . ... ( 혹시 모르 니까 은행 가 서 확인 해 보 세요 . 은행 재량 있 습니다 . ) - 연말 정산 결과 안 나왔 다면 최 근년 도 = 2018 년 꺼 떼 어 가 시 면 됩니다 . - 연말 정산 결과 나오 면 -> 2019 년 꺼 가져가 야 합니다 . - 재직 이 짧 으면 평균 세전 월급 x 12 개월 - 첫 월급 만 있 으면 첫 세전 월급 x 12 개월 [ 전세 대출 소득 인정 문제 ] 은행 의 기본 은 - 4 대 보험 - 첫 월급 x 12 개월 이렇게 합니다 . 만약 4 대 보험 이 없 는 경우 ? - 재직 증명서 + 급여 통장 + 급여 명세서 들 고 은행 가 서 확인 해 봐야 합니다 . ( 은행 에서 해 줄 수 도 있 습니다 . 은행 재량 입니다 . ) [ 중소기업 전세 대출 - 내 가 다니 는 회사 가 해당 되 나요 ? 병원 인데 해당 될까요 ? 유치원 인데 해당 될까요 ? ] 내 가 다니 는 회사 가 해당 되 는지 안 되 는지 는 그냥 아래 법인 번호 넣 어 보 시 면 됩니다 . 주택 도시 기금 ( 중소기업 청년 전세 대출 ) - 법인 번호 확인 페이지 \\ufeff ( 주택 도시 기금 사이트 안 열리 면 / 막혀 있 으면 / 은행 에 직접 문의 해 보 셔야 함 ) 위 에서 소속 기업 규모 확인 -> 법인 번호 넣 어 보 시 면 중소기업 해당 되 는지 나와요 . 해당 된다 -> \" 중소기업 전세 대출 \" 낼름 받 으시 면 됩니다 . 해당 없 다 -> \" 버팀목 전세 대출 \" 받 으시 면 됩니다 . ( 2 개 다 국가 복지 전세금 입니다 . ) [ 중소기업 전세 대출 연봉 3500 만 원 간당간당 , , , 3500 만 원 약간 넘 어요 어쩌 죠 ? ] 애매 하 면 은행 가 서 아래 행동 강령 따르 세요 1 ) \" 중소기업 전세 대출 받 으러 왔 어요 . \" 2 ) \" 소득 서류 그냥 은행원 한테 줍니다 . \" 3 ) \" 연봉 3500 만 원 넘 는데 운운 \" <- 이 말 은행 가 서 입 도 뻥끗 하 지 마세요 . - 은행원 이 된다 -> 중소기업 전세 대출 낼름 신청 해서 사용 하 면 됩니다 . - 은행원 이 안 된다 -> 버팀목 전세 대출 그냥 받 으시 면 됩니다 . ( 두 개 다 국가 복지 전세 대출 입니다요 . ) 확률 은 50 % 반반 ! 은행 고고씽 ~ [ 육아 휴직 전 급여 인정 문제 - 전세 대출 , 디딤돌 대출 모두 해당 ] - 누구 는 휴직 전 급여 인정 받 으려고 하 고 ( 소득 최대한 높혀 서 많이 받 으려고 ) - 누구 는 휴직 후 급여 인정 받 으려고 하 고 ( 소득 초과 안 되 려고 . ..) 귀 에 걸 면 귀걸이 , 코 에 걸 면 코걸이 됩니다 . 은행 에서 일단 원칙 은 \" 휴직 전 급여 \" 를 인정 합니다 . ( 대출 받 고 영원히 복직 안 하 는 건 아니 여서 그렇 습니다 . ..) [ 소득 인정 되 는 경우 - 전세 대출 한도 ] - 그냥 연봉 3 ~ 4 배 나옵니다 . ( 단 , 개인 전세 대출 한도 1 억 인 사람 이 -> 신용 대출 3000 만 원 받 으면 -> 전세 대출 한도 가 1 억 에서 -> 9200 만 원 정도 로 줄 어 버립니다 . 1 : 1 삭감 은 되 지 않 아요 . 이거 는 꼭 알 아두 세염 . ..) [ 무소득 인 경우 - 전세 대출 한도 ] 1 ) 버팀목 전세 대출 무소득 자 자격 으로 2700 ~ 3000 만 원 신청 ( 이론 상 최대 3300 만 원 까지 가능 ) 2 ) 청년 맞춤 형 전세 대출 / 카 뱅 청년 전세 대출 최대 7 , 000 만 원 신청 3 ) 일반 은 행전 세대 출 - 신용카드 사용 액 많 으면 대체 소득 으로 전세 대출 가능 하 구요 . - 건강 보험료 많이 내 시 면 ( 재산 많 아서 ) 그거 대체 소득 으로 가능 합니다 . ( 이 2 개 는 은행 에 문의 하 고 진행 해야 해용 ) 위 2 개 방법 이 있 습니다 . 따라서 현재 무소득 자 인 경우 최악 을 가정 하 면 버팀목 전세 대출 3000 만 원 가능 한 거 에요 . . 버팀목 전세 대출 - 무소득 자 안 해 주 는 은행원 한테 일침 놓 은 글 [ 전세 대출 신용 등급 ] 중소기업 전세 / 버팀목 전세 / 신혼 부부 전세 대출 은 요 . - 이론 상 8 ~ 9 등급 도 가능 합니다 . ( 이론 상 그렇 다는 뜻 입니다 . ) - 실제로 개인 회복 중 에 도 승인 되 는 경우 있 어요 . ( 물론 , , , 안 되 는 경우 도 있 습니다 ;...) 그래서 우리 은행 , 국민은행 , 기업 은행 , 농협 은행 , 신한은행 5 개 은행 가 셔서 개인 정보 넣 고 주택공사 전세 대출 가능 등급 인지 확인 을 해 보 셔야 합니다 . gettyimagebank [ 중소기업 전세 대출 , 버팀목 전세 대출 받 고 이직 하 면 ? 퇴사 하 면 ? 연봉 오르 면 ? ] - 2 년 후 계속 중소기업 다닌다 . -> 4 년 까지 연장 -> 5 년 차 에 버팀목 전세 대출 로 연장 - 2 년 후 대 기업 , 공무원 되 었 다 . -> 버팀목 전세 대출 로 전환 연장 - 2 년 후 무직 상태 다 . -> 버팀목 전세 대출 로 전환 연장 - 2 년 후 연봉 1 억 넘어갔 다 . -> 버팀목 전세 대출 로 전환 연장 ( 중소기업 다니 면 4 년 까지 중소기업 연장 ) - 2 년 후 결혼 했 다 . -> 신혼 부부 전세 대출 ( 또는 버팀목 전세 대출 로 전환 연장 또는 대환 대출 ) - 2 년 후 유 주택 자 . -> 상환 또는 일반 전세 대출 로 대환 대출 하 셔야 합니다 . - 2 년 후 나이 초과 -> 4 년 까지 연장 -> 5 년 차 에 버팀목 전세 대출 로 연장 이렇게 다 됩니다 . 중간 에 변동 생겨도 일단 계약 이 므로 2 년 은 사용 가능 합니다 . 걱정 마세요 ~ ( 중소기업 전세 , 버팀목 전세 , 신혼 부부 전세 셋 다 국가 복지 전세금 입니다 . ) ( 위 3 개 대출 은 하나 의 뼈대 를 둔 같 은 대출 입니다 . 혜택 만 갈라놓 은 거 라서 그렇 습니다 . ) ( 2020 년 신규 도입 ) 전세 대출 기간 10 년 -> 1 자녀 당 2 년 씩 늘 어서 -> 최장 20 년 까지 유지 가능 [ 추가 주요 한 사항 ] 시 중 의 모든 대출 은 ( 전세 대출 / 디딤돌 대출 / 신용 대출 모두 포함 ) 대 출신 청일 ~ 대출 실행 일 ( 잔금 일 ) 까지 아무 변동 이 없 다는 전제 로 대출 승인 을 해 줍니다 . ( 재직 상태 , 신용 등급 , 신용 대출 등 ) 받 자마자 변동 이 생기 면 필시 문제 가 되 구요 . 이 직 , 산재 , 질병 등 퇴사 면 그건 참작 이 되 겠 죠 . 이 직 의 경우 에 도 소득 이 달라지 기 때문 에 dti 산정 , 그리고 소득 초과 하 면 전세 대출 / 디딤돌 대출 불 가능 상황 이런 게 다 고려 되 어야 합니다 . ( 지식인 에 제일 많이 올라오 는 질문 = 대출 신청 해 놓 고 퇴사 하 면 어떻게 되 나요 ? ) ( 대출 은행원 이 제일 싫 어 하 는 거 = 대출 신청 해 놓 고 조건 변동 ( 신용 대출 받 기 , 퇴사 하 기 등등 ) [ 전세 대출 받 고 이사 가 면 어떻게 되 나요 ? ] 전세 대출 은 a / s 서비스 가 아래 와 같이 세 가지 있 어요 . - 목적물 변경 : 이사 갈 경우 - 증액 : 전세금 집 주인 이 통수 치 구 올려 달 라구 하 는 경우 - 목적물 변경 및 증액 : 이사 가 면서 전세금 같이 오르 는 경우 위 세 가지 a / s 기능 이 있 거든요 . 그래서 올라간 전세금 하 구 여 + 재직 증명서 + 근로 소득 원천 징수 영수증 이렇게 기억나 시 죠 . 그거 들 구 은행 가 면 처리 해 줍니다 . - 이 사갈 집 85 제곱미터 초과 하 면 안 되 구요 . - 집 에 융자 없 거나 적 어야 하 구요 . .. 등등 이런 조건 을 다시 살펴봐야 합니다 . 따라서 계약 부터 하 지 마시 고 , 일단 은행 부터 ㄱ ㄱ ㄱ 하 세용 . 그냥 이사 가 고 전세금 안 오르 면 . ..? 전세금 -> 은행 -> 새 집 주인 이체 끝 . ( 은행 에서 집 변경 해 줌 ) 그냥 이사 가 고 전세금 오르 면 . ..? 전세금 -> 은행 + 추가 대출 + 추가 님 돈 -> 새 집 주인 이체 끝 . ( 은행 에서 집 변경 해 줌 ) 그냥 이사 가 고 전세금 내려가 면 . ..? 전세금 -> 은행 + 일부 상환 + 일부 님 돈 돌려줌 -> 새 집 주인 이체 끝 . ( 은행 에서 집 변경 해 줌 ) [ 일반 전세 대출 인데 -> 중소기업 전세 대출 로 갈아타 고 싶 어요 ! ] [ 버팀목 전세 대출 인데 -> 중소기업 전세 대출 로 갈아타 고 싶 어요 ! ] 대환 대출 문의 입니다 . ( 은행원 들 이 가장 싫 어 하 는 업무 ㅎㅎ ) - 버팀목 전세 -> 중소기업 - 중소기업 -> 버팀목 - 중소기업 -> 신혼 부부 전세 - 일반 전세 대출 -> 중소기업 / 버팀목 / 신혼 부부 전세 등등 , , , 이렇게 대환 대출 은 요 . .. 지금 5 개 은행 마다 세부 업무 가 다릅니다 . - 기존 집 + 증액 만 가능 한 경우 - 기존 집 대출 상환 해야 가능 한 경우 - 이사 를 가 면 대환 대출 이 가능 한 경우 등등 세부 업무 단 이 라서요 . 이런 경우 는 우리 은행 , 국민은행 , 기업 은행 , 농협 은행 , 신한은행 5 개 은행 대표 번호 -> 대출 -> 주택 도시 기금 -> 상담 사 연결 이나 거래 은행 지점 대출 은행원 한테 정확 하 게 물 어 보 고 진행 을 하 세요 . 필자 는 위 의 5 대 은행 + 대출 + 주택 도시 기금 전세 대출 / 디딤돌 대출 실무 경험 자 입니다 . 그러나 저 조차 위 의 5 개 은행 중 1 개 은행 의 업무 만 알 고 있 어요 . 잘못 된 정보 로 은행 가 면 진행 자체 가 안 되 기 때문 에 요 . 정확 하 게 은행 에 물 어 보 고 진행 을 하 세요 . 은행 에서 방법 을 찾 아 줍니다 ~ [ 전세 대출 심사 중 -> 신용 대출 일으키 면 어떻게 되 나요 ? ] 기본 적 으로 대출 심사 중 에 는 다른 대출 을 일으키 면 안 됩니다 . 이건 기본 이 에요 . 왜냐면 대출 신청 일 현재 기준 으로 모든 게 고정 ( fix ) 됩니다 . 연봉 + 신용 등급 + 다른 대출 다 넣 고 전세 대출 한도 를 봤 는데 , , , 대출 을 중간 에 일으키 면 -> 대 출한 도 바뀝니다 . -> 신용 등급 변동 생길 수 도 있 습니다 . 당연히 그래서 전세 대출 실행 -> 신용 대출 실행 순서 대로 가 는 게 맞 구요 . ( 그러 함 에 도 반대 로 신용 대출 부터 받 아도 되 는 경우 는 , , , ) 개인 전세 대출 한도 가 충분 한데 대출 을 적 게 신청 한 경우 는 신용 대출 을 먼저 받 아도 됩니다 . 그런데 이게 좀 불 확실 해서 보통 은 같 은 은행 에서 전세 대출 한도 + 신용 대출 심사 를 본 다음 잔금 날 전세 대출 실행 -> 신용 대출 실행 이렇게 해서 맞춰 주 는 게 보통 입니다 . 실제로 개인 전세 대출 한도 1 억 인 사람 이 -> 신용 대출 3000 만 원 받 으면 -> 전세 대출 한도 가 1 억 에서 -> 9200 만 원 정도 로 줄 어 버립니다 . 1 . 20 % 전세 대출 한도 가 삭감 되 면 너무 아까워서 그런 거 에요 . 꼭 알 아두 세염 . .. ( 주택 도시 기금 에 한도 돌려 보 고 개인 한도 가 충분 한 상황 에서 전세 대출 을 소액 만 신청 하 시 는 경우 라면 신용 대출 을 먼저 받 아도 됩니다 . 그렇 다 하 더라도 다른 변수 가 생길 수 도 있 으니 은행 에 꼭 문의 하 고 진행 을 하 세요 . ) [ 전세 대출 세대주 문제 ] 전세 대출 신청 하 실 때 이 세대 주문제 , , , 매우 중요 합니다 . 헷갈리 니까 잘 따라오 면서 읽 어 보 세요 . .. - 일반 버팀목 전세 대출 = 단독 세대주 가능 - 청년 버팀목 전세 대출 = 예비 세대 주도 신청 가능 - 중소기업 전세 대출 = 예비 세대 주도 신청 가능 - 신혼 부부 전세 대출 = 혼인 전 예비 세대주 / 혼인 후 세대 주로 신청 가능 위 에서 예비 세대주 는 그냥 신청 해도 되 는데요 . ( 예비 세대주 : 세대원 상태 로 대출 신청 가능 -> 대출 을 먼저 받 고 이사 + 전입 + 세대주 서류 를 은행 에 나중 에 제출 해도 된다는 뜻 입니다 . ) 버팀목 전세 대출 은 세대주 요건 을 충족 한 상태 에서 신청 이 가능 합니다 . 중소기업 전세 대출 은 예비 세대주 자격 으로 바로 신청 가능 합니다 . 신혼 부부 전세 대출 은 - 혼인 전 = 예비 세대 주로 바로 신청 가능 - 혼인 후 = 세대주 자격 으로 신청 해야 됩니다 . 이 차이 가 있 어요 . 많이 헷갈릴 수 있 습니다 . 특히 세대주 문제 는 부정확 하 면 아 얘 대출 진행 자체 가 안 됩니다 . 조심 하 세요 . 그리고 예비 세대 주로 신청 가능 하 신 분 이 , 세대주 만들 려고 , , , 가라 로 고시원 , 원룸 이런 데 임시방편 으로 비싼 월세 주 고 전입 해 전세 대출 신청 하 시 마시 라고 이렇게 설명 드리 는 겁니다 . 지금 그런 분 들 많이 계십니다 . 예비 세대 주로 가능 한 분 들 은 돈 낭비 하 지 마시 구요 . .. 꼭 예비 세대주 자격 그대로 신청 하 세요 . 그리고 세대주 문제 헷갈리 면 역시 우리 은행 , 국민은행 , 기업 은행 , 농협 은행 , 신한은행 5 개 은행 대표 번호 -> 대출 -> 주택 도시 기금 -> 상담 사 연결 이나 거래 은행 지점 대출 은행원 한테 정확 하 게 물 어 보 고 진행 을 하 세요 . 은행 에서 방법 을 찾 아 줍니다 . 혼자 고민 하 지 마 세용 ! [ 전세 대출 이용 중 -> 나중 에 결혼 하 면서 디딤돌 대출 신청 하 면 문제 가 될까요 ? ] 전세 대출 이용 중 -> 디딤돌 대출 신청 ( 당연히 가능 ) -> 디딤돌 대출 실거 주 입주 의무 -> 전세 는 당연히 이사 나옴 -> 전세금 은행 상환 끝 . 이렇게 하 라고 국가 에서 주거 복지 정책 으로 버팀목 전세 대출 , 디딤돌 대출 만들 어 놓 은 겁 니 당 ~ 당연히 버팀목 전세 대출 안 고 있 는 상태 에서 중도금 대출 , 디딤돌 대출 다 신청 됩니다 . ~ 왜냐면 지난 글 에서 다 설명 드렸 지만 전세 대출 있 어도 디딤돌 대출 은 70 % 대출 다 나와요 . 부부 연봉 1600 만 원 으로 3 억 아파트 70 % 2 . 1 억 대출 나오 는 게 국가 디딤돌 대출 입니다 . 걱정 안 하 셔도 됩니다 . [ 필요 서류 ] 1 . 사업자 등록증 ( 회사 ) 2 . 주 업종 코드 확인 서 ( 회사 ) 3 . 재직 증명서 ( 회사 ) 4 . 원천 징수 영수증 ( 회사 또는 홈 택스 ) 5 . 고용 보험 피보험 자격 이력 내역 ( 근로복지공단 ) 6 . 건강 보험 자격 득실 확인 서 ( 건강보험공단 ) 7 . 주민 등록 등본 , 초본 ( 최근 이사 이력 포함 ) 8 . 전 세계 약서 ( 이사 확정 일자 동사 무소 ) 9 . 계약금 5 % 이상 을 이체 영수증 [ 전세 대출 받 고 + 모자란 돈 구하 는 순서 ] 돈 구하 는 순서 , 순서 대로 정리 해 드릴께요 . 1 ) 전세 대출금 70 %~ 80 % 확보 2 ) 내 돈 20 %~ 30 % 가 없 어 영 ㅜㅜ 3 ) 예금 , 적금 , 청약 , 보험 적립금 담보 대출 90 % 까지 나옵니다 . ( 어릴 때 부모 님 이 들 어 주 신 거 혹시 있 나 보 세요 ) 4 ) 없 으면 ? => 신용 대출 ( 1 금융 권 ) 5 ) 안 되 면 ? => 새 희망 홀씨 대출 ( 1 금융 권 ) 6 ) 비싸 서 싫 다면 => 부모 님 한테 빌려 달 라구 하 고 용돈 이 자 드리 세요 . 7 ) 흙 수저 라 아무것 도 없 다면 ? => 전세 를 -> 반 전세 로 낮추 시 고 월세 를 올리 세요 ( 전세 , 반 전세 , 월세 보증금 도 전부 70 %~ 80 % 전세 대출 가능 합니다 . ) 이 방법 밖 에 는 없 습니다 . ( 같 은 은행 에서 전세 대출 받 고 + 그 다음 바로 신용 대출 , 이 순서 대로 받 아야 전세 대출 한도 가 안 잡 아 먹혀요 ! ) 30 % 더 어떻게 받 으려구 대부 업체 , 캐피탈 , 사금융 절대 쓰 지 마세요 . 꼬리 가 개 를 흔드 는 모양 이 됩니다 . ! 전세 대출 받 고 내 돈 모자라 면 구하 는 순서 ( 대학생 , 직장 인 필독 ) [ URL ] 국가 전세 대출 1 억 받 으면 실제 한 달 이자 ( 월 10 만 원 ~ 15 만 원 수준 입니다 . 제발 월세 피 빨리 지 말 고 국가 전세금 이용 하 세요 . ) ( 월세 1 년 아끼 면 매년 \" 갤럭시 폴드 \" 를 살 수 있 는 돈 입니다 . ) ( 본 글 은 \" 바보 아저씨 경제 이야기 \" 책 내용 \" 버팀목 전세 대출 무조건 \", \" 취직 하 면 내 돈 한 푼 없이 1 억 전세 구하 는 방법 \" 글 내용 을 바탕 으로 작성 된 글 입니다 . ) 온라인 기고 10 개월 만 에 구독자 25 , 000 명 , 조 회수 600 만 을 돌파 한 생활 경제 , 바보 아저씨 의 경제 이야기 전세 대출 1 대 교주 의 교지 , ,, ( 敎旨 : \" 월세 노예 해방 을 선언 하 노라 \") [ URL ] [ 바보 아저씨 의 온라인 연관 글 더 보 기 ] 버팀목 전세 대출 - 무소득 자 안 해 주 는 은행원 한테 일침 놓 은 글 중소기업 전세 대출 ( 1 억 월 이 자 10 만 원 ) - 중소기업 , 중견 기업 버팀목 전세 대출 ( 1 억 월 이 자 20 만 원 ) - 공무원 , 대 기업 , 전문직 , 학생 , 무소득 자 전세 근저당 계산 방법 - 전세 사 기 당하 지 않 는 방법 신혼 부부 전세 대출 , 신혼 부부 디딤돌 대출 - 알 기 쉽 게 총 정리 편 현실 경제 속 경제 적 불 평등 의 실제 사례 6 가지 ( 월세 노예 의 실체 , 국가 전세 대출 , 전세 근저당 , 확정 일자 + 계약서 잘 설명 된 글 ) 2020 년 중소기업 / 버팀목 / 신혼 부부 / 전세 대출 연봉 별 최대 한도 바보 아저씨 의 경제 이야기 바보 아저씨 의 경제 이야기 ( 일반 인 자비 출판 -> 6 위 경제 베스트셀러 가 된 책 ) 경제 / 경영 베스트셀러 순위 ( 2019 년 2 월 기준 ) [ 바보 아저씨 의 경제 이야기 저자 주요 faq 공유 ] 중소기업 전세 대출 연봉 35 , 034 , 500 원 입니다 . 될까요 ? 은행원 은 소득 어떻게 판단 해요 ? [ URL ] 버팀목 신혼 부부 전세 대출 한도 차이 , 신한은행 1 . 1 억 , 기업 은행 1 . 6 억 왜 이렇게 차이 가 나 는 거 죠 ? 연봉 4900 만 원 신혼 부부 입니다 [ URL ] 전세 대출 원룸 다 가구 , 왜 은행 에서 잘 안 해 주 나요 ? 되 는 건가요 ? 안 되 는 건가요 ? ( 실제로 되 는데 , , , 은행원 재량 거절 입니다 . ) [ URL ] 중소기업 청년 전세 자금 대출 은 조건 만 맞 으면 다 되 나요 ? [ URL ] 중소기업 전세 대출 , 주거 용 오피스텔 전세 1 억 안전 한가요 ? [ URL ] 중소기업 전세 대출 연봉 , 작년 2800 , 올해 3600 , 연말 정산 안 했 는데 대출 가능 할까요 ? [ URL ] 전세 자금 대출 , 연봉 3000 만 원 + 신용 대출 8000 만 원 가능 할까요 ? [ URL ] 신혼 부부 전세 대출 , 남편 1500 + 아내 3000 + 대출 1 . 8 억 있 어요 가능 한가요 ? [ URL ] 무직자 전세 대출 , 4 대 보험 없 는 직장 인데 전세 대출 가능 한가요 ? [ URL ] 전세 대출 무소득 자 다 빌려 주 나요 ? 누가 무소득 자 를 해 주 나요 ? 말 이 안 됩니다 . [ URL ] 중소기업 전세 대출 , 1 억 법인 전세 인데 가능 할까요 ? [ URL ] 신혼 부부 전세 대출 vs 디딤돌 대출 , 충 주사 는 30 대 공무원 이 에요 . 가능 할까요 ? [ URL ] 중소기업 전세 대출 , 회사 지역 말 고 다른 지역 에서 대출 가능 한가요 ? [ URL ] 보금자리 론 , 심사 기간 이 얼마나 걸려요 ? 계약금 날리 는 거 아닌가요 ? [ URL ] 월세 1 달 후 전세 계약 이 가능 할까요 ? 중소기업 전세 대출 인천 송도 입니다 . [ URL ] 신혼 부부 생애 첫 주택 마련 대출 , 연체 기록 해제 6 등급 인데 받 을 수 있 나요 ? [ URL ] 전세 대출 + 신용 대출 , 연봉 2400 만 원 직장인 이 에요 . 1 억 가능 할까요 ? [ URL ] 정부 전세 자금 지원 ? 나오 나요 ? 지인 이 지원 대상 이 아니 래요 . [ URL ] 청년 전세 대출 전월세 지원 어떤 게 있 나요 ? 연봉 3000 + 대출 3000 + 신용 등급 7 등급 입니다 . [ URL ] 중소기업 청년 전세 대출 , 연봉 2800 , 대출 470 , 등급 6 ~ 7 , 전세 1 . 1 억 가능 할까요 ? [ URL ] 전세 자금 대출 , 와이프 몰래 숨겨둔 대출 1080 만 원 있 어요 . 가능 할까요 ? 연봉 5000 , 대출 5000 [ URL ] 중소기업 전세 대출 이직 , 이 직 후 연봉 3700 입니다 . 이 직 전 급여 인정 가능 한가요 ? [ URL ] 전세 자금 대출 , 하나 은행 , 연봉 6000 , 부채 6500 , 미혼 입니다 . 한도 가 얼마 까지 가능 할까요 ? [ URL ] 전 세대 출문 의 , 24 살 , 보증금 700 / 월세 84 살 아요 . 대출 2800 있 는데 전세 대출 가능 할까요 ? [ URL ] 부모 님 집 전세 대출 가능 할까요 ? 중소기업 청년 전세 대출 , 25 살 , 부모 님 주택 2 층 에 전세 들어가 려 합니다 . [ URL ] 중소기업 취업 청년 전월세 보증금 대출 , 개인 사업 회사 , 30 살 , 법인 번호 가 없 어요 . 가능 한가요 ? [ URL ] lh 주택공사 전 세대 출도 깡통 전세 사 기 당할 수 있 나요 ? [ URL ] 버팀목 전세 대출 , 매매 가 1 . 70 억 / 선순위 1 . 2 억 / 전세 7500 만 원 안전 한가요 ? [ URL ] 건물 근저당 , 건물 13 억 , 융자 1 . 8 억 , 선순위 7 억 , 전세 1 . 7 억 들어가 도 안 전할까요 ? [ URL ] 건물 25 억 , 근저당 11 억 , 보증금 8 . 5 억 , 원룸 전세 9500 만 원 안전 할까요 ? [ URL ] 중소기업 전세 대출 , 건물 43 억 / 34 세대 / 채권 19 억 / 보증금 19 억 안전 한가요 ? [ URL ] 전 세집 들어가 려고 하 는데 융자 가 있 어요 . 전세 2 . 3 억 / 융자 3 억 안 전할까요 ? [ URL ] 신혼집 전세 대출 , 매매 가 전세 가 차이 가 없 습니다 . 안 전할까요 ? [ URL ] 중소기업 전세 대출 직후 , 집 주인 집 매매 하 면 ? 14 일 전세 대출 , 15 일 집 매도 합니다 . 전세금 안전 한가요 ? [ URL ] 중소기업 청년 전세 대출 , 전세 1 억 인데 , 8000 / 20 반 전세 계약 도 가능 할까요 ? [ URL ] 법인 전세 임대차 계약 , 법인 보증 보험 , 법인 전세 특약 [ URL ] 회사 보유 분 미등기 전세 계약 질문 합니다 . [ URL ] 한 달 생활비 팩 폭 자취 한 달 생활비 팩 트 폭격 , 숨 만 쉬 어도 70 ~ 80 만 원 [ URL ] 한국 빈부 격차 의 원인 빈부 격차 의 원인 , 대한민국 헬 조선 의 현실 [ URL ] 바보 아저씨 의 경제 이야기 “ 앞 만 보 며 바보 처럼 정말 열심히 인생 을 살 았 는데 , , , 돌이켜 보 니 정말 딱 , 바보 서민 이 되 어 있 더라 . ..\" 부디 다른 분 들 은 저 보다 , 지금 보다 더 나 은 , 삶 을 위한 지혜 를 찾 으시 길 간절히 바랍니다 . ” ( 바보 아저씨 의 헬 조선 현실 생 존기 , 현실 생존 지침서 - babo uncle green book ver 1 . 0 ) 바보 아저씨 의 경제 이야기 비하인드 [ URL ] 청년 전세 자금 대출',\n",
       "       'google colab 의 전체 세션 유지 시간 은 12 시간 이 고 , 90 분 이상 비활성 화 되 어 있 으면 끊 긴 다고 하 는데 , 머신 러닝 학습 을 하 다 보 면 90 분 동안 조작 을 안 하 는 일 이 흔하 다 . 이렇게 학습 을 하 다 보 면 자주 런타임 연결 끊김 창 이 뜨 게 되 는데 , 이것 을 방지 할 수 있 는 방법 이 없 는지 google 에서 찾 아 봤 다 . [ URL ] [ URL ] google colab 을 실행 시키 는 크롬 브라우저 창 에서 f 12 ( 혹은 ctrl - shift - i ) 를 눌러서 개발자 도구 창 을 열 고 console 창 에서 아래 와 같이 입력 을 해 주 면 된다 . function clickconnect ( ) { / / 백 엔드 를 할당 하 지 못했 습니다 . // gpu 이 ( 가 ) 있 는 백 엔드 를 사용 할 수 없 습니다 . 가속기 가 없 는 런타임 을 사용 하 시 겠 습니까 ? / / 취소 버튼 을 찾 아서 클릭 var buttons = document . queryselectorall ( \" colab - dialog . yes - no - dialog paper - button # cancel \"); buttons . foreach ( function ( btn ) { btn . click ( ) ; }); console . log ( \" 1 분 마다 자동 재 연결 \"); document . queryselector ( \"# top - toolbar > colab - connect - button \"). click ( ) ; } setinterval ( clickconnect , 1000 * 60 ) ; 런타임 유형 을 gpu 로 하 는 것 이 cpu 로 하 는 것 보다 60 배 이상 학습 속도 가 빠른 것 같 다 . 그런데 google colab 에서 런타임 유형 을 gpu 로 하 면 연결 이 잘 안 될 때 가 많 다 . 한국 시간 아침 7 시 30 분 이후 에 연결 하 면 gpu 로 연결 이 잘 되 고 , 저녁 때 는 연결 이 잘 안 된다 . 아무래도 미국 등 외국 에서 많이 사용 해서 그런 것 같 다 . google colab 에서 buffered data was truncated after reaching the output size limit 방지 [ URL ] model . fit ( ) 함수 에서 파라미터 를 verbose = 1 로 하 면 트레이닝 시 buffered data was truncated after reaching the output size limit 라고 출력 이 나오 고 , 그 뒤 로 는 출력 결과 가 화면 에 표시 가 안 될 때 가 있 다 . 백 그라운드 에서 계속 실행 은 되 는 것 같 은데 , 출력 결과 가 안 나와서 제대로 실행 되 고 있 는지 확인 이 안 된다 . model . fit ( ) 함수 에서 파라미터 를 verbose = 0 혹은 2 로 하 면 이 와 같 은 현상 을 막 을 수 있 는데 , 0 으로 하 면 training 할 때 log 가 전혀 출력 이 안 되 서 답답 하 니까 2 로 하 는 게 좋 다 . verbose : integer . 0 , 1 , or 2 . verbosity mode . 0 = silent , 1 = progress bar , 2 = one line per epoch . [ 출처 ] [ URL ] google colab 에서 30 분 마다 현재 출력 창 지우 기 - 트레이닝 시 현재 실행 중 인 셀 의 출력 이 너무 길 어 지 면 보 기 불편 하 므로 30 분 마다 현재 실행 중 인 셀 의 출력 을 지워 주 는 코드 이 다 . 위 와 마찬가지 로 크롬 브라우저 의 console 창 에서 아래 코드 를 실행 해 준다 . function cleancurrentoutput ( ) { var btn = document . queryselector ( \". output - icon . clear _ outputs _ enabled . output - icon - selected [ title $=\\' 현재 실행 중 . ..\\'] iron - icon [ command = clear - focused - or - selected - outputs ] \"); if ( btn ) { console . log ( \" 30 분 마다 출력 지우 기 \"); btn . click ( ) ; } } setinterval ( cleancurrentoutput , 1000 * 60 * 30 ) ;',\n",
       "       \"samples ( training data = son : 15 + hours , park : 5 + hours , moon : 2 + hours ) click if you can ' t hear any sound 제너 러 티 브 어 드 벌서 리얼 네트워크 와 베리 에셔 널 오토 인코더 가 핫 하 다 . seo son park 오스트랄로피테쿠스 아 파렌 시스 는 멸종 된 사람 족 종 으로 , 현재 에 는 뼈 화석 이 발견 되 어 있 다 . seo son park moon 저 는 데브 시스터즈 에서 머신 러닝 엔지니어 로 일 하 고 있 는 김태훈 입니다 . seo son park moon 스타워즈 는 2017 년 12 월 에 개봉 합니다 . seo son park moon 손석희 는 대한민국 의 언론인 으로 , jtbc 보도 담당 사장 이 다 . seo son park moon 그리고 정마 담 한테 주 려는 거 이거 이거 , 이거 이거 장 짜리 아니 여 ? seo son park moon 이거 실화 냐 ? seo son park moon 아버지 가 방 에 들어가 신다 . seo son park 아버지 가방 에 들어가 신다 . seo son park 아버지 가 방 에 들어가 신다 . seo son park 오늘 의 날씨 는 어제 보다 3 도 높 습니다 . seo son park moon 오늘 의 날씨 는 , 어제 보다 3 도 높 습니다 . seo son park moon 조금 뒤 300 m 앞 에서 강남 구청 방면 으로 좌회전 하 시 기 바랍니다 . seo son park moon 프리 벳 가 4 번지 에 살 고 있 는 더 즐 리 부부 는 자신 들 이 정상 적 이 라는 것 을 아주 자랑 스럽 게 여기 는 사람 들 이 었 다 . seo son 그 들 은 기이 하 거나 신비 스런 일과 는 전혀 무관 해 보였 다 . seo son 아니 , 그런 터무니없 는 것 은 도저히 참 아 내 지 못했 다 . seo son 더 즐 리 씨 는 그루 닝 스 라는 드릴 제작 회사 의 중역 이 었 다 . seo son 그 는 목 이 거의 없 을 정도 로 살 이 뒤룩뒤룩 찐 몸집 이 큰 사내 로 , 코밑 에 는 커다란 콧수염 을 기르 고 있 었 다 . seo son 더 즐 리 부인 은 마른 체구 의 금발 이 었 고 , 목 이 보통 사람 보다 두 배 는 길 어서 , 담 너머 로 고개 를 쭉 배 고 이웃 사람 들 을 몰래 훔쳐 보 는 그녀 의 취미 에 는 더없이 제격 이 었 다 . seo son\",\n",
       "       '번역 ) 내 가 covid 19 데이터 를 시각 화 하 지 않 는 이유 그리고 여러분 들 도 ( 아마도 ) 하 지 않 아야 하 는 이유 출처 : why i ’ m not making covid 19 visualizations , and why you ( probably ) shouldn ’ t either by william r . chase 대피 명령 에 따라 집 에 있 으면서 제 가 이 글 을 쓰 는 동안 에 도 신종 코로나 바이러스 sars - cov - 2 * 는 전례 없 는 속도 로 전 세계 에 퍼지 고 있 습니다 . 바이러스 와 함께 시각화 차트 도 같이 퍼지 고 있 죠 . 하지만 저 는 현재 까지 이 주제 에 대해서 두드러지 게 이야기 를 하 지 않 았 습니다 . 자랑 하 고자 하 는 것 은 아니 지만 , 다른 시각화 전문가 들 에 비해 저 는 스스로 가 이 주제 에 대해서 꽤 나 전문 성 을 갖췄 다고 생각 합니다 . 저 는 학부 에서 미생물학 을 전공 하 면서 바이러스학 , 미생물 진화 학 , 그리고 전염병 의 역학 을 집중 적 으로 공부 했 습니다 . 졸업 후 에 는 역학 연구실 에서 데이터 분석 과 시각화 를 주로 하 는 연구 분석가 로서 일 했 습니다 . 그러 고 나 서 데이터 시각화 전문가 가 되 었 습니다 . 바이러스 자체 는 sars - cov - 2 ( south asian respiratory syndrome coronavirus 2 ) 라고 불리 며 , 이 바이러스 가 야기 하 는 병명 이 covid - 19 ( coronavirus disease of 2019 ) 입니다 . 그렇 다면 저 는 왜 다른 많 은 사람 들 처럼 covid 19 로 차트 , 지도 , 대시보드 , 추적 기 , 그리고 모델 을 만들 지 않 았 을까요 ? 두 가지 이유 가 있 습니다 . ( 1 ) 저 는 속보 를 좋아하 지 않 고 , ( 2 ) “ 많이 배울수록 모르 는 것 을 깨닫 게 된다 ” ( 더닝 - 크루거 효과 , 아래 차트 참조 ) 는 말 을 믿 기 때문 입니다 . 그래서 저 는 보 면서 기다리 기 로 했 습니다 . 지난 몇 달 동안 저 는 과학 계 , 정부 , 그리고 공공 ( 언론사 와 개인 ) 채널 들 에서 나오 는 발병 에 대한 리포트 들 을 주의깊 게 살펴보 았 습니다 . 제 가 살펴본 것 과 여러분 께 covid 19 데이터 를 분석 하 거나 시각 화 하 는 것 을 자제 하 달 라고 요청 하 는 이유 를 설명 드리 겠 습니다 . 이게 중요 한 이유 covid 19 판 데 믹 은 9 / 11 이래 로 그 어떤 이벤트 보다 더 넓 게 , 그리고 더 완벽 하 게 세계 의 주의 를 주목 시켰 습니다 . 사람 들 은 자신 의 안위 에 대해 걱정 하 고 있 으며 , 정보 에 목말라 하 고 있 습니다 . 이 로 인해 이 주제 에 대한 데이터 시각화 가 대중 에게 이례 적 으로 높 게 노출 되 는 위험 한 상황 을 연출 했으며 , 허위 정보 나 잘못 된 정보 를 전달 하 는 시각 화 는 세계 에 해 를 끼칠 수 있 습니다 . 잠시 여러분 이 완벽 하 게 정확 한 데이터 ( 현재 는 불 가능 하 지만 ) 에 접근 할 수 있 다고 가정 해 봅시다 . covid 19 시각화 가 받 게 될 놀라운 소셜 미디어 의 관심 은 우리 의 차트 가 엄청나 게 많 은 사람 들 이 보 게 된다는 것 을 의미 하 며 , 이 사람 들 중 에 는 도해 력 이 부족 한 사람 들 도 포함 됩니다 . 여러분 의 새로운 청중 이 가진 도해 력 에 대해 아주 사려 깊 은 고려 가 없 다면 , 여러분 의 시각화 자료 는 오독 될 가능 성 이 높 습니다 . 만약 여러분 의 차트 가 틀렸 거나 오독 되 면 무슨 일 이 벌어질까요 ? 여러분 이 ( 사망자 , 감염자 등 을 ) 과 대 예측 했 다면 , 최선 의 경우 보 는 사람 들 에게 불 필요 한 스트레스 와 불안 을 야기 할 것 이 고 , 최악 의 경우 대 규모 공황 과 정부 자원 을 잘못 배분 하 는 것 을 야기 할 수 있 을 것 입니다 . 만약 여러분 이 과소 예측 을 한다면 , 안전 에 대한 잘못 된 인식 을 심 어 줄 수 있 으며 , 사람 들 은 일상 적 인 활동 을 다시 해도 괜찮 다고 생각 할 수 있 으며 , 단체 와 정부 는 적절 한 행동 을 취하 지 않 을 수 도 있 고 , 이 는 사망자 를 야기 할 수 있 다 . 어느 경우 가 됐 건 여러분 은 잘못 된 정보 를 퍼트 렸 으며 , 이것 이 정부 를 쓰러트리 지 는 않 더라도 혼란 을 야기 하 고 , 전문가 의 의견 을 흐리 게 만드 는 데 에 일조 할 것 입니다 . 데이터 시각화 전문가 는 진실 의 창구 로 간주 되 기 때문 에 보통 이 는 굉장히 큰 창피 일 겁니다 . 하지만 이제 많 은 것 이 바뀌 었 습니다 . 사망자 가 늘어났 고 , 앞 으로 도 더 늘어날 것 이 며 , 여러분 의 시각화 가 더 나쁘 게 만들 수 도 있 습니다 . 하지만 이 를 바로잡 을 수 있 다면요 ? # flattenthecurve 는 어떻 고요 ? 이게 바로 데이터 시각화 가 사람 들 에게 정보 를 전달 하 고 생명 을 구할 수 있 는 기회 아닌가요 ? 네 , 데이터 시각화 가 빛날 시간 이 맞 습니다 . 실제로 도움 을 주 기 위해 여러분 이 할 수 있 는 것 들 에 대한 섹션 을 보 세요 . 안타깝 게 도 제 가 본 수백 개 의 데이터 시각화 중 에서 아주 작 은 부분 만 도움 이 되 는 카테고리 에 들어갔 습니다 . 제 가 본 대부분 의 프로젝트 는 확진 자 수 , 사망자 수 , 치명률 , 역학 예측 , 바이러스 전파 , 또는 다른 사실 이나 숫자 에 대한 것 들 이 었 고 , 모두 틀렸 습니다 . 확실히 말씀 드리 겠 습니다 . 그 누구 도 이 통계 수치 를 정확 하 게 보 고 할 수 없 습니다 . 이건 불 가능 한 일 이 에요 . ft , nyt , who 등 에서 나온 위대 한 차트 들 중 에서 도 틀린 것 들 이 있 었 습니다 . 이 는 그 누구 도 이러 한 통계 수치 에 대해 보 고 하 지 말 아야 한다는 것 은 아니 며 , 사실 제 가 언급 한 모든 단체 는 우리 가 알 고 있 는 것 과 더욱 중요 한 우리 가 모르 는 것 에 대해 소통 하 기 위해 엄청난 노력 을 하 고 있 습니다 . 제 가 모든 시각화 가 틀렸 다고 말 한 것 에 는 모든 자료 가 실수 를 했 거나 의도 적 으로 거짓말 을 한다는 것 은 아닙니다 . 이러 한 차트 들 은 완벽 하 지 않 은 데이터 에 기반 하 여 최선 의 예측 을 보여 주 고 있 습니다 . 하지만 납득 할 만 한 수준 의 정확도 를 가진 데이터 를 모으 는 데 에 는 큰 시간 과 자원 을 투자 해야 하 며 , 불 확실 성 에 대해 효과 적 으로 의사소통 하 는 것 또한 어렵 습니다 . 만약 여러분 이 covid 19 데이터 로 프로젝트 를 만드 는 것 을 생각 하 고 계시 다면 , 스스로 에게 질문 을 한 번 해 보 세요 . 내 가 거대 한 기관 들 과 최고 수준 의 보건 전문가 들 보다 더 잘 할 수 있 을까 ? 그렇 지 않 다면 자신 이 만든 부족 하 고 잠재 적 으로 해 가 될 수 있 는 것 대신 전문가 의 자료 를 홍보 하 세요 . 이러 한 위기 상황 에서 , 그리고 발병 에 대한 현재 상태 의 데이터 에서 , 이러 한 보고 는 전문가 들 에게 맡겨야지 , 재미 로 주말 에 하 는 코딩 프로젝트 에 사용 해서 는 안 됩니다 . 모든 covid 19 차트 가 틀린 이유 covid - 19 의 대 발생 에 대해 아주 쉬운 질문 을 하나 해 보 겠 습니다 . 이 바이러스 의 근원지 로 알려진 우한 에서 는 몇 명 이나 감염 되 었 을까요 ? 정답 은 , ‘ 아무 도 모른다 ’ 입니다 . 여기 에 는 두 가지 주된 문제 가 있 습니다 . ( 1 ) 광범위 한 검진 방법 의 부재 와 ( 2 ) 감염 된 많 은 사람 들 ( 아마도 대부분 ) 이 증상 이 없 었 고 , 걸렸 다는 사실 조차 도 모를 것 입니다 . 이러 한 불 확실 성 은 관련 된 많 은 측정치 를 오염 시킵니다 . 예 를 들 어 , 감염 률 을 알 지 못하 면 치명률 을 정확 하 게 계산 할 수 없 습니다 . 이러 한 정보 가 없 다면 많 은 역학 모형 들 은 실패 할 것 이 며 , 이 는 확산 심 각도 에 대해 파악 하 는 것 을 복잡 하 게 만듭니다 . 아마도 우리 가 가진 가장 정확 한 지표 는 사망자 수 ( 퍼센티지 가 아닌 숫자 입니다 ! ) 입니다 . 이러 한 이유 때문 에 ft 와 같 은 큰 방송국 들 이 보도 에서 사망자 수 를 강조 하 는 것 입니다 . 그러나 , 이 숫자 마저 도 예상 치 입니다 . 다양 한 국가 들 에서 오 는 사 망주 숫자 데이터 에 대한 정확도 와 완성도 에 대한 문제 가 있 으며 , 오진 한 경우 나 파악 할 수 없 는 경우 는 항상 있 기 마련 입니다 . 그리고 향후 가 어떨지 예측 을 하 거나 모형 을 만드 는 일 은 잊어버리 시 기 바랍니다 . 이러 한 종류 의 모형 은 적 게 는 수십 , 많 게 는 수백 개 의 변수 에 의존 하 는데 , 우리 가 아 는 지표 들 중 정확 한 것 은 거의 없 습니다 . 제발 모델링 은 학계 에 맡겨 두 세요 . 이 들 의 첫 마디 는 그 모형 들 이 엄청나 게 큰 신뢰구간 을 가지 고 있 고 , 아주 큰 불 확실 성 을 보여 준다고 시인 할 것 입니다 . 어려움 은 fivethirtyeight 의 훌륭 한 기사 에 훨씬 더 잘 설명 되 어 있 습니다 . visualization of the complications with modeling covid 19 deaths , by jasmine mithani and fivethirtyeight 바이러스 에 대한 가장 기초 적 인 과학 적 사실 들 조차 도 알려 지 지 않 았 습니다 . 바이러스 는 열 에서 얼마나 생존 할 수 있 는가 ? 바이러스 는 어떻 게 증식 을 하 는가 ? 바이러스 가 변형 을 일으킬 수 있 는 방법 은 무엇 인가 ? 사람 들 이 바이러스 에 대해 지속 적 인 면역 을 만들 수 있 는가 ? 전문가 들 에게 이러 한 질문 을 했 을 때 돌아오 는 대답 은 “ 아직 모릅니다 ” 일 것 입니다 . 올바른 과학 은 시간 이 걸리 며 , 이 질문 들 에 대한 좋 은 대답 을 얻 기 위해서 는 기다려야 합니다 . 해석 에 있 어서 의 문제점 우리 에게 쓸 만 한 데이터 ( 예 를 들 어 사망자 수 ) 가 있 다고 하 더라도 효과 적 으로 의사 를 전달 하 는 것 은 아주 까다롭 습니다 . 예 를 들 어 보 죠 . 독자 로서 제 가 저희 동네 의 사망자 숫자 를 봤 을 때 저 한테 이 숫자 는 무슨 의미 일까요 ? 제 가 알 고 싶 어 하 는 것 은 ‘ 내 가 어느 정도 로 놀라 야 하 는 거 지 ? ’ 일 겁니다 . 그렇 다면 제 가 사 는 곳 근처 에 사망자 가 많 다면 , 제 가 죽 을 수 도 있 으니 정신 이 나가 도 되 겠 군요 ! 그렇 지만은 않 습니다 . 왜냐하면 저 는 젊 고 건강 한데 바이러스 는 지병 이 있 는 나이 든 사람 에게 더 치명 적 이 기 때문 입니다 . 아 , 그럼 긴장 을 풀 어도 되 겠 군요 . 아뇨 , 또 틀렸 습니다 ! 비록 확률 이 더 낮 다고 해도 저 는 면역 이 없 고 , 바이러스 에 죽 은 젊 고 건 겅한 사람 들 도 있 습니다 . 그럼 중간 정도 로 만 걱정 하 면 될까요 ? 이러 한 종류 의 차이 와 미묘 함 은 이해 하 기 까다롭 습니다 . 과학 , 미생물학 , 데이터 분석 을 아 는 저 같 은 사람 조차 도 이러 한 차트 를 볼 때 면 이성 적 인 뇌 와 감정 적 인 뇌 가 그 중간 을 찾 으려고 싸웁니다 . 이 에 대해 조금 만 더 깊 게 생각 하 다 보 면 , 둘 이 만나 는 그 지점 에서 모든 게 산산조각 납니다 . 저 는 인구 밀도 가 높 은 필라델피아 에 살 고 있 는데 , 제 가 보 고 있 는 차트 가 인구 밀도 도 반영 하 고 있 을까요 ? 그리고 나 이 든 사람 들 의 치명률 이 더 높 다고 했 는데 , 제 가 사 는 곳 의 인구 분포 에 맞 게 수정 되 었 는지 도 궁금 하 네요 … 정확힌 치명률 없이 도 이걸 계산 하 는 게 가능 할까요 ? 그리고 공중 보건 도 당연히 염두 해야 합니다 . 병원 의 갯 수 와 산소 호흡기 수 , 그리고 의료 접근성 등 도 우리 의 예측 에 영향 을 줄 수 있 기 때문 입니다 . 훨씬 더 많 은 것 들 을 나열 할 수 있 지만 , 여러분 도 이제 무슨 뜻 인지 아셨 을 거 라고 생각 합니다 . 이러 한 사항 들 은 보고 된 사망자 수 의 정확도 에 영향 을 주 지 않 을 수 도 있 지만 , 독자 로서 여러분 은 사망자 수 보 다는 자신 이나 여러분 의 어머니 , 여동생 이 죽 을 확률 에 더 신경 이 쓰 입니다 *. 이런 차트 들 을 볼 때 그런 식 으로 논리 적 인 비약 을 하 기 도 하 고 , 이 때문 에 모든 사항 들 이 그렇게 왜곡 된 것 이 기 도 합니다 . * 또는 여러분 이 미국 에 살 고 있 다면 본인 의 주식 포트폴리오 가 더 신경 쓰일 수 도 있 겠 군요 . 모두 의 우선 순위 는 다르 니까요 … covid 19 데이터 를 시각 화 해야 하 는 사람 은 누구 인가 ? 이 모든 것 들 은 몇 가지 주요 포인트 로 요약 할 수 있 습니다 : 말 그대로 우리 의 삶 과 죽음 이 걸려 있 고 , 데이터 는 고르 지 않 고 질 도 좋 지 않 으며 , 데이터 는 교육 을 받 은 사람 들 조차 잘못 해석 할 가능 성 이 높 습니다 . 이 말 인 즉 슨 , covid - 19 통계 로 보고 를 할 모든 사람 은 문제 를 제기 하 고 , 실수 를 발견 할 수 있 도록 여러 명 으로 팀 을 만들 어서 작업 을 해야 합니다 . 그 팀 에 는 다양 한 곳 에서 받 아 오 는 복잡 하 고 난잡 한 데이터 를 모으 고 검증 하 는 사람 , 공중 보건 과 역학 전문가 ( 또는 최소한 이런 사람 들 에게 컨설팅 을 받 거나 ) , 데이터 에 존재 하 는 불 확실 성 을 효과 적 으로 보여 주 는 방법 을 이해 하 고 독자 들 을 가장 올바른 해석 으로 이끌 어 줄 커뮤니케이션 전문가 가 있 어야 합니다 . 불 확실 한 데이터 로 , 불 확실 한 시기 에 대중 에게 가능 한 한 많 은 정보 를 제공 하 고자 하 는 사람 들 로 이루어진 팀 들 도 있 습니다 . 특히 저 는 ft ( financial times ) , nyt ( new york times ) , 그리고 scmp ( south china morning post ) 의 그래픽 팀 에 깊 은 감사 를 드립니다 . 또한 이 문제 는 많 은 시간 과 주의 를 필요 로 한다는 것 을 의미 하 기 도 합니다 . 제 가 covid - 19 에 대한 그 어떤 작업 도 하 지 않 은 이유 중 하나 는 제게 이 문제 를 철저 하 고 정확 하 게 다룰 시간 이 없 다고 여겼 기 때문 입니다 . 이 는 주말 동안 진행 하 는 프로젝트 나 사이드 프로젝트 로 다룰 만 한 사안 이 아닙니다 . 그렇지만 이 데이터 가 여러분 에게 흥미 롭 고 , 분석 이나 시각화 기술 을 연습 하 고자 한다면 , 데이터 를 내려 받 아서 혼자 작업 한다고 해 를 끼치 지 는 않 을 겁니다 . 그 결과 를 사람 들 과 공유 하 려고 할 때 비로소 위험 해 지 는 것 입니다 . 여러분 이 조사 를 하 는 동안 새로운 것 을 발견 한다면 , 그 분야 의 전문가 에게 의견 을 구하 거나 , 언론사 또는 지역 보건 당국 에 연락 해서 그 결과 가 도움 이 되 는지 를 여쭤 보 십시오 . 그리고 이 데이터 로 작업 을 하 는 경우 에 는 나이팅게일 ( nightingale ) 과 아만다 매 클렉 ( amanda mkulec ) 이 쓴 중요 한 고려 사항 을 따르 도록 하 시 기 바랍니다 . 트위터 에서 진정 한 위험 은 확인 되 지 않 은 작업 을 공개 적 으로 공유 할 때 오 는 것 이 지 개인 적 인 방법 으로 작업 하 는 것 에 는 아무런 문제 가 없 다고 지적 해 준 스테파니 튜 얼 크 ( stephanie tuerk ) 씨 께 감사 드립니다 . 여러분 이 도울 수 있 는 방법 만약 여러분 이 데이터 과학자 , 개발자 , 또는 시각화 전문가 라면 , covid - 19 발병 에 여러 가지 도움 을 줄 수 있 습니다 . 어떤 것 을 하 면 좋 을 지 에 대한 간단 한 팁 들 입니다 .',\n",
       "       '‘ 좀 비 통계 ( zombie stat ) ’ 라는 말 이 있 다 . 어디 선가 나왔 다고 전해 지 는 수치 가 끝없이 이어지 면서 ‘ 사실 ’ 로 굳어지 며 여기저기 서 사용 되 는 현상 이 다 . 보통 사람 들 이 필요 로 하 거나 , 고정 관념 을 더욱 견고 하 게 만들 어 주 는 용도 로 사용 된다 . 이런 말 에 ‘ 근거 ’ 가 되 는 통계 수치 가 붙 고 수치 가 추가 되 면 그 말 이 사람 들 의 머릿속 에 더욱 깊이 박히 게 되 고 , 그 말 이 근거 가 없 다고 아무리 설명 해도 잠시 주춤 하 는 듯 하 다가 또 어느 때 에 시점 과 상관 없이 망령 처럼 되살아나 서 , 그 현상 을 바라보 는 사람 들 의 뇌 를 좀 먹 는다 . 그리고 이 것 은 ‘ 통계 ’ 라며 ‘ 사실 ’ 이라고 이야기 한다 . 그 통계 가 이 시점 에서 는 이미 죽 은 존재 인 것 도 깨닫 지 못한다 . 아니 , 특정 시점 에서 죽 은 통계 면 오히려 다행 이 다 . 요즘 은 사설 위키 같 은 커뮤니티 나 sns 같 은 데 에서 누군가 가 비유 로 사용 하 거나 , 출처 가 알 수 없 는 말 도 ‘ 팩 트 ’ 라는 이름 으로 여기저기 에 인용 된다 . ‘ 아인슈타인 이 사람 은 평생 두뇌 의 10 % 만 사용 한다고 했 다 ’( 1 ) 같이 사실 이 아닌 출처 도 숫자 와 출처 의 무게 로 지금 까지 도시 전설 이 되 어 가 고 있 지 않 은가 . 여기 서 의 숫자 가 통계 수치 가 되 면 좀 비 통계 가 된다 . 통계 란 기본 적 으로 어떤 상황 을 숫자 로 요약 한 값 이 다 . ‘ 상황 ’ 이 란 어떤 시공간 을 말 하 고 , 통계 는 결국 특정 시공간 의 스냅샷 을 떠서 수치 화 된 지식 이 므로 제약 조건 과 함께 하 는 숫자 다 . 그 시공간 을 작 게 잡 으면 많 은 경우 를 설명 할 수 없 고 시공간 을 넓 게 잡 으면 각각 의 상황 에 대한 설명력 이 부족 해진다 . 하지만 사람 들 은 이 것 을 망각 하 고 숫자 만 을 기억 한다 . 그 많 은 숫자 중 에서 도 기억 하 기 쉽 고 사람 들 이 짚 어 주 는 것 이 눈 에 잘 들어온다 . 만사 에 피곤 한 현대인 은 많 은 것 을 기억 하 기 를 원하 지 않 는다 . 복잡 한 것 을 읽 는 것 을 원하 지 않 는다 . 간단 하 면서 도 오래오래 통용 되 는 진리 를 찾 고 , 140 자 이내 로 만사 가 설명 되 는 ‘ 사이다 ’ 문장 만 을 읽 는다 . 요약 된 내용 이 마음 에 안 드 는 보고서 는 대충 읽 고 넘겨 버린다 . 클릭 수 를 늘려서 광고 를 실어야 하 는 언론 은 원 하 는 논조 에 숫자 를 끼워서 제목 을 짓 는다 . 조건 은 기사 에 간단히 실 어 두 면 일단 자신 들 의 책임 은 아니 다 . 그리고 피곤 한 사람 들 은 그 제목 만 을 읽 고 넘긴다 . 열 에 하나 본문 을 읽 는 사람 이 있 을 것 이 고 , 그 중 에서 또 열 에 하나 가 숫자 가 만들 어 진 조건 을 확인 할 것 이 다 . ( 그리고 여기 서 의 ‘ 열 에 하나 ’ 는 10 % 가 아닌 일부 라는 뜻 의 관용어 구임 을 밝힌다 . 아마도 읽 는 분 들 은 이해 하 실 것 이 라 믿 어 의심 치 않 으나 혹시나 여기 서 도 좀 비 통계 가 만들 어 질까봐 걱정 을 해 보 았 다 . ) 하 지만 남 은 사람 들 은 제목 만 을 보 고 , 최근 의 데이터 로 만들 어 진 정리 내용 보 다는 본인 의 머 릿 속 에서 떠돌아다니 는 좀 비 통계 와 직관 만 을 머릿속 에 남겨 두 고 일 을 결정 하 고 , ‘ 어디 에서 봤 는데 말 이 지 ’ 라고 하 면서 다른 사람 들 과 이야기 를 하 고 , 그렇게 확산 되 고 , 또 하나 의 좀 비 가 그렇게 탄생 하 고 퍼져 나갈 것 이 다 . 좀 비 바이러스 의 전 염력 은 강하 다 . 사람 들 이 흥미 있 어 할 것 이 아니 라면 좀 비 통계 로 만들 어 지 지 도 않 았 다 . 그런 달콤 한 숫자 는 대개 고정 관념 을 다시금 확인 해 주 는 것 들 이 다 . 간혹 고정 관념 을 놀랍 게 뒤집 어 주 는 숫자 도 있 지만 , 그런 것 중 에서 는 본인 의 입맛 에 맞 는 것 을 취한다 . 본인 이 알 고 있 던 것 이 나 , 입맛 에 맞 지 않 는 것 을 새로이 받아들이 는 것 은 달콤 하 지 않 고 맛 이 쓰 다 . 고정 관념 이 뒤집히 는 데 다 본인 에게 유리 하 지 않 은 이야기 는 이해 하 기 전 에 감정 적 인 거 부감 이 생겨서 , 이 를 바로 받아들이 는 것 보다 혹시나 빠져 나갈 구멍 이 있 는지 출처 와 예외 사항 을 찾아보 는 행동 이 앞선다 . 그리고 는 혹여 어쩔 수 없이 열심히 씹 어서 맛 을 희석 시키 고 억지로 삼켜 이해 했 다손 치 더라도 금방 잊어버린다 . 희석 된 맛 은 오래 기억 되 지 않 는다 . 많 은 곳 에서 좀 비 가 넘쳐나 고 , 데이터 가 자리 잡 으면서 무수 한 숫자 들 이 데이터 라는 이름 을 달 고 진실 인 척 하 면서 데이터 에 마저 좀 비 가 넘쳐나 는 사회 가 되 었 다 . 성수 를 뿌린다 손 쳐도 성수 가 제대로 되 었 는 지도 알 수 없 고 , 바이러스 만 끊임없이 퍼져서 이제 는 어디 까지 가 좀 비이 고 어디 까지 가 제대로 된 사실 인지 알 수 없 는 통계 수치 가 넘쳐난다 . 그래도 우리 는 여기 에서 어떻게 든 정신 을 차리 고 살 아야 한다 . 물론 누구 나 어느 정도 좀 비 통계 에 감염 되 어 있 겠 지만 , 우리 가 백신 을 만들 수 는 없 지만 , 그래도 소금 이 라도 입 에 물 고 버텨야 한다 . 우리 는 늘 그렇 듯 자신 의 자리 에서 자신 이 하 는 일 에서 조금 더 주의 를 기울여서 할 수 있 는 일 을 해야 한다 . 특히 데이터 를 만지 는 사람 들 의 역할 이 중요 하 다 . 통계 로 이루어진 결과 는 다수 의 이야기 가 많 다 . 주제 를 정하 고 데이터 를 수집 하 는 주체 는 본인 이 원 하 는 목적 의 데이터 를 수집 하 고 가공 해서 통계 결과 를 만들 어 낸다 . 그 과정 에서 결과 를 볼 대상 이 원 하 는 주제 를 고르 고 , 그 주제 에 대한 데이터 를 만드 는 과정 에서 일단 해당 주체 가 생각 하 는 ‘ 다수 ’ 의 입맛 에 어느 정도 맞 는 데이터 를 만들 게 된다 . 그 주체 의 뇌 가 어느 정도 좀 비 통계 에 잠식 당해 있 다면 이런 현상 은 더욱 심해진다 . 그리고 이렇게 모아진 데이터 를 사용 해서 통계 를 사용 해서 크 게 뭉뚱그리 는 과정 에서 , 그나마 남 아 있 던 소수 의 데이터 는 더욱 줄어든다 . 그리고 이 통계 로 이야기 를 만드 는 과정 에서 , 작 게 줄어든 이야기 는 잡음 이 되 어 사라진다 . 특히 좀 비 통계 에 잠식 당한 뇌 에서 는 이런 이야기 는 눈 에 들어오 지 도 않 을 것 이 다 . 통계 로 데이터 를 예쁘 게 추상 화 할 때 도 , 최대한 고정 관념 에 덜 사로잡히 고 중립 적 인 위치 를 유지 하 기 위해 노력 해야 한다 . 물론 어느 정도 의 통찰 을 활용 해야 데이터 의 패턴 도 보이 고 , 중요 한 내용 도 찾 을 수 있 을 것 이 다 . 하지만 그 ‘ 중요 한 내용 ’ 이 라는 것 이 , 과연 어떤 근거 에서 ‘ 중요 하 다 ’ 고 생각 했 는 지 를 한 번 되짚 어 보 아야 한다 . ‘ 재미있 어서 ’, 데이터 를 볼 사람 이 ‘ 좋 아 할 것 같 아서 ’ 라면 그 기반 에 는 고정 관념 , 다수 의 사고 가 자리 잡 고 있 는 것 은 아닌지 를 되돌아보 자 . 인구 통계학 정보 에 너무 매몰 되 지 말 고 , 가능 한 한 행동 기반 으로 데이터 를 사용 해야 한다 . ‘ 30 - 40 대 남성 ’ 보다 ‘ sf 소설 을 많이 구매 한 회원 ’ 에게 sf 소설 신간 을 추천 하 는 것 이 더 자연 스럽 겠 지만 , 많 은 사람 들 이 ‘ 30 - 40 대 남성 이 sf 를 많이 읽 을 테 니까 ’ 라고 이야기 하 며 이 사람 들 을 대상 으로 sf 신간 광고 를 타 겟 팅 하 기 를 원하 며 굳이 얻 기 힘든 인구 통계학 데이터 를 어떻게 얻 을 수 있 을까 하 고 고민 한다 . ( 2 ) 특정 대상 에 대한 통계 가 아니 라면 , 많 은 경우 소수 의 데이터 를 따로 고려 하 지 않 는다 . 사람 의 사진 을 대충 수집 하 면 백인 남성 이 상당수 일 것 이 고 , 흑인 여성 의 데이터 는 비율 상 훨씬 적 을 것 이 다 . 그리고 이렇게 적 게 수집 된 데이터 의 부류 는 확률 이나 통계 에서 는 더욱 제외 될 것 이 다 . 확률 형 알고리즘 을 사용 하 는 머신 러닝 모델 로 자동 처리 되 는 데이터 는 더욱 그럴 것 이 다 . 그래서 많 은 핸드폰 의 얼굴 인식 에서 여성 과 흑인 의 인식 률 이 낮 았 고 , 자동 의료 진단 시스템 에서 아시안 의 질병 예측 정확도 가 낮 았 다 . ( 3 ) 기술 과 데이터 는 만드 는 사람 이 생각 하 는 다수 중심 으로 돌아가 게 되 어 있 다 . 그래서 데이터 를 만들 고 활용 하 는 사람 은 더욱 다수 와 고정관념 에 매몰 되 지 않 아야 한다 . 혹여 그렇게 데이터 가 손 에 들어와도 , 가능 한 한 데이터 의 상태 를 파악 하 고 , 중립 적 으로 사용 할 수 있 도록 노력 해야 한다 . 물론 데이터 를 수집 할 때 더 노력 을 한다거나 , 이 를 층화 표집 한다거나 , 데이터 의 가중치 를 다르 게 사용 한다거나 하 는 몇 가지 추가 적 인 처리 를 해야 데이터 의 불 균형 을 그나마 보완 할 수 있 고 , 그렇 다고 항상 잘 되 라는 보장 도 없 고 번거 롭 기 만 할 것 이 다 . ‘ 빅 데이터 ’ 라는 미명 하 에 있 는 데이터 를 무조건 적 으로 다 사용 해서 모델링 해서 좋 은 성능 을 내 고 싶 은 마음 도 있 을 것 이 다 . 그래봐야 다수 의 데이터 에 오 버피팅 ( 과 적 합 ) 되 기 밖에 더 하 겠 는가 . 그리고 그 결론 은 장기 적 으로 는 그다지 재미없 고 뻔한 , 가끔 은 비판 도 받 을 수 있 는 결과 밖에 낳 지 못할 것 이 다 . 그냥 무심코 만들 어 진 데이터 와 통계 결과 를 보 는 사람 도 , 데이터 와 통계 를 접할 때 , 본인 의 인지 를 넓히 려고 노력 해야 할 것 이 다 . 물론 이런 과정 의 맛 은 쓰 고 , 별 효과 도 잘 모를 것 이 다 . 하지만 그냥 보 고 넘어갈 것 이 면 모르 겠 지만 , 웬지 기억 을 하 거나 주변 에 이야기 를 할 정도 라거나 일 을 결정 하 게 되 는 , 어느 정도 영향 을 미치 는 사안 에 대한 통계 는 가능 한 한 출처 와 조사 방법 을 확인 하 자 . 어떤 신문 기사 는 이 에 대해서 생략 하 기 도 하 지만 그래도 이 정도 는 표기 해 주 는 경우 가 많 다 . ‘ a 에 대해 70 % 가 찬성 해 ’ 라는 헤드라인 을 아침 에 읽 고 주변 사람 들 에게 열심히 말 하 고 다녔 는데 , 알 고 보 니 ‘ 100 명 중 응답 한 사람 은 10 명 이 고 그 중 7 명 이 긍정 적 반응 이 었 고 , 해당 사안 에 대해 70 % 의 사람 이 긍정 적 인 반응 을 보였 다 ’ 라는 통계 에서 나온 이야기 라는 것 을 알 고 나 면 허무 하 지 않 을까 . 그리고 이런 것 을 계속 보다 보 면 , 나중 에 는 어디 에서 조사 했 는지 만 보 아도 대강 이 것 이 신뢰 할 만 한 이야기 인지 아닌 지 어느 정도 가늠 할 수 도 있 게 된다 . 그리고 기존 에 알 고 있 던 것 과 는 다른 , 조금 은 재미있 는 이야기 가 눈 에 띌 지도 모른다 . 혹은 기묘 하 게 사람 들 의 입맛 에 맞 게 만들 어 진 이야기 가 , 수치 를 조금 만 자세히 보 고 문장 을 비틀 어 보 면 완전히 다른 이야기 였 다는 것 을 알 게 될 런지 도 모른다 . 어쩔 수 없이 기존 의 사고 와 안 맞 는 통계 결과 를 가끔 문장 을 묘하 게 왜곡 해서 사람 들 의 눈 에 잘 들어오 는 형태 로 바꿔 버리 는 경우 도 은근히 산재 해 있 기 때문 이 다 . 많 은 이야기 에 ‘ 숫자 ’ 가 들어가 면 객관 적 인 것 마냥 포장 되 고 읽 는 사람 이나 쓰 는 사람 이나 중립 적 으로 판단 하 고 있 다는 지적 허영심 에 사로잡히 게 되 지만 무비판 적 으로 읽 는 숫자 는 이미 알 고 있 는 사고방식 과 편향 이 열 어 준 통로 로 들어오 는 바이러스 와 같 다 . ‘ 팩 트 ’ 와 ‘ 사이다 ’ 는 자극 적 이 고 시원 하 며 소화 를 돕 지만 다량 으로 섭취 하 면 위장 만 상하 고 , 이런 것 을 사람 들 이 많이 섭취 할 수록 별로 세상 을 보 고 현실 을 받아들이 는데 도움 이 되 지 않 는 통계 만 잔뜩 생산 되 고 , 그 사이 사이 에 는 달콤 한 좀 비 통계 들 이 넘실댈 것 이 다 . 그리고 결국 그런 좀 비 통계 들 은 다수 편향 적 의사 결정 들 만 을 낳 을 뿐 이 다 . 물론 다수 편향 에 기대 어 사 는 게 편한 사람 들 이야 자신 의 입맛 에 맞 는 좀 비 통계 에 뇌 를 절이 고 지적 허영 에 빠진 채 신선놀음 을 하 면 되 겠 지만 , 이런 현상 이 언제 까지 갈 지 모르 겠 다는 생각 을 조금 이 라도 한다면 , 혹은 이런 다수 편향 에 조금 이 라도 불편 한 생각 이 드 는 사람 들 이 라면 , 조금 만 더 불편 한 숫자 읽 고 쓰 기 를 시도 해 보 는 것 도 괜찮 을 것 이 다 . 특히 데이터 와 통계 를 만드 는 데 조금 이 라도 기여 하 는 사람 에게 는 이런 조금 더 중립 적 이 고 씁쓸 한 자세 는 필수 적 일 것 이 다 . ( 1 ) 아인슈타인 이 하 지 않 았 지만 아인슈타인 의 명언 으로 알려져 있 다 . ( 출처 : [ 아인슈타인 이 말 합니다 ] , 알베르트 아인슈타인 · 앨리스 칼라 프리스 저 , 김명남 번역 , 에이도스 , 2015 ) ( 2 ) 심지어 이 는 알라딘 서점 의 통계 로 보 면 근거 없 는 이야기 다 ( [ URL ] ( 3 ) 이 내용 은 최근 읽 고 있 는 보이 지 않 는 여자 들 에서 영향 을 받 았 다 .',\n",
       "       \"gram - schmidt ( 그람 - 슈미트 ) 직교 화 . . 오늘 최적화 관련 글 을 읽 다가 gram - schmidt 에 대한 내용 이 나왔 다 . 옛날 학생 때 배웠 던 것 같 긴 한데 기억 이 가물가물 하 다 . 주어진 벡터 들 로부터 수직 인 벡터 들 을 새로 만들 어 내 는 방법 이 란 정도 는 알 고 있 지만 명확 하 지 않 다 . ' 떡 본 김 에 제사 지낸다 ' 고 gram - schmidt 직교 화 에 대해 간단히 정리 해 본다 . 그람 - 슈미트 ( gram - schmidt ) 직교 화 란 ? 주어진 벡터 들 을 이용 해서 서로 수직 인 벡터 들 을 만드 는 방법 이 다 . 좀 더 고상 한 말 로 표현 하 면 주 어 진 벡터 들 에 대한 직교 기저 ( orthogonal basis ) 또는 정규직 교기 저 ( orthonormal basis ) 를 구하 는 과정 이 다 . 그람 - 슈미트 직교 화 ( gram - schmidt orthogonalization ) : 주어진 벡터 v 1 , v 2 , ... 로 부터 이 벡터 들 을 생성 할 수 있 는 직교 기저 ( orthogonal basis ) 를 구하 는 과정 : 주어진 벡터 v 1 , v 2 , ... 로 부터 이 벡터 들 을 생성 할 수 있 는 직교 기저 ( orthogonal basis ) 를 구하 는 과정 그람 - 슈미트 정규 직교 화 ( gram - schmidt orthonormalization ) : 주어진 벡터 v 1 , v 2 , ... 로 부터 이 벡터 들 을 생성 할 수 있 는 정규직 교기 저 ( orthonormal basis ) 를 구하 는 과정 ☞ 기저 , 직교 기저 , 정규직 교기 저 등 의 용어 는 [ 선형 대수학 # 3 ] 고유값 과 고유 벡터 글 참조 그람 - 슈미트 ( gram - schmidt ) 직교 화 수식 주어진 벡터 v 1 , v 2 , ..., vk 에 대해 , 이 벡터 들 을 생성 할 수 있 는 직교 벡터 u 1 , u 2 , ... 들 은 다음 과 같이 얻 어 진다 ( 단 , proj u ( v ) 는 벡터 v 를 벡터 u 에 수직 으로 투영 한 벡터 ) . --- ( 1 ) 이렇게 얻 어 진 u 1 , u 2 , ..., uk 는 서로 수직 ( orthogonal ) 이 고 벡터공간 v = { v 1 , v 2 , ..., vk } 에 대한 직 교기 저 가 된다 . 그리고 이러 한 과정 을 그람 - 슈미트 직교 화 ( orthogonalization ) 라 부른다 . 여기 서 더 나아가 ui 들 을 단위벡터 ( 길이 가 1 인 벡터 ) 로 만들 면 e 1 , e 2 , ..., ek 는 벡터공간 v 의 정규직 교기 저 ( orthonormal basis ) 가 된다 . 그리고 이러 한 과정 을 그람 - 슈미트 정규 직교 화 ( orthonormalization ) 라 부른다 . --- ( 2 ) 그람 - 슈미트 ( gram - schmidt ) 직교 화 원리 그람 - 슈미트 직교 화 원리 는 2 단계 로 설명 할 수 있 다 . 먼저 , 벡터 v 를 이용 해서 u 1 , u 2 , ..., ui 모두 와 수직 인 벡터 를 만드 는 방법 은 v 를 벡터공간 { u 1 , u 2 , ..., ui } 에 투영 시킨 후 v 에서 빼 는 것 이 다 . 즉 , v ' = v - proj { u 1 , ..., ui } ( v ) 는 u 1 , u 2 , ..., ui 모두 와 수직 인 벡터 가 된다 . 그림 1 . gram - schmidt 직교 화 원리 1 벡터공간 { u 1 , ..., ui } 는 수학 적 으로 는 u 1 , ..., ui 의 일차 결합 으로 생성 할 수 있 는 모든 가능 한 벡터 들 의 집합 으로 정의 된다 . 또는 간단 하 게 이 벡터 들 을 모두 포함 하 는 부분공간 ( subspace ) 또는 평면 으로 생각 하 면 된다 . v 를 이 공간 에 투영 한 후 v 에서 빼 면 이 공간 의 모든 벡터 와 수직 인 벡터 가 얻 어 진다 . 다음 으로 벡터 v 를 공간 { u 1 , ..., ui } 에 투영 시킨 벡터 는 아래 그림 과 같이 v 를 u 1 , u 2 , ..., ui 각각 에 투영 시킨 벡터 의 합 으로 구해진다 ( 단 , ui 가 서로 수직 인 경우 ) . 그림 2 . gram - schmidt 직교 화 원리 2 이제 원래 의 식 ( 1 ) 으로 돌아가 보 자 . 지금 까지 내용 을 잘 이해 했 다면 gram - schmidt 직교 화 과정 이 손쉽 게 이해 되 리라 생각 한다 . gram - schmidt 제대로 이해 하 기 ( q & a ) q 1 . 직교 화 도중 에 { u 1 , u 2 , ..., ui } 에 수직 인 벡터 를 새로 생성 할 때 v 를 사용 하 지 않 고 아무 벡터 나 잡 아서 투영 시켜도 되 지 않 을까 ? 왜 굳이 원래 의 vi 들 을 이용 해야 하 는지 ? a . 안 된다 . v 를 사용 해야 한다 . gram - schmidt 직교 화 가 무조건 수직 인 벡터 들 만 만들 어 내 는 방법 이 라고 생각 한다면 그건 오해 이 다 . 입력 v 1 , v 2 , ..., vk 에 대해 gram - schmidt 를 적용 하 여 얻 어 진 u 1 , u 2 , ... 들 은 v 1 , v 2 , ...., vk 를 생성 할 수 있 는 직교 기저 ( orthogonal basis ) 가 된다 . 즉 , u 1 , u 2 , .. 들 은 벡터 v 1 , v 2 , ..., vk 와 동일 한 공간 에 포함 되 면서 이 공간 을 생성 할 수 있 는 벡터 들 이 다 . 그림 1 을 보 자 . 왼쪽 예 에서 3 차원 공간 을 가정 하 면 u 와 수직 인 벡터 는 무한 이 많이 존재 한다 . 그 중 v - proju ( v ) 는 u 와 v 에 의해 결정 되 는 공간 ( 평면 ) 에 속한 벡터 임 을 확인 할 수 있 다 . 즉 , u , v 에 대해 직교 화 로 얻 은 벡터 는 u , v 에 의해 결정 되 는 부분공간 ( subspace ) 에 포함 되 면서 서로 수직 인 벡터 들 이 다 . q 2 . 직교 화 는 입력 벡터 의 수 만 많 으면 무한히 적용 할 수 있 는가 ? 즉 , 무한히 많 은 수 의 서로 수직 인 벡터 들 을 만들 어 낼 수 있 는가 ? a . 그렇 지 않 다 . 상식 적 으로 생각 해도 n 차원 공간 에서 n 개 보다 많 은 서로 수직 인 벡터 들 이 존재 할 순 없 다 . 입력 v 1 , v 2 , ... 벡터 들 이 모두 일차 독립인 경우 에 만 gram - schmidt 로 입력 벡터 의 수 와 동일 한 개수 의 수직 벡터 들 이 만들 어 진다 . 만일 직교 화 과정 도중 에 일차 독립 이 아닌 벡터 가 입력 으로 들어오 면 여기 서 생성 된 u 는 0 벡터 가 된다 . 입력 v 1 , v 2 , ..., vk 까지 는 일차 독립 이 라 하 자 . 그런데 , 새로 들어온 벡터 v k + 1 이 기존 의 v 1 , ..., vk 와 일차 독립 이 아니 라고 하 자 . 즉 , v k + 1 이 v 1 , ..., vk 로 이루어진 공간 에 포함 된 벡터 라고 가정 하 자 . 그러 면 v k + 1 에서 { v 1 , ..., vk } 에 내린 투영 벡터 는 자기 자신 이 된다 . 따라서 u = v k + 1 - proj { v 1 , ..., vk } ( v k + 1 ) = 0 이 된다 . gram - schmidt 과정 도중 에 영벡터 가 나온다면 이 를 무시 하 고 다음 입력 벡터 로 넘어가 거나 또는 차원 의 개수 만큼 수직 벡터 가 얻 어 졌으면 직교 화 과정 을 종료 한다 . by 다크 프로그래머\",\n",
       "       '크롤링 3 beautiful soup 왜 beautiful soup 를 사용 하 는가 ? 매번 웹 사이트 를 방문 해서 데이터 를 수집 하 고 , html 5 lib 를 사용 해서 크롤링 을 해 왔 는데 , html 5 lib 가 나무 구조 여서 차원 이 너무 많 아서 원 하 는 요소 를 뽑 아 오 기 쉽 지 않 았 다 . beautiful soup 를 사용 하 면 원 하 는 요소 를 쉽 게 가져올 수 있 다 . 기존 html 5 lib 을 사용 해서 naver 의 title 가져오 기 from urllib import request import html 5 lib url = \"[ URL ] with request . urlopen ( url ) as f : html = f . read ( ) . decode ( \\' utf - 8 \\') dom = html 5 lib . parse ( html ) head = dom . getchildren ( ) [ 0 ] titles = [ child for child in head . getchildren ( ) if child . tag == \\'{[ URL ] ] title = titles [ 0 ] . text print ( title ) >> naver beautiful soup 를 사용 해서 naver 의 title 가져오 기 from urllib import request from bs 4 import beautifulsoup url = \"[ URL ] with request . urlopen ( url ) as f : html = f . read ( ) . decode ( \\' utf - 8 \\') bs = beautifulsoup ( html , \\' html 5 lib \\') # html 5 를 사용 해서 dom 을 알 아서 만들 어 준다 . # select ( ) 를 사용 하 면 모든 결과 를 리스트 에 담 고 , select _ one ( ) 을 사용 하 면 하나 의 요소 만 반환 title = bs . select _ one ( \\' title \\'). text # selec _ one ( ) 안 에 인자 는 태그 이름 이 아니 라 css 문법 이 다 . print ( title ) >> naver : 훨씬 더 쉽 게 웹 사이트 의 타이틀 을 가지 고 올 수 있 다 ! css ( cascading style sheets ) 정의 마크업 언어 가 웹 사이트 의 몸체 를 담당 한다면 , css 는 옷 과 액세서리 와 같 은 꾸미 는 역할 을 담당 한다고 할 수 있 다 . css 문법 클래스 찾기 . class . classname {} id 찾 기 # id # idname {} 자식 selector > body > . highlight {} body 의 바로 밑 에 자식 ( 직계 자식 ) 중 highlight 클 래스 인 것 body 의 자식 의 자식 중 hightlight 클 래스 인 것 은 해당 안 됨 애 란 이 네 책방 실습 애 란 이 네 애 란 이 네 책방 애 란 이 네 책방 에 오 신 것 을 환영 합니다 . 마음껏 구경 하 세요 . 소설 만화 역사 x 부분 을 다음 과 같이 바꿔 주 세요 ! highlight 클래스 로 바꾸 기 . highlight {} >> \\' 마음껏 구경 하 세요 \\', \\' 만화 \\' >> background 색 이 바뀐다 . welcome 아이디 로 바꾸 기 # welcome {} >> \\' 애 란 이 네 책방 에 오 신 것 을 환영 합니다 . \\' >> background 색 이 바뀐다 . ul 혹은 ul 의 자식 이 면서 hightlight 클 래스 인 것 ul . highlight {} >> \\' 만화 \\' >> background 색 이 바뀐다 . ul 중 에 highlight 클 래스 인 것 ul . highlight {} >> 아무것 도 변하 지 않 음 . 태그 이름 이 ul 이 면서 highlight 클 래스 인 element 가 없 어서 ul 혹은 ul 의 자식 중 li 이 면서 highlight 클 래스 인 것 ul li . highlight {} >> \\' 만화 \\' >> background 색 이 변한다 . 공백 이 없 으면 해당 element 들 중 해당 속성 들 공백 이 있 으면 본인 과 자식 을 포함 하 는 element 들 중 해당 속성 들 을 불러 옴 body 의 직계 자손 의 하위 항목 중 에서 highlight 클 래스 인 element body > . highlight {} >> \\' 마음껏 구경 하 세요 \\' >> background 색 이 변한다 . yes 24 파이썬 검색 결과 목록 추출 하 기 robots . txt 확인 robots . txt user - agent : * disallow : / templates / disallow : / member / allow : / templates 와 member 데이터 만 건들 지 않 으면 ( 그리고 과도 한 트래픽 을 유발 하 지 않 는다면 ) 데이터 를 수집 해도 괜찮 은 것 같 습니다 . 필요 한 패키지 import html 5 lib : 엉망 으로 만들 어 진 html 문서 도 적절히 잘 분석 해서 dom 구조 로 만들 어 줌 . beautifulsoup 4 : ss selector 를 이용 하 여 dom 구조 에서 원 하 는 엘리먼트 들 을 뽑아내 는 기능 을 제공 # html 5 lib 와 beautifulsoup 4 를 설치 하 는 명령어 ( 혹시 안 깔려 있 을 때 대비 ) : # ! pip install html 5 lib beautifulsoup 4 from urllib import request from bs 4 import beautifulsoup import pandas as pd html 받 아 오 기 예스 24 서버 로 http 요청 을 보내 서 html 을 받 아 온 후 파이썬 문자열 ( str ) 로 변환 해 보 겠 습니다 . url = \"[ URL ] with request . urlopen ( url ) as f : html = f . read ( ) . decode ( \\' utf - 8 \\') - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ------------------------- unicodedecodeerror traceback ( most recent call last ) in ( ) 1 url = \"[ URL ] 2 with request . urlopen ( url ) as f : ----> 3 html = f . read ( ) . decode ( \\' utf - 8 \\') unicodedecodeerror : \\' utf - 8 \\' codec can \\' t decode byte 0 xb 4 in position 241 : invalid start byte don \\' t panic 왜 오류 가 발생 했 을까 ? 소스 코드 를 살펴보 니 아래 와 같 은 부분 이 있 습니다 . < meta http - equiv = \" content - type \" content = \" text / html ; charset = euc - kr \" / > utf - 8 이 아닌 euc - kr 을 써야 합니다 . euc - kr 은 오래 전 에 한국 에서 만 쓰이 던 낡 은 방식 이 지만 불행히 도 아직 도 상당수 한국 웹 사이트 에서 이 방식 을 사용 합니다 . url = \"[ URL ] with request . urlopen ( url ) as f : html = f . read ( ) . decode ( \\' euc - kr \\') 사이트 에 따라 utf - 8 또는 euc - kr 로 코드 를 바꿔 주 는 반복 작업 을 하 고 싶 지 않 습니다 . ( 애 란 쌤 이 ) 구글 검색 을 해 보 니 이렇게 쓰 면 된다고 합니다 . url = \"[ URL ] with request . urlopen ( url ) as f : charset = f . headers . get _ content _ charset ( ) html = f . read ( ) . decode ( charset ) html 문자열 을 분석 하 여 dom 구성 하 기 html 5 lib 를 이용 하 여 dom 을 구성 한 후 dom 트리 구조 를 탐색 하 여 원 하 는 정보 를 추출 하 는 코드 를 만들 어도 되 지만 번거 롭 습니다 . beautifulsoup 을 이용 하 면 css 셀 렉터 를 써서 원 하 는 정보 를 쉽 게 추출 해낼 수 있 습니다 . beautifulsoup 은 내부 적 으로 dom 트리 를 구성 하 는데 , 이 때 어떤 분석기 ( parser ) 를 사용 할지 지정 해 줄 수 있 습니다 . 우리 는 html 5 lib 를 쓰 도록 하 겠 습니다 . soup = beautifulsoup ( html , \\' html 5 lib \\') soup 객체 에 는 select _ one ( ) 함수 와 select ( ) 함수 가 있 습니다 . 두 함수 모두 css 셀렉 터로 원 하 는 엘리먼트 를 찾 아 주 는 기능 을 한다는 점 은 같 지만 select _ one ( ) 함수 는 : 처음 으로 발견 한 하나 의 엘리먼트 만 반환 합니다 select ( ) 함수 는 발견 한 모든 엘리먼트 를 리스트 형식 으로 반환 합니다 . print ( len ( soup . select _ one ( \\' a \\'))) print ( len ( soup . select ( \\' a \\'))) print ( soup . select ( \" a \")[ 0 ] == soup . select _ one ( \" a \")) 1 659 true 먼저 상품 리스트 ( div 태그 , class 는 goodslist ) 안 의 상품명 만 추출 해 보 겠 습니다 . title _ elem = soup . select ( \\' div . goodslist p . goods _ name a strong \\') titles = [ ] for i in title _ elem : titles . append ( i . text ) len ( titles ) , titles ( 20 , [\\' do it ! 점프 투 파이썬 \\', \\' 모두 의 파이썬 \\', \\' 밑바닥 부터 시작 하 는 딥 러닝 \\', \\' 파이썬 을 이용 한 머신 러닝 , 딥 러닝 실전 개발 입문 \\', \\' 파이썬 과 케 라스 를 이용 한 딥 러닝 / 강화 학습 주식 투자 \\', \\' 모두 의 알고리즘 with 파이썬 \\', \\' 파이썬 라이브러리 를 활용 한 머신 러닝 \\', \\' 파이썬 으로 데이터 주무르 기 \\', \\' 파이썬 자연어 처리 의 이론 과 실제 \\', \\' 파이썬 gui 프로그래밍 쿡 북 2 / e \\', \\' 처음 시작 하 는 파이썬 \\', \\' hello coding 한입 에 쏙 파이썬 \\', \\' 초보 자 를 위한 파이썬 200 제 \\', \\' 한 권 으로 배우 는 파이썬 기초 & 알고리즘 사고 법 \\', \\' 파이썬 과 케 라스 로 배우 는 강화 학습 \\', \\' 파이썬 을 활용 한 금융 공학 레시피 \\', \\' 파이썬 을 이용 한 웹 크롤링 과 스 크레이 핑 \\', \\' 파이썬 라이브러리 를 활용 한 데이터 분석 \\', \\' 파이썬 으로 배우 는 알고리즘 트레이딩 \\', \\' 블록 과 함께 하 는 파이썬 딥 러닝 케 라스 \\']) 다음 으로 상품 가격 ( 할인 이 적용 된 가격 ) 을 추출 해 보 겠 습니다 . price _ elements = soup . select ( \\' div . goodslist p . goods _ price strong \\') prices = [ i . text for i in price _ elements ] len ( prices ) , prices ( 20 , [\\' 16 , 920 원 \\', \\' 10 , 800 원 \\', \\' 21 , 600 원 \\', \\' 27 , 000 원 \\', \\' 22 , 500 원 \\', \\' 14 , 400 원 \\', \\' 27 , 000 원 \\', \\' 24 , 750 원 \\', \\' 31 , 500 원 \\', \\' 31 , 500 원 \\', \\' 27 , 000 원 \\', \\' 13 , 500 원 \\', \\' 18 , 000 원 \\', \\' 27 , 000 원 \\', \\' 24 , 300 원 \\', \\' 25 , 200 원 \\', \\' 27 , 000 원 \\', \\' 29 , 700 원 \\', \\' 36 , 000 원 \\', \\' 22 , 500 원 \\']) 이런 ! 사람 이 읽 기 쉽 도록 세 자리 수 마다 쉼표 를 삽입 한 데 다 가격 뒤 에 \\' 원 \\' 이 붙 어 있 습니다 . 또한 가격 데이터 의 타입 이 숫자 ( int ) 가 아니 라 문자열 입니다 . 이대로 라면 상품 가격 을 통계 적 으로 분석 하 는 등 , 크롤링 한 데이터 를 이후 에 활용 하 는 데 에 별도 의 전처리 과정 이 필요 해 불편 해질 것 입니다 . 쉼표 와 \\' 원 \\' 을 제거 하 고 , 데이터 타입 을 int 로 변환 해 줍시다 . 코드 1 과 2 는 실질 적 으로 동일 한 기능 을 하 며 동일 한 결과물 을 생 성 하나 , 2 가 보다 깔끔 합니다 . # 코드 1 prices _ tidy = [ ] for price in prices : price _ nocomma = price . replace ( \\',\\', \\'\\') price _ nowon = price _ nocomma [ : - 1 ] prices _ tidy . append ( price _ nowon ) prices _ tidy [ \\' 16920 \\', \\' 10800 \\', \\' 21600 \\', \\' 27000 \\', \\' 22500 \\', \\' 14400 \\', \\' 27000 \\', \\' 24750 \\', \\' 31500 \\', \\' 31500 \\', \\' 27000 \\', \\' 13500 \\', \\' 18000 \\', \\' 27000 \\', \\' 24300 \\', \\' 25200 \\', \\' 27000 \\', \\' 29700 \\', \\' 36000 \\', \\' 22500 \\'] # 코드 2 prices _ tidy = [ int ( i . replace ( \\',\\', \\'\\')[:- 1 ] ) for i in prices ] prices _ tidy [ 16920 , 10800 , 21600 , 27000 , 22500 , 14400 , 27000 , 24750 , 31500 , 31500 , 27000 , 13500 , 18000 , 27000 , 24300 , 25200 , 27000 , 29700 , 36000 , 22500 ] titles 와 prices _ tidy , 두 리스트 로 데이터 프레임 을 만들 어 봅시다 . df = pd . dataframe ( {\" title \": titles , \" price \": prices _ tidy }, columns =[\\' title \\', \\' price \\' ] ) df . head ( ) title price 0 do it ! 점프 투 파이썬 16920 1 모두 의 파이썬 10800 2 밑바닥 부터 시작 하 는 딥 러닝 21600 3 파이썬 을 이용 한 머신 러닝 , 딥 러닝 실전 개발 입문 27000 4 파이썬 과 케 라스 를 이용 한 딥 러닝 / 강화 학습 주식 투자 22500 수고 하 셨 습니다 ! yes 24 베스트셀러 목록 추출 하 기 수업 에서 는 yes 24 \\' 파이썬 \\' 키워드 검색 결과 창 을 대상 으로 실습 을 했 던 것 같 은데 , 수업 자료 와 애 란 쌤 이 올려 주 신 콜 랩 노트북 에 는 베스트셀러 페이지 목록 추출 실습 으로 되 어 있 어서 내용 을 추가 했 습니다 . 사실 우리 가 수업 시간 에 배우 지 않 은 내용 이 있 을 가능 성 이 있 어 애 란 쌤 이 올려 주 신 콜 랩 노트북 내용 을 그대로 복사 해 왔 습니다 . # html 5 lib 와 beautifulsoup 4 를 설치 하 는 명령어 ( 혹시 안 깔려 있 을 때 대비 ) : # ! pip install html 5 lib beautifulsoup 4 from urllib import request from bs 4 import beautifulsoup f 12 를 눌러 크롬 의 개발자 도구 를 통해 문서 를 살펴보 니 베스트셀러 를 담 고 있 는 영역 은 id 가 \" bestlist \" 인 div 엘리먼트 의 자식 인 ol 엘리먼트 입니다 . ol 엘리먼트 에 속한 li 엘리먼트 하나하나 가 각 책 에 대한 정보 를 담 고 있 습니다 . 따라서 아래 와 같이 쓰 면 책 40 권 에 해당 하 는 li 엘리먼트 40 개 가 나와야 합니다 . url = \"[ URL ] with request . urlopen ( url ) as f : charset = f . headers . get _ content _ charset ( ) html = f . read ( ) . decode ( charset ) bs = beautifulsoup ( html , \\' html 5 lib \\') len ( bs . select ( \\'# bestlist > ol > li \\')) 40 잘 되 는 것 을 확인 하 였 습니다 . 각 li 안 에 는 p 태그 가 여러 개 있 는데 이 중 세 번 째 p 엘리먼트 안 에 책 이름 이 담겨 있 고 , 가격 을 담 고 있 는 p 엘리먼트 에 는 price 클래스 가 붙 어 있 습니다 . < li > < p > . .. < p > . .. < p > < a href = \"...\" > 책 이름 . .. < p class = \" price \" > < strong > 가격 책 이름 을 뽑아내 볼까요 ? bs . select ( \\'# bestlist > ol > li p : nth - child ( 3 ) a \\') - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ------------------------- notimplementederror traceback ( most recent call last ) in ( ) ----> 1 bs . select ( \\'# bestlist > ol > li p : nth - child ( 3 ) a \\') / usr / local / lib / python 3 . 6 / dist - packages / bs 4 / element . py in select ( self , selector , _ candidate _ generator , limit ) 1449 else : 1450 raise notimplementederror ( -> 1451 \\' only the following pseudo - classes are implemented : nth - of - type . \\') 1452 1453 elif token == \\'*\\': notimplementederror : only the following pseudo - classes are implemented : nth - of - type . 각 li 의 자식 중 세 번 째 자식 인 p 를 찾 으려고 했으나 해당 셀 렉터 문법 은 beautifulsoup 4 에서 아직 구현 하 지 않 았 다며 에러 가 발생 합니다 . 아쉽 지만 각 책 에 해당 하 는 li 엘리먼트 들 까지 만 찾 아서 변수 에 담 은 후 각 li 엘리먼트 에서 원 하 는 정보 를 뽑아내 는 코드 를 따로 만들 어야 합니다 . books = bs . select ( \\'# bestlist > ol > li \\') titles = [ ] for book in books : # \" p : nth - of - type ( 3 ) \" 은 li 의 자식 중 세 번 째 p 엘리먼트 를 찾 아 줍니다 . title = book . select _ one ( \\' p : nth - of - type ( 3 ) a \\'). text titles . append ( title ) titles [ \\' 역사 의 역사 \\', \\' 죽 고 싶 지만 떡볶이 는 먹 고 싶 어 \\', \\' 열 두 발자국 \\', \\' 설민석 의 한국 사 대 모험 7 \\', \\' 돌이킬 수 없 는 약속 \\', \\' 나 는 오늘 도 경제 적 자유 를 꿈꾼다 \\', \\' 모든 순간 이 너 였 다 \\', \\' 언어 의 온도 ( 100 만 부 돌파 기념 양장 특별 판 ) \\', \\' 곰돌이 푸 , 행복 한 일 은 매일 있 어 \\', \\' 사피엔스 \\', \\' 원피스 one piece 89 \\', \\' 나 는 나 로 살 기 로 했 다 \\', \\' 아몬드 \\', \\' 고 양 이 1 \\', \\' 한때 소중 했 던 것 들 \\', \\' 개인 주의자 선언 \\', \\' 나미 야 잡화점 의 기적 ( 100 만 부 기념 특별 한정판 ) \\', \\' 고 양 이 2 \\', \\' 에듀 윌 한국사 능력 검정 시험 2 주 끝장 고급 개정판 3 . 0 \\', \\' 혼자 공부 법 \\', \\' 해 커스 토익 실전 1000 제 reading 1 문제집 \\', \\' 앨리스 , 너 만 의 길 을 그려봐 \\', \\' 2019 전 한길 한 국사 필기 노트 + 빵꾸 노트 \\', \\' 설민석 의 한국 사 대 모험 6 \\', \\' 행복 해 지 는 연습 을 해요 \\', \\' 해 커스 토익 기출 보카 \\', \\' 설민석 의 한국 사 대 모험 1 \\', \\' 82 년 생 김지영 \\', \\' 하마터면 열심히 살 뻔 했 다 \\', \\' 어디 서 살 것 인가 \\', \\' 해 커스 토익 실전 1000 제 listening 1 문제집 \\', \\' 해 커스 토익 reading ( 2018 ) \\', \\' 어떻 게 살 것 인가 \\', \\' 2019 선재 국어 세트 \\', \\' 곰돌이 푸 , 서두르 지 않 아도 괜찮 아 \\', \\' 열혈 강호 76 \\', \\' 있 으려나 서점 \\', \\' 내게 무해 한 사람 \\', \\' 마법천자문 42 \\', \\' 대한민국 아파트 부 의 지도 \\'] 비슷 한 방법 으로 가격 도 뽑 아 냅시다 . books = bs . select ( \\'# bestlist > ol > li \\') titles = [ ] prices = [ ] for book in books : # \" p : nth - of - type ( 3 ) \" 은 li 의 자식 중 세 번 째 p 엘리먼트 를 찾 아 줍니다 . title = book . select _ one ( \\' p : nth - of - type ( 3 ) a \\'). text titles . append ( title ) price = book . select _ one ( \\' p . price \\'). text prices . append ( price ) prices [ \\' 14 , 400 원 ( 10 %+ 5 %)\\', \\' 12 , 420 원 ( 10 %+ 5 %)\\', \\' 15 , 120 원 ( 10 %+ 5 %)\\', \\' 9 , 450 원 ( 10 %+ 5 %)\\', \\' 13 , 500 원 ( 10 %+ 5 %)\\', \\' 15 , 120 원 ( 10 %+ 5 %)\\', \\' 12 , 420 원 ( 10 %+ 5 %)\\', \\' 12 , 420 원 ( 10 %+ 5 %)\\', \\' 10 , 800 원 ( 10 %+ 5 %)\\', \\' 19 , 800 원 ( 10 %+ 5 %)\\', \\' 4 , 500 원 ( 10 %+ 5 %)\\', \\' 12 , 420 원 ( 10 %+ 5 %)\\', \\' 10 , 800 원 ( 10 %+ 5 %)\\', \\' 11 , 520 원 ( 10 %+ 5 %)\\', \\' 12 , 600 원 ( 10 %+ 5 %)\\', \\' 12 , 150 원 ( 10 %+ 5 %)\\', \\' 13 , 320 원 ( 10 %+ 5 %)\\', \\' 11 , 520 원 ( 10 %+ 5 %)\\', \\' 18 , 900 원 ( 10 %+ 5 %)\\', \\' 12 , 600 원 ( 10 %+ 5 %)\\', \\' 10 , 710 원 ( 10 %+ 5 %)\\', \\' 12 , 420 원 ( 10 %+ 5 %)\\', \\' 18 , 900 원 ( 10 %)\\', \\' 9 , 450 원 ( 10 %+ 5 %)\\', \\' 13 , 050 원 ( 10 %+ 5 %)\\', \\' 11 , 610 원 ( 10 %+ 5 %)\\', \\' 8 , 820 원 ( 10 %+ 5 %)\\', \\' 11 , 700 원 ( 10 %+ 5 %)\\', \\' 13 , 500 원 ( 10 %+ 5 %)\\', \\' 14 , 400 원 ( 10 %+ 5 %)\\', \\' 10 , 710 원 ( 10 %+ 5 %)\\', \\' 16 , 920 원 ( 10 %+ 5 %)\\', \\' 13 , 500 원 ( 10 %+ 5 %)\\', \\' 46 , 800 원 ( 10 %)\\', \\' 12 , 420 원 ( 10 %+ 5 %)\\', \\' 4 , 050 원 ( 10 %+ 5 %)\\', \\' 11 , 520 원 ( 10 %+ 5 %)\\', \\' 12 , 150 원 ( 10 %+ 5 %)\\', \\' 8 , 820 원 ( 10 %+ 5 %)\\', \\' 15 , 120 원 ( 10 %+ 5 %)\\'] 가격 을 정수 로 바꿔 주 면 좋 겠 습니다 . 우선 괄호 안 에 담긴 내용 을 제거 해 볼까요 ? 파이썬 문자열 객체 에 는 split ( ) 함수 가 있 습니다 . 이 함수 를 써서 여 는 괄호 \"(\" 문자 를 기준 으로 문자열 을 둘 로 나눈 뒤 앞 부분 ( 0 번 째 조각 ) 을 취하 면 괄호 뒷 부분 을 제거 할 수 있 습니다 . \" 14 , 000 원 ( 10 %+ 5 %)\". split ( \"(\") [ \\' 14 , 000 원 \\', \\' 10 %+ 5 %)\\'] \" 14 , 000 원 ( 10 %+ 5 %)\". split ( \"(\")[ 0 ] \\' 14 , 000 원 \\' \" 원 \" 이 라는 글자 와 쉼표 를 제거 하 면 숫자 만 남 습니다 . \" 14 , 000 원 ( 10 %+ 5 %)\". split ( \"(\")[ 0 ] . replace ( \\' 원 \\', \\'\\'). replace ( \\',\\', \\'\\') \\' 14000 \\' 이제 숫자 만 남 은 문자열 들 을 정수 로 바꿔 줍시다 . int ( \" 14 , 000 원 ( 10 %+ 5 %)\". split ( \"(\")[ 0 ] . replace ( \\' 원 \\', \\'\\'). replace ( \\',\\', \\'\\')) 14000 해당 코드 를 함수 로 만들 어 볼까요 ? def to _ int ( raw ) : nums = raw . split ( \"(\")[ 0 ] . replace ( \\' 원 \\', \\'\\'). replace ( \\',\\', \\'\\') return int ( nums ) to _ int ( \" 14 , 000 원 ( 10 %+ 5 %)\") 14000 이제 원래 코드 에 적용 해 봅시다 . books = bs . select ( \\'# bestlist > ol > li \\') titles = [ ] prices = [ ] for book in books : # \" p : nth - of - type ( 3 ) \" 은 li 의 자식 중 세 번 째 p 엘리먼트 를 찾 아 줍니다 . title = book . select _ one ( \\' p : nth - of - type ( 3 ) a \\'). text titles . append ( title ) price = book . select _ one ( \\' p . price \\'). text prices . append ( to _ int ( price ) ) prices [ 14400 , 12420 , 15120 , 9450 , 13500 , 15120 , 12420 , 12420 , 10800 , 19800 , 4500 , 12420 , 10800 , 11520 , 12600 , 12150 , 13320 , 11520 , 18900 , 12600 , 10710 , 12420 , 18900 , 9450 , 13050 , 11610 , 8820 , 11700 , 13500 , 14400 , 10710 , 16920 , 13500 , 46800 , 12420 , 4050 , 11520 , 12150 , 8820 , 15120 ] 리스트 컴프리 헨 션 을 써서 코드 를 줄여 볼까요 ? books = bs . select ( \\'# bestlist > ol > li \\') titles = [ b . select _ one ( \\' p : nth - of - type ( 3 ) a \\'). text for b in books ] prices = [ to _ int ( b . select _ one ( \\' p . price \\'). text ) for b in books ] dataframe 에 넣 어 봅시다 . import pandas as pd df = pd . dataframe ( {\\' title \\': titles , \\' price \\': prices }, columns =[\\' title \\', \\' price \\'] ) df . head ( ) title price 0 역사 의 역사 14400 1 죽 고 싶 지만 떡볶이 는 먹 고 싶 어 12420 2 열 두 발자국 15120 3 설민석 의 한국 사 대 모험 7 9450 4 돌이킬 수 없 는 약속 13500 전체 코드 를 한 번 에 모아 볼까요 ? from urllib import request import pandas as pd from bs 4 import beautifulsoup url = \"[ URL ] with request . urlopen ( url ) as f : charset = f . headers . get _ content _ charset ( ) html = f . read ( ) . decode ( charset ) def to _ int ( raw ) : nums = raw . split ( \"(\")[ 0 ] . replace ( \\' 원 \\', \\'\\'). replace ( \\',\\', \\'\\') return int ( nums ) bs = beautifulsoup ( html , \\' html 5 lib \\') books = bs . select ( \\'# bestlist > ol > li \\') titles = [ b . select _ one ( \\' p : nth - of - type ( 3 ) a \\'). text for b in books ] prices = [ to _ int ( b . select _ one ( \\' p . price \\'). text ) for b in books ] df = pd . dataframe ( {\\' title \\': titles , \\' price \\': prices }, columns =[\\' title \\', \\' price \\'] ) df . head ( ) title price 0 역사 의 역사 14400 1 죽 고 싶 지만 떡볶이 는 먹 고 싶 어 12420 2 열 두 발자국 15120 3 설민석 의 한국 사 대 모험 7 9450 4 돌이킬 수 없 는 약속 13500 url 만 넣 으면 beautifulsoup 객체 를 만들 어 주 는 코드 도 함수 로 만들 면 좋 겠 습니다',\n",
       "       '버팀목 전세 자금 대출 이 란 근로자 와 서민 의 주거 안정 을 위해 주택 도시 기금 을 활용 해 낮 은 금리 로 안정 적 인 주택 전세 자금 대출 을 받 을 수 있 는 상품 입니다 . 따라서 조건 이 까다롭 긴 하 지만 본인 이 자격 조건 이 된다면 일반 금융 권 전세 대출 을 이용 하 는 것 보다 훨씬 유리 합니다 . 또한 대출 을 받 을 때 집 주인 동의 가 필요 없 다는 것 도 큰 장점 이 죠 . 버팀목 전세 대출 조건 대출 신청 일 현재 ▲ 무주택 세대주 로서 대출 대상 주택 이 ▲ 임차 보증금 2 억 원 이하 ( 단 , 서울 , 경기 , 인천 등 의 수도 권 지역 은 3 억 원 이하 ) ▲ 전용 면적 85 ㎡ 이하 ( 수도 권 을 제외 한 도시 지역 이 아닌 읍 , 또는 면 지역 은 100 ㎡ 이하 ) 에 임대차 계약 을 체결 하 고 ▲ 임차 보증금 의 5 % 이상 을 지불 한 경우 에 해당 되 면 이용 이 가능 합니다 . 임차 보증금 의 5 % 이상 을 지불 해야 한다는 것 은 보통 전세 계약 을 할 때 10 % 정도 의 계약금 을 내 니까 계약 을 한 후 에 신청 하 라는 것 이 죠 . 대출자 격 좀 더 세부 적 으로 살펴보 면 , 첫째 , 대출 신청 일 현재 단독 세대주 를 제외 한 만 19 세 이상 인 세대주 ( 단 , 만 25 세 미만 의 미혼 인 자녀 가 직계 존속 을 부양 하 는 조건 으로 신청 하 는 경우 세대 합가 기간 ( 주민 등록 등 본상 합가 일 기준 ) 연속 하 여 6 개월 이상 인 경우 ) 또는 세대 주로 인정 되 는 사람 이 해당 됩니다 . 여기 서 세대 주라 함 은 주택 공급 에 관한 규칙 제 2 조제 8 항 에 따라 세대 별 주민 등록 표상 에 직계 존속 , 배우자 ( 배우자 의 직계 존속 포함 ) 또는 직계 비속 인 세대원 으로 이루어진 세대 의 세대주 를 말 합니다 . 세대주 의 세대원 인 배우자 대출 신청 일 로부터 3 개월 이내 에 결혼 으로 인하 여 세대 주로 예정 된 자 민법 상 미성년 인 형제 , 자매 로 구성 된 세대 의 세대주 만 25 세 이상 인 단독 세대주 ( 다만 , 행복 주택 에 입주 하 는 만 19 세 이상 의 대학 생 및 사회 초년생 을 포함 ) 만 19 세 이상 만 25 세 미만 의 단독 세대주 ( 청년 전용 버팀목 대출 ) 단 , 청년 전용 버팀목 대출 은 본인 의 소득 수준 , 상환 부담 , 주택 임차 현황 등 을 고려 하 여 보증금 3 천만 원 , 임차 전용 면적 60 ㎡ 이하 주택 에 2 천만 원 한도 로 지원 둘째 , 대출 신청 일 현재 세대주 로서 세대주 를 포함 한 세대원 전원 이 무주택자 여야 합니다 . 서민 을 위한 상품 의 취지 에 맞 게 무주택자 를 대상 으로 합니다 . 셋째 , 대출 신청인 과 배우자 의 연소 득 합산 금액 이 5 천만 원 이하 여야 합니다 . 단 , 신혼 가구 , 혁신 도시 이전 공공 기관 종사자 또는 타 지역 으로 이주 하 는 재 개발 구역 내 세입자 인 경우 6 천만 원 이하 로 완화 됩니다 . 역시 서민 금융 상품 답 게 소득 기준 을 정해 놓 았 습니다 . 넷째 , 1 주택 에 2 가구 이상 이 독립 된 주거 공간 ( 출입문 공유 포함 ) 형태 로 거주 하 는 경우 에 도 지원 받 을 수 있 습니다 . 대출 대상 주택 버팀목 전세 대출 을 받 기 위해서 는 앞서 말씀 드린 자격 조건 외 에 도 대상 주택 의 범위 에 해당 되 어야 합니다 . 임차 전용 면적 이 85 ㎡ ( 수도 권 을 제외 한 도시 지역 이 아닌 읍 또는 면 지역 은 100 ㎡) 이하 주택 ( 주거 용 오피스텔 은 85 ㎡ 이하 포함 ) 이 어야 합니다 . 또한 , 임차 하 려는 는 건물 이 등기부 등 본상 주택 이 어야 하 고 , 만약 복합 용도 ( 근린 생활 시설 등 ) 로서 , 사무실 , 점포 , 상가 등 으로 되 어 있 으면 대출 이 불 가능 합니다 . 대출 금리 버팀목 전세 대출 이율 은 부부 합산 연소 득 과 보증금 액수 에 따라 달라지 는데요 . 연 2 . 3 % ~ 2 . 9 % 수준 입니다 . 고정 금리 도 선택 할 수 있 다면 좋 겠 지만 , 아쉽 게 도 변동 금리 입니다 . 국토 교통부 고시 금리 ( 변동 금리 ) 부부 합산 연소 득 보증금 : 5 천만 원 이하 보증금 : 5 천만 초과 ~ 1 억 원 이하 보증금 : 1 억 원 초과 2 천만 원 이하 연 2 . 3 % 연 2 . 4 % 연 2 . 5 % 2 천만 원 초과 ~ 4 천만 원 이하 연 2 . 5 % 연 2 . 6 % 연 2 . 7 % 4 천만 원 초과 ~ 6 천만 원 이하 연 2 . 7 % 연 2 . 8 % 연 2 . 9 % 그래도 일반 금융 권 에 비해서 는 상당히 저금리 로 이용 할 수 있 습니다 . 추가 로 아래 와 같 은 우대금리 혜택 을 받 을 수 있 습니다 . 우대금리 부부 합산 연소 득 4 천만 원 이하 로서 , 기초 생활 수급 권 자 · 차상 위계 층 · 한 부모 가족 확인서 를 발급 받 은 가구 는 연 1 % p 의 우대금리 혜택 을 받 을 수 있 습니다 . 신혼 가구 는 0 . 7 % p , 다 자녀 는 0 . 5 % p , 다 문화 · 장애 우 · 노인 부양 · 고령자 가구 는 연 0 . 2 % p 의 우대금리 를 받 을 수 있 습니다 . 단 , 노인 부양 가구 는 신 규시 부터 계속 해서 부양 하 는 경우 만 금리 우대 가 가능 합니다 . 2018 년 1 월 29 일 부터 아동 이 있 는 저소득층 의 주거비 부담 경감 을 위해 부부 합산 연소 득 2 천만 원 이하 인 2 자녀 가구 는 0 . 2 % 우대금리 를 적용 받 을 수 있 습니다 . 이 우대금리 는 다음 의 추가 금리 우대 와 는 달리 중복 적용 이 안 됩니다 . 추가 금리 우대 주거 안정 월세 대출 성실 납부 자 는 연 0 . 2 % p 의 추가 금리 우대 를 받 을 수 있 습니다 . 또한 , 국토 교통부 부동산 전자 계약 시스템 을 활용 하 여 주택 의 임대차 계약 을 체결 하 면 2018 년 12 월 까지 한시 적 으로 0 . 1 % p 의 금리 우대 를 받 을 수 있 습니다 . 신혼 부부 는 기존 신혼 우대금리 0 . 7 % p 에 추가 로 최대 0 . 4 % p 까지 추가 우대 받 을 수 있 습니다 . ( 2019 년 1 월 29 일 시행 ) 추가 우대금리 는 중복 적용 을 받 을 수 있 습니다 . 대 출한 도 대출 은 전 ( 월 ) 세 계약서 상 임차 보증금 의 70 % 이내 로 아래 와 같이 받 을 수 있 으나 , 대출 한도 는 신청인 의 소득 · 부채 · 신용 도 등 에 따라 달라질 수 있 습니다 . 단 , 2018 년 1 월 29 일 부터 혼인 5 년 이내 신혼 부부 는 대출 비율 이 10 % p 상향 되 어 임대 보증금 의 80 % 까지 이용 이 가능 합니다 . 구분 일반 가구 다자녀 신혼 가구 수도 권 ( 서울 , 경기 , 인천 ) 최대 1 억 2 천만 원 최대 1 억 4 천만 원 최대 1 억 7 천만 원 그 외 지역 최대 8 천만 원 최대 1 억 원 최대 1 억 원 3 천만 원 대출 기간 및 상환 방법 대출 기간 은 기본 2 년 에 4 회 를 연장 할 수 있 어 최장 10 년 까지 가능 합니다 . 주택 도시 보증 공사 의 전세금 안심 대출 보증서 는 최대 2 년 1 개월 로 4 회 를 연장 하 면 최장 10 년 5 개월 간 보증 을 받 을 수 있 습니다 . 상환 방법 은 일시 상환 또는 혼합 상환 이 가능 한데요 . 혼합 상환 방식 이 란 대출 기간 중 원금 일부 ( 10 %) 를 나누 어 갚 고 잔여 원금 을 만기 에 일시 상환 하 는 방식 입니다 . 이 경우 한국 주택 금융 공사 보증서 이용 시 보증 수수료 의 최대 0 . 1 % p 를 인하 받 을 수 있 습니다 . 버팀목 전세 자금 대출 연장 기한 을 연장 하 기 위해서 는 기한 을 연장 할 때 마다 최초 대출금 의 10 % 이상 상환 하 거나 상환 이 어려울 경우 에 는 연 0 . 1 % p 의 금리 를 가산 합니다 . 그리고 기한 을 연장 할 때 마다 현재 임차 보증금 을 기준 으로 금리 를 재산 정하 게 됩니다 . 버팀목 전세 대출 보증료 버팀목 전세 대출 의 장점 중 하나 는 중도 상환 수수료 가 없 다는 것 입니다 . 그러나 인지세 ( 고객 / 은행 각 50 % 부담 ) 와 보증료 는 비용 이 있 습니다 . 만약 , 장애 인 가구 나 다자녀 가구 , 다 문화 가구 등 의 사회 배려 계층 에 해당 된다면 보증료 율 을 할인 받 을 수 있 습니다 . 주택 도시 보증 공사 전세금 안심 대출 보증서 보증료 : 대 출금액 의 0 . 05 % + 전세금 반환 보증금 액 의 0 . 128 %( 아파트 ) , 0 . 154 %( 그 외 주택 ) 한국 주택 금융 공사 주택 금융 신용 보증서 보증료 : 0 . 12 %( 임차 보증금 1 억 원 이하 ) , 0 . 15 %~ 0 . 22 %( 임차 보증금 1 억 원 초과 ~ 4 억 원 이하 ) 대출 신청 방법 및 구비 서류 버팀목 전세 대출 은 직접 은행 에 방문 해서 상담 을 받 고 신청 할 수 있 습니다 . 취급 은행 은 우리 은행 , kb 국민은행 , ibk 기업 은행 , nh 농협 , 신한은행 , keb 하나 은행 에서 신청 하 실 수 있 습니다 . 그런데 버팀목 전세 자금 대출 은 신청 할 수 있 는 기간 이 정해져 있 습니다 . 신규 대출 이 라면 임대차 계약서 상 입 주일 과 주민 등록 등 본상 전입 일 중 빠른 날짜 로부터 3 개월 이내 에 대출 을 신청 해야 하 고 , 추가 대출 의 경우 에 는 주민 등록 등 본 상 전입 일 로부터 1 년 이상 , 기존 대출 실행 일 로부터 1 년 이상 경과 하 고 계약 갱 신일 로부터 3 개월 이내 에 신청 해야 합니다 . 버팀목 전세 자금 대출 서류 확정 일자 부 임대차 계약서 임차 보증금 의 5 % 이상 납입 한 영수증 주민 등록 등본 ( 최근 5 개년 주소 변동 이력 이 포함 된 1 개월 이내 발 급분 ) 필요 시 주민 등록 초본 , 가족 관계 증명서 등 ( 1 개월 이내 발급 분 ) 대상 주택 등기 사항 전부 증명서 ( 구 등기부 등본 ) 소득 확인 서류 – 원천 징수 영수증 , 소득 금액 증명 원 , 신고 사실 없 음 “ 사실 증명 원 ” ( 무소득 자 ) 등 단 , 재직 기간 1 년 미만 인 근로 소득 자 의 경우 급여 통장 사본 등 제출 재직 확인 서류 – 건강 보험 자격 득실 확인 서 , 사업자 등록 증명 원 등 기타 필요 시 요청 서류 버팀목 전세 자금 대출 은 행복 주택 입주 예정자 도 신청 이 가능 합니다 . 만 19 세 이상 단독 세대 주인 대학 생 뿐 아니 라 사회 초년생 도 버팀목 전세 대출 을 신청 할 수 있 으니 참고 하 셔서 이용 하 시 면 좋 을 것 같 습니다 . 더불 어 같 은 주택 도시 기금 으로 운용 하 는 주거 안정 월세 대출 과 도 상당히 비슷 한 부분 이 많 습니다 . 함께 참고 하 시 기 바랍니다 .',\n",
       "       '여기 에서 git - scm 를 설치 해야 한다 . 그냥 웬만 하 면 기본 옵션 그대로 계속 next 하 면 될 것 이 다 . 설치 가 끝난 다음 에 는 git bash 가 있 을 텐데 그걸 켜 거나 아니 면 cmd 창 에서 git config -- global user . name username git config -- global user . email user @ email . mail 이렇게 세팅 해 줘야 한다 . 그 다음 에 vscode 를 실행 하 면 저절로 git 를 찾 아 줘서 기능 을 쓸 수 있 다 .',\n",
       "       '이번 포스팅 은 앞 의 게시 글 을 토대 로 웹 크롤링 을 위한 환경 설정 후 scrapy 를 이용 하 여 뉴스 기사 에 대한 크롤링 을 하 여 json , csv , mongodb 에 저장 하 는 방법 에 대한 글 이 다 . 1 . robots . txt ( 로봇 배제 표준 ) 웹 크롤링 에 앞서 크롤링 하 고자 하 는 사이트 가 크롤링 이 가능 한지 아닌지 부터 알 아 보 아야 한다 . 이 를 확인 할 수 있 는 것 이 바로 \\' 로봇 배제 표준 \\' 이라고 하 고 \\' robots . txt \\' 에서 확인 할 수 있 다 . 해당 사이트 주소 뒤 에 \\'/ robots . txt \\' 를 입력 하 면 된다 . 로봇 배제 표준 은 웹 사이트 에 로봇 이 접근 하 는 것 을 방지 하 기 위한 규약 으로 , 일반 적 으로 접근 제한 에 대한 설명 을 robots . txt 에 기술 한다 . 이 규약 은 1994 년 6 월 에 처음 만들 어 졌 고 , 아직 이 규약 에 대한 rfc 는 없 다 . 이 규약 은 권고 안 이 며 , 로봇 이 robots . txt 파일 을 읽 고 접근 을 중지 하 는 것 을 목적 으로 한다 . 따라서 , 접근 방지 설정 을 하 였 다고 해도 , 다른 사람 들 이 그 파일 에 접근 할 수 있 다 . 출처 : [ URL ] 1 ) 네이버 ( naver ) 뉴스 ( [ URL ] 네이버 뉴스 의 경우 아래 와 같이 모든 로봇 을 차단 하 고 있 기 때문 에 크롤링 이 가능 하 지 않 다 . user - agent : yeti allow : / main / imagemontage disallow : / user - agent : * disallow : / 2 ) 다음 ( daum ) 뉴스 ( [ URL ] 다음 뉴스 는 newsview 만 제외 하 고 로봇 의 접근 을 허용 하 기 때문 에 크롤링 이 가능 하 다 . user - agent : * allow : / disallow : / */ newsview 따라서 , 다음 뉴스 에서 중앙일보 - 정치 기사 를 크롤링 하 기 로 했 다 . 2 . scrapy 프로젝트 생성 뉴스 를 크롤링 할 scrapy 프로젝트 를 아래 와 같이 생성 한다 . 1 2 3 4 5 6 7 8 9 10 # 웹 크롤링 가상 환경 으로 진입 cjh @ cjhui - macbook - pro : ~$ source activate crawler # scrapy 프로젝트 생성 ( crawler ) cjh @ cjhui - macbook - pro : ~$ scrapy startproject newscrawling new scrapy project \\' newscrawling \\' , using template directory \\'/ users / cjh / anaconda / envs / crawler / lib / python 3 . 5 / site - packages / scrapy / templates / project \\' , created in : / users / cjh / newscrawling you can start your first spider with : cd newscrawling scrapy genspider example example . com colored by color scripter cs 위 와 같이 프로젝트 를 생성 한 뒤 경로 를 따라 들어가 보 면 아래 와 같 은 \\' spider \\' 폴더 와 파일 들 을 확인 할 수 있 다 . \\' spider \\' 폴더 와 \\' items . py \\', \\' pipelines . py \\', 그리고 \\' settings . py \\' 의 역할 은 여기 서 확인 할 수 있 다 . 3 . 크롤링 할 페이지 구조 파악 하 기 먼저 소스 코드 를 작성 하 기 전 해당 페이지 [ 다음 뉴스 > 중앙일보 > 정치 ] ( 크롤링 당시 날짜 : 2017 . 05 . 04 ) 의 구조 를 파악 하 는 것 이 중요 하 다 . 해당 페이지 를 들어가 보 면 아래 의 그림 과 같이 [ 제목 - 기사 ( 말 줄임 처리 ) ] 로 구성 된 리스트 형식 으로 구성 되 어 있 다 . ① 크롤링 할 기사 제목 ( title ) ② 크롤링 할 기사 내용 ( article ) 은 아래 의 그림 처럼 말 줄임 처리 가 되 어 있 어 전체 기사 내용 을 가져오 지 못한다 . 따라서 전체 기사 내용 을 가져오 기 위해 다음 과 같 은 방법 을 택했 다 . i ) 기사 제목 ( title ) 과 해당 기사 의 링크 ( url ) 을 먼저 크롤링 한 뒤 csv 파일 로 저장 한다 . ii ) csv 파일 로 저장 된 기사 의 링크 를 ( url ) 를 불러와 전체 기사 내용 ( article ) 을 다시 크롤링 해 준다 . 위 와 같 은 방법 을 하 기 위해 item . py 에 링크 를 크롤링 하 는 클래스 ( class ) 와 기사 내용 을 크롤링 하 는 클래스 , 총 두 개 의 클래스 를 생성 해 줘야 한다 . ③ 해당 페이지 번호 에 접근 하 여 크롤링 해 줘야 하 므로 소스 코드 작성 시 페이지 수 에 대한 처리 가 필요 하 다 . ④ 각종 인터넷 브라우저 에 는 오른쪽 마우스 버튼 클릭 시 \\' 검사 \\'( chrome 의 경우 ) 라는 항목 이 존재 한다 . ⑤ scrapy 에서 는 xpath 를 이용 하 여 크롤링 할 정보 를 가져올 수 있 다 . 아래 의 기사 제목 ( title ) 의 xpath 는 \\'//*[@ id =\" marticle \"]/ div [ 2 ] / ul / li [ 15 ] / div / strong / a \\' 이 다 . 여기 서 기사 제목 은 / /*[@ id =\" marticle \"]/ div / ul / li / div / strong / a 태그 를 공통 으로 가지 고 있 다는 것 을 파악 할 수 있 다 . ( xpath 는 크롤링 할 사이트 의 태그 를 보 고 삽질 을 조금 해 보 시 면 어느 정도 이해 가 가실 겁니다 . ... ㅜㅜ ) 4 . 파일 작성 1 ) items . py : 크롤링 할 데이터 를 정의 해 주 는 파일 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # -*- coding : utf - 8 -*- # define here the models for your scraped items # # see documentation in : # [ URL ] import scrapy class newscrawlingitem ( scrapy . item ) : # define the fields for your item here like : source = scrapy . field ( ) # 신문사 category = scrapy . field ( ) # 카테고리 title = scrapy . field ( ) # 제목 url = scrapy . field ( ) # 기사 링크 date = scrapy . field ( ) # 날짜 article = scrapy . field ( ) # pass colored by color scripter cs 2 ) spiders 폴더 안 의 newsspider . py : 크롤링 할 로직 및 내용 들 을 작성 하 는 파일 ① newsurlspider 클래스 : 기사 제목 과 기사 의 링크 를 가져오 는 클래스 이 며 , { source ( 신문사 ) , category ( 카테고리 ) , title ( 기사 제목 ) , url ( 기사 링크 ) , date ( 날짜 ) } 을 크롤링 한다 . ② newsspider 클래스 : 기사 의 내용 을 크롤링 하 는 클래스 이 며 , { source ( 신문사 ) , category ( 카테고리 ) , title ( 기사 제목 ) , date ( 날짜 ) , article ( 기사 내용 ) } 을 크롤링 한다 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 # -*- coding : utf - 8 -*- import scrapy import time import csv from newscrawling . items import newscrawlingitem class newsurlspider ( scrapy . spider ) : name = \" newsurlcrawler \" def start _ requests ( self ) : press = [ 8 , 190 , 200 ] # 8 : 중앙 , 190 : 동아 , 200 : 조선 pagenum = 2 date = [ 20170501 ] # date = [ 20170501 , 20170502 , 20170503 , 20170504 , 20170505 , 20170506 , 20170507 , 20170508 ] for cp in press : for day in date : for i in range ( 1 , pagenum , 1 ) : yield scrapy . request ( \"[ URL ] . format ( cp , i , day ) , self . parse _ news ) def parse _ news ( self , response ) : for sel in response . xpath ( \\'//*[@ id =\" marticle \"]/ div [ 2 ] / ul / li / div \\' ) : item = newscrawlingitem ( ) item [ \\' source \\' ] = sel . xpath ( \\' strong / span [ @ class =\" info _ news \"]/ text ( ) \\' ). extract ( ) [ 0 ] item [ \\' category \\' ] = \\' 정치 \\' item [ \\' title \\' ] = sel . xpath ( \\' strong [ @ class =\" tit _ thumb \"]/ a / text ( ) \\' ). extract ( ) [ 0 ] item [ \\' url \\' ] = sel . xpath ( \\' strong [ @ class =\" tit _ thumb \"]/ a / @ href \\' ). extract ( ) [ 0 ] item [ \\' date \\' ] = sel . xpath ( \\' strong [ @ class =\" tit _ thumb \"]/ span / span [ @ class =\" info _ time \"]/ text ( ) \\' ). extract ( ) [ 0 ] print ( \\'*\\' * 100 ) print ( item [ \\' title \\' ] ) time . sleep ( 5 ) yield item class newsspider ( scrapy . spider ) : name = \" newscrawler \" def start _ requests ( self ) : with open ( \\' newsurlcrawl . csv \\' ) as csvfile : reader = csv . dictreader ( csvfile ) for row in reader : yield scrapy . request ( row [ \\' url \\' ] , self . parse _ news ) def parse _ news ( self , response ) : item = newscrawlingitem ( ) item [ \\' source \\' ] = response . xpath ( \\'//*[@ id =\" csub \"]/ div [ 1 ] / em / a / img / @ alt \\' ). extract ( ) [ 0 ] item [ \\' category \\' ] = \\' 정치 \\' item [ \\' title \\' ] = response . xpath ( \\'//*[@ id =\" csub \"]/ div [ 1 ] / h 3 / text ( ) \\' ). extract ( ) [ 0 ] item [ \\' date \\' ] = response . xpath ( \\'/ html / head / meta [ contains ( @ property , \" og : regdate \")]/@ content \\' ). extract ( ) [ 0 ] [ : 8 ] item [ \\' article \\' ] = response . xpath ( \\'//*[@ id =\" harmonycontainer \"]/ section / div [ contains ( @ dmcf - ptype , \" general \")]/ text ( ) \\' ). extract ( ) \\\\ + response . xpath ( \\'//*[@ id =\" harmonycontainer \"]/ section / p [ contains ( @ dmcf - ptype , \" general \")]/ text ( ) \\' ). extract ( ) print ( \\'*\\' * 100 ) print ( item [ \\' title \\' ] ) print ( item [ \\' date \\' ] ) time . sleep ( 5 ) yield item colored by color scripter cs 3 ) pipelines . py : 데이터 가공 및 db 저장 을 수행 하 는 파일 이번 포스팅 에서 는 json , csv , mongodb 총 세 가지 방법 으로 크롤링 한 데이터 를 저장 하 는 코드 를 작성 하 였 다 . 나중 에 사용 할 때 는 세 가지 중 하나 를 선택 하 면 된다 . 이번 포스팅 에서 는 mongodb 에 저장 하 는 클래스 를 이용 하 였 다 . mongodb 설치 에 관련 된 것 은 mac - os 에 - mongodb - 설치 - 및 - robomongo - 설치 를 확인 하 면 된다 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 # -*- coding : utf - 8 -*- # define your item pipelines here # # don \\' t forget to add your pipeline to the item _ pipelines setting # see : [ URL ] from __ future __ import unicode _ literals from scrapy . exporters import jsonitemexporter , csvitemexporter from scrapy . conf import settings from scrapy . exceptions import dropitem from scrapy import log import pymongo # json 파일 로 저장 하 는 클래스 class jsonpipeline ( object ) : def __ init __( self ) : self . file = open ( \" newscrawl . json \" , \\' wb \\' ) self . exporter = jsonitemexporter ( self . file , encoding = \\' utf - 8 \\' , ensure _ ascii = false ) self . exporter . start _ exporting ( ) def close _ spider ( self , spider ) : self . exporter . finish _ exporting ( ) self . file . close ( ) def process _ item ( self , item , spider ) : self . exporter . export _ item ( item ) return item # csv 파일 로 저장 하 는 클래스 class csvpipeline ( object ) : def __ init __( self ) : self . file = open ( \" newsurlcrawl . csv \" , \\' wb \\' ) self . exporter = csvitemexporter ( self . file , encoding = \\' utf - 8 \\' ) self . exporter . start _ exporting ( ) def close _ spider ( self , spider ) : self . exporter . finish _ exporting ( ) self . file . close ( ) def process _ item ( self , item , spider ) : self . exporter . export _ item ( item ) return item # mongodb 에 저장 하 는 class mongodbpipeline ( object ) : def __ init __( self ) : connection = pymongo . mongoclient ( settings [ \\' mongodb _ server \\' ] , settings [ \\' mongodb _ port \\' ] ) db = connection [ settings [ \\' mongodb _ db \\' ] ] self . collection = db [ settings [ \\' mongodb _ collection \\' ] ] def process _ item ( self , item , spider ) : valid = true for data in item : if not data : valid = false raise dropitem ( \" missing { 0 }!\" . format ( data ) ) if valid : self . collection . insert ( dict ( item ) ) log . msg ( \" news added to mongodb database ! \" , level = log . debug , spider = spider ) return item colored by color scripter cs 4 ) settings . py : 기본 설정 을 정의 해 주 는 파일 이 며 , pipelines . py 에서 정의 한 클래스 에 대해 어떤 클래스 를 사용 할 건지 정의 해 준다 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # -*- coding : utf - 8 -*- # scrapy settings for newscrawling project # # for simplicity , this file contains only settings considered important or # commonly used . you can find more settings consulting the documentation : # # [ URL ] # [ URL ] # [ URL ] bot _ name = \\' newscrawling \\' spider _ modules = [ \\' newscrawling . spiders \\' ] newspider _ module = \\' newscrawling . spiders \\' log _ level = \\' error \\' # # url 크롤링 시 csvpipeline 설정 # item _ pipelines = {\\' newscrawling . pipelines . csvpipeline \\': 300 , } # 기사 내용 크롤링 시 mongodbpipeline 설정 item _ pipelines = { \\' newscrawling . pipelines . mongodbpipeline \\' : 300 , } mongodb _ server = \" localhost \" mongodb _ port = 27017 mongodb _ db = \" news _ crawl \" mongodb _ collection = \" news \" colored by color scripter cs 5 . scrapy 실행 1 ) 기사 제목 ( title ) 및 기사 링크 ( url ) 크롤링 하 여 csv 파일 로 저장 하 기 이제 소스 코드 작성 이 끝났으니 scrapy 를 실행 하 여 크롤링 해 보 도록 한다 . 먼저 , 기사 제목 ( title ) 과 기사 링크 ( url ) 을 크롤링 하 여 csv 파일 로 저장 한다 . 이때 settings . py 를 다음 과 같이 변경 해 준다 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 bot _ name = \\' newscrawling \\' spider _ modules = [ \\' newscrawling . spiders \\' ] newspider _ module = \\' newscrawling . spiders \\' log _ level = \\' error \\' # # url 크롤링 시 csvpipeline 설정 item _ pipelines = { \\' newscrawling . pipelines . csvpipeline \\' : 300 , } # 기사 내용 크롤링 시 mongodbpipeline 설정 # item _ pipelines = {\\' newscrawling . pipelines . mongodbpipeline \\': 300 , } # mongodb _ server = \" localhost \" # mongodb _ port = 27017 # mongodb _ db = \" news _ crawl \" # mongodb _ collection = \" news \" colored by color scripter cs 그런 다음 터미널 ( terminal ) 에서 아래 의 명령어 를 통해 newsurlspider 클래스 의 name 인 \\' newsurlcrawler \\'( newsspider . py 참고 ) 을 실행 한다 . 명령 을 실행 하 게 되 면 아래 의 그림 과 같이 출력 된다 . 또한 newsurlcrawl . csv 파일 이 생성 된 것 을 확인 할 수 있 다 . 1 2 3 4 cjh @ cjhui - macbook - pro : ~$ source activate crawler ( crawler ) cjh @ cjhui - macbook - pro : ~$ cd pycharmprojects / ( crawler ) cjh @ cjhui - macbook - pro : ~ / pycharmprojects $ cd newscrawling / ( crawler ) cjh @ cjhui - macbook - pro : ~ / pycharmprojects / newscrawling $ scrapy crawl newsurlcrawler cs 2 ) 기사 내용 ( article ) 크롤링 하 여 mongodb 에 저장 하 기 1 ) 번 에서 저장 한 newsurlcrawl . csv 파일 의 url 을 읽 어 기사 내용 을 크롤링 하 여 mongodb 에 저장 한다 . 그 전 에 mongodb 가 실행 되 어 있 어야 한다 . settings . py 파일 을 아래 와 같이 변경 해 준다 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 bot _ name = \\' newscrawling \\' spider _ modules = [ \\' newscrawling . spiders \\' ] newspider _ module = \\' newscrawling . spiders \\' log _ level = \\' error \\' # # url 크롤링 시 csvpipeline 설정 # item _ pipelines = {\\' newscrawling . pipelines . csvpipeline \\': 300 , } # 기사 내용 크롤링 시 mongodbpipeline 설정 item _ pipelines = { \\' newscrawling . pipelines . mongodbpipeline \\' : 300 , } mongodb _ server = \" localhost \" mongodb _ port = 27017 mongodb _ db = \" news _ crawl \" mongodb _ collection = \" news \" colored by color scripter cs 그런 다음 터미널 ( terminal ) 에서 아래 의 명령어 를 통해 newsspider 클래스 의 name 인 \\' newscrawler \\'( newsspider . py 참고 ) 을 실행 한다 . 명령 을 실행 하 게 되 면 아래 의 그림 과 같이 출력 된다 . 또한 robomongo 를 통해 mongodb 에 크롤링 한 기사 내용 이 저장 된 것 을 확인 할 수 있 다 . 1 2 3 4 cjh @ cjhui - macbook - pro : ~$ source activate crawler ( crawler ) cjh @ cjhui - macbook - pro : ~$ cd pycharmprojects / ( crawler ) cjh @ cjhui - macbook - pro : ~ / pycharmprojects $ cd newscrawling / ( crawler ) cjh @ cjhui - macbook - pro : ~ / pycharmprojects / newscrawling $ scrapy crawl newscrawler cs',\n",
       "       'import requests import json # json import 하 기 # custom _ header 을 통해 아닌 것 처럼 위장 하 기 custom _ header = { \\' referer \\' : \\'[ URL ] , \\' user - agent \\' : \\' mozilla / 5 . 0 ( macintosh ; intel mac os x 10 _ 14 _ 4 ) applewebkit / 537 . 36 ( khtml , like gecko ) chrome / 73 . 0 . 3683 . 103 safari / 537 . 36 \\' } # 해당 접속 사이트 가 아닌 원본 데이터 가 오 는 url 추적 . network 에서 가지 고 온다 . url = \"[ URL ] req = requests . get ( url , headers = custom _ header ) # custom _ header 를 사용 하 지 않 으면 접근 불가 if req . status _ code == requests . codes . ok : print ( \" 접속 성공 \" ) stock _ data = json . loads ( req . text ) # json 에 반환 된 데이터 가 들어가 있 다 . for rank in stock _ data [ \\' data \\' ] : # stock _ data 는 \\' data \\' key 값 에 모든 정보 가 들어가 있 다 . print ( rank [ \\' rank \\' ] , rank [ \\' symbolcode \\' ] , rank [ \\' name \\' ] , rank [ \\' tradeprice \\' ] ) else : print ( \" error code \" ) 접속 성공 1 a 001000 신라 섬유 2350 2 a 068270 셀 트리 온 211500 3 a 048410 현대 바이오 12650 4 a 005930 삼성전자 44650 5 a 207940 삼성 바이오 로직스 338500 6 a 020560 아시아나항공 6460 7 a 002210 동성 제 약 20150 8 a 007460 에이 프로 젠 kic 4000 9 a 066570 lg 전자 77000 10 a 000660 sk 하이닉스 80200',\n",
       "       \"( 참조 - [ URL ] 구글 로그인 을 해 볼 것 이 다 * 개념 - oauth 를 통해 사용자 로부터 허가 를 받 고 얻 어 낸 access token 을 이용 하 여 resource server 에서 얻 어 온 사용자 id 를 이용 하 여 사용 자 를 인증 한다 - user ( resource owner ) 로 부 터 허가 를 받 아 얻 어 온 access token 을 이용 하 여 가져온 id 이 므로 pw 가 없이 도 해당 user 임 을 증명 할 수 있 다 . * 과정 1 ) 환경 구성 1 . build . gradle 에 google ( ) 을 추가 한다 2 . build . gradle 에서 ' com . google . android . gms : play - services - auth : 16 . 0 . 1 ' 의존 성 을 추가 한다 appcompat 을 27 . 1 . 1 버전 을 이용 하 고 있 었 으나 의존 성 충돌 이 일어나 26 . 1 . 0 으로 다운 그레이드 했 다 sdk 버전 도 26 으로 맞춰 준다 . 3 . file -> project structure 를 누른다 4 . app -> properites 탭 의 compile sdk version 을 api 26 으로 맞추 어 준다 . 2 ) 코드 구글 의 sign - in document 를 참조 하 며 개발 을 진행할 것 이 다 . 1 . 사용자 의 id 와 기본 profile 정보 를 요청 하 기 위해 googlesigninoptions 객체 를 default _ sign _ in 인자 와 함께 생 성 을 하 라고 한다 * 가장 최고 의 사용 자 경험 을 제공 하 기 위해 앱 에서 필요 로 하 는 범위 만 을 요청 할 것 을 권고 하 고 있 다 또한 추가 적 인 범위 에 대한 허가 를 원한다면 그 역시 사용 자 의 화면 에 나타남 을 말 하 고 있 다 . 2 . 그 다음 sign - in activity 의 oncreate ( ) 메소드 에 googlesigninclient 객체 를 위 에서 생성 한 gso 객체 를 인자 로 주 어 생성 한다 . 3 . 기존 의 로그인한 사용 자 가 있 는지 확인 을 하 는 부분 이 다 onstart ( ) 메소드 에 위 의 코드 를 추가 할 것 을 권고 하 고 있 다 googlesignin . getlastsignedinaccount ( this ) ; 메소드 를 사용 하 면 기존 에 로그인 된 사용 자 객체 를 얻 을 수 있 다 . 기존 의 사용 자 가 있 는 경우 의 코드 를 추가 하 면 된다 ( 우리 앱 에선 추가 하 지 않 겠 다 ) 4 . 다음 은 구글 에서 제공 하 는 버튼 을 xml 에 추가 한다 오른쪽 에 보이 는 것 과 같 은 모양 의 버튼 이 추가 된다 . 5 . 1 ) 버튼 이 눌렸 을 때 의 행동 을 추가 한다 2 ) 우리 들 이 허가 를 요청 할 gso 객체 를 인자 로 하 여 만든 mgooglesigninclient 객체 의 getsigninintent ( ) ; 메소드 를 이용 하 여 intent 를 만든다 . 3 ) 만들 어 진 intent 를 startactivityforresult ( ) 에 인수 로 전달 하 여 실행 한다 4 ) 사용 자 에게 인증 허가 를 요청 하 는 화면 ( activity ) 가 보여진다 . * startactivityforresult - startactivityforresult ( ) 는 intent 에 입력 된 activity 로 부 터 결과 를 받 을 때 이용 하 는 메소드 - 사용 자 가 startactivityforresult ( ) 로 호출 된 activity 의 작업 을 마치 면 onactivityresult ( ) 메소드 가 호출 이 된다 . 사용자 가 google signin 버튼 을 클릭 하 면 onclick 메소드 가 실행 되 고 이어 signin ( ) 메소드 를 호출 한다 signin ( ) 메소드 는 사용 자 에게 허가 를 요청 하 는 엑 티비 티 를 띄우 며 그것 을 startactivityforresult 를 이용 하 여 사용 자 의 행동 에 대한 결과 를 응답 받 는다 . 6 . 사용자 가 signin 을 하 고 난 뒤 에 는 onactivityresult ( ) 가 호출 되 며 googlesigninaccount 객체 를 얻 어 낼 수 있 다 이것 을 handlesigninresult 를 호출 하 며 인자 로 전달 한다 사용 자 가 activity 에서 한 행동 을 onactivityresult ( ) 에서 data 로 받 을 수 있 으며 googlesignin . g e t signedinaccountfromintent ( data ) ; 메소드 를 통해 task 객체 로 변환 할 수 있 다 . task 객체 를 인수 로 handlesigninresult ( ) 메소드 를 호출 한다 7 . task 객체 의 getresult ( ) 메소드 를 이용 하 여 googlesigninaccount 객체 를 반환 받 을 수 있 다 . googlesigninaccount 객체 를 통해 사용 자 의 google 계정 정보 를 얻 어 올 수 있 다 . 얻 어 온 account 객체 를 통해 사용 자 의 정보 를 log 로 출력 해본다 . 8 . 사용자 의 google 계정 정보 를 잘 받 아 온 것 을 볼 수 있 다 .\",\n",
       "       'multi gpu 환경 에서 etri 한국어 bert 모델 활용 한 korquad 학습 방법 etri 에서 제공 해 주 신 한국어 bert 모델 을 활용 하 여 한국어 기계 독해 ( korquad ) 를 multi gpu 환경 에서 tensorflow 로 학습 할 수 있 도록 하 였 습니다 . ( 코드 는 etri 에서 제공 해 주 신 pytorch 코드 를 보 고 변경 하 였 습니다 . ) 형태소 분석기 는 세종 품사 태그 로 바꾼 mecab 형태소 분석기 api 를 적용 하 였 습니다 . dependency 는 기존 run _ squad _ morph . py 와 같 습니다 . ( python >= 3 . 5 , tensorflow >= 1 . 12 , urllib 3 ) etri 의 한국어 bert 모델 을 활용 하 시 려면 다음 의 링크 에서 서약서 를 작성 하 시 고 키 를 받 으셔서 다운 받 으시 면 됩니다 . ( 사용 허가 협 약서 를 준수 하 기 때문 에 pretrained 모델 을 공개 하 지 않 습니다 . ) 실행 방법 requirements python 3 . 6 tensorflow == 1 . 14 . 0 urllib 3 실행 방법 step 1 . mecab 형태소 분석기 api 설치 합니다 . step 2 . etri _ pretrained directory 만들 어서 etri pretrained model checkpoint 저장 합니다 . step 3 . shell script path 바꿔 줍니다 . ( docker 사용 하 면 mount 시킬 volume 의 source path 만 바꿔 주 세요 . ) bert _ base _ dir 를 clone 하 신 path 로 바꿔 주 세요 step 4 . 실행 합니다 . ./ run _ squad _ etri . sh korquad result ( dev set ) model exact match f 1 etri + mecab 84 . 08 92 . 46 변경 된 부분 tokenization tokenizer 는 etri 에서 제공 해 주 신 tokenization _ morp . py 를 그대로 활용 하 였 습니다 . import src _ tokenizer . tokenization _ morp as tokenization run _ squad . py 변경 부분 class squadexample 를 etri 의 run _ squad _ morph . py 에 있 는 class squadexample 로 대체 했 습니다 . def do _ lang ( text ) : openapiurl = \"[ URL ] http = urllib 3 . poolmanager ( ) response = http . request ( \" post \" , openapiurl , fields = { \\' targettext \\' : text }) return response . data . decode ( ) represent _ ndoc 함수 를 다음 과 같이 바꿨 습니다 . def represent _ ndoc ( p _ json ) : text = \\'\\' morp _ list = [ ] position _ list = [ ] for sent in p _ json : text = sent [ \\' text \\' ] for morp in sent [ \\' morp \\' ] : morp _ list . append ( morp [ \\' lemma \\' ] + \\'/\\' + morp [ \\' type \\' ] ) position _ list . append ( int ( morp [ \\' position \\' ] ) ) return { \\' text \\' : text , \\' morp _ list \\' : morp _ list , \\' position _ list \\' : position _ list } 아래 함수 는 형태소 분석 api 가 return 한 json 포맷 에 맞췄 습니다 . mapping _ answer _ korquad 함수 안 에 p _ json [ \\' sentence \\'] 를 p _ json 로 바꿔 주 세요 . ( etri json 포맷 과 약간 다름 니다 . 유의 해 주 세요 . ) 함수 안 에 를 로 바꿔 주 세요 . ( etri json 포맷 과 약간 다름 니다 . 유의 해 주 세요 . ) convert _ examples _ to _ features read _ squad _ examples --> read _ squad _ examples _ and _ do _ lang 자세 한 건 코드 를 참고 해 주 세요 . ( 너무 길 어서 . ..) multi gpu 활용 tensorflow 에서 multi gpu 환경 으로 학습 하 시 려면 tf . contrib . distribute . c o llectiveallreducestrategy tf . contrib . distribute . mirroredstrategy 과 같 은 함수 를 활용 해야 합니다 . 참고 자료 run _ squad . py 변경 부분 argument 로 다음 을 추가 해 주 시 고 flags . define _ integer ( \" num _ gpus \" , 8 , \" total number of gpus to use . \" ) flags . define _ bool ( \" multi _ worker \" , false , \" multi - worker training . \" ) run _ config 부분 을 다음 과 같이 바꿨 습니다 . if flags . multi _ worker : distribution = tf . contrib . distribute . c o llectiveallreducestrategy ( num _ gpus _ per _ worker = 1 ) run _ config = tf . estimator . runconfig ( experimental _ distribute = tf . contrib . distribute . distributeconfig ( train _ distribute = distribution , remote _ cluster = { \\' worker \\' : [ \\' localhost : 5000 \\' , \\' localhost : 5001 \\' ] , }, ) ) else : distribution = tf . contrib . distribute . mirroredstrategy ( num _ gpus = flags . num _ gpus ) run _ config = tf . estimator . runconfig ( train _ distribute = distribution ) estimator 는 다음 과 같이 바꿨 습니다 . estimator = tf . estimator . estimator ( model _ fn = model _ fn , config = run _ config , params = { \\' batch _ size \\' : flags . train _ batch _ size if flags . do _ train else flags . predict _ batch _ size , } ) optimization . py 변경 부분 adamweightdecayoptimizer 가 multi - gpu 환경 에서 동작 하 지 않 기 때문 에 adamoptimizer 로 바꿨 습니다 . ( 실험 해 보 진 않 았 지만 tpu 를 활용 할 때 와 성능 차이 가 많이 나지 는 않 을 것 같 습니다 . ) optimizer = tf . train . adamoptimizer ( learning _ rate = learning _ rate , beta 1 = 0 . 9 , beta 2 = 0 . 999 , epsilon = 1 e - 6 ) partner [ URL ]',\n",
       "       '다른 기회 에 정리 하 다가 친구 들 과 스터디 를 꽤 오래 해서 본 책 도 꽤 많 길래 여태 까지 공부 했 던 것 들 을 정리 . python codecademy python [ URL ] think python / allen downey 파이썬 코딩 의 기술 / 브렛 슬 라킨 probability and statistics an introduction to probability and inductive logic / ian hacking statistical explained / steve mckillup think stats / allen downey think bayes / allen downey regression analysis by example / samprit chatterjee & ali s . hadi data mining data mining / ian h . witten , eibe frank , mark a . hall machine learning pattern recognition & machine learning / christopher bishop deep learning 모두 를 위한 머신 러닝 / 딥 러닝 강의 [ URL ] natual language processing 자연어 처리 특론 대학원 강의 ( nltk 로 수업 진행 ) 스탠포드 cs 224 n 동영상 강의 graph theory 코세라 applied social network analysis in python [ URL ] logic introduction to logic / harry j . gensler neuro science 신경 과학 : 뇌 의 탐구 3 판 / mark f . bear , barry w . connors , michael a . paradiso neuro imaging',\n",
       "       'melon playlist continuation 카카오 아레나 melon playlist continuation 대회 에 참여 한 내용 을 정리 한 repository 입니다 . 필요 모듈 fire gensim implicit numpy pandas tqdm 개발 환경 colab pro gpu 16280 mib ram 25 . 51 gb linux - 4 . 19 . 104 +- x 86 _ 64 - with - ubuntu - 18 . 04 - bionic python 3 . 6 . 9 myals 실행 을 위하 여 gpu 가 반드시 필요 합니다 . ( cpu 버전 미구 현 ) 실행 step 1 . 데이터 다운로드 아레나 홈페이지 에 제공 되 는 파일 을 res 디렉 토리 에 다운로드 받 습니다 . ├ ── melon - playlist - continuation ├ ── res ├ ── train . json ├ ── val . json ├ ── test . json └ ── song _ meta . json step 2 . 모델 학습 모델 다운로드 step 2 - 1 . baseline ( genre _ most _ popular ) 실행 $ > python genre _ most _ popular . py run \\\\ -- song _ meta _ fname = res / song _ meta . json \\\\ -- train _ fname = res / train . json \\\\ -- question _ fname = res / test . json 결과 는 arena _ data / results / results . json 에 저장 됩니다 . step 2 - 2 . 모델 학습 $ > python train . py train \\\\ -- train _ fname = res / train . json \\\\ -- test _ fname = res / test . json \\\\ -- val _ fname = res / val . json 위 command 를 실행 하 면 coo . txt ( als 알고리즘 을 위한 데이터 ) 와 tag _ dict . pkl ( tag 를 id 와 매핑 한 딕셔너리 의 pickle 파일 ) 과 함께 다음 과 같 은 모델 들 이 생성 됩니다 . model 설명 용량 model _ song 1 . pkl myals 55 mb model _ song 2 . pkl bm 25 3 mb model _ song 3 . pkl bm 25 8 mb model _ song 4 . pkl cosine 5 mb model _ tag _ w 1 . pkl w 2 v 16 mb model _ tag _ w 2 . pkl w 2 v 20 mb model _ tag _ w 3 . pkl w 2 v 27 mb model _ tag 1 . txt cosine 22 mb model _ tag 2 . txt bm 25 22 mb model _ tag 3 . txt als 24 mb model _ tag 4 . txt cosine 22 mb model _ tag 5 . txt bm 25 22 mb model _ tag 6 . txt als 24 mb model _ tag 7 . txt cosine 17 mb model _ tag 8 . txt bm 25 17 mb w 2 v _ model . pkl w 2 v 220 mb w 2 v _ results . json w 2 v 10 mb step 3 . 평가 데이터 생성 inference . py 을 실행 하 면 res / results . json 결과 파일 이 생성 됩니다 . $ > python inference . py infer \\\\ -- test _ fname = res / test . json \\\\ -- result _ fname =/../ res / results . json 결과 는 res / results . json 에 저장 됩니다 . 생성 되 는 파일 들 의 디렉 토리 는 다음 과 같 습니다 . ├ ── melon - playlist - continuation ├ ── coo . txt ├ ── model _ song 1 . pkl ├ ── model _ song 2 . pkl ├ ── model _ song 3 . pkl ├ ── model _ song 4 . pkl ├ ── model _ tag _ w 1 . pkl ├ ── model _ tag _ w 2 . pkl ├ ── model _ tag _ w 3 . pkl ├ ── model _ tag 1 . txt ├ ── model _ tag 2 . txt ├ ── model _ tag 3 . txt ├ ── model _ tag 4 . txt ├ ── model _ tag 5 . txt ├ ── model _ tag 6 . txt ├ ── model _ tag 7 . txt ├ ── model _ tag 8 . txt ├ ── tag _ dict . pkl ├ ── w 2 v _ model . pkl ├ ── res └ ── train _ val . json └ ── results . json ( 최종 답안 ) └ ── arena _ data └ ── results ├ ── results . json ( baseline 답안 ) └ ── w 2 v _ results . json 알고리즘 저희 팀 은 주로 matrix factorization 기반 인 als 와 neighborhood - base learning 인 bm 25 와 cosine 을 사용 하 였 고 , 자연 언어 처리 모델 인 gensim 의 word 2 vec 을 사용 하 였 습니다 . als 와 bm 25 , cosine 은 implicit library 에 있 는 것 을 사용 하 였 고 , myals 는 als 를 변형 하 여 사용 하 였 습니다 . 1 . als , myals ( alternating least squares ) 다음 의 모델 들 에 대하 여 song 을 예측 하 였 습니다 . model _ song 1 . pkl ( myals ) 다음 의 모델 들 에 대하 여 tag 를 예측 하 였 습니다 . model _ tag 3 . txt ( als ) model _ tag 6 . txt ( als ) 2 . bm 25 , cosine 다음 의 모델 들 에 대하 여 song 을 예측 하 였 습니다 . model _ song 2 . pkl ( bm 25 ) model _ song 3 . pkl ( bm 25 ) model _ song 4 . pkl ( cosine ) 다음 의 모델 들 에 대하 여 tag 를 예측 하 였 습니다 . model _ tag 1 . txt ( cosine ) model _ tag 4 . txt ( cosine ) model _ tag 7 . txt ( cosine ) model _ tag 2 . txt ( bm 25 ) model _ tag 5 . txt ( bm 25 ) model _ tag 8 . txt ( bm 25 ) 3 . word 2 vec word 2 vec 는 카카오 아레나 포럼 에 올라와 있 는 코드 를 참고 하 였 습니다 . 저희 팀 의 코드 는 word 2 vec . py 에 작성 하 였 습니다 . 다음 과 같 은 모델 들 에 대하 여 song 을 예측 하 였 습니다 . word 2 vec model 생 성 은 20 분 정도 소요 됩니다 . w 2 v _ model . pkl 학습 한 모델 을 바탕 으로 가중치 들 과 neighborhood 의 개수 등 을 조절 하 여 ensemble 할 수 있 는 데이터 들 을 생성 하 였 습니다 . 생성 된 데이터 들 은 다음 과 같 습니다 . arena _ data / results / w 2 v _ results . json model _ tag _ w 1 . pkl model _ tag _ w 2 . pkl model _ tag _ w 3 . pkl 4 . ensemble 위 에서 생성 한 데이터 를 기반 으로 , song 과 tag 각각 따로 앙상블 을 실시 하 여 결과 를 도출 했 습니다 . feature model song myals , cosine , bm 25 , word 2 vec tag als , cosine , bm 25 , word 2 vec tag 예측 의 경우 , 총 11 개 의 모델 이 각각 주어진 playlist 와 가까운 playlist 들 을 찾 고 , 그 playlist 들 에서 가장 자주 등장 하 는 10 개 의 tag 들 을 답안 으로 제출 하 였 습니다 . 대략 적 실행 시간 위 에서 언급 된 개발 환경 에서 의 대략 적 인 실행 시간 입니다 .',\n",
       "       'better way 36 . 자식 프로세스 를 관리 하 려면 subprocess 를 사용 하 자 172 쪽 created : 2017 / 01 / 20 modified : 2019 / 06 / 13 1 . 병행 성 과 병렬 성 병행 성 ( concurrency ) 이 란 컴퓨터 가 여러 일 을 마치 동시 에 하 듯이 수행 하 는 것 을 말 한다 . 예 를 들 어 cpu 코어 가 하나 인 컴퓨터 에서 운영 체제 는 단일 프로세서 에서 실행 하 는 프로그램 을 빠르 게 변경 한다 . 이런 time sharing 의 한 기법 을 context switching 이 라고 한다 . 이 방법 으로 프로그램 을 교대 로 실행 하 여 프로그램 들 이 동시 에 실행 하 는 것 처럼 보이 게 한다 . 반면 병렬 성 ( parallelism ) 은 여러 작업 을 동시 에 실행 하 는 것 이 다 . cpu 코어 가 여러 개 인 컴퓨터 는 여러 프로그램 을 동시 에 실행 할 수 있 다 . 각 cpu 코어 가 각기 다른 프로그램 의 명령어 를 실행 하 여 각 프로그램 이 같 은 순간 에 실행 하 게 해준다 . 현대 의 어지간 한 컴퓨터 는 cpu 코어 를 여러 개 가지 고 있 다 . 내 5 년 된 노트북 도 확인 해 보 니 코어 가 2 개 이 다 . $ lscpu architecture : x 86 _ 64 cpu op - mode ( s ) : 32 - bit , 64 - bit byte order : little endian cpu ( s ) : 2 # ! !!!!!!!!!! on - line cpu ( s ) list : 0 , 1 thread ( s ) per core : 1 # 생략 . .. # lscpu 는 ubuntu 에 설치 되 어 있 으며 다른 운영 체제 에 는 없 을 수 있 음 병렬 성 과 병행 성 사이 의 가장 큰 차이점 은 속도 향상 이 다 . 한 프로그램 에서 서로 다른 두 실행 경로 를 병렬 로 진행 하 면 전체 작업 에 걸리 는 시간 이 절반 으로 준다 . 즉 , 실행 속도 가 두 배 로 빨라진다 . 반면 에 병행 프로그램 은 수천 가지 실행 경로 를 병렬 로 수행 하 는 것 처럼 보이 게 해 주 지만 전체 작업 속도 는 향상 되 지 않 는다 . 파이썬 을 쓰 면 병행 프로그램 을 쉽 게 작성 할 수 있 다 . 시스템 호출 , 서브 프로세스 , c 확장 을 이용 한 병렬 작업 에 도 파이썬 을 쓸 수 있 다 . 그러나 병행 파이썬 코드 를 실제 병렬 로 실행 하 게 만드 는 건 정말 어렵 다 . 이런 미묘 한 차이 가 생기 는 상황 에서 파이썬 을 최대한 활용 하 는 방법 을 알 아야 한다 . 2 . subprocess 소개 파이썬 은 실전 에서 단련 된 자식 프로세스 실행 과 관리 용 라이브러리 를 갖추 고 있 다 . 따라서 명령 줄 유틸리티 같 은 다른 도구 들 을 연계 하 는 데 아주 좋 은 언어 다 . ( ex . shell ) 기존 쉘 스크립트 가 시간 이 지나 면서 점점 복잡 해 지 면 , 자연히 파이썬 코드 로 재 작성 하 여 가독성 과 유지 보수성 을 확보 하 려 하 기 마련 이 다 . 파이썬 으로 시작 한 자식 프로세스 는 병렬 로 실행 할 수 있 고 , 그래서 파이썬 을 사용 하 면 cpu 코어 를 모두 이용 해 프로그램 의 처리 량 을 극대 화 할 수 있 다 . 이전 부터 파이썬 에서 서브 프로세스 ( 자식 프로세스 ) 를 실행 하 는 방법 은 여러 개 있 었 는데 요즘 최선 의 방법 은 내장 subprocess 모듈 을 사용 하 는 것 이 다 . subprocess 로 자식 프로세스 를 실행 하 는 방법 은 간단 하 다 . 다음 코드 에서 는 popen 생성자 가 프로세스 를 시작 한다 . communicate 메소드 는 자식 프로세스 의 출력 을 읽 어 오 고 자식 프로세스 가 종료 할 때 까지 대기 한다 . import os import subprocess from time import time proc = subprocess . popen ( [ \\' echo \\' , \\' hello from the child process ! \\' ] , stdout = subprocess . pipe ) out , err = proc . communicate ( ) print ( out ) b \\' hello from the child process ! \\' 위 의 코드 를 조금 해석 해 보 자 : subprocess . popen 서브 프로세스 를 생성 하 는 생성자 이 다 . 문서 를 살피 면 수많 은 인자 를 받 는다 . [ \\' echo \\', \\' hello from the child ! \\'], 실행 할 명령 을 리스트 나 단일 문자열 로 입력 한다 . 의미 있 는 단위 로 나누 어야 한다 . stdout = subprocess . pipe 프로세스 의 결과물 의 방향 을 표준 출력 으로 지정 할 수 있 는데 ( stdout ) 여기 서 는 pipe 로 지정 한다 . 실제 쉘 에서 의 파이프 처럼 출력물 을 다른 프로세스 의 입력 으로 전환 하 는 등 의 작업 이 가능 해진다 . proc . communicate ( ) 자식 프로세스 가 끝 나기 까지 기다리 고 출력 을 받 아 온다 . ( stdout , stderr ) 를 튜플 로 반환 한다 . 자식 프로세스 는 부모 프로세스 와 파이썬 인터프리터 와 는 독립 적 으로 실행 된다 . 자식 프로세스 의 상태 는 다른 작업 을 하 는 동안 주기 적 으로 폴링 된다 . ( polling ) popen . poll ( ) 에서 poll 은 실제 운영 체제 용어 로 보통 저 수준 장비 사이 에서 서로 의 상태 나 사용 여부 등 을 기다리 는 것 을 말 한다 . 여기 서 자식 프로세스 의 상태 는 파이썬 이 다른 작업 을 하 는 동안 주기 적 으로 폴링 ( polling ) 된다 . ( 즉 , 상태 를 확인 하 게 된다 . ) proc = subprocess . popen ( [ \\' sleep \\' , \\' 0 . 3 \\' ] ) while proc . poll ( ) is none : print ( \\' child is working \\' ) print ( \\' exit status \\' , proc . poll ( ) ) child is working child is working # . .. exit status 0 sleep 은 파이썬 함수 가 아닌 쉘 커맨드 로 몇 초간 다음 쉘 스크립트 실행 을 멈추 고 대기 하 는 함수 이 다 . 예제 에서 는 이 \\' 기다리 는 작업 \\' 이 종료 되 기 전 까지 무수 한 문장 을 출력 하 고 있 다 . poll 메 서 드 는 자식 프로세스 가 종료 되 지 않 았 으면 none 을 반환 하 고 종료 됐 으면 정수 의 리턴 코드 를 반환 한다 . 위 에서 는 0 . 3 초 동안 프로세스 가 실행 되 었 고 그동안 무수 한 \\' child is working \\' 이 출력 된 것 을 확인 할 수 있 다 . 3 . subprocess 의 장점 : 병렬 성 부모 에서 자식 프로세스 를 떼 어 낸다는 건 부모 프로세스 가 자유 롭 게 여러 자식 프로세스 를 병렬 로 실행 할 수 있 음 을 의미 한다 . 자식 프로세스 를 떼 어 내 려면 모든 자식 프로세스 를 먼저 시작 하 면 된다 . def run _ sleep ( period ) : proc = subprocess . popen ( [ \\' sleep \\' , str ( period ) ] ) return proc size = 10 start = time ( ) procs = [ ] for _ in range ( size ) : proc = run _ sleep ( 0 . 1 ) procs . append ( proc ) for proc in procs : proc . communicate ( ) end = time ( ) print ( \\' finished in \\' , end - start ) finished in 0 . 1650395393371582 run _ sleep 함수 는 period 동안 \\' 잠 을 자 는 \\' 자식 프로세스 를 반환 한다 . 아직 communicate 는 실행 하 지 않 아 실제 작동 은 하 지 않 고 있 는 상태 다 . 그리고 size 개 만큼 해당 자식 프로세스 를 만들 어서 두 번 째 for 문 에서 한 번 에 실행 한다 . 그리고 전체 실행 시간 을 확인 해 보 니 약 0 . 17 초 정도 이 다 . 이 예제 에서 생성 한 자식 프로세스 의 개수 는 10 개 였 기 때문 에 만약 프로그램 이 병렬 로 실행 되 지 않 았 다면 1 초 가 넘 는 시간 이 걸렸 을 것 이 다 . 하지만 10 개 의 자식 프로세스 가 모두 병렬 로 실행 될 수 있 었 기 때문 에 시간 은 0 . 2 초 도 걸리 지 않 았 다 . 4 . subprocess 활용 : 프로세스 의 파이프 라이닝 ( pipelining ) 앞선 예제 에서 subprocess . pipe 를 잠깐 살펴봤 다 . 쉘 에서 파이프 라이닝 ( pipelining ) 을 통해 프로세스 의 출력 을 다른 프로세스 의 입력 으로 전환 할 수 있 듯이 , 자식 프로세스 의 입출력 을 다른 프로세스 의 입출력 을 통해 받 는 것 이 가능 하 다 . 예 를 들 어 어떤 데이터 를 암호 화 하 는 데 쉘 의 openssl 명령 줄 도구 를 사용 하 려 한다고 하 자 . 명령 줄 인수 와 i / o 파이프 를 사용 해 자식 프로세스 를 실행 하 는 건 간단 하 다 . def run _ openssl ( data ) : env = os . environ . copy ( ) env [ \\' password \\' ] = b \\' \\\\ xe 2 4 u \\\\ xd 0 ql 3 s \\\\ x 11 \\' proc = subprocess . popen ( [ \\' openssl \\' , \\' enc \\' , \\'- des 3 \\' , \\'- pass \\' , \\' env : password \\' ] , env = env , stdin = subprocess . pipe , stdout = subprocess . pipe ) proc . stdin . write ( data ) proc . stdin . flush ( ) # 자식 프로세스 가 입력 을 반드시 받 게 함 . return proc 위 식 은 파이프 로 어떤 data 인자 를 받 으면 그 인자 를 openssl enc 로 암호 화 하 는 프로세스 를 반환 한다는 것 을 의미 한다 . 각 코드 부분 에 대해 간략히 설명 하 면 다음 과 같 다 . env 운영 체제 의 환경 변수 의 값 을 받 아 와서 password 변수 를 임의 의 값 으로 바꾼다 . subprocess . popen ( ... ) 바뀐 변수 값 을 바탕 으로 openssl 을 사용 하 는 자식 프로세스 를 호출 한다 . 이때 stdin , stdout 인자 에 모두 pipe 을 줬 다 . 이 는 프로세스 의 입력 과 출력 을 사용 자 가 제어 하 겠 다는 의미 이 다 . 이 예제 에서 는 다른 프로세스 의 입출력 과 파이프 라이닝 을 한다 . proc . stdin . write ( data ) 표준 입력 ( stdin ) 을 pipe 로 줬 기 때문 에 사용 자 가 프로세스 에 입력 을 직접 줄 수 있 다 . write 메소드 에 겁먹 지 말 자 . 유닉스 에서 는 프로세스 든 , 소켓 이 든 다 파일 이 니까 . proc . stdin . flush ( ) i / o 의 관점 에서 입력 이 바로 프로세스 로 넘어가 지 않 을 수 있 다 . 성능 문제 에 있 어서 다음 입력 까지 기다렸 다가 한 번 에 chunk 로 데이터 를 넘길 수 도 있 기 때문 이 다 . 지금 우리 는 바로 프로세스 에 데이터 를 넘겨야 하 기 때문 에 flush 메소드 로 자료 를 확실히 전달 한다 . 예제 에서 는 파이프 로 암호 화 함수 에 임의 의 바이트 를 전달 하 지만 실전 에서 는 사용 자 입력 , 파일 핸들 , 네트워크 소켓 등 을 전달 할 것 이 다 . procs = [ ] for _ in range ( 3 ) : data = os . urandom ( 10 ) proc = run _ openssl ( data ) procs . append ( proc ) out , err = proc . communicate ( ) print ( out [ - 10 : ] ) b \\' eq \\\\ xca \" \\\\ xc 5 \\\\ x 04 r ( = q \\' b \\' w \\\\ xcf j \\\\ xbf \\\\ x 12 \" \\\\ xe 7 \\\\ xb 1 lj \\' b \" \\\\ x 87 \\\\ xfd b \\\\ x 8 c `\\'{ f \\\\ x 0 e \\\\ x 13 \" os . urandom 은 인자 로 받 은 길 의 의 랜덤 바이트 값 을 출력 한다 . 이 data 변수 를 통해 run _ openssl 함수 를 실행 한다 . 단순히 입력 을 외부 에서 받 는 것 뿐 아니 라 유닉스 의 파이프 처럼 한 자식 프로세스 의 결과 를 다른 프로세스 의 입력 으로 연결 하 여 병렬 프로세스 의 체인 을 생 설 할 수 있 다 . 다음 은 md 5 명령 줄 도구 에서 입력 스트림 을 md 5 알고리즘 으로 암호 화 하 는 자식 프로세스 를 반환 하 는 함수 다 . def run _ md 5 ( input _ stdin ) : proc = subprocess . popen ( [ \\' md 5 sum \\' ] , # 운영 체제 마다 정확 한 프로그램 이름 이 다름 . \\' md 5 \\' 등 . stdin = input _ stdin , stdout = subprocess . pipe ) return proc 이제 데이터 를 암호 화 하 는 openssl 프로세스 집합 과 암호 화 된 결과 를 파이프 라이닝 해 md 5 로 다시 해시 하 는 프로세스 집합 을 시작 할 수 있 다 . input _ procs = [ ] hash _ procs = [ ] for _ in range ( 3 ) : data = os . urandom ( 10 ) proc = run _ openssl ( data ) input _ procs . append ( proc ) hash _ proc = run _ md 5 ( proc . stdout ) hash _ procs . append ( hash _ proc ) run _ openssl 프로세스 의 출력 , 즉 stdout 을 run _ md 5 의 stdin 으로 입력 함 으로써 파이프 라이닝 이 되 었 다 . 일단 자식 프로세스 들 이 시작 하 면 이 들 사이 의 i / o 는 자동 으로 일어난다 . 할 일 은 모든 작업 이 끝나 고 최종 결과물 이 출력 되 기 를 기다리 는 것 뿐 이 다 . for proc in input _ procs : proc . communicate ( ) for proc in hash _ procs : out , err = proc . communicate ( ) print ( out . strip ( ) ) b \\' 4 fe 204 c 19 bd 577 feb 58224 eee 3 a 06508 -\\' b \\' f 0 b 012242 bf 4 bc 3331 b 23 eca 8 cdb 0 bda -\\' b \\' 601 e 667 ddbf 36825 b 20245 c 37 cc 7 dbfd -\\' 5 . 자식 프로세스 의 강제 종료 자식 프로세스 가 종료 되 지 않 거나 입력 또는 출력 파이프 에서 블록 될 염려 가 있 다면 communicate 메 서 드 에 timeout 파라미터 를 넘겨야 한다 . 이렇게 하 면 자식 프로세스 가 일정 한 시간 내 에 응답 하 지 않 을 때 예외 가 일으켜 오동작 하 는 자식 프로세스 를 종료 할 기회 를 얻 는다 . proc = run _ sleep ( 10 ) try : proc . communicate ( timeout = 0 . 1 ) except subprocess . timeoutexpired : proc . terminate ( ) proc . wait ( ) print ( \\' exit status \\' , proc . poll ( ) ) # exit status - 15 6 . 핵 심정리',\n",
       "       '안녕 하 세요 , 오늘 은 디지털 방식 으로 논문 을 읽 는 방법 을 보여 드릴 예정 입니다 . 과정 생 분 들 은 수업 예습 을 하 는 방법 으로 활용 하 시 면 되 고요 , 수료 생 분 들 은 본인 연구 에 관련 된 자료 를 이런 방식 으로 읽 을 수 있 겠 구나 하 고 보 시 면 됩니다 . 1 . 아이 패드 로 필기 하 며 읽 기 : 초급 위 두 사진 중 윗 쪽 의 pdf 는 유 패드 에서 밑줄 을 그으면서 읽 었 던 것 이 고 , 아래 두 사진 은 굿 노트 로 옮겨 와서 필기 하 면서 읽 은 사진 입니다 . 애플 펜슬 나오 기 전 이 어서 고무 팁 스타일러스 를 썼 고요 . 스타일러스 는 아마 벨 킨 에서 나온 걸 썼 던 걸로 기억 해요 . ( 정확 하 진 않 음 ) 유 패드 에서 굿 노트 로 넘어오 게 된 이유 는 \\' 직선 밑줄 \\' 기능 이 유 패드 에 는 없 고 굿 노트 에 있 어서 였 습니다 . 제 가 밑줄 을 너무 비뚤비뚤 그려 서요 . . ㅋㅋ 그런데 참 재미있 는 게 , 사람 은 아날로그 이 든 디지털 이 든 자기 가 활용 하 는 방식 만큼 만 활용 할 줄 아 는 것 같 아요 . 위 사진 에서 필기 가 회색 이 잖아요 , 그게 제 가 평소 에 종이 에 예습 을 할 때 에 는 검정 펜 이나 샤프 만 사용 하 던 습관 이 있 어서 그랬 어요 . 최대한 아 날로 그 상태 의 제 습관 과 비슷 하 게 구축 하 려고 했 던 거 죠 . 2 . 종이 로 읽 은 것 스캔 해서 넣 기 이건 당시 에 시력 이 많이 안 좋 아 져서 종이 에 인쇄 해서 샤프 로 표시 해 가 면서 읽 은 걸 다시 스캔 해서 pdf 로 넣 은 거 예요 . 이렇게 다시 스캔 해서 수업 에 들어갈 때 에 는 아이패드 만 가지 고 갔 어요 . 3 . 마인드맵 으로 요약정리 한 후 인쇄 하 기 수형 도 마인드맵 은 아래 같 은 형태 를 말 해요 . 일명 top - down 방식 이 라고 도 합니다 . 1 , 2 , 3 , 4 , 5 자리 에 논문 의 소제목 이나 단행본 한 챕터 의 소제목 이 들어가 게 한 후 내용 을 정리 하 면 한 눈 에 보 기 좋 습니다 . 바로 위 사진 이 제 가 top down 방식 으로 내용 정리 하 는 예시 고요 . 그런데 이게 인쇄 할 때 에 는 불편 하 거든요 . 아이 패드 에 직접 필기 를 한다면 마인드맵 전체 를 pdf 로 내보내 면 되 지만 , 종이 에 인쇄 한다면 마인드맵 을 워드 에서 열 수 있 는 파일 로 내보내 면 깔끔 한 개요 형태 로 인쇄 할 수 있 습니다 . 위 워드 파일 은 교재 를 읽 으면서 원래 mindmeister 에서 수형 도 모양 으로 요약정리 를 한 것 을 워드 로 내보낸 모습 이 에요 . 저 때 도 눈 이 안 좋 아서 저걸 종이 에 인쇄 해 갔 어요 . 이런 방식 을 택한 건 , 마인드맵 에서 수형 도 방식 으로 정리 하 는 것 이 챕터 의 내용 을 한 눈 에 보 기 좋 기 때문 이 었 어요 . 4 . 워드 / 한글 / pages 이용 해서 요약 정리 하 기 표 를 많이 사용 해야 할 때 이용 하 면 좋 습니다 . 마인드맵 에다가 표 까지 따로 넣 기 는 번거롭 거든요 . 또 매번 손 이 든 스타일러스 든 직접 그리 기 도 귀찮 고 요 . 5 . 아이패드 에서 필기 앱 으로 애플 펜슬 로 정리 하 면서 읽 기 + 단권 화 : 고급 위 사진 은 아이패드 에서 굿 노트 앱 으로 , 애플 펜슬 을 이용 해서 읽 은 단행본 의 일부 를 다시 pdf 로 내보내 어 하나 의 파일 로 만든 것 입니다 . 이제 드디어 컬러 를 쓰 기 시작 했 죠 ㅋㅋ ㅋㅋ 사실 컬러 를 쓰 게 된 것 은 파일 롯 사 의 \\' 프릭션 \\' 인 \" 지워 지 는 펜 \" 을 발견 하 면서 , 아날로그 필기 가 컬러 로 바뀌 게 되 었 기 때문 이 었 어요 . 아이패드 에서 자료 를 관리 하 기 시작 하 면서 본격 적 인 단권 화 가 아이패드 안 에서 이루어지 게 되 었 습니다 . 필요 한 다른 자료 를 인터넷 에서 검색 하 거나 다른 논문 / 책 에 있 는 부분 을 캡쳐 해서 불러오 는 방식 으로 단권 화 를 하 였 습니다 . 이 연재 초반 에 등장 한 단권 화 와 비교 해 보 면 정말 많이 발전 했 죠 . 2016 / 04 / 08 - [ 아날로그 + 디지털 공부 법 ] - [ 필기 의 끝판 왕 ] 2 . 중 고등학교 ( 1 ) 아날로그 : 교재 에 단권 화 하 기 2016 / 04 / 09 - [ 아날로그 + 디지털 공부 법 ] - [ 필기 의 끝판 왕 ] 3 . 중 고등학교 ( 2 ) 아날로그 : 노트 에 단권 화 하 기 * 모바일 에서 다른 공부 법 카테고리 보 기 : 왼쪽 하단 투명 한 ≡ 아이콘 -> 카테고리 메뉴 -> 글 목록 ** 페이스북 페이지 : [ URL ] *** 티스토리 에서 비밀 댓글 작성 시 답글 을 확인 할 수 없 으므로 공개 로 달 아 주 세요 .',\n",
       "       \"이 글 에서 분석 해 볼 paper 는 [ forecasting at scale ] 으로 , facebook 의 신기 방기 한 시계열 분석 라이브러리 인 prophet 에 대한 설명 이 있 는 paper 입니다 . 논문 으로 는 20 페이지 가 넘 어 읽 기 가 불편 ( ? ) 할 수 있 어 제 가 대신 읽 어 보 겠 습니다 . peer - reviewed 가 되 어 있 지 않 다고 되 어 있 지만 , 현실 에서 미치 는 라이브러리 의 현재 파급 력 으로 보 아 충분히 볼 만 한 가치 가 있 어 보 입니다 . 저작 권 을 살펴보 니 냅다 사용 해도 괜찮 네요 . 이 를 살펴보 게 된 이유 는 , kdd 2018 미세먼지 예측 에서 상위 권 에 포진 한 랭 커 가 날씨 예보 정보 를 전혀 쓰 지 않 고 과거 정보 만 으로 냅다 미세먼지 예측 량 을 맞추 게 되 는 방법 중 하나 가 바로 이 prophet library 이 기 때문 이 였 기 때문 입니다 . 이 글 에서 대부분 의 내용 은 paper 에서 언급 하 는 내용 이 며 , 몇 가지 이해 를 돕 기 위한 이미지 몇 개 만 인터넷 에서 찾 아서 붙여 놨으니 살펴보 시 고 필요 하 다면 원래 paper 를 찾아보 면 될 듯 합니다 . 링크 는 아래 와 같 습니다 . [ URL ] 저자 는 sean j tay 와 benjamin letham 두 명 입니다 . 우리 나라 국적 의 회사 도 이렇게 세상 에 영향 을 미치 는 뛰어나 거나 실용 적 인 paper 도 발표 하 고 존경 도 받 으면 좋 을 것 같 다는 생각 이 듭니다 . 초록 은 현재 신기 하 게 도 현재 시계열 의 전문가 가 많이 없 다는 점 을 강조 해서 말 하 고 있 다는 점 이 눈 에 들어옵니다 . 한국 이나 미국 이나 마찬가지 인 듯 싶 습니다 . 그래서 아무 나 쉽 게 만질 수 있 는 business - time series 도구 를 만들 었 다 ! 라고 하 는 점 이 인상 적 입니다 . 시계열 분석 은 실제 생산 관리 나 수요 예측 을 위해 특별히 많이 쓰 게 되 는데 , paper 에서 는 다음 두 가지 점 에 있 어서 한계 가 있 다고 지적 합니다 . 1 ) 완전 자동 화 되 는 시계열 은 튜닝 하 기 가 어렵 다는 점 2 ) 기업 도메인 지식 이 뛰어난 사람 은 시계열 에 대한 지식 이 부족 한 점 . 시계열 을 통한 예측 은 특히 나 실무 에서 굉장히 수요 가 큰 데 도 불구 하 고 품질 이 그다지 좋 지 않 은 편 입니다 . 그래서 paper 는 scale ( 컴퓨팅 파워 를 뜻 하 는 것 이 아닌 , 모델 자체 의 확장 가능 성 에 대한 개념 ) 이 가능 한 시계열 을 만들 겠 다는 원대 한 포부 를 밝힙니다 . 최대한 많 은 사람 들 이 쓸 수 있 고 , 여러 feature 들 을 고려 할 수 있 는 누구 나 만질 수 있 는 시계열 도구 를 제공 하 는 데 목적 이 있 습니다 . analyst - in - the - loop , 즉 분석가 들 은 필요 한 모델링 과 그 결과 를 살펴보 는 것 으로 족하 고 나머지 피곤 한 작업 들 은 도구 가 알 아서 해 주 도록 하 는 것 이 목적 이 겠 죠 . 그렇 다면 시계열 에 들어갈 만 한 요소 들 은 도대체 무엇 이 있 을까요 ? 위 는 페이스북 의 여러 이벤트 , 친구 신청 이나 여러 상호 작용 을 점 으로 나타낸 그래프 인데 여기 에 는 어떤 효과 가 숨 어 있 을까요 . 자세히 살펴보 면 눈 에 보이 는 연도 , 요일 , 그리고 잘 살펴보 면 연말 효과 , 시즌 효과 등 도 숨 어 있 을 것 입니다 . 심지어 는 물건 이 새로 출시 되 거나 할 때 트렌드 가 완전히 ( ! ) 바뀌 는 경우 가 생깁니다 . prophet 이 아닌 기존 의 방법 들 을 소개 하 자면 아래 에 잘 나타나 있 습니다 . 위 에서부터 차례 대로 제일 일반 적 인 auto . arima 를 이용 한 방법 , 그 다음 은 ets 는 지수 평활 법 을 이용 한 방법 , seasonal naive 방법 , tbats ( 주 , 년 도 계절 성 고려 ) 하 는 모델 입니다 . arima 모형 이 좀 특이 한 편 인데 , 계절 성 을 잘 포착 하 지 못하 는 모습 을 보여 주 고 있 습니다 . ets 와 snaive 는 좀 더 장기 적 인 안목 없이 직선 만 찍찍 그 어 놨 구요 . 이러 한 현상 이 나왔 을 때 바로 고객 한테 들 고 가 는 것 은 위험 한 행위 입니다 . 바로 몇 가지 파라미터 들 을 바꾸 면서 튜닝 노가다 를 시작 해야 할 수 도 요 . arima 의 경우 , 최대 차분 갯 수 , 자기 회귀 , 이동평 균 세 부분 을 조정 가능 한데 이 부분 이 잘 모르 는 사람 들 에게 는 쉽 지 않 을 거 라고 paper 에서 는 분석 하 는 사람 들 을 쪼 오금 무시 ( ? ) 합니다 . 역시 페이스북 연구원 들 . .. 영리 한데 ? 어쨌거나 네 가지 모델 모두 제일 끝 쪽 의 데이터 의 흐름 은 잘 포착 하 지 도 못하 고 있 는데 , prophet 은 이러 한 부분 을 잘 포착 해 주 는지 한 번 살펴보 면 되 겠 습니다 . prophet 은 harvey & peters 1990 의 기본 적 인 세 개 의 요소 를 따릅니다 . g ( t ) 는 반복 적 인 요소 를 가지 지 않 은 트렌드 . s ( t ) 는 요일 혹은 연 계절 성 과 같 은 반복 적 인 변화 , 그리고 h ( t ) 는 holiday 와 같이 가끔 씩 불 규칙 하 게 영향 을 미치 는 요소 입니다 . e 는 정규 분포 를 따르 는 잔차 라고 가정 합니다 . 이 는 gam 모델 ( generalized additive model ) 과 비슷 한데 , 뭔가 새로운 것 이 발견 되 었 을 때 다시 모델 을 쉽 게 훈련 할 수 있 다는 장점 이 있 습니다 . ( l - bfgs 참조 ) 따라서 , 페이스북 이 만든 prophet 이 라는 모델 도 , 위 처럼 뭔가 라인 을 하나 기 가 막히 게 그리 는데 초점 을 맞추 고 있 지 , arima 처럼 내부 데이터 구조 가 어떻게 생겼 는지 에 중점 을 두 고 있 지 는 않 다고 합니다 . 이렇게 해서 얻 는 이득 은 아래 와 같 은데요 , - 유연 성 : 계절 성 과 여러 기간 들 에 대한 예측 을 쉽 게 모델 에 적용 할 수 있 습니다 . 분석가 들 은 여러 가지 를 해 볼 수 있 겠 죠 . - arima 모델 과 다르 게 , 모델 을 차분 해서 정규 화 시킬 필요 도 없 고 결 측 치 들 을 굳이 구겨 넣 을 이유 가 없 습니다 . - 훈련 은 빠르 고 분석가 는 여러 가지 상세 한 모델 스펙 을 탐험 할 수 있 습니다 . 샤이니 와 같 은 어플리케이션 에서 요 ! - 결국 에 는 회귀분석 과 같 은 느낌 이 기 때문 에 좀 어렵 고 생소 한 시계열 분석 등 보다 빠르 게 적응 할 수 있 는 측면 이 있 습니다 . g ( t ) : trend 이제 , 실무자 들 이 겪 은 페이스북 에서 의 여러 상황 에 대한 모델 들 을 살펴보 도록 합니다 . 두 가지 를 소개 하 고 있 는데 saturating growth model , 그리고 piecewise linear model 두 가지 입니다 . 이 두 개 의 모델 은 나름 의 g ( t ) 를 설정 합니다 . 먼저 saturating growth model 입니다 . 페이스북 에서 나온 논문 인지 는 몰라도 , ( 저 는 앱 이 깔려 있 지 않 지만 ) 어떤 지역 들 은 그냥 인터넷 접속 이 가능 한 사람 들 이 다 페이스북 유저 아닐까 ? 라는 물음 을 던지 면서 아래 와 같 은 식 을 써 놓 습니다 . c - carrying capacity , k - growth rate , m - offset parameter 이해 를 돕 기 위해 그래프 를 하나 그려 보 면 , 아래 와 같 은 모양 을 띄 게 될 겁니다 . 다만 , 여기 서 c 는 인터넷 사용 자 의 증가 에 따라서 충분히 바뀔 수 있 는 값 이 기 때문 에 c ( t ) 로 교체 하 고 , 성장 률 또한 지역 마다 달라지 기 때문 에 이 를 충분히 반영 해 줘야 합니다 . 여기 서 중요 한 changepoint 라는 개념 이 생기 는데 , 모델 에 무언가 변동 사항 이 생기 는 시점 을 포착 해서 뭔가 조치 를 취해야 할 때 필요 한 항목 이 라 보 면 될 것 같 습니다 . 예 를 들 어 처음 에 는 성장 률 을 k % 로 잡 았 다면 이 는 점점 지나 면서 changepoint 마다 조금 씩 조정 이 되 면서 아래 와 같 은 형식 으로 수정 이 될 것 입니다 . 결국 최종 적 으로 도출 되 는 식 은 이 조정 치 들 을 모두 고려 한 piecewise logistic growth model 로 탄생 하 게 됩니다 . 여기 서 piecewise 란 , 상황 에 따라 여러 방정식 이 묶이 는 경우 를 말 하 는데 , 어쨌든 우리 는 시간 에 따라 조정 되 는 조정 치 a ( t ) 를 가지 고 있 으므로 동적 으로 바뀌 게 되 므로 piecewise 라는 말 이 이해 가 될 수 있 습니다 . 위의 의 식 이 좀 복잡 한데 a ( t ) 는 adjustments 를 위한 함수 로 보 고 , 계속 해서 성장 률 이 시간 에 따라 바뀔 수 있 다는 점 을 표시 한 식 입니다 . m 도 그 에 맞춰 곡선 으로 이어지 게 바뀌 어 줘야 하 니 똑같이 조정 을 해 주 고요 . 다만 , c ( t ) 라는 함수 는 대체 어떻게 짜 느냐 . paper 에서 이 부분 은 슬며시 독자 에게 공 을 넘깁니다 . 월드 뱅크 자료실 이 라든지 너 의 도메인 지식 을 이용 하 면 되 지 않 겠 어 ? 라는 말 을 던지 고 홀연히 설명 을 마칩니다 . 결국 중요 한 건 prophet 에서 사용 하 는 g ( t ) 라는 항목 은 도메인 지식 이 짬뽕 된 아래 의 g ( t ) 로 사용 할 수 있 다는 것 이 중요 하 다고 말 할 수 있 을 겁니다 . 예 를 들 어 전자 제품 의 수요 를 때려 맞춰야 하 는 경우 각종 광고 나 날씨 에 대한 영업 사원 들 의 노하우 가 있 다면 시계열 에 슬쩍 녹이 기 가 쉽 고 , 이 를 시각 적 으로 확인 하 기 도 용이 하 다 를 말 하 고 있 다고 보 면 될 것 같 습니다 . 하지만 , 우리 가 미래 구간 을 예측 해야 할 때 는 사실 이런 changepoint 가 어디 서 출몰 할지 알 기 가 불 가능 합니다 . prophet 에서 는 이러 한 changepoint 의 등장 도 과거 와 같이 미래도 adjustment ~ laplace ( 0 , τ ) 의 주기 로 나타난다고 가정 합니다 . 그리고 τ 는 이전 의 데이터 에서 유추 가능 한 값 이 되 겠 습니다 . s ( t ) : seasonality 시계열 은 다른 데이터 와 다르 게 주기성 을 가집니다 . paper 에서 는 푸리에 급수 로부터 시작 해갑니다 . p 는 목적 에 맞 게 연단 위 라면 365 . 25 를 , 일 주일 단위 라면 7 을 넣 게 됩니다 . 여기 서 n 을 얼만큼 넣 느냐 가 이슈 가 되 는데 , 연도 기준 이 라면 n 은 10 , 그리고 주 단위 라면 n 은 3 이 모든 문제 에 제일 잘 들어맞 는 것 같 다고 주장 합니다 . 물론 이 파라미터 를 조정 할 수 도 있 겠 죠 . 보통 n 이 크 면 패턴 이 빠르 게 바뀌 게 되 며 , n 이 작 으면 느리 게 변하 는데 아래 의 구글 이미지 를 참고 하 면 될 것 같 습니다 . 그리고 이 를 풀 기 위해 행렬식 으로 표현 하 자면 , β = [ a 1 , b 1 , . . . , an , bn ] 에 대해 라는 식 을 도출 하 게 됩니다 . h ( t ) : holiday 사실 실제 비즈니스 상황 에서 는 제일 중요 한 것 일 수 도 있 는 게 휴일 여부 인데 , 다른 건 뻔한 측면 이 있 는 한편 블랙 프라이데이 나 여타 다른 이벤트 들 은 크 게 기업 들 의 생산 관리 나 이윤 창출 에 영향 을 미치 게 됩니다 . 설날 같 은 휴일 도 범아 시아 적 으로 영향 을 미치 고 있 구요 . 게다가 설날 같 은 경우 는 음력 으로 정해져서 매일 날짜 가 바뀌 며 , 11 월 넷째 주 목요일 행사 ! 와 같이 회사 별 로 일자 가 정해 지 지 않 은 경우 도 있 습니다 . 크리스마스 는 매년 같 다고 해도 말 입니다 . 이 를 하나하나 코딩 에 넣 기 란 여간 성가신 일 이 아닙니다 . 하지만 , prophet 에서 는 이러 한 휴일 과 방학 등 의 상황 을 잘 이해 하 고 있 으며 아래 와 같 은 식 으로 나타내 고 있 습니다 . t 로 나타내 어 지 는 특정 한 시간 이 우리 의 휴일 리스트 d 에 포함 되 어 있 음 을 확인 하 고 이 에 대한 조정 이 들어가 며 , 추가 적 으로 특정 휴일 주변 날 들 도 냅다 휴일 과 마찬가지 의 영향력 을 가지 게 파라미터 설정 도 가능 합니다 . model fitting 주기성 과 휴일 에 관한 정보 가 행렬 x 에 준비 되 어 있 고 , changepoint 에 대한 정보 가 행렬 a 에 잘 마련 되 어 있 으면 아래 와 같 은 몇 가지 심플 한 코드 로 결과 를 꺼내 볼 수 있 습니다 . ( 참고 로 stan 구 현물 은 r 과 python 등등 을 지원 합니다 . [ URL ] 이러 한 간단 한 구 현물 로 낸 결과 는 아래 와 같 습니다 . 맨 위 에서 봤 던 arima 등등 과 같 은 시간 의 자료 로써 , prophet 은 주 단위 , 연단 위 주기성 을 잘 포착 하 고 있 는 것 으로 보입니다 . 다만 2014 년 을 보 면 2013 년 을 통해 조금 은 오 버피팅 된 느낌 이 있 긴 합니다 . 모든 사용 가능 한 데이터 로 트렌드 를 나타낸 그래프 로 , 점선 으로 표현 된 부분 은 샘플 이 없 는 예측 부분 입니다 . 아래 는 각각 의 요소 별 로 어떠 한 변화 가 있 나 확인 해 볼 수 있 는 그래프 입니다 . 실제 r 로 해봐도 그냥 냅다 코드 만 부르 면 끝나 더군요 . ( 실습 부분 은 나중 에 ) 분석가 는 그래서 무엇 을 할 수 있 나 ? paper 에서 prophet 이 자주 쓰이 기 를 바라 는 분석가 의 정의 는 , 시계열 과 통계 를 잘 모를 수 도 있 지만 물건 이 언제 팔리 고 어느 공휴일 에 얼만큼 나가 는지 정말 잘 알 고 있 는 우리 네 회사원 과 같 은 ' 업무 ' 경험 이 풍부 한 사람 입니다 . - capacities ( 시장 총 수요 ) - changepoints ( 상품 이 바뀌 거나 신 제품 이 출시 될 때 ) - holiday and seasonality ( 판매량 에 영향 을 많이 미치 는 휴일 등 ) - smoothing parameter ( 주기 마다 변동 을 얼마나 나타내 야 하 는지 ) 우리 들 은 이 에 대한 조건 들 을 바꿔서 계속 prophet 을 실행 해 볼 수 있 습니다 . 재미있 게 도 이 paper 에서 강조 하 는 포인트 는 분석가 는 그럴듯한 시각 화 툴 을 가지 고 이러 한 파라미터 들 을 쉽 게 조정 하 여 플로팅 하 고 다시 재 모델 링 해 보 는 과정 을 빠르 게 반복 하 기 를 추천 한다는 것 입니다 . τ 를 바꿔서 주기성 을 자주 반영 하 게 해준다던 지 , σ 를 바꿔서 주기성 을 강하 게 반영 하 게 해준다던 지 , 등 을 말 입니다 . 이러 한 점 은 맨 위 의 그림 에 있 는 것 처럼 도메인 지식 을 가지 고 있 는 사람 이 직관 을 가지 고 해야 더 나 은 부분 이 있 을 것 입니다 . 현란 한 수식 들 이 등장 하 지만 , 어느 정도 의 기본 파라미터 들 이 무엇 을 하 는지 만 알 고 바로 조정 을 하 면서 모델 을 만들 면 쉽 게 도메인 전문가 가 전문 지식 을 넣 을 수 있 다고 주장 합니다 . 페이스북 이 만든 prophet 은 [ transform - visualize - model ] ( wickham & grolem 2016 ) 과 비슷 한 접근 법 을 사용 했 다고 하 여 참고 할 만 합니다 . 인간 이 찾아낸 인사이트 가 코딩 이 되 어 다시 모델 이 되 는 반복 적 인 모델 이 라고 하 네요 . prophet 은 인간 의 직관 은 극대 화 시키 고 , 자동 화 시키 는 부분 은 자동 화 시키 는 편리 한 툴 이 라고 할 수 있 겠 습니다 . model evaluation 여기 서 마무리 되 어야 할 것 같 지만 , 모델 을 만드 는데 있 어 제일 중요 한 부분 은 forecast 결과 를 평가 하 는 부분 이 라고 합니다 . 즉 , 평가 를 한 후 좋 은지 나쁜지 빠르 게 확인 할 수 있 어야 이것 이 loop 가 되 면서 다시 좋 은 모델 을 만들 기 위한 자양분 이 될 것 이 기 때문 입니다 . 일단 현란 하 게 수식 한 번 적 어 주 지만 별게 아닙니다 . 201810 주 차 ( t ) 까지 자료 가 있 고 이후 에 8 주 차 ( h ) 를 더 예측 하 는데 그 사이 거리 입니다 . 페북 은 mape ( mean absolute percentage error ) 를 해석 상 선호 한다고 합니다 . 오 차 항 은 위 와 같 은데 , 몇 가지 가정 은 있 습니다 . 지역 적 ( locally ) 평활 화 가 되 어 있 어 에러 가 있 으면 예측 전구 간 에서 일정 하 게 발생 하 여야 한다는 점 , 그리고 시간 이 지날수록 ( h ) 예 측력 은 조금 씩 떨어져야 한다는 것 입니다 . 이 paper 에서 는 에러 를 체크 하 기 위해 simulated historical forecasts 방법 을 소개 합니다 . 사실 이 방법 은 누구 나 생각 할 수 있 는 상식 적 인 방법 입니다 . 데이터 가 시계열 이 고 막 섞 을 수 가 없 기 때문 에 여러 가지 데이터 절 단점 에서 생성 되 는 forecast 데이터 를 가지 고 측정 할 수 있 습니다 . 데이터 전역 에서 윈도우 사이즈 가 작 은 여러 데이터 셋 을 가져올 수 있 는데 이러 한 것 들 을 모아 예측 을 한다면 여러 예측 을 해 볼 수 있 습니다 . 여러 번 측정 하 면 에러 는 어느 지점 으로 수렴 할 것 입니다 . 사실 이 윈도우 가 작 으면 에러 가 너무 막 바뀌 고 윈도우 가 너무 크 면 사실 계속 돌려도 어차피 들 어 있 는 데이터 가 비슷 할 것 이 기 때문 에 그냥 경험 상 이 들 은 대충 전체 기간 의 반절 정도 를 대상 으로 사이즈 를 잡 고 나올 수 있 는 예측 치 를 측정 한다고 합니다 . 그리고 또 하나 팁 이 있 다면 트렌드 를 좀 더 확실 하 게 보 기 위해 산점도 를 사용 하 며 라인 차트 는 이용 하 지 않 는 편 이 라고 합니다 . 이렇게 해서 열심히 뽑아낸 결과 는 , 다음 과 같 습니다 . 역시 에러 율 에서 제일 낮 은 게 prophet 입니다 . auto . arima 는 파라미터 를 수동 으로 설정 하 지 않 는 한 은 에러 가 굉장히 높 습니다 . ( 수동 으로 파라미터 튜닝 이 당연히 가능 하 지만 여기 서 주인공 은 prophet 이 므로 ) 마지막 으로 페북 연구원 들 이 놓치 지 않 고 친절 하 게 가르쳐 주 는 모델 수정 법 도 보너스 로 있 습니다 . - baseline 모델 과 비교 하 여 뭔가 떨어져 보일 때 는 trend , seasonality 등 을 수정 하 세요 . - 특정 일자 에 예측 률 이 떨어진다면 , 아웃 라이어 를 제거 하 세요 . - 특정 cutoff ( 연말 등 ) 에 예측 률 이 떨어진다면 , changepoint 를 추가 하 는 방법 이 있 습니다 . 개인 적 으로 논문 을 읽 고 facebook 에 대해 다시 생각 해 보 게 되 는 계기 가 되 었 습니다 . facebook 을 통해 뭔가 활동 을 하 다 보 면 뻑뻑 한 규정 때문 에 막히 는 경우 가 대부분 이 였 는데 , 이렇게 논문 과 오픈 소스 라이브러리 를 통해 세상 에 기여 한다는 점 이 멋지 지 않 나요 ? tutorial 은 사실 많이 존재 하 기 때문 에 굳이 자세 하 게 적 을 필요 는 없 을 것 같 습니다 . 바로 이용 해 보 기 시작 하 자 구 욧\",\n",
       "       '안드로이드 프로젝트 를 디 컴파일 해 볼려고 인터넷 을 찾 다 보 니 . . 프로젝트 url 이나 내용 들 이 좀 변경 이 되 어서 . . 정리 차원 에서 끄적여 봅니다 . 준비물 당연 한 이야기 이 겠 지만 , 컴퓨터 에 jdk 가 설치 되 어 있 어야 합니다 . 1 . dex 2 jar apk 이미지 를 jar 파일 로 변환 해 줍니다 . 2 . jd - gui jar 파일 의 내용 ( 소스 코드 ) 보여 주 는 툴 3 . apk studio 안드로 이 리소스 를 쉽 게 풀 어 줍니다 . apk 다운로드 받 기 먼저 apk 파일 을 구해야 합니다 . 아래 사이트 에서 다운로드 받 으면 좀 더 편하 게 다운로드 를 받 을 수 있 습니다 . url : [ URL ] 간단 하 게 apk 의 id 를 입력 하 면 , 바로 apk 를 다운로드 받 을 수 있 습니다 . apk 를 jar 파일 로 변환 하 기 : dex 2 jar dex 2 jar . zip 파일 의 압축 을 풀 고 , cmd 에서 아래 와 같이 실행 하 면 됩니다 . d 2 j - dex 2 jar . bat - f - o [ 파 일 명 ] . jar [ apk 파 일 명 ] . apk facebook apk 를 예제 로 풀 어 보 면 , 아래 와 같 습니다 . d 2 j - dex 2 jar . bat - f - o sample . jar com . chbreeze . jikbang 4 a . apk jar 의 내용 보 기 : jd - gui jd - gui 를 실행 해서 파일 열기 위 로 위 에서 변환 했 던 jar 선택 하 면 , 소스 를 볼 수 있 습니다 . 리소스 보 기 apk - studio 로 실행 해서 보 시 면 됩니다 . 안드로이드 아이콘 으로 apk 파일 을 선택 하 시 면 , 안 에 있 는 파일 을 풀 고 조회 가 가능 합니다 . \\u200b',\n",
       "       'class field ( object ) : def __ init __ ( self , name ) : self . name = name self . internal _ name = \"_\" + self . name def __ get __ ( self , instance , instance _ type ) : if instance is none : return self return getattr ( instance , self . internal _ name , \"\" ) # instance 의 self . internal _ name 라는 이름 의 속성 을 반환 , # 만약 그러 한 속성 이 없 으면 \"\" 을 반환 # 즉 , getattr ( instance , self . internal _ name ) => instance . self . internal _ name def __ set __ ( self , instance , value ) : setattr ( instance , self . internal _ name , value ) # instance 의 self . internal _ name 라는 이름 의 속성 에 value 로 할당 # 즉 , setattr ( instance , self . internal _ name , value ) # => instance . self . internal _ name = value',\n",
       "       '우분투 카카오톡 설치 우분투 18 . 04 카카오톡 설치 방법 에 대해서 설명 드립니다 . playonlinux 카카오톡 설치 대신 직접 우분투 wine 설치 후 카카오톡 을 설치 할 예정 입니다 . 그리고 한글 입력 과 폰트 , 트레이 아이콘 설정 방법 등 을 함께 설명 드립니다 . ubuntu 기본 적 인 환경 설정 방법 은 아래 글 을 참고 해 주 시 기 바랍니다 . 우분투 설치 후 설정 우분투 wine 설치 현재 카카오톡 은 리눅스 를 공식 적 으로 지원 하 지 않 습니다 . 따라서 리눅스 기반 의 우분투 에서 윈도우 프로그램 을 실행 하 기 위해서 wine 이 라는 소프트웨어 가 필요 합니다 . wine 은 윈도우 프로그램 을 유닉스 계열 운 영체 에서 실행 할 수 있 는 호환 성 계층 ( compatibility layer ) 입니다 . playonlinux 또한 wine 을 기반 으로 실행 되 게 되 는데 , playonlinux 를 기반 으로 하 지 않 고 wine 을 직접 사용 하 여 카카오톡 을 설치 하 고 실행 하 는 방법 에 대해서 설명 드리 도록 하 겠 습니다 . 다음 명령어 로 wine 을 설치 할 수 있 습니다 . 64 bit 시스템 을 사용 하 고 계셔도 , wine 은 32 bit 기반 으로 실행 되 는 것 이 보다 안정 적 입니다 . 따라서 아래 의 명령어 로 wine 설치 하 실 경우 , i 386 패키지 가 함께 설치 될 것 입니다 . $ sudo apt install wine - stable cabextract wine 이 성공 적 으로 설치 되 었 을 경우 , 다음 명령어 를 이용 하 여 환경 을 초기 화 해 주 시 기 바랍니다 . $ winearch = win 32 wineprefix =~/. wine wine wineboot ~/. wine 디렉터리 에 설치 된 프로그램 과 함께 wine 설정 파일 이 모두 존재 하 게 됩니다 . 윈도우 프로그램 을 다시 설치 하 시 거나 , 설정 을 모두 삭제 할 경우 ~/. wine 디렉터리 를 삭제 해 주 신 다음 위 의 명령어 를 다시 실행 하 면 됩니다 . wine 설정 우분투 wine 카카오톡 설치 하 기 위해서 는 wine 을 먼저 설정 해 주 셔야 하 며 , 윈도우 기본 라이브러리 를 설치 해 주 셔야 합니다 . 다음 명령어 를 이용 하 여 , winetricks 라는 윈도우 라이브러리 를 설치 할 수 있 는 스크립트 를 다운 받 습니다 . $ wget [ URL ] $ chmod + x winetricks $ . / winetricks -- optout 그리고 다운 받 은 스크립트 를 실행 하 면 , 다음 과 같 은 화면 을 확인 하 실 수 있 습니다 . 위 의 화면 에서 [ ok ] 버튼 을 클릭 합니다 . 그리고 다음 과 같 은 화면 에서 [ install a windows dll or component ] 를 선택 하 여 [ ok ] 버튼 을 클릭 합니다 . 다음 화면 과 같이 설치 할 패키지 를 선택 할 수 있 는 화면 이 나타납니다 . 아래 의 화면 에서 gdiplus , riched 30 , wmp 9 , msxml 6 패키지 와 d 3 dx 9 _ 43 를 설치 합니다 . 그리고 [ ok ] 버튼 을 클릭 하 면 선택 된 패키지 가 설치 되 게 됩니다 . 설치 가 완료 되 면 실행 된 winetricks 를 종료 합니다 . 카카오톡 실행 에 필수 라이브러리 가 설치 되 지 않 을 경우 , 카카오톡 로그인 실패 또는 방화벽 등 의 네트워크 문제 로 로그인 실패 메세지 가 나타날 수 있 으니 주의 해 주 시 기 바랍니다 . 주로 발생 하 는 로그인 오류 는 카카오톡 오류 코드 50114 입니다 . 설치 되 는 라이브러리 , wine 의 운영 체제 버전 , 카카오톡 설치 버전 등 을 확인 해 주 시 기 바랍니다 . 한글 폰트 설치 윈도우 가 설치 된 pc 에서 c : / windows / fonts 디렉 토리 에서 gulim . ttf 한글 폰트 를 복사 한 뒤 에 ~/. wine / drive _ c / windows / fonts 에 복사 합니다 . 폰트 의 퍼 미션 은 644 으로 지정 해 주 셔야 합니다 . 그리고 ~/. wine / system . reg 파일 을 엽 니다 . \" ms shell dlg \"=\" tahoma \" \" ms shell dlg 2 \"=\" tahoma \" 위 의 내용 을 아래 와 같이 수정 합니다 . \" ms shell dlg \"=\" gulim \" \" ms shell dlg 2 \"=\" gulim \" 우분투 카카오톡 설치 아래 의 페이지 에 방문 하 신 다음 [ 다운로드 ] 메뉴 에서 카카오톡 설치 파일 을 다운 받 습니다 . winecfg 명령어 를 이용 하 면 현재 wine 에서 사용 되 는 윈도우 버전 을 확인 할 수 있 습니다 . 설정 된 윈도우 버전 에 맞 는 카카오톡 을 받 으시 면 됩니다 . [ URL ] 다운 받 으신 카카오톡 설치 파일 을 다음 명령어 로 설치 를 합니다 . $ wine - stable kakaotalk _ setup . exe 카카오톡 실행 우분투 영문 판 에 한글 을 설정 하 여 사용 하 고 있 을 경우 , 카카오톡 실행 시 언어 셋 을 설정 해 주 셔야 합니다 . exec = env wineprefix =\"/ home / ubuntu / . wine \" wine - stable c : \\\\\\\\\\\\\\\\ windows \\\\\\\\\\\\\\\\ command \\\\\\\\\\\\\\\\ start . exe / unix / home / ubuntu / . wine / dosdevices / c : / programdata / microsoft / windows / start \\\\\\\\ menu / programs / kakaotalk / kakaotalk . lnk ~/. local / share / applications / wine / programs / kakaotalk / kakaotalk . desktop 파일 을 편집기 로 엽 니다 . 그리고 위 의 내용 을 아래 와 같이 수정 합니다 . lang 라는 환경 변수 가 추가 되 었 는데 , 카카오톡 설치 경로 에 주의 해 주 시 기 바랍니다 . exec = env wineprefix =\"/ home / ubuntu / . wine \" lang =\" ko _ kr . utf - 8 \" wine - stable c : \\\\\\\\\\\\\\\\ windows \\\\\\\\\\\\\\\\ command \\\\\\\\\\\\\\\\ start . exe / unix / home / ubuntu / . wine / dosdevices / c : / programdata / microsoft / windows / start \\\\\\\\ menu / programs / kakaotalk / kakaotalk . lnk gnome 쉘 을 다시 실행 하 거나 , 재 부팅 합니다 . 그리고 카카오톡 을 아래 와 같이 검색 하 여 실행 할 수 있 습니다 . 우분투 카카오톡 한글 깨 짐 또는 한글 입력 이 안 될 경우 언어 셋 또는 한글 폰트 등 을 확인 해 주 시 기 바랍니다 . 실행 된 카카오톡 화면 은 아래 와 같 습니다 . 시스템 트레이 설정 카카오톡 이 실행 되 면서 아래 와 같이 [ wine sytem tray ] 윈도우 가 함께 생성 됩니다 . 이 생성 된 윈도우 를 gnome 상단 패널 에 붙이 도록 하 겠 습니다 . 다음 명령어 를 이용 하 여 gnome shell extension 을 설치 합니다 . $ sudo apt install gnome - shell - extension - top - icons - plus gnome 쉘 을 다시 실행 하 고 , 검색 에서 [ tweaks ] 를 검색 하 여 실행 합니다 . [ extensions ] 탭 에서 topicons plus 라는 플러그인 을 활성 화 하 면 아래 의 이미지 처럼 패널 에 붙 은 것 을 확인 하 실 수 있 으실 겁니다 . 카카오톡 한글 깨 짐 우분투 에서 카카오톡 을 실행 해서 가장 자주 발생 하 는 문제 가 한글 깨 짐 문제 입니다 . 여러 가지 형태 로 한글 깨 짐 문제 가 나타날 수 있 는데 , 자주 발생 하 는 문제 가 한글 입력 시 네모 박스 인 사각형 으로 나타나 는 문제 입니다 . 원인 과 해결 방법 을 함께 설명 드리 도록 하 겠 습니다 . 기존 의 먼저 카카오톡 이 실행 되 고 있 다면 , 먼저 카카오톡 을 종료 해 주 시 기 바랍니다 . 그리고 다음 명령어 카카오톡 이 설치 된 디렉터리 로 이동 합니다 . $ cd \"/ home / ubuntu / . wine / dosdevices / c : / program files / kakao / kakaotalk \" 그리고 카카오톡 이 설치 된 디렉터리 에서 다음 명령어 로 직접 카카오톡 을 실행 합니다 . $ wine - stable kakaotalk . exe 카카오톡 이 실행 된 다음 직접 한글 을 입력 하 실 경우 , 아래 의 이미지 처럼 한글 이 깨 질 수 있 습니다 . 위 의 이미지 처럼 한글 이 깨 졌을 경우 , 실행 중 인 카카오톡 을 종료 후 다음 과 같이 실행 합니다 . $ lang =\" ko _ kr . utf - 8 \" wine - stable kakaotalk . exe 정상 적 으로 한글 이 입력 되 게 될 경우 , 카카오톡 이 실행 될 때 의 언어 셋 을 위 와 같이 설정 하 여 실행 되 면 됩니다 . 본문 에서 는 데스크 탑 실행 스크립트 를 수정 하 여 실행 하 는 방법 이 설명 되 었 습니다 . 원 하 시 는 형태 로 스크립트 를 작성 하 셔서 실행 하 셔도 됩니다 . ( 본문 인용 시 출처 를 밝혀 주 시 면 감사 하 겠 습니다 . )',\n",
       "       \"웹 브라우저 에서 지금 보 고 있 는 사이트 의 주소 를 복사 해서 다른 곳 에 붙여 넣 었 더니 , 한글 은 온데간데없이 사라지 고 왠 % 로 시작 하 는 이상 한 문자 가 대신 들어가 있 는 것 을 본 적 이 있 으신 가요 . 바로 url 인코딩 때문 입니다 . 파이썬 으로 크롤링 을 진행할 때 도 이 한글 이 종종 문제 가 되 는데요 . 오늘 은 그 해결 방법 을 알아보 겠 습니다 . 퍼센트 인코딩 이 란 퍼센트 인코딩 ( percent - encoding ) 은 url 에 문자 를 표현 하 는 문자 인코딩 방법 으로 영문자 , 숫자 , 몇몇 기호 만 을 사용 하 여 문자 를 나타냅니다 . 이 외 에 한글 , 한자 , 특수 문자 등 은 사용 할 수 없 습니다 . 때문 에 파이썬 에서 한글 포함 된 url 주소 에 요청 을 보내 면 오류 가 발생 하 게 됩니다 . 다행히 이 오류 를 피하 는 방법 이 있 습니다 . 첫 번 째 방법 은 한글 텍스트 를 퍼센트 인코딩 하 는 하 는 것 입니다 . import urllib urllib . parse . quote ( ' 행주 ') # % ed % 96 % 89 % ec % a 3 % bc 두 번 째 방법 은 requests 라이브리 를 사용 해서 요청 을 보낼 때 params 매개변수 를 함께 사용 하 는 것 입니다 . import requests url = ' 주소 ' payload = {' key 1 ': ' value 1 ', ' key 2 ': ' value 2 '} r = requests . get ( url , params = payload ) 예시 지 마켓 에서 ' 노트북 ' 이 라는 키워드 로 검색 을 했 습니다 . 이때 주소창 을 잘 보 면 노트북 이 라는 한글 문자 가 퍼센트 인코딩 된 것 을 볼 수 있 습니다 . 파이썬 에서 퍼센트 인코딩 처리 를 하 는 예제 를 다루 어 보 겠 습니다 . 1 ) 한글 텍스트 를 직접 적 으로 퍼센트 인코딩 하 는 경우 # 라이브러리 가져오 기 import requests from bs 4 import beautifulsoup import urllib # 검색 키워드 퍼센트 인코딩 처리 keyword = ' 노트북 ' keyword = urllib . parse . quote ( keyword ) url = f '[ URL ] # http 요청 및 처리 r = requests . get ( url ) soup = beautifulsoup ( r . text , ' html . parser ') keyword = soup . select ( '. box __ keywords . list __ keywords li ') for word in keyword : print ( word . get _ text ( ) ) 2 ) params 매개변수 를 이용 하 는 경우 url = f '[ URL ] payload = {' keyword ': ' 노트북 '} r = requests . get ( url , params = payload ) soup = beautifulsoup ( r . text , ' html . parser ') keyword = soup . select ( '. box __ keywords . list __ keywords li ') for word in keyword : print ( word . get _ text ( ) ) 두 코드 모두 상품 연관 검색어 를 출력 해줍니다 . - 이 글 은 아나콘다 ( anaconda 3 ) 가 설치 된 주피터 노트북 에서 작성 되 었 습니다 .\",\n",
       "       '2012 / 12 / 03 볼 로 네즈 파스타 , 라구 소스 딸리 아 뗄 레 , 리가토니 위키 에 따르 면 pellegrino artusi 가 1891 년 에 쓴 science in the kitchen and the art of eating well 주방 의 과학 과 잘 먹 는 것 의 예술 이 라는 책 에 볼로냐 지방 에서 먹 는 고기 소스 에서 기인 한 음식 이 라고 처음 나와 있 다고 한다 . 시간 이 지나 면서 ragù alla bolognese 라는 이름 의 요리 로 발전 했 고 일반 적 으로 라구 소스 라고 도 불리 며 현재 는 세계 적 으로 가장 사랑 받 는 소스 중 에 하나 이 다 . 이탈리아 요리 를 보존 한다는 이탈리안 아카데미 오브 퀴진 에서 는 클래식 볼 로 네즈 라구 에 들어가 는 재료 로 소고기 , 판 체타 , 양파 , 당근 , 샐러리 , passata 라는 체 에 내린 토마토 ( 토마토퓌레 대체 가능 ) , 고기 브로스 , 드라이 와인 ( 스파클 링 을 제외 한 레드 혹은 화이트 ) 소금 , 후추 , 우유 에 추가 적 으로 크림 까지 권장 하 고 있 다 . 마른 버섯 이나 닭 간 등 도 잘 어울린다고 하 고 실제로 이 재료 를 각각 추가 한 레시피 로 요리 한 것 도 보 았 다 . food network 에서 괜찮 아 보이 는 레시피 와 처음 으로 산 요리 책 을 참고 해서 만들 었 다 . food network 의 레시피 는 양파 , 당근 , 샐러리 , 마늘 , 올리브 오 일 , 소금 , 다진 소고기 , 토마토 , 레드와인 , 물 , 월계수 잎 , 타임 , 파르마 지안 레지 아노 치즈 , 마무리 에 뿌려 주 는 질 좋 은 올리브 오 일 요리 책 의 레시피 는 판세 타 , 올리브유 , 버터 , 양파 , 당근 , 샐러리 , 다진 소고기 , 다진 돼지고기 , 토마토 페이스트 , 화이트 와인 , 소금 , 후추 , 넛 맥 , 치킨 스톡 , 생크림 으로 이루어진 레시피 인데 집 에 있 는 재료 로 가감 해서 만들 었 다 . 그래서 내 가 사용 한 재료 는 넉넉 하 게 4 인분 정도 되 는 분량 으로 버터 2 스푼 , 올리브 오 일 , 샐러리 1 대 , 양파 1 개 , 당근 반개 , 마늘 5 개 , 다진 소고기 600 그램 , 와인 200 미리 , 홀 토마토 400 ~ 450 미리 , 물 500 미리 , 큐브 형 치킨 스톡 1 개 , 월계수 잎 2 장 , 아탈 리안 시즈 닝 1 스푼 이 다 . 여기 에 마지막 에 소금 , 후추 , 넛 맥 ( 생략 가능 ) 을 넣 고 조리 한 다음 2 인 분당 200 미리 컵 에 파르 마산 치즈 1 컵 과 생크림 1 컵 은 파스타 를 만들 때 소스 를 다시 끓이 면서 먹 기 직전 에 추가 한다 . 와인 은 레드와인 과 화이트 와인 모두 드라이 한 것 이 면 다 잘 어울린다 . 화이트 와인 을 넣 었 을 때 는 색 이 조금 더 밝 고 상대 적 으로 상큼 한 맛 이 나 는 데 비해 레드와인 은 색 이 짙 고 향도 조금 더 깊 으며 헤비 한 느낌 이 조금 있 다 . 내 취향 에 는 일반 적 으로 파스타 에 더 많이 쓰 는 화이트 와인 이 나 은데 둘 중 에 있 는 걸로 쓰 면 괜찮 고 나 는 딴지 조금 더 오래 되 어 먼저 써야 되 는 것 으로 쓰 고 있 다 . 생크림 을 넣 는 것 이 더 전통 적 인 레시피 에 가깝 고 미트 토마토소스 까지 만 만들 었 을 때 의 신맛 에 고소 한 맛 이 더해져 소스 의 맛 을 빈틈없이 거의 완전히 채워 주 기 때문 에 생크림 은 넣 는 것 이 훨씬 ! 좋 다 . 먼저 샐러리 , 양파 , 당근 , 마늘 은 곱 게 다지 고 버터 + 올리브 오일 에 볶 는 데 판 체타 대용 으로 베이컨 을 함께 볶 아도 좋 다 . 15 분 ~ 20 정도 약한 불 에 깊 은 맛 이 나 도록 볶 는다 . 야채 다지 는 데 만 30 분 이 걸렸 다 ( 대충 다지 면 15 분 . .). 그냥 푸드 프로세서 를 사용 하 는 걸 추천 . ... 그 다음 에 소고기 를 넣 고 10 ~ 15 분 정도 소고기 에 약간 갈색빛 이 돌 도록 볶 은 다음 팬 을 기울여서 기름 을 제거 한다 . 와인 을 넣 고 졸이 면서 알콜 의 향 이 다 날아갈 때 까지 익히 다가 홀 토마토 를 넣 고 조금 더 졸 도록 끓인다 . 그리고 닭 육수 나 소고기 육수 가 있 으면 더 좋 은 데 없 으니까 물 을 400 미리 넣 고 월계수 잎 과 이탈리안 시즈 닝 , 치킨 스톡 을 넣 었 다 . 소스 가 끓 으면 뚜껑 을 닫 고 약 불로 줄여 향 이 더 해 지 고 맛 이 응축 되 도록 1 시간 반 에서 2 시간 정도 소스 의 물기 가 거의 다 졸아들 도록 조리 하 는데 중간 에 열 어 봐서 물 이 모자라 면 타 지 않 을 정도 로 물 을 추가 해서 오래 도록 끓이 는 것 이 좋 다 . 물 을 더 넣 는 것 에 주저 하 지 말 고 물 을 더 넣 고 졸이 는 것 을 반복 하 는 것 이 조금 덜 끓이 는 것 보다 몇 배 는 더 좋 다 . 이 과정 을 시머 링 simmering 이 라고 하 는데 시머 링 은 최대 4 시간 까지 도 가능 하 다 . 나 는 지쳐서 2 시간 만 . .. 넛 맥 1 꼬 집 ( 은 생략 한 적 도 있 다 ) 에 소금 은 간 을 봐서 약간 싱겁 도록 넣 어 완성 했 다 . 부글부글 끓 는 느낌 이 아니 라 중약 불 에 천천히 오래 끓여야 고기 의 육수 가 천천히 배 어 나오 고 야채 와 토마토 , 치킨 육수 ( 소고기 육수면 더 좋 지만 ) , 시즈 닝 등 에서 나오 는 맛 이 서로 조화 를 잘 이루 어 각 재료 의 튀 는 맛 이 없 어 진다 . 소스 를 식힌 다음 바로 먹 어도 되 지만 밤 에 만들 어 둔 것 이 기 때문 에 식혀서 냉장 보관 했 다 . 약간 촉촉 한 토마토 고기 볶음 이 라는 생각 이 들 때 까지 조리 한 상태 이 다 . 냉장 한 소스 에 다진 소고기 에서 나온 기름 이 굳 어 있 으므로 스푼 으로 덜 어 내 고 반 을 덜 어 팬 에 넣 었 다 . 소스 가 살짝 끓 도록 데워 지 면 크림 을 넣 고 파르 마산 치즈 를 갈 아서 1 컵 정도 넣 어 끓 기 직전 에 불 을 끈다 . 소스 와 버무려서 내 도 되 지만 알 덴 테 정도 로 삶 은 파스타 에 얹 어서 먹 어도 좋 다 . 딸리 아 뗄 레 는 바닷물 정도 되 는 간기 가 있 는 소금물 에 6 ~ 7 분 삶 았 고 소스 를 얹 고 난 다음 치즈 를 더 뿌렸 다 . 마지막 사진 은 내 가 사진 찍 고 있 는 동안 우리 집 식구 가 자기 먹 을 그릇 에 치즈 갈 아 놓 은 것 . . ㅎㅎ 많이 도 갈 았 다 . 남 는 소스 를 빵 에 얹 어 먹 고 그릇 을 닦 아 가 며 먹 으니 아주 맛있 었 다 . 볼로 네즈 소스 는 기본 적 으로 딸리 아 뗄 레 면 이나 그 와 비슷 한 모양 의 면 이 편평 한 파파르델레 나 페투치네 와 가장 잘 맞 고 두꺼운 롱 파스타 가 아닌 숏 파스타 에 도 고기 가 들어가 함께 씹히 는 맛 으로 잘 어울린다 . 딸리 아 뗄 레 면 과 리가토니 등 에 해서 먹 었 고 펜 네 에 도 어울릴 것 같 아서 한 냄비 냉장고 에 저장 해 두 었 다 . 부드러운 딸리 아 뗄 레 면 을 푹푹 퍼 먹 으면 고기 가 듬뿍듬뿍 씹혀 애 들 입맛 에 도 맞 을 것 같 고 내 입맛 에 도 맞 는 괜찮 은 미트 소스 파스타 ragù alla bolognese 였 다 . 이 소스 를 베 사멜 소스 와 함께 라자냐 파스타 에 켜켜이 쌓 으면 라자냐 가 된다 . 딸리 아 뗄 레 다음 으로 해서 먹 은 라구 소스 리가토니 . 소스 와 함께 버무려서 있 는 모습 이 그리 이쁘 지 는 않 지만 원통 안 에 미트 소스 가 그득그득 들어가 서 씹히 는 맛 이 아주 좋 다 . 리가토니 는 끓 는 소금물 에 10 분 정도 삶 았 고 팬 에서 1 분 정도 소스 와 함께 더 볶 았 다 . 후딱 만드 는 파스타 에 비해서 드 는 시간 이 어마어마 하 지만 일단 미트 소스 만 한 냄비 만들 어 두 면 금방 먹 기 좋 고 만들 어 둔 소스 는 냉동 보관 도 가능 하 다 . 냉장실 에 는 열흘 까지 괜찮 았 다 . 그만한 시간 을 들일 만 한 가치 가 있 는 파스타 였 다 . 요약 하 면 양파 당근 샐러리 마늘 오래 볶 고 , 고기 볶 고 , 와인 졸이 고 , 토마토 , 육수 , 월계수 잎 , 허브 넣 고 뚜껑 닫 고 푹푹 끓여서 거의 고기 만 남 는 느낌 이 되 면 식혀서 냉 장보관 , 아무 때 나 꺼내 서 파스타 삶 고 소스 데우 고 생크림 , 치즈 넣 으면 끝 . 음식 을 할 때 에 는 참고 한 내용 을 봐 가 면서 하 는 것 보다 어느 정도 과정 을 여러 번 되풀이 해 떠올리 고 숙지 가 끝난 다음 에 해야 좋 다고 생각 한다 . 처음 해 보 는 음식 을 레시피 한 번 보 고 하나 씩 넣 고 만들 어 보 면 그 때 에 는 어찌어찌 잘 만들 게 되 어도 다음 에 만들 때 에 덥썩 내 가 만들 수 있 는 음식 이 라는 생각 이 덜 드 는 것 같 다 . ( 내 경우 . .) 내 가 만든 음식 을 내 가 또 다시 만드 려고 할 때 에 도 돌아서 면 잊어버리 는 요즘 의 상태 때문 에 이미 쓴 글 이나 메모 를 참고 하 고 있 다 . 이럴 때 만들 었 던 과정 을 다시 한 번 읽 고 , 조리 할 때 에 는 요약 한 대로 외워서 급할 때 에 는 외운 대로 하 고 요리 중간 에 시간 이 있 을 때 한 번 더 들여다본다 . 그러 면서 점차 내것이 되 었 을 때 에 응용 도 가능 하 고 비교 도 가능 하 게 된다는 것 이 최근 의 생각 이 긴 한데 또 언제 바뀔지 는 모르 겠 다 . ..',\n",
       "       '예전 에 올린 투 움 바 파스타 와 거의 비슷 한데 재료 를 조금 더 간소 하 게 만들 었 다 . 평소 에 는 새우 가 들어가 는 크림소스 파스타 를 만들 면 새우 머리 로 낸 육수 를 사용 하 는 경우 가 많 은데 투 움 바파 스타 에 는 냉동 새우 살 을 해동 해서 구워서 넣 고 , 따로 육수 가 될 재료 는 없이 향신료 와 케 찹 을 넣 어 만드 는 크림 파스타 인데 이렇게 따로 베이스 가 될 맛 을 낼 재료 가 없 는 크림 파스타 에 는 굴 소스 를 아주 약간 넣 어 감칠맛 을 더 하 면 잘 어울린다 . 크림소스 파스타 에 크림 만 들어가 는 것 보다 는 새우 비스크 - [ URL ] 새우 엔 초비 - [ URL ] 새우 쉐 차안 - [ URL ] 이렇게 육수 가 되 는 재료 가 꼭 있 는 것 이 좋 다 . 새우 가 들어가 는 경우 외 에 도 꽃게 나 바지락 , 홍합 등 을 넣 는 때 가 많 다 . 이렇게 할 때 는 생물 재료 가 들어가 서 늘 손 이 많이 가 는데 투 움 바 파스타 처럼 간단 한 파스타 에 넣 는 치킨 스톡 이나 굴 소스 약간 은 크림소스 의 맛 이 밋밋 하 지 않 도록 도와 준다 . 사용 한 재료 는 2 인분 으로 스파게티 니 200 그램 올리브 오 일 양송이버섯 10 개 새우 약 30 마리 소금 , 후추 올리브 오 일 샬롯 3 개 다진 마늘 0 . 5 스푼 이탈리안 시즈 닝 0 . 5 티스푼 케이 옌 페퍼 0 . 5 티스푼 파프리카 파우더 0 . 5 티스푼 어니언 파우더 0 . 5 티스푼 갈릭 파우더 0 . 5 티스푼 코리 앤더 파우더 0 . 3 티스푼 후추 0 . 3 티스푼 케 찹 1 . 5 스푼 굴 소스 1 티스푼 ( 치킨 파우더 있 으면 0 . 5 티 ) 생 크림 약 500 미리 우유 100 ~ 200 미리 ( 농도 나 취향 에 우유 양 가감 ) 파르 마산 치즈 약 2 줌 소금 약간 ( 간 보고 필요시 약간 ) 크림소스 파스타 는 링귀 니나 페투치네 를 많이 사용 하 는 데 스파게티 니 를 좋아해서 스파게티 니 를 사용 했 다 . 샬롯 은 냉동 한 것 을 사용 했 고 샬롯 대신 굵 은 쪽파 의 흰 부분 을 사용 해도 괜찮 다 . 케 이옌 페퍼 는 매운 맛 을 , 파프리카 파우더 는 붉 은 색 을 내 기 위해 사용 하 는 데 고추장 용 고운 고춧가루 1 티스푼 으로 대체 해서 사용 해도 괜찮 다 . 이탈리안 시즈 닝 대신 에 오 레 가노 를 사용 해도 좋 고 , 갈릭 파우더 는 넣 는 것 이 더 나았 다 . 크림소스 에 는 코리 앤더 파우더 약간 과 넛 맥 이나 메이스 를 아주 약간 넣 으면 늘 더 잘 어울린다 . 어쨌든 향신료 는 아래 와 같이 미리 혼합 해 두 었 다 . 새우 는 냉장 해동 해서 흐르 는 물 에 씻 어 물기 를 닦 고 올리브 오일 을 두른 팬 에 노릇노릇 하 게 구워 두 었 다 . 버섯 도 적당히 썰 어서 노릇노릇 하 게 구워 두 었 다 . 파스타 100 그램 당 물 1 리터 , 소금 0 . 5 티스푼 으로 잡 고 물 을 끓여서 팔팔 끓 으면 파스타 를 넣 고 봉투 에 적힌 시간 만큼 삶 았 다 . 스파게티 니 의 경우 는 5 ~ 6 분 이 라 파스타 가 물 에 잠기 면 타이머 를 켜 고 소스 를 만들 기 시작 하 면 시간 이 딱 맞 다 . ( 소스 를 만들 면서 오가 면서 파스타 가 서로 붙 지 않 게 저 어 준다 . ) 파스타 를 삶 는 동안 소스 를 만들 었 다 . 소스 를 만드 는 시간 은 6 ~ 7 분 정도 로 잡 고 파스타 가 익 는 시간 에 맞춰서 시작 하 면 적당 하 다 . 팬 에 올리브 오일 을 두르 고 샬롯 과 다진 마늘 을 노릇노릇 하 게 볶 았 다 . 여기 에 준비 한 케 찹 과 향신료 를 넣 어서 한 번 볶 은 다음 생크림 과 우유 를 붓 고 끓이 기 시작 했 다 . 크림 이 끓어오르 면 불 을 줄이 고 굴 소스 를 아주 약간 넣 었 다 . 생크림 을 졸여서 농도 를 조절 하 는데 나 는 소스 가 많 은 것 보다 는 딱 맞 는 정도 를 좋아해서 조금 바 특 하 게 끓였 다 . 취향 에 따라 우유 의 양 을 조절 해서 소스 의 농도 를 조금 더 묽 게 조절 할 수 있 다 . 투 움 바 소스 가 보통 크림소스 정도 의 농도 가 되 면 파르 마산 치즈 를 듬뿍 넣 고 시간 에 맞 게 삶 아 진 파스타 를 크림소스 에 넣 었 다 . 여기 에 미리 구워 둔 새우 와 양송이버섯 을 넣 고 전체 적 으로 한 번 볶 았 다 . 마지막 으로 간 을 보 고 모자란 간 은 소금 약간 이나 파르 마산 치즈 로 조절 하 면 완성 .',\n",
       "       '토마토소스 와 구운 가지 로 파스타 를 만들 면 다 맛있 고 여기 에 리코타 치즈 와 발 사빅 비네 그레트 의 조합 을 아주 좋 아 한다 . 이 비슷 한 조합 하 면 또 먼저 떠오르 는 이름 이 노르마 파스타 이 다 . 노르마 파스타 의 주재료 는 토마토 퓨레 , 가지 , 바질 , 리코타 살라타 인데 리코타 살라타 를 구할 수 가 없 어서 아쉽 다 . 오늘 은 토마토 퓨레 나 소스 없이 올리브 오일 에 샬롯 과 마늘 , 엔 초비 , 페페 론 치노 를 볶 다가 토마토 를 넣 고 파스타 와 구운 가지 , 그린 올리브 를 토스 해서 파스타 를 만들 었 다 . 여기 에 케이퍼 가 들어가 면 푸 타네스 카이다 . 집 에 있 는 재료 도 고려 해서 재료 를 정하 는데 파스타 에 올리브 오 일 / 방울토마토 / 엔 초비 / 샬롯 / 마늘 / 페페 론 치노 / 그린 올리브 + 구운 가지 / 리코타 치즈 / 발사믹 비네 거 / 올리브 오 일 이런 식 으로 생각 해서 조합 했 다 . 노르마 파스타 가 전통 적 인 시칠리아 음식 이 고 , 푸 타네스 카도 남부 이탈리아 ( 나폴리 / 시칠리아 ) 음식 이 라 재료 조합 이 여름 여름 한 느낌 이 다 . 사용 한 재료 는 스파게티 니 200 그램 소금 올리브 오 일 엔 초비 4 필렛 샬롯 1 개 ( 생략 가능 ) 마늘 3 개 ( 마늘 은 좋 아 하 니까 5 개 까지 ) 페페 론 치노 6 개 방울토마토 넉넉히 ( 20 ~ 30 개 ) ( 파스타 삶 는 물 약간 ) 그린 올리브 10 개 가지 3 개 ( 소금 뿌리 고 구운 것 ) 이탈리안 시즈 닝 약간 후추 약간 선택 재료 로 리코타 치즈 150 그램 ( 좋 아 하 는 만큼 ) 발사믹 비네 거 올리브 오일 신선 한 바질 이나 오레 가노 가 있 다면 마지막 에 마지막 에 추가 하 면 더 좋 다 . 면은 오 일 파스타 에 잘 어울리 고 평소 에 도 좋 아 하 는 데 체코 스파게티 니 를 사용 했 다 . 칼라마타 올리브 도 좋 아 하 는데 이번 에 는 코스트코 에서 사온 그린 올리브 를 사용 했 다 . 올리브 는 씨 있 는 것 으로 사 서 과육 만 잘라서 쓰 면 질감 이 단단 하 고 맛있 다 . 올리브 오일 은 데 체코 를 다 써서 처음 사 본 백설 안달루시아 산 엑스트라 버진 올리브 오일 을 사용 했 다 . 가지 는 양 끝 을 잘라 내 고 1 센치 정도 되 는 두께 로 썰 어서 아래 에 소금 을 뿌리 고 착착 놓 은 다음 위 에 도 소금 을 뿌려서 20 분 정도 절였 다 . 수분 과 쓴맛 을 빼 는 동시 에 소금 간 을 해서 간 이 맞 고 달 큰 한 맛 이 더 좋 아 진다 . 카스텔 베 트라 노 그린 올리브 는 과육 을 깎 아 내 고 반점 이 조금 있 어서 손질 했 다 . 조리 하 지 않 고 그냥 먹 어도 맛있 다 . 마늘 은 일정 한 두께 로 슬라이스 하 고 샬롯 도 슬라이스 하 고 페페 론 치노 는 반 으로 부수 고 엔 초비 는 4 필렛 을 준비 했 다 . 축축 해진 가지 는 키친 타올 로 눌러서 수분 을 닦 아 냈 다 . 가지 는 노릇 노릇 하 게 굽 는데 바닥 에 기름 을 깔 지 않 고 가지 위 에 기름 을 약간 씩 뿌려 가 며 구우면 덜 기름지 다 . 파스타 는 1 리터 정도 물 을 잡 고 소금 을 1 티스푼 넣 어서 삶 았 다 . 봉투 에 6 분 이 라고 적혀 있 어서 5 . 5 분 간 삶 았 다 . 팬 에 넣 고 나 서 오래 익 는 것 이 아니 라서 취향 에 맞 게 삶 으면 적당 하 다 . 팬 에 올리브 오일 을 두르 고 마늘 , 샬롯 , 엔 초비 , 페페 론 치노 를 가볍 게 볶 다가 여기 에 파스타 와 후추 를 넣 고 볶 다가 간 을 보 고 파스타 삶 은 물 을 반 국자 정도 넣 었 다 . 구운 가지 와 올리브 를 넣 고 한 번 더 볶 아서 완성 . 접시 에 담 아서 올리브 오일 을 약간 뿌렸 다 . 나 는 오일 파스타 에 치즈 를 자주 넣 는 편 은 아니 라서 이대로 도 좋 은데 우리 집 에 리코타 치즈 처 돌 이 . . 가 있 어서 리코타 치즈 를 올리 고 발사믹 비네 거 와 올리브 오일 을 조금 더 뿌렸 다 . 처 돌이 는 처 돌 이 답 게 ; 이게 더 좋 단다 . 나 는 반 쯤 먹 고 나 서 중간 에 리코타 치즈 와 발사믹 비네 그레트 를 넣 어서 둘 다 맛있 게 먹 었 다 . 음식 에 어떤 재료 가 들어갔 다면 그 재료 의 맛 이 나 는 것 이 당연 한데 이 파스타 는 정말 재료 그대로 의 정직 한 맛 이 다 . 짭조름 한 엔 초비 와 토마토 , 짭잘 고소 한 올리브 , 매콤 한 고추 , 마늘 의 향 이 올리브 오일 에 당연히 잘 어울리 고 구운 가지 와 리코타 치즈 , 발사믹 비네 거 를 추가 하 면 또 한 겹 이 더 해진 맛 을 낸다 . 상큼 하 고 맛있 게 잘 먹 었 다 .',\n",
       "       '모두 를 위한 머신 러닝 / 딥 러닝 강의 모두 를 위한 머신 러닝 과 딥 러닝 의 강의 알 파고 와 이세돌 의 경기 를 보 면서 이제 머신 러닝 이 인간 이 잘 한다고 여겨진 직관과 의사 결정 능력 에서 도 충분 한 데 이타 가 있 으면 어느 정도 또는 우리 보다 더 잘 할 수 도 있 다는 생각 을 많이 하 게 되 었 습니다 . andrew ng 교수 님 이 말씀 하 신 것 처럼 이런 시대 에 머신 러닝 을 잘 이해 하 고 잘 다룰 수 있 다면 그야말로 \" super power \" 를 가지 게 되 는 것 이 아닌가 생각 합니다 . 더 많 은 분 들 이 머신 러닝 과 딥 러닝 에 대해 더 이해 하 고 본인 들 의 문제 를 이 멋진 도구 를 이용 해서 풀 수 있 게 하 기 위해 비디오 강의 를 준비 하 였 습니다 . 더 나아가 이론 에 만 그치 지 않 고 최근 구글 이 공개 한 머신 러닝 을 위한 오픈 소스 인 tensorflow 를 이용 해서 이론 을 구현 해 볼 수 있 도록 하 였 습니다 . 수학 이나 컴퓨터 공학 적 인 지식 이 없이 도 쉽 게 볼 수 있 도록 만들 려고 노력 하 였 습니다 . 시즌 rl - deep reinforcement learning 시즌 nlp - deep nlp lec 0 : 수업 의 개요 비디오 슬라이드 슬라이드 bot lab 1 - 1 : api . ai 의 개념 비디오 bot lab 1 - 2 : api . ai 사용 해 보 기 비디오 시즌 1 - 딥 러닝 의 기본 ( tf 1 . x lab 완료 ! ) 비디오 리스트 [ 보너스 ] deep deep network aws 에서 gpu 와 돌려 보 기 ( powered by aws ) 실습 슬라이드 비디오 [ 보너스 2 ] aws 에서 저렴 하 게 spot instance 를 터 미 네이션 걱정 없이 사용 하 기 ( powered by aws ) 실습 슬라이드 비디오 acknowledgement 비디오 리스트 ( 천 천 이 업데이트 예정 입니다 . 시즌 1 먼저 들으신 다음 들으시면 좋 습니다 . ) ( tba ) 이 비디오 는 저 도 인터넷 등 을 통해 공부 하 면서 만든 것 이 며 아래 자료 를 많이 사용 하 였 습니다 . 의견 주기 비디오 나 강의 에 대한 의견 이 있 으시 면 아래 로 이메일 을 보내 주 시 면 됩니다 . 홍콩 과 기대 김성훈 hunkim + ml @ gmail . com',\n",
       "       '\" 이 포스트 는 이런 분 에게 추천 합니다 . \" - 파이썬 에서 한글 인코딩 문제 로 골머리 않 고 계시 는 분 - unicodedecodeerror : \\' ascii \\' codec can \\' t decode byte 0 xbe in position 0 : ordinal not in range ( 128 ) 오류 를 자주 출력 하 는 오류 에 짜증 이 치밀 어 오르 시 는 분 - 유니코드 , utf - 8 , cp 949 등 인코딩 에 대해서 헷갈리 시 는 분 들 - 한글 만 출력 할려면 이상 한 특수 문자 만 눈 에 보 시 는 분 들 요즘 파이썬 으로 개발 할 일 이 많 아 져서 계속 부딪치 는 게 한글 인코딩 이 다 . 이놈 의 한글 인코딩 은 심심 하 면 이런 메세지 를 보 게 된다 . 직역 하 면 유니코드 디코드 에러 가 어쩌구저쩌구 , 아스키 코텍 이 어쩌고저쩌구 . 결론 부터 말 하 자면 0 xbe 값 이 아스키 범위 ( 0 ~ 128 ) 를 넘어섰 다는 얘기 다 . 1 ) 인코딩 이 란 ? encode 의 사전 적 뜻 은 1 . 암호 로 바꾸 다 2 . 부호 화 하 다 3 . ( 외국어 로 ) 표현 하 다 , 라는 뜻 이 다 . 1 번 뜻 은 오히려 암호학 에 더 가까운 뜻 이 다 . 사실 암호학 이 다 . 컴퓨터 가 알 기 쉽 게 만들 어 주 는 언어 이 기 때문 이 다 . 예 를 들 어 문자 인코딩 은 우리 가 쓰 는 \\' a \\' 라는 언어 를 컴퓨터 가 인식 하 기 쉬운 언어 \\' 65 \\' 로 바꿔 주 는 것 을 의미 한다 . 2 ) 문자 코드 문자 코드 는 쉽 게 생각 하 면 아스키코드 가 대표 적 인 예 이 다 . 우리 가 잘 외우 고 있 는 \\' a \\' 는 아스키 10 진수 로 65 이 다 . 대학교 c 시간 의 첫 번 째 필기 문제 로 나올 뻡한 문제 이 다 . 이놈 의 문자 코드 가 여러 개 인게 문제 다 . 대표 적 인 문자 코드 를 한번 살펴보 자 . ( 1 ) ascii 코드 - american standard code for information interchange , 미국 정보 교환 표준 부호 - 7 bit 글자 인코딩 으로 0 부터 127 까지 총 128 개 의 문자 표현 이 가능 대학교 때 많이 배운다 숫자 , 영어 는 1 byte , 한글 은 2 byte , 주입식 교육 으로 후배 들 한테 심심 하 면 물 어 봤 던 것 이 생각난다 . 미국 정보 교환 표준 부호 라는 거창 한 설명 보다 는 , 아스키코드 로 숫자 , 영문자 , 특수 문자 를 표현 할 수 있 다고 보 면 되 겠 다 . ( 필자 는 심심 하 면 아스키코드 표 에 있 는 걸로 계산 하 기 일수 이 다 . ) python 에서 생각 보다 아스키코드 를 가지 고 놀 수 있 는 경우 를 많이 볼 수 있 다 . 아스키코드 는 아래 와 같이 변경 할 수 있 다 1 2 3 4 5 6 7 # 문자 아스키코드 로 바꾸 기 print ord ( \\' a \\' ) # 아스키코드 문자 로 바꾸 기 print char ( 90 ) cs ( 2 ) 유니 코드 ( unicode ) - 전 세계 의 모든 문자 를 컴퓨터 에서 일관 되게 표현 하 고 다룰 수 있 도록 설계 된 산업 표준 ( 출처 : 위키백과 ) - 한 글자 당 16 bit ( 2 byte ) 사용 - 65536 글자 내 에 모든 언어 가 표현 이 가능 함 . 범용 적 인 코드 가 유니코드 이 다 . 파이썬 에서 변수 에 한글 을 넣 어 줄 때 반드시 아래 와 같 은 코드 로 설정 해 줘야 한다 . 아니면 인코딩 변환 과정 에서 unicodedecodeerror : \\' ascii \\' codec can \\' t decode 라는 성가신 에러 를 보 게 될 것 이 다 . 1 2 3 4 5 6 7 # 변수 에 유니코드 입력 하 기 abc = u \" 안녕 하 세요 \" print abc # 유니코드 에러 나 는 경우 abc = \" 안녕 하 세요 \" unicode ( abc ) colored by color scripter cs ( 3 ) utf - 8 - 유니코드 를 위한 가변 길 이 문자 인코딩 방식 중 하나 로 , 켄 톰프슨 과 롭 파이크 가 만들 었 다 . utf - 8 은 universal coded character set + transformation format – 8 - bit 의 약자 이 다 . ( 출처 : 위키백과 ) - 한 글자 당 1 ~ 4 byte 를 사용 한다 . - asp . net 은 물론 오늘날 웹 사이트 에서 범용 적 으로 사용 하 고 있 다 . - 웹 사이트 에 한글 언어 팩 이 없 더라도 한글 을 표현 할 수 있 다 . - 조합 형 방식 이 다 . 한글 의 초성 , 중성 , 종성 등 한글 의 조합 방식 을 그대로 이용 하 고 있 다 . 그래서 초성 , 중성 , 종성 3 byte 이 다 . - utf - 8 로 인코딩 을 하 기 위해서 는 반드시 변수 type 이 unicode 여야 한다 위 의 코드 는 한글 ( 유니코드 ) 를 utf - 8 로 인코딩 한 모습 니다 . 1 번 째 줄 : \" 안녕 하 세요 \" 를 유니코드 로 문자열 저장 2 번 째 줄 : \" 안녕 하 세요 \" 를 utf - 8 로 인코딩 3 , 4 번 째 줄 : \" 안녕 하 세요 \" utf - 8 로 인코딩 했 을 경우 문자 >> \\'\\\\ xec \\\\ x 95 \\\\ x 88 \\\\ xeb \\\\ x 85 \\\\ x 95 \\\\ xed \\\\ x 95 \\\\ x 98 \\\\ xec \\\\ x 84 \\\\ xb 8 \\\\ xec \\\\ x 9 a \\\\ x 94 \\' 5 , 6 번 째 줄 : utf - 8 이 한글 을 3 byte 로 표현 할 수 있 다고 해서 \"\\\\ xec \\\\ x 95 \\\\ x 88 \" 출력 했 더니 \" 안 \" 이 라는 문자열 을 표시 한 모습 7 , 8 번 째 줄 : 아까 앞 에서 utf - 8 방식 이 조합 형 문자 라고 말 해서 호기심 으로 앞 에 \"\\\\ xec \" 를 출력 하 면 \\' ㅇ \\' 이 출력 될 것 이 라고 생각 한 멍청 한 1 인 . 9 , 10 번 째 줄 : 다시 utf - 8 로 디 코딩 했 더니 유니코드 가 어떻게 저장 되 어 있 는지 확인 가능 ( 4 ) cp 949 , euc - kr - cp 949 는 인코딩 은 euc - kr 의 확장 및 하위 호환 이 다 . - utf - 8 이 조합 형 방식 이 라면 , cp 949 는 완성 형 방식 이 다 . ( ex , 가 , 갸 , 거 , 겨 형태 로 표현 ) - cp 949 로 인코딩 을 하 기 위해서 는 반드시 변수 type 이 unicode 여야 한다 위 의 코드 는 한글 ( 유니코드 ) 를 cp 949 로 인코딩 한 모습 니다 . 3 ) 다양 한 트러블 슈팅 으로 파이썬 한글 사용 마스터 하 기 필자 가 겪 은 다양 한 한글 인코딩 에러 사례 를 통해 한글 인코딩 을 해결 하 자 . 1 ) 무조건 코드 를 짤 때 변수 에 한글 을 집어넣 을 때 는 u \" 한글 \" 을 이용 하 자 . 1 2 3 # 변수 에 한글 값 넣 어 주 기 abc = u \" 안녕 하 세요 \" cs 변수 뿐 만 아니 라 아래 예제 와 같이 파일 다이얼로그 이용 할 떄 , 파일 형식 값 편집 할 때 , 메세지 박스 편집 할 때 다양 하 게 유니코드 를 설정 해 줘야지 한글 깨 짐 현상 을 예방 할 수 있 다 . 아래 는 위 에서 설명 한 한글 을 사용 해야 될 경우 의 예시 코드 를 일부 가져다 놓 았 다 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 파일 다이얼로그 이용 할 때 파일 형식 사용 def findexcelfile ( self ) : edlg = qfiledialog ( ) edlg . setfilemode ( qfiledialog . anyfile ) edlg . setfilter ( u \" 엑셀 파일 ( *. xls *. xlsx * xlsm * xlsb ) \" ) if edlg . exec _(): self . excelfilename = edlg . selectedfiles ( ) self . edit _ findexcelfile . settext ( self . excelfilename [ 0 ] ) # qmessagebox 알림 메세지 세팅 if checklen = = 0 : qmessagebox . about ( self , u \" 오류 \" , u \" 중복 된 파일 추가 입니다 . \" ) else : qmessagebox . about ( self , u \" 알림 \" , u \" 파일 % d 개 가 추가 되 었 습니다 . \" % ( checklen ) ) cs 2 ) 윈도우 또는 리눅스 쉘 커맨드 창 에서 실행 시켰 을 때 syntaxerror : non - ascii character \\'\\\\ xeb \\' in file test . py on line 5 , but no encoding declared ; 와 같 은 에러 가 보일 때 이럴 때 사용 하 는 것 이 코드 앞 에 붙여 주 는 coding : cp 949 , coding : utf - 8 를 붙여 주 게 되 면 커맨드 창 에서 한글 이 정상 적 으로 보여진다 . 1 2 3 4 5 # -*- coding : cp 949 -*- from bs 4 import beautifulsoup # -*- coding : utf - 8 -*- from bs 4 import beautifulsoup cs 3 ) 현재 내 가 받 아 온 string 값 이 유니코드 인지 utf - 8 인지 cp 949 인지 모를 때 코딩 은 머리 가 이해 하 고 있 더라고 결과 값 이 안 나오 면 짜증 나 기 마련 이 다 . 이럴 때 는 무조건 디버깅 또는 print 로 출력 출력 밖 에 없 다 . 에러 를 이해 하 기 쉬운 가장 좋 은 예제 는 다음 과 같 다 . 1 번 째 줄 : \" 안녕 하 세요 \" 를 유니코드 로 저장 2 , 3 번 째 줄 : s 변수 의 type 을 확인 해 봤 더니 \" 유니코드 \" 이 다 . 4 ~ 9 번 째 줄 : s 변수 를 각각 utf - 8 , cp 949 로 인코딩 하 였 더니 type 은 \\' str ( 아스키 코드 ) \\' 이 다 . 10 번 째 줄 : utf - 8 로 디 코딩 했 더니 다시 type 이 \\' unicode \\' 로 변경 되 었 다 . 이렇게 type 함수 를 통해 현재 내 가 변수 에 저장 한 문자열 이 str ( 아스키코드 ) 인지 unicode 인지 확인 이 가능 하 다 . 자 만약 에 특정 변수 를 아래 와 같이 unicode 함수 에 인자 로 넣 고 호출 하 였 는데 아래 와 같 은 에러 가 발생 했 을 경우 >>> unicode ( s 3 ) >>> unicodedecodeerror : \\' ascii \\' codec can \\' t decode byte 0 xbe in position 0 : ordinal not in range ( 128 ) 1 . 만약 위 와 같 은 에러 가 발생 했 을 때 는 우선 s 3 변수 를 utf - 8 또는 cp 949 로 먼저 decoding 을 해 보 자 . 2 . 그 다음 에 print type ( s 3 ) 로 했 을 경우 unicode 로 출력 되 는지 확인 하 자 . 대부분 이 방법 을 이용 하 면 unicodedecodeerror 는 어디 서 문제 가 발생 했 는지 인지 하 고 해결 이 가능 할 것 이 다 . 4 ) 실전 코드 활용 하 기 . 이전 \" 파이썬 을 통 애 나라장터 파싱 프로그램 \" 포스트 에서 아래 와 같이 유니코드 와 , cp 949 를 인코딩 / 디 코딩 하 는 코드 가 있 었 다 . 필자 는 이 유니코드 디코드 에러 때문 에 상당 한 스트레스 를 받 았 던 걸로 기억 한다 . 이 중 에서 중요 한 몇 줄 만 살펴보 자 . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # -*- coding : cp 949 -*- from bs 4 import beautifulsoup soup = beautifulsoup ( body , \\' html . parser \\' ) parse _ a = soup . find _ all ( \\' a \\' ) parse _ tr = soup . find _ all ( \\' tr \\' ) # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ######################### # 1 : 공고 명 parsing for test in parse _ tr : itemstring = test . encode ( \\' cp 949 \\' ) start = itemstring . find ( \" 0 : nlast = itemstring . find ( \" \" , start ) tmpstring = itemstring [ start : nlast ] nfirst = tmpstring . rfind ( \"\\\\\">\" ) + 2 item = tmpstring [ nfirst : ] try : string = item . decode ( \\' cp 949 \\' ) worksheet . write ( name _ count , 2 , unicode ( string ) ) except unicodedecodeerror : erorcheck = 1 worksheet . write ( name _ count , 2 , u \" 오류 \" , xlwt . easyxf ( \" font : bold on ; pattern : pattern solid , fore _ color pink ;\" ) ) name _ count = name _ count + 1 colored by color scripter cs 1 , 2 번 째 줄 : 웹 페이지 파싱 을 통해 데이터 를 읽 어 와서 변수 에 집어넣 었 더니 한글 깨 짐 현상 이 발생 하 였 다 . 따라서 cp 949 로 문자열 을 인코딩 하 였 다 . 20 , 21 번 째 줄 : 엑 셀 에 한글 데이터 를 집어넣 을려면 unicode 방식 을 이용 해야 된다 . 따라서 cp 949 로 다시 디 코딩 해 주 는 모습 이 다 . 5 ) 참고 사이트 ( reference ) - 인코딩 방식 이해 하 기 ( [ URL ] - 문자 인코딩 의 개념 ( [ URL ] 이 글 을 통해 python 한글 인코딩 에러 해결 에 도움 이 됬 으면 하 는 바람 이 다 .',\n",
       "       'previous next 전체 재생 ◀ 앵커 ▶ 코로나 19 가 일상 을 통제 한 이후 수도 권 시민 의 지하철 이용 실태 를 빅 데이터 로 분석 해 봤 습니다 . 이용자 수 가 최대 30 % 까지 줄 었 는데 눈 에 띄 는 게 승객 이 가장 많이 감소 한 역 이 고속터미널역 이 었 습니다 . 지방 가 는 사람 이 그만큼 줄 었 고 이동 하 더라도 고속버스 보다 자가용 이나 기차 를 탔 다는 얘깁니다 . 특히 출근 시간 대별 이용자 수 를 비교 해 봤 더니 가장 이른 시간 에 타 는 분 들 의 감소 폭 이 가장 작 았 습니다 . 출근 하 고 말 고 를 내 마음 대로 결정 할 수 없 는 일 을 하 고 있 는 겁니다 . 먼저 정진욱 기자 입니다 . ◀ 리포트 ▶ 새벽 5 시 40 분 , 서울 여의도역 . 첫차 가 도착 할 시간 입니다 . 이렇게 가 게 문 이 굳 게 닫힌 이른 시각 에 도 시민 들 이 출근길 을 서두르 고 있 습니다 . 증권사 등 일반 회사 들 이 정상 근무 에 들어가 기 전 일 을 끝마쳐야 하 는 사람 들 입니다 . [ 새벽 근무 노동자 ] \" 여의도 에서 청소 하 는 일 을 해요 . 없 을 시간 에 해야 하 니까 … \" [ 새벽 근무 노동자 ] \" 요식업 쪽 에 있 으니까 ( 가게 ) 오픈 을 하 면 이 시간 에 오 고 … 일 을 한다 라는 것 만 해도 다행 이 죠 . 몸 으로 뛰 는 일 들 은 그런 ( 출근 ) 조정 은 남일 이 라고 생각 했 지 … \" 2 시간 쯤 지난 7 시 반 부터 는 정장 차림 의 직장인 들 이 출근 합니다 . 7 시 반 부터 10 시 까지 . 코로나 감염 을 우려 해 혼잡 시간 을 피해 출근 하 는 겁니다 . [ 위 성현 ] \" 출퇴근 시간 에 좀 자유 를 줬었 고 , 10 시 출근 정도 가 제일 괜찮 았 던 것 같 아요 . \" [ 김리진 ] \" 교차 근무 제 그런 것 도 많이 하 고 , 재택근무 위주 로 많이 했었 어요 . \" 실제로 지하철 이용 빅 데이터 에서 도 업무 에 따라 출근 시간 이 달라지 는 게 확인 됐 습니다 . 일용직 노동자 들 이 많이 출근 하 는 첫차 시각 , 즉 새벽 5 시대 의 탑승객 은 감소 폭 이 가장 적 었 습니다 . 반면 큰 회사 가 몰려 있 는 여의도 , 종 로 , 강남 권 14 개 역사 에서 는 , 22 % 가량 의 러시아워 출근 비율 이 최대 4 % p 감소 했 고 이 시간 을 피해 출근 하 는 비율 은 증가 했 습니다 . [ 정도희 / sk 텔레콤 그룹 장 ] \" 8 시 반 부터 9 시 사이 에 출근 시간 이 굉장히 집중 돼 있 었 습니다 . 코로나 이후 에 는 회사 에서 도 출퇴근 시간 을 여유 롭 게 ( 조정 ) 하 면서 분산 된 것 같 습니다 . \" 시간대 별 로 는 점심 시간 대 이용 이 급감 한 것 으로 나타나 음식점 의 매출 감소 와 연관 된 것 으로 분석 됐 습니다 . mbc 뉴스 정진욱 입니다 . ( 영상 취재 : 김 동세 , 독 고명 / 영상 편집 : 정지영 ) 이 기사 어땠 나요 ? 좋 아요 훌륭 해요 슬퍼요 화나 요 후속 요청 이 시각 주요 뉴스 많이 본 뉴스 mbc 포털 sns 유튜브 분야 별 추천 뉴스',\n",
       "       '1 월 15 일 공덕역 서울 벤처 허브 에서 진행 된 < 한 페이지 머신 러닝 > 강연 ( 강사 홍원의 ) 을 들 었 다 . ( 한 페이지 가 아닌 것 같 은 게 함정 . ..) 보통 머신 러닝 을 기술 적 으로 만 이해 를 해서 \" 데이터 튜닝 \" \" 알고리즘 갖 다 쓰 기 \" \" 성능 높이 기 \" 에 치중 을 하 게 되 는데 , 조금 더 이론 적 으로 직관 적 인 이해 를 하 게 된 계기 가 되 었 다 . 본 강의 의 특징 은 한 페이지 단위 로 설명 을 해서 전체 적 인 개념 을 알 수 있 었 다 . 컴퓨터 는 의사 결정 도구 이 다 . 확정 적 상황 ( under certainty ) 과 확률 적 상황 ( under uncertainty ) 에서 컴퓨터 의 동작 에 대한 설명 . 확정 적 상황 에서 는 전제 - 결론 - 전제 - 결론 이 반복 되 는 logic 에서 , if - then 프로그래밍 을 통해 결론 을 낸다 . 확률 적 인 상황 에서 는 어떤 사건 에 대한 기대치 인 확률 을 통해 , 반복 적 인 상황 에서 의 통계 에 기반 하 여 학습 과 평가 가 이뤄 진다 . 위 4 개 의 네모 는 모델 , 아래 4 개 의 네모 는 동작 . 가운데 4 개 의 네모 는 이론 적 , 바깥 4 개 의 네모 는 어플리케이션 단계 이 다 . 머신 러닝 의 개념 어떤 상황 으로부터 , 트레이닝 데이터 로 모델 을 최적 화 시키 고 , 테스트 셋 으로 검증 하 는 것 . 데이터 사이언 티스 트 는 \" 데이터 를 통해서 의사 결정 을 돕 는 것 \" 가계부 를 보 고 돈 을 쓸지 안 쓸지 의사 결정 을 제안 하 는 것 과 같 다 . 질문 이 많이 나왔 던 트레이닝 셋 과 테스트 셋 . 트레이닝 셋 과 검증 데이터 셋 은 같 은 타임 라인 에서 움직이 는 거 고 그 이후 에 테스트 셋 을 통해서 정립 된 모델 을 최종 적 으로 테스트 하 는 것 . 최적 화 는 금 을 최대 화 하 고 똥 을 최소 화 하 는 것 이 목적 . 알고리즘 성능 평가 에 대한 직관 적 인 설명 . 그물 안 의 물고기 와 쓰레기 , 그물 밖 의 쓰레기 와 물고기 로 쉽 게 설명 할 수 있 었 다 . 보통 공부 를 할 때 , 내 가 공부 하 는 것 을 넘 어서 이해 한 것 을 어떻게 쉽 게 다른 사람 에게 설명 해야 할지 고민 하 게 되 는데 , 나 에게 이 수업 은 그런 고민 을 공유 할 수 있 어서 좋 았 다 . 기존 수업 은 교과서 적 인 설명 이 었 다면 , 이 수업 은 비유 를 통해서 이해 하 기 쉬웠 고 , google docs 를 활용 해서 강사 와 실시간 ( ? ) 질의 응답 도 가능 한 점 이 좋 았 다 . 해외 유학 중 인 강사 가 중간 중간 설명 해 주 는 대학원 이야기 도 공감 되 는 점 이 많 았 다 . 학생 들 이나 취 준 생 이 자신 의 스펙 을 어필 하 며 \" 회사 나 학교 에서 무언가 를 받 고 싶 다 \" 는 것 을 피력 하 지만 , 중요 한 것 은 회사 나 학교 에서 무엇 을 받 고 싶 어 할지 를 고민 하 라는 것 . 무엇 을 해 줄 수 있 냐는 것 을 생각 해 보 는 좋 은 기회 였 다 .',\n",
       "       '고전 관념론 편집 일원 론 적 관념론 은 물질 이 아닌 의식 은 모든 것 의 토대 라고 주장 한다 . 이러 한 입장 은 우주 에 는 오로지 한 가지 의 실체 만 이 있 다고 주장 하 기 때문 에 일원 론 적 이 며 , 그 하나 의 실체 는 의식 적 이 라고 주장 하 기 때문 에 관념 론 적 이 다 . 아낙사고라스 는 모든 것 은 누스 에 의해 생성 된다고 생각 했으며 , 누스 는 코스모스 와 일치 하 여 , 인간 을 코스모스 와 연결 시키 고 신 으로 가 는 길 을 제공 한다고 생각 하 였 다 . 다수 의 종교 적 철학자 는 관념론자 이 다 . 지식 을 가진 존재 는 무감각 한 물질 을 앞선다는 믿음 은 경험 하 는 주체 가 필연 적 으로 실체 라고 주장 하 는 듯 하 다 . 힌두 관념론 은 베단타 철학 과 카쉬 미르 시바파 의 핵심 적 교의 이 다 . 기독교 신학자 들 은 12 세기 부터 아리스토텔레스주의 적 스콜라주의 의 영향 에 도 불구 하 고 신플라톤주의 에 기반 을 둔 관념론 적 견해 를 주장 하 였 다 . hermann lotze 와 같 은 이후 의 유신 론 적 관념론자 는 그 안 에서 모든 것 은 통일성 을 획득 한다는 세계 의 토대 ( world ground ) 에 관한 이론 을 제안 하 였 다 . 이 이론 은 신교 신학자 들 에게 널리 받아들여졌 다 . 신사상 운동 과 같 은 현대 의 몇몇 종교 운동 은 특별히 관념 론 적 지향 을 가지 고 있 다고 평가 된다 . 크리스천 사이언스 신학 은 관념 론 적 형태 를 포함 한다 . 진정 하 게 존재 하 는 모든 것 은 신 이자 신 의 생각 이 며 , 감각 에 나타나 는 세계 는 그 본저 에 있 는 정신 적 실체 의 왜곡 이 며 , 왜곡 은 생각 의 재 설정 을 통하 여 교정 될 수 있 다고 가르친다 . 명나라 의 유학자 인 왕양명 은 정신 은 객체 를 형상 화 하 기 때문 에 객체 는 정신 으로부터 완전히 떨어져 존재 하 지 않 는다고 주장 하 였 다 . 세계 가 정신 을 형상 화 하 는 것 이 아니 라 , 정신 이 세계 에게 원인 을 제공 하 므로 정신 은 내 적 인 빛 과 선천 적 인 선 , 어떤 것 이 선한 지 에 대한 이해 를 가져 모든 원인 의 원천 이 라고 주장 하 였 다 . 유가행파 사상가 들 은 의식 을 궁극 적 으로 실존 한다고 주장 하 기 위해 의심 에 초점 을 맞춘 것 이 아니 라 , 대승불교 의 유가행파 의 의식 만 을 염두 에 두 는 접근 은 진정한 형 이 상학 적 관념론 은 아니 다 . 유가행파 에게 의식 은 원인 과 상태 를 요동치 게 하 여 순간 마다 나타나 기 때문 에 단지 관례 적 으로 실존 할 뿐 이 며 , 의식 은 업과 고 의 원인 이 기 때문 에 중요 한 개념 이 다 . 플라톤 의 형상 이론 은 관념 적 인 형상 을 어떠 한 상황 으로부터 도 독립 적 으로 존재 하 는 보편 자 로 묘사 한다 . arne grøn 는 이러 한 교의 를 초월 적 관념 론 으로서 의 형 이 상학 적 관념 론 의 고전 적 예 라고 부르 는 반면 , simone klein 은 플라톤 을 형 이 상학 적 객관 적 관념 론 의 가장 이른 대표 자 라고 부른다 . 플라톤 은 물질 은 실존 하 지만 순간 적 이 며 불 완전 하 다고 주장 하 였 고 , 물질 은 우리 의 신체 와 감각 에 의해 인식 되 며 , 우리 의 이성 적 영 론 에 의해서 직접 적 으로 인식 되 는 외부 의 이데아 로부터 그 존재 를 부여받 는다고 주장 하 였 다 . 그러므로 플라톤 은 근대 의 관념론자 가 회피 하 려고 노력 하 는 형 이 상학 적 , 인식 론 적 이원론자 이 다 . [ 7 ] 주관 적 관념론 편집 주관 적 관념론 ( 유심론 또는 현상론 ) 은 경험 과 세계 의 관계 에 대해서 논한다 . 주 관념 관념론 에서 객체 는 인식 자 내부 의 감각 데이터 의 모음 그 이상 이 아니 다 . 클로 인 의 주교 이 자 아일랜드 의 철학자 였 던 조지 버클리 는 주관 적 관념 론 의 주창자 중 한 명 으로서 개인 은 대상 에 대한 감각 이나 개념 만 을 직접 적 으로 알 수 있 으며 , 물질 과 같 은 비 실재 적 인 것 은 알 수 없 다고 주장 하 면서 자신 스스로 는 유심론 이 라고 부른 이론 을 발전 시켰 다 . 버클리 는 \" 존재 하 는 것 은 인식 되 는 것 이 다 ( esse est percipi ) \" 라며 , 개념 은 그 존재 를 위하 여 인식 되 는 것 에 의존 한다고 주장 하 였 다 . 영국 의 철학자 인 아서 콜리어 ( arthur collier ) 는 버클리 와 의 사이 에서 영향 을 주고받 은 적 이 없 는 것 으로 보임 에 도 비슷 한 주장 을 발표 하 였 다 . 우리 가 알 수 있 는 유일 한 실제 는 영원 한 대상 에 대하 여 상상 된 이미지 이 다 . 그러 한 이미지 의 원인 으로서 의 물질 은 생각 될 수 없 으며 , 그러므로 그것 은 우리 에게 아무것 도 아니 다 . 관찰자 와 관련 되 지 않 은 절대 적 물질 로서 의 외부 세계 는 존재 하 지 않 는다 . 인식 하 는 정신 이 존재 하 지 않 는다면 세계 는 그것 이 나 타 는 것 처럼 존재 할 수 없 다 . 콜리 너 는 케임브리지 플라톤주의 자 인 존 노리스 ( john norris ) 의 ⟪ 이상 적 또는 정신 으로 만 인식 되 는 세계 에 대한 이론 에 관한 논문 ⟫( an essay towards the theory of the ideal or intelligible world ) 의 영향 을 받 았 다 . 초월 적 관념론 편집 이마누엘 칸트 에 의해 18 세기 에 주창 된 초월 적 관념론 은 정신 은 우리 가 인식 한 세계 를 시공간 의 형태 로 형상 화 한다고 주장 한다 . — 순수 이성 비판 . .. 물질 적 인 세계 전체 는 주체 로서 의 우리 자신 의 감각 안 에서 의 현상 적 인 모습 이 자 상상 의 일종 일 뿐 이 기 때문 에 내 가 생각 하 는 주체 를 제거 한다면 세계 는 한 번 에 사라져야 한다 . 객관 적 관념론 편집 관념론 은 정신 을 세계 의 기초 에 두 는 견해 를 취하 는 철학 이나 객관 적 관념론 은 이 정신 을 인간 의식 , 즉 주관 으로서 의 정신 을 초월 한 , 객관적으로 존재 하 는 정신 ( 신 이라든가 절대정신 ) 이 라 하 여 , 이 에 바탕 을 두 고 세계관 을 수립 하 는 철학 이 다 . 또한 개인 적 인 주관 ( 의식 ) 이 아니 라 인간 일반 ( 一般 ) 의 의식 을 생각 하 여 이것 이 세계 를 만든 다는 생각 도 객관 적 관념론 이 라 하 는 수 도 있 으나 이러 한 입장 은 오히려 주관 적 관념론 이 라고 하 는 것 이 적절 하 다 . 객관 적 관념 론 의 주창자 로 는 토머스 힐 그린 , 조사 이 어 로이스 , 베네데토 크로체 , 찰스 샌더스 퍼스 등 이 있 다 . 셸링 은 객체 없이 주체 가 존재 할 수 없 기 때문 에 피히테 의 나 ( i ) 는 내 가 아닌 것 ( not - i ) 를 필요 로 한다고 주장 하 였 다 . 그러므로 주관 적 인 것 과 객관 적 인 것 , 즉 관념 적 인 것 과 실제 적 인 것 사이 에 차이 는 없 다 . 이것 이 셸링 의 절대 적 동일 성 이 다 . 관념 이나 정신 적 인 이미지 는 정신 외부 의 확장 된 객체 와 동일 하 다 . 절대 적 관념론 은 어떻게 존재 가 포괄 적 인 전체 로서 이해 될 수 있 는지 에 대한 g . w . f . 헤겔 의 입장 이 다 . 헤겔 은 자신 의 철학 을 버클리 의 \" 주관 적 관념론 \" 과 칸트 와 피히테 의 \" 초월 적 관념론 \" 과 구별 하 여 \" 절대 적 \" 관념론 이 라고 불렀 다 . [ 8 ] 헤겔 이 보 기 에 주관 적 관념론 이나 초월 적 관념론 은 헤겔 의 관념론 과 달리 역사 에 대한 궁극 적 이 고 변증법 적 인 철학 의 비판 에 기반 하 지 않 았 다 . 이성 과 지성 의 활용 은 철학자 가 궁극 적 인 역사 적 실제 와 , 자기 결정 의 현상학 적 인 성질 , 자기 인식 의 변증법 적 발전 , 역사 의 영역 에서 의 성질 을 알 게 해 준다 . 헤겔 은 자신 의 저서 ⟪ 대 논리학 ⟫ 에서 유한 한 성질 은 자신 을 결정 하 기 위하 여 다른 유한 한 성질 에 의존 하 기 때문 에 완전히 \" 실제 적 \" 이 지 않 다고 주장 한다 . 반면 에 질 적 인 무한 은 더욱 자기 결정 적 이 며 그러므로 완전히 실제 적 이 다 . 비슷 하 게 유한 한 자연 적 인 것 은 덜 자기 결정 적 이 기 때문 에 도덕 적 으로 책임 있 는 인간 , 윤리 적 인 공동체 , 신 과 같 은 정신 적 인 것 과 보다 덜 실질 적 이 다 . 그러므로 유한 한 성질 이나 자연 적 인 대상 이 완전히 실제 적 이 라는 유물론 과 같 은 학설 은 잘못 되 었 다 . [ 9 ] 같이 보 기 편집 각주 편집 참고 자료 편집 이 문서 에 는 다음 커뮤니케이션 ( 현 카카오 ) 에서 gfdl 또는 cc - sa 라이선스 로 배포 한 글로벌 세계 대백 과 사전 의 내용 을 기초 로 작성 된 글 이 포함 되 어 있 습니다 .',\n",
       "       '샹 포 의 기욤 ( guillaume de champeaux , 1070 년 경 ~ 1121 년 ) 은 프랑스 의 철학자 이 자 신학자 이 다 . 보편 논쟁 ( 普遍 論 爭 ) 에서 실재론 을 주장 하 였 다 . 피에르 아벨라르 는 그 의 제자 이 다 .',\n",
       "       '로스켈리누스 ( roscellinus , 1050 경 - 1124 경 ) 는 프랑스 의 스콜라 철학자 이 다 . 보편 논쟁 에 있 어서 의 유명론 최초 의 대표자 이 다 . 콩피에뉴 에서 태어나 소피스트 인 요하네스 밑 에서 변증 ( 논리 ) 을 배웠 다 . 교회 참사 회원 ( 敎會 參事 會員 ) 으로 논리 를 교수 하 고 신학 문제 에 변증 적 ( 辨證 的 ) 방법 을 적용 하 였 다 . 삼신론 ( 三神論 ) 을 가르쳤 다는 이유 로 수아송 종교 회의 에서 오류 취소 를 요구 받 고 이 를 철회 하 기 도 했 다 . 다시 교수 를 시작 하 여 투르 , 로슈 ( 여기 에서 아벨라르 두스 를 제자 로 삼 았 다 ) , 브장송 등 에서 활약 하 였 다 . 태어난 해 와 죽 은 해 는 명확 하 지 않 다 . 스코투스 에리우게나 로부터 안 셀 무스 에 이르 는 전통 적 인 실재론 적 견해 에 대해 명백히 유물론 을 제창 한 로스켈리누스 와 , 극단 적 인 형태 로 실념론 ( 實 念 論 ) 을 주장 하 는 샹 포 의 기욤 의 출현 은 보편 논쟁 의 대립 을 첨예화 하 였 다 . 그 가 쓴 저작 은 전해 지 는 것 이 별로 없 고 , 그 가 가르친 것 과 논적 들 이 그 가 가르쳤 다고 하 여 책망 하 는 것 을 구별 하 기 는 매우 어렵 다 . 아벨라르 두스 에게 보낸 편지 에 그 의 학설 이 전해 지 는 데 지나 지 않 는다 .',\n",
       "       '보편 논쟁 ( 普遍 論 爭 ) 에서 보편 의 문제 는 중세 철학 전체 를 일관 하 는 가장 중요 한 문제 로서 스콜라 철학 은 이 문제 로부터 시작 해서 이 문제 로 끝 났 다고 까지 말 할 수 있 다 . 아벨라르 두스 가 그 의 스승 샹 포 의 기욤 으로 하여금 자기 의 학설 을 변경 시키 게 한 문제 였 고 , 솔즈베리 의 요하네스 에 의하 면 인간 이 이 문제 를 해결 한다는 것 은 불 가능 하 다 . 논쟁 의 중심점 은 보편 개념 ( 類 와 種 ) 의 타당 가치 문제 및 개념 의 실제 성 · 객관 성 의 문제 이 다 . 초기 스콜라 철학 에서 는 신학 상 의 삼위일체 론 이나 교회 의 보편 성 과 결합 되 어 문제 가 됐 고 , 12 세기 의 사상계 를 들끓 게 하 였 다 . 발단 은 보 에 티 우스 가 라틴어 로 번역 한 포르피리오스 의 < 범주론 서설 ( 範疇 論 序說 ) > 에 있 다 . 유와 종 은 실재 인가 , 또는 사고 상 의 존재 인가 , 실재 한다면 물체 인가 , 또는 비 ( 非 ) 물체 인가 , 감각 적 대상 으로부터 분리 되 어 존재 하 는가 , 또는 감각 적 대상 자체 안 에 존재 하 는가 이상 의 세 가지 문제 를 그 는 제기 하 였으나 해결 을 보여 주 지 는 못했 던 것 이 다 . 이 설문 을 보 에 티 우스 는 < 범주론 주석 > 에서 제기 하 고 실재 하 는 것 은 사물 인가 , 또는 단순 한 음성 인가 , 하 는 형태 로 변경 시켰 다 . 사물 이 라고 하 는 실재론 ( 實在 論 ) 과 음성 이 라고 하 는 유명론 ( 唯 名論 ) 에 분류 되 는 논쟁 을 야기 시켰 다 . 콩피에뉴 의 로스켈리누스 와 샹 포 의 기욤 이 출현 하 자 양진영 의 대립 은 첨예화 되 었 다 . 스코투스 에리우게나 로부터 캔터베리 의 안셀무스 에 이르 는 전통 적 견해 는 신학 적 이유 도 있 어서 , 실재론 에 기울어져 있 고 , 명확 하 게 유명론 을 제창 한 것 은 로스켈리누스 이 다 . 극단 적 인 형태 로 실재론 을 주장 한 것 은 윌리엄 이 었 다 . 여러 가지 가설 중 에서 어느 것 을 선택 하 는가 하 는 것 은 하나 의 철학 을 완성 하 지 않 고서 는 불 가능 하 다 . 아리스토텔레스 와 플라톤 중 에서 누구 를 선택 하 는가 , 그렇 지 않 으면 이 들 을 결합 시키 는가 하 는 문제 가 되 면 자연학 · 형이상학 의 문제 까지 얽힌다 . 아벨라르 두스 에 의해 보편 의 문제 는 더욱 촉진 되 었 다 . 그 는 유명론 적 색채 를 가지 면서 조정 적 입장 을 취해 토마스 아퀴나스 의 온건 한 실재론 에 이르 는 길 을 열 었 다 . 그 에 의하 면 보편 은 추상 에 의해 획득 된 보편 개념 을 표시 하 기 위한 선언 인 것 이 다 . 사물 에 있 어서 어떤 객관 적 으로 있 는 것 은 문제 가 되 지 않 는다 . 사물 은 개별 적 인 것 으로 보편 은 아니 기 때문 이 다 . 토마스 아퀴나스 는 새로이 알려진 아리스토텔레스 와 이븐 시나 의 저술 의 영향 을 받 아 온 건 한 실재론 을 완성 하 였 다 . 보편 개념 에 있 어서 보편 의 내용 과 형식 을 구별 하 고 사유 밖 의 실재 와 구체 적 개체 에 내재 ( 內在 ) 하 는 본질 을 보편 개념 의 내용 에 대응 시킨다 . 개념 상 보편 의 형식 은 어떤 주관 적 인 것 으로서 사유 의 산물 이 지만 , 사유 형식 의 기초 는 지성 의 추상 활동 ( 抽象 活動 ) 에 있 다고 한다 . 14 , 15 세기 의 스콜라 철학자 인 오리올 의 피에르 , 오컴 의 윌리엄 , 아 이이 의 피에르 등 은 온건 한 실재론 을 고려 하 지 않 고 다시금 유명론 의 주관 적 주장 을 폈 다 . 따라서 신학 과 철학 을 분리 시키 고 스콜라 적 종합 을 붕괴 시켰 다 .',\n",
       "       '실재 ( 實在 , reality ) 란 인식 주체 로부터 독립 해 객관적으로 존재 한다고 여겨 지 는 것 을 말 한다 . 꿈 이나 망상 과 같이 인식 주체 에 의해 만들 어 진 것 은 구별 된다 . 또 , 표상 ( 表象 ) 을 변화 시키 는 사물 의 배후 에 있 다고 하 는 불변 의 실체 ( 實體 ) 를 의미 하 는 경우 도 있 다 .',\n",
       "       \"오컴 의 윌리엄 ( william of ockham , occam , 1280 년 - 1349 년 ) 은 영국 프란치스코 수도회 의 수사 이 자 철학자 이 다 . 영국 서리 주 의 오컴 출신 이 다 . 윌리엄 은 프란치스코 수도회 의 수사 로 지극히 청빈 한 삶 을 살 았 다 . 유명론 의 선구자 로서 그 는 일반 적 으로 근대 철학 의 아버지 로 인정 받 고 있 다 . 방법 론 적 원리 인 오컴 의 면도날 로 유명 한 오컴 은 신앙 문제 를 개인 의 문제 로 보다 자유주의 적 으로 생각 하 였 고 종교 개혁 기 에 루터 가 좋 아 했 던 유일 한 스콜라 철학자 였 다 . 영국 사리 주 의 오컴 마을 에서 태어났 다 . 프란치스코 회 에 속하 고 옥스퍼드 에서 배웠 으나 파리 에서 교편 을 잡 았 고 , 당시 세상 을 시끄럽 게 하 던 교황 권 ( 敎皇 權 ) 과 세속 권 ( 世俗 權 ) 의 싸움 에 흥미 를 갖 고 세속 권 을 지지 하 였 다 . 《 명제 집 ( 命題 集 ) 》 의 내용 에 관해 교황청 의 심문 을 받 았 고 아비뇽 에 호출 당했으며 , 1326 년 그 의 학설 은 이단 선고 를 받 았 다 . 2 년 후 교황청 의 추구 를 피해 파도바 의 마르 실리 우스 와 마찬가지 로 바이에른 의 루트비히 4 세 밑 으로 도피 하 여 보호 를 요청 했 다 . 도피 이후 에 도 그 는 교황 을 공격 하 는 글 을 몇 편 발표 하 였으며 , 뮌헨 에서 죽 은 것 으로 추측 된다 . 그 의 철학 상 업적 은 유명론 의 혁신 으로 추상 적 인 것 은 사유 속 에 개념 으로 존재 하 는 데 지나 지 않 고 실재 하 는 것 은 인식 되 는 개체 뿐 이 라고 하 였 다 . 다만 신앙 에 는 다른 진리 가 있 으며 , 이러 한 면 에서 는 신 의 절대 성 을 강조 하 고 신 은 노새 의 모습 으로 도 나타날 수 있 다고 하 며 , 신 의 지배 하 에서 는 비 합리 도 가능 하 다고 생각 하 였 다 . 오컴 은 신앙 을 위해서 신앙 과 지식 을 일관 되게 구별 하 고자 하 였 고 철학 적 문제 를 신학 적 관점 에서 비판 하 고 신학 을 철학 적 으로 반성 하 였 다 . 오컴 은 고유 한 의미 에서 과학 에 대한 엄격 한 정의 를 얻 으려고 하 였으며 고유 하 게 과학 이 라고 불릴 수 있 는 지식 은 보증 된 전제 로부터 필연 적 귀결 로 나오 는 논증 적 지식 이 라고 주장 하 였 다 . 또한 ' 좋 은 공동 사회 ' 건설 이야말로 군주 의 의무 라 하 고 , 그렇 지 못한 독재자 를 죽이 는 권리 를 국민 이 갖 고 있 다고 주장 하 였 다 . 교회 에 관해서 는 탁발 승단 ( 托鉢 僧團 ) 과 같 은 완전 한 무소유 가 이상 이 라고 말 하 며 교황 을 비난 하 였 다 .\",\n",
       "       '유명론 ( 唯 名論 , nominalism ) 이 란 형이상학 에서 보편 과 추상 적 인 대상 을 거부 하 고 단지 일반 적 혹은 추상 적 인 용어 들 의 존재 만 을 인정 하 고 단정 하 는 철학 적 견해 이 다 . 보편 과 추상 적 인 대상 의 존재 를 거부 한다 . 유명론 은 중세 스콜라 철학 의 보편 논쟁 의 하나 이 다 . 중세 초기 부터 보편 ( 普遍 ) 과 개체 ( 個體 ) 의 관계 에 대해 실념론 ( 實 念 論 , realism ) 과 유명론 ( nominalism ) 의 대결 이 있 었 다 . 보편 이 우선 해서 존재 한다고 하 는 실념론 에 대해 개체 가 우선 해서 존재 한다고 생각 하 는 것 이 유명론 이 다 . 처음 으로 유명론 을 주장 한 사람 은 로스켈리누스 였 다 . 그 후 주류 를 이룬 실념론 에 대항 하 여 다시 유명론 을 내세워서 스콜라 철학 에 도전 한 사람 은 페트루스 아우레 올루 스나 뒤 랑 드 생 푸르 생 이 었 다 . 페트루스 는 개체 는 언제나 지각 ( 知覺 ) 의 대상 이 라 하 였 고 , 또한 뒤 랑 은 이성 에 의존 하 는 것 이 권위 에 의존 하 는 것 보다 옳 다고 하 였 다 . 이러 한 경향 을 대성 하 여 유명론 을 실념론 과 대비 되 는 하나 의 큰 학파 로 형성 시킨 사람 은 오컴 의 윌리엄 이 었 다 . 그 는 영국인 특유 의 경험주의 를 바탕 으로 그 무렵 옥스퍼드 에 일어난 과학 적 연구 를 신학 · 철학 에 응용 하 여 새로운 경험 과학 의 길 을 열 었 다 . 그 에 의하 면 참된 명제 는 직접 명료 하 게 증명 되 지 않 으면 안 된다 . 그 에 반하 여 추상 적 인식 은 그 대상 의 존재 여부 를 확인 하 지 못한다 . 확인 되 는 것 은 특수 한 개체 의 인식 뿐 이 다 . 따라서 보편 은 개념 또는 소리 에 지나 지 않 고 실재 하 는 것 은 개체 뿐 이 다 . 이것 은 로저 베이컨 의 원리 가 철학 적 으로 전개 된 결과 였 다 . 그 를 계승 한 것 은 애덤 워 덤 , 미르 쿠르 의 존 등 이 다 . 그 중 에 도 오트 르 쿠 르 의 니콜라우스 는 모순율 ( 矛盾 律 ) 만 이 확실 한 기본 원칙 이 며 5 관 의 판단 인 경험 에 의해 인식 되 는 것 이외 에 는 긍정 할 수 없 다고 하 였 다 . 자연 에 관해서 는 아리스토텔레스 의 질료 와 형상 의 이론 을 버리 고 아톰 설 을 택했 다 . 뷔리당 은 오컴 주의 를 신봉 하 여 자연 연구 에 종사 했 고 타성 의 원리 를 발견 하 였 다 . 이러 한 의미 에서 그 는 근대 역학 ( 力學 ) 의 개조 이 다 . 최후 의 스콜라 학자 가브리엘 비엘 은 유명론 을 쉽 게 해설 하 여 멜란히톤 및 루터 에게 영향 을 미쳤 다 . 로버트 d . 누 슨 ( robert d . kundsen ) 은 루터 의 두 왕국 사상 에서 유명론 의 영향 이 나타난다고 한다 . [ 1 ] 이 와 같이 하 여 유명론 은 스콜라학 의 벽 을 뚫 고 근대 과학 · 근대 사상 의 길 을 준비 했 다 .',\n",
       "       \"1033 년 혹 1034 년 에 부르 고 뉴 왕국 의 아오스타 ( 현재 이탈리아 북부 피에몬테주 ) 에서 귀족 가문 인 아버지 곤 돌 포 ( gondulfo ) 와 어머니 에르 멘 베르가 ( ermenberga ) 사이 에서 장남 으로 태어났 다 . 27 세 에 그 는 베크 수도원 에서 수사 가 되 었 다 . 안 셀 무스 의 일생 은 신학자 였 던 베크 대수도원 시대 와 , 정치 · 종교 간 의 대립 이 심한 환경 에서 도 교회 의 자유 와 권리 를 배려 해서 헌신 한 캔터베리 시대 로 나뉜다 . 안셀무스 는 초기 에 ' 이해 하 기 위하 여 나 는 믿 는다 ' 는 태도 에서 < 모 놀 로 기움 ( 모놀로그 ) >, 신 의 존재 증명 으로 유명 한 < 프로 슬로 기움 > 과 < 진리 론 > 을 저술 하 고 후 에 는 속죄론 으로 유명 한 < 쿠르 데우스 호모 ( 왜 신 은 사람 이 되 었 는가 ) > 를 저술 했 다 .\",\n",
       "       \"아벨라르 는 당시 실재론 진영 을 대표 했 던 샹 포 의 기욤 과 친분 을 쌓 은 뒤 , 1102 년 파리 근교 에 입 성 , 교육자 로서 의 명성 을 쌓 아 가 기 시작 한다 . 그리고 자신 의 입장 을 보다 분명히 하 게 됨 에 따라 의견 차이 를 극복 하 지 못하 고 결국 기욤 과 결별 하 게 된다 . 아벨라르 는 1079 년 프랑스 서부 의 도시 낭트 인근 르 팔레 라는 곳 에서 영주 이 자 노트르담 대성당 의 수사 신부 를 지낸 아버지 에게서 태어났 다 . [ 1 ] 보편 논쟁 의 양축 을 형성 했 던 유명론 과 실재론 사이 에서 자신 만 의 독특 한 인식 론 과 형이상학 체계 를 구축 했으며 , 가정 교사 로 가르쳤 던 제자 이 자 후 에 로마 가톨릭교회 의 수녀 가 되 는 엘로이즈 와 의 사랑 으로 도 유명 하 다 . [ 2 ] 기욤 은 각기 다른 사물 을 하나 의 개념 으로 묶 는 공통 적 인 존재 자 , 즉 보편 자 가 사물 들 사이 에 존재 하 는 차이 와 는 관계없이 실재 함 을 주장 했 다 . 이를테면 ' 인간 ' 과 같 은 종 ( 種 ) 및 유 ( 類 ) 의 개념 들 은 ' 철수 ' 나 ' 영희 ' 와 독립 적 인 한편 으로 하나 의 ' 실체 ' 로서 존재 한다는 것 이 다 . 이 에 아벨라르 는 ' 종 ' 이나 ' 유 ' 등 의 일반 개념 들 이 단지 언어 의 산물 에 불과 하 다는 유명론 의 입장 을 거부 했 다 . 실제로 보편 개념 들 이 텅 빈 기호 에 불과 하 다면 그러 한 개념 들 이 포함 된 문장 또한 아무런 의미 가 없 거나 의미 가 있 다고 해도 이해 될 수 없 었 으리라는 것 이 다 . 그 는 이렇 듯 부분 적 으로 는 기욤 의 실재론 을 받아들였 는데 , 다른 한편 으로 는 그러 한 개념 의 실재성 이 물리 적 인 것 이 아니 라 관념 적 이 라고 주장 함 으로써 기욤 을 반박 했 다 . 보편 자 가 보편 적 이 고 일반 적 일 수 있 는 것 은 단지 인간 의 사고 에 의한 것 일 뿐 , 그것 이 통상 적 인 의미 에서 혹은 플라톤 적 의미 에서 실재 하 기 때문 은 아니 라는 것 이 다 . 아벨라르 에 따르 면 보편 개념 은 인간 의 오성 이 구체 적 인 사물 들 에 대한 경험 을 토대 로 각각 의 유사 한 속성 들 을 추려낸 , 즉 추상 한 결과물 이 다 . ' 인간 ' 이 라는 개념 은 ' 철수 ' 와 ' 영희 ' 를 비롯 한 모든 사람 들 에게서 발견 되 는 공통 된 속성 을 통해 성립 된다 . 이렇 듯 아벨라르 는 실재론 과 유명론 의 이분법 적 논리 에서 벗어나 인간 사고 의 경험 적 측면 과 추상 적 측면 을 모두 중시 함 으로써 중세 보편 논쟁 의 한계 를 극복 하 고자 했 다 . 이러 한 그 의 입장 은 개념론 이 라고 도 불린다 .\",\n",
       "       '형이상학 ( 形 而 上學 · 영어 : metaphysics ) 으로 번역 되 는 영어 낱말 \" 메타 피직스 ( metaphysics ) \" 는 그리스어 의 메타 ( meta : 뒤 ) 와 푸 지카 ( fusika : 자연학 ) 의 결합 으로 아리스토텔레스 에서 유래 하 였 다 . [ 1 ] 아리스토텔레스 의 정의 에 따르 면 , 형이상학 은 존재 의 근본 을 연구 하 는 학문 이 다 . [ 1 ] 그리고 라틴어 의 역어 로 세계 의 궁극 적 근거 를 연구 하 는 학문 이 며 , 다른 정의 로 는 , 형이상학 은 사회 의 근본 체계 , 사회 현상 , 모든 지식 들 또는 인류 대다수 에게 그 보다 나 은 지식 일지라도 , 그것 들 의 근원 은 변증 된 체계 가 아니 라 , 하나 의 독립 된 개별 적 영역 이 라고 주장 하 는 철학 이념 이 기 도 하 다 . 또한 아리스토텔레스 는 존재 의 근본 을 연구 하 는 부문 을 \" 제 1 철학 \" 이 라 하 고 동식물 등 을 연구 하 는 부문 을 \" 자연학 \" 이 라 했 다 . [ 1 ] 그 가 죽 은 후 유고 ( 遺稿 ) 를 정리 · 편집 함 에 있 어 제 1 철학 에 관한 것 이 \" 자연학 \" 뒤 에 놓여 그때 부터 메타 피지 카 ( metaphysica : 형이상학 ) 라는 말 이 쓰이 게 되 었 다 . [ 1 ] 형이상학 에 대한 동서양 의 견해 는 차이 가 있 다 . 대표 적 인 차이 로 는 서양 의 경우 인간 은 형 이 상학 적 진리 들 을 직접 적 인 경험 으로 알 수 없 다는 견해 가 많 은 반면 , 동양 의 경우 형 이 상학 적 진리 들 을 직접 적 인 경험 으로 알 수 있 다는 견해 가 많 다 . [ 2 ]',\n",
       "       '방정식 편집 n 개체 로 이루어진 개체군 을 s , e , i , r 의 네 그룹 으로 나누 어 s + e + i + r = 1 . {\\\\ displaystyle s + e + i + r = 1 . } 혹은 n s + n e + n i + n r = n . {\\\\ displaystyle ns + ne + ni + nr = n . } 의 공식 이 성립 되 도록 한다 . 모든 개체 는 susceptible ( s , 감염 대상 군 ) → exposed ( e , 접촉 군 ) → infectious ( i , 감 염군 ) → recovered ( r , 회복 군 ) 의 단계 를 거친다 . 전염병 의 확산 은 다음 과 같이 설명 될 수 있 다 . d s d t = − β s i , d e d t = β s i − a e , d i d t = a e − γ i , d r d t = γ i . {\\\\ displaystyle {\\\\ begin { aligned }{\\\\ frac {\\\\ mathrm { d } s }{\\\\ mathrm { d } t }}&=-\\\\ beta si , \\\\\\\\{\\\\ frac {\\\\ mathrm { d } e }{\\\\ mathrm { d } t }}&=\\\\ beta si - ae , \\\\\\\\{\\\\ frac {\\\\ mathrm { d } i }{\\\\ mathrm { d } t }}&= ae -\\\\ gamma i , \\\\\\\\{\\\\ frac {\\\\ mathrm { d } r }{\\\\ mathrm { d } t }}&=\\\\ gamma i . \\\\ end { aligned }}} 이것 은 상미분 방정식 의 비 선형 시스템 에 속한다 . 문헌 에서 는 여러 형태 의 공식 을 발견 할 수 있 는데 예 를 들 면 β s i n {\\\\ displaystyle {\\\\ frac {\\\\ beta si }{ n }}} 항 을 β s i {\\\\ displaystyle \\\\ beta si } 대신 쓰 는 식 이 다 . 이외 에 도 s + e + i + r {\\\\ displaystyle s + e + i + r } 의 합 을 반드시 1 {\\\\ displaystyle 1 } 이 라고 정하 는 대신 n 을 전체 개체군 이 라 할 때 n = s + e + i + r {\\\\ displaystyle n = s + e + i + r } 라고 정의 할 수 도 있 다 . 수량 단위 설명 s ( t ) 1 감염 대상 군 ( susceptible ) : 감염 될 수 있 으나 아직 감염 되 지 않 은 개체 의 수 e ( t ) 1 접촉 군 ( exposed ) : 이미 감염 되 었 으나 아직 병 을 전염 시키 지 는 않 는 단계 에 있 는 개체 의 수 i ( t ) 1 감 염군 ( infectious ) : 병 을 전염 시킬 수 있 는 개체 의 수 r ( t ) 1 회 복군 ( recovered 또는 resistent ) : 병 에서 회복 한 개체 의 수 와 격리 중 사망 한 개체 의 수 의 합 t d 시간 ( 일 ) β 1 / d 감염 률 ( transmission rate ) . 역수 는 접촉 평균 시간 과 같 다 . γ 1 / d 회복 률 ( recovery rate ) . 역수 는 평균 전염 가능 시간 과 같 다 . a 1 / d 역수 는 평균 지연 시간 ( latency ) 과 같 다 . 평균 지연 시간 은 접촉 군 ( exposed ) 의 한 개체 가 병 을 전염 시킬 수 있 게 되 어 감 염군 으로 분류 되 기 까지 의 평균 시간 을 나타내 며 잠복기 와 는 다른 데 이 는 증상 의 발현 과 병 을 전염 시킬 수 있 는 능력 이 갖춰 지 는 것 을 동치 할 수 없 기 때문 이 다 . 감염 률 은 접촉 률 ( contact rate ) 로 불리 기 도 하 는데 , 더 상세 하 게 는 β = p c {\\\\ displaystyle \\\\ beta = pc } 로 p {\\\\ displaystyle p } 는 감염 확률 을 , c 는 접촉 률 을 나타낸다 . 기초 감염 재 생산 수와 의 관계 편집 병 의 확산 이 멈추 려면 d e d t = 0 {\\\\ displaystyle {\\\\ frac {\\\\ mathrm { d } e }{\\\\ mathrm { d } t }}= 0 } 와 d i d t = 0 {\\\\ displaystyle {\\\\ frac {\\\\ mathrm { d } i }{\\\\ mathrm { d } t }}= 0 } 의 조건 이 성립 해야 한다 . 이 조건 들 을 방정식 에 대입 하 면 a e = β s i {\\\\ displaystyle ae =\\\\ beta si } 와 a e = γ i {\\\\ displaystyle ae =\\\\ gamma i } 가 되 므로 β s = γ {\\\\ displaystyle \\\\ beta s =\\\\ gamma } 라는 결과 가 도출 된다 . 이 는 기초 감염 재생 산수 r 0 = 1 {\\\\ displaystyle r _{ 0 }= 1 } 의 경우 와 같 고 s 0 = n {\\\\ displaystyle s _{ 0 }= n } 이 라고 하 면 [ 1 ] [ 2 ] r 0 = β n γ {\\\\ displaystyle r _{ 0 }={\\\\ frac {\\\\ beta n }{\\\\ gamma }}} 가 된다 . n = 1 {\\\\ displaystyle n = 1 } 일 때 정규 화 된 인명 수 나 변형 된 seir 공식 을 사용 하 면 ( sir 모형 에 도 적용 할 수 있 으나 r 0 {\\\\ displaystyle r _{ 0 }} 를 구하 는 공식 에서 β {\\\\ displaystyle \\\\ beta } 의 정의 가 다르 다 ) r 0 = β / γ {\\\\ displaystyle r _{ 0 }=\\\\ beta / \\\\ gamma } [ 3 ] [ 4 ] 중간 단계 로 의 이행 을 나타내 는 매개변수 a {\\\\ displaystyle a } 는 접촉 군 에 속한 환자 가 사망 할 가능 성 을 무시 할 경우 기초 감염 재생 산수 에 영향 을 주 지 않 는다 . [ 1 ] 시간 에 영향 을 받 는 순 감염 재생 산수 ( net reproduction number ) 는 q = 1 − s {\\\\ displaystyle q = 1 - s } 일 때 , r q = r 0 ⋅ s {\\\\ displaystyle r _{ q }= r _{ 0 }\\\\ cdot s } 또는 r q = ( 1 − q ) ⋅ r 0 {\\\\ displaystyle r _{ q }=\\\\ left ( 1 - q \\\\ right ) \\\\ cdot r _{ 0 }} 로 정의 할 수 있 다 . 최대 감염자 비율 편집 기초 감염 재생 산수 는 개체군 의 최대 감염자 비율 에 큰 영향 을 준다 . 병 에 감염 된 개체 전체 를 j {\\\\ displaystyle j } 라고 하 고 j ( t ) = e ( t ) + i ( t ) {\\\\ displaystyle j ( t ) = e ( t ) + i ( t ) } 이 면 위 의 미분 방정식 에 의해 d j d s = d e + d i d s = − γ i + β s i − β s i = γ β s − 1 {\\\\ displaystyle {\\\\ frac {\\\\ mathrm { d } j }{\\\\ mathrm { d } s }}={\\\\ frac {\\\\ mathrm { d } e +\\\\ mathrm { d } i }{\\\\ mathrm { d } s }}={\\\\ frac {-\\\\ gamma i +\\\\ beta si }{-\\\\ beta si }}={\\\\ frac {\\\\ gamma }{\\\\ beta s }}- 1 } 또는 기초 감염 재생 산수 r 0 = β γ {\\\\ displaystyle r _{ 0 }={\\\\ frac {\\\\ beta }{\\\\ gamma }}} 일 때 d j d s = 1 r 0 s − 1 . {\\\\ displaystyle {\\\\ frac {\\\\ mathrm { d } j }{\\\\ mathrm { d } s }}={\\\\ frac { 1 }{ r _{ 0 } s }}- 1 . } 가 된다 . 이 방정식 을 d j = d s r 0 s − d s {\\\\ displaystyle \\\\ mathrm { d } j ={\\\\ frac {\\\\ mathrm { d } s }{ r _{ 0 } s }}-\\\\ mathrm { d } s } 로 바꾸 고 변수 분리 법 을 통한 적분 에 의해 모든 t 에 적용 되 는 j ( t ) + s ( t ) − 1 r 0 ln \\u2061 s ( t ) = const {\\\\ displaystyle j ( t ) + s ( t ) -{\\\\ frac { 1 }{ r _{ 0 }}}\\\\ ln s ( t ) ={\\\\ text { const }}} 가 도출 되 는 데 여기 서 ln {\\\\ displaystyle \\\\ ln } 은 자연로그 를 뜻 한다 . 따라서 j ( t ) + s ( t ) − 1 r 0 ln \\u2061 s ( t ) = j ( 0 ) + s ( 0 ) − 1 r 0 ln \\u2061 s ( 0 ) {\\\\ displaystyle j ( t ) + s ( t ) -{\\\\ frac { 1 }{ r _{ 0 }}}\\\\ ln s ( t ) = j ( 0 ) + s ( 0 ) -{\\\\ frac { 1 }{ r _{ 0 }}}\\\\ ln s ( 0 ) } 혹은 j ( t ) = j ( 0 ) + s ( 0 ) − 1 r 0 ln \\u2061 s ( 0 ) + 1 r 0 ln \\u2061 s ( t ) − s ( t ) ⏟ =: f ( s ( t ) ) . {\\\\ displaystyle j ( t ) = j ( 0 ) + s ( 0 ) -{\\\\ frac { 1 }{ r _{ 0 }}}\\\\ ln s ( 0 ) +\\\\ underbrace {{\\\\ frac { 1 }{ r _{ 0 }}}\\\\ ln s ( t ) - s ( t ) } _{=:\\\\ f ( s ( t ) ) }.} 가 성립 한다 . 도움 함수 f ( x ) = ln \\u2061 x r 0 − x {\\\\ displaystyle f ( x ) =\\\\ ln {\\\\ frac { x }{ r _{ 0 }}}- x } 는 f ′ ( x ) = 1 r 0 x − 1 {\\\\ displaystyle f \\'( x ) ={\\\\ frac { 1 }{ r _{ 0 } x }}- 1 } 이 므로 최대 값 이 x = 1 r 0 {\\\\ displaystyle x ={\\\\ frac { 1 }{ r _{ 0 }}}} 이 다 . 최대 감염자 비율 j max {\\\\ displaystyle j _{\\\\ max }} 에는 s ( t ) = 1 r 0 {\\\\ displaystyle s ( t ) ={\\\\ frac { 1 }{ r _{ 0 }}}} 일 때 도달 하 게 되 며 , 따라서 j max {\\\\ displaystyle j _{\\\\ max }} 는 기초 감염 재생 산수 와 초기 값 j {\\\\ displaystyle j } 및 s {\\\\ displaystyle s } 만 의 영향 을 받 는다 : j max = j ( 0 ) + s ( 0 ) − 1 r 0 ln \\u2061 s ( 0 ) − 1 r 0 + 1 r 0 ln \\u2061 1 r 0 = j ( 0 ) + s ( 0 ) + 1 r 0 ( ln \\u2061 1 r 0 s ( 0 ) − 1 ) . {\\\\ displaystyle j _{\\\\ text { max }}= j ( 0 ) + s ( 0 ) -{\\\\ frac { 1 }{ r _{ 0 }}}\\\\ ln s ( 0 ) -{\\\\ frac { 1 }{ r _{ 0 }}}+{\\\\ frac { 1 }{ r _{ 0 }}}\\\\ ln {\\\\ frac { 1 }{ r _{ 0 }}}= j ( 0 ) + s ( 0 ) +{\\\\ frac { 1 }{ r _{ 0 }}}\\\\ left ( \\\\ ln {\\\\ frac { 1 }{ r _{ 0 } s ( 0 ) }}- 1 \\\\ right ) . } 아직 알려 지 지 않 은 바이러스 등 에 의해 새로이 등장 하 는 전염병 의 경우 s ( 0 ) = 1 {\\\\ displaystyle s ( 0 ) = 1 } 이 고 j ( 0 ) = 0 {\\\\ displaystyle j ( 0 ) = 0 } 으로 설정 되 고 최대 감염자 비율 과 기초 감염 재생 산수 의 관계 는 다음 과 같 아 진다 . j max = 1 + 1 r 0 ( ln \\u2061 1 r 0 − 1 ) . {\\\\ displaystyle j _{\\\\ text { max }}= 1 +{\\\\ frac { 1 }{ r _{ 0 }}}\\\\ left ( \\\\ ln {\\\\ frac { 1 }{ r _{ 0 }}}- 1 \\\\ right ) . } 이 공식 은 sir 모형 의 최대 감염자 비율 을 구하 는 공식 과 일치 한다 . 전염병 유행 말기 회복 된 개체 의 비율 편집 격리 가 전혀 없이 전염병 이 유행 할 경우 개체군 내 에서 감염 된 전체 개체 의 비율 도 기초 감염 재생 산수 와 상관 관계 가 있 다 . 미분 방정식 으로 나타낼 경우 d s d r = s ′ ( t ) r ′ ( t ) = − β s γ = − r 0 s . {\\\\ displaystyle {\\\\ frac {\\\\ mathrm { d } s }{\\\\ mathrm { d } r }}={\\\\ frac { s \\'( t ) }{ r \\'( t ) }}=-{\\\\ frac {\\\\ beta s }{\\\\ gamma }}=- r _{ 0 } s . } 이 고 초기 값 이 r ( 0 ) = 0 {\\\\ displaystyle r ( 0 ) = 0 } 라면 s ( t ) = s ( 0 ) e − r 0 r ( t ) . {\\\\ displaystyle s ( t ) = s ( 0 ) {\\\\ mathrm { e } }^{- r _{ 0 } r ( t ) }.} 이 다 . t → ∞ {\\\\ displaystyle t \\\\ to \\\\ infty } 일 경우 e = i = 0 {\\\\ displaystyle e = i = 0 } 이 고 따라서 s + r = 1 {\\\\ displaystyle s + r = 1 } 이 된다 . 여기 서 1 − q = s ( 0 ) e − r 0 q , q : = lim t → ∞ r ( t ) . {\\\\ displaystyle 1 - q = s ( 0 ) {\\\\ mathrm { e } }^{- r _{ 0 } q },\\\\ quad q : =\\\\ lim _{ t \\\\ to \\\\ infty } r ( t ) . } 를 도출 할 수 있 고 다음 과 같 은 공식 에 이르 게 된다 . − r q e − r q = ( q − 1 ) r 0 e ( q − 1 ) r 0 = − s ( 0 ) r 0 e − r 0 . {\\\\ displaystyle - r _{ q }{\\\\ mathrm { e } }^{- r _{ q }}=( q - 1 ) r _{ 0 }{\\\\ mathrm { e } }^{( q - 1 ) r _{ 0 }}=- s ( 0 ) r _{ 0 }{\\\\ mathrm { e } }^{- r _{ 0 }}.} x : = − s ( 0 ) r 0 e − r 0 {\\\\ displaystyle x : =- s ( 0 ) r _{ 0 }\\\\ mathrm { e } ^{- r _{ 0 }}} 이 고 y : = ( q − 1 ) r 0 {\\\\ displaystyle y : =( q - 1 ) r _{ 0 }} 라고 했 을 때 최종 적 인 공식 은 y e y = x {\\\\ displaystyle y \\\\ mathrm { e } ^{ y }= x } 가 되 고 람베르트 w 함수 w ( x ) {\\\\ displaystyle w ( x ) } 를 활용 해 y = w ( x ) {\\\\ displaystyle y = w ( x ) } 로 바꾼 뒤 역치 환하 는 과정 을 거쳐 q = 1 + 1 r 0 w ( − s ( 0 ) r 0 e − r 0 ) {\\\\ displaystyle q = 1 +{\\\\ frac { 1 }{ r _{ 0 }}} w ( - s ( 0 ) r _{ 0 }{\\\\ mathrm { e } }^{- r _{ 0 }})} 에 도달 하 게 된다 . w 함수 의 필요 한 부분 을 계산 하 려면 f ( w ) : = w e w − x {\\\\ displaystyle f ( w ) : = w \\\\ mathrm { e } ^{ w }- x } 함수 의 2 차 테일러 다항식 에 − 1 을 넣 고 영점 을 구한 뒤 고정 소수점 반복 을 w ↦ x e − w {\\\\ displaystyle w \\\\ mapsto x \\\\ mathrm { e } ^{- w }} 로 한 차례 적용 한다 . 그 결과물 은 w = x exp \\u2061 ( 1 − 2 e x + 2 ) . {\\\\ displaystyle w = x \\\\ exp ( 1 -{\\\\ sqrt { 2 \\\\ mathrm { e } x + 2 }}).} 이 다 . w 함수 의 가까운 근사치 는 w ( x ) ≈ φ n ( w ) , {\\\\ displaystyle w ( x ) \\\\ approx \\\\ varphi ^{ n }( w ) , } 에 의해 얻 을 수 있 고 여기 서 φ n {\\\\ displaystyle \\\\ varphi ^{ n }} 는 뉴턴 방법 의 n 번 째 반복 인 φ ( w ) = w − f ( w ) f ′ ( w ) = x e − w + w 2 w + 1 {\\\\ displaystyle \\\\ varphi ( w ) = w -{\\\\ frac { f ( w ) }{ f \\'( w ) }}={\\\\ frac { x \\\\ mathrm { e } ^{- w }+ w ^{ 2 }}{ w + 1 }}} 을 뜻 한다 . 현실 의 전염병 에 적용 할 때 는 n = 4 {\\\\ displaystyle n = 4 } 이 면 충분 하 다 . 기하급수 적 초기 단계 편집 전염병 의 초기 단계 에서 는 확산 이 기하급수 적 인 형태 에 가깝 게 일어난다 . i = i ( 0 ) e λ t {\\\\ displaystyle i = i ( 0 ) {\\\\ mathrm { e } }^{\\\\ lambda t }} 을 가정 한다면 i ′ = λ i {\\\\ displaystyle i \\'=\\\\ lambda i } 역시 참 이 된다 . 그 에 따라 a e = γ i + λ i {\\\\ displaystyle ae =\\\\ gamma i +\\\\ lambda i } 와 r = γ i / λ {\\\\ displaystyle r =\\\\ gamma i / \\\\ lambda } 이 성립 하 며 따라서 1 − s = e + i + r = γ + λ a i + i + γ λ i = ( γ + λ a + 1 + γ λ ) i . {\\\\ displaystyle 1 - s = e + i + r ={\\\\ frac {\\\\ gamma +\\\\ lambda }{ a }} i + i +{\\\\ frac {\\\\ gamma }{\\\\ lambda }} i ={\\\\ big ( }{\\\\ frac {\\\\ gamma +\\\\ lambda }{ a }}+ 1 +{\\\\ frac {\\\\ gamma }{\\\\ lambda }}{\\\\ big ) } i . } 라는 결과 가 나온다 . 이 방정식 을 양쪽 다 미분 한 후 − s ′ = β s i {\\\\ displaystyle - s \\'=\\\\ beta si } 로 치환 하 고 i {\\\\ displaystyle i } 로 나누 면 β s = ( γ + λ a + 1 + γ λ ) λ {\\\\ displaystyle \\\\ beta s ={\\\\ big ( }{\\\\ frac {\\\\ gamma +\\\\ lambda }{ a }}+ 1 +{\\\\ frac {\\\\ gamma }{\\\\ lambda }}{\\\\ big ) }\\\\ lambda } 혹은 a β s = ( λ + a ) ( λ + γ ) . {\\\\ displaystyle a \\\\ beta s =(\\\\ lambda + a ) ( \\\\ lambda +\\\\ gamma ) . } 를 얻 게 된다 . 초기 에 는 s ≈ 1 {\\\\ displaystyle s \\\\ approx 1 } 가 상당히 정확 한 근삿값 이 므로 s = 1 {\\\\ displaystyle s = 1 } 이 성립 하 고 매개변수 a , β , γ {\\\\ displaystyle a , \\\\ beta , \\\\ gamma } 와 증식 상수 λ {\\\\ displaystyle \\\\ lambda } 의 관계 를 알아낼 수 있 다 . 다른 체계 적 접근 법 으로 는 s {\\\\ displaystyle s } 를 곧바로 1 로 정의 하 고 미분 방정식 을 연립 일차 방정식 으로 단순 화 하 여 ( e ′ i ′ ) = ( − a β a − γ ) ( e i ) {\\\\ displaystyle {\\\\ begin { pmatrix } e \\'\\\\\\\\ i \\'\\\\ end { pmatrix }}={\\\\ begin { pmatrix }- a &\\\\ beta \\\\\\\\ a &-\\\\ gamma \\\\ end { pmatrix }}{\\\\ begin { pmatrix } e \\\\\\\\ i \\\\ end { pmatrix }}} 로 설명 하 는 것 이 가능 하 다 . [ 5 ] 다른 접근 방법 들 도 고정 계수 와 고유값 & 고유 벡터 를 활용 한 선형 상미분 방정식 에 기반 한다 . 증식 상수 는 계수 행렬 j : = ( − a β a − γ ) {\\\\ displaystyle j : ={\\\\ big ( }{\\\\ begin { smallmatrix }- a &\\\\ beta \\\\\\\\ a &-\\\\ gamma \\\\ end { smallmatrix }}{\\\\ big ) }} 의 고유 값 으로 이미 발견 한 방정식 은 0 = det ( j − λ ( 1 0 0 1 ) ) = ( a + λ ) ( γ + λ ) − a β . {\\\\ displaystyle 0 =\\\\ det \\\\ left ( j -\\\\ lambda {\\\\ begin { pmatrix } 1 & 0 \\\\\\\\ 0 & 1 \\\\ end { pmatrix }}\\\\ right ) =( a +\\\\ lambda ) ( \\\\ gamma +\\\\ lambda ) - a \\\\ beta . } 에 의해 구할 수 있 다 . 모든 기하급수 적 증식 과정 에서 와 마찬가지 로 증식 상수 λ {\\\\ displaystyle \\\\ lambda } 는 더 이해 가 쉽 게 t n = ln \\u2061 ( n ) λ , {\\\\ displaystyle t _{ n }={\\\\ frac {\\\\ ln ( n ) }{\\\\ lambda }},} 를 통해 수 배 의 증식 이 이루어지 기 까지 의 시간 으로 나타낼 수 있 으며 , 이 는 특히 배 가 시간 t 2 {\\\\ displaystyle t _{ 2 }} 에도 적용 가능 하 다 . 예시 편집 다음 은 독일 의 코로나 19 범유행 을 모델링 할 때 쓰인 매개변수 를 파이썬 에서 그대로 적용 한 예시 이 다 . [ 6 ] 전염병 의 확산 은 기초 감염 재생 산수 = 2 . 4 {\\\\ displaystyle = 2 . 4 } 를 토대 로 이루어지 고 , 이 는 중요 한 격리 조치 들 이 취해 지 지 않 았 을 경우 에 해당 한다 . 기초 값 문제 를 수치 적 으로 푸 는 데 는 오일러 방법 이 면 충분 하 다 . from numpy import array as vector # explicit euler method def euler _ method ( f , t 0 , x 0 , t 1 , h ) : t = t 0 ; x = x 0 a = [ [ t , x ] ] for k in range ( 0 , 1 + int ( ( t 1 - t 0 ) / h ) ) : t = t 0 + k * h x = x + h * f ( t , x ) a . append ( [ t , x ] ) return a def seir _ model ( beta , gamma , a ) : def f ( t , x ) : s , e , i , r = x return vector ( [ - beta * s * i , beta * s * i - a * e , a * e - gamma * i , gamma * i ] ) return f def seir _ simulation ( beta , gamma , a , e 0 , i 0 , days , step = 0 . 1 ) : x 0 = vector ( [ 1 . 0 - e 0 - i 0 , e 0 , i 0 , 0 . 0 ] ) return euler _ method ( seir _ model ( beta , gamma , a ) , 0 , x 0 , days , step ) def diagram ( simulation ) : import matplotlib . pyplot as plot plot . style . use ( \\' fivethirtyeight \\' ) figure , axes = plot . subplots ( ) figure . subplots _ adjust ( bottom = 0 . 15 ) axes . grid ( linestyle = \\':\\' , linewidth = 2 . 0 , color = \"# 808080 \" ) t , x = zip ( * simulation ( ) ) s , e , i , r = zip ( * x ) axes . plot ( t , s , color = \"# 0000 cc \" ) axes . plot ( t , e , color = \"# ffb 000 \" , linestyle = \\'--\\' ) axes . plot ( t , i , color = \"# a 00060 \" ) axes . plot ( t , r , color = \"# 008000 \" , linestyle = \\'--\\' ) plot . show ( ) def simulation 1 ( ) : n = 83200000 # einwohnerzahl von deutschland 2019 / 2020 r 0 = 2 . 4 ; gamma = 1 / 3 . 0 return seir _ simulation ( beta = r 0 * gamma , gamma = gamma , a = 1 / 5 . 5 , e 0 = 40000 . 0 / n , i 0 = 10000 . 0 / n , days = 140 ) diagram ( simulation 1 ) s , e , i , r 의 네 군 이 전체 개체군 에서 차지 하 는 비율 을 날짜 별 로 계산 한 결과 . s 는 청색 , e 는 노란색 점선 , i 는 자홍색 , r 는 녹색 점선 으로 표시 . 여기 서 볼 수 있 는 것 은 전염병 이 면역 임계 치 ( critical immune threshold ) q c = 1 − 1 r 0 = 58 % {\\\\ displaystyle q _{ c }= 1 -{\\\\ frac { 1 }{ r _{ 0 }}}= 58 \\\\,\\\\%} 에 도달 한 다음 에 도 감염 군 에 의해 계속 전파 된다는 점 이 다 . 다만 전염병 이 면역 임계 치 에 도달 한 후 에 는 약 한 달 간 의 강력 한 격리 조치 를 통해 멈추 도록 만들 수 있 을 것 이 다 . 인구 통계 역학 을 포함 할 경우 편집 상태 도 사망률 μ {\\\\ displaystyle \\\\ mu } 를 상수 로 두 고 이 에 상응 하 는 출생률 과 함께 모형 을 확장 시킨 s ′ = μ − β s i − μ s , e ′ = β s i − a e − μ e , i ′ = a e − γ i − μ i , r ′ = γ i − μ r {\\\\ displaystyle {\\\\ begin { aligned } s \\'&=\\\\ mu -\\\\ beta si -\\\\ mu s , \\\\\\\\ e \\'&=\\\\ beta si - ae -\\\\ mu e , \\\\\\\\ i \\'&= ae -\\\\ gamma i -\\\\ mu i , \\\\\\\\ r \\'&=\\\\ gamma i -\\\\ mu r \\\\ end { aligned }}} 공식 도 있 다 . 원래 seir 모형 과 는 다르 게 전염병 의 풍토병 화 를 전제 하 며 s ′ = e ′ = i ′ = r ′ = 0 {\\\\ displaystyle s \\'= e \\'= i \\'= r \\'= 0 } 라고 정의 한 평 형 에 이르 기 까지 감염 대상 군 s {\\\\ displaystyle s } 에서 는 진동 이 올 수 도 있 다 . 기초 감염 재생 산수 는 여기 서 평형 상태 를 놓 고 볼 때 다음 과 같이 정의 할 수 있 다 . r 0 = β a ( μ + a ) ( μ + γ ) . {\\\\ displaystyle r _{ 0 }={\\\\ frac {\\\\ beta a }{(\\\\ mu + a ) ( \\\\ mu +\\\\ gamma ) }}.} 시간 의존 적 전염 률 ( time - dependent transmission rate ) 편집 전염병 을 대하 는 태도 의 변화 , 격리 와 계절 성 은 전염 률 의 변화 를 가져오 고 , 이 는 전염 률 을 시간 의존 적 함수 β ( t ) {\\\\ displaystyle \\\\ beta ( t ) } 로 모델링 할 때 고려 되 는 사안 이 다 . 이 때 에 도 다른 모형 들 은 달라지 지 않 는다 . [ 7 ] 계절 성 을 가장 단순 하 게 모델링 하 는 방법 으로 는 사인 진동 ( sine oscillation ) 형태 로 날씨 가 추운 달 에 는 전염 률 이 높 고 따뜻 한 달 에 는 전염 률 이 낮 게 나오 는 것 을 가정 할 수 가 있 다 . [ 8 ] 명백 한 시간 의존도 를 가진 미분 방정식 체계 는 자생 적 이 지 않 고 따라서 더 이상 직접 적 으로 역동 적 인 체계 라고 할 수 없 다 . 다만 t ′ = 1 {\\\\ displaystyle t \\'= 1 } 의 추가 를 통해 인위 적 으로 자생 적 인 체계 를 갖출 수 는 있 다 . 외부 링크 편집 seir 모형 계산기 전염병 의 경과 를 seir 모형 과 변수 의 자유 로운 입력 을 통해 시뮬레이션 하 기 참고 문헌 편집 matt j . keeling , pejman rohani : modeling infectious diseases in humans and animals . princeton university press , 2008 . . princeton university press , 2008 . matthias an der heiden , udo buchholz : modellierung von beispielszenarien der sars - cov - 2 - epidemie 2020 in deutschland . robert koch - institut , abteilung für infektionsepidemiologie ( 20 . märz 2020 ) . doi : 10 . 25646 / 6571 . 2 .',\n",
       "       '오스트리아 마리보르 . 치터 연주자 . 오스트리아 마리보르 . 치터 ( zither ) 는 골무 로 줄 을 뜯 어 음 을 내 는 현악기 의 일종 이 다 . 역사 [ 편집 ] 치터 의 모습 . 악기 의 발생 시기 는 매우 오래 된 것 으로 알려졌으며 현존 악기 로 는 17 세기 의 것 뿐 이 다 . 이 악기 는 주로 헝가리 , 오스트리아 , 독일 남부 , 스위스 등 에서 애용 되 는 민속 악기 로서 크기 는 60 – 80 cm 정도 의 공명통 ( 共鳴 筒 ) 이 있 는 상자 형태 의 악기 이 다 . 무릎 또는 대 ( 臺 ) 위 에 놓 고 연주 한다 . 몸통 위 의 한 쪽 에 구멍 이 있 어 그 위 에 거트 ( gut ) 또는 금속 으로 된 보통 25 줄 에서 30 줄 의 현 ( 반주 용 ) 이 끼워져 있 고 그 옆 으로 병행 하 여 프렛 위 에 5 줄 혹은 6 줄 의 가락 용 금속 현 이 매여 있 다 . 이 와 같 은 현 의 수효 나 몸통 의 모양 은 각기 지방 사람 들 의 기호 에 따라 많 은 차이 가 있 다 . 조현 도 각 지방 의 곡 의 양식 에 따라 다르 다 . 가락 용 의 현 의 조현 에 는 빈 식 과 뮌헨 식 이 있 으나 일반 적 으로 는 뮌헨 식 이 쓰인다 . 주법 은 가락 은 골무 를 끼운 오른손 엄지손가락 으로 연주 하 고 반주 는 왼손 의 가운데 3 손가락 으로 연주 한다 . 독주 악기 로 나 반주 용 악기 로 도 쓰이 며 가락 현 의 투명 한 울림 에 화음 현의 부드러운 울림 이 조화 하 여 그 음색 은 비할 데 없이 아름답 고 로맨틱 한 향기 를 가진다 . 요한 슈트라우스 2 세 의 왈츠곡 \" 비엔나 숲 의 이야기 \" 의 서주 나 1949 년 의 영화 《 제 3 의 사나이 》 에 쓰여 그 아름다운 음빛깔 로 인하 여 널리 인기 있 는 악기 가 되 었 다 .',\n",
       "       '× matlab 명령 다음 matlab 명령 에 해당 하 는 링크 를 클릭 했 습니다 . 명령 을 실행 하 려면 matlab 명령 창 에 입력 하 십시오 . 웹 브라우저 는 matlab 명령 을 지원 하 지 않 습니다 .',\n",
       "       \"두 행렬 간 상관 관계 를 찾 아 두 개 의 열 벡터 간 상관관계 와 비교 합니다 . 표본 데이터 를 생성 합니다 . rng ( ' default ' ) x = randn ( 30 , 4 ) ; y = randn ( 30 , 4 ) ; 행렬 x 의 2 열 과 행렬 y 의 4 열 간 의 상관 관계 를 추가 합니다 . y ( : , 4 ) = y ( : , 4 ) + x ( : , 2 ) ; x 와 y 의 열 간 의 상관 관계 를 계산 합니다 . [ rho , pval ] = corr ( x , y ) rho = 4 × 4 - 0 . 1686 - 0 . 0363 0 . 2278 0 . 3245 0 . 3022 0 . 0332 - 0 . 0866 0 . 7653 - 0 . 3632 - 0 . 0987 - 0 . 0200 - 0 . 3693 - 0 . 1365 - 0 . 1804 0 . 0853 0 . 0279 pval = 4 × 4 0 . 3731 0 . 8489 0 . 2260 0 . 0802 0 . 1045 0 . 8619 0 . 6491 0 . 0000 0 . 0485 0 . 6039 0 . 9166 0 . 0446 0 . 4721 0 . 3400 0 . 6539 0 . 8837 예상 대로 x 의 2 열 과 y 의 4 열 간 의 상관 계수 , 즉 rho ( 2 , 4 ) 가 가장 높 으며 , 이 는 두 열 간 의 높 은 양 의 상관 관계 를 나타냅니다 . 대응 하 는 p - 값 인 pval ( 2 , 4 ) 는 표시 된 4 자리 까지 0 입니다 . p - 값 이 유 의 수준 0 . 05 보다 작 기 때문 에 ' 두 열 간 에 상관관계 가 없 다 ' 는 가설 이 기각 됨 을 나타냅니다 . corrcoef 를 사용 하 여 x 와 y 간 의 상관 관계 를 계산 합니다 . [ r , p ] = corrcoef ( x , y ) r = 2 × 2 1 . 0000 - 0 . 0329 - 0 . 0329 1 . 0000 p = 2 × 2 1 . 0000 0 . 7213 0 . 7213 1 . 0000 corr 함수 와 다르 게 matlab ® 함수 corrcoef 는 입력 행렬 x 와 y 간 의 상관 관계 를 계산 하 기 전 에 이 두 입력 행렬 을 열 벡터 x ( : ) 및 y ( : ) 로 변환 합니다 . 따라서 행렬 x 의 2 열 과 행렬 y 의 4 열 이 변환 된 열 벡터 에서 서로 다른 섹션 에 있 으므로 이 두 열 간 의 상관 관계 가 더 이상 존재 하 지 않 게 됩니다 .\",\n",
       "       '여름 에 특히 추천 하 는 레시피 입니다 . 올리브유 , 식초 ( 레몬 ) , 설탕 정도 의 조합 이 라면 재료 구하 기 가 어렵 지 는 않 겠 죠 ? 이 소스 를 베이스 로 찬 파스타 에 뿌리 면 콜드 파스타 , 풀 위 에 뿌리 면 그대로 상큼 한 샐러드 가 됩니다 . 곁들이 는 재료 는 냉장고 상황 에 따라 바꾸 면 되 니 , 소스 만 갖춰 두 면 활용 도 가 높 지요 . 혼자 살 때 화이트 와인 식초 를 안 사 고 안 사 다가 결국 본가 들어오 기 몇 주 전 에 샀 는데 ( 왠지 쓸 데 도 없 을 것 같 고 . .) 생각 보다 비싸 지 도 않 고 이런 요리 할 때 유용 합니다 . 레몬 은 신선 한 맛 도 좋 고 제스트 도 긁 어 쓸 수 있 지만 쓰레기 도 나오 고 ( 중요 ) 매번 짜 다 보 면 스 퀴져도 설거지 해야 하 고 ( 중요 ) 하 다 보 니 상큼 한 음식 을 좋아하 신다면 와인 식초 하나 쯤 장만 해 두 는 것 도 괜찮 습니다 . 화이트 랑 레드 중 에 고민 하 다 레드 는 색깔 도 있 고 , 이미 발사믹 이 있 으니 깔끔 하 게 화이트 로 가 자고 생각 하 고 화이트 를 샀었 네요 . 백화점 식품 코너 가 면 식초 가 다양 한데 , 고르기 어렵 잖 아요 . 이럴 때 저 는 . ... 1 ) 제일 싼 건 피하 고 2 ) 살 수 있 는 가격대 에서 크기 가 작 은 것 을 사면 ( 단위 가격 이 높 음 ) 3 ) 망하 지 는 않 는다 . 는 기준 으로 구매 합니다 . 그냥 야매 팁 이 니 참고 만 하 셔요 : ) 포스팅 이 엄청나 게 밀려 있 어요 . 올해 는 영상 도 찍 으려고 했 는데 벌써 6 월 이 코앞 입니다 . 다 들 잘 지내 고 계신지 -',\n",
       "       '4 . 이해 하 셨 다고 생각 하 신 분 들 을 위해 질문지 를 만들 어 봤 습니다 . 정확 한 답 이 있 는 질문 도 있 고 , 정확 한 답 이 없 는 질문 도 있 습니다 . 미리 검색 하 지 않 고 아래 질문 들 에 막힘없이 대답 할 수 있 다면 올 웨 더 투자 를 하 셔도 될 듯 합니다 . \\u200b 1 ) 60 / 40 대비 올 웨더 전략 의 차이점 2 ) 다른 회사 ( aqr , wealthfront , panagora ) 들 의 risk parity 전략 과 올 웨 더 전략 의 차이점 3 ) 현재 환율 에 환전 해서 올 웨 더 투자 를 시작 하 는 게 맞 는지 4 ) 올 웨더 에서 왜 물가 연동 채 와 명목 채권 의 크기 가 회사채 , 신흥 국채 권 의 비율 보다 높 은 지 5 ) 올 웨더 에서 왜 신흥 국채 권 은 달러 표기 채권 이 아니 라 로컬 화폐 채권 을 써야 하 는지 6 ) 올 웨더 에서 왜 자산 배분 에 모 멘 텀 을 넣 거나 cape 등 의 valuation 지표 를 활용 하 지 않 는지 . 왜 동적 자산 배분 을 안 하 는지 7 ) 머니 의 올 시즌스 포트폴리오 와 올 웨 더 포트폴리오 의 차이점 8 ) ( 데이터 를 구하 기 쉬운 ) 1996 년 부터 엑 셀로 백 테스트 할 수 있 는가 ? 9 ) 불리 오의 올 웨더 가 올 웨더 가 아니 라고 얘기 하 는 이유 10 ) 올 웨 더 투자자 들 이 국내 투자자 대비 소외 받 는 해 는 언제 인지 그런 단점 을 어떻게 보완 할 수 있 는지 11 ) 올 웨 더 포트폴리오 에서 가장 마음 에 안 드 는 자산 군 과 그 이유 12 ) 올 웨 더 포트폴리오 를 업그레이드 한다면 어떻게 ? 13 ) edv 같 은 etf 는 내부 적 으로 어떻게 동작 하 는지 ? 입금 들어오 면 어떻게 하 는지 . 돈 이 나가 면 어떻게 하 는지 . 14 ) 채권 의 maturity , duration , coupon 이 무엇 인지 . 금리 에 따라 채권 의 가격 이 바뀌 는 이유 는 무엇 인지 . 15 ) 인덱스 펀드 에 너무 많 은 자금 이 들어가 있 어 2008 년 같 은 상황 이 다시 오 면 갑자기 환매 가 나올 수 있 는데 이 부분 어떻게 생각 하 는지 16 ) 전략 이 알려져 도 문제 가 없 는지 ? 문제 가 없 다면 왜 문제 가 없 는지 17 ) 상관 관계 란 무엇 이 고 , 두 자산 군 의 상관 관계 는 어떻게 알 수 있 는지 18 ) 올 웨더 의 연평균 기대 수익 률 과 그 이유 , 연평균 변동 성 과 그 이유 19 ) 산술 평균 과 기하 평균 의 차이 20 ) 원화 기준 으로 수익 률 을 계산 할 때 기대 수익 률 과 변동성 이 어떻게 달라지 는지 21 ) 올 웨 더 투자자 들 이 가장 행복 한 해 는 어떤 특징 이 있 는지 22 ) 달러 / 원 환율 의 1970 년 대 부터 대략 어떻게 움직여왔 는지 . 23 ) 왜 올 웨더 와 risk parity 전략 에서 는 장기채 를 쓰 는지 24 ) 50 퍼센트 손해 가 나 면 몇 퍼센트 이득 이 나 야 원금 회복 이 가능 한지 25 ) 미국 주식 최악 의 시기 와 원금 회복 하 는 데 까지 걸리 는 기간 26 ) 한국 주식 최악 의 시기 와 원금 회복 하 는 데 까지 걸리 는 기간 ( 원화 기준 , 달러화 기준 ) 27 ) 평균 과 표준편차 의 개념 에 대해 이해 하 고 있 다 . 28 ) 환율 적용 해서 백 테스트 는 어떻게 하 는지 29 ) 올 웨더 는 언제 팔 아야 하 는지 30 ) 리 밸 런 싱 은 어떤 주기 로 해야 하 는지 31 ) 백 테스트 는 왜 1970 년 대 가 들어가 야 하 는지 32 ) 왜 중앙은행 은 인플레이션 이 올라가 면 금리 를 인상 하 는지 33 ) 양 적 완화 란 무엇 인지 . 왜 하 는지 . 34 ) 4 개 의 박스 ( 성장 이 기대 보다 높 을 때 / 낮 을 때 / 인플레이션 이 기대 보다 높 을 때 / 낮 을 때 ) 에 어떤 자산 들 이 들어가 는지 그 이유 35 ) 주식 과 채권 의 상관 관계 는 어떤지 \\u200b',\n",
       "       '※ 이 글 에서 해킹 대상 으로 하 는 안드로이드 어플리케이션 은 제 가 개발 한 어플리케이션 이 고 , 정상 적 으로 작동 하 고 있 는 고유 한 서버 가 존재 합니다 . 따라서 오직 공부 목적 으로 제한 적 으로 해킹 을 시도 하 시 는 것 만 용납 합니다 . 서버 에 트래픽 공격 , 악의 적 목적 이 다분 한 공격 을 하 시 면 저 와 경찰서 에서 만나 실 수 도 있 습니다 . ※ 자신 이 특정 한 어플리케이션 의 apk 파일 을 가지 고 있 다면 이것 을 실제 자바 ( java ) 소스 코드 형태 로 보 기 위해서 는 디 컴파일 과정 이 수반 되 어야 합니다 . 디 컴파일 ( decompile ) 이란 쉽 게 말 하 면 클래스 ( class ) 형태 의 파일 을 다시 원래 의 소스 코드 형태 인 자바 ( java ) 형식 의 파일 로 바꾸 어 주 는 것 입니다 . 특히 코드 난독 화 ( code obfuscation ) 가 이루어지 지 않 은 클래스 ( class ) 파일 의 경우 에 는 사실상 거의 특정 한 어플리케이션 을 그대로 복원 할 수 있 을 정도 로 디 컴파일 은 강력 합니다 . 저 는 이러 한 과정 에서 대표 적 인 자바 디 컴파일러 인 jadx 를 소개 하 고자 합니다 . 제 가 아 는 자바 디 컴파일러 중 에서 는 가장 사용 하 기 도 간편 하 고 상당히 기능 도 강력 한 편 입니다 . 특히 apk 파일 을 다른 변환 과정 없이 즉시 자바 소스 코드 형태 로 디 컴파일 할 수 있 다는 점 에서 몹시 간단 합니다 . jadx 최신 버전 다운로드 : [ URL ]',\n",
       "       \"안녕 하 세요 ! 오늘 소개 할 음식 은 바나나 머핀 입니다 : ) 가장 처음 베 이킹 을 시작 했 을 때 가장 많이 구워 먹 었 던 게 바나나 머핀 인데 , 사 먹 는 것 도 맛있 지만 집 에서 해 먹 는 건 더 맛있 어요 ! 만들 기 도 쉽 고 재료 들 도 흔해서 베 이킹 초보 자 들 한테 도 딱 이 고요 바나나 자체 가 버터 를 대체 할 때 사용 되 기 도 하 는데 , 그래서인지 기름 도 비교 적 적 게 들어가 는 레시피 입니다 : ) ( 굳이 말 하 면 ' 노 버터 ' 레시피 임 ! ) 그럼 레시피 시작 ! 바나나 머핀 바나나 머핀 방법 : 베이 킹 시간 : 1 시간 ~ 1 시간 30 분 머핀 10 ~ 12 개 분량 바나나 머핀 재료 계량 중력분 1 - 1 / 2 c 베이 킹 소다 1 tsp 베이 킹 파우더 1 tsp 소금 1 / 2 tsp 시나몬 파우더 / 계핏가루 1 tsp 백설탕 1 / 2 c 갈색 설탕 1 / 4 c 바나나 , 으깨 서 준비 3 ~ 4 개 ( 약 1 - 1 / 2 c ) 계란 1 개 식용유 1 / 3 c 바닐라 추출 액 1 - 1 / 2 tsp 크 럼 토핑 ( crumb topping ) * * 달 게 드 시 기 싫 으신 분 들 은 제외 해 주 세요 . 재료 계량 갈색 설탕 1 / 3 c 중력분 2 tbsp 시나몬 파우더 / 계피 가루 1 / 2 tsp 무염 버터 , 실온 에 꺼내 서 준비 * 1 tbsp ( 14 g ) * 가염 버터 로 대체 가능 인용 레시피 : [ URL ] 1 머핀 팬 은 유산지 를 깔 아서 준비 해 주 시 고 , 바나나 는 으깨 서 준비 해 주 세요 . 2 믹 싱 볼 에 빨간 배 경색 의 재료 들 을 한번 체 에 친 후 잘 섞 어 주 세요 . 설탕 은 체 에 잘 안 쳐질 수 도 있 는데 , 큰 덩어리 가 있 다면 으깨 주 시 기 만 하 면 됩니다 . 3 다른 믹 싱 볼 에 파란 배 경색 의 재료 들 을 잘 섞 어 주 세요 . 4 빨간 배 경색 의 재료 들 과 파란 배 경색 의 재료 들 을 낱 밀가루 가 보이 지 않 을 정도 로 만 섞 어 주 세요 . 이때 마른 재료 ( 빨간색 ) 와 젖 은 재료 ( 파란색 ) 를 따로 섞 은 후 혼합 하 는 이유 는 오버 믹 싱 함 으로써 글루텐 이 잡히 는 걸 방지 하 기 위함입니다 . 5 아이스크림 스쿱 으로 준비 된 반죽 을 유산지 안 에 넣 어 주 세요 . 6 크 럼 토핑 을 사용 하 실 분 들 은 모든 재료 들 을 잘 섞 은 후 , 유산지 에 넣 은 반죽 위 에 잘 배분 해 주 세요 ( 달 게 드 시 고 싶 지 않 으신 분 들 은 제외 해 주 세요 ! ) 7 190 도 에 예열 한 오븐 에서 18 ~ 20 분 동안 구워 주 세요 . 이쑤시개 / 젓가락 으로 찔러 보 았 을 때 반죽 이 묻 어 나오 지 않 는다면 완성 된 거 랍니다 : )! 이 레시피 는 정말 간단 한 레시피 예요 ! 마른 재료 들 은 마른 재료 들 끼리 한번 체 에 쳐서 준비 해 주 고 , 젖 은 재료 들 은 젖 은 재료 들 끼리 잘 섞 어서 준비 하 시 면 돼요 : ) 그런 다음 마른 재료 와 젖 은 재료 들 을 혼합 해 주 시 면 되 는데 , 글루텐 이 잡히 면 안 되 니 낱 밀가루 가 보이 지 않 을 정도 로 만 섞 어 주 세요 : ) 이렇게 마른 재료 와 젖 은 재료 들 을 각각 섞 은 후 혼합 하 는 이유 도 글루텐 이 잡히 는 것 을 방지 하 기 위함 이 예요 ! 준비 된 반죽 은 유산지 를 깔 아 놓 은 머핀 팬 에 배분 해 주 시 면 되 는데 , 저 는 아이스크림 스쿱 으로 했 더니 11 개 나왔 어요 ~_~ 그런 다음 에 달 게 드 시 고 싶 으신 분 들 은 위 에 올릴 크 럼 토핑 을 준비 해서 얹 어 주 세요 ! 전 개인 적 으로 단 걸 좋 아 하 는 편 이 긴 한데 , 재료 들 을 소보 루 만들 때 처럼 골고루 안 섞 어서 그런지 씹히 는 맛 이 있 어서 별로 였 어요 ㅜ 그래서 다음 에 바나나 머핀 할 때 는 토핑 없이 하 려고 하 는데 혹시 단 걸 싫 어 하 시 거나 씹히 는 맛 을 싫어하 시 는 분 들 은 참고 하 세용 : d 토핑 을 소 보루 로 대체 하 고 싶 으신 분 들 은 제 가 전 에 올린 소보 루 포스트 확인 하 세요 ▶▶ [ URL ] 이렇게 크 럼 토핑 까지 얹 은 후 예열 한 오븐 에서 구워 주 시 면 190 도 에서 20 ~ 22 분 완성 ! 전 유산지 가 하나 남 아서 강아지 쿠키 도 하나 구웠 어요 ㅋㅋㅋ 제 가 바나나 머핀 준비 하 는 동안 언니 가 개 들 과자 만들 고 있 었 거든요 ! ( 내내 바나나 를 주 재료 로 함 ) 아래 는 다 구워진 머핀 이 에요 ! 구워진 머핀 은 바로 식 힘 망 에 옮기 지 마시 고 , 약 3 ~ 5 분 동안 휴지 시킨 뒤 식 힘 망 으로 옮겨 주 시 면 모양 이 덜 망가지 고 좋 아요 ! 너무 오랫동안 머핀 틀 에 놔둘 경우 물 이 찰 수 도 있 으니 되 도록 이 면 물 이 생기 기 전 에 식 힘 망 으로 옮겨서 완전히 식혀 주 세요 : ) 이렇게 구운 머핀 은 식 힘 망 에서 식힌 후 냉장 보관 하 시 거나 밀폐 용기 에 담 아서 실온 에서 2 일 까지 보관 가능 합니다 : ) 버터 가 들어간 머핀 들 은 냉장고 안 에 들어가 면 딱딱 해져서 별론데 , 이 레시피 는 식용유 를 사용 해서 냉장 보관 해도 부드러워서 좋 아요 : ) 맛 도 위 에 토핑 이 없 다는 걸 가장 하 면 달 지 도 않 아서 아침 에 먹 기 딱 좋 고요 ( 토핑 있 으면 좀 단 편 인데 , 막 엄청 단 편 은 아니 에요 . 아침 에 드실 분 들 은 토핑 빼 주 시 고 , 간식 으로 드 시 거나 커피 랑 드 시 고 싶 으신 분 들 은 토핑 이랑 해 주 시 면 될 거 예요 ) 집 에 오래 된 바나나 가 있 다면 꼭 한번 시도 해 보 세요 : ) 참고 로 위 에서 언급 한 강아지 쿠키 레시피 가 궁금 하 신 분 들 은 링크 클릭 하 세요 ▶▶ [ URL ] 4 월 에 올린 거 라 사진 도 아직 핸드폰 카메라 고 말투 도 지금 이랑 다르 지만 저희 집 개 들 은 정말 좋 아 해요 ! ( 특히 우리 집 검 은 소시지 할망구 ㅋㅋㅋ ) 그럼 포스트 끝 ! 위 의 토핑 없이 구워 봤 어요 레시피 의 1 . 5 배 해서 12 개 로 배분 해서 구웠 는데 , 저 는 그렇 게 한 게 크기 가 딱 좋 더라고요 참고 하 세용 : )\",\n",
       "       \"d . arima 모형 arima 모형 은 autoregressive integrated moving average 라는 뜻 으로 , arma 모형 이 과거 의 데이터 들 을 사용 하 는 것 에 반해 arima 모형 은 이것 을 넘어서 서 과거 의 데이터 가 지니 고 있 던 ' 추세 ( momentum ) ' 까지 반영 하 게 된다 . 즉 , correlation 뿐 아니 라 cointegration 까지 고려 한 모델 이 다 . cointegration 은 correlation 보다 설명 하 기 가 더 어려운데 , 가장 단순 하 게 설명 하 자고 하 면 correlation 은 서로 간 에 선형 관계 를 설명 하 는 것 이 라면 cointegration 은 추세 관계 를 설명 한다 , 즉 cointegration 인 시점 이 고려 되 지 않 으면 성립 하 지 않 기 때문 에 시계열 데이터 에 만 쓰이 는 개념 이 다 . 선형 관계 두 변수 x - y 간 에 correlation 이 0 보다 크 면 x 가 큰 값 이 나올 때 y 값 도 큰 값 을 가진다 . 두 변수 x - y 간 에 correlation 이 0 보다 작 으면 x 가 큰 값 이 나올 때 y 값 은 작 은 갑 을 가진다 . 추세 관계 두 변수 x - y 간 에 cointegration 이 0 보다 크 면 x 의 값 이 이전 값 보다 증가 하 면 y 값 도 증가 한다 . 두 변수 x - y 간 에 cointegration 이 0 보다 작 으면 x 의 값 이 이전 값 보다 증가 하 면 y 값 은 감소 한다 . < 추가 적 인 example > 만약 correlation 이 0 보다 작 고 cointegration 은 0 보다 큰 관계 라면 , x 가 큰 값 이 며 증가 하 는 추세 에 있 는 경우 y 는 현재 작 은 값 이나 빠르 게 증가 하 는 추세 로 반응 하 게 된다 . 만약 correlation 이 0 보다 크 고 cointegration 은 0 보다 작 은 관계 라면 , x 가 큰 값 이 며 증가 하 는 추세 에 있 는 경우 y 는 현재 큰 값 이나 빠르 게 감소 하 는 추세 로 반응 하 게 된다 . correlation 과 cointegration 의 개념 이 다소 혼란 스럽 겠 지만 , 간단히 현재 의 관계 와 추세 의 관계 라는 요소 로 분리 해서 생각 하 다 보 면 아주 어렵 게 이해 되 진 않 으리라 생각 한다 . 어쨋든 , arima 모형 은 추세 또한 고려 할 수 있 기 때문 에 momentum 을 중요 하 게 보 는 분석가 들 에게 아주 유용 하 다 . note : arima 모델 은 자기 자신 의 추세 만 고려 한다 . white noise 의 추세 는 고려 하 지 않 는다 . 올바른 모델 의 white noise 는 추세 가 존재 하 면 안 되 기 때문 이 다 . 즉 , autoregressive 는 자기 자신 의 correlation 을 말 하 는 것 이 고 integrated 모델 은 자기 자신 의 cointegration 을 말 하 는 것 이 다 . 결론 적 으로 , 가장 단순 한 형태 인 arima ( 1 , 1 , 1 ) 모형 은 아래 와 같 다 . a *{ x ( t ) - x ( t - 1 ) }={ b * x ( t - 1 ) }+{ c * e ( t - 1 ) }+ d + u * e ( t ) 즉 x 의 추세 는 이전 x 의 값 과 이전 의 white noise 의 결과 의 영향 을 받 게 된다는 뜻 이 다 . 식 을 조금 다르 게 전개 하 면 아래 와 같 은 형태 가 된다 . x ( t ) =[ x ( t - 1 ) +{ b * x ( t - 1 ) }+{ c * e ( t - 1 ) }+ d + u * e ( t ) ] / a 그런데 이 모형 은 자세히 보 면 arma ( 1 , 1 ) 과 다를 바 가 없 다 . 그래서 arima ( 1 , 1 , 1 ) 은 사실상 쓰이 지 않 는다 . 그러 니 더 복잡 한 모델 인 arima ( 1 , 2 , 1 ) 를 소개 하 도록 하 겠 다 . a *[{ x ( t ) - x ( t - 1 ) }-{ x ( t - 1 ) - x ( t - 2 ) }]={ b * x ( t - 1 ) }+{ c * e ( t - 1 ) }+ d + u * e ( t ) 이 는 x 를 2 차 미분 한 값 에 대한 모델 이 다 . 추세 의 추세 . .. 라는 표현 은 좀 이상 하 고 , 데이터 가 확실 하 게 모 멘 텀 성향 을 지닌다고 가정 했 을 때 모 멘 텀 의 변화 를 모델링 한 것 이 라고 보 는 것 이 맞 겠 다 . 즉 이 모델 은 모 멘 텀 의 변화 는 x 의 이전 값 과 이전 에 발생 한 white noise 에 의해 결정 된다는 것 을 표현 한 것 이 다 . 마찬가지 로 x ( t ) 에 대해서 만 전개 하 면 아래 와 같 은 수식 이 되 며 , 이 는 사실 arma ( 2 , 1 ) 과 매우 유사 하 다 . x ( t ) =( 2 + b / a ) * x ( t - 1 ) + x ( t - 2 ) +( c / a ) * e ( t - 1 ) +( d / a ) +( u / a ) * e ( t ) 수식 을 보 면서 조금 답답 함 을 느 꼇 을 것 이 고 , arma 모델 과 많이 비슷 하 다는 생각 도 했 을 것 이 다 . 많 은 학자 들 도 비슷 하 게 생각 하 기 때문 에 arima 모델 을 선호 하 지 않 고 arma 모델 만 택하 는 경우 도 많 으며 , 필자 또한 arima 모델 을 선호 하 지 않 는다 . 특히 추세 의 일관 성 이나 유의미 성 이 크 지 않 은 데이터 의 경우 arima 모형 은 arma 모형 보다 모델 의 타당 성 이 떨어지 기 도 하 다는 점 에서 arima 모델 을 도입 하 는 경우 가 그리 흔하 게 발견 되 지 는 않 는 것 같 다 . 이번 편 에서 수식 이 자주 등장 해서 독자 들 이 흥미 를 잃 지 않 았 을까 고민 이 되 지만 다음 편 에서 는 보다 실용 적 인 내용 인 , ' 우수 한 모델 을 발굴 하 는 방법 ' 을 직관 적 인 그림 들 을 통해 설명 하 도록 하 겠 다 . written by 푸른 생선\",\n",
       "       '궁극 의 라구 볼 로 네 제 를 만들 어 보 자 - 1 시중 에 흔한 음식 인데 , 특별 한 맛 을 내 는 식당 들 이 있 다 . 방송 에서 는 pd 들 이 집요 하 게 그 들 만 의 레시피 를 알 아 내 려고 쫓 아 다니 는 맛집 들 . \" 저 맛 의 비밀 은 뭘까 ? \" 궁금 해 하 는 시청자 들 의 걷잡 을 수 없 는 호기심 이 높 은 시청 률 로 연결 되 기 때문 인데 , 그렇게 쥔장 이나 요리사 들 을 쫓아다니 다 보 면 별별 재료 와 방법 들 이 다 쏟아져 나온다 . 나 만 의 소스 레시피 에 , 기기묘묘 한 숙성 법 , 수십 가지 의 한약재 를 첨가 해서 탕약 을 방불 케 하 는 국물 에 때로 는 황당 스러운 재료 들 까지 출현 을 하 는 데 그러 다 보 면 , 생뚱맞 게 이런 경우 를 만나 기 도 하 고 . ..... 쉐프 들 의 자존심 혹은 로망 은 \" 재료 만 좋 으면 별다른 양념 이 필요 없 습니다 . 헛헛헛 ! \" 이지만 , 실제로 는 한구석 버젓이 쌓 아 놓 고 못 치운 다시 다 , 미원 , 온갖 조미료 . ............... ㅎㅎㅎ 하지만 , 다른 방향 에서 접근 한 조리 방법 의 차이 나 , 구석구석 쌓인 디테일 때문 에 완전히 다른 맛 을 내 는 요리 도 있 다 . 아무리 맛 을 보 고 , 들여다 봐도 특별 한 재료 는 눈 에 뜨이 지 않 는데 도대체 어떻게 이런 맛 이 ? 무릎 을 탁 치 게 만드 는 솜씨 와 함께 요리 는 이래야 하 지 않 을까 싶 은 절묘 한 맛 . 바로 오늘 의 주제 라고 하 겠 다 . 쿠 킹 을 시작 하 기 전 에 , 음식 의 오리지널 한 맛 을 이해 한다는 것 은 어떤 의미 일까 ? 잠깐 생각 해 보 면 , 이영돈 pd 의 먹거리 x 파일 , \" 냉면 육수 의 비결 \" 편 을 보 다가 이런 생각 이 들 었 다 . 사진 은 방송 중 에 출현 해서 , 쇠고기 맛 조미료 , 설탕 , 식초 로 만 만들 어 진 \" 화학 적 냉면 육수 \" 를 맛보 는 조리 학과 학생 들 분노 에 찬 혹평 을 기대 하 고 싶 겠 지만 , 실망 스럽 게 도 대답 은 ? \" 시원 하 고 , 맛있 는데요 . \" 였 단다 . 하지만 , 나 는 이 친구 들 의 입맛 이 나빠서 맛 을 구별 하 지 못했 다고 생각 하 지 는 않 는다 . 내 생각 에 는 오히려 평소 의 학습 효과 때문 이 라고 보 는데 . 무슨 말 이 냐 하 면 , 평소 에 전통 적 인 맛 의 냉면 을 맛보 고 , 경험 해 왔 다면 이렇게 대답 하 지 않 았 을 거 라는 말 이 다 . 바로 , 오리지널 한 맛 을 이해 하 고 못하 고 의 차이 인데 . 내 가 무슨 식신 ( 食神 ) 의 혓바닥 을 가지 고 있 어서 , 요리 에 첨가 된 티끌 만큼 의 조미료 를 대뜸 감지 하 고 , 수저 를 던지 며 일갈 을 하 는 사람 은 아니 지만 . 이북 출신 의 부모 님 을 따라 오랫동안 평양냉면 을 섭렵 한 결과 , 냉면 은 이래야 한다는 기준 을 이해 하 고는 있 다 . 냉면 을 맹렬히 사랑 하 는 이북 출신 들 과 그 들 로 인해서 냉면 을 이해 하 게 된 남쪽 의 추종 자 들 ? 사이 에 이루어진 암묵 적 동의 에 의하 면 . . . . . . . ......................... ㅋ 냉면 육수 는 담백 하 면서 도 깊이 가 있 고 , 육수 와 섞 은 동치미 국물 에서 자연 스럽 게 느껴 지 는 산미 , 그 이상 의 과도 한 신맛 이 범접 해서 는 안 되 며 , 면발 은 메밀 함량 이 높 아 툭툭 끊기 면서 도 향 이 좋 고 구수 해야 하 고 , 육수 의 온도 는 입안 을 시원 하 게 할 정도 에서 그쳐야 담백 하 고 순한 맛 들 을 놓치 지 않 을 수 있 고 , 식초 나 겨자 는 가급적 섞 지 말 아야 순수 한 맛 의 냉면 을 즐길 수 있 다고 들 생각 하 는데 . .......... 본인 들 은 어떠 신지 ? 이 기준 에 맞추 면 대충 이런 비주얼 의 냉면 이 탄생 을 하 는 데 어릴 적 많이 먹 었 던 평양 면옥 , 을지 면옥 등 이 내게는 냉면 의 기준 이 다 . 하지만 , 이런 냉면 들 을 신 세대 ? 에게 맛 을 보이 면 공통 적 으로 반응 하 는 소감 은 \" 심심 하 다 \" 는 것 이 란다 . 즉 , 입맛 의 기준 이 \" 새콤 , 달콤 , 짭짤 , 목 젓 까지 시원 \" 에 맞춰져 있 다는 말 이 다 . 그래서 이 분 들 의 기준 에 맞춘 냉면 의 비주얼 은 대충 이렇게 나오 게 되 어 있 다 . 어으 ~ 보 기 만 해도 시원 한 게 군침 이 돈다 돌 아 . ㅎㅎ 이 냉면 에 비하 면 윗 쪽 사진 의 비주얼 은 양념 을 하 다가 만 수준 이 라고 해야 하나 ? 하지만 , 슬프 게 도 윗 쪽 의 냉면 을 만드 는 데 드 는 공력 은 절대로 만만 치가 않 고 , 손님 들 의 기호 는 점점 아랫 쪽 으로 몰려가 고 있 으니 이런 이유 때문 에 만들 기 쉽 고 , 입 에 쩍쩍 달라 붙 는 조미료 냉면 국물 이 새로운 냉면 의 판단 기준 이 됐 다는 결론 이 다 . 그러 니 , 슬퍼할 것 없 다 . 분노 할 것 도 없 다 . 세상만사 가 이렇게 발전 하 는 것 이 니 말 이 다 . ( 정치 도 마찬가지 , 뭔 짓 을 해도 지지율 고공 행진 에 는 두 손 두 발 다 들 었 다 . 누구 탓 이 아니 다 . 트렌드 고 대세 라니까 ) 그리고 , 불행 하 게 도 한식 전체 가 이런 트렌드 를 따라가 고 있 지 않 나 하 는 생각 까지 드 는데 . 조금 더 나가 면 또 다시 한식 예찬 론 자 들 의 돌팔매 가 시작 될 것 이 므로 오늘 은 여기 까지 하 고 . ( 요즘 많이 묵 었 어 ~ ㅋㅋ ) 그러 면 , 먼저 과연 오리지널 한 라구 볼 로 네 제 의 맛 은 무엇 일까 ? 라구 볼 로 네 제 에서 어떤 맛 을 느낄 수 있 어야 전통 적 인 맛 에 가깝 고 , 잘 만든 소스 라고 인정 을 할 수 있 는 것 일까 ? 예전 에 \" 세 시간 쿡 하 는 볼 로 네 제 소스 - [ URL ] \" 라는 포스팅 을 올린 적 이 있 다 . 이 포스팅 이 일반 적 인 버전 의 볼 로 네 제 소스 만들 기 라면 오늘 은 고급 반 볼 로 네 제 소스 를 만들 어 보 자 . 재료 - 간단 하 다 . 도구 - 특별 한 것 필요 없 다 . 하지만 , 마냥 쉽 지 많 은 않 으니 , 어느 정도 요리 를 이해 하 는 분 들 이 도전 하 기 바란다 . 그래서 이 레시피 를 제대로 따라 할 수 있 으면 깜놀 한 맛 보증 한다 . 이후 에 는 나름 잘 한다고 소문난 식당 의 볼 로 네 제 파스타 를 먹 으며 슬며시 미소 지 을 수 있 다 . \" 이 정도 가지 고 ~ 헛헛 허 \" 우선 , 볼 로 네 제 는 미트 소스 라는 것 을 이해 해야 한다 . 무슨 말 이 냐 하 면 , 고기 맛 의 소스 라는 말 인데 , 요점 은 다른 재료 들 이 고기 의 맛 과 밸런스 를 맞추 고 보조 하 는 역할 에 그쳐야 한다는 것 이 다 . 그러니까 , 과다 한 야채 나 휘 핑 크림 , 다량 의 토마토소스 나 부 재료 들 은 모두 불 필요 하 고 , 언제나 그렇 듯이 적절 한 밸런스 가 이 요리 의 관건 이 라고 할 수 있 는데 . 그렇게 완성 된 소스 에서 는 부드럽 고 실 키 ( silky ) 하 지만 리치 한 육향 과 맛 , 그리고 알 덴 테 한 파스타 의 조합 이 완벽 해야 한다 . 궁금 하 쥐 ? 시작 해 보 자 . 참고 로 이 레시피 는 내 가 좋 아 하 는 뚱뚱 이 쉐프 마리오 바탈리 ( mario batali ) 의 볼 로 네 제 만드 는 방법 에 몇 가지 레시피 를 더한 것 이 니 참고 하 시 고 . 먼저 재료 는 고기 세 종류 소고기 ( beef chuck ) 2 파운드 , 돼지고기 1 파운드 , 송아지 고기 1 파운드 의 비율 이 다 . 안다 알 아 . 한국 에서 송아지 고기 구하 기 힘들 다매 . 그러면 쇠고기 70 %, 돼지고기 30 % 의 비율 로 고기 를 갈 아 오 시 면 되 는데 고기 를 가급적 잘 게 갈 아 주 시 고 ( 정육점 아저씨 와 친하 게 지내 는 일 은 당신 인생 을 좀 더 즐겁 게 만드 니 참고 하 시 고 ) 이렇게 고기 를 펼쳐 놓 는다 . 이유 는 ? 차가운 고기 의 온도 를 상온 에 가깝 게 올려서 , 볶 을 때 팬 이나 냄비 의 온도 가 떨어지 지 않 도록 하 는 것 인데 이걸 무시 하 면 ? 물 ( 육즙 ) 질질 나오 고 . ...... 개판 된다 . 깨알 같 은 디테일 을 얘기 할 때 는 무지 중요 하 기 때문 이 라는 걸 알 아 주 면 정말 좋 겠 다 . 양파 , 샐러리 , 당근 , 토마토 페이스트 , 드라이 와인 , 마늘 , 우유 , 소금 , 후추 와 약간 의 허브 끝 . 그리고 , 야채 들 이 많이 널려 있 지만 다른 요리 에 사용 할 재료 들 이 고 , 이 소스 에 는 딱 한 개 나 두 개 밖에 는 안 들어간다 . 샐러리 는 두 줄기 ( 그렇 다 2 줄기 만 ) 를 가능 한 한 가늘 게 썰 어서 아주 조그맣 게 사각형 으로 자른다 . 왼쪽 은 다른 요리 의 재료 니 신경 끄 고 , 오른쪽 사이즈 로 쬐끄맣 게 양파 2 개 ( 중간 사이즈 의 양파 ) . 역시 아주 아주 조그맣 게 자르 고 , 오른쪽 조금 보이 는 재료 는 한번 더 신경 끄 시 고 , 당근 1 개 . 역시 아주 작 게 , 세 가지 야채 가 거의 균일 한 크기 가 되 도록 죽 어 라고 자른다 . 세 가지 야채 를 자르 고 나 면 이미 시간 은 3 - 40 분 훌쩍 지났 을 거 다 . 그것 도 왠 만큼 칼질 이 능숙 한 사람 얘기 고 , 칼질 에 서툰 사람 은 1 시간 쯤 낑낑 거려 야 할 것 같 다 . 그렇 다고 뭉텅뭉텅 자르 면 ? 역시 소스 가 개판 되 니 , 적당히 넘어갈 생각 하 지 말 고 . 마늘 4 - 5 개 쯤 다져서 준비 하 고 냄비 가 중요 하 다 . 두툼 하 고 , 논 스틱 주철 냄비 를 가지 고 있 으면 아주 제대로 길 이 들 어 있 어야 하 고 , 없 으면 다시 한번 두툼 하 고 논 스틱 처리 된 냄비 가 필수 적 이 다 . 그러 니 술 쳐 마실 ? 돈 다시 한 번 아껴서 . .......... ㅋㅋㅋ 미트볼 레시피 를 올리 면서 크루제 냄비 같 은 두툼 , 논 스틱 이 좋 다고 했 더니 어떤 분 댓글 에 하 는 말 이 요즘 포스팅 이 식품 회사 홍보 직원 같 단다 . ㅋ 기 가 막혀서 . 미국 에서 내 가 한국어 로 네이버 에 포스팅 올리 는데 식품 회사 , 냄비 회사 에서 협찬 해 줄 것 같 나 보 지 ? 그리고 , 돈 몇 푼 받 고 무슨 제품 홍보 할 생각 없 고 , 그렇게 궁하 지 는 않 으니 제발 이런 댓글 은 쓰 지 않 으면 좋 겠 다 . 하지만 , 냄비 는 아직 도 중요 하 다 . ㅋ 이 냄비 는 스타웁 ( staub ) , 9 쿼트 ( 대충 2 . 3 갤 론 ) 빅 사이즈 . 크루제 하고 경쟁사 제품 한 번 씩 올렸으니 됐 쥐 ? 그리고 , 이 냄비 는 눈독 들 이 다가 진짜 로 술 쳐 마실 돈 을 아껴서 , 그것 도 세일 할 때 샀 으니 그러 면 진짜 됐 쥐 ? 냄비 를 달군 후 에 올리브 오일 왕창 , 버터 왕창 ( 1 / 4 파운드 나 한 스틱 정도 ) 넣 고 녹인다 . 스타웁 제품 이 크루제 와 다른 부분 은 무광 에나멜 코팅 과 뚜껑 의 디자인 인데 뚜껑 전체 에 일정 하 게 돌기 가 만들 어 져 있 다 . 이게 무슨 역할 을 하 는가 하 면 냄비 에서 재료 를 끓일 때 증발 하 는 액체 가 뚜껑 에 맺힌 뒤 , 이 돌기 를 따라서 냄비 전체 로 골고루 다시 떨어지 는데 , 말 하 자면 basting ( 육즙 이나 수분 을 골고루 끼얹 는 ) 하 는 효과 가 있 다 . 홍보 아니 고 , 참고 하 라고 . ...... ㅋ 버터 가 다 녹 았 으면 야채 를 전부 같이 넣 고 마늘 다진 것 도 넣 고 볶 기 시작 한다 . 가정 용 스토브 는 화력 이 약하 니 계속 강한 불로 볶 아 주 면 된다 . 물론 재료 가 적 으면 중간 불 에서 강 불로 조절 하 며 익혀 주 고 소금 과 후추 로 밑간 을 하 고 대충 20 분 정도 볶 으면 되 는데 요령 은 이렇 다 . 바닥 까지 잘 섞 고 , 저 어 주 면서 눌어붙 거나 타 지 않 게 , 야채 의 수분 은 대부분 증발 을 시키 지만 , 절대로 갈색 으로 브라우닝 시키 지 말 고 . 그리고 , 재료 들 이 충분히 볶 아 져서 부드러운 상태 가 되 도록 하 려면 20 분 쯤 볶 아야 할 거 다 . 스페인 과 이태리 에서 는 이렇게 볶 아 진 야채 나 밑 재료 를 소 프리 또 ( soffritto ) 라고 부르 는데 , 프랑스 에서 는 미 레프 와 ( mirepoix ) , 미국 의 케 준 ( cajun ) 쿠 킹 에서 는 홀리 트리니티 ( holy trinity ) 등등 으로 부른다 . 음 . ........ 이건 그냥 참 고 사항 . ^^ 이제 는 고기 전부 다 넣 고 강한 불로 볶 아 준다 . 끊임없이 바닥 까지 긁 어서 섞 고 , 저 어 주 면서 고기 가 뭉치 지 않 도록 잘 게 부수 고 , 소금 과 후추 로 넉넉히 간 을 한 다음 야채 와 잘 섞 어 준다 . ** 중요 한 것 은 야채 를 볶 을 때 , 고기 를 볶 을 때 각각 소금 , 후추 로 밑간 을 해서 쿠 킹 하 는 동안 전체 적 으로 간 이 배 도록 만드 는 것 이 다 . 그리고 , 완성 되 기 직전 마지막 으로 간 을 한번 더 하 면 완성 이렇게 센불 로 볶 다 보 면 처음 에 는 육즙 이 흥건 하 게 나온다 . 계속 볶 는다 . 얼마나 오래 ? 1 시간 정도 볶 아야 원 하 는 시점 이 되 니 참고 하 시 고 . 이제 부터 중요 한 시점 . 수분 이 대부분 증발 하 고 , 고기 에서 지방 이 흘러 나오 면서 분리 가 되 는데 한쪽 에 모인 지방 이 끓 기 시작 하 는 것 이 보일 것 이 다 . 계속 볶 아 . 언제 까지 ? 아래 의 사진 과 같이 almost crispy , 바삭 한 상태 가 되도록 . 이 정도 시점 이 되 면 냄비 에서 지방 이 끓 으면서 고기 가 튀 는 소리 를 들 을 수 있 다 . \\' 탁탁 \\' 하 는 소리 가 들리 면 ( 정말 잘 들리 니 인내 를 가지 고 저 어 주 세용 ~) 완성 되 는 시점 이 다가왔 다는 신호 다 . 이게 말 은 쉬운 데 1 시간 30 분 정도 끝없이 재료 를 볶 다 보 면 다리 도 아프 고 , 허리 도 아플 뿐 더러 자칫 하 면 냄비 바닥 에 재료 가 눌어붙 게 되 는 데 눌어붙 어서 타 기 시작 하 는 순간 훌륭 한 볼 로 네 제 소스 는 물 건너가 니 쫌 만 인내 를 가지 시 라 다시 한 번 정리 하 면 , 바닥 에 눌어붙 지 않 도록 바닥 전체 를 긁 듯이 저 어 주 면서 , 타 지 않 도록 , 바삭 하 게 , 색깔 은 이 정도 의 갈색 이 나올 때 까지 ( 탁탁 하 는 소리 를 잊 지 마시 고 ) 지방 에 고기 가 튀 는 시점 을 지나 고 도 5 - 10 분 가량 은 더 볶 아야 한다 . 그리고 첨가 하 는 토마토 페이스트 , 170 그램 짜리 작 은 캔 하나 . 이제 좀 더 어렵 고 중요 한 시점 이 왔 는데 토마토 페이스트 ( 토마토 퓨레 나 생 토마토 등 은 일체 들어가 지 않 으니 기억 하 시 고 ) 6 온스 ( 170 그램 ) 짜리 작 은 것 한 통 넣 는다 . 토마토 맛 은 이게 전부 다 . 다시 한 번 토마토 맛 은 보조 역할 타 지 않 도록 개스 불은 중 불 정도 로 낮추 고 그리고 , 고기 와 함께 바닥 의 지방 까지 전부 섞이 도록 저으 면서 볶 는다 . 토마토 페이스트 가 들어가 면 더 잘 눌 어 붙 으니 극히 조심 을 하 면서 볶 아야 하 는데 분리 된 지방 과 고기 , 야채 와 함께 토마토 페이스트 가 섞이 면서 볶 아 지 는 향기 는 정말 매력 적 이 다 . 이 재료 들 이 토마토 페이스트 와 완벽히 결합 해서 볶 아 진 어느 시점 에 는 러스틱 하 면서 강렬 한 향기 를 맡 을 수 있 는 데 그러 면 , 이제 고난 의 행군 은 끝 나가 고 있 고 , 어려웠 던 시간 은 거의 지나가 고 있 다는 말 이 다 . 인생 도 이래야 하 는데 말 이 지 . 나이 가 들 면서 는 고생 한 보람 이 있 게 점점 생활 이 안정 되 어 가 고 , 은퇴 할 시점 에서 는 먹 고 살 걱정 , 자녀 들 걱정 에서 한시름 놓 을 수 있 는 순간 이 자연 스럽 게 다가 와야 하 는데 현실 은 ? 명퇴 하 고 , 남 은 돈 탈탈 털 어서 치킨 집 ? 이건 분명히 사회 시스템 의 문제 가 있 다는 말 이 니까 기억 하 시 기 를 , 인생 은 나 의 의지 와 관계 없이 진행 이 되 는 경우 가 많 지만 , 별 생각 없 던 나 의 선택 이 자녀 들 의 먼 미래 까지 좌우 하 니 한번 더 내 선택 을 돌 아 보 시 고 . 이게 목표 로 하 는 색깔 이 다 . 절대로 태우 면 안 되 고 , 쓰 거나 탄 맛 이 나 면 안 되 고 , 재료 들 이 완벽 하 게 섞인 맛 이 나야 하 는데 , 구수 하 면서 진한 맛 과 함께 꼬 들 한 식감 을 느낄 수 있 어야 한다 . 여기 까지 가 이 레시피 의 알파 와 오메가 되 겠 다 . 재료 들 을 완벽 하 게 볶 아서 풍미 와 함께 식감 이 극대 로 증가 된 시점 . 바탈리 이외 에 이렇게 강하 고 꼬 들 하 게 볶 는 방법 을 사용 하 는 쉐프 가 있 는지 찾 아 보 았 지만 없 던 것 같 은데 , 바삭 한 고기 와 토마토 페이스트 를 볶 아서 새로운 식감 을 창조 하 는 이 레시피 는 확실히 다른 차원 의 맛 을 낸다 . 바탈리 에게 찬사 를 ! ! 그리고 는 우유 두 컵 가량 넣 고 ( 반드시 whole milk 를 사용 하 시 고 ) 바닥 을 긁 듯이 잘 저어서 눌어붙 은 것 이 없 도록 섞 어 준다 . 그리고 , 약간 의 드라이 허브 첨가 . ( 드라이 바질 2 티스 픈 , 월계수 잎 4 장 그리고 이태리 고추 가루 인 페페 로 치 니 아주 약간 1 / 2 티스 픈 정도 ) 참고 로 바탈리 는 허브 를 사용 하 지 않 는데 , 내게는 은은 하 게 깔려 있 는 허브 의 향기 와 풍미 는 포기 할 수 없 는 유혹 이 다 . 허브 의 맛 이 튀 도록 많이 넣 으면 안 되 고 , 전체 적 인 맛 이 고급 스러워 지 도록 약간 만 넣 어 준다 여기 서부터 는 충분 한 수분 이 있 기 때문 에 좀체로 타 지 않 으니 안심 하 시 고 살살 저으 면서 되직 해 질 때 까지 볶 아 준다 . 중 불로 다시 한 번 15 분 정도 이 정도 되직 해 지 면 드라이 한 화이트 와인 반병 정도 . 3 - 400 ml 가량 우유 는 재료 에 리치 함 과 실 키 한 식감 을 더 해 주 고 화이트 와인 은 산미 와 함께 자연 스러운 단맛 , 그리고 와인 의 풍미 를 더 해 주 게 된다 . 잘 저 어 주 면 이런 모양 이 되 고 이 시점 부터 는 뚜껑 을 닫 고 아주 약한 불로 천천히 끓여 준다 . 20 분 에 한 번 정도 뚜껑 을 열 고 저 어 주 는데 뚜껑 을 열 었 을 때 이렇게 거품 이 보글보글 작 게 올라오 는 정도 로 화력 을 약하 게 하 면 된다 . 얼마나 오래 끓이 면 될까 ? 대충 여기 서부터 3 시간 정도 . ㅋㅋ 그러니까 전체 적 으로 는 5 시간 이상 을 볶 고 , 끓여야 한다는 말 이 다 . 하품 이 나온다 . 하지만 , \" 나 는 꼭 해 먹 고 말 끄 야 ! !\" 라는 각오 와 함께 하늘 이 두쪽나 도 만들 고 말 리라는 지극정성 이 있 다면 당신 이 이제 까지 경험 하 지 못했 던 라구 볼 로 네 제 를 맛볼 수 있 으니 . ............... 행진 ~ 행진 ~ 전진 ! 하 는 거 야 아 ~~~~ 그리고 , 20 분 에 한 번 씩 뚜껑 을 열 면 어떤 현상 이 생기 냐 하 면 수분 과 지방 이 서서히 분리 가 되 는 것 을 볼 수 있 는데 바닥 을 긁 듯이 저으 면서 동시 에 다른 재료 들 과 다시 한 번 잘 섞 어 주 시 라 . 분리 되 면 다시 섞 고 분리 되 면 다시 섞 고 분리 되 면 다시 섞 고 x 3 ( 1 시간 에 세 번 x 세 시간 ㅋㅋ ) 그리고 , 중간 중간 우유 와 치킨 스탁 의 비율 을 1 : 1 정도 로 섞 어서 수분 을 더 해 주 는데 소스 가 너무 되직 하 게 되 면 조금 씩 보충 을 해 준다 . 치킨 스탁 을 첨가 하 는 이유 는 우유 의 양 이 너무 많 으면 소스 가 전체 적 으로 너무 크리미 해 지 기 때문 이 고 , 동시 에 물 을 넣 으면 소스 의 맛 이 묽 어 지 는 것 또한 방지 하 기 위해서 이 다 . 최종 적 인 농도 가 이 정도 가 되 면 적당 하 고 색깔 은 이 정도 진하 게 나오 면 완성 이 된 것 이 다 . 밀크 초콜렛 같 은 색깔 과 실크 같 은 소스 , 하지만 고기 의 텍 스쳐 는 뭉게지 지 않 고 살 아 있 는 시점 이 시점 에서 마지막 으로 소금 과 후추 로 간 을 하 면 소스 는 완성 이 되 는데 . .............. 여기 서 맛 을 보 면 이제 까지 경험 했 던 볼 로 네 제 와 는 차원 이 다른 맛 을 느낄 수 있 다 . 아주 진하 면서 도 실크 같 은 텍스 쳐 . 육향 이 살 아 있 는 분명 한 맛 , 강렬 한 풍미 와 식감 까지 , 하지만 , 진정한 라구 소스 는 완벽 한 파파 델리 ( papardelle ) 면 이 없 으면 앙꼬 없 는 찐빵 샤리 없 는 스 시 속없 는 만두 드레싱 없 는 샐러드 등등 이 라고 말 할 수 있 다 . 이제 2 / 3 쯤 왔 다 . 쿠사 의 획기 적 인 , 그리고 , 기발 한 파파 델리 면 과 함께 볼 로 네 제 파스타 가 완성 되 는 다음 회 를 기다리 시 라 . to be continued . . . . . .........................',\n",
       "       '\\ufeff\\ufeff \\u200b 얼마 전 부터 신용 카드 를 리빌 딩 하 기 시작 했 습니다 . 신용카드 도 막무가내 로 만들 고 사용 했 지만 현명 한 소비 를 위해서 대대 적 으로 리빌 딩 을 했 습니다 . 덕분 에 신용카드 는 12 개 가 되 었 지만 포인트 가 쌓이 는 것 을 보 니 흐뭇 한 미소 가 지 어 집니다 , 물론 그만큼 소비 가 늘어난 것 은 비밀 입니다 . \\u200b 가장 쉬운 재테크 는 소비 를 줄이 고 저축 을 하 는 것 입니다 . 피 킹 률 이 아무리 좋 은 카드 를 사용 해도 100 % 이상 의 피 킹 률 을 자랑 하 는 저축 을 이기 지 는 못 합니다 . 하 지만 어쩔 수 없이 소비 를 해야 한다면 가장 현명 한 소비 를 하 는 것 이 맞 겠 죠 . \\u200b 자 ~ 그럼 신한 카드 딥 드림 플래티넘 을 소개 하 겠 습니다 . \\u200b \\u200b \\u200b 신한 카드 딥 드림 플래티넘 + ( deep dream platinum +) \\u200b 연회비 33 , 000 원 ( 해외 겸용 ) 평균 지출 / 해외 포함 - 150 만 원 이상 피 킹 률 4 . 5 % 이하 ( 68 , 000 포인트 이상 / 150 만 원 사용 시 ) 이동 통신 자동 이 체 필수 / 신한 통장 자동 이 체 필수 \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b 딥 드림 플래티넘 ( 이하 딥 드림 ) 은 무조건 1 . 2 %( 신한 계좌 자동 이 체 , 전월 실적 150 만 원 이상 ) 를 적립 해줍니다 . 아무 생각없이 사용 한다면 이 정도 적립 에서 많 게 는 2 % 의 피 킹 률 을 보여 줍니다 . 따라서 평범 한 카드 에 불과 하 게 됩니다 . \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b 하 지만 드림 영역 에서 는 사용 하 시 면 1 . 2 %+ 2 . 2 %= 3 . 4 % 를 적립 해줍니다 . 그리고 드림 영역 중 가장 많이 사용 한 한 곳 은 1 . 2 %+ 2 . 2 + 2 . 2 %= 5 . 6 % 를 적립 해줍니다 . 따라서 드림 영역 에서 도 한 곳 만 집중 적 으로 사용 하 시 면 피 킹 률 이 상당히 올라가 게 됩니다 . \\u200b \\u200b 다만 , 1 . 2 % 를 제외 한 2 . 2 % 적립 은 5 만 포인트 라는 적립 한도 가 있 습니다 . 따라서 1 . 2 % 는 무제한 적립 이 라 보 시 면 되 고 나머지 2 . 2 %, 2 . 2 %+ 2 . 2 % 는 5 만 포인트 가 적립 한도 라고 생각 하 시 면 됩니다 . \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b 드림 영역 은 백화점 , 할인점 , 편의점 , 잡화 , 영화 , 커피 , 골프 , 해외 , 이동 통신 요금 이 있 습니다 . \\u200b 그럼 피 킹 률 을 높이 기 위해서 드림 영역 중 어느 곳 에 몰 빵 을 하 면 좋 을까요 ? \\u200b 눈치 빠른 분 들 은 아 시 겠 지만 이동 통신 요금 에 몰 빵 하 시 면 됩니다 . \\u200b 이동 통신 요금 은 보통 통신비 + 휴대폰 기기 값 + 소액결제 로 이루어집니다 . 여기 서 1 인 당 50 만 원 까지 한도 가 주어지 는 소액결제 를 이용 하 시 면 피 킹 률 을 손쉽 게 올릴 수 있 습니다 . \\u200b 참고 로 소액결제 는 인터넷 쇼핑몰 은 거의 대부분 사용 이 가능 합니다 . 오프라인 의 경우 sk 텔레콤 은 티 페이 를 활용 하 면 됩니다 . 물론 소액결제 도 ㄴ ㅇㅂㅍㅇ포인트 ㅇ포인트로 충전 이 됩니다 . 부부 가 모두 자동 이 체 를 신청 하 고 113 만 원 까지 사용 하 신다면 정확히 5 만 원 이 적립 됩니다 . \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b 이제 나머지 금액 인 370 , 000 원 의 실적 을 채워 야 겠 죠 ? 여기 서 포인트 적립 제외 에 는 ㅅ ㅍㄱ이 없 습니다 . 따라서 ㅅ ㅍㄱ 신공 을 쓰 시 면 됩니다 . 이 부분 이 궁금 하 시 면 비밀 덧 글 을 달 아 주 세요 . \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b 그 이외 의 혜택 중 에 도 해외 결제 10 % 캐쉬 백 이 있 습니다 . 1 년 동안 사용 한 금액 중 최대 5 만 원 까지 니까 해외 결 제시 50 만 원 정도 는 딥 드림 플래티넘 을 이용 하 시 면 연회비 도 충분히 뽑 을 수 있 습니다 . 그럼 무한 태클 환영 합니다 . 감사 합니다 .',\n",
       "       '불러도 대답 해 주 지 않 는 고양이 들 이 가장 많이 하 는 행동 이 바로 ‘ 귀 ’ 만 움직이 는 것 입니다 . 이름 을 부르 면 파라 볼라 안테나 처럼 생긴 귀 를 소리 가 나 는 방향 으로 움직이 는데요 . \\u200b 이것 은 고양이 입장 에서 “ 잘 들 었 어 ” 라는 사인 입니다 . 즉 집사 입장 에서 는 귀 만 실룩실룩 움직일 뿐 사운드 가 없 어 대답 을 하 지 않 는 것 처럼 느껴 지 지만 , 고양이 는 “ 잘 듣 고 있 어 ” , “ 잘 들 었 어 ” 라는 표현 을 귀 로 나타내 고 있 는 거 죠 . 고양이 가 귀 만 움직이 더라도 대답 해 주 고 있 는 것 이 니 애정 을 담 아 자주 불러 줍시다 . \\u200b \\u200b',\n",
       "       '친구 와 대화 하 던 중 열역학 제 2 법칙 에 대한 이야기 가 나왔 다 . 그리고 지구 는 열린계 인가 닫힌계 인가 에 대한 이견 이 생겼 다 . 나 는 지구 가 열린계 라고 이야기 했 고 친구 는 닫힌계 라고 이야기 했 다 . 지구 가 닫힌계 라는 주장 의 근거 는 이러 했 다 . 지구 에 태양 의 에너지 가 들어오 지만 나가 는 양 도 똑같 으며 그 합 은 항상 일정 하 여 변하 지 않 는다 . 그러므로 지구 는 닫힌계 이 다 . 내 주장 은 이러 했 다 . 네 이야기 는 지구 가 항상성 을 유지 한다는 이야기 일 뿐 이 고 그 마저 도 에너지 의 항상성 이 아닌 기온 의 항상성 일 뿐 이 다 . 또한 에너지 의 출입 자체 가 열린계 와 닫힌계 의 구분 의 기준 ( 틀린 얘기 임 . 바로 뒤 에 나오 지만 . ) 이 기 때문 에 에너지 가 출입 되 고 있 는 지구 는 열린계 이 다 . 일단 우리 는 검색 을 통해 닫힌계 는 고립계 와 다르 다 라는 사실 을 알 게 되 었 다 . 1 . 고립계 ( isolated system ) 는 에너지 와 물질 의 출입 이 둘 다 없 는 계 를 말 한다 . 2 . 닫힌계 ( closed system ) 는 에너지 의 출입 은 있 되 물질 의 소통 은 없 는 계이 다 . 3 . 열린계 ( open system ) 는 에너지 와 물질 둘 다 소통 이 있 는 계이 다 . 열역학 제 2 법칙 은 닫힌계 가 아닌 고립계 의 얘기 다 . 여기 서 친구 는 지구 가 닫힌계 이 다 라고 주장 했으며 나 는 열린계 이 다 라고 주장 했 다 . 내 가 지구 가 열린계 라는 것 에 만 원 을 걸 수 있 다고 말 하 자 친구 는 닫힌계 라는 것 에 5 만 원 을 걸 수 있 다고 말 했 다 . 약 두 시간 동안 열렬히 검색 하 며 갑론을박 을 하 다가 , 결국 한 인터넷 백 과 사전 에서 닫힌계 라고 단정지 은 것 을 근거 로 나 는 그 친구 에게 커피 를 사 주 게 되 었 다 . 하지만 마음 속 깊이 납득 할 수 는 없 어서 내 가 속해 있 는 페북 상 의 과학 관련 커뮤니티 에 아래 의 질문 을 올렸 다 . \" 과사 동지 여러분 안녕 들 하 신지요 ~ 뜬금없 지만 질문 하나 드려도 될까요 ? 친구 와 열역학 제 2 법칙 얘기 하 다가 , 지구 는 열린계 인가 닫힌계 인가 에 대한 내기 를 하 게 되 었 습니다 . 지구 가 고립계 가 아닌 것 은 둘 다 수긍 을 했 는데요 , 에너지 의 출입 이 아닌 물질 의 출입 여부 로 열린계 와 닫힌계 가 구분 이 된다는 것 을 알 게 되 었 습니다 . 저 는 운석 이 떨어지 고 우주선 을 발사 하 기 도 하 기 때문 에 지구 에 는 물질 의 출입 이 가능 하 다고 보 아야 하 고 그러므로 지구 는 열린계 다 라고 주장 하 였 고 친구 는 운석 이나 우주선 은 흔치 않 은 사례 이 며 미미 한 양 의 출입 이 기에 닫힌계 다 라고 주장 했 습니다 . 또 친구 가 제레미 리프킨 의 이야기 를 하 기에 그 사람 은 과학자 가 아닌 사회 학자 쪽 으로 알 고 있 으며 엔트로피 라는 책 을 통해 엔트로피 의 개념 을 오도 하 게 만들 었 다고 욕 을 좀 먹 기 도 하 는 걸로 알 고 있 어서 그 얘기 를 하 며 신뢰 성 에 대해 의문 을 제기 했 구요 . 그 친구 는 분명 고등학교 때 도 닫힌계 로 배웠 다고 얘기 를 하 더군요 . 나중 엔 농담 으로 닫힌 건 지구 가 아니 라 니 마음 이 야 라고 가벼운 인신공격 까지 하 기 에 이르 렀 습니다 . 그 친구 는 제게 열린 건 지구 가 아니 라 네 뚜껑 아니 냐고 . .. 저 는 니 가 변호사 니까 법 적 으론 닫힌계 일 수 도 있 겠 지 하지만 실제로 는 열린계 야 . 거 법 이 참 문제 가 많 아 . 라고 하 기 도 . .. ( 물론 농담 이 었 습니다 . ..) 아무튼 , 결국 넷 상 의 어떤 백과사전 에서 닫힌계 다 라고 규정지 은 것 을 발견 하 고 제 가 커피 를 사 긴 했 습니다만 . .. 얘기 중간 에 정재승 박사 님 과 이덕환 박사 님 께서 열린계 지만 닫힌계 라고 볼 수 도 있 다 라고 쓰 신 글 을 발견 하 기 도 했 습니다 . 엄밀 하 게 말 하 자면 지구 는 닫힌계 일까요 열린계 일까요 ? \" 그리고 지금 하나 의 답변 이 올라와 대화 를 하 였 는데 이러 하 다 . 다만 이 분 은 과학자 가 아닌 서울 에 있 는 병원 원장 님 이 시 다 ;;; 과학 자분 께서 답변 해 주 시 면 좋 은데 . .. ㅠ 추가 ) 몇몇 분 들 의 답변 이 추가 되 었 다 . 현직 과학 자분 들 이 신지 는 몰라도 서울대 화학 전공 자 등등 이 포함 되 어 있 다 . 위 에 내 가 언급 했 던 경제학자 ( !) 제레미 리프킨 은 지구 를 부분 적 으로 닫힌 체계 라고 했 나 보 다 . 아니 . .. 그냥 closed system 의 번역 을 저리 한 건가 ? 일리야 프리고진 . .. 검색 해 보 았 다 . 음 . .. 위 설명 을 전부 정확히 이해 하 기 위해선 지금 은 해선 안 되 는 많 은 공부 가 필요 하 다는 생각 이 든다 . 물 의 기원 이 혜성 이나 소행성 이 라는 설 . 검색 해 보 았 다 . [ 오늘 의 세상 ] \" 물 의 기원 , 혜성 아닐 수 도 \"… 과학 계 大 혼란 최신 기사 가 있 네잉 . 원시 지구 에선 물 이 남 아 있 을 수 없 었 다고 한다 . 그러므로 물 은 지구 밖 에서 들어온 것 이 라고 . 그래서 혜성 에서 온 것 이 다 라는 추측 이 유력 했으나 아니 었 다는 얘기 같 다 . 소행성 쪽 으로 연구 가 진행 될 것 이 라고 한다 . 크리스 쳔 이 다 보 니 저런 기사 를 볼 때 여러 생각 이 드 는데 . .. 아무튼 패스 . 내 가 열린계 라고 우길 근거 들 이 약간 은 생긴 듯 ? 추 추가 ) 역전 가능 할 것 같 다 . 음 . .. 위 설명 을 전부 정확히 이해 하 기 위해선 지금 은 해선 안 되 는 많 은 공부 가 필요 하 다는 생각 이 든다 . 물 의 기원 이 혜성 이나 소행성 이 라는 설 . 검색 해 보 았 다 . 최신 기사 가 있 네잉 . 원시 지구 에선 물 이 남 아 있 을 수 없 었 다고 한다 . 그러므로 물 은 지구 밖 에서 들어온 것 이 라고 . 그래서 혜성 에서 온 것 이 다 라는 추측 이 유력 했으나 아니 었 다는 얘기 같 다 . 소행성 쪽 으로 연구 가 진행 될 것 이 라고 한다 . 크리스 쳔 이 다 보 니 저런 기사 를 볼 때 여러 생각 이 드 는데 . .. 아무튼 패스 . 내 가 열린계 라고 우길 근거 들 이 약간 은 생긴 듯 ? 추 추가 ) 역전 가능 할 것 같 다 .',\n",
       "       '위 에서 찾 은 태그 ( table 에 해당 하 는 ) 를 pd . read _ html 으로 읽 어 줄 텐데 , 여기 서 주의 할 점 은 beautifulsoup 이 아닌 문자열 형태 로 넣 어 줘야 합니다 . 그래서 , table 태그 에 있 던 값 을 문자열 로 변경 ( str ( table ) ) 한 뒤 , pd . read _ html ( ) 으로 읽 어 줍니다 .',\n",
       "       \"마라 탕 의 노예 가 쓰 는 마라 탕 집 후기 ( 신촌 , 건대 , 서울대 , 대림 등등 ) update 01 . 09 . 2019 < 마라 탕 의 노예 가 쓰 는 마라 탕 추천 글 및 후기 by 금 개 , 적절 , 노 고추 > 이 모든 것 은 우리 학교 학생 식당 에 마라 탕 이 들어오 며 시작 되 었 다 . ( 근데 왜 마라 탕 가게 에서 이런 구불구불 한 그릇 많이 쓰 는지 알 고 싶 음 . 중국 인 들 이 공구 하나 ? ) 마라 탕 은 어떤 매운 향신료 ( 화자 오 ) 가 들어간 음식 인데 ( 사람 들 에게 마라 탕 설명 할 때 마다 하 는 말 ) 매콤 하 고 중독 성 이 몹시 심하 다 . 마라는 맵 고 아리 다는 뜻 이 다 . 그래서 먹 으면 입술 이 발갛 게 되 는 개 이득 효과 를 겪 을 수 있 음 . 별 생각 없이 주 2 회 꼬박꼬박 마라 탕 을 먹 던 나 는 결국 방학 에 도 , 졸업 후 에 도 마 라 탕 을 먹 으러 학교 에 가 게 되 었 다 . ...... 내 장례식 에 도 육개장 대신 마라 탕 을 먹 을 것 이 다 . 난 마라 탕 을 좋아해서 먹 는 것 이 아니 라 마 라 탕 에 의해 조종 되 어 마 라 탕 의 노예 로써 먹 는 것 이 다 . 마라 탕 은 그렇게 나 아주 무서운 음식 이 다 . 중국 정부 가 한국 을 정복 하 려고 전파 시키 는 게 아닐까 무서울 정도 . .. 우린 결국 마라 를 국유 화 한 중국 정부 에게 충성 할지 도 모른다 . 금 개 는 마 라 탕 먹 고 심장병 까지 나 았 다 . 혼자 마라 탕 집 가 서 마 라 탕 먹 고 아이스 아메리카노 한잔 때려 주 면 인생 행복 완성 임 . 곧 마라 탕 은 평양냉면 을 잇 는 힙스터 음식 이 될 것 이 다 . 이 글 은 성지 가 될 것 임 . 평양냉면 은 일단 육수 라는 점 에서 베지 테 리안 힙스터 들 에게 외면 당함 . 등장인물 소개 이 글 은 마라 탕 에 미친 년 들 ( a . k . a 마 미년 ) 들 의 합작 으로 만들 어 졌 다 . 마 미년 들 은 마라 탕 을 너무 좋 아 하 고 퀴어 프렌들리 하 기 때문 에 2017 년 퀴어 퍼레이드 에 범마 라 탕 연대 로 후원금 을 모아 후원 하 고 퀴어 퍼레이드 책자 에 실리 기 도 하 였 다 . 적절 : 이 글 글쓴이 . 초급 중국어 b 0 . ...... 어머니 중문 과 . 금 개 : 온갖 난리 를 치 고 다녀서 온갖 마라 탕 을 맛본 사람 . 구몬 중국어 일본어 경험자 ( 사실 외고 중국어 과 출신 ) 노 고추 : 중국 에서 중고 등 학교 를 나온 마라 탕 계 의 에이스 . 우리 가 안 먹 어 본 음식 들 이미 중국 에서 먹 어 보 았 고 중국어 도 존 잘 이 라 같이 있 으면 든든 함 . 근데 좀 이상 한 사람 . 예린 : 조용 하 지만 술 을 성실히 꾸준 하 게 마시 고 노 는 것 도 꾸준히 하 기 에 빠지 지 않 는 사람 . 중국어 성적 모름 . 언론 보도 ( 제목 을 클릭 하 시 면 됩니다 ) 지역 정리 * 건대 * 동대문 * 명동 , 종각 * 광화문 * 시청 * 을 지로 * 한양대 * 신촌 , 이 대 , 홍대 * 망원 * 대림 * 서울대 입구 * 이태원 * 신도림 * 강남 * 여의도 건대 < 라 화 쿵푸 > 마라 샹 궈 최애 집 인데 동대문 에 도 있 고 건대 에 도 있 다 . 마라 탕 은 땅콩 베이스 라 국물 이 진하 고 부드럽 다 . 마라 샹 궈 는 미친 자극 성 을 자랑 한다 . 그 어디 서 도 이렇게 자극 적 인 곳 은 없 었 다 . 약간 팬 에 늘러 붙 도록 볶 아 줘서 긁어먹 는 재미 가 있 다 . 동대문 은 너무 가게 가 작 아서 먹 기 힘들 고 건대 는 가게 는 큰 데 사람 이 항상 너무 많 아서 정신 이 없 다 . 번호표 를 주 는데 중국인 아주머니 들 이 독특 한 발성 으로 소리 를 지르 며 번호 를 부르 심 . 동대문 점 은 마라 탕 만 원 부터 가능 ( 이런 건 불법 으로 해야 한다 ㅡㅡ혼자 먹 을 수 가 없 자 나 ) 마라 샹 궈 는 건대 점 2 만 원 부터 가능 . < 건대 매운 향 솥 > 마라 탕 비추 천 . 여기 마라 탕 이 매우 별로 . ..!!! 땅콩 베이스 를 넘 어서 하나 도 안 맵 고 ( 맵 기 조절 불가 ) 별로 안 뜨겁 게 나온다 ! 그리고 무게 잴 때 그릇 무게 까지 들어가 서 너무 비싸 짐 . 정가 제 로 마라 탕 6 천 원 짜리 가 있 는데 개별 로 재료 고르 는 것 도 가능 . 마라 샹 궈 는 맵 기 조절 가능 하 고 맛있 음 . 크림 새우 너무 얇 고 음 내 가 생각 한 크림 새우 가 아니 야 . ...... 꿔 바로우 는 맛있 음 . 2 층 에 조용히 양 꼬치 먹 을 수 있 는 공간 있 고 좋 음 . < 건대 순 희 냉면 > 평양냉면 집 을 개조 한 것 같 은 비 쥬얼 . .. 즉 한국 음식점 같 은 느낌 . 이 라고 생각 했 는데 두 번 째 방문 에서 보 니 이름 이 진짜 순 희 냉면 이 었 음 . 널찍 하 고 한산 해서 천천히 술 마시 며 먹 기 좋 다 . 마라 샹 궈 적당히 맛있 고 , 마라 탕 도 너무 자극 적 이 지 않 고 맛있 다 . 꽃 빵 을 서비스 로 자주 주심 . 라 화 쿵푸 골목 에서 왼쪽 으로 꺾 었 을 때 주차장 과 함께 있 는 집 . 토마토 편의점 안 쪽 . 여기 냉면 이 연변 식 냉면 인데 아주 맛있 다 . 술 먹 고 먹 어서 그런가 . .. 왜 이렇게 맛있 냐고 겁나 먹 음 . 연변 식 순대 는 찹쌀 이 들어가 있 다 보 니 탄수화물 폭발 이 라 너무 배불러서 . . 음 . .. 난 먹 기 힘들 었 음 . .. 마라 샹 궈 를 반찬 으로 먹 으면 괜찮 을 것 같 은데 난 밥 많이 못 먹 으니깐 . . 메뉴판 이 매우 크 다 . 그래서 나 와 금 개 가 모두 가려져 벌임 . 근데 내 가 저 메뉴판 금 개 랑 같이 보 다가 금 개 쪽 으로 재채기 해서 금 개 가 너무 어처구니 없 어 했 다 . 지난 겨울 여기 서 마 라 닭 이 란 걸 시켰 다 ( 위 사진 ) . 그런데 우리 가 마라 닭 을 시키 니까 다 들 굉장히 당황 한 눈치 였 고 얼마 지나 지 않 아 직원 이 다급 하 게 닭 을 바깥 에서 사 오 는 것 을 목격 ;;; 이걸 시켜 보 고 왜 마라 샹 궈 집 에 소고기 양고기 돼지고기 옵션 만 있 고 닭고기 는 없 는지 알 게 되 었 다 . 넘 빡빡 허 다 . .. < 건대 쿵푸 > 외관 이 마라 탕 집 같 지 않 다 . 즉 밝 고 깨끗 함 . 마라 탕 과 마라 샹 궈 만 판다 . 술 을 안 파 는 게 유감 ( 그래서 깨끗 한 것 일 지도 ) . 술집 이 라기 보다 일반 음식점 느낌 . 그릇 도 뭔가 일본 라멘 같 은 그릇 . .. 국물 은 땅콩 소스 진하 고 맵 게 먹 으면 진짜 맵 다 . 매운 맛 이 제일 매운 맛 이 고 강한 맛 은 적당히 맵 다 . 매운 맛 너무 괴로워서 순한 맛 이랑 섞 어 먹 어 또 . .. 여기 앞 으로 혼자 자주 와서 먹 을 것 같 다 ! ( 그리고 실제로 자주 옴 . .. 좀 지나치 게 자주 가 는 듯 ) 오늘 고급 정보 를 알 았 는데 술 을 사 와서 먹 어도 된다 ! 마라 샹 궈 는 약간 타이 음식 . . 같 은 느낌 이 다 . 다른 곳 마라 샹 궈 랑 은 다름 . 향신료 나 이런 게 다르 다 . < 건대 석기 시대 > 비 건 옵션 이 가능 한 곳 . 샹 궈 는 좀 호불호 갈릴 수 있 음 . 표고 꿔 바로우 가 오지 게 맛있 다 . 동대문 < 동대문 가화 어쩌구 > 라 화 쿵푸 옆 에 있 는 곳 인데 종업원 이 내 취향 . .. 인상 쓰 고 나시 입 고 두꺼운 팔뚝 을 자랑 하 며 주문 받 아 줌 . 마라 탕 은 그렇게 자극 적 이 지 않 고 카레 향 이 난다 . 마라 샹 궈 꽤 자극 적 이 고 맛있 다 . 꿔 바로우 아주 맛있 음 . 그런데 꿔 바로우 튀기 는 소리 가 ㅋㅋㅋ ㅋㅋㅋ ㅋㅋㅋ ㅋㅋ ㅋㅋ 기계 돌리 는 소리 . .. 나 비오 는 줄 ( 그만큼 조 올라 뜨겁 다 ) 찹쌀 탕수 육류 임 . 연태 고량주 큰 것 만 팔 아서 둘 이 서 어쩔 수 없이 큰 거 다 마심 . 사진 을 그지 같이 찍 었 네 . .. 여기 서 마 라면 도 파 는데 , 신촌 에 있 는 유명 한 마 라면 집 이랑 너무 다르 다 . 거긴 짜장면 의 마라 화 같 은데 여긴 맑 은 국물 이 나온다 . 그 외 동대문역 주변 에 마라 탕 집 이 하나 더 있 는데 가 게 외관 이 안 에서 인육 먹 고 있 을 것 같 아서 안 가 봄 . 명동 , 종각 < 신루 풍마 라 탕 > 3 천 원 짜리 미니 전 을 먹 는 재미 가 있 다 . 한국 의 전 같 은 게 아니 고 밀가루 반죽 을 구운 듯 한 . ..? 난 치즈 미니 전 을 먹 었 고 치즈 만 열심히 먹 었 다 . 미니 전 으로 매운 맛 을 좀 중화 시킬 수 있 음 . 마라 탕 에 식초 의 신 맛 이 많이 난다 . .... 그래서 난 별루 여 뜸 . ..... ( 후 에 노 고 추가 알려 주 었 는데 미니 전 이름 은 사실 쇼 좌 빙 . 그리고 저렇게 별 재료 가 안 들어간 것 은 대만 식 이 라고 했 다 . 중국 에서 는 베이컨 달걀 등 을 넣 어서 쇼 좌 빙 을 만든다고 . 미니 전병 같 은 것 이 라 보 면 됨 ) 그리고 2 층 에 위치 했 는데 엘레 베 이터 를 타 면 문 이 한 번 닫히 고 다시 열리 고 다시 닫힌다 . 탈 때 마다 그랬음 . 이유 는 알 수 없 다 . < 화룽 마라 룽 샤 > 금 개 가 여기 네이버 지도 에 도 안 나오 는 맛집 이 라고 했 는데 알 고 보 니 화풍 마라 룽 샤 로 이름 을 잘못 알 고 있 어서 그런 것 이 었 다 . 화룽 마라 룽 샤 입니다 . 그런데 여기 글씨체 가 진짜 오해 하 게 생김 . 이 곳 에 는 정말 온갖 마라 가 있 다 . 마 라오 이 란 것 도 있 음 ㅅ ㅂ ㅋㅋㅋ ㅋㅋㅋ ㅋㅋㅋ ㅋㅋ 3 층 까지 있 고 공간 은 쾌적 하 다 ( 화장실 은 대부분 의 마라 탕 집 이 그러 하 듯 그닥 . ..) 3 층 에 우리 밖에 없 어서 노 고추 는 팝핀 까지 추 었 다 . 정말 맛있 고 정말 맛있 다 ㅠㅠㅠ 내 가 그리워 하 던 자극 이 가득 하 다 . 지 삼 선 도 맛있 었 는데 두만강 의 지 삼 선 은 극 강의 과자 같이 바삭 하 다면 여기 는 가지 그 자체 의 풍미 가 좀 살 아 있 다 ! ! < 원신 마라 탕 > 약간 여기 들어가 도 될까 . ..? 싶 은 골목 에 위치 해 있 다 . 여기 윗 네일 샵 이름 이 되게 이상 했 는데 기억 이 안 난다 . 마라 탕 순한 맛 으로 먹 으니까 진짜 순하 고 맛있 었 다 . 지난 겨울 에 도 왔었 는데 그 때 도 맛있 었 던 게 기억 나 . .. 국물 을 많이 주 는 편 같 다 . 이 때 노 고추 는 볶음밥 을 먹 었 는데 ( 건강 을 위해 금마 라 중 ) 볶음밥 맛 이 약간 짜 다는 것 외 엔 무척 이나 평범 하 여 조금 놀랐 다 . 쇼 좌 빙 에 노 고추 는 이건 또 중국식 은 아니 지만 만족 하 였 다 . < 마 쵸 마라 > 거의 오픈 하 자마자 가 게 되 었 는데 직원 이 아주 친절 하 고 깨끗 하 다 . 물티슈 를 주 는 것 도 위생 을 강조 하 기 위함 이 아닌지 . .? 서비스 로 꿔 바로우 도 주 었 다 . 아주 깔끔 한 마라 탕 맛 이 다 . 엄청 자극 적 이 진 않 고 적당 한 자극 으로 맛있 었 다 . 광화문 < 쿵 푸마 라 탕 > 쿵 푸마 라 탕 체인점 이 다 그러 하 듯 내부 가 깨끗 하 고 진하 고 달달 한 국물 이 특징 . 2 층 까지 있 다 . 시청 < 라 향각 > 3 단계 임 에 도 자극 적 인 맛 이 부족 했 고 무엇 보다 . .. 고수 를 꼬치 로 계산 . .. 비싸 . ... 을지로 < 줄리아 > 힙스터 공간 . 여태 까지 알 던 마라 탕 집 과 다른 . .. 밥집 이 아니 라 술집 임 . 재료 를 고를 수 없 고 그냥 알 아서 마 라 샹 궈 와 탕 을 내주 는 데 맛있 음 . 마라 샹 궈 살짝 단맛 이 난다 신기 하 게 도 . .. 그래도 충분히 자극 적 . 멘 보 샤 는 맛있 긴 한데 나 는 그런 좀 딱딱 한 빵 에 있 는 걸 안 좋아하 고 부드러운 빵 에 있 는 걸 좋 아 해서 . . 조금 그랬 음 . 토마토 계란탕 금 개 가 엄청나 게 퍼먹 음 맛있 음 아무튼 분위기 가 몹시 힙 해서 미쳐 벌이 는 줄 알 았 다 . 힙스터 분 들 에게 추천 합니다 . . 화장실 도 그냥 무난 하 다 . 한양대 < 한양대 마라마 라 탕 > 여기 가 날 중독 시킨 무서운 곳 . .. 마라 샹 궈 는 없 고 마 라 탕 은 국물 이 깔끔 한 편 ! 근데 너무 짜 . ..... 그리고 재료 가 너무 복불복 ( 재료 못 고름 ) 원래 이름 이 ' 과 교원 쌀국수 ' 였 는데 한 학기 후 이름 을 마라 마 라 탕 으로 바꿨 다 . 뭣 이 중 한지 아 는 것 이 여 . .. 여기 는 하이델베르크 대학 의 학생 식당 이 관광지 로 유명 해졌 듯 유명 해질 지도 모른다 . < 한양대 양국 복 마라 탕 > 마라 탕 에 양고기 추가 해 먹 으면 짱 맛있 다 . .( 금 개 왈 . 나 는 채식 마라 탕 만 먹 음 ) 땅콩 소스 가 들어가 지 않 고 맑 은 국물 ( 사진 상 으로 확인 가능 ) . 보통 매 움 으로 먹 으면 조금 부족 함 을 느낄 수 있 다 맵 게 해도 별로 안 매 움 . ...( 조금 실망 ) 가지 볶음밥 은 너무 짰 다 ㅠ _ ㅠ ( 소면 이 라는 사 천 음식 을 자 뜩 파 는데 국물 있 는 국수 같 은 거 다 마라소 면 이랑 볶음 땅콩 소면 맛있 었 다 . ( 볶음 땅콩 소면 은 땅콩 이 들어가 있 는 국수 이 고 국물 이 없 는 걸 시키 려면 볶음 면 을 골라야 함 . ..) < 왕십리 1 번지 옆 쪽 2 층 에 있 는 중국집 - 만리 향양 꼬치 ( 이름 제보 받 음 ) > 꿔 바로우 는 존 맛 인데 ( 좀 독특 했 음 술 취해서 잘 기억 안 남 ) 마라 탕 은 먹 지 마세요 . .... ㅠㅠㅠ 넘 나 별로 . .. 골라 먹 을 수 있 는 게 아니 라 이모 가 그냥 주 는 건데 육개장 인 줄 알 았 어 . .. 하지만 계란탕 맛있 읍니다 소주 먹 기 좋 은 공간 ! 이모 너무너무 친절 하 십니다 마 라 탕 대신 꿔 바로 우랑 소주 드세요 신촌 , 이 대 , 홍대 < 신촌 호탕 마라 탕 > 금 개 는 여기 에서 포인트 만 거의 10 만 원 을 썼 는데 즉 여기 서 백만 원 이상 을 썼 다는 뜻 이 다 . ... 여기 마라 샹 궈 적당히 자극 적 이 고 좋 다 . 절반 은 찌 고 절반 은 구운 반반 만두 셩 젠 빠오 가 있 는데 ( 중국인 존나 지혜 로움 . .. 짬짜면 은 아이디어 일 뿐 지혜 가 아니 었 던 것 . ... ) 만두 별로 안 좋아하 는 적절 금 개 모두 맛있 게 먹 었 다 . ( 너무 맛있 어서 꿈 에 나옴 . ..) 여기 에서 연유 에 찍 어 먹 는 빵 도 먹 었 는데 맛있 었 다 . 마라 외 의 메뉴 도 다 너무 맛있 다 . 마라 탕 젤 맵 게 해도 괴롭 게 맵 지 않 고 진짜 매콤 한 수준 ? 갠 적 으로 마라 탕 은 여기 가 최애 ㅠㅠㅠ ( 3 층 에 훠궈 집 생긴 것 도 가 보 았 는데 깔끔 하 게 잘 나온다 . 1 인 1 훠궈 로 나옴 ㅋㅋ 국물 그릇 ? 이 쪼끄맣 게 . .. 좋 았 음 . 근데 맛 은 그냥 그랬 다 ) < 신촌 기차역 이 대마 라 탕 > 집 앞 에 생겨서 가 봤 는데 국물 이 지나치 게 사골 베이스 라 마 라 탕 특유 의 건강 해치 는 맛 이 잘 안 남 . 매운 맛 으로 먹 으면 괜찮 을지 도 ? 무게 재서 5 천 원 이상 되 면 끓여 준다 아주머니 친절 해서 좋 음 마 라 맛 강하 지 않 으나 입문 용 으로 추천 ! !! ( 마라 샹 궈 는 비추 천 . ..) < 이 대역 차이 나전병 > 여기 도 사골 베이스 국물 이 라 조금 성 에 안 차 는 맛 이 다 . 가게 가 좁 고 오픈 키친 이 며 리얼 중국 길거리 느낌 임 . 야채 , 라면 , 곤약 마라 탕 세 종류 ( 5 , 6 , 7 천 원 ) 중 에 골라서 주문 하 면 이모 가 바로 끓여 준다 . 나 는 여긴 마 라 탕 보다 찌 엔 삥 ( 전병 , 중국 샌드위치 ) 이 더 맛있 었 다 . < 신촌 라 화 쿵 부 혹은 라 화 쿵푸 > 라 화 쿵푸 가 요즘 이곳저곳 에 우후죽순 으로 생기 는데 신촌 라 화 쿵푸 에 유독 너무 안 좋 은 기억 이 많 다 ㅠㅠ 직원 들 이 굉 ~ 장히 불친절 했 음 . .. 나 뿐 아니 라 내 주변 사람 들 모두 그렇게 말 했 다 . .. 금 개 : 예전 에 1 층 에 자리 가 남 았 다는 이유 로 2 층 에 올라가 려던 우리 에게 소리 지름 , 샹 궈 먹 다가 머리카락 나온 적 있 음 ( 같 은 가격 으로 다시 해 주 셨으나 다른 메뉴 는 안 된다고 하 심 . .), 옆 테이블 에서 맥주잔 이 깨졌 는데 잘 안 치워져 있 어서 옆자리 앉 은 금 개 허벅지 에 박혀서 피 남 ㅠㅠ . . < 신촌 복성 각 양 꼬치 마라 탕 > 양 꼬치 맛집 인데 재료 를 고를 수 없 는 한 그릇 뚝딱 마라 탕 을 시킬 수 있 다 . 고수 향 이 강하 고 엄청 진하 고 만두 와 오뎅 이 들어가 있 음 . 옥수수 면 이 많이 들어가 있 고 극 강의 염분 을 충전 할 수 있 다 . < 홍대 원숭이 . .. 혹은 손오공 마라 탕 > 이건 홍대 원숭이 마라 탕 . . 아니 손오공 마라 탕 의 마라 반 ( 마라 비빔면 같 은 , .,., 약간 새콤 한 맛 ) 인데 아주 특이 하 고 맛 이 좋 다 손오공 마라 탕 은 샹 궈 , 탕 둘 다 아주 괜찮 고 마 라 반 이 라는 레어 메뉴 가 있 으며 평일 에 는 마 라 탕 을 채수 로 도 끓여 주 셔서 비 건 옵션 이 가능 하 다 . 샹 궈 도 물론 비 건 가능 하 고 마 라 반 은 육수 로 삶 는 것 이 기 때문 에 비 건 은 아니 라고 함 < 서교 손오공 마라 탕 > \\u200b 위 의 홍대 점 은 . .. 위생 에서 걸리 고 말 았 읍니다 . ..( 두 둥 ) 하지만 서교 점 은 마라 탕 집 중 에서 도 위생 으로 손꼽히 는 집 이 라니 걱정 말 고 드 시 길 ( 오픈 형 주방 ! !) 비 건 옵션 이 가능 하 고 , 비 건 옵션 을 해도 마 라 샹 궈 가 정말 정말 맛있 읍니다 ㅠㅠㅠ 마라 탕 도 맛있 지만 마 라 샹 궈 가 워낙 맛있 어서 묻혀 벌임 . . ( 그리고 내 친구 들 이 표고 를 넣 어서 나 는 마 라 탕 을 먹 다가 멈춰야 했 다 . ... 난 표고 가 싫 은 사람 . ..) 그리고 버섯 꿔 바로우 가 있 는데 채식 한 뒤 로 꿔 바로우 못 먹 었 던 분 들 에게 강추 합니다 ㅠㅠ 증말 너무 맛있 어 . .. < 연남동 홍화 마라 탕 > 재료 바 에서 조금 쉰 냄새 가 나 서 두부 를 적 게 담 앗 는데 아니나다를까 조금 재료 에서 약간 시큼 한 냄새 났 . ..... 2 단계 ( 보통 맛 ) 먹 었 는데 마 라 맛 이 굉장히 특이 하 게 . . 짠맛 이 많이 남 뭔가 소스 를 과하 게 넣 은 것 처럼 . .. 지 삼선 무난 . .. 달 짠맛 . ... 망원 < 망원동 딘 딘 향 > 마라 샹 궈 -> 기름 이 많 고 떡볶이 처럼 찌 듯이 볶 아 져서 개인 적 으로 는 조금 불호 였 음 , 소스 는 괜찮 으나 마 라 향 이 강하 지 는 않 음 , 그러나 공기 밥 이 무료 로 제공 된다 . < 망원동 라 화 쿵 부 > 망원동 에선 라 화 쿵 부 가 가장 평 이 좋 은 것 같 다 . 하지만 라 화 쿵 부 . .. 너무 한국 화 된 맛 이 라 마 라 마 라 하 지 않 아서 나 는 . .. 그냥 그랬 다네 . .. 대림 < 대림 봉자 마라 탕 > 금 개 : 양고기 마라 탕 은 재료 고 를 필요 없이 5 천 원 에 겁나 진한 국물 + 고기 짱짱 많이 주 신다 . 제일 맛있 었 던 것 같 음 . . 그 외 에 도 온갖 중국 음식 을 팔 고 있 어서 도전 해 보 기 좋 다 . 나 는 당 콩 볶음 ( 땅콩 아님 ) 이 란 걸 먹 었 엇 는데 졸라 신기 하 게 맛있 었 음 . 주변 에 중국 길거리 음식 도 많이 팔 고 중국 식 재료 도 많이 팔 지만 치외법권 이 라 대부분 카드 결제 안 됨 . ( 마라 탕 집 은 카 결 됨 ) 금 개 와 노 고추 는 지하철역 출구 에서 인분 을 목격 했 는 사람 이 네 . .. 트라우마 가 생겼 어 . .. 그 다음 에 적절 과 왔 을 때 에 는 머리 에서 피 흘리 는 할아버지 를 목격 해 버렸 네 . ... 적절 : 비린내 때문 에 잘 먹 지 못하 였 다 . .. 너무 그 . .. 비쥬 얼도 . ...... 탕수육 은 맛있 었 음 < 대림 원숭이 어쩌구 > 이모 가 많이 무서웠 다 . 마라 샹 궈 생각 보다 자극 적 이 지 않 았 음 . 그 외 에 먹 은 메뉴 모두 맛있 었 다 . 이 날 대림 에 가 다가 피 흘리 는 할아버지 를 대림 역 에서 목격 하 고 경찰 이 수습 하 는 것 을 보 았 다 . < 대림 화라 룽 샤 > 민물 가재 나 가재 를 주력 상품 으로 하 는 화라 룽 샤 에서 마라 룽 샤 를 먹 었 다 . 위생 장갑 으로 가재 를 깨 고 살 을 발라 낸 뒤 같이 시킨 계란 볶음밥 을 인도인 처럼 손 으로 먹 으면 양념 이 적절 하 여 매우 맛있 다 . 하지만 위생 장갑 을 껴도 손 에 신기 하 게 도 양념 이 조금 베여 있 음 . 이 사실 을 모르 고 적절 은 먹 고 난 뒤 눈 을 비볐 다가 죽음 을 경험 하 였 다 . .... 서울대 입구 < 표 표마 라 탕 > 재료 가 최소한 으로 있 고 정갈 하 고 깨끗 하 며 싸 다 ! ! < 양 떼목 장 > 노 고추 집 주변 인데 극 강의 매 움 을 자랑 한다고 한다 < 두만강 > 양 꼬치 맛있 음 여긴 마 라 탕 2 - 3 인분 해서 다 셋 팅 되 서 나오 고 만 팔 천 원 정도 극 강의 비 쥬얼 을 자랑 함 . .. 퍼먹 는 형식 샹 궈 는 조금 실망 . .. ! 그런데 마라 탕 은 국물 은 진짜 맛있 다 다른 집 마라 탕 과 뭔가 다름 . . 지 삼 선 도 진짜 맛있 다 . 바삭바삭 하 고 과자 같 다 ! ! < 몽중 인 > 분위기 는 좋 다 . 가게 자체 가 홍콩 느낌 이 물씬 . 뭔가 중경 상림 돋 기 도 하궁 . . ㅎ 그런데 마라 탕 은 마라 탕 이 아니 고 백숙 . .?? 삼계탕 에 고춧가루 뿌린 거 먹 는 것 같 은 느낌 이 었 다 . 마라 탕 특유 의 건강 을 해치 는 맛 이 부재 한 . .. 조금 실망 . ..^^.... ㅠㅠ ( 출국 직전 에 먹 은 거 라 좀 . .^^ 실망 . .. 새언니 와 먹 었 는데 언니 가 우리 두만강 갈까 ? 라는 말 을 하 게 한 그런 맛 . ..) 그래도 맛있 긴 맛있 었 다 . 이태원 ( 녹사평 , 경리 단 길 ) < 완 차이 야 > ( 화질 구지 인 것 은 아이폰 탓 일까 아니 면 네이버 블로그 에서 크기 를 줄였 기 때문 일까 . ...?) 홍콩식 마라 탕 집 . 우리 가 치즈 플래터 , 마라 탕 , 마라 샹 궈 를 시키 자 주인장 님 께서 오 셔서 마 라 탕 이 뭔지 아냐 고 물 어 봤 다 . .. 재료 는 고를 수 없 고 알 아서 주 심 . 그래도 재료 푸짐 하 다 . 샹 궈 와 탕 모두 고수 가 올라가 있 었 다 . 아마 빼 달 라고 하 면 빼 주 실 듯 ( 고수 를 싫어하 는 건 아닌데 마 라 탕 먹 고 타이 푸드 가 서 타이 푸드 먹 으니까 너무 향신료 의 향연 이 라 혀 가 피곤 해짐 . ...) 마라 탕 국물 이 여태 까지 먹 은 곳 과 는 조금 달랐 다 . 홍콩식 이 란 이런 걸까 . ..?? 샹 궈 도 예상 가능 한 맛 근데 왠지 유독 맛있 게 느껴졌 음 . 다른 곳 보다 덜 맵 다 ! 그렇 다고 안 매운 건 아님 . 치즈 플래터 는 꽃 빵 , 춘권 등 을 치즈 에 찍 어 먹 을 수 있 는 건데 존 맛 이 다 ㅠㅠ ( 위 사진 참고 ) 체다 치즈 는 항상 옳다 가격대 는 좀 있 음 신 도림 < 하우 마라 탕 > 마라 탕 이 아니 라 거의 설렁탕 이 었 다 . .. 사골 베이스 라고 하 는데 . .. 그래서 한국인 이 면 맛있 게 먹 을 맛 ! ! ( 그리고 채 식인 이 라면 조금 당황 할 맛 . ..) 하지만 약간 . . 위생 . .. 내 가 담 지 않 은 것 . .. 나와 벌여 . .. 조금 . . 맘 에 걸리 는 . .. 그리고 너무나 불친절 했 다 . . ㅠ 강남 < 천진 영감 > 중국 천진 지역 맛 이 라고 하 는데 그냥 한국 화 된 맛 이 아닐까 하 는 . .. 재료 를 고를 수 없 고 그냥 갖 다 준다 . 고수 가 많이 들어가 는데 위 에 있 어서 우리 는 그냥 빼 고 먹 었 다 ( 하지만 전 고수 를 좋아합니다 친구 들 때문 에 뺐 을 뿐 . .) 큰 사이즈 시켜서 고기 당면 추가 했 더니 4 명 이 먹 기에 충분 한 양 이 되 었 다 . 안 에 생선 이 들 어 있 는 게 맛있 었 다 . 순두부 도 들 어 있 고 . .. 그런데 신기 하 게 도 . .. 끓이 면 끓일 수록 단 맛 이 나서 . .. ( 나 뿐 아니 라 다른 블로그 후기 에서 도 ) 사실 난 그래서 단맛 이 너무 강해서 못 먹 었 다 . 그걸 좋아하 는 사람 들 도 있 겠 지만 . .. 3 천 원 짜리 땅콩 빙수 가 아주 맛있 었 으니 완전 추천 . 1 인 1 빙 가능 ! ! 여의도 < 쿵 푸마 라 탕 > 쿵 푸마 라 탕 역시 나 달달 한 국물 의 . . 그런데 마라 샹 궈 1 단계 로 했 더니 정말 아무 자극 이 없 었 다 . 다 들 밍밍 하 다고 했 지만 나 는 그렇게 깊 게 씹 을 수록 맛 이 느껴 지 는 이런 느낌 도 맛있 었 다는 반전 . **************** **************** **************** **************** **************** **************** **************** *************** ********** * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * ************************* 아무튼 앞 으로 저 에게 마라 탕 맛집 정보 를 보내 주 세요 . .. 이 글 은 마라 탕 데이터베이스 를 위한 것 입니다 . 이 를 위한 구글 독스 를 만들 까 하 는 데 그러 면 노 고 추가 졸라 괴롭힌다 ( 지난 학기 같이 팀 플 했 는데 너무나 열심히 해서 우리 정신 적 고통 받 아 벌 엿 다 . 하루 에 논문 세 개 씩 읽 게 함 ) 2019 9 월 1 일 현재 가장 좋 아 하 는 마라 탕 집 은 두만강 이 고 마 라 샹 궈 는 손오공 마라 탕 임 을 밝힙니다\",\n",
       "       '[ 모집 ] 딥 러닝 을 이용 한 자연어 처리 자연 언어 처리 ( 혹은 자연어 처리 : natural language processing ) 는 인간 이 발화 하 는 언어 현상 을 기계 적 으로 분석 해서 컴퓨터 가 이해 할 수 있 는 형태 로 만드 는 자연 언어 이해 혹은 그러 한 형태 를 다시 인간 이 이해 할 수 있 는 언어 로 표현 하 는 제반 기술 을 의미 합니다 . 따라서 자연어 처리 기술 이 발달 하 면 기계 로 하여금 우리 의 언어 를 잘 분석 할 수 있 습니다 . 이번 강의 는 자연어 처리 의 최고 의 전문가 중 한 분 이 신 뉴욕 대 조경현 교수 님 과 함께 합니다 . * 일정 : 2018 년 6 월 11 일 , 12 일 18 시 ~ 22 시 ( 양일 참여 모두 가능 한 사람 ) * 장소 : 네이버 그린 팩토리 커넥트 홀 ( 2 f ) * 신청 방법 : 네이버 폼 으로 신청서 작성 , 대상자 검토 후 참여 가능 여부 개별 연락 * 신청 기한 : 5 월 10 일 ~ 5 월 20 일 까지 세계 적 인 석학 과 함께 하 는 명 강의 를 현장 에서 먼저 들 을 수 있 는 기회 를 잡 으시 고 , 자연어 처리 지식 과 영감 을 얻 어 가 시 길 바랍니다 . 어서 아래 의 링크 를 클릭 하 세요 ! ** 본 강연 은 , 2018 년 7 월 중 , edwith 에서 온라인 으로 공개 됩니다 . 강연자 인 조경현 교수 는 국내 이공 계 분야 의 여성 및 성 소수 연구자 를 지원 하 기 위해 강연료 전액 을 기부 하 였 습니다 . 많 은 분 들 에게 소중 한 배움 의 기회 를 제공 해 주 시 는 교수 님 께 다시 감사 의 말씀 을 드립니다 . [ URL ] q 3 wwko',\n",
       "       '후배 님 으로부터 딥 러닝 공부 방법 을 추천 해 달 라는 부탁 을 받 고 정리 해 본 내용 을 페북 에 도 공유 합니다 . 공부 하 는 시간 순 으로 정리 하 였 습니다 . 0 . 스티브 워즈니악 옹 은 \" all my great stuff , i learned outside of school \" 이 라 했 다 . 누가 가르쳐 주 는 것 을 그대로 배우 는 것 보다 , 스스로 여기저기 헤매 보 면서 이것저것 생각 해 보 고 만들 어 보 는 것 이 가장 좋 다고 생각 한다 . 나 는 그렇게 헤매 면서 여기 까지 왔 고 , 앞 으로 도 열심히 즐겁 게 헤매 고 다닐 것 같 다 . 하 지만 헤매 고 있 을 시간 이 없 는 경우 , 또는 헤매 는 것 이 즐겁 지 않 고 짜증 만 나 는 경우 에 는 먼저 간 사람 이 찾 아 둔 길 을 따라가 는 것 이 좋 겠 다 . 내 가 찾 아 둔 지름길 을 공유 한다 . 1 . 가장 먼저 할 일 은 코세라 의 앤드류 응 교수 님 강의 를 듣 는 것 이 다 . 강의 동영상 은 유튜브 에 도 모두 공개 되 어 있 다 . 하지만 꼭 코세라 에서 들으면서 옥타브 로 숙제 를 해 봐야 한다 . 무료 로 도 들 을 수 있 지만 , 79 달러 를 내 고 들으면 강의 내용 이 머리 속 에 더 잘 들 어 오 게 된다 . 진짜 다 . * 코세라 의 앤드류 응 교수 님 의 머신 러닝 강의 : [ URL ] [ URL ] / certificate / machine - learning * 다른 스타일 의 강의 들 모음 : [ URL ] [ URL ] / dgtgrade / posts / 1145680742157457 한국어 강의 를 원하 면 김성훈 교수 님 의 [ 모두 를 위한 딥 러닝 ] 강의 를 들으면 된다 . * 모두 를 위한 딥 러닝 : [ URL ] youtu . be / bs 6 o 0 zogx 4 e ? list = pllmkm 4 tgfjnls ojrejn 31 gzatbcj _ mpum 혹시 그냥 엄청나 게 쉬운 강의 부터 시작 하 고 싶 으면 휴먼 러닝 을 들으면 된다 . * 휴먼 러닝 : [ URL ] youtu . be / crakdnk 2 w 9 c ? list = plefqda 1 sdkhtr uun _ d 3 pdxar 2 xtg qw 8 ph 2 . 1 번 의 강의 를 듣 다 보 면 금새 선형 회귀 와 신경망 의 기초 에 대해서 알 게 된다 . 이때 universal approximation theorem 에 대해서 공부 한 뒤 간단 한 신경망 을 직접 python + numpy 로 구현 해 봐야 한다 . * 참고 글 : [ URL ] [ URL ] / groups / tensorflowkr / permalink / 332680743739657 꼭 python 으로 해야 하 는 건가 ? 아니 다 . 그럴 리 가 없 지 않 은가 . 하지만 내 가 추천 하 는 지름길 은 python 이 다 . 그게 대세 이 기 때문 이 다 . 대세 가 꼭 나 나 너 에게 맞 는 것 은 아니 지만 대세 를 따르 면 편하 다 . 이 글 은 어디 까지 나 지름길 에 대한 글 이 지 나 의 길 이나 너 의 길 에 대한 글 이 아니 다 . python 이 생소 하 더라도 괜찮 다 . python 은 초기 진입 장벽 이 매우 낮 은 언어 이 므로 겁먹 을 필요 없 다 . 처음 에 는 numpy 의 신택스 가 좀 어려워 보일 수 있 는데 익숙 해 지 고 나 면 numpy 없 으면 못 살 거 같 은 느낌 이 들 정도 로 numpy 는 멋진 것 이 다 . python + numpy + 기타 등등 의 설치 의 지름길 은 anaconda 다 . ide 는 나 는 pycharm 을 사용 하 고 있 다 . 원래 vi 를 사랑 하 고 ( 진짜 로 ) 지금 도 사랑 하 지만 pycharm 써 보 고 나 니 앞 으로 적어도 python 코딩 은 vi 에서 는 못 할 것 같 다 . 개발 환경 준비 에 대한 더 상세 한 내용 은 아래 의 영상 을 참고 하 면 된다 . * 머신 러닝 개발 환경 준비 : [ URL ] youtu . be / pmkwjxfzdh 4 ? list = plefqda 1 sdkhtr uun _ d 3 pdxar 2 xtg qw 8 ph 3 . 신경망 과 python , 그리고 numpy 가 어느 정도 익숙 해 지 고 나 면 드디어 tensorflow 를 사용 해 볼 때 다 . 마찬가지 로 꼭 tensorflow 여야 하 는가 ? 하 는 질문 이 있 을 수 있 다 . 아니 다 . 하 지만 tf 가 대세 다 . 앞 에서 지도 학습 문제 를 풀 어 봤 으므로 이제 는 비지 도 학습 문제 를 풀 어 볼 때 가 되 었 다 . 비지 도 학습 이 란 것 을 이해 할 수 있 는 가장 쉬운 방법 은 auto encoder 를 직접 만들 어 보 는 것 이 다 . 그리고 데이터 는 머신 러닝 의 헬로 월드 인 mnist 를 사용 하 면 된다 . 즉 , 목표 는 mnist ae 를 만드 는 것 이 다 . 아직 은 cnn 에 대해서 모르 므로 괜히 어렵 게 cnn 으로 하 지 말 고 fc 로 만 해도 된다 . mnist 는 너무 쉬운 문제 라서 fc 로 해도 잘 된다 . tensorflow 가 너무 빨리 업그레이드 되 고 , 스펙 도 많이 변하 고 있 어서 , 겨우 몆주전에 올라온 글 의 정보 가 현재 상황 과 맞 지 않 거나 , 예 제 코드 가 지금 은 잘 안 돌아가 기 도 하 는데 그 점 주의 해야 한다 . 웹 에서 구한 예제 코드 가 바로 안 돌아간다고 겁먹 을 필요 없 다 . 대부분 아주 살짝 씩 만 수정 해 주 면 돌아갈 거 다 . 어떻게 수정 할 지 는 스택 오버 플로우 가 알려 줄 거 다 . 그리고 윈도우 에서 도 tensorflow 잘 돌아간다 . gpu 도 잘 이용 할 수 있 다 . 더 심각 하 게 머신 러닝 을 열심히 잘 해 보 려면 결국 리눅스 로 가 는 게 이래저래 편하 긴 하 다 . tf 외 의 라이브러리 들 이 윈도우 에서 잘 안 되 는 경우 들 이 간혹 있 다 . 하지만 일단 이 글 에서 다루 는 지름길 의 범위 내 에서 는 그냥 윈도우 에서 해도 문제 없 다 . 4 . 여기 까지 왔 으면 딥 러닝 이 어떤 것 인지 대강 감 은 잡힌다 . 이제 부터 신나 게 이것저것 공부 하 고 만들 어 보 고 하 면 된다 . 그런데 역시 시간 을 아끼 고 싶 으면 추가 로 아래 글 도 읽 어 보 고 길 을 떠난다 . * 참고 글 : [ URL ] [ URL ] / dgtgrade / posts / 1328790023846527 5 . 이제 부터 는 훨씬 더 큰 규모 의 신경망 을 다뤄야 하 고 , 그러 려면 relu 와 친해져야 한다 . relu 에 대해서 진지 하 게 고민 해 볼 필요 가 있 다 . relu 가 왜 비선형 인지 ? 뉴런 에서 비 선형 처리 부분 이 없 어 지 면 어떻게 되 는 것 인지 ? 왜 sigmoid 보다 relu 가 좋 은 것 인지 ? 등 에 대해서 고민 해 본다 . * 참고 글 : [ URL ] [ URL ] / dgtgrade / posts / 1337481972977332 추가 로 bias 가 없 으면 어떻게 되 는지 등 신경망 전체 의 수학 적 의미 에 대해서 다각도 로 고민 해 본다 . sigmoid , tanh 를 사용 한 경우 괜히 어렵 게 느껴 지 지만 relu 를 사용 한 경우 신경망 전체 계산 에서 곱하 기 , 더 하 기 , max 밖 에 없 어서 어렵 게 생각 할 것 없 다 . 머리 속 에서 만 고민 해 보 지 말 고 코딩 을 해 보 면 좋 다 . 여기 까지 왔 으면 이런 저런 실험 코딩 은 어렵 지 않 을 거 다 . 6 . 지금 까지 해 본 것 보다 훨 신 큰 규모 의 신경망 을 학습 시키 기 위해서 는 gpu 가 필요 하 다 . cpu 로 할 때 보다 10 배 ~ 50 배 정도 빠르 게 학습 시킬 수 있 다 . cpu 로 하 면 뭐 하나 돌려 보 고 드라마 하나 보 고 자리 에 돌아와 보 면 에러 떠 있 다 . 같 은 것 을 gpu 로 돌려 보 면 차 한 잔 할 새 도 없이 에러 가 떠 있 을 것 다 . cpu 로 하 면 돌려 놓 고 다음 날 아침 이 되 어서 야 결과 를 볼 수 있 는 경우 가 꽤 있 다 . 죽 는다 . 답답 해서 . gtx 1080 이 필요 하 다 . ( 상세 설명 생략 하 고 ) 대세 다 . 문제 는 가격 인데 대강 100 만 원 정도 한다 . 그리고 1 개 보다 2 개 가 좋 다 . 학습 을 2 배 로 빨리 할 수 있 기 때문 만 은 아니 다 . 1 개 밖 에 없 는 경우 에 는 하나 학습 돌려 놓 은 뒤 로 추가 로 개발 진행 한 내용 을 잠깐 만 실험 삼 아 돌려 보 는 것 을 할 수 없 기 때문 이 다 . 아주 할 수 없 지 는 않 을 것 같 은데 아무튼 쉽 지 않 다 . 그런데 이 녀석 을 2 개 나 꼽 으려면 메인보드 와 파워 도 좋 아야 한다 . 그리고 gtx 1080 은 딥 러닝 용 으로 만 사용 하 고 디스플레이 용 으로 는 메인보드 의 내장 그래픽 카드 를 사용 하 는 것 이 여러모로 편하 므로 내장 그래픽 카드 도 쓸 만 해야 한다 . 예 를 들 어 4 k 모니터 를 사용 중 이 라면 내장 그래픽 카드 가 4 k 를 지원 해야 하 겠 다 . 이렇게 해서 준비 하 면 본체 에 만 대략 총 300 만 원 정도 의 투자 가 필요 하 다 . 학교 나 회사 등 의 조직 에 속한 경우 에 는 조직 장 을 잘 ( ...) 설득 하 여 구매 하 면 된다 . 개인 의 경우 에 는 . .. 그렇 다 . 이런 투자 를 쉽 게 하 기 는 어려울 거 다 . 문제 다 . 조직 이 든 개인 이 든 당장 이 정도 의 투자 가 어려운 경우 에 는 aws 나 google cloud 등 을 이용 하 는 것 도 방법 이 겠 다 . 아무래도 개발 은 로컬 에서 하 는 것 이 편할 테 니 개발 은 로컬 에서 하 고 cpu 로 만 돌려 본 후 에 본격 적 인 학습 은 클라우드 에서 gpu 로 돌리 면 되 겠 다 . 코드 변경 은 필요 없 고 , 클라우드 사용료 는 시간 당 몇 백 원 수준 이 라고 한다 . 나 는 클라우드 에서 는 열심히 해 본 적 이 없 어서 더 상세 한 안내 는 못 한다 . 7 . 이제 드디어 개 와 고양이 를 분류 해 볼 수 있 는 때 가 왔 다 . convolutional neural network 를 사용 하 면 된다 . cnn 을 공부 하 고 , cnn 을 이용 해서 무언가 재밌 는 걸 만들 어 본다 . 이렇게 딥 러닝 이 핫 하 게 된 것 도 cnn 때문 이 다 . cnn 으로 는 많 은 일 을 해 볼 수 있 다 . 수백 줄 정도 의 tf 코드 로 만 으로 도 본인 스스로 놀 랄 만한 신기 한 것 들 을 만들 어 볼 수 있 다 . 매우 잘 만들 면 세상 사람 들 도 놀래 킬 수 있 다 . * 참고 글 : [ URL ] [ URL ] / groups / tensorflowkr / permalink / 341049512902780 용기 있 는 사람 들 은 이쯤 에서 gan 을 해 봐도 된다 . gan 은 정말 . .. 기발 하 고 기특 한 녀석 이 다 . * 참고 글 : [ URL ] [ URL ] / groups / tensorflowkr / permalink / 420422164965514 8 . 그런데 막상 이렇게 큰 신경망 을 다루 려다 보 면 이런 저런 이유 로 잘 안 될 거 다 . 그러면 이제 batch normalization 을 적용 해야 한다 . bn 은 감동 이 다 . 앞 에서 얘기 한 이런 저런 문제 들 중 기초 적 인 문제 들 을 한방 에 해결 해 준다 . * 참고 글 : [ URL ] [ URL ] / dgtgrade / posts / 1337790532946476 9 . 이제 강화 학습 을 공부 해 볼 수 있 다 . 알 파고 는 바로 이 강화 학습 으로 만들 어 졌 다 . 강화 학습 은 openai gym 에서 진행 하 는 것 이 좋 다 . 이 쯤 되 면 더 이상 이런 단편 적 인 내용 의 글 이 필요 할 것 으로 생각 하 지 않 는다 . 10 . 각자 의 길 을 간다 . 다만 남 들 이 고민 해 둔 거 그대로 공부 만 하 려 하 지 말 고 , 또 공부 많이 한 다음 뭔가 만들 어 보 려 하 지 말 고 , 간단 한 뭔가 라도 실제로 만들 어 보 면서 공부 하 기 를 추천 한다 . 물론 대부분 의 경우 찾아보 면 분명히 남 들 이 이미 더 잘 정리 하 고 잘 만들 어 둔 것 이 있 을 거 다 . 하지만 본인 이 직접 만들 어 보 면서 1 ) 문제 를 발견 하 고 2 ) 해결책 을 고민 해 보 고 하 는 것 이 남 들 이 정리 해 둔 문제 와 해답 을 먼저 보 는 것 보다 훨씬 공부 가 많이 된다 . 특히 답 이 아니 라 문제 가 뭔지 를 스스로 발견 하 는 과정 은 매우 중요 하 다 .',\n",
       "       '일제 하 조선 평양부 대동문 통 에 자리 를 잡 고 , 주인 의 이름 을 옥호 에 내건 림 중식 면옥 ( 林 仲 植 麵屋 ) 은 상당 한 규모 의 면옥 이 었 다 . 종업원 이 10 이나 됐으니 말 이 다 . 그러나 이 집 의 종업원 대우 는 시원찮 았 다 . 1927 년 2 월 7 일 밤 에 벌어진 일 이 다 . 허기진 종업원 열 사람 앞 에 림 중식 이 내 어 준 밥 은 며칠 묵 은 데 다 얼기 까지 한 밥 이 었 다 . 종업원 들 은 제 몫 의 끼니 를 보 고 “ 포악 ” 하 다고 느꼈 다 . 또한 “ 분개 ” 했 다 . 반죽 꾼 으로 일 하 던 김치 문 은 행동 이 앞섰 다 . 김치 문 은 밥그릇 을 내던졌 다 . 김치 문은 “ 주인 에게 행패 를 부 ” 렸 고 , 그 뒤 전 종업원 파업 이 시작 되 었 다 ( ‘ 조선일보 ’ 1927 년 2 월 11 일자 ) . 왕조 의 실록 과 의궤 , 그리고 고조 리서 와 이른바 반가 와 종가 에 전해 온다는 비법 만 을 전통 의 전부 로 생각 하 는 순간 , 한국 음식 문화사 에 대한 이해 와 설명 은 지나치 게 성글 어 진다 . 성글 어 지 다 못해 거짓말 이 될 수 밖에 없 다 . 근 100 년 간 한국 음식 문화 의 충격 이란 , 요컨대 전 에 없 던 음식 상품 화 의 충격 이 다 . 음식 이 이윤 과 임금 노동 이 라는 맥락 에서 태어날 수 밖에 없 는 세상 을 맞 은 사회 경제사 의 충격 이 다 . 음식점 이 라는 전 에 없 던 제도 를 처음 대한 대중 이 느낀 충격 이 다 . 또한 음식점 음식 과 공장 생산 식품 에 대한 선망 을 대중 과 대중 매체 가 서로 함께 증폭 시키 며 만들 어 낸 충격 이 다 . 이 충격 을 보통 사람 의 가정 이 고스란히 받아들인 충격 이 다 . 실록 과 의궤 와 고조 리서 와 한 집안 비법 은 이 를 담 을 이유 가 없 다 . 이 들 자료 는 오히려 앞서 말 한 충격 이 그 전 에 는 없 었 음 을 역설 적 으로 드러내 는 자료 이 다 . 국가 와 가문 의 의례 에 나온 음식 에 어디 관능 상 의 평가 가 껴들 겠 는가 . 공동체 안 에 머문 음식 과 대중 을 상대 로 하 는 음식 은 태생 이 다르 다 . “ 주인 에게 횡포 ” 음식 노동 사 블랙리스트 다시 1927 년 으로 돌아가 자 . 이때 는 조선 대 도시 의 음식점 영업 이 완전히 자리 를 잡 은 때 다 . 더구나 조선 의 제 2 도시 평양 은 1924 년 에 인구 10 만 을 돌파 하 고 , 1930 년 대 말 인구 30 만 을 돌파 하 는 등 무섭 게 성장 하 는 도시 였 다 . 평양 은 도시 성장 과 함께 무려 50 군데 나 되 는 면옥 이 성업 한 냉면 의 도시 였 다 . 이제 얼음 은 사계절 내내 공급 된다 . 고조 리서 제면 의 전제 는 제분 이 다 . 그런데 제분업 이 성장 하 면서 공장 이 공급 한 메밀가루 가 얼마 든지 시장 에 나왔 다 . 육수 맛 에 요술 을 부릴 인류 역사 상 첫 msg 인 아지노모토 는 1910 년 8 월 조선 에 상륙 했 다 . 면발 에 탄력 을 더 할 “ 면소 다 ” , 즉 식용 탄산 수소 나트륨 도 주인 이 쓰 기 로 결심 하 면 없 어서 못 쓸 일 은 없 는 세상 이 되 었 다 . 냉면 의 진짜 대중 화 가 이루 어 졌 고 , 그만큼 냉면 일 을 할 인력 이 더 필요 했 다 . 면옥 일 은 한 철 의 날품팔이 로 감당 할 수 가 없 었 다 . 면옥 은 노동자 를 고용 해 분업 체제 를 갖추 었 다 . 면옥 의 주방 에 반죽 을 맡 은 반죽 꾼 , 면 을 삶 는 발대 꾼 , 면 을 찬물 에 헹구 는 앞잡이 , 손 님 에게 나가 기 직전 냉면 의 화룡점정 장식 을 담당 한 고명 꾼 같 은 새로운 주방 노동자 가 나타났 다 . 주방 밖 에서 도 사람 이 필요 했 다 . 여느 음식점 에서 배달 을 맡 은 이 들 은 그저 배달부 로 불렸 지만 , 냉면 을 배달 하 는 이 들 은 따로 “ 중머리 ” 라고 부를 정도 로 대중 에게 별난 존재 로 인식 되 었 다 . 면옥 영업 은 도시 에 이채 를 더 하 는 새로운 문물 이 었 다 . 묵 고 언 밥 을 내던진 반죽 꾼 은 숙련 노동 자 였 다 . 앞서 나온 행패 란 분 을 참 지 못한 자 의 욕설 과 주먹질 이 었 을 것 이 다 . 아예 밥상 까지 엎 었 는지 도 모르 겠 다 . 숙련 노동자 를 비롯 한 종업원 이 파업 을 결심 하 자 림 중식 면옥 도 멈추 어 섰 다 . 가진 사람 들 의 대응 또한 빠르 고 확실 했 다 . 면옥 주인 들 이 결성 한 평양 면옥 조합 은 즉시 임시 평의원 회의 를 개최 했 다 . 그 들 은 “ 주인 에게 횡포 한 행동 을 하 는 직공 은 일체 사용 치 않 기 로 결의 ” 했 다 . 음식 노동 사상 블랙리스트 의 탄생 이 다 . 아울러 이 결의 를 어긴 면옥 에 대해서 는 3 원 의 벌금 을 물리 기 로 결의 했 다 . 여기 서 끝날 리 가 없 다 . 일제 평양 경찰 은 평양 면옥 조합 의 결의 직후 김치 문 을 포함 해 모두 4 명 의 조합원 을 구속 했 다 . 이 들 을 붙잡 아 경찰서 에 몰아넣 는 데 에 는 “ 고등계 ” 가 나섰 다 . 일제 고등계 란 독립운동 과 반제국주의 활동 을 감시 하 고 정치범 과 사상범 을 담당 한 고등 경찰 을 이른다 . 노동 운동 탄압 또한 고등 경찰 의 중요 업무 였 다 . 평양 면옥 노조 ‘ 착취 ’ 에 맞서 뭉치 다 새 시대 의 냉면 이 불티나 게 팔리 고 , 전 에 없이 면옥 이 성장 하 는 만큼 면옥 에 고용 된 노동자 들 의 노동 운동 또한 꾸준히 성장 하 고 있 었 다 . 김치 문 이 밥그릇 을 던지 기 전 에 , 이미 면옥 노동자 들 은 일제 고등 경찰 이 신경 을 곤두세울 만 한 행동 을 한 적 이 있 다 . 1925 년 평양 시내 면옥 노동자 들 은 “ 착취 ” 와 “ 학대 ” 에서 벗어나 기 위해 조직 화 에 들어섰 고 , 1925 년 4 월 에 는 270 명 조합원 가운데 208 명 의 노동자 가 동맹 파업 에 들어갔 다 . 일터 는 달랐 지만 노동자 는 단결 의 힘 을 알 고 있 었 다 . 평양 면옥 노동조합 으로 불린 이 들 은 산별 노조 처럼 행동 했 다 . 1925 년 4 월 25 일 이 들 은 고용주 를 상대 로 임금 인상 외 에 본 조합 에 가입 하 지 않 은 자 를 채용 하 지 말 것 , 채용 과 해고 에서 본 조합 의 승인 을 얻 을 것 등 을 요구 했 다 . 더욱 눈 에 들어오 는 것 은 일요일 과 각 면옥 의 휴업 일 을 유급 휴일 로 할 것 을 요구 한 점 이 다 . 이 들 은 그 누구 보다 현대 를 이해 한 현대인 이 었 다 . 이 들 은 전략 을 가지 고 움직였 다 . 조합원 208 명 은 4 월 30 일 다시 평양 시내 에 집결 했 다 . 그러 고 는 한층 수위 가 높 은 파업 을 결의 한다 . 초파일 곧 석가 탄신일 은 당시 공휴일 은 아니 었 지만 제등 행렬 같 은 볼거리 가 있 어 잔치 분위기 가 있 는 날 이 었 다 . 대 도시 시민 들 은 이 날 을 휴일 아닌 휴일 로 여겼 다 . 덕분 에 냉면 주문 이 폭 증 하 는 면옥 의 대목 이 었 다 . 1925 년 초파일 , 평양 시내 면옥 은 간신히 문 만 열 었 다 . 주인 과 온 가족 이 매달려 노동자 없이 문 을 연 것 이 다 . 그러나 중머리 의 배달 은 포기 해야 했 다 . 이윽고 평양 경찰서 고등계 가 중재 에 나섰 다 . 이날 오후 3 시 평양 면옥 노동조합원 들 은 중재 를 받아들여 복귀 했 다 . 임금 인상 안 , 유급 휴일 보장 , 이번 총동맹 파업 을 이유 로 어떤 해고 자 도 내 지 않 을 것 등 을 경찰 중재 로 면옥 주인 들 과 합의 했 기 때문 이 다 . 그러나 다시 어디 서 본 것 같 은 일 이 벌어졌 다 . 평양 면옥 가운데 김제룡 랭 면 집 , 석기 태 랭 면 집 , 신영우 랭 면 집 등 에서 50 명 의 노동자 를 해고 한 것 이 다 ( 이 기간 ‘ 동아일보 ’ 참조 ) . “ 조합원 은 비통 함 을 참 지 못하 고 울 었 다 ” 시대 가 바뀌 었 다 . 일터 가 새롭 고 , 일 이 새로웠 건만 자본가 또는 실업가 라고 하 기 뭣 한 “ 주인 ” 들 은 주방 에서 가부장 노릇 을 했 다 . 그 들 의 일제 경찰 의존 은 농민 의 저항 이 일어나 면 원님 바짓가랑이 를 붙들 던 토반 지주 의 행태 와 별로 다르 지 않 다 . 이런 우스운 짓 도 했 다 . 1925 년 11 월 평양 내 면옥 주인 들 은 육수 에 닭 육수 를 덧 국 으로 쓰 거나 아지노모토 를 쓰 지 않 기 로 결의 해 세상 의 비웃음 을 샀 다 . 면옥 간 경쟁 을 줄이 고 , 하루 2 ~ 3 원 을 아끼 기 위해서 라는 이 결의 는 현대 적 경영 과 동떨어진 구시대 적 작태 일 뿐 이 다 . 내 업장 에서 일 하 는 사람 에게 언 밥 내놓 는 마음 이 여기 깃들 어 있 다 . 일제 경찰 은 일제 경찰대 로 조선 노동자 단결 이 이 세상 에서 제일 보 기 가 싫 은 노릇 이 었 을 것 이 다 . 이런 때 에 면옥 노동자 들 은 내 삶 을 누구 에게 구걸 하 지 않 았 다 . 단결 했 다 . 연대 했 다 . 그리하여 구시대 인물 과 일제 경찰 을 협상 과 중재 의 자리 로 끌어냈 다 . 속 시원 한 한 방 의 해결 을 손 에 쥐 지 는 못했 지만 면옥 노동자 들 은 무릎 을 꿇 지 도 않 았 다 . 같 은 해 12 월 에 는 부산 에서 파업 중 인 인쇄 노동자 들 에게 29 원 32 전 을 모금 해 전달 하 기 도 했 다 . 조합원 과 시민 을 향한 강연회 도 꾸준히 이어 갔 다 . 이 들 이 초빙 한 연사 들 은 대개 일제 경찰 이 “ 불온 ” 딱지 를 붙일 만 한 인물 이 었 다 . 1930 년 에 는 평양 시내 일곱 군데 악덕 면옥 을 습격 해 폭동 을 일으키 기 도 했 다 . 1931 년 에 는 조합 결성 기념식 까지 성대히 열 었 다 . 평양 외 에 도 사리원 , 해주 , 원산 , 신의주 등 오늘날 에 도 냉면 과 함께 떠오르 는 서울 이북 도시 가 다 면옥 노조 가 대단 했 던 곳 이 다 . 그러나 1930 년 대 후반 이 면 어떤 노동 운동 도 일제 의 탄압 을 더 이상 견디 기 어려웠 다 . 평양 면옥 노동조합 소식 도 잦아들 던 1936 년 4 월 23 일 , 지난 11 년 간 활동 한 사리원면옥 노동조합 마저 일제 경찰 의 해산 명령 으로 하루 아침 에 해산 된다 . 단결 과 상부상조 를 통해 사리원 시민 의 지지 와 공감 을 이끌 어 낸 노동조합 이 었 지만 독일 , 이탈리아 와 짝패 가 된 무시무시 한 일제 를 이겨낼 길 은 없 었 다 . 해산 하 는 날 “ 조합원 오 십 여 명 은 비통 함 을 참 지 못하 고 ” 울 었 다 . 최근 100 년 의 음식 문화사 를 쫓 다 보 면 어김없이 만나 는 풍경 이 있 다 . 바로 논밭 과 산골 과 포구 에서 음식 자원 을 놓 고 벌어진 전 에 없 던 싸움 이 다 . 새 음식점 만큼 새로운 노동 운동 의 탄생 이 다 . 전 에 없 던 것 은 냉장고 나 아지노모토 만 이 아니 다 . 1919 년 3 ㆍ 1 운동 은 때 가 안 됐 는데 쓸데없이 거리 에 나섰 다가 사람 들 이 다치 거나 죽 은 일 일까 . 평양 면옥 노동조합 의 총파업 , 김치 문 의 밥그릇 , 사리원면옥 노동조합 의 눈물 이 다 잊 을 수 없 는 음식 문화사 의 한 장면 이 다 . 우리 가 냉면 한 그릇 먹 기 까지 만만 찮은 역사 를 지나왔 음 을 떠올리 게 하 는 한 순간 이 다 . 고영 음식 문헌 연구자 공동 기획 : 한국일보 ㆍ인문학협동조합 0 0 공유 기사 저장 한국일보 뉴스 네이버 채널 구독 하 기',\n",
       "       '언론 팩 트 체크 결과 136 건 중 111 건 거짓 . .. “ 인포 데 믹 은 인류 의 적 ” ‘ 총선 앞 검사 축소 ’ ‘ 공 적 마스크 개인 정보 中 유출 ’ 등 검증 없이 확산 “ 인포 데 믹 ( infodemic ) 역시 우리 의 적 이 다 . ” 지구촌 전체 가 신종 코로나 바이러스 감염증 ( 코로나 19 ) 으로 몸살 을 앓 던 지난달 28 일 , 안토니우 구테 흐 스 유엔 사무총장 은 이 같이 말 했 다 . 코로나 19 가 ‘ 인류 공동 의 적 ’ 임 은 두말 할 필요 가 없 겠 지만 , 그 에 못잖 은 또 하나 의 심각 한 위협 도 실재 하 고 있 다는 뜻 이 었 다 . 인포 데 믹 은 정보 ( information ) 와 팬데 믹 ( pandemic ㆍ 세계 적 대유행 ) 의 합성어 로 , ‘ 잘못 된 정보 가 유행병 처럼 빠른 속도 로 퍼지 는 현상 ’ 을 가리킨다 . 자의 든 타의 든 , 거짓 정보 로 대중 을 호도 하 는 결과 를 야기 하 는 이른바 ‘ 가짜 뉴스 ( fake news ) ’ 에 대한 경계심 이 잔뜩 배 어 있 는 발언 이 었 던 셈 이 다 . 물론 사실 과 다르 다고 무조건 가짜 뉴스 가 되 는 건 아니 다 . 원래 가짜 뉴스 란 겉 으로 는 ‘ 언론 보도 ’ 의 형태 를 띠 지만 , 누군가 가 어떤 의도 를 갖 고 조작 해서 교묘히 만들 어 낸 ‘ 속임수 뉴스 ’ 를 일컫 는 개념 이 었 다 . 그러나 용어 가 내뿜 는 강렬 한 아우라 탓 인지 너도나도 마구 사용 하 면서 그 의미 가 대폭 확장 됐 다 . 예컨대 사실 검증 을 제대로 하 지 못한 채 기사 화 한 언론 의 오보 ( 誤報 ) 도 요즘 엔 ‘ 가짜 뉴스 ’ 로 불릴 때 가 있 다 . 심지어 활자 화 되 지 도 않 은 , 시중 에 떠도 는 소문 이나 의혹 을 당사자 가 반박 할 때 에 도 ‘ 가짜 뉴스 ’ 라는 표현 이 동원 된다 . 때문 에 학계 에선 가짜 뉴스 의 개념 이 지나치 게 광범위 해 지 면서 모호 해진 이상 , 다른 표현 을 써야 한다는 주장 이 힘 을 얻 고 있 다 . 사람 들 을 속이 려는 목적 성 을 띠 고 고의 적 으로 만든 정보 를 뜻 하 는 ‘ 허위 정보 ( disinformation ) ’ 와 의도 치 않 은 실수 로 생성 된 ‘ 잘못 된 정보 ( misinformation ) ’ 는 구분 해서 사용 해야 한다는 것 이 다 . 그럼에도 불구 , 이미 대중 속 으로 파고든 ‘ 가짜 뉴스 ’ 개념 은 사실 이 아니 거나 근거 가 희박 한 데 도 사람 들 이 믿 을 법 한 거짓 정보 전체 를 통칭 하 는 의미 로 통용 되 고 있 는 실정 이 다 . 한국일보 는 코로나 19 사태 와 관련 , 광의 의 개념 에서 바라본 가짜 뉴스 의 실태 와 현주소 를 짚 어 보 기 로 했 다 . 이 를 위해 먼저 가짜 뉴스 의 유통 ㆍ확산은 결국 기존 언론 과 도 밀접 한 관련 이 있 다는 데 착안 , 대중 의 관심 을 끌 었 던 코로나 19 정보 들 에 대한 각 매체 의 사실 검증 ( 팩 트 체크 ) 활동 을 분석 해 봤 다 . 그 결과 , ‘ 사회 적 혼란 땐 가짜 뉴스 가 급증 한다 ’ 는 속설 처럼 실제로 코로나 19 위 기 국면 을 틈타 허위 정보 가 무더기 로 쏟아져 나온 것 으로 파악 됐 다 . 서울대 언론 정보 연구소 산하 snu 팩 트 체크 센터 ( factcheck . snu . ac . kr ) 에 따르 면 , 올해 들 어 국내 언론사 30 곳 이 자체 판단 에 따라 사실 여부 를 따져 본 총 230 건 의 정보 ( 이달 16 일 기준 ) 가운데 59 %( 136 건 ) 는 코로나 19 관련 이 었 던 것 으로 집계 됐 다 . 그리고 이 중 80 % 이상 ( 111 건 ) 은 거짓 ( ‘ 전혀 사실 아님 ’ 61 건 , ‘ 대체로 사실 아님 ’ 50 건 ) 으로 드러났 다 . 인터넷 과 사회관 계망 서비스 ( sns ) 등 을 통해 유포 된 코로나 19 관련 미확인 정보 들 가운데 언론 이 주목 했 던 10 건 중 8 건 은 허위 내용 이 었 다는 얘기 다 . 다만 전수 조사 가 아니 었 고 , 무작위 추출 방식 이 아닌 언론 의 취사 선택 에 따른 정보 검증 이 었 다는 점 은 한계 로 지적 되 지만 , 적어도 ‘ 코로나 19 관련 가짜 뉴스 가 적 지 않 았 다 ’ 는 추론 은 충분히 가능 해 보인다 . 정은령 snu 팩 트 체크 센터 센터 장 은 “ 위기 상황 에선 자신 과 지인 들 을 보호 하 기 위해 최대한 많 은 정보 를 수집 하 려는 욕구 가 있 다 ” 며 “ 그만큼 허위 정보 가 확산 하 기 도 쉬운 여건 이 되 는 것 ” 이 라고 말 했 다 . 그 는 “ 코로나 19 와 관련 해선 ‘ 전문가 가 말 했 다 ’ ‘ 해외 논문 에 따르 면 ’ 등 의 표현 까지 들어가 있 어 신뢰 할 만 한 수준 으로 인식 된 허위 정보 가 많 았 던 게 특징 ” 이 라고 설명 했 다 . ◇ 허위 정보 , 특정 진영 입맛 대로 편집 ㆍ확산 이 처럼 가짜 뉴스 는 시점 이 문제 일 뿐 , 언젠가 는 언론 이나 정부 기관 등 에 의해서 걸러 지 는 게 대부분 이 다 . 그러나 문제 는 그리 간단 치 않 다 . 의도 했 든 아니 든 , 기성 언론 에 의한 ‘ 가짜 뉴스 확대 재 생산 ’ 이 적 지 않 기 때문 이 다 . 여기 엔 특정 세력 의 ‘ 의도 ’ 마저 종종 개입 한다 . 코로나 19 위 기 국면 에서 도 마찬가지 였 다 . 4 ㆍ 15 총선 을 앞두 고 큰 논란 을 부른 ‘ 정부 가 코로나 19 확진 자 수 를 줄이 기 위해 검사 를 막 고 있 다 ’ 는 허위 정보 가 대표 적 사례 다 . 단초 가 된 건 지난달 말 쯤 인천 소재 한 종합 병원 에 근무 하 는 심장 내 과 전문의 a 씨 가 페이스북 에 올린 댓글 이 었 다 . 여기 서 a 씨 는 “ ( 정부 가 ) 검사 를 못 하 게 하 고 있 다 . 총선 전 까지 는 검사 도 확진 도 늘 지 않 을 것 같 다 ” 고 밝혔 다 . 당시 만 해도 확인 되 지 않 았 던 a 씨 주장 은 지난달 30 일 보수 성향 으로 추정 되 는 한 페이스북 이용자 등 이 “ 정부 의 사악 한 짓 을 퍼트 려 달 라 ” 면서 문제 의 댓글 캡처 사진 을 게재 하 면서 급속히 퍼지 기 시작 했 다 . 다음 날 엔 구독자 100 만 명 이 넘 는 보수 유튜브 채널 ‘ 신 의 한수 ’ 에 ‘ 의사 양심선언 ! 정부 가 코로나 검사 를 막 고 있 다 ! ’ 는 제목 의 영상 이 업로드 됐 다 . a 씨 의 댓글 내용 은 기정사실 화 됐 다 . 이후 페이스북 에 는 이 영상 링크 와 함께 ‘ 충격 , 정부 가 코로나 검사 를 막 고 있 다 ’ 는 취지 의 글 이 잇따라 게시 됐 다 . 하 지만 ‘ 검사 축소 ’ 의혹 은 지난달 31 일 부터 주요 언론 들 이 팩 트 체크 를 통해 ‘ 사실 아님 ’ 판정 을 내리 며 일단락 되 는 듯 했 다 . 그런데 끝 이 아니 었 다 . 총선 이틀 전 인 13 일 , 일간지 의 논설위원 이 문제 의 a 씨 댓글 을 인용 하 며 ‘ 정부 의 확진 자 조 작설 ’ 을 다시 끄집어낸 탓 이 다 . 이 보다 10 여 일 전 , 같 은 언론사 가 기사 를 통해 ‘ 사실 이 아니 다 ’ 라고 일축 했 던 허위 정보 의 불씨 를 되살려 낸 것 이 다 . 보건복지부 가 곧바로 “ 의사 소견 에 따라 코로나 19 가 의심 되 면 바로 진단 검사 를 할 수 있 다 ” 고 정면 반박 했 지만 , 이 를 이용 하 고 싶 은 정치 권 은 가만 있 지 않 았 다 . 이튿날 인 14 일 김종인 미래 통합 당 총괄 선거 대책 위원장 은 “ 의심 증상 이 있 어도 엑스레이 ( x - ray ) 로 폐렴 이 확인 돼야 코로나 19 검사 를 할 수 있 게 만들 었 다 . 총선 까지 는 확진 자 수 를 줄이 겠 다는 것 ” 이 라고 주장 하 며 맞장구 를 쳤 다 . 선거 를 하루 앞두 고 해당 의혹 을 재 점 화 해 보 려는 의도 가 명백 했 다 . 결국 이 사건 은 의사 a 씨 의 ‘ 반성문 ’ 으로 마무리 됐 다 . 지난 17 일 그 는 페이스북 을 통해 “ ( 의도 와 는 달리 ) 제 글 이 정부 가 감염 을 숨기 기 위해 검사 수 를 줄이 고 있 다는 음모론 으로 뒤바뀐 채 편집 돼 인용 됐 다 ” 며 “ 경솔 했 다 . 죄송 하 다 ” 고 밝혔 다 . 한국일보 는 a 씨 의 구체 적 인 입장 을 확인 하 기 위해 페이스북 과 병원 등 을 통해 연락 을 취했으나 답 을 듣 지 는 못했 다 . a 씨 가 근무 하 는 병원 관계자 는 “ a 씨 가 페이스북 에 올린 댓글 과 반성문 은 모두 개인 적 판단 에 따른 것 으로 병원 과 는 무관 하 다 ” 며 “ 병원 은 복지부 지침 에 따라 검사 를 다 하 고 있 다 ” 고 설명 했 다 . ◇ 거짓 판명 돼도 ‘ 속보 ’ ‘ 전달 사항 ’ 달 고 부활 특정 진영 의 입맛 에 맞춘 언론 보도 는 또 있 었 다 . 지난달 7 일 한 보수 인터넷 매체 는 ‘ 한국 은 마스크 대란 인데 … 일본 , 가구 당 마스크 40 매 무료 지급 ’ 이 라는 제목 의 기사 를 출고 했 고 , 이 는 급속도 로 퍼졌 다 . 제목 만 보 면 한국 정부 의 코로나 19 대응 이 일본 정부 에 뒤처지 는 것 같 지만 , 실제 기사 내용 은 ‘ 일본 홋카이도 등 일부 지역 주민 들 에게 가구 당 마스크 6 개 가 지급 되 고 순차 적 으로 총 40 매 로 늘릴 계획 ’ 이 라는 게 전부 다 . 사실 과 허위 를 뒤섞 는 수법 으로 ‘ 정부 공격 ’ 에 유용 한 정보 를 편집 하 고 유통 시킨 셈 이 다 . 이 는 가짜 뉴스 확산 의 빌미 가 됐 다 . 이튿날 디시 인사이드 등 인터넷 커뮤니티 에 는 해당 기사 를 캡 처한 게 시물 들 이 잇따랐 다 . 제목 은 ‘ 가구 당 마스크 40 매 무료 지급 ’ 이 었 고 , 댓글 은 ‘ 저게 나라 지 ’ ‘ 중국 에 퍼 주 기 때문 에 우리 는 저런 거 못 한다 ’ 등 정부 비판 일색 이 었 다 . 유사 언론 들 도 ‘ 한국 은 일 주일 에 마스크 2 장 을 사 려고 줄 을 서 는데 , 일본 정부 는 가구 당 40 장 을 지급 한다 ’ 는 기사 형태 의 게시물 을 올리 면서 가세 했 다 . 그러나 이 에 대해 다수 언론 은 팩 트 체크 를 거쳐 ‘ 사실 아님 ’ 이 라는 결론 을 내렸 다 . 정은령 센터 장 은 “ 허위 정보 를 가려내 기 위해 선 분 노나 공포 를 불러일으키 는 내용 인지 확인 할 필요 가 있 다 ” 며 “ 예컨대 ‘ 왜 대책 을 안 세우 는 거 야 ’ 같 은 감정 이 드 는 정보 라면 유의 해서 봐야 한다 ” 고 지적 했 다 . 가짜 뉴스 는 허위 로 드러나 도 곧잘 다시 살아난다 . 지난달 14 일 온라인 상 에선 ‘ 연세대 약학 대학 장 의 발언 ’ 이 라면서 “ 의약 계 가 코로나 19 변이 에 따른 2 차 파동 을 우려 하 고 있 다 ” 는 글 이 퍼지 기 시작 했 다 . ‘ 한국 의 코로나 19 는 s 형 인데 , 이탈리아 에서 번지 는 코로나 는 변형 된 바이러스 로 감 염력 이 4 배 나 강해서 2 차 파동 이 날 수 도 있 다 ’ 는 내용 이 었 다 . 이 에 대해 연세대 는 “ 약학 대학 장이 사석 에서 코로나 19 관련 연구 에 대해 언급 한 적 은 있 으나 , 변종 바이러스 나 2 차 파동 에 대해 말 한 적 은 없 다고 한다 ” 고 부인 했 다 . 팩 트 체크 에 나섰 던 복수 의 국내 언론 판단 도 ‘ 사실 아님 ’ 이 었 다 . 그런데 한 달 뒤 , 이 를 짜깁 기 한 내용 이 ‘ 속보 ’ 라는 제 목하 에 다시 등장 했 다 . 지난 19 일 우파 성향 으로 보이 는 블로거 가 여당 정치인 을 비꼬 는 글 에 ‘ 총 동문회 소식 전파 ’ 라며 ‘ 의약 계 의 코로나 19 2 차 파동 우려 ’ 를 전하 는 내용 을 적 었 다 . ‘ 연세대 약학 대학 장 의 발언 ’ 이 라는 부분 만 쏙 뺀 채 “ 주변 분 들 에게 도 이 정보 를 적극 알려 주 시 라 ” 고도 했 다 . 이미 수차례 허위 로 드러난 내용 을 마치 새로운 소식 ( 뉴스 ) 인 것 처럼 전하 면서 본인 의 정치 적 견해 를 뒷받침 하 는 용도 로 활용 한 것 이 다 . ‘ 공 적 마스크 를 사 면 개인 정보 가 중국 으로 유출 된다 ’ 는 루머 도 다르 지 않 다 . 지난달 11 일 을 전후 해 ‘ 주민 등록 번호 를 알려 주 고 마스크 를 구매 할 경우 , 개인 정보 가 해킹 당해 선거 조작 에 활용 될 수 있 다 . 약국 에서 공 적 마스크 를 구입 하 지 말 라 ’ 는 내용 이 카카오톡 단체 대화방 을 중심 으로 확산 했 다 . 이 역시 언론사 의 팩 트 체크 결과 , 전혀 사실 이 아니 었 다 . 그런데 도 지난달 20 일 변형 된 형태 의 가짜 뉴스 게시물 이 ‘ 전달 사항 ’ 이 라며 또 다시 한 블로그 에 올랐 다 . ‘ 약국 을 운영 하 는 분 이 보내온 글 ’ 이 라는 추가 설명 과 함께 , 약국 에서 마스크 를 사 려고 주민 번호 를 불러 주 는 순간 개인 의 모든 정보 가 중국 공산당 으로 흘러갈 수 있 다는 내용 이 었 다 . 가짜 뉴스 의 위험 성 에 주목 해야 하 는 이유 는 무엇 보다 잘못 된 정보 가 잘못 된 결과 를 초래 할 수 있 기 때문 이 다 . 지난달 1 일 과 8 일 경기 성남시 은혜 의 강 교회 에서 발생 한 코로나 19 집단 감염 사태 가 단 적 인 사례 다 . 당시 교회 에선 예배 에 참석 한 신도 들 의 입 에 분무기 로 소금물 을 뿌렸 다 . 인터넷 커뮤니티 와 단체 채팅 방 등 에서 ‘ 소금물 로 입 을 헹구 거나 소금 을 섭취 해 인체 의 염분 농도 를 높이 면 코로나 19 를 예방 ㆍ 치료 할 수 있 다 ’ 는 설 이 돌 았 던 탓 이 다 . 교회 입장 에선 ‘ 바이러스 예방 ’ 목적 이 었 다지만 , 결과 적 으론 확진 자 입 에 소금물 을 뿌렸 던 분무기 를 소독 하 지 않 고 다른 예배 참석자 들 에게 도 사용 하 면서 감염 을 부추긴 꼴 이 됐 다 . 가짜 뉴스 는 위기 극복 과정 에서 도 심각 한 방해 요인 으로 작용 한다 . 박 능 후 복지부 장관 은 지난 20 일 라디오 방송 에 출연 해 “ 가짜 뉴스 가 돌 면 일 자체 에 몰두 하 기 도 바쁜 의료진 들 이나 방역 당국 이 그걸 해명 하 느라 참 힘 이 든다 ” 고 토로 했 다 . 당면 한 위험 요소 를 제거 하 는 데 모든 역량 을 집중 해야 할 판 에 허위 정보 라는 또 다른 적 과 싸우 는 ‘ 소모전 ’ 을 치를 수 밖에 없 다는 말 이 다 . ◇“ 기성 언론 불신 있 지만 팩 트 체크 역할 기대 ” 전문가 들 은 가짜 뉴스 문제 의 핵심 은 결국 ‘ 언론 ’ 에 있 다고 강조 한다 . 기성 언론 이 사실 여부 를 충분히 검증 하 지 않 고 기사 를 생산 하 는 탓 에 가짜 뉴스 가 영향력 을 키우 고 있 으며 , 따라서 이 를 극복 할 해법 도 ‘ 저널리즘 의 회복 ’ 에서 찾 아야 한다는 얘기 다 . 미국 의 언론 학자 인 휘트니 필립스 시러큐스 대 교수 는 저서 ‘ 미디어 는 어떻게 허위 정보 에 속 았 는가 ’ 에서 “ 기자 들 은 자신 들 이 거짓 정보 유통 을 확산 시키 고 있 다는 걸 깨달 아야 한다 ” 며 보도 에 신중 을 기해야 한다고 강조 했 다 . 정은령 센터 장도 “ 대중 은 기성 언론 을 불신 하 면서 도 위기 상황 에선 전통 적 인 미디어 를 찾 는다 ” 며 “ 믿 을 만 한 정보 를 제공 해 주 길 바라 는 기대 에 부응 할 책임 이 있 다 ” 고 설명 했 다 . 언론사 와 기자 들 이 보다 더 적극 적 으로 팩 트 체크 에 임해야 한다는 뜻 이 다 . 이 와 관련 , 지난 15 일 영국 옥스퍼드 대 부설 로이터 저널리즘 연구소 가 발표 한 ‘ 6 개국 국민 들 은 코로나 바이러스 에 대한 뉴스 와 정보 를 어떻게 이용 하 고 평가 했 는가 ’ 보고서 내용 은 꽤 흥미 롭 다 . 지난달 31 일 부터 이달 7 일 까지 각국 의 미디어 이용자 ( 한국 1 , 009 명 , 영국 2 , 216 명 , 미국 1 , 273 명 , 독일 2 , 003 명 , 스페인 1 , 018 명 , 아르헨티나 1 , 003 명 ) 를 상대 로 실시 한 설문 조사 에서 한국 의 경우 언론 신뢰도 가 상당히 낮 은 수준 인데 도 불구 , 코로나 19 관련 정보 를 접하 는 출처 로 ‘ 언론사 를 이용 했 다 ’ 는 응답 비율 이 77 % 로 가장 높 게 나타났 다 . 스페인 과 아르헨티나 는 74 % 로 동일 했 고 , 영국 과 미국 은 50 % 대 , 독일 은 40 % 대 에 그쳤 다 . 한국 의 기성 언론 에 대한 따가운 비판 과 는 별개 로 , 여전히 언론 을 주된 정보 채널 로 삼 고 있 음 을 보여 주 는 대목 이 다 . 아울러 수용자 의 미디어 리터 러시 ( 독해력 ) 증진 도 가짜 뉴스 폐해 방지 에 필수 적 인 요소 로 꼽힌다 . 김 여라 국회 입 법조 사처 조사 관 은 지난 2 월 ‘ 허위 조작 정보 에 대한 팩 트 체크 의 현황 및 과제 ’ 보고서 에서 “ 언론사 들 이 ‘ 받아쓰 기 저널리즘 ’ 에서 벗어나 팩 트 체크 보도 에 주목 하 는 건 고무 적 인 일 ” 이 라며 “ 이 와 함께 국민 들 의 미디어 독해력 함양 노력 도 필요 하 다 ” 고 강조 했 다 . 청소년 대상 미디어 리터 러시 교육 을 하 는 박미영 한국 nie 협회 대표 도 “ 코로나 19 는 인류 가 처음 맞 는 것 이 어서 전문가 마다 견해 가 다를 수 는 있 지만 , 정보 출처 가 개인 이 아니 라 공신력 있 는 기관 인지 , 어느 시점 에 나온 정보 인지 등 은 꼭 확인 해야 한다 ” 고 말 했 다 . 특히 최근 청소년 들 이 정보 습득 채널 로 가장 많이 찾 는 유튜브 에 대해선 “ 성향 에 따라 한쪽 정보 를 몇 번 보 면 자동 추천 기능 때문 에 계속 그쪽 정보 에 만 노출 된다 ” 며 “ 확증편향 ( 편견 을 강화 하 는 정보 만 수용 ) 을 피하 기 위해 반대쪽 자료 도 의식 적 으로 찾 아 봐야 한다 ” 고 조언 했 다 . 채 지선 기자 letmeknow @ hankookilbo . com 0 0 공유 기사 저장 한국일보 뉴스 네이버 채널 구독 하 기',\n",
       "       '정영오 의 직격 황 승식 서울대 보건 대학원 교수 코로나 19 사태 를 계기 로 질병 , 특히 유행병 은 단순히 환자 의 몸 과 질병 사이 의 문제 가 아니 라 사회 적 , 정치 적 현실 과 밀접히 연결 돼 점 을 새삼 깨닫 게 된다 . 건강 에 영향 을 미치 는 사회 구조 와 제도 등 을 연구 하 는 사회 역학 ( social epidemiology ) 에 대한 관심 도 따라서 커지 고 있 다 . 황 승식 ( 47 ) 서울대 보건 학과 교수 는 ‘ 의료 와 소득 의 상호 작용 ‘ 등 이 분야 연구 에 천착 해 전문가 이 다 . 황 교수 는 최근 ‘ 세계 각국 의 코로나 19 방역 정책 비교 ’ 라는 연구 를 발표 했 다 . 그 가 생각 하 는 코로나 19 사태 의 현재 와 미래 를 들 어 봤 다 . - 우려 했 던 ‘ 2 차 확산 ’ 이 현실 이 됐 다 . 지금 상황 에서 방역 당국 이 집중 해야 할 건 무엇 인가 . “ 아직 큰 파도 는 오 지 않 았 다 . 많 은 전문가 들 이 코로나 19 팬데 믹 ( 세계 적 대유행 ) 의 ‘ 세컨드 웨이브 ’( 2 차 대유행 ) 는 계절 적 으로 인플루엔자 의 유행 이 시작 될 가을 과 겨울 사이 환절기 에 시작 될 것 으로 보 고 있 다 . 이런 경향 은 남반구 에서 확인 됐 다 . 겨울 로 접어드 는 7 월 말 8 월 초 에 남반구 에서 확진 자 가 다시 확대 됐 다 . 그 이유 는 바이러스 의 특성 이 아니 라 , 사람 의 생활 습관 과 관련 이 깊 다 . 여름 에 야 주기 적 으로 창문 열 어 환기 하 라는 권고 를 잘 따를 수 있 지만 , 찬 바람 이 불 면 감염 위험 이 상대 적 으로 높 은 실내 에 머무 는 시간 도 늘어나 고 , 환기 도 꺼리 게 되 고 손 씻 는 횟수 도 줄어든다 . 현재 수도 권 을 중심 으로 한 ‘ 2 차 확산 ’ 상황 이 길 어 져 가을 까지 이어진다면 그야말로 최악 의 상황 이 될 위험 성 이 있 다 . 반 대로 과거 대구 나 이태원 사례 처럼 성공 적 으로 대처 한다면 이번 상황 도 작 은 파도 로 끝날 수 있 다 . 지금 의 재 확산 을 2 차 대유행 으로 가 기 전 에 차단 하 는 게 가장 중요 하 다 . 코로나 19 방역 과 관련 해 우리 나라 대처 의 강점 은 ‘ 3 t ’ 로 요약 된다 . 대 규모 선제 검사 ( test ) 와 신속 한 역학 추적 ( trace ) 을 통해 감염자 와 접촉자 를 조기 에 격리 치료 ( treat ) 하 는 것 이 다 . 이런 시스템 을 유지 강화 해야 한다 . 여기 서 문제 가 되 는 게 방역 범위 를 벗어나 있 는 사람 들 의 비율 즉 ‘ 깜깜 이 환자 ’ 비율 이 다 . 현재 20 % 를 넘어섰 는데 더 늘어나 면 3 t 시스템 도 위험 해진다 . ” 우리 방역 의 성공 비결 은 ‘ 3 t ’ - 최근 전 염력 이 강한 gh 그룹 유전자형 코로나 19 바이러스 가 유행 한다 . 지난 5 월 이태원 클럽 집단 감염 부터 유행 한 gh 그룹 바이러스 는 1 , 2 월 중국 우한 교민 사이 에서 발견 된 s 그룹 이나 2 ~ 4 월 신천지 집단 감염 에서 나온 v 그룹 보다 , 전 염력 이 평균 6 배 , 최대 9 배 강 하 다는 연구 결과 도 있 다 . 이렇게 변이 가 빨리 일어난다면 백신 개발 이 소용없 는 것 아닌가 . 지금 까지 발견 된 코로나 19 유전자 변형 은 소 ( 小 ) 변이 이 다 . 현재 개발 중 인 백신 의 약효 에 문제 가 될 수준 은 아니 라는 뜻 이 다 . 매년 새로운 인플루엔자 예방 접종 을 새로 하 는 것 과 같 은 수준 의 변이 다 . 신종 감염병 바이러스 와 숙주 인 사람 과 의 관계 변화 는 전형 적 인 진화 의 과정 이 다 . 바이러스 입장 에서 는 번식 을 위한 숙주 인 사람 이 많이 남 아 있 는데 굳이 유전자 를 변형 시켜야 할 이유 가 없 다 . 진화 생물학 에서 는 이런 상황 을 ‘ 진화 압 ’ 이 라 표현 한다 . 유행 초기 에 바이러스 의 대 ( 大 ) 변이 는 거의 일어나 지 않 는 이유 가 여기 있 다 . ” - ‘ 세계 각국 의 코로나 19 방역 정책 비교 ’ 에 대해서 도 연구 했 는데 , 우리 정부 의 코로나 19 방역 정책 의 장단점 을 다른 나라 와 비교 한다면 . “ 특별히 우리 나라 만 시행 한 정책 은 없 다 . 다만 대만 과 우리 나라 는 다른 나라 정부 와 달리 한발 앞서 적시 에 정책 을 시행 해 초기 방역 에 성공 했 다 . 특히 코로나 19 검사 키트 를 빠르 게 개발 하 고 대량 확보 한 공 이 컸 다 . 이렇게 신속 하 게 대 처한 것 은 2015 년 중동 호흡기 증후군 ( 메르스 ) 사태 때 에 교훈 을 잊 지 않 았 기 때문 이 다 . 감염병 발병 대체 시스템 이 메르스 사태 를 계기 로 갖춰졌 고 , 정부 도 신속 대응 이 중요 하 다는 사실 을 절감 했 다 . 미국 에 도 진단 키트 가 있 었 으나 정부 의 대응 이 늦 어 사태 를 키웠 다 . 또 하나 는 경제 적 충격 을 최소 화 한 것 이 다 . 지역 봉쇄 나 국경 봉쇄 를 시도 하 지 않 으면서 방역 도 효과 적 으로 해냈 다 . 봉쇄 는 코로나 19 유행 이 처음 시작 된 우한 과 중국 내 다른 지역 처럼 발생 규모 차이 가 급격 할 때 에 만 효과 적 이 다 . 한국 처럼 지역 간 발생 차이 가 크 지 않 고 지역 내 이동 이 활발 한 나라 에서 는 이득 보다 손해 가 큰 정책 이 다 . ” - 하지만 초기 정부 가 성공 적 으로 유지 했 던 방역 과 경제 의 균형추 가 7 월 이후 경제 로 치우치 며 , 2 차 확산 의 원인 을 제공 했 다는 비판 을 피하 기 힘들 어 보인다 . “ 바이러스 감염 차단 만 이 목표 라면 사람 들 을 못 움직이 게 하 면 된다 . 하지만 경제 가 돌 지 않 으면 더 큰 피해 가 생긴다 . 두 가지 상충 한 요구 에 대해 어디 서 균형 점 을 맞추 느냐는 문제 는 정말 누구 도 먼저 걸 어 보 지 못한 길 을 걷 는 거 다 . 방역 은 결국 과학 과 정치 의 조화 가 중요 하 며 , 특히 정부 가 국민 에게 얼마나 정밀 한 메시지 를 전달 하 느냐 가 중요 하 다 . ” 코로나 19 위험 계층 200 만 명 에 달해 - 정부 는 코로나 19 가 상반기 내 안정 화 될 것 을 가정 하 고 , 2 분기 에 재정 을 집중 투자 했 고 그 효과 를 바탕 으로 3 분기 이후 경제 반 등 을 기대 했 다 . 하지만 그 기대 가 무너진 상황 이 다 . 코로나 19 취약 계층 에 대한 정부 의 각종 지원 이 절실 한데 , 재정 여력 은 상반기 보다 부족 하 다 . “ 일본 에서 는 코로나 19 방역 을 위해 ‘ no ! 3 밀 ( 밀폐 ㆍ밀접ㆍ밀집 ) ’ 을 강조 한다고 한다 . 3 밀 에 노출 가능 성 이 높 은 사람 들 이 대부분 사회 경제 적 으로 취약 한 사람 들 이 다 . 취약 계층 이 코로나 19 에 감염 될 가능 성 이 높 은 이유 이 다 . 감염병 전문가 들 사이 에서 ‘ 감염병 만큼 정치 적 인 현상 은 없 다 ’ 는 말 을 부인 하 는 사람 은 거의 없 다 . 이런 불 평등 을 완화 하 려면 정부 의 손길 이 필요 하 다 . 특히 취약 계층 중 에서 의학 적 으로 도 코로나 19 에 취약 한 만성 질 환자 에 대한 정부 의 돌봄 이 절실 한 상황 이 다 . 우리 나라 는 전 국민 이 건강 보험 가입자 또는 의료 급여 수급 권 자 혜택 을 받 도록 되 어 있 지만 건강 보험료 를 납부 하 지 못하 는 사람 들 이나 의료 급여 사각지대 도 많 다 . 건강 보험료 체납자 , 국민 기초 생활 보장 수급 자 등 을 고려 할 때 사각지대 에 놓여 있 는 사람 은 200 만 명 정도 로 짐작 된다 . 코로나 19 사태 조기 해결 가능 성 이 사라진 상황 에서 향후 최단 6 개월 에서 2 년 까지 이런 취약 계층 에 대한 도움 이 지속 될 체계 를 만들 어야 한다 . 또 사태 장기 화 로 생계 절벽 에 몰릴 수 밖에 없 는 영세자 영업자 나 저소득층 을 위한 사회 안전망 도 보강 해야 한다 . 상반기 처럼 일회성 긴급 재난 지원금 살포 에 그칠 것 이 아니 라 선별 적 이 되 지속 적 인 지원 체계 가 필요 하 다 . 재정 건전 성 을 걱정 해 취약 계층 에 대한 지원 을 줄인다면 , 방역 체계 가 무너질 수 있 는 심각 한 상황 이 다 . ” - 코로나 19 감염 에 대한 공포 가 대구 신천지 교도 나 이태원 동성애자 같 은 소수자 에 대한 비난 으로 번지 는 사례 가 반복 된다 . 급기야 최근 에 는 수도 권 감염 확산 의 주원인 으로 지목 된 일부 종교 단체 나 극우 인사 들 이 검진 을 거부 하 거나 왜곡 과장 주장 을 퍼뜨리 며 정부 의 방역 정책 에 저항 하 는 상황 으로 까지 악화 했 다 . 여기 에 는 감염자 동선 공개 등 우리 정부 의 적극 적 방역 정책 도 영향 을 미쳤 다 . 방역 을 위해 허용 되 는 사생활 이나 인권 침해 의 범위 는 어디 까지 인가 . “ 감염병 을 관리 하 기 위해 어쩔 수 없이 벌어지 는 인권 침해 를 어느 선 까지 허용 해야 하나 를 두 고 전 세계 어디 에 도 합의 된 기준 이 없 다 . 방역 의 필요 성 이 그 기준 을 정하 는 것 이 아니 라 , 반 대로 각 사회 의 특성 이 방역 작업 의 한계 를 규정 한다고 보 는 게 맞 을 것 이 다 . 우리 사회 에 원래 소수자 에 대한 혐오 가 없 었 는데 갑자기 코로나 19 로 생긴 것 이 아니 다 . 또 종교인 에 대한 신뢰 가 높 았 는데 코로나 19 때문 에 신뢰 가 낮 아 진 것 도 아니 다 . 우리 사회 에 잠재 된 여러 문제 가 코로나 19 라는 일종 의 돋보기 를 통해 커다랗 게 드러난 거 다 . 이런 문제 의 근본 적 해결 을 위해서 는 소수자 에 대한 존중 등 사회 의 개방 성 과 관용도 가 높 아 져야 겠 지만 이건 단기간 에 해결 될 문제 가 아니 다 . 특히 우리 나라 는 기술 적 진보 는 상당 이 앞섰 지만 , 정부 나 구성원 상호 간 의 사회 적 신뢰도 는 상당 이 낮 은 특성 을 보여준다 . 많 은 나라 는 기술 적 진보 와 사회 적 신뢰 가 비례 하 여 증가 하 는데 우리 나라 는 이 추이 에서 벗어나 있 다 . 이런 특성 을 고려 하 면 정부 의 적극 적 인 감염자 동선 공개 는 부작용 이 클 수 밖에 없 다 . 상호 간 신뢰도 가 낮 은 상황 에서 감염자 개인 정보 공개 는 과도 한 배제 와 비난 으로 흐를 가능 성 이 높 다 . 그렇 다고 감염 위험 관련 정보 를 무조건 막 을 수 도 없 다 . 우리 사회 의 앞선 기술력 이 이런 딜레마 의 해결책 이 될 수 있 을 것 이 다 . 국내 이동 통신사 들 은 스마트폰 이용자 의 동선 주변 이용자 를 식별 할 수 있 는 기술력 을 갖추 고 있 다 . 감염 위험 자 에 대한 정보 공개 가 아니 라 비 공개 로 대상자 에게 위험 을 고지 하 는 것 이 가능 하 다 . 또 감염자 개인 정보 공개 는 최소 화 하 는 대신 감염 이 발생 한 장소 를 공개 하 는 것 이 바람직 하 다 . 덧붙여서 정치 권 에서 논의 되 는 감염 의심 자 의 검사 거부 등 에 대한 처벌 강화 방안 은 실효 성 없이 감염 위험 만 키울 수 있 어 우려 된다 . 코로나 19 를 계기 로 우리 사회 에서 도 개인 정보 공개 범위 에 대한 성숙 한 고민 이 시작 되 기 바란다 . ” 과도 한 감염자 노출 은 방역 에 역효과 _ 코로나 19 사태 는 언제 쯤 진정 될까 . “ 결국 백신 접종 확대 로 전 세계 적 으로 집단 면역 이 실현 돼야 사태 가 진정 됐 다고 볼 수 있 을 것 이 다 . 백신 개발 과 관련 가장 낙관 적 인 견해 도 올 연말 백신 의 개발 , 내년 상반기 임상 안전성 확보 , 전 국민 백신 접종 등 의 단계 를 거쳐야 한다 . 결국 아무리 짧 게 잡 아도 내년 말 이후 에 나 코로나 19 사태 가 진정 될 것 이 다 . 그런데 매 단계 엄청난 어려움 이 도사리 고 있 다 . 임상 안전성 검증 문제 가 특히 그렇 다 . 건강 한 사람 에게 접종 해야 하 기 때문 에 10 만 명 당 한 명 의 사망률 도 결코 안 전하 다 할 수 없 다 . 이 를 우리 나라 에 대입 하 면 전 국민 코로나 19 백신 접종 으로 500 명 이 위험 해 지 는 셈 이 다 . 현재 까지 코로나 19 사망자 가 300 명 수준 인 것 비교 하 면 그 위험 성 이 얼마나 높 은 것 인지 쉽 게 이해 할 수 있 다 . 물론 권위주의 국가 에서 는 그 위험 기준 을 낮출 수 있 을 것 이 다 . 또 안 전한 백신 이 개발 된 후 에 도 충분 한 백신 을 확보 하 는 것 도 단기간 내 이루 기 힘들 것 이 다 . 이 모든 장애 를 해결 하 고 백신 개발 과 접종 이 순조 롭 게 진행 되 더라도 코로나 19 사태 이전 처럼 해외여행 을 자유 롭 게 하 려면 3 년 은 더 기다려야 할 것 이 다 . 물론 백신 접종 증명서 는 반드시 첨부 해야 한다 . ” 정영오 논설위원 young 5 @ hankookilbo . com 변한 나 사원 blossom @ hankookilbo . com 0 0 공유 기사 저장 한국일보 뉴스 네이버 채널 구독 하 기',\n",
       "       'windows 의 개발 환경 은 예전 부터 최악 이 란 평가 가 많 았 지만 , 작년 5 월 wsl 의 등장 으로 옛말 이 되 었 습니다 . 많이 불 안정 하 고 느리 단 평 이 많 아 설치 를 꺼렸 으나 , 지난 12 일 에 wsl 2 가 나오 며 꽤 괜찮 아 졌 단 평 이 많 길래 저 도 설치 해 봤 습니다 . 물론 리눅스 의 개발 환경 이 최강 인 이유 중 하나 인 \\' 그것 밖에 할 게 없 다 \\' 는 이유 는 windows 가 앞 으로 아무리 발전 해도 도달 할 수 없 겠 지만 요 . windows 하위 시스템 활성 화 윈도우 버튼 을 누르 고 powershell 을 검색 하 신 후 , 관리자 권한 으로 powershell 을 실행 해 주 세요 . enable - windowsoptionalfeature - online - featurename microsoft - windows - subsystem - linux 위 명령어 를 입력 하 신 뒤 컴퓨터 를 재 시작 해 주 세요 . linux 설치 microsoft 스토어 를 실행 하 시 고 linux 를 검색 하 시 면 리눅스 os 들 이 나옵니다 . 전 ubuntu 를 설치 했 습니다 . 위 과정 이 완료 되 면 다시 터미널 을 켜 시 고 wsl 을 입력 해 보 세요 . 익숙 한 우분투 향 이 가득 한 터미널 로 바뀌 면 성공 하 신 겁니다 . * 잘 진행 되 지 않 으면 우분투 앱 을 한 번 실행 하 시 면 이름 과 비밀 번호 를 설정 하 는 터미널 이 뜹니다 . 이름 과 비밀 번호 를 설정 하 신 뒤 터미널 에서 wsl - l 을 입력 하 시 고 리눅스 os 가 뜨 는지 확인 해 주 세요 . 이 아래 로 는 전부 선택 사항 입니다 . 우분투 의 설치 는 끝 났으니 , 즐겁 게 개발 을 시작 하 시 면 됩니다 . windows terminal 설치 개인 적 으로 powershell 은 좀 못 생겨서 windows terminal 을 선호 합니다 . 필요 하 시 면 설치 하 시 면 됩니다 . powershell 보다 훨씬 깔끔 하 고 , 다양 한 기능 이 있 습니다 . oh my zsh 설치 oh my zsh 를 이용 하 시 면 터미널 을 훨씬 더 자유 롭 게 커 스터 마이 징 하 실 수 있 습니다 . sudo apt install zsh 위 명령어 를 입력 하 셔서 zsh 를 설치 하 시 고 # curl sh - c \"$( curl - fssl [ URL ] # wget sh - c \"$( wget - o - [ URL ] 위 명령어 를 입력 해 oh my zsh 를 설치 하 실 수 있 습니다 . 자세 한 내용 은 oh my zsh 의 레 포지 토리 를 확인 해 주 세요 . remote - wsl 설치 vs code 에 remote - wsl 을 설치 하 시 면 우분투 터미널 을 vs code 에서 도 사용 하 실 수 있 습니다 . 설치 하 신 후 , 좌측 하단 의 파란 버튼 을 클릭 하 시 거나 , ctrl + shift + p 를 입력 하 신 후 wsl 을 입력 하 셔서 remote - wsl : new window 를 클릭 하 시 면 위 사진 처럼 우분투 의 터미널 을 사용 하 실 수 있 습니다 .',\n",
       "       '미국 주식 을 시작 하 시 는 분 들 을 위해 증권사 별 로 거래 수수료 및 환전 수수료 를 정리 한 글 입니다 . 증권사 환율 우대 의 비밀 도 함께 작성 했 습니다 . 환율 우대 80 %, 90 %, 95 % 가 꼭 저렴 한 건 절대 아니 예요 ㅎㅎ ( 환전 수수료 는 각 증권사 의 고객 센터 에 전화 해야 만 알 수 있 더군요 . ) 최저 수수료 가 없 는 곳 은 미래 에 셋 대우 뿐 이 었 는데 , 얼마 전 부터 최저 수수료 가 거의 다 폐지 됐 네요 ;; 환율 이란 ? 거래 수수료 는 매수 , 매도 할 때 내 는 수수료 입니다 . 환전 수수료 는 환전 할 때 증권사 에 내 야 하 는 수수료 겠 죠 . 환율 에 대해 잘 모르 신다면 , 밑 의 참고 글 을 읽 어 주 세요 . 시간 을 아끼 기 위해 예시 로 설명 드리 겠 습니다 . 현재 환율 $ 1 = 1 , 000 원 , 환전 스프 레드 = 5 원 $ 1 을 사 려면 1 , 005 원 이 필요 하 고 , $ 1 을 원화 로 바꾸 면 995 원 이 됩니다 . 환전 스프 레드 율 은 5 원 / 1 , 000 원 = 0 . 5 % 죠 . 즉 , 환전 스프 레드 율 = 환전 스프 레드 / 환율 입니다 . ※ 알 고 있 으면 유용 한 단어 들 환율 ( = 매매 기준율 ) , 전신환 율 ( = 전신환 매매 율 ) , 현찰 환율 ( = 현찰 매매 율 ) , 환전 스프 레드 , 환전 스프 레드 율 미국 주식 최저 수수료 폐지 의 역사 2018 년 9 월 까지 는 대부분 의 증권사 에 최저 수수료 가 있 었 습니다 . ( 미래 에 셋 대우 는 최저 수수료 없 었 음 ) 어느 순간 점점 최저 수수료 가 폐지 되 기 시작 합니다 . 2018 . 10 . 12 nh 투자 증권 폐지 2018 . 11 . 26 키움증권 폐지 2019 . 1 . 8 kb 증권 폐지 2019 . 3 . 29 유진 증권 폐지 2019 . 7 월 대신 증권 폐지 2019 . 8 . 1 삼성증권 폐지 . .. 이 덕분 에 미국 주식 거래 에 부담 이 확연히 줄 었 습니다 . 최저 수수료 의 중요 성 소액 투자자 에게 최저 수수료 는 큰 부담 이 었 습니다 . 예 를 들 어 볼게요 . a 증권사 에서 거래 수수료 = 0 . 2 %, 최저 수수료 = $ 10 였 습니다 . 애플 주가 = $ 100 , 이 때 5 주 매수 하 려면 , 거래 수수료 는 얼마 였 을까요 ? $ 500 * 0 . 2 % = $ 1 을 내 는 게 아니 라 , $ 10 를 내 야 했 습니다 . 애플 주가 가 $ 120 로 올라서 5 주 모두 매도 하 려면 , 수수료 는 $ 1 . 2 ( =$ 600 의 0 . 2 %) 가 아닌 $ 10 를 내 야 한 것 이 죠 . 예 에서 알 수 있 듯이 , 최저 수수료 는 소액 투자자 들 에게 가혹 한 부담 이 었 어요 . 하지만 이 때 에 도 미래 에 셋 대우 는 거래 수수료 가 0 . 25 %, 최저 수수료 가 없 었 습니다 . 소액 투자자 가 미국 주식 을 할려면 미래 에 셋 대우 를 선택 하 는 게 최고 의 판단 이 \" 였 \" 지요 . ※ 국내 주식 수수료 는 얼마 일까 ? 요즘 많 은 증권사 에서 국내 주식 수수료 가 무료 라고 합니다 . 사실 완전 0 원 은 아니 고 , \" 단 , 유관 기관 수수료 및 제 비용 제외 \" 라는 말 이 붙 어 있 죠 . 국내 주식 거래 를 할 때 는 다음 의 3 가지 수수료 를 내 야 합니다 . ① 증권사 수수료 + ② 유관 기관 수수료 + ③ 제 세금 ① 증권사 수수료 : 증권사 에서 가져가 는 수수료 . 이것 이 무료 라는 얘기 입니다 . ② 유관 기관 수수료 : 한국 거래소 , 증권 예탁 원 , 증권업 협회 등 에 내 야 하 는 수수료 . 거래 금액 의 0 . 003 ~ 0 . 006 % 정도 입니다 . 이 수수료 는 무조건 내 야 합니다 . ③ 제 세금 : 주식 매 도시 부과 되 는 세금 으로 , 거래 금액 의 0 . 3 % 였 지만 , 2019 . 6 . 3 부터 0 . 25 % 가 되 었 습니다 . 정확히 말씀 드리 면 코스피 , 코스닥 은 0 . 25 %, 코 넥스 는 0 . 1 % 예요 ㅎㅎ 종합 하 면 , 유관 기관 수수료 는 매우 미미 하 니 무시 할 수 있 을 테 고 , 주식 을 팔 때 에 만 거래 금액 의 0 . 25 % 를 내 야 합니다 . 증권사 별 거래 수수료 및 환전 수수료 ( 미국 주식 에 한함 ) 미국 주식 거래 시 고려 해야 하 는 수수료 거래 수수료 와 환전 수수료 를 고려 해야 합니다 . 이제 부터 거래 수수료 는 \" 수수료 \" 로 줄여 부르 겠 습니다 . 환전 수수료 는 $ 1 으로 환전 하 는 데 필요 한 원화 를 계산 해 보 세요 . 예 . $ 1 을 구하 려면 , a 증권사 는 1 , 167 . 8 원 이 필요 하 고 , b 증권사 는 1189 . 45 원 이 필요 하 다 . 해외 증권사 에 내 는 라이센스 비 , 예 탁원 보관 수수료 등 이 있 는데 , 이 들 은 주로 수수료 에 포함 됩니다 . 몇 증권사 에서 는 실시간 원화 주문 을 지원 하 고 있 습니다 . 이것 은 매매 시 실시간 환전 을 이용 하 는 것 을 말 하 는 건데요 . 환율 에 유연 하 게 대처 할 수 있 도록 , 원화 주문 보다 는 달러 주문 을 추천 드려요 . 꼭 환차익 실현 이 아니 더라도 , 환율 이 낮 을 때 원화 거래 로 매도 하 면 손해 를 볼 수 있 기 때문 이 죠 . sec fee 도 빠져나가 는데 , 연 1 ~ 3 회 빈도 로 변동 됩니다 . 매우 소액 이 니 신경 안 쓰 셔도 됩니다 . ※ sec fee 란 ? 미국 주식 을 매 도시 미국 증권 거래 위원회 에 세금 을 내 야 합니다 . sec fee 는 미국 증권 거래 위원회 에서 징수 하 는 세율 로 , 미국 주식 을 매도 할 때 만 낸다고 해서 미국 주식 매도 거래세 라고 도 부릅니다 . 1 년 에 약 1 ~ 3 회 정도 바뀌 는데 , 제 가 글 쓴 시점 에서 는 거래 금액 의 0 . 00207 % 입니다 . 낮 을 때 는 0 . 00056 %, 0 . 00130 % 정도 였 던 적 도 있 네요 . 매우 소액 이 라서 크 게 신경 안 쓰 셔도 됩니다 . 참고 링크 : sec fee rates 의 변화 환전 스프 레드 계산 방식 환전 스프 레드 는 2020 . 01 . 08 기준 환율 로 제 가 계산 했 습니다 . ( 약간 의 오 차 는 감안 해 주 시 면 감사 하 겠 습니다 ) 미래 에 셋 대우 는 환전 스프 레드 가 고정 값 5 원 입니다 . 타 증권사 는 계산법 이 전신환 율 ( 송금 보낼 때 ) 인 곳 도 있 고 , 환율 의 약 1 % 로 계산 하 는 곳 도 있 어요 . 제 가 몇몇 고객 센터 에 문의 했 는데 , 미래 에 셋 대우 는 5 원 이 라고 하 며 , 나머지 대부분 의 증권사 는 환율 의 약 1 % 정도 로 생각 하 면 된다고 하 더군요 . 저 는 주로 전신환 율 로 계산 하 였 고 , 삼성증권 은 ( 자체 고시 환율 을 쓰 기 때문 에 ) 환율 1 % 로 가정 , 한국 투자 증권 은 1 % 로 계산 한다고 들 었 기 때문 에 1 % 로 계산 , 농협 은행 은 0 . 97 % 로 계산 한다고 하 여 0 . 97 % 로 계산 했 어요 . 하지만 환율 스프 레드 말 고도 고려 해야 될 게 있 습니다 . 증권사 마다 적용 하 는 환율 이 다른데 , 매우 중요 합니다 . 참고 하 는 고시 은행 이 다르 기 때문 인데 , 바로 다음 내용 을 재미있 게 읽 어 주 세요 ㅎㅎ 키움증권 은 신한은행 고시 환율 을 적용 합니다 . 위 의 표 를 보 면 환전 스프 레드 는 11 . 2 원 이 되 겠 죠 ? 95 % 환율 우대 를 받 으면 11 . 2 원 * 5 % ≒ 0 . 6 원 이 계산 되 죠 . 즉 , $ 1 로 환전 하 려면 1170 . 1 ( 1169 . 5 + 0 . 6 ) 원 이 필요 하 죠 . 대신 증권 은 하나 은행 고시 환율 을 적용 합니다 . 표 에서 환전 스프 레드 는 11 . 4 원 이 되 죠 . 95 % 환율 우대 를 받 으면 11 . 4 원 * 5 % ≒ 0 . 6 원 이 계산 되 죠 . $ 1 을 살 려면 1169 . 6 원 ( 1169 . 0 + 0 . 6 ) 이 필요 하 게 되 요 . 한국 투자 증권 은 자체 고시 환율 을 적용 합니다 . 환전 스프 레드 = 환율 의 1 % 로 가정 하 면 , 11 . 7 원 이 되 죠 . 환율 우대 없 으면 $ 1 을 사 는 데 1182 . 3 원 ( 1170 . 8 + 11 . 7 ) 이 필요 하 죠 . 환율 우대 60 % 는 11 . 7 원 * 40 % ≒ 4 . 7 원 . 즉 , $ 1 을 사 는 데 1175 . 5 원 ( 1170 . 8 + 4 . 7 ) 이 필요 해요 . 환율 우대 80 % 는 11 . 7 원 * 20 % ≒ 2 . 3 원 이 됩니다 . $ 1 을 사 는 데 1173 . 1 원 ( 1170 . 8 + 2 . 3 ) 이 필요 하 죠 . 미래 에 셋 대우 는 서울 외국환 고시 환율 을 적용 하 며 , 환전 스프 레드 는 5 원 고정 입니다 . 환율 우대 를 안 받 으면 , $ 1 을 살 려면 1170 . 3 원 ( 1165 . 3 + 5 ) 이 필요 하 고 , 30 % 환율 우대 를 받 으면 , $ 1 을 살 려면 1168 . 8 원 ( 1165 . 3 + 3 . 5 ) 이 필요 합니다 . 유진 투자 증권 도 하나 은행 고시 환율 을 적용 합니다 ( 대신 증권 과 동일 ) . 환전 스프 레드 는 11 . 4 원 이 되 겠 죠 . 환율 우대 없이 $ 1 을 사 는 데 1180 . 4 원 ( 1169 . 0 + 11 . 4 ) 이 필요 합니다 . 환율 우대 를 95 % 정도 나 받 았 는데도 , 매매 기준율 부터 가 다르 니까 미래 에 셋 대우 에 비해 전혀 저렴 하 지 가 않 습니다 . 따라서 , 환전 수수료 가 저렴 한지 안 저렴 한지 는 미래 에 셋 대우 를 기준 으로 생각 하 시 는 게 편합니다 . 증권사 가 시중 은행 환율 을 참고 한다면 , 환율 우대 가 95 % 정도 는 되 야 미래 에 셋 대우 와 비슷 하 군요 ㅎㅎ ( 2020 . 2 . 2 추가 내용 ) 방문자 포 로 리 님 덕분 에 중요 한 내용 을 깨닫 게 됐 어요 . 곰곰히 생각 해 보 세요 . 원화 → 달러 로 바꿔야 미국 주식 거래 를 할 수 있 는데 , 배당금 이나 매매 차익 을 얻 고 나 서 다시 달러 → 원화 로 바꿔야 하 겠 죠 ? 시중 은행 은 서울 외국환 보다 환율 이 높 으니까 , 원화 → 달러 환전 시 에 는 서울 외국환 이 유리 하 지만 , 달러 → 원화 환전 시 에 는 시중 은행 이 더 유리 합니다 . 2020 . 1 . 31 종가 기준 으로 살펴볼게요 . 유난히 이 날 은 서울 외국환 과 시중 은행 환율 차이 가 큰 날 이 에요 . - 미래 에 셋 대우 증권 ( 서울 외국환 ) 매매 기준 율 1183 . 5 원 송금 보낼 때 ( 환율 우대 x ) 1188 . 5 원 ( 환율 우대 50 %) 1186 . 0 원 송금 받 을 때 ( 환율 우대 x ) 1178 . 5 원 ( 환율 우대 50 %) 1181 . 0 원 - 키움증권 ( 신한은행 ) 매매 기준 율 1193 . 5 원 송금 보낼 때 ( 95 % 환율 우대 ) 1194 . 1 원 송금 받 을 때 ( 95 % 환율 우대 ) 1192 . 9 원 저 와 친구 가 10 만 원 으로 환전 놀이 를 한다고 생각 해 볼게요 . 저 는 미래 에 셋 대우 50 % 환율 우대 로 환전 놀이 를 하 고 , 친구 는 키움증권 95 % 환율 우대 로 놀이 를 할 거 에요 . 두 명 다 원화 → 달러 → 원화 로 바꾸 는 놀이 입니다 . 저 : 100 , 000 원 → $ 84 . 3 → 99 , 558 원 친구 : 100 , 000 원 → $ 83 . 7 → 99 , 846 원 ( 소수점 둘째 자리 에서 반올림 ) 원화 → 달러 → 원화 까지 생각 해야 하 는데 , 환전 수수료 면 에서 키움증권 이 더 이득 이 에요 ㅎㅎ ! ( 방문 해 주 신 포 로 리 님 덕분 에 귀중 한 정보 알 게 됐 어요 . 포로 리 님 감사 드려요 ) 식 을 만들 어 보 면 , 고시 환율 은 높 으면서 환전 스프 레드 는 적 은 증권사 가 유리 해요 ! ! ( ※ 계산 식 이 궁금 하 신 분 은 댓글 참고 부탁 드려요 ) 최저 수수료 없 는 증권사 별 종합 비교 계산 은 2020 . 1 . 8 미국 달러 환율 ( 종가 기준 ) 로 했 습니다 ( 약간 의 오 차 감안 ) . 서울 외국환 환율 1165 . 3 원 , keb 하나 은행 1169 . 0 원 , 신한은행 1169 . 5 원 입니다 . 착각 하 시 기 쉽 지만 환전 은 별로 할 기회 가 없 어요 . 거래 때 마다 환전 수수료 를 내 는 게 아니 라 , 처음 에 달러 마련 할 때 한 번 내 는 거 에요 . 달러 → 원화 로 바꾸 고 싶 을 때 환전 수수료 를 또 한 번 내 는 거 구요 . 환전 수수료 가 5 원 정도 의 차이 는 큰 금액 은 아닌 것 같 습니다 . 거래 수수료 도 중요 한데 , 미국 주식 은 단타 가 거의 없 으니 매매 가 잦 지 않 을 겁니다 . 하지만 이왕이면 매수 수수료 , 매도 수수료 는 낮 은 게 좋 습니다 . ( 2020 . 8 . 18 추가 ) 현재 키움증권 뿐 아니 라 대신 증권 크 레 온 , 삼성증권 에서 도 큰 이벤트 를 하 고 있 습니다 . ( 키움증권 은 거래세 0 . 1 %, 환율 우대 95 %, 대신 증권 크 레온 은 거래세 0 . 08 %, 환율 우대 95 %, 삼성증권 은 거래세 0 . 09 %, 환율 우대 95 %) 따라서 , 제 생각 으로 는 대신 증권 크레 온과 키움증권 , 삼성증권 이 가장 좋 아 보 입니다 . 거래 수수료 와 환율 스프 레드 가 낮 기 때문 이 죠 . 최저 수수료 가 폐지 되 서 미국 주식 하 기 좋 은 증권사 가 많 아 졌 어요 . 국내 주식 은 매 도시 거래 금액 0 . 25 % 를 내 야 하 므로 , 오히려 미국 주식 이 더 저렴 할 수 도 있 어요 . 자세 한 내용 은 밑 의 각 증권사 별 설명 들 을 읽 어 주 세요 ! 제 생각 으론 키움증권 이 가장 좋 아 보이 고 ( 거래 수수료 와 환율 스프 레드 가 낮 습니다 ) , 두 번 째 로 는 대신 증권 크 레온 이 좋 아 보입니다 ( 마찬가지 이유 입니다 ) . 제 생각 으론 키움증권 이 가장 좋 아 보이 고 , 두 번 째 로 는 대신 증권 크 레 온 , 세 번 째 는 미래 에 셋 대우 가 좋 아 보 입니다 . 세 개 모두 상당히 좋 아 보이 고 , 나머지 증권사 는 큰 차이 없 는 것 같 습니다 . ( ~ 2020 . 12 . 31 ) 매수 수수료 0 . 1 %, 매도 수수료 0 . 1 % 기타 거래세 ( = sec fee ) 0 . 00207 % $ 1 환 전시 원화 ( 환율 우대 95 % 시 ) 1170 . 1 원 -- 환전 스프 레드 ( 환율 우대 95 % 시 ) 0 . 6 원 신한은행 고시 환율 적용 환전 스프 레드 11 . 2 원 환율 우대 : 95 % 원화 거래 시 환율 우대 100 % ( 환차익 실현 이 힘드 니까 비 추천 ) 2020 . 3 월 까지 해외 주식 계좌 만들 면 $ 40 지급 ( 이벤트 페이지 참고 ) 수수료 0 . 1 % 는 제 예상 으로 는 계속 연장 될 것 같 습니다 . 올해 중 한 번 이라도 미국 주식 거래 를 하 면 자동 으로 2021 년 말 까지 연장 된대요 . 비대 면 계좌 만 만들 면 매수 수수료 , 매도 수수료 모두 0 . 25 % 로 적용 된다고 합니다 . 꼭 0 . 1 % 수수료 이벤트 참가 신청 해야 해요 . 방법 은 영웅 문 어 플 또는 키움증권 홈피 → 이벤트 → 0 . 1 % 수수료 이벤트 , $ 40 지급 이벤트 참가 신청 . 매수 수수료 0 . 2 %, 매도 수수료 0 . 2 % 기타 거래세 ( = sec fee ) 0 . 00207 % $ 1 환 전시 원화 ( 환율 우대 95 %) 1169 . 6 원 ← 환전 스프 레드 * 5 % ≒ 0 . 6 원 $ 1 환 전시 원화 ( 환율 우대 80 %) 1171 . 3 원 ← 환전 스프 레드 * 20 % ≒ 2 . 3 원 $ 1 환 전시 원화 ( 환율 우대 70 %) 1172 . 4 원 ← 환전 스프 레드 * 30 % ≒ 3 . 4 원 하나 은행 고시 환율 적용 환전 스프 레드 11 . 4 원 환율 우대 : mts 어 플로 거래 하 면 환전 우대 는 무조건 70 %. 고객 센터 1544 - 4488 전화 로 환 전시 , 환전 금액 상관없이 계좌 총 자산 에 따라 다름 . 총 자산 200 만 원 이상 이 면 환율 우대 80 %, 총 자산 500 만 원 이상 은 95 % 환율 우대 적용 됨 . 매수 수수료 0 . 25 %, 매도 수수료 0 . 25 % 기타 거래세 ( = sec fee ) 0 . 00207 % $ 1 환 전시 원화 ( 환율 우대 없 음 ) 1170 . 3 원 ← 환전 스프 레드 5 원 $ 1 환 전시 원화 ( 환율 우대 30 %) 1168 . 8 원 ← 환전 스프 레드 * 70 % ≒ 3 . 5 원 $ 1 환 전시 원화 ( 환율 우대 50 %) 1167 . 8 원 ← 환전 스프 레드 * 50 % ≒ 2 . 5 원 서울 외국환 고시 환율 적용 환전 스프 레드 5 원 환율 우대 : 예탁 자산 구간 이 3 천만 원 이상 일 때 환율 우대 30 %, 1 억 원 이상 은 환율 우대 50 % 환율 우대 는 고객 센터 1588 - 6800 전화 해서 신청 해야 함 매수 수수료 0 . 26 %, 매도 수수료 0 . 26 % 기타 거래세 ( = sec fee ) 0 . 00207 % ※ 위 의 그림 에서 한국 투자 증권 수수료 는 헷갈릴 수 있 어요 . 국내 수수료 : 국내 증권사 에 내 는 수수료 해외 수수료 : 해외 증권사 에 내 는 라이센스 비 + 예 탁원 보관 수수료 등 즉 , 국내 수수료 0 . 20 % + 해외 수수료 0 . 06 % = 0 . 26 % 가 됩니다 . $ 1 환 전시 원화 ( 환율 우대 없 음 ) 1182 . 5 원 ← 환전 스프 레드 11 . 7 원 $ 1 환 전시 원화 ( 환율 우대 60 %) 1175 . 5 원 ← 환전 스프 레드 * 40 % ≒ 4 . 7 원 $ 1 환 전시 원화 ( 환율 우대 80 %) 1173 . 1 원 ← 환전 스프 레드 * 20 % ≒ 2 . 3 원 당사 고시 환율 적용 - 직원 은 시중 은행 보다 환율 이 좀 더 낮 은 편 이 라는데 , 2020 . 01 . 08 기준 으로 시중 은행 보다 더 높 더군요 ; 2020 . 01 . 08 기준 으로 시중 은행 보다 더 높 더군요 ; 환전 스프 레드 율 1 % 환율 우대 : 등급 에 따라 환율 우대 60 ~ 80 %. 자세히 알아보 려면 고객 센터 에 문의 해 주 세요 ㅎㅎ 매수 수수료 0 . 25 %, 매도 수수료 0 . 25 % 기타 거래세 ( = sec fee ) 0 . 00207 % $ 1 환 전시 원화 1180 . 8 원 ← 환전 스프 레드 11 . 3 원 국민은행 고시 환율 적용 환전 스프 레드 11 . 3 원 환율 우대 : 지점 방문 해서 협의 해야 하 며 , mts 로 거래 시 환율 우대 0 % ※ 원 마켓 에서 는 원화 거래 가 가능 하 며 , 이때 는 환전 우대 100 % ( 변화 하 는 환율 에 대처 하 려면 달러 거래 추천 ) 매수 수수료 0 . 25 %, 매도 수수료 0 . 25 % 기타 거래세 ( = sec fee ) 0 . 00207 % $ 1 환 전시 원화 1182 . 2 원 ( 가정 ) ← 환전 스프 레드 11 . 7 원 ( 가정 ) 당사 고시 환율 적용 - 시중 은행 과 유사 환전 스프 레드 율 1 % 로 가정 환율 우대 : 없 음 매수 수수료 0 . 25 %, 매도 수수료 0 . 25 % 기타 거래세 ( = sec fee ) 0 . 00207 % $ 1 환 전시 ( 환율 우대 없 음 ) 원화 1182 . 2 원 ← 환전 스프 레드 11 . 4 원 농협 은행 고시 환율 적용 환전 스프 레드 율 0 . 97 % 환전 우대 : 환전 금액 1000 만 원 15 % 우대 , 3000 만 원 30 % 우대 , 5000 만 원 50 %, 1 억 70 %, 3 억 80 % 매수 수수료 0 . 25 %, 매도 수수료 0 . 25 % 기타 거래세 ( = sec fee ) 0 . 00207 % $ 1 환 전시 ( 환율 우대 없 음 ) 원화 1180 . 4 원 ← 환전 스프 레드 11 . 4 원 하나 은행 고시 환율 을 적용 한다 . 다른 대부분 의 증권사 와 마찬가지 로 전신환 율 적용 다른 대부분 의 증권사 와 마찬가지 로 전신환 율 적용 환율 우대 : 우대 기준 정립 된 것 없 음 . 고객 센터 에 전화 하 면 환율 우대 협의 가능 해외 주식 거래 시 추가 적 으로 알 아 둬야 할 내용 해외 주식 은 매매 수익 에 대해 양 도 소득세 를 내 야 합니다 . 연간 매매 차익 을 따졌 을 때 , 250 만 원 을 초과 한 수익 분 에 대해서 22 % 의 양 도 소득세 를 내 야 해요 . 배당금 은 미국 에서 15 % 떼 고 지급 되 어 , 15 % 가 빠진 금액 을 받 게 됩니다 . 배당금 에 대해서 는 특별히 저희 가 신경 쓸 필요 는 없 습니다 . ※ 국내 배당 소득세 는 15 . 4 % 금융 소득 ( 이자 소득 + 국내외 배당 소득 ) 이 연 2 , 000 만 원 을 초 과시 , 초과분 에 대해서 는 종합 과 세 대상 이 됩니다 . 즉 , 2 , 000 만 원 초과분 에 대한 금융 소득 이 근로 소득 , 연금 소득 , 기타 소득 등 과 합산 하 여 종합 과 세 대상 이 됩니다 . 이해 가 안 가 거나 궁금 하 신 점 은 꼭 질문 주 세요 . 제 블로그 를 찾 아 주 신 여러분 감사 드려요 : -)',\n",
       "       '펄 플렉 서티 ( perplexity ) 두 개 의 모델 a , b 가 있 을 때 이 모델 의 성능 은 어떻게 비교 할 수 있 을까 ? 두 개 의 모델 을 오타 교정 , 기계 번역 등 의 평가 에 투입 해 볼 수 있 다 . 그리고 두 모델 이 해당 업무 의 성능 을 누가 더 잘 했 는지 를 비교 하 면 된다 . 그런데 두 모델 의 성능 을 비교 하 고자 , 일일이 모델 들 에 대해서 실제 작업 을 시켜 보 고 정확도 를 비교 하 는 작업 은 공수 가 너무 많이 드 는 작업 이 다 . 만약 비교 해야 하 는 모델 이 두 개 가 아니 라 그 이상 의 수 라면 시간 은 비교 해야 하 는 모델 수 만큼 늘어날 수 있 다 . 이러 한 평가 를 외부 평가 ( extrinsic evaluation ) 라고 하 는데 , 이러 한 평가 보다 는 어쩌면 조금 은 부정확 할 수 는 있 어도 테스트 데이터 에 대해서 빠르 게 식 으로 계산 되 는 더 간단 한 평가 방법 이 있 다 . 바로 모델 내 에서 자신 의 성능 을 수치 화 하 여 결과 를 내놓 는 내부 평가 ( intrinsic evaluation ) 에 해당 되 는 펄 플렉 서티 ( perplexity ) 이 다 . 1 . 언어 모델 의 평가 ( evaluation ) 의 방법 . pp . 펄 플렉 서티 ( perplexity ) 는 언어 모델 을 평가 하 기 위한 내부 평가 지표 이 다 . 보통 줄여서 ppl 또는 pp 라고 표현 합니다 . pp 를 처음 배울 때 다소 낯설 게 느껴질 수 있 는 점 이 있 다면 , pp 는 수치 가 높 을수록 좋 은 성능 을 의미 하 는 것 이 아니 라 , ‘ 낮 을 수록 ’ 언어 모델 의 성능 이 좋 다는 것 을 의미 한다는 점 이 다 . pp 는 선택 할 수 있 는 가능 한 경우 의 수 를 의미 하 는 분기 계수 ( branching factor ) 이 다 . pp 는 이 언어 모델 이 특정 시점 에서 평균 적 으로 몇 개 의 선택지 를 가지 고 고민 하 고 있 는지 를 의미 한다 . 가령 , 언어 모델 에 어떤 테스트 데이터 를 주 고 측정 했 더니 pp 가 10 이 나왔 다고 해 보 자 . 그렇 다면 해당 언어 모델 은 테스트 데이터 에 대해서 당므 단어 를 예측 하 는 모든 시점 ( time - step ) 마다 평균 적 으로 10 개 의 단어 를 가지 고 어떤 것 이 정답 인지 고민 하 고 있 다고 볼 수 있 다 . 같 은 테스트 데이터 에 대해서 두 언어 모델 의 pp 를 각각 계산 후 에 pp 의 값 을 비교 하 면 , 두 언어 모델 중 어떤 것 이 성능 이 좋 은 지도 판단 이 가능 하 다 . 당연히 pp 가 더 낮 은 언어 모델 의 성능 이 더 좋 다고 볼 수 있 다 . 단 , 평가 방법 에 있 어서 주의 할 점 은 언어 모델 의 pp 는 테스트 데이터 에 의존 하 기 때문 에 , 두 개 이상 의 언어 모델 을 비교 할 때 는 정량 적 으로 양 이 많 고 , 또한 도메인 에 알맞 은 테스트 데이터 를 사용 해야 신뢰도 가 높 다는 점 이 다 . 2 . 펄 플렉 서티 ( perplexity ) 의 수식 펄 플렉 서티 ( perplexity ) 는 아래 와 같 은 수식 으로 정의 된다 . 여기 서 x 는 선택 가능 한 경우 의 수 중 하나 이 며 , p ( x ) 는 x 의 확률 을 나타낸다 . 만약 모든 x 의 확률 이 1 / x 로 같 다면 , 즉 , 정답 후보 의 확률 이 모두 같 다면 pp 는 x 가 된다 . 하지만 모든 x 중 에서 하나 의 x 의 확률 이 1 이 고 , 나머지 x 의 확률 이 0 이 라면 pp 는 1 이 된다 . 이 경우 에 는 수식 상 으로 는 언어 모델 이 다음 단어 를 말 할 때 마다 100 % 정답 임 을 확신 하 고 고민 조차 않 는다는 뜻 이 될 것 이 다 . 하지만 주의 할 점 은 pp 의 값 이 낮 다는 것 은 테스트 데이터 상 에서 높 은 정확도 를 보인다는 것 이 지 , 사람 이 직접 느끼 기 에 좋 은 언어 모델 이 라는 것 을 반드시 의미 하 진 않 는다는 점 이 다 . pp 는 또한 크로스 엔트로피 ( cross - entropy ) 와 다음 과 같 은 식 의 관계 를 가진다 . 3 . 기존 언어 모델 vs . 딥 러닝 을 이용 한 언어 모델 . pp 의 실제 사용 사례 를 확인 해 보 자 . 페이스북 ai 연구 팀 은 우리 가 앞서 배운 n - gram 언어 모델 과 이후 배우 게 될 딥 러닝 을 이용 한 언어 모델 에 대해서 pp 로 성능 테스트 를 한 표 를 공개 한 바 있 다 . 표 에서 맨 위 의 줄 의 언어 모델 인 n - gram 을 이용 한 언어 모델 이 며 pp 가 67 . 6 으로 측정 되 었 다 . 5 - gram 을 사용 하 였으며 , 이 책 에서 는 별도 설명 을 생략 하 겠 다고 했 던 일반 화 ( generalization ) 방법 이 사용 된 모델 이 다 . 반면 , 그 아래 의 모델 들 은 딥 러닝 을 이용 한 언어 모델 들 로 페이스북 ai 연구 팀 이 자신 들 의 언어 모델 을 다른 언어 모델 과 비교 하 고자 하 는 목적 으로 기록 했 다 . 아직 rnn 과 lstm 등 이 무엇 인지 배우 지 는 않 았 지만 , 딥 러닝 을 이용 한 언어 모델 들 은 대부분 n - gram 을 이용 한 언어 모델 보다 더 좋 은 성능 평가 를 받 았 음 을 확인 할 수 있 다 .',\n",
       "       'gatsby js 란 무엇 인가 gatsby js 는 정적 html 생성기 이 다 . 일반 적 인 단순 한 페이지 는 하나 의 html 로 만들 어 질 수 있 다 . 사이트 가 커지 고 페이지 별로 html 이 생성 되 어야 한다면 , 페이지 에 접근 할 때 마다 db 에서 정보 를 받 아 와서 html 을 만들 어 내 는 ssr 방식 , api 로 해당 페이지 정보 를 받 아 와서 html 페이지 를 만들 어 내 는 csr 방식 , 그리고 , 그때 마다 페이지 를 만들 어 내 는 것 이 아닌 페이지 를 원하 는 시점 빌드 시점 마다 만들 어 내 는 방식 이 있 을 수 있 다 . gatsby js 는 가공 할 정보 를 graphql 에서 가져와서 빌드 시점 에 정적 페이지 를 만들 어 내 는 방식 을 취하 고 있 다 . 이미 배포 할 때 각 페이지 정보 들 이 모두 배포 시점 에 만들 어 져 지 므로 , 따로 앱 서버 가 필요 하 지 않 다는 장점 이 있 다 . gatsby js 기본 정보 gatsby cli 를 이용 해서 gatsbyjs 를 사용 할 수 있 다 . 이때 gatsby cli 는 webpack , reactjs , react - route 등 을 이미 포함 하 고 있 으므로 , 이 를 간단 하 게 이용 할 수 있 게 해준다 . 현재 19 년 2 월 을 기준 으로 gatsby 버전 은 2 . 0 . 107 gatsby cli 버전 은 2 . 4 . 8 이 며 , 리 액트 버전 은 16 . 7 . 0 이 다 . gatsbyjs 는 페이지 가 로드 되 기 전 에 gatsbyjs 관련 스크립트 를 먼저 다운 받 고 이후 의 페이지 에서 필요 한 js 와 css 정보 를 다운 받 는다 . 5 분 만 에 설치 하 고 실행 하 기 1 . npm install — global gatsby - cli 2 . gatsby new [ 프로젝트 폴더 명 ] 3 . cd [ 프로젝트 폴더 명 ] 4 . gatsby develop / / 개발 모드 로 시작 한다 . 프로젝트 구조 살펴보 기 / . cache gatsby 의 내부 캐시 이 다 . / public gatsby build 의 output 이 들어간다 . / plugins npm 에 들어가 지 않 은 라이브러리 나 플 로그인 을 넣 을 수 있 다 . / src - / pages 파일 이름 과 폴더 이름 을 경로 로 따르 는 페이지 - / component 컴포넌트 의 모음 폴더 - / images 이미지 모음 폴더 / static static 폴더 에 파일 을 저장 하 면 webpack 에서 파일 을 처리 하 지 않 고 공용 폴더 에 복사 되 는 폴더 가 존재 한다 . 설정 파일 살펴보 기 gatsby - config . js gatsby 사이트 의 기본 구성 파일 이 다 . 여기 서 사이트 제목 및 설명 , 포함 할 gatsby 플러그인 등 사이트 ( 메타 데이터 ) 에 대한 정보 를 지정 할 수 있 다 . gatsby 사이트 의 기본 구성 파일 이 다 . 여기 서 사이트 제목 및 설명 , 포함 할 gatsby 플러그인 등 사이트 ( 메타 데이터 ) 에 대한 정보 를 지정 할 수 있 다 . gatsby - browser . js gatsby 브라우저 api 의 사용 이 있 는 경우 사용 한다 . gatsby 브라우저 api 의 사용 이 있 는 경우 사용 한다 . gatsby - node . js gatsby 노드 api 사용 이 있 을 경우 의 사용법 을 정의 한다 . gatsby 노드 api 사용 이 있 을 경우 의 사용법 을 정의 한다 . gatsby - ssr . js gatsby 서버 사이드 렌더링 api 사용 이 있 을 경우 의 사용법 정의 한다 . gatsby 로 블로그 만들 기 gatsby 는 react 를 사용 하 여 spa 페이지 를 쉽 게 구현 할 수 있 게 해준다 . 이 를 이용 하 여 , 간단 한 예제 로 블로그 를 만들 어 보 자 . gatsby 로 markdown 블로그 만들 기 블로그 를 만들 때 post 내용 을 markdown 으로 작성 해 두 면 , 많 은 곳 에서 재 사용 하 기 쉬우므로 , markdown 문법 을 이용 해서 블로그 를 만들 어 보 자 . gatsby 가 markdown 파일 을 읽 기 위해서 는 몇 가지 세팅 이 필요 하 다 . gatsby 가 markdown 파일 을 읽 어서 정적 html 파일 로 만드 는 방법 은 아래 순서 대로 이루어진다 . 1 . ` gatsby - source - filesystem ` 로 마크 다운 파일 을 읽 는다 . 2 . ` gatsby - transformer - remark ` 로 마크 다운 파일 을 해석 한다 . 3 . 해석 된 데이터 를 graphql 로 가져 져 온다 . 4 . 가져온 정보 를 미리 설정 한 템플 릿 에 배치 한다 . 5 . gatsby 의 createpageapi 를 사용 하 여 데이터 와 템플 릿 을 정적 페이지 만든다 . gatsby - config . js 에 필요 한 정보 설정 하 기 gatsby 로 마크다운 을 읽 기 위해서 는 gatsby - source - filesystem 플 로그인 과 마크다운 을 필요 한 정보 로 해석 하 기 위한 gatsby - transformer - remark 이 필요 하 다 . 해당 내용 을 gatsby - config . js 에 세팅 해야 한다 . // gatsby - config . js plugins : [ { resolve : ` gatsby - source - filesystem `, options : { name : ` markdown - pages `, path : `${__ dirname }/ src / 마크 다운 파일 이 위치 할 폴더 이름 `, }, }, ` gatsby - transformer - remark `, ] 마크다운 을 html 로 변경 하 기 위한 템플 릿 만들 기 gatsby 는 graphql 를 이용 해서 markdown 데이터 정보 를 가져온다 . 가져온 정보 는 template 에 게 주 어 지 며 , 정의 한 곳 에 세팅 된다 . // markdown - template . js import react from \" react \" import { graphql } from \" gatsby \" export default function template ( { data }) { const { markdownremark : { frontmatter , html } } = data ; return ( { frontmatter . title } { frontmatter . date } ) } export const pagequery = graphql ` query ( $ path : string ! ) { markdownremark ( frontmatter : { path : { eq : $ path } }) { html frontmatter { date ( formatstring : \" yyyy 년 mm 월 dd 일 \") path title } } } ` 템플 릿 을 정적 html 로 만들 기 gatsby 는 node . js api 으로 정적 페이지 를 만들 어 낸다 . 이 를 사용 하 기 위해서 는 gatsby - node . js 에 세팅 해야 한다 . graphql 의 allmarkdownremark 가 읽 어 온 모든 마크다운 을 가져온다 . edges 에 각각 의 node ( markdown ) 정보 가 들 어 있 는데 이 정보 와 위해서 작성 한 template 을 합성 하 여 createpage 에서 실제 정적 파일 을 만들 어 낸다 . // gatsby - node . js const path = require ( \" path \") exports . createpages = ( { actions , graphql }) => { const { createpage } = actions const blogposttemplate = path . resolve ( ` 템플 릿 파일 `) return graphql ( ` { allmarkdownremark ( sort : { order : desc , fields : [ frontmatter ___ date ] } limit : 1000 ) { edges { node { frontmatter { path } } } } } `). then ( result => { if ( result . errors ) { return promise . reject ( result . errors ) } result . data . allmarkdownremark . edges . foreach ( ( { node }) => { createpage ( { path : node . frontmatter . path , component : blogposttemplate , context : {}, }) }) }) } 첫 포스트 작성 해 보 기 markdown post 를 작성 할 때 중요 한 점 은 graphql 에게 해당 파일 의 정보 를 알려줘야 한다는 점 이 다 . --- path : \" url 정보 \" date : \" 생성 일자 \" title : \" 타이틀 정보 \" --- 마크 다운 내용 - 과 - 사이 에 path 정보 를 작성 하 여야 graphql 에서 frontmatter 으로 해당 파일 정보 를 처리 할 수 있 게 된다 . 이전 markdown - template . js 에서 작성 한 graphql 에서 현재 path 와 마크다운 에서 존재 하 는 path 를 비교 하 여 필요 한 정보 를 post 에 표현 하 게 된다 . gatsby 를 netlify 에 배포 하 기 이제 작성 한 gatsby 를 실제 접속 가능 한 사이트 로 배포 해 보 자 . netlify 란 무엇 인가 netlift 는 정적 페이지 를 무료 로 빌드 및 배포 할 수 있 게 도와 주 는 사이트 이 다 . 특징 은 https 를 제공 하 며 , github 의 특정 repo 의 특정 브랜치 가 push 될 때 마다 자동 빌드 배포 를 도와 준다는 점 이 다 . netlify 시작 하 기 아래 순 으로 진행 하 면 된다 . 1 . 가입 한다 . 2 . github , gitlab , bitbucket 중 에서 연결 할 서비스 를 선택 한다 . 3 . 선택 한 서비스 의 특정 repo 를 선택 한다 . 4 . 선택 된 repo 의 branch 를 선택 한다 . 5 . 빌드 될 스크립트 ( 예시 gatsby build ) 를 입력 한다 . 6 . 빌 드 된 폴더 ( 예시 / public ) 를 입력 한다 . 7 . 빌드 와 배포 되 는 것 을 지켜본다 . 이제 해당 브랜치 에 push 할 때 마다 , netlify 에서 자동 으로 해당 내역 을 빌 드 배포 한다 . 추가 적 으로 나중 에 필요 한 도메인 이 있 다면 설정 할 수 있 다 .',\n",
       "       '. 앞선 시간 에 학습 알고리즘 은 인간 의 사고 과정 을 그대로 따라 간다고 말 했 습니다 . . 만약 사람 이 어떤 데이터 를 토대 로 결과 를 예측 했 는데 틀렸 다면 무엇 이 틀렸 는지 확인 하 고 결과 가 올바르 게 나타나 는 방향 으로 수정 할 것 이 고 머신 러닝 을 예측 의 틀린 정도 를 오차 ( error ) 로 생각 하 고 올바른 결과 가 나오 도록 방정식 을 수정 하 는 것 입니다 . . 오차 를 수정 하 는 방식 에 는 최소 제곱법 ( method of least squares — lsm or lms ) 최 우추 정법 ( maximum likelihood method — mle ) 최대 사후 확률 추정 ( maximum a posterior estimation — map ) 기울기 ( 미분 ) 강 하법 ( gradient descent — gd ) 등등 이 있 고 . 오늘 은 이 오 차 를 수정 하 는 방식 에 대해 말 해 보 겠 습니다 . . andrew ng 교수 님 의 명 강의 . 매우 많 은 머신 러닝 강좌 들 이 있 는데 대부분 이 cost function 과 gradient descent 만 을 언급 하 고 넘어가 버립니다 . . 가장 쉽 게 접근 할 수 있 고 적어도 local minimum 을 찾 는다는 보장 이 있 기 때문 에 ( 수학 적 으로 증명 되 어 있 습니다 ) gd 를 선호 하 기 때문 입니다 . . 그렇 다면 백문 이 불여일견 ! 위 에 언급 한 기본 적 인 4 가지 방식 에 대해 설명 하 겠 습니다 . . 1 . 최소 제곱법 ( lsm or lms ) 실제 답 과 결과 값 의 오차 의 제곱 의 합 이 최소 가 되 는 해 를 구하 는 방법 . 머신 러닝 에서 배우 는 가장 단순 한 모델 로 입력 과 출력 의 관계 가 선형 이 라고 가정 합니다 . . 알 고 싶 은 값 예측 방정식 예측 과 알 고 싶 은 값 의 차이 ( 유클리드 거리 ) 의 제곱 >> 오차 의 제곱 의 합 은 위 와 같이 표현 되 며 이 값 을 최소 값 을 구하 기 위해서 최적 화 해야 하 는 변수 에 대해서 각각 편미분 한 값 이 0 이 되 도록 하 는 점 을 찾 는 것 이 겠 지요 . 그러 면 linear regression — wikipedia 위 와 같이 데이터 들 이 있 을 때 오차 의 제곱 이 제일 작 은 ( 값 들 을 깔끔 하 게 통과 하 는 ) 함수 를 얻 을 수 있 는 것 입니다 . . 이 방법 은 간단 한 계산 이 지만 데이터 가 많 아 지 면 계산 량 이 매우 많이 증가 한다는 단점 이 있 습니다 . . 이때 오 차 제곱 의 합 을 cost function 이 라고 하 고 이 는 나중 에 gradient descent 에서 도 사용 하 게 됩니다 . 이번 에 는 확률 의 개념 을 생각 해 보 겠 습니다 . . 2 . 최 우추 정법 ( mle ) — 위키피디아 에서 는 ( 최대 가능 도 방법 ) 이 라고 하 는 군요 원 하 는 결과 가 나올 가능 성 을 최대 로 만드 는 모수 를 선택 하 는 방법 . 말 이 참 어렵 네요 . 쉬운 예제 로 설명 을 해 보 자면 동전 던지 기 를 한다고 생각 해 보 는 겁니다 . . 10 번 던져서 앞 앞 앞 앞 앞뒤 뒤 뒤 뒤 뒤 ( 원 하 는 결과 ) 가 나왔 다고 하 면 동전 던지 기 라는 행위 는 1 / 2 확률 ( 모수 ) 이 라고 생각 할 수 있 습니다 . . 그런데 만약 10 번 다 앞면 만 나왔 다면 ? ?? 정말 극한 의 확률 이 나왔 을 수 도 있 지만 동전 던지 기 라는 행위 가 1 / 2 확률 이 아니 라 다를 것 이 라고 생각 하 는 것 입니다 . ( 가정 입니다 . ) 그래서 10 번 다 앞면 이 나오 려면 동전 던지 기 의 확률 이 어떨 때 가능 성 이 제일 높 을까 ? 를 구하 는 것 입니다 . ( 결과 를 보 고 원인 을 추측 하 는 것 이 지요 ) . 이 를 가능 도 ( likelihood ) 라고 합니다 . . 동전 던지 기 앞면 의 확률 동전 던지 기 앞면 의 확률 을 p ( x = front ) = theta 라고 하 면 . 10 번 다 앞면 이 나온 가능 도 는 10 번 다 앞면 이 나오 는 가능 도 이 라고 할 수 있 습니다 . 당연히 미분 해 볼 필요 도 없이 최대 값 은 p ( x ) = 1 이 겠 네요 . . 7 번 앞면 , 3 번 뒷면 이 라고 하 면 7 번 앞면 3 번 뒷면 나오 는 가능 도 이 라고 할 수 있 을 것 이 고 . 미분 하 여 계산 하 면 최대 값 을 구할 수 있 고 계산 이 매우 귀찮 을 것 이 므로 보통 로그 를 취해서 계산 합니다 . ( 단조 증가 이 므로 경향 변하 지 않 음 ) . 이 부분 에 대한 자세 한 내용 은 매우 매우 수학 적 인 이야기 이 므로 링크 로 첨부 하 겠 습니다 . ( 읽 어 보 시 기 를 추천 합니다 . ) . 최대 가능 도 방법 [ URL ] 계산 에 대한 이야기 [ URL ] . 위 링크 의 글 을 읽 어 보 신 분 에게 한 가지 더 이야기 할 것 이 있 습니다 . 처음 언급 한 lse 와 mle 와 의 관계 에 대한 것 입니다 . lse 에서 본 듯 한 수식 lse 는 데이터 들 과 오 차 가 가장 적 은 선형 해 를 구하 는 것 인데 만약 데이터 들 이 표준 정규분포 ( white gaussian noise ) 로 나타난다면 데이터 들 은 표준 정규 분포 를 따르 는 데이터 들 이 와 같이 나타날 것 이 고 이 를 mle 를 사용 해 보 면 주 어 진 식 을 만족 할 확률 가능 도 로그 를 취해본다 . 로그 를 취한 결과 를 보 면 결국 이전 에 lsm 의 오 차 가 최소 가 되 는 조건 이 mle 의 가능 도 가 최대 가 되 는 것 이 라는 것 을 알 수 있 습니다 . . 결국 lsm 은 mle 에 포함 되 는 개념 이 며 likelihood 라는 척도 로 최적화 를 진행 하 는 것 입니다 . . . 그런데 이 방법 은 큰 문제 가 존재 합니다 . 위 에 동전 을 던질 때 10 번 다 앞면 이 나왔 다면 이 동전 은 100 % 확률 로 앞면 이 나오 는 것 일까요 ? . 아닙니다 . . 데이터 의 수 가 무수히 많 아서 모든 경우 를 고려 하 지 않 는다면 이 방법 은 편협 한 확률 게임 을 할 수 있 습니다 . 그래서 최대 사후 확률 추정 ( map ) 이 등장 합니다 . . continue … . . 2 부 링크 [ URL ] cf ) 오탈 자 혹은 잘못 된 개념 에 대한 피드백 은 항상 환영 합니다 .',\n",
       "       '행렬 을 통해 여러 변수 들 이 상호 작용 을 통해 변화 해 나가 는 과정 을 기술 할 수 있 다 . 예 를 들 어 , x 1 과 x 2 가 상호 작용 하 지 않 는 경우 에 는 다음 과 같이 변화 가 없 음 을 기술 할 수 있 다 . 여기 서 t 는 상호 작용 한 step 수 를 나타낸다 . 또 , x 1 과 x 2 이 서로 값 을 교환 하 는 관계 라면 다음 과 같이 기술 할 수 있 다 . 이렇게 행렬 을 통해 변수 들 의 크기 에 영향 을 받 는 상호 작용 을 기술 할 수 있 다 . 이러 한 기술 을 이용 하 면 step 이 증가 하 면 증가 할 수록 변수 들 이 어떻게 변해 가 는지 를 생각 해 볼 수 있 다 . 이렇게 본다면 , 행렬 의 가역성 이란 현재 상태 와 상호 관계 를 통해 이전 상태 를 예측 할 수 있 는가 하 는 이야기 가 된다 . 위 와 같이 가역 행렬 은 상호 관계 를 표현 하 는 행렬 의 역행렬 로 표시 할 수 있 다 . 현재 의 상태 와 둘 의 관계 를 알 면 , 이전 에 어떠 한 상태 였 는지 알 수 있 게 되 는 것 이 다 . 이러 한 가역 행렬 은 행렬식 이 0 이 아닐 때 존재 할 수 있 다 . 2 차 정방 행렬 은 행렬 요소 를 [ [ a , b ] , [ c , d ] ] 로 표현 할 때 ad - bc 로 구해진다 . 그럼 , ad - bc 를 0 으로 만드 는 비가역 행렬 들 을 살펴보 자 . 공통 적 으로 결과 값 이 특정 한 관계 , 특정 한 수 로 표현 되 는 것 을 알 수 있 다 . 즉 , 변수 들 의 상태 는 늘 같 거나 같 은 비율 을 갖 게 된다 . 그리고 , x 1 과 x 2 에 수많 은 가능 한 변수 들 이 존재 하 게 된다 . 예 를 들 어 , 예 로 제시 한 첫 번 째 비가역 행렬 의 t + 1 때 의 x 1 , x 2 의 값 이 [ [ 0 ] , [ 0 ] ] 인 경우 , \" x 1 + x 2 = 0 \" 을 만족 하 는 모든 변수 들 이 이전 의 상태 가 될 수 있 게 되 는 것 이 다 . 이것 은 x 1 과 x 2 의 두 변수 가 하나 의 관계 에 속해 버림 을 나타낸다 . x 1 과 x 2 의 변수 를 각기 축 으로 설정 하 여 평면 을 그려 본다면 , 초기 x 1 과 x 2 의 상태 는 평면 위 의 한 점 에 해당 된다 . 그런데 , 위 와 같 은 비가역 행렬 을 거치 게 되 면 , 하나 의 점 또는 하나 의 선 으로 x 1 과 x 2 의 상태 가 수축 이 되 어 버린다 . x 1 과 x 2 가 같 은 비율 을 가지 는 것 은 변수 의 상태 가 선 으로 수축 됨 을 나타내 며 , 0 으로 변해 버리 는 것 은 점 으로 수축 됨 을 나타낸다 . 2 차원 평면 이 1 차원 의 선과 0 차원 의 점 으로 수축 되 면 , 본디 2 차원 의 상태 가 어떤 상태 였 는지 알 수 없 게 된다 . 공간 을 나타내 는 정보 가 증발 해 버리 는 것 이 다 . 이 를 통해 x 1 과 x 2 가 강한 상관 을 보이 는 경우 에 대해 생각 해 볼 수 있 다 . 강한 상관 을 보인다는 것 은 행렬식 이 작 은 값 을 가진다는 것 을 의미 하 고 , 행렬식 이 작 다는 것 은 두 변수 가 가질 수 있 는 상태 가 수축 되 어 지 고 있 다는 것 을 의미 한다 . 상태 가 수축 됨 으로써 , x 1 과 x 2 의 상관 관계 가 주어지 게 되 는 것 이 다 . 결론 즉 , 가역 적 인 것 은 약한 상관 을 지닌 작용 , 비가역 적 인 것 은 강한 상관 을 지닌 작용 으로 생각 해 볼 수 있 다 . 그리고 , 상호 관계 를 통해 강한 상관 관계 를 지니 는 변수 들 에게 는 개인 의 값 보다 는 행렬 의 곱 을 통한 변환 이 더 큰 의미 를 지닌다는 것 을 의미 한다 . \" 개인 이 어떠 한 값 을 가지 고 있 었 는가 \" 보다 , \" 어떠 한 반응 이 있 는가 \" 가 앞 으로 의 변화 에 있 어 더 큰 의미 를 가진다는 것 이 다 . 개체 간 의 상호 작용 을 행렬 로 표시 하 는 네트워크 이론 에서 매우 흥미 롭 게 볼 수 있 는 관점 이 될 수 있 을 것 같 다 .',\n",
       "       \"원본 보 기 원본 보 기 [ 김하나 기자 ] 지난해 부터 요동치 는 집값 에 전세 나 월세 로 사 는 임차인 ( 세입자 ) 은 불안 합니다 . 내 가 낸 보증금 을 돌려받 지 못하 면 어쩌 나 하 는 걱정 때문 입니다 . 임대인 ( 집 주인 ) 이 갭 투자자 로 추정 돼 깡통 전세 가 우려 되 거나 , 새로운 임차인 이 구해 지 지 않 는다면 더욱 그렇 습니다 . [ 부동산 법률 방 ] 이 임대인 에게 무슨 일 이 있 어도 내 보증금 을 지킬 수 있 는 방법 을 크 게 세 가지 로 소개 합니다 . 바로 △ 전세 보증 보험 △ 임차권 등기 △ 전세 자금 보증 특례 조치 등 입니다 . 임차인 들 의 사연 과 함께 어떤 경우 에 이러 한 세 가지 방법 을 쓰 면 되 는지 살펴봅니다 . a 씨 는 다 가구 주택 에 거주 하 고 있 습니다 . 다음 주 에 보증금 을 돌려받 는 과정 에서 스트레스 를 받 고 싶 지 않 아 뒤늦 게 나마 전세 보증 보험 에 가입 하 려고 합니다 . 그런데 마침 집 주인 에게 연락 이 왔 습니다 . 최근 에 집 이 팔려서 임대인 이 변경 될 예정 이 라고 합니다 . a 씨 는 고민 에 빠졌 습니다 . 계약서 상 집 주인 이 달라지 는데 이런 경우 전세 보증 보험 에 가입 하 려면 어떻게 해야 하 는 것 이 었 습니다 . 지인 의 얘기 를 들 어 보 면 계약서 를 다시 작성 해야 한다고 합니다 . 그렇 다면 a 씨 는 후 순위 로 밀려 불리 해 지 는 게 아닐까요 ? ☞ 부동산 법률 방 의 박진석 변호사 입니다 . a 씨 는 걱정 없이 주택 도시 보증 공사 ( hug ) 의 ‘ 전세 임대 주택 전세 보증금 반환 보증 ’ 에 가입 하 면 됩니다 . 이른바 ' 전세 보증 보험 ' 으로 불리 는 이 상품 은 임차 계약 이 종료 되 었 음 에 도 임대인 이 전세 보증금 을 반환 하 지 못하 는 경우 hug 가 보증 책임 을 부담 하 게 됩니다 . 과거 에 는 hug 가 세입자 로부터 보증금 반환 채권 을 양 도 받 기 전 에 집 주인 의 확인 ( 동의 ) 절차 를 먼저 거쳐야 했 습니다 . 하지만 현재 제도 상 으로 는 집 주인 의 동의 를 받 을 필요 없이 , 세입자 가 보증금 반환 보증 상품 에 가입 하 면 됩니다 . hug 가 집 주인 에게 위 채권 이 hug 로 양도 됐 다는 통지서 를 보내 는 것 으로 절차 가 끝납니다 . 따라서 집 주인 이 변경 되 더라도 별도 의 계약서 를 작성 할 필요 없이 서류 만 구비 하 셔서 주택 도시 보증 공사 또는 연계 된 은행 에서 가입 하 면 됩니다 . 구비 서류 는 크 게 6 가지 입니다 . ① 임차인 신분증 ② 확정 일자 부 전세 계약서 ③ 보증금 지급 확인 서류 ④ 부동산 등기 사항 전부 증명서 ⑤ 주민 등록 등본 ⑥ 전입 세대 열람 내역 ( 주민 센터 발급 ) 등 입니다 . b 씨 는 새로 이 사갈 집 의 계약 을 최근 마쳤 습니다 . 문제 는 현재 살 고 있 는 집 이 너무 빠지 지 않 는다는 것 입니다 . 전세 계약 상 으로 는 계약 만료 가 한 달 반 정도 남 았 습니다 . 그 때 까지 도 기존 집 이 빠지 지 않 으면 어쩌 나 걱정 입니다 . b 씨 는 임차권 등기 명령 신청 을 고려 하 면서 동시 에 새로 이사 가 는 집 의 대항력 을 위해서 전입 신고 를 바로 할 생각 입니다 . 그렇 다면 기존 집 의 전입 신고 가 없 어 지 기 때문 에 임차권 등기 신청 이 안 되 는 게 아닐까 고민 입니다 . b 씨 는 지인 들 과 방법 을 짜냈 습니다 . 새로 계약 한 집 에 b 씨 가 전입 신고 를 한 후 b 씨 의 어머니 를 세대원 으로 전입 시키 는 겁니다 . 그리고 그 뒤 b 씨 가 기존 집 의 전입 으로 다시 들어가 려는 것 입니다 . 과연 이런 방법 밖 에 없 는 것 일까요 ? ☞ 박 변호사 입니다 . 이사 를 앞둔 분 들 이 라면 누구 나 하 는 고민 입니다 . 지금 살 고 있 는 집 이 나가 지 않 는 것 입니다 . 그렇 다 보 니 임차권 등기 명령 을 생각 하 게 됩니다 . 이 는 ① 임대차 가 종료 된 후 ② 보증금 이 반환 되 지 않 은 경우 의 임차인 만 이 신청 할 수 있 습니다 . 다만 반드시 신청 시 까지 전입 신고 를 유지 할 필요 는 없 습니다 . 주민 등록 을 먼저 이전 한다고 하 더라도 임대차 가 종료 될 때 까지 보증금 을 못 받 았 다면 임차권 등기 명령 신청 에 문제 는 없 습니다 . 지금 살 고 계시 는 집 의 임대차 계약 기간 과 새로 이사 갈 집 에 대한 임대차 계약 기간 이 겹치 지 않 는다면 , 굳이 전입 신고 를 먼저 했 다가 다시 옮긴 후 또 다시 옮길 필요 가 없 습니다 . 설령 일부 기간 이 겹친다고 하 더라도 새로운 집 에 전입 신고 한 다음 , 종전 임대차 계약 기간 만료 를 기다린 후 에 임차권 등기 명령 을 신청 하 시 면 됩니다 . c 씨 는 임대인 ( 집 주인 ) 과 여러 가지 일 을 겪 으면서 신뢰 가 거의 없 는 상태 입니다 . 전세 로 사 는 집 의 만기 가 세 달 전 입니다 . 하지만 집 을 보 러 오 는 사람 도 없 고 시간 만 가 고 있 습니다 . c 씨 또한 새 집 을 아직 구하 지 못해서 곤란 한 상황 입니다 . 보증금 을 돌려받 을 때 까지 집 에 버티 고 있 어도 되 는지 눈치 가 보입니다 . 또 다른 문제 는 c 씨 가 전세 자금 대출 을 받 았 다는 점 입니다 . 새로 이사 갈 집 도 대출 의 도움 을 받 으려고 합니다 . 집 이 안 나가 면 만기일 에 보증금 을 못 받 을 수 도 있 다는 생각 도 듭니다 . 기존 대출 이 미상환 된 상태 에서 새 집 의 전세 대출 이 가능 할지 가 궁금 합니다 . ☞ 박 변호사 입니다 . 임대차 계약 기간 이 종료 하 기 1 개월 전 까지 갱신 하 지 않 겠 다는 의사 를 표시 하 였음에도 임대차 계약 종료 시 에 보증금 을 반환 받 지 못한 경우 에 는 주택 을 인 도 하 지 않 아도 됩니다 . 기존 전세금 대출 이 상환 되 지 않 은 상태 에서 새로운 전세금 대출 이 가능 한지 는 해당 금융 기관 에 문의 하 시 는 것 이 좋 겠 습니다 . 다만 , 한국 주택 금융 공사 에서 는 ' 임대차 계약 이 끝난 후 임차 보증금 을 반환 받 지 못해 주택 임대차 보호법 제 3 조 의 3 에서 정하 는 임차권 등기 명령 신청 접수 후 또는 임차권 등기 완료 후 신규 주택 으로 이주 를 희망 하 는 임차인 ' 으로서 일정 한 요건 을 충족 한 경우 에 는 최대 2 억 원 한도 의 추가 보증 을 제공 하 는 특례 조치 가 있 습니다 . 이 를 참고 하 시 길 바랍니다 . 정리 = 김하나 한경 닷컴 기자 hana @ hankyung . com 답변 = 박진석 법무법인 심평 변호사 ( 피터 팬 의 좋 은 방 구하 기 자문 역 ) 한경 닷컴 바로 가 기 ] [ 모바일 한경 구독 신청 ⓒ 한국 경제 & hankyung . com , 무단 전재 및 재 배포 금지\",\n",
       "       '━ 아이 마음 다이어리 〈 4 〉 주의력 결핍 과잉 행동 장애 ( adhd ) 원본 보 기 2 년 전 초등 학교 1 학년 성철 이 를 만났 다 . 엄마 는 아이 가 초등 학교 입학 후 학용품 을 자주 잃 어 버리 고 숙제 를 안 해도 학교 적응 과정 이 니 차츰 나아지 겠 거니 생각 했 다 . 부모 가 병원 진료 를 결심 한 것 은 여름 방학 때 제주도 가족 여행 이 계기 가 됐 다 . 도착 한 첫날 널찍 한 호텔 로비 를 보 고 흥분 한 성철 이 는 신 이 나 서 이리저리 뛰어다니 다 로비 한복판 의 조형물 에 정면 으로 부딪쳐 이마 가 찢어졌 다 . 가족 여행 은 그렇게 하루 만 에 끝 이 났 다 . 방학 숙제 도 미루 다 개학 하루 앞두 고 몰 아서 시작 했 다 . 처음 병원 에 왔 을 때 엄마 는 성철 이 에 대해 “ 덤벙 댄다 . 뭐 하나 끝 까지 하 는 게 없 다 . 말 이 많 다 . ” 라고 말 했 다 . 엄마 는 거의 매일 성철 이 담임 선생 님 의 전화 를 받 았 다 . “ 성철 이 가 오늘 급식 줄 기다리 다 끼어들 어 친구 와 다퉜 어요 . ” “ 수업 시간 에 지우개 를 조각 내 친구 들 에게 던져서 혼났 어요 . ” 성철 이 는 2 ~ 3 차례 의 면담 과 심층 평가 를 거친 후 주의력 결핍 과잉 행동 장애 ( adhd · attention deficit hyperactivity disorder ) 진단 을 받 았 다 . adhd 는 일반인 에게 유명 한 병명 이 지만 제대로 알 고 이해 하 는 사람 은 많 지 않 다 . 이 병 은 만 6 ~ 12 세 사이 에 발생 하 는 대표 적 인 신경 발달 장애 다 . 1798 년 스코틀랜드 의사 크라이튼 박사 가 지금 의 adhd 와 유사 한 첫 사례 를 보 고 했 다 . 이후 미국 의학 진단 체계 에 공식 적 으로 도입 된 것 은 1968 년 이 다 . 역사 가 오래 된 병 이 다 . adhd 의 대표 증상 은 부주의 와 과잉 행동 , 충동 성 이 다 . 초등학생 10 명 중 1 명 정도 나타나 며 그 중 70 % 는 청소년기 까지 지속 하 고 50 % 는 성인기 까지 이어질 수 있 다 . 성철 이 가 adhd 진단 을 받 은 후 부모 는 2 주 간격 으로 수개월 간 부모 교육 을 받 았 다 . 아이 에게 ‘ 사후 잔소리 보다 사전 알 람 하 기 ’ 를 권고 했 고 가정 내 에서 아이 문제 행동 하나하나 에 대응 할 태도 를 교육 했 다 . 이른바 부모 와 함께 하 는 행동 수정 요법 이 다 . 아이 가 잘 한 행동 에 대해서 는 아낌없이 칭찬 하 되 남 에게 피해 를 주 는 행동 에 대해서 는 미리 아이 와 함께 정한 불 이익 항목 을 이행 하 게 하 는 것 이 다 . 부모 의 태도 와 원칙 이 일관 돼야 하 고 반응 은 즉각 적 이 어야 함 을 강조 했 다 . 나 는 동시 에 성철 이 는 약물 치료 가 필요 하 다고 말 했 다 . 약물 치료 라는 말 에 부모 의 표정 이 심각 해졌 다 . 아이 가 약물 에 중독 되 어 평생 약 에 의존 하 게 될 것 이 라는 걱정 이 컸 다 . “ adhd 증상 이 라고 말씀 하 신 것 들 이 대부분 남자 아이 가 어릴 때 보이 는 모습 아닌가요 ? 저 도 어릴 때 무척 부산 했 는데 지금 은 멀쩡 합니다 . 왜 약물 치료 까지 받 아야 하 는지 솔직히 이해 가 안 갑니다 . ” 성철 이 아빠 는 다소 강한 어조 로 약물 치료 에 대한 반감 을 표현 했 다 . “ 네 맞 습니다 . 보통 아이 들 도 가끔 보일 수 있 는 행동 들 이 죠 . 하지만 일반 적 인 아이 들 은 집중 해야 할 일 이 생기 면 비록 흥미 가 없 어도 40 분 정도 집중 할 수 있 지만 , adhd 아이 들 은 사소 한 자극 에 도 바로 흐트러 집니다 . 잠시 는 집중 할 수 있 지만 수 분 내 다른 곳 으로 초점 이 벗어났 다 돌아오 기 를 반복 하 는 것 이 죠 . 그러 다 보 니 과제 를 끝내 는 시간 이 일반 아이 들 보다 매우 더 딥 니다 . 결국 마무리 를 못 하 기 도 하 고요 . 수업 시간 에 누군가 연필 을 떨어뜨렸 을 때 일반 아이 들 은 신경 을 안 쓰 지만 , adhd 아이 는 ‘ 저 연필 이 어디 에 갔 을까 ? ’ 에 대해 좀 더 길 게 생각 합니다 . 게다가 보통 아이 들 은 이런 일 을 가끔 겪 지만 , adhd 아이 들 은 거의 매일 이런 문제 가 반복 되 어 학교 생활 이나 대인 관계 능력 이 손상 됩니다 . ” 나 는 진료실 책상 위 뇌 모형 의 가장 앞부분 을 가리키 며 설명 을 이 어 갔 다 . “ 여기 가 사람 의 실행 기능 을 담당 하 는 전 전두엽 입니다 . adhd 아이 는 전 전두엽 발달 이 또래 에 비해 느 립니 다 . ” 부모 는 고개 를 끄덕이 며 뇌 모형 을 응시 했 다 . 실행 기능 은 계획 세우 기 , 우선 순위 정하 기 , 작업 기억력 , 자기 객관화 , 자기 조절 능력 등 을 포함 한다 . 작업 기억력 은 일상 생활 에서 필요 한 단기 기억 력 같 은 것 이 다 . 작업 기억력 저하 로 인한 현상 은 다음 과 같 다 . ‘ 아이 가 방 에서 숙제 하 던 중 샤프심 이 없 다 → 샤프심 찾 으러 동생 방 에 간다 → 로봇 조립 하 는 동생 을 본다 → 순간 그 방 에 온 이유 를 까맣 게 잊 는다 → 로봇 조립 하 는 동생 을 참견 한다 → 숙제 를 제시간 에 마치 지 못한다 . ’ adhd 의 증상 은 도파민 이나 노어 에피네프린 과 같 은 신경전달물질 이 수용체 에 제대로 전달 되 지 않 아 전 전두엽 이 원활 하 게 작동 하 지 못해 발현 한다 . 유전 적 영향 을 받 는 신경 발달 장애 이 므로 초기 면담 시 가족력 을 꼼꼼히 점검 해야 한다 . “ 천재 화 가 레오나르도 다빈치 도 adhd 를 지녔 다는 사실 에 대해 혹시 들 어 보 신 적 이 있 나요 ? ” 나 는 10 여 년 전 학회 차 피렌체 를 방문 했 을 때 관람 했 던 그 의 대표 적 인 미완성 작품 ‘ 동방 박사 의 경배 ’ 를 떠올리 며 다빈치 이야기 를 시작 했 다 . “ 이탈리아 피렌체 우피치 미술관 에 는 다빈치 의 미완성 작품 들 이 전시 된 방 이 있 습니다 . ” 국내외 많 은 adhd 전문가 들 은 강의 나 부모 교육 시간 에 다빈치 에 대해 자주 언급 하 는 편 이 다 . 부모 는 흥미 롭 다는 표정 으로 내 말 에 귀 를 기울였 다 다빈치 가 일생 완성 한 작품 은 20 점 을 넘기 지 못한다 . 왜 그렇게 미 완성작 들 이 많 은 걸까 ? 미국 의 유명 전기 작가 월터 아이작슨 은 최근 저서 『 레오나르도 다빈치 』 에서 “ 레오나르도 는 구상 을 현실 화 하 는 것 보다 미래 를 위한 구상 자체 를 좋아해서 현재 에 집중 하 지 못하 고 쉽 게 산만 해졌 다 . 그 는 인내심 을 훈련 받 지 못한 천재 였 다 ” 라고 말 한다 . 다빈치 도 작품 을 마무리 하 지 못하 고 중도 포기 가 많 은 자신 의 모습 때문 에 상당히 괴로워했 다고 한다 . 새로운 펜촉 을 테스트 하 거나 무료 한 시간 을 보낼 때 노트 에 “ 무엇 이 라도 완성 된 것 이 있 는지 말 해 봐 … 말 해 봐 … ” 라는 문장 을 반복 해 쓸 정도 였 다 . 그 에게 작품 을 의뢰 하 려다가 도 그 가 작품 을 완성 하 지 못할 것 이 라는 의구심 에 후원 과 의뢰 를 망설인 사람 이 많 았 다고 한다 . 다빈치 가 인류 역사 상 다재다능 한 천재 임 은 부인 할 수 없 지만 , 집중력 과 끈기 부족 으로 주변 사람 들 과 동료 들 에게 신뢰감 을 주 지 못했 음 을 알 수 있 다 . 그 탓 인지 경제 적 으로 도 늘 돈 이 부족 했 다고 전해진다 . 성철 이 에 대한 이야기 로 돌아갔 다 . “ 성철 이 도 많이 힘들 겁니다 . 진료 첫날 아이 에게 소원 을 물 었 을 때 그 대답 을 잊 을 수 가 없 어요 . ‘ 차분 해 지 고 싶 어요 . 더 는 혼나 고 싶 지 않 아요 . 칭찬 받 고 싶 어요 ’ 라고 답 했 거든요 . 아이 가 일부러 그러 는 것 이 아닌데 부모 나 선생 님 께 늘 혼나 기 만 하 니 자꾸 위축 되 고 마음속 깊이 화 도 쌓이 게 되 어 우울증 과 같 은 정서장애 가 추가 로 생길 수 가 있 습니다 . ” 부모 는 원인 에 근거 한 치료법 의 취지 를 잘 이해 했 고 성철 이 는 약물 치료 를 시작 했 다 . 성철 이 의 문제 행동 들 은 하나 둘 씩 개선 되 기 시작 했 다 . 겨울 방학 에 는 그룹 사회 성 치료 와 놀이 치료 도 병행 했 다 . 혼나 는 빈도 가 확연히 줄 었 고 자신 감 이 생겼 다 . 단짝 도 생기 고 반 친구 들 에게 인기 도 많 아 졌 다 . 운동 신경 이 특히 뛰어나 축구 나 농구 를 잘 했 다 . 부산 스럽 고 충동 적 인 행동 들 에 가려 보이 지 않 던 성철 이 의 강점 들 이 빛 을 발하 기 시작 했 다 . 10 개월 정도 지났 을 무렵 부모 는 성철 이 가 이제 학교 생활 도 잘 하 고 부모 와 관계 도 많이 좋 아 졌으니 병원 에 그만 오 고 싶 다고 말 했 다 . 치료 가 효과 가 없 어서 가 아니 라 오히려 효과 가 드라마틱 하 니 아이 가 평생 병원 에 의존 할까 봐 겁 이 난다고 했 다 . 성철 이 가 치료 를 중단 한 지 1 년 이 되 어 간다 . 올해 3 학년 이 되 었 을 성철 이 가 코로나 상황 에서 온라인 수업 과 등교 를 병행 하 는 이 시기 를 잘 버티 고 있 기 를 진심 으로 바란다 . ※ 개인 정보 보호 를 위해 등장인물 을 가명 으로 처리 했 고 , 전체 흐름 을 왜곡 하 지 않 는 범위 에서 일부 내용 을 각색 했 음 을 알려 드립니다 . 천근 아 연세대 세브 란스 병원 소아 정신 과 교수 연세대 학교 의과 대학 을 졸업 하 고 동대 학원 에서 석 · 박사 학위 를 받 았 다 . 2008 년 영국 국제 인명 센터 ( ibc ) 의 ‘ 세계 100 대 의학자 ’ 로 선정 . 서울시 교육청 자문 위원 , 가정 법률 상담소 교육 위원 , 법무부 여성 아동 정책 심 의 위원 으로 활동 했 다 . 저서 로 는 『 아이 는 언제나 옳다 』, 『 엄마 나 는 똑똑 해 지 고 있 어요 』 가 있 다 . ▶ 중앙 sunday [ 홈페이지 ] ⓒ 중앙 sunday ( [ URL ] and 중앙일보 ( [ URL ] 무단 전재 및 재 배포 금지',\n",
       "       'dgist 뇌 · 인지 과학 전공 분자 정신 의 학연 구실 오용석 ( 왼쪽 앞 ) 교수 연구 팀 dgist 뇌 · 인지 과학 전공 분자 정신 의 학연 구실 오용석 ( 왼쪽 앞 ) 교수 연구 팀 【 대구 = 뉴시스 】 박준 기자 = 대구경북 과학 기술원 ( dgist ) 은 뇌 · 인지 과학 전공 분자 정신 의 학연 구실 오용석 교수 연구 팀 이 뇌 속 해마 구역 내 감정 조절 신경 회로 를 구성 하 는 모시 신경 세포 의 활성 변화 가 세로토닌 계 항우울제 의 치료 효능 에 결정 적 인 역할 을 한다는 사실 을 규명 했 다고 16 일 밝혔 다 . 우울증 은 적기 에 치료 받 지 못하 면 , 환자 및 가족 의 삶 의 질 을 황폐 화 시킬 뿐 만 아니 라 극단 적 인 경우 자살 에 까지 이르 게 되 는 심각 한 정신 질환 이 다 . 우리 나라 는 oecd 국가 중 높 은 자살 율 을 기록 ( 인구 10 만 명 당 24 . 3 명 , 2017 년 기준 ) 해 왔으며 총 5664 억 원 의 의료비 가 지출 되 는 등 사회 · 경제 적 으로 심각 한 사회 문제 로 떠오르 고 있 다 . 현재 우울증 의 치료 를 위해서 는 세로토닌 계 항우울제 ( ssri · snri ) 가 가장 광범위 하 게 처방 되 고 있 지만 높 은 약물 저항성 , 다양 한 부작용 , 치료 효과 지연 등 과 같 은 여러 약점 을 가지 고 있 다 . 또한 항우울제 투여 후 신경 계 내 세로토닌 증가 는 1 시간 이내 에 즉각 일어나 지만 환자 의 기분 개선 을 포함 한 치료 효과 는 빨라야 2 ~ 3 주 , 평균 적 으로 2 달 이상 의 장기 투여 후 에 나 나타난다 . 이러 한 치료 효과 의 지연 현상 은 단순히 세로토닌 의 양 이 효능 을 좌우 하 는 것 이 아니 라 감정 조절 신경 회로 의 근본 적 인 활성 변화 를 유도 함 으로써 효능 을 나타낼 것 이 라는 것 을 암시 해 왔 다 . 하지만 이 와 관련 한 메커니즘 은 아직 잘 알려져 있 지 않 았 다 . 오 교수 연구 팀 은 특히 이번 연구 를 통해 해마 신경 회로 를 구성 하 는 모시 세포 가 항우울제 의 단기 투여 가 아닌 장기 투여 조건 에서 만 활성 이 증가 한다는 것 과 이러 한 약물 에 의한 신경 회로 의 가소 성 변화 가 항우울제 의 직접 적 인 효능 에 필수 적 이 라는 사실 을 밝혔 다 . 주목 할 점 은 모시 세포 의 단기간 활성 유도 만 으로 도 항우울제 의 장기 처방 과 유사 한 정도 의 성 체신 경발 생활 성 과 부분 적 감정 행동 의 변화 를 일으키 는데 충분 했 다는 사실 이 다 . 또 기존 항 우울 약물 의 느린 치료 효과 를 극복 하 고 목적지 에 빨리 도달 할 수 있 는 지름길 을 개척 할 수 있 는 단서 를 발견 했 다 . 모시 세포 는 해마 신경 회로 를 구성 하 는 신경 세포 의 한 종류 이 다 . 오용석 교수 는 \" 항우울제 의 장기 처방 이 해마 모시 신경 세포 의 활성 조절 과정 을 거쳐 약물 효과 를 나타낸다는 사실 을 밝혔 다 \" 고 말 했 다 . 오 교수 는 이어 \" 이 는 항우울제 의 치료 지연 반응 과 연관 된 신경 세포 활성 변화 조절 현상 을 발견 했 다는 점 을 고려 할 때 기존 치료 약물 의 단점 을 극복 한 높 은 약물 순응 도 와 속성 - 차세대 항우울제 개발 을 위한 중요 한 단서 를 제공 해 줄 것 으로 기대 된다 \" 고 밝혔 다 . 한편 이번 연구 결과 는 세계 최고 수준 의 정신 의학 학술지 인 분자 정신 의 학지 ( molecular psychiatry ) 올해 3 월 호 온라인 판 에 게재 됐 다 . june @ newsis . com',\n",
       "       '과학 기술 정보 통신부 로고 © news 1 ( 서울 = 뉴스 1 ) 이창규 기자 = 과학 기술 정보 통신부 가 정보 통신 기획 평가 원 과 \\' 2020 년 혁신 성장 청년 인 재 집중 양성 \\' 을 통해 4 차 산업 혁명 핵심 분야 청년 실무 인 재 1700 명 을 양성 한다고 1 일 밝혔 다 . 올해 로 3 년 째 인 혁신 성장 청년 인 재 집중 양성 사업 은 만 34 세 이하 의 청년 구직자 를 산업 현장 에 즉시 투입 가능 한 소프트웨어 실무 인재 로 양성 해 4 차 산업 분야 내 일자리 미스 매칭 을 해소 하 고 취업 과 연계 하 는 사업 이 다 . 4 차 산업 혁명 이 전 세계 적 으로 화두 가 되 고 있 지만 정작 기업 일선 에서 는 관련 인재 가 없 다는 문제 가 계속 지적 돼 왔 다 . 이 에 과기 정통부 는 4 차 산업 혁명 핵심 분야 청년 실무 인재 를 2 차 에 걸쳐 공모 할 예정 이 다 . 1 차 공모 는 4 월 말 까지 기존 에 선정 된 21 개 교육 기관 ( 27 개 과제 ) 을 통해 4 차 산업 선도 8 대 분야 에서 1290 명 의 교육 생 을 모집 하 고 2 차 공모 는 5 월 말 까지 교육 기관 신규 선정 후 5 대 분야 에서 600 명 규모 의 교육 생 을 모집 한다 . 목표 인 1700 명 을 초과 해 모집 하 는 이유 에 대해 과기 정통부 는 \" 2018 년 시범 사업 을 실시 한 결과 취업 이나 학업 복귀 등 의 이유 로 중도 이탈자 가 많이 나왔 다 \" 며 \" 그래서 중도 이탈자 를 고려 해 1700 명 에서 14 % 추가 한 1900 명 정도 를 모집 한다 \" 고 설명 했 다 . 1 차 공모 에서 는 δ 인공지능 δ 클라우드 δ 빅 데이터 δ 블록체인 δ 증강현실 ( ar ) · 가상현실 ( vr ) δ 자율 주행 차 δ 드론 δ 스마트 공장 등 의 분야 와 관련 해 교육 생 을 모집 하 고 . 2 차 공모 에서 는 증강현실 ( ar ) · 가상현실 ( vr ) , 자율 주행 차 , 드론 분야 는 제외 된다 . 교육 생 들 은 학급 당 최소 24 명 규모 로 편성 돼 주 40 시간 ( 1 일 8 시간 ) , 총 6 개월 ( 960 시간 ) 에 걸쳐 산업체 전문가 의 맞춤 형 멘토링 을 통해 프로젝트 과제 를 집중 적 으로 수행 한다 . 또한 모든 교육 과정 은 국비 로 진행 되 며 교육 기간 중 모든 교육 생 에게 식비 와 교통비 등 생활 지원금 도 지급 된다 . 과제 평가 우수 교육 생 으로 선발 되 면 해외 정보 통신 기술 ( ict ) 우수 기관 을 견학 할 수 있 는 기회 도 주어진다 . 아울러 각 교육 기관 은 채용 의사 가 있 는 기업 과 협력 관계 를 구축 , 기업 방문 과 간담회 등 취업 지원 활동 을 지속 적 으로 추진 한다 . 과기 정통부 송경희 소프트웨어 정책 관은 \" 인공지능 · 빅 데이터 등 4 차 산업 핵심 분야 실무 지식 을 두루 갖춘 젊 은 인재 들 이 창업 에 도 도전 해 소프트웨어 기반 의 신 산업 을 활성 화 하 고 새로운 일자리 도 창출 해 줄 것 \" 이라고 말 했 다 . yellowapollo @ news 1 . kr',\n",
       "       '( 시사저널 = 조유 빈 기자 ) 우울 하 다 . 무기력 하 다 . 감염병 관련 뉴스 를 보 는 데 많 은 시간 을 할애 한다 . 확진 자 가 증가 하 면 불안감 은 더 커진다 . 반복 되 는 일상 이 지겹 다 . \\' 집 콕 생활 \\' 에 도 지쳤 다 . 기침 을 하 면 불안 하 다 . 혹시나 신종 코로나 바이러스 감염증 ( 코로나 19 ) 에 걸린 것 은 아닐까 걱정 된다 . 이제 정말 과부하 가 걸렸 다 . 코로나 19 의 2 차 대유행 조짐 이 보이 면서 이렇게 국민 들 의 정신 건강 에 도 빨간불이 켜졌 다 . \\' 코로나 우울 \\' 이 다 . 세계 보건 기구 ( who ) 는 코로나 19 로 인한 정신 건강 악화 를 \\' 정신 보건 분야 에 전례 없 는 위기 \\' \\' 초대 형 악재 \\' 라고 표현 했 다 . 감염 을 두려워하 는 이 들 , 방역 조치 에 영향 을 받 는 이 들 까지 도 정신 보건 을 위협 받 고 있 다는 것 이 다 . who 는 최근 정신 건강 지원 사업 을 코로나 19 대유행 대응 의 핵심 요소 로 고려 하 는 것 이 시급 하 다는 의견 을 내놓 았 다 . \\' 코로나 우울 \\' 은 심각 한 사회 적 문제 가 됐 다 . ⓒ freepik 두려움 · 일상 생활 변화 가 스트레스 로 이어져 코로나 우울 은 코로나 19 확산 으로 일상 에 큰 변화 가 닥치 면서 생긴 우울 감 이나 무기력증 을 뜻 한다 . 코로나 19 와 우울 감 ( blue ) 이 합쳐진 신조어 \\' 코로나 블루 \\' 를 대체 하 는 단어 다 . 어려운 용어 로 인해 정보 에서 소외 되 지 않 도록 문화 체육관 광부 와 국립 국어 원 이 쉬운 우리말 로 다듬 었 다 . 병 에 대한 두려움 외 에 도 격리 나 사회 적 거리 두기 를 통해 일상 생활 에 변화 가 생기 는 것 , 코로나 19 사태 에 따른 경제 적 어려움 도 원인 이 될 수 있 다 . 급격 한 스트레스 상황 에서 나타나 는 신체 증상 인 불면증 , 식욕 이상 , 소화 불량 , 두 통 , 어지럼 , 답답 함 등 이 대표 적 인 증상 이 다 . 적당 한 불안 은 감염병 확산 방지 에 도움 이 될 수 있 다 . 일종 의 경고 등 역할 을 하 면서 개인위생 을 지키 거나 사회 적 거리 두기 에 참여 하 게 하 는 촉매제 가 된다 . 그러나 불안 이 확장 되 고 스트레스 가 과도 해 지 면 그것 은 정신 건강 과 직결 된다 . 실제로 코로나 19 로 인한 우울 을 겪 고 있 는 사람 들 이 늘어나 고 있 다 . 시장 조사 기관 엠브레인 트렌드모니터 가 2020 년 7 월 전국 만 19 ~ 59 세 성인 남녀 1000 명 을 대상 으로 실시 한 온라인 설문 조사 결과 에 따르 면 코로나 우울 을 경험 했 다고 응답 한 비율 은 35 . 2 % 에 달했 다 . 3 명 중 1 명 이상 이 코로나 우울 을 호소 한 셈 이 다 . 남성 ( 28 . 8 %) 보다 는 여성 ( 41 . 6 %) 의 응답 률 이 상대 적 으로 높 았 다 . 직업 별 로 보 면 바깥 활동 이 적 은 전업주부 가 48 . 8 % 로 코로나 우울 증상 을 가장 많이 경험 하 고 있 었 다 . 대학생 · 대학원생 ( 43 . 8 %), 코로나 19 로 인해 수입 에 영향 을 받 는 프리랜서 ( 37 . 0 %) 등 이 뒤 를 이 었 다 . 코로나 우울 로 인한 사회 적 불안 도 커 지 고 있 다 . \\' 공공 안전 을 위협 할 수 있 는 타인 의 일탈 에 대한 비난 강도 가 상당히 높 아 진 것 같 다 \\' 는 데 81 . 3 % 가 동의 했 다 . \\' 코로나 19 로 많 은 사람 들 의 신경 이 곤두서 있 는 것 같 다 \\' 는 항목 에 도 73 . 2 % 가 \" 그렇 다 \" 고 답했 다 . \\' 일상 적 인 행위 에 도 날카로운 반응 을 보이 는 것 같 다 \\' 는 응답 도 69 % 에 달했 다 . 이런 상황 이 기에 응답자 들 은 심리 방역 의 중요 성 을 강조 했 다 . 전체 응답자 의 84 . 6 % 가 \" 심리 방역 이 그 어느 때 보다 중요 해진 것 같 다 \" 고 답했 다 . 코로나 19 관련 심리 상담 41 만 건 이상 코로나 우울 은 젊 은 층 에서 더 심각 하 다 . 20 대 는 경제 적 측면 , 주거 , 취업 문제 등 에서 코로나 19 의 여파 와 가장 맞닿 아 있 는 세대 다 . 알바 몬 이 8 월 24 일 20 대 성인 남녀 4550 명 을 대상 으로 설문 조사 를 실시 한 결과 , 20 대 중 70 . 9 % 가 코로나 우울 을 겪 고 있 다고 응답 했 다 . 증상 은 답답 함 ( 57 . 9 %) 과 무 기력 함 ( 55 . 1 %) 이 가장 많 았 으며 , 주변 사람 들 에 대한 경계심 증가 ( 19 . 2 %), 감정 기복 ( 17 . 5 %) 이 뒤 를 이 었 다 . 코로나 우울 을 겪 는 이유 로 는 코로나 19 가 언제 끝날지 모른다는 불안 과 일자리 감소 로 취업 이 안 될 것 같 은 불안감 , 취미 활동 제한 으로 오 는 우울 감 , 소득 감소 로 인한 경제 적 불안감 등 이 꼽혔 다 . 실제로 코로나 19 와 관련 된 심리 상담 도 크 게 늘어났 다 . 국가 트라우마 센터 에 따르 면 1 월 29 일 부터 8 월 26 일 까지 국가 트라우마 센터 와 정신 건강 복지 센터 등 에서 이뤄진 코로나 19 관련 심리 상담 건수 는 총 41 만 6125 건 에 이른다 . 지난해 35 만 3388 건 을 이미 훌쩍 넘어섰 다 . 8 월 초 까지 상담 한 건수 는 37 만 여 건 이 었 는데 , 코로나 19 감염 이 지속 되 고 2 차 대유행 이 시작 되 면서 상담 건수 가 크 게 늘어났 다 . 사회 학자 렌 펄 린 의 스트레스 확산 개념 에 따르 면 스트레스 는 다른 영역 으로 확산 되 면서 정신 건강 에 영향 을 미친다 . \\' 코로나 19 감염 위험 \\' 이 라는 1 차 스트레스 를 넘 어 사회 적 고립 , 외로움 , 가족 간 갈등 증가 등 2 차 스트레스 로 이어질 가능 성 이 있 다는 것 이 다 . 이 때문 에 스트레스 확산 을 막 기 위해서 는 개인 적 인 노력 과 사회 적 지원 , 스트레스 대처 능력 등 이 요구 된다 . 정부 도 심각 성 을 인식 하 고 코로나 우울 을 예방 하 기 위한 대책 을 마련 하 고 있 다 . 중앙 재난 안전 대책 본부 는 국민 들 을 대상 으로 심리 상담 핫라인 ( 1577 - 0199 ) 을 운영 하 고 있 다 . 추가 적 인 심리 지원 대책 도 추진 한다 . 박 능 후 보건 복지 부 장관 은 \" 코로나 장기 화 로 인한 사회 적 고립 , 외출 자제 등 으로 불안감 과 우울 이 증가 하 고 이 로 인한 자살 증가 우려 도 확산 하 고 있 다 \" 며 \" 국가 트라우마 센터 소셜 미디어 와 정신 건강 자 가 진단 앱 등 을 통해 전 국민 심리 자 가 진단 을 추진 할 예정 \" 이라고 밝힌 바 있 다 . 카카오톡 으로 국가 트라우마 센터 를 친구 등록 하 면 마음 건강 검사 를 통해 무료 자 가 진단 을 할 수 있 다 . 국립 정신 건강 센터 의 정신 건강 자 가 검진 앱 을 다운로드 해 진단 하 는 방법 도 있 다 . 심리 방역 의 중요 성 이 강조 되 면서 , 앱 을 통한 자 가 검진 처럼 비대 면 정신 건강 관리 를 할 수 있 는 방법 들 도 주목 된다 . 국립 정신 건강 센터 는 최근 \" 마음 성장 프로그램 앱 인 \\' 마성 의 토닥토닥 \\' 의 우울 및 불안 증상 을 감소 시키 는 효과 가 연구 결과 로 확인 돼 스마트 의료 분야 국제 학술지 인 \\' telemedicine and e - health \\' 에 게재 됐 다 \" 고 밝혔 다 . 마성 의 토닥토닥 은 고려 대학교 허지원 교수 연구 팀 과 덕성 여 대 최승원 교수 연구 팀 이 보건 복지 부 의 지원 을 받 아 개발 한 앱 이 다 . 센터 는 실제로 코로나 19 지원 현장 에 파견 된 근무자 가 앱 을 사용 해 심리 적 완화 에 도움 을 받 은 사례 를 제시 하 기 도 했 다 . 지자체 등 도 코 로 나 우울 대책 내놓 아 지자체 에서 도 각 정신 건강 복지 센터 등 의 비대 면 전화 상담 을 통해 심리 상담 을 진행 하 고 , 각각 의 심리 백신 을 마련 하 고 있 다 . 서울시 코 비드 19 심리 지 원단 은 마음 의 스트레스 를 풀 어 나갈 수 있 는 지침 을 제공 하 는 \\' 마음 처방전 \\' 을 제공 하 고 있 고 , 경기도 와 경기도 정신 건강 복지 센터 는 온라인 무료 심리 면역 프로그램 \\' spring \\' 을 운영 한다 . 광주 광역시 는 \\' 마음 뽀짝 \\' 캠페인 을 열 고 , 광역 정신 건강 복지 센터 마음 뽀짝 홈페이지 의 자 가 검진 코너 를 통해 마음 건강 을 체크 하 고 무료 상담 을 할 수 있 도록 했 다 . 대구시 는 시 · 구 · 군 청소년 상담 복지 센터 와 함께 청소년 코로나 우울 극복 심리 방역 서비스 를 제공 하 고 있 다 . 각 지자체 의 심리 방역 프로그램 을 확인 해 정신 건강 을 회복 하 는 것 도 중요 하 다 . 무엇 보다 중요 한 것 은 개인 의 마음가짐 이 라고 전문가 들 은 조언 한다 . 대한 신경 정신 의 학회 는 \\' 마음 건강 지침 \\' 을 통해 코로나 우울 에 대처 하 기 위한 자세 를 강조 하 고 있 다 . 불 확실 한 정보 는 불안 과 스트레스 를 가중 하 고 이성 적 인 판단 을 어렵 게 하 기 때문 에 질병관리본부 에서 제공 하 는 정보 에 집중 하 고 , sns 와 뉴스 를 과도 하 게 확인 하 지 말 것 을 권고 한다 . 신종 감염병 은 많 은 것 이 불 확실 하 기 에 스스로 통제 가능 한 활동 으로 주의 를 전환 할 것 , \\' 혐오 \\' 는 감염 위험 이 있 는 사람 을 숨 게 만들 어 방역 에 어려움 을 겪 게 하 기 때문 에 자제 할 것 을 제안 한다 . 가족 과 친구 , 동료 와 화상 전화 나 온라인 을 이용 해 지속 적 으로 소통 하 면서 외로움 과 소외감 을 물리치 는 것 도 중요 하 다 . 정신 건강 을 지키 기 위해 규칙 적 인 식사 와 운동 , 수면 습관 도 유지 해야 한다 . 과도 한 두려움 이나 공포감 에 압도 돼 있 다면 정신 건강 전문가 와 의 상담 이 필요 하 다 . 우울증 검사 를 통해 코로나 19 와 관련 한 심리 건강 을 체크 해 볼 수 있 다 . 아래 에 있 는 자 가 진단 리스트 를 통해 심리 건강 을 진단 해 보 자 . 전문가 들 은 두 가지 질문 으로 이뤄진 우울증 자 가진 단표 ( phq 2 ) 의 점수 가 3 점 이상 일 경우 , 병원 을 찾 아 심리 건강 을 측정 해 볼 것 을 강조 한다 . 홍승봉 삼성 서울 병원 신경 과 교수 는 \" 일단 우울증 자 가진 단표 ( phq - 2 ) 로 자신 의 상태 를 확인 할 수 있 다 . 두 질문 의 점수 가 3 점 이상 이 면 우울증 이 므로 반드시 병원 을 찾 아야 한다 . 우울증 선별 질문지 ( phq - 9 ) 로 우울증 의 정도 를 측정 하 고 , 상담 을 통해 환자 에게 맞 는 치료법 을 찾 는다 \" 고 설명 했 다 .',\n",
       "       '31 일 낮 수도 권 대형 쇼핑몰 에 입점 한 프랜차이즈 카페 가 붙여 놓 은 안내문 . 내부 테이블 은 모두 치운 상태 로 테이크 아웃 고객 만 받 고 있 었 다 . / 사진 = 김남이 기자 \" 도심 의 개인 카페 가 영향 을 받 지 동네 카페 는 큰 변화 없 습니다 . \" 프랜차이즈 카페 의 실내 영업 이 금지 되 면서 동네 카페 가 반사 이익 을 볼 것 이 라는 전망 이 나왔 으나 실제 상인 들 은 변화 가 없 다는 반응 이 다 . 반사 이익 을 보 는 카페 는 동네 카페 가 아니 라 대 규모 ‘ 도심 카페 ’ 라는 설명 이 다 . ━ 주택가 동네 카페 \" 이미 손 님 줄 어서 . .. 2 . 5 단계 큰 영향 없 어 \" ━ 정부 는 기존 보다 강화 된 사회 적 거리 두 기 ‘ 2 . 5 단계 ’ 를 지난 30 일 부터 시행 했 다 . 수도 권 프랜차이즈 카페 는 매장 내 음식 · 음료 섭취 가 금지 되 고 , 일반 음식점 · 휴게 음식점 · 제과점 은 밤 9 시 부터 다음 날 오전 5 시 까지 는 포장 · 배달 만 허용 된다 . 31 일 서울 시내 의 한 햄버거 전문점 앞 으로 시민 들 이 지나가 고 있 다 . 사회 적 거리 두기 2 . 5 단계 시행 으로 프랜차이즈 형 커피 전문점 에 대해 취식 이 불 가능 하 면서 실내 취식 이 가능 한 패스트푸드 전문점 을 찾 는 시민 들 이 늘어나 고 있 다 . / 사진 = 뉴스 1 2 . 5 단계 가 시행 되 면서 기존 프랜차이즈 카페 고객 이 실내 영업 이 가능 한 동네 카페 나 제과점 으로 몰릴 것 이 라는 분석 이 나왔 다 . 실제 지난 30 일 몇몇 도심 제과점 에 고객 이 가득 찬 모습 이 보이 기 도 했 다 . 하지만 취재진 이 만난 상인 들 의 대답 은 달랐 다 . 반사 이익 을 보 는 것 은 주변 에 프랜차이즈 카페 가 많 았 던 도심 에 있 는 개인 카페 라는 설명 이 다 . 서울 강북구 미아 사거리 에서 개인 카페 를 운영 하 는 a 씨 는 \" 프랜차이즈 카페 가 주변 에 있 던 개인 카페 나 제과점 이 반사 이익 을 보 지 동네 상권 에 있 는 카페 는 큰 영향 이 없 는 것 같 다 \" 고 말 했 다 . 그 는 \" 평소 에 보이 지 않 던 손 님 이 2 ~ 3 명 보였으나 이번 조치 와 상관 이 있 는지 는 모르 겠 다 \" 며 \" 이번 조치 를 취할 때 업체 의 형태 가 아니 라 평수 를 기준 으로 했 으면 좋 았 을 것 같 다 \" 고 전했 다 . ━ 도심 직장인 \" 제과점 이나 패스트 푸드 점 찾 아 \"... 낮 시간 에 도 썰렁 한 쇼핑몰 ━ 서울 에서 카페 를 운영 하 는 이윤재 씨 ( 29 ) 도 2 . 5 단계 영향 은 아직 없 다는 이야기 를 했 다 . 이 씨 는 “ 이미 어려웠 기 때문 에 2 . 5 단계 시행 됐 다고 아직 체감 되 는 건 없 다 ” 며 “ 잘 모르 는 손 님 은 개인 카페 에서 도 테이크 아웃 만 되 냐고 물 어 봤 다 ” 고 말 했 다 . 31 일 낮 수도 권 대형 쇼핑몰 의 푸드 코트 모습 . 점심 시간 직전 이 지만 대부분 의 좌석 이 비 어 있 었 다 . / 사진 = 김남이 기자 도심 의 개인 카페 나 제과점 형 카페 가 반사 이익 을 보 는 것 은 고정 적 수요 때문 으로 보인다 . 서울 강남 에서 근무 하 는 직장 인 b 씨 는 \" 업무상 외부 에서 고객 을 만날 곳 이 마땅 치 않 다 \" 며 \" 근처 제과점 형 카페 를 찾 거나 음료 가 나오 는 패스트푸드 점 을 찾 게 된다 \" 고 말 했 다 . 몇몇 재택근무 자 들 도 갈 곳 을 잃 었 다 . 직장 이 김 모 씨 는 \" 집 에 있 으면 늘어지 는 경우 가 있 어 쾌적 한 근처 프랜차이즈 카페 를 자주 찾 았 다 \" 며 \" 당분간 은 정말 ‘ 재택 근무 ’ 를 해야 할 것 같 다 \" 고 전했 다 . 일반 상인 들 은 2 . 5 단계 조치 에 크 게 영향 을 받 지 않 는 낮 시간 에 도 손 님 이 줄 었 다고 전했 다 . 시민 들 이 바깥출입 자체 를 꺼려 서다 . 31 일 낮 스타 벅스 리버사이드 팔 당 dt 점 의 모습 . 평일 에 도 낮 에 도 사람 이 가득차 는 곳 이 만 이날 은 주차장 이 한산 하 다 . / 사진 = 김남이 기자 31 일 기자 가 찾 은 수도 권 대형 쇼핑몰 에 는 평소 보다 손 님 이 크 게 준 것 이 눈 에 띄 었 다 . 점심 시간 이 었 지만 푸드 코트 에 사람 이 거의 없 었 다 . 고객 이 매우 적 어 보인다는 기자 의 질문 에 한 상인 은 \" 정말 ( 손 님 이 ) 없 어요 \" 라며 말끝 을 흐렸 다 . 드라이브 스루 카페 도 큰 변화 는 없 었 다 . 가장 인기 가 많 은 드라이브 스루 카페 로 꼽히 는 스타 벅스 리버사이드 팔 당 dt 점 도 평이 했 다 . 지난 30 일 차량 이 길 게 줄 선 모습 이 보였으나 시행 첫날 과 주말 이 겹쳐 발생 한 현상 으로 보인다 . 오히려 평일 낮 에 도 꽉 차 던 주차장 이 한산 한 모습 이 었 다 . 프랜차이즈 카페 업계 관계자 는 \" 가맹점 주 의 매장 매출 이 줄어들 것 같 아 걱정 은 된다 \" 면서 도 \" 상황 이 엄중 한 만큼 정부 가 지시 한 방역 지침 을 잘 따를 것 \" 이라고 말 했 다 . 김남이 기자 kimnami @ mt . co . kr , 정경훈 기자 straight @ mt . co . kr',\n",
       "       '코로나 확산 으로 집 에서 만 지내 는 ‘ 집 콕 ’ 생활 이 늘 면서 운동량 이 부족 해 근육 이 줄어들 었 다는 사람 이 늘 었 다 . ‘ 확 찐 자 ’ 에 이 어 ‘ 근 감소 자 ’ 의 출현 이 다 . 고령자 는 더 그렇 다 . 노화 로 인해 그렇 지 않 아도 줄어드 는 근육 인데 , 신체 활동 이 줄 면서 근육 퇴행 에 대한 우려 가 높 다 . 나이 가 들 어 근육 량 이 줄 면 몸 의 자세 가 앞 으로 기울 기 쉽 다 . 척추 골다공증 은 앞쪽 부터 생겨서 앞쪽 척추 높이 가 낮 아 진다 . 자연스레 몸 이 앞 으로 쏠리 며 처진다 . 근육 훈련 으로 몸 을 바로 세우 고 균형 을 잡 는데 필요 한 몸 ‘ 뒷 근육 ’ 강화 가 무엇 보다 중요 하 다 . 뒷 근육 이 퇴화 하 면 극단 적 으로 ‘ 꼬부랑 할머니 ’ 처럼 땅 만 보 고 살 아야 할 수 도 있 다 . 코로나 19 로 헬스클럽 에 가 거나 실외 운동 을 하 기 어려운 상황 인지라 , 집 에서 엉덩이 · 척추 · 허벅지 뒷 근육 을 키우 는 운동 을 실천 해야 ‘ 직립 보행 ’ 을 유지 하 며 활력 있 는 생활 을 할 수 있 다 . 뒷 근육 운동 ◇ 앞 으로 고꾸라지 는 듯 한 생활 \\ue3e2 근 골격계 노화 앞당겨 현대인 들 은 하루 종일 스마트폰 을 손 에서 놓 지 못하 는 등 구부정 한 생활 을 하 고 있 다 . 앞 으로 고꾸라지 는 듯 한 자세 때문 에 우리 몸 뒷 근육 이 퇴행 해 거북목 · 굽 은 등 에 시달리 고 있 다 . 최근 책 ’ 100 세 까지 바르 게 서 고 싶 다면 항 중력 근 을 키워라 ‘ 를 펴낸 강남 세브 란스 병원 정형외과 김학선 교수 는 “ 구부정 한 자세 는 보행 할 때 필요 한 근육 의 부담 을 증가 시킨다 ” 며 “ 근육 피로 를 누적 시키 고 근육통 을 유발 하 며 , 무게 중심 변화 에 대한 근육 의 대처 능력 을 감소 시켜 조금 만 걸어도 힘들 고 넘어질 위험 을 높인다 ” 고 말 했 다 . 구부정 한 자세 는 근육 과 관절 에 미세 한 손상 을 일으키 고 이것 이 누적 되 면 관절 퇴행 도 유발 한다 . 악순환 의 고리 는 결국 근 골격계 노화 를 앞당긴다 . ◇ 주 3 ~ 5 회 는 근육 운동 해야 고령 층 은 2 주 만 누워 있 어도 온몸 의 근육 이 빠질 정도 로 근육 퇴화 가 빠르 기 때문 에 근육 운동 은 잊 지 않 아야 한다 . 세계 보건 기구 ( who ) 는 65 세 이상 은 근육 운동 을 최소 주 2 회 이상 하 라고 권장 한다 . 호서 대 물리 치료 학과 김기 송 교수 는 “ 근육 운동 은 일 주일 에 3 ~ 5 회 하 는 것 이 이상 적 ” 이 라며 “ 근육 은 잘 사용 하 지 않 으면 점점 양 이 적어지 고 , 갑자기 운동 할 경우 에 는 근육 에 탄력 이 없 어 근육 파열 , 염좌 등 의 부상 이 발생 할 수 있 으므로 근육 운동 을 생활 화 해야 한다 ” 고 말 했 다 . ◇ 몸 을 세우 는 데 가장 중요 한 엉덩이 근육 앞 으로 구부정 한 몸 을 바로 세우 는 뒷 근육 운동 은 목 , 척추 , 엉덩이 , 허벅지 , 종아리 를 중심 으로 시행 하 면 된다 . < \\uef0e 그래픽 \\uef0d > 김학선 교수 는 “ 몸 을 세우 는 데 가장 중요 한 근육 이 바로 엉덩이 근육 ” 이 라며 “ 허리 가 굽 은 사람 을 보 면 허리 가 굽 은 것 이 아니 라 엉덩이 와 허리 가 연결 되 는 힙 조인트 부위 의 근육 이 퇴화 돼 있 다 ” 고 말 했 다 . 엉덩이 근육 은 신체 활동 이 줄어들 면 가장 빨리 감소 한다 . 김 교수 는 “ 나이 가 들 면 바지 엉덩이 부분 부터 헐렁 해 지 는 것 을 보 면 알 수 있 다 ” 며 “ 몸 중앙 에 있 는 엉덩이 근육 을 강화 해야 만 골반 과 척추 로 이어지 는 무게 의 중심 잡 기 와 균형 유지 가 원활 해진다 ” 고 말 했 다 . 척주 세움 근 ( 척추 기립 근 ) 도 척추 를 바로 잡 고 있 기 때문 에 강화 해야 한다 . 척주 세움 근 은 운동 도 필요 하 지만 평소 자세 가 더 중요 한다 . 등 이 굽 은 자세 로 앉 아 있 으면 척주 세움 근 이 과도 하 게 늘어난 상태 가 지속 되 고 , 이 과정 에서 미세 하 게 손상 된다 . 손상 된 근육 이 회복 되 는 과정 에서 지방 으로 대체 되 는 경우 가 많 은데 , 근육 의 질 이 크 게 떨어진다 . 목 근육 도 마찬가지 . 거북목 자세 때문 에 목 근육 이 늘어나 면 근육 손상 등 으로 근육 이 질 이 떨어지 므로 바른 자세 와 함께 근육 운동 을 실천 해야 한다 .',\n",
       "       '“ 가능 한 자세 와 동작 범위 로 근육 상태 체크 해 보 세요 ” 집 에서 간단히 자신 의 근육 나이 를 측정 하 는 방법 이 있 다 . 먼저 상체 근육 과 유연 성 을 측정 하 기 위한 방법 으로 ‘ 두 손 모아 들 어 올리 기 ’ 방법 이 있 다 . 양 팔꿈치 를 붙이 고 최대한 얼굴 위 로 올리 면 된다 . 나이 에 따라 적정 팔꿈치 위치 가 있 는데 , 20 대 는 눈 위치 까지 올리 고 , 50 대 이상 은 대개 입 보다 아래 다 . 실제 나이 기준 에 못 미친다면 근육 의 탄력 성 과 유연 성 이 저하 된 상태 라고 이해 하 면 된다 . 호서 대 물리 치료 학과 김기 송 교수 는 “ 근육 량 과 근육 의 질 을 대변 하 는 유연 성 을 간접 적 으로 보 는 지표 ” 라며 “ 이 처럼 동작 이나 자세 로 자신 의 근육 상태 를 간단히 체크 할 수 있 다 ” 고 말 했 다 . ‘ 한 발 로 서 서 양팔 을 옆 으로 들 어 올리 기 ’ 는 하체 근육 과 균형 감각 을 측정 하 는 방법 이 다 . 눈 을 감 고 한 발 로 버티 다 균형 이 깨지 는 데 걸리 는 시간 을 재 면 된다 . 나이 기준 보다 못 미치 면 역시 근육 나이 가 실제 나이 보다 많 은 것 이 다 . 자세 유지 에 중요 한 코어 근육 ( 배 근육 등 ) 을 보 는 방법 도 있 다 . 몸 을 40 도 정도 젖힌 후 양다리 를 들 어 올리 는 각도 를 통해 측정 이 가능 하 다 .',\n",
       "       \"ngrok 공식 페이지 에서 ngrok 은 nat 와 방화벽 뒤 에 있 는 로컬 서버 를 안전 한 터널 을 통해 공개 인터넷 에 노출 시켜 주 는 도구 라고 설명 되 어 있 습니다 . 즉 , 포트 포워딩 과 같 은 네트워크 환경 설정 변경 없이 로컬 에 실행 중 인 서버 를 안 전하 게 외부 에서 접근 가능 하 도록 해 주 는 도구 입니다 . 설치 홈페이지 에서 설치 파일 을 다운로드 받 아서 설치 할 수 있 지만 , 저 는 brew 이용 해서 설치 를 진행 했 습니다 . $ brew cask install ngrok ==> satisfying dependencies ==> downloading [ URL ] # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ######################### 100 . 0 % ==> no sha - 256 checksum defined for cask ' ngrok ' , skipping verification . ==> installing cask ngrok ==> linking binary ' ngrok ' to '/ usr / local / bin / ngrok ' . 🍺 ngrok was successfully installed ! 설치 가 완료 됐 고 , 설치 확인 명령 을 실행 해 보 도록 하 겠 습니다 . $ ngrok -- help name : ngrok - tunnel local ports to public urls and inspect traffic description : ngrok exposes local networked services behinds nats and firewalls to the public internet over a secure tunnel . share local websites , build / test webhook consumers and self - host personal services . detailed help for each command is available with ' ngrok help ' . open [ URL ] for ngrok ' s web interface to inspect traffic . examples : ngrok http 80 # secure public url for port 80 web server ngrok http - subdomain = baz 8080 # port 8080 available at baz . ngrok . io ngrok http foo . dev : 80 # tunnel to host : port instead of localhost ngrok tcp 22 # tunnel arbitrary tcp traffic to port 22 ngrok tls - hostname = foo . com 443 # tls traffic for foo . com to port 443 ngrok start foo bar baz # start tunnels from the configuration file version : 2 . 2 . 8 author : inconshreveable - commands : authtoken save authtoken to configuration file credits prints author and licensing information http start an http tunnel start start tunnels by name from the configuration file tcp start a tcp tunnel tls start a tls tunnel update update ngrok to the latest version version print the version string help shows a list of commands or help for one command ngrok 사용 방법 ngrok 사용 방법 은 매우 간단 합니다 . 로컬 서버 포트 가 8080 이 라고 가정 하 면 아래 명령 을 실행 하 면 외부 에서 접근 가능 합니다 . $ ngrok http 8080 ngrok by @ inconshreveable ( ctrl + c to quit ) session status online session expires 7 hours , 59 minutes version 2 . 2 . 8 region united states ( us ) web interface [ URL ] forwarding [ URL ] -> localhost : 8080 forwarding [ URL ] -> localhost : 8080 connections ttl opn rt 1 rt 5 p 50 p 90 0 0 0 . 00 0 . 00 0 . 00 0 . 00 외부 네트워크 환경 에서 브라우저 를 열 고 [ URL ] 입력 하 면 로컬 에 실행 중 인 서버 8080 포트 로 접속 하 여 확인 할 수 있 습니다 . 무료 사용 의 경우 ngrok 명령 실행 종료 후 재 실행 시 접속 url 이 변경 되 는 문제 가 있 지만 , 테스트 용 으로 사용 하 기 엔 무료 사용 도 충분 한 것 같 습니다 . session expire 해결 ngrok 은 기본 session 유지 시간 이 8 시간 입니다 . 8 시간 이 지난 후 엔 다시 ngrok 을 실행 해야 하 며 이때 url 이 변경 되 는 문제 가 있 습니다 . 이렇게 세션 을 8 시간 이상 유지 가 필요 한 경우 우선 [ URL ] 가입 을 진행 합니다 . google 이나 github 계정 으로 쉽 게 가입 후 로그인 가능 합니다 . 로그인 후 에 auth token 을 복사 합니다 . ngrok 명령 을 재 실행 합니다 . $ ngrok http 80 -- authtoken ={ auth - token } ngrok by @ inconshreveable ( ctrl + c to quit ) session status online account 홍 길 동 ( plan : free ) version 2 . 2 . 8 region united states ( us ) web interface [ URL ] forwarding [ URL ] -> localhost : 80 forwarding [ URL ] -> localhost : 80 위 와 같이 session expires 항목 이 더 이상 노출 되 지 않 는 것 을 확인 할 수 있 습니다 . 어떤 경우 에 사용 하 나 ?\",\n",
       "       '아 , 인터넷 . 과거 에 는 컴퓨터 와 외부 의 대상 사이 에 데이터 를 주고받 으려면 사람 이 직접 손 으로 타이핑 하 거나 디스크 를 연결 해 정보 를 복사 해야 했 다 . 지금 은 통신 네트워크 를 이용 한다 . 인터넷 은 네트워크 들 의 네트워크 로 , 세계 곳곳 의 컴퓨터 를 서로 연결 시켜 준다 . 인터넷 에 비하 면 과거 의 방식 은 말 타 고 파발 보내 던 시절 같 다 . 여러 가지 용도 로 쓰이 지만 , 인터넷 은 데이터 를 교환 하 기 위한 도구 다 . 인터넷 을 활용 한 서비스 로 는 여러 가지 가 있 지만 그 중 에서 도 ‘ 웹 ( 월드 와이드 웹 , www ) ’ 이 가장 널리 쓰인다 . 웹 은 인터넷 에서 다양 한 정보 를 서로 연결 해 제공 하 는 정보 환경 이 다 . 여러분 도 아마 매일 같이 웹 클라이언트 ( 웹 브라우저 ) 로 수많 은 웹 서버 ( 웹 사이트 ) 가 제공 하 는 서비스 를 이용 해 봤 을 것 이 다 . 이 때 이용 하 는 웹 클라이언트 프로그램 이나 웹 서비스 를 제공 하 는 프로그램 을 만드 는 활동 을 웹 프로그래밍 이 라고 한다 . 웹 환경 은 많 은 연구 와 사업 이 이루어지 는 분야 이 기 때문 에 깊이 들어가 려면 다뤄야 할 주제 가 많 다 . 이 책 에서 는 파이썬 라이브러리 를 이용 해 아주 기초 적 인 웹 프로그래밍 을 체험 해 볼 것 이 다 . ‘ 부록 : http 기초 ’ 를 참고 하 면 더 쉽 게 이해 할 수 있 을 것 이 다 . 11 . 5 . 1 요청 과 응답 웹 브라우저 ( 클라이언트 ) 로 웹 사이트 ( 서버 ) 에 접속 할 때 일어나 는 일 을 순서 대로 생각 해 보 자 . 사용자 가 웹 브라우저 의 주소창 에 주소 를 입력 한다 . 요청 : 웹 브라우저 는 요청 메시지 를 작성 해 웹 서버 로 발송 한다 . 요청 메시지 전달 : 요청 메시지 가 인터넷 의 복잡 한 통신망 을 거쳐 웹 서버 에 전달 된다 . 응답 : 웹 서버 는 요청 받 은 정보 를 요청 자 에게 보낸다 . 응답 메시지 전달 : 응답 메시지 가 인터넷 의 복잡 한 통신망 을 거쳐 웹 브라우저 에 전달 된다 . 웹 브라우저 가 응답 메시지 를 해석 해 사용 자 에게 정보 를 출력 해 준다 . 우리 가 웹 사이트 에 접속 할 때 마다 이 과정 이 수 초 안 에 처리 된다 . 요청 메시지 전달 과 응답 메시지 전달 은 운영 체제 와 인터넷 사업자 들 이 담당 하 고 있 기 때문 에 잘 모르 더라도 웹 프로그래밍 을 하 는 데 큰 문제 가 되 지 는 않 는다 . 그 대신 요청 ( request ) 과 응답 ( response ) 을 이해 하 는 것 은 필요 하 다 . 웹 클라이언트 가 되 어 웹 서버 에 요청 해 보 고 , 웹 서버 가 되 어 웹 클라이언트 의 요청 에 응답 해 보 자 . 11 . 5 . 2 웹 클라이언트 로서 정보 요청 하 기 요청 이 란 일정 한 약속 ( http ) 에 따라 클라이언트 ( 서비스 이용자 ) 가 서버 ( 서비스 제공 자 ) 에게 특정 주소 ( url ) 에 해당 하 는 정보 를 달 라고 메시지 를 보내 는 것 이 다 . 정보 를 요구 하 는 입장 에서 는 요청 만 제대로 할 줄 알 면 된다 . 요청 을 해서 웹 환경 에 공개 된 자원 에 접근 할 수 있 다 . 이 때 자원 이 란 웹 문서 뿐 아니 라 이미지 · 음악 · 영상 등 여러 가지 형태 의 정보 를 통틀어 말 하 는 것 이 다 . 단순히 자원 을 조회 하 는 것 뿐 아니 라 , 로그인 · 글 올리 기 · 인터넷 쇼핑 등 다양 한 일 이 모두 요청 을 통해 이루어진다 . 파이썬 으로 웹 요청 을 수행 하 는 것 은 여러분 이 평소 웹 브라우저 로 웹 사이트 에 접속 하 는 것 과 똑같 다 . 차이 가 있 다면 , 주소 를 입력 하 는 곳 이 주소창 이 아니 라 함수 의 매개변수 라는 것 정도 다 . 웹 공간 에 존재 하 는 수많 은 자원 은 [ URL ] 과 같 은 형식 의 주소 로 식별 한다 . 이 식별자 를 ‘ url ( uniform resource locator ) ’ 이 라고 한다 . 어떤 자원 의 url 을 알 면 , 파이썬 으로 그 자원 을 요청 할 수 있 다 . 웹 에 정보 요청 하 기 파이썬 은 url 과 웹 요청 에 관련 된 모듈 들 을 urllib ( url 관련 라이브러리 라는 의미 ) 이 라는 패키지 로 묶 어 제공 한다 . 두 가지 모듈 만 알 면 http 요청 을 할 수 있 다 . urllib . parse : url 해석 · 조작 기능 을 담 은 모듈 : url 해석 · 조작 기능 을 담 은 모듈 urllib . request : http 요청 기능 을 담 은 모듈 urllib . request 모듈 의 http 요청 기능 부터 살펴보 자 . urllib . request 모듈 을 임포 트 한 후 , urllib . request . urlopen ( 요청 할 url ) . read ( ) . decode ( \\' utf - 8 \\') 이 라는 표현 을 실행 하 면 웹 요청 을 보낼 수 있 다 . 명령 이 조금 길 어 어렵 게 느껴질 듯 하 다 . 명령 이 긴 이유 는 다음 과 같 은 중간 과정 을 처리 해야 하 기 때문 이 다 . urllib . request . urlopen ( ) 함수 는 웹 서버 에 정보 를 요청 한 후 , 돌려받 은 응답 을 저장 하 여 ‘ 응답 객체 ( httpresponse ) ’ 를 반환 한다 . 반환 된 응답 객체 의 read ( ) 메서 드 를 실행 하 여 웹 서버 가 응답 한 데이터 를 바이트 배열 로 읽 어 들인다 . 읽 어 들인 바이트 배열 은 이진수 로 이루어진 수열 이 어서 그대로 는 사용 하 기 어렵 다 . 웹 서버 가 응답 한 내용 이 텍스트 형식 의 데이터 라면 , 바이트 배열 의 decode ( \\' utf - 8 \\') 메서 드 를 실행 하 여 문자열 로 변환 할 수 있 다 . 이 때 ‘ utf - 8 ’ 은 유니코드 부호화 형식 의 한 종류 인데 decode ( ) 함수 의 기본 인자 이 므로 생략 해도 된다 . 이것 을 매번 입력 하 기 귀찮 다면 다음 과 같이 함수 로 정의 해 두 는 것 도 좋 은 생각 이 다 . 코드 11 - 77 웹 문서 요청 함수 정의 해 두 기 import urllib . request def request ( url ) : \"\"\" 지정 한 url 의 웹 문서 를 요청 하 여 , 본문 을 반환 한다 . \"\"\" response = urllib . request . urlopen ( url ) byte _ data = response . read ( ) text _ data = byte _ data . decode ( \\' utf - 8 \\') return text _ data 웹 요청 이 필요 할 때 마다 이 페이지 를 펼쳐 보 고 따라 입력 해도 된다 . 여러 번 하 다 보 면 저절로 익혀 진다 . 다음 은 이 책 을 소개 하 는 웹 사이트 [ URL ] 에 접속 ( 요청 ) 해 본 예 다 . 따라 입력 해 보 기 바란다 . 요청 을 실행 했 을 때 인터넷 연결 이 원활 하 지 않 거나 , url 이 잘못 되 었 다면 예외 가 발생 할 수 있 다 . 코드 11 - 78 웹 문서 요청 하 기 >>> import urllib . request >>> url = \\'[ URL ] # 요청 할 url >>> webpage = urllib . request . urlopen ( url ) . read ( ) . decode ( \\' utf - 8 \\') >>> print ( webpage ) # 응답 받 은 텍스트 확인 : html 문서 가 출력 된다 . .. ( 뭔가 복잡 한 내용 이 출력 된다 ) . .. 웹 문서 의 형식 요청 한 결과 로 서버 가 응답 해 준 텍스트 를 print ( ) 함수 로 출력 해 살펴보 자 . 뭔가 이해 하 기 힘든 복잡 한 텍스트 가 화면 을 가득 메울 것 이 다 . 이것 은 html ( hypertext markup language ) 이 라는 언어 로 작성 된 문서 다 . 웹 브라우저 로 접속 했 을 때 전달 받 는 문서 와 동일 한 문서 다 . 웹 브라우저 는 html 문서 를 사람 이 보 기 좋 게 가공 하 여 출력 해 주 지만 , 파이썬 표준 라이브러리 는 그렇게 해 주 지 않 는다 . 그래서 모양 이 날 것 의 html 문서 는 생소 해 보일 수 있 다 . 웹 브라우저 에서 도 ‘ 소스 보 기 ’ 기능 을 이용 해 보 면 , 가공 되 지 않 은 html 문서 를 볼 수 있 다 . 그림 11 - 2 웹 브라우저 로 html 문서 ‘ 소스 보 기 ’ 웹 의 정보 를 굳이 웹 브라우저 가 아니 라 파이썬 에서 읽 어 들인다면 , 그 목적 은 읽 어 들인 정보 를 프로그램 으로 처리 하 기 위한 것 이 다 . html 문서 는 웹 브라우저 로 보 기 에 는 편리 하 지만 , 엄격 하 게 형식 화 되 지 는 않 았 기 때문 에 프로그램 으로 해석 하 고 처리 하 기 가 까다로운 편 이 다 . 웹 에 는 프로그램 에서 다루 기 편리 한 편리 한 형식 으로 제공 되 는 정보 도 많이 있 다 . 그런 형식 의 한 예 가 json 이 다 . 웹 브라우저 로 [ URL ] 접속 해 json 형식 의 데이터 를 열람 해 보 자 . 그림 11 - 3 웹 의 json 데이터 를 웹 브라우저 로 열기 이 데이터 를 파이썬 대화 식 셸 에서 도 읽 어 들여서 웹 브라우저 로 받 은 것 과 비교 해 보 자 . urllib . request . urlopen ( ) 함수 로 위 의 url 에 요청 하 면 된다 . 코드 11 - 79 웹 에서 json 데이터 읽 어 들 이 기 >>> url = \\'[ URL ] # 요청 할 주소 >>> text _ data = urllib . request . urlopen ( url ) . read ( ) . decode ( \\' utf - 8 \\') >>> print ( text _ data ) [ { \" title \": \" interstella \", \" genre \": \" sf \", \" year \": 2014 , \" starring \": [ \" m . mcconaughey \", \" a . hathaway \", \" j . chastain \"] }, { \" title \": \" braveheart \", \" genre \": \" drama \", \" year \": 1995 , \" starring \": [ \" m . gibson \", \" s . marceau \", \" p . mcgoohan \"] }, { \" title \": \" mary poppins \", \" genre \": \" fantasy \", \" year \": 1964 , \" starring \": [ \" j . andrews \", \" d . van dyke \"] } ] 웹 브라우저 와 마찬가지 로 json 데이터 가 응답 되 었 다 . json 데이터 는 json . loads ( ) 함수 를 이용해 파이썬 컬렉션 으로 해석 할 수 있 다 . ( 11 . 5 절 ) 다음 과 같이 컬렉션 으로 해석 해 두 고 , 데이터 를 원하 는 대로 이용 할 수 있 다 . 코드 11 - 80 웹 에서 받 은 json 데이터 해석 · 가공 하 기 >>> import json >>> movies = json . loads ( text _ data ) >>> sorted _ by _ year = sorted ( movies , key = lambda movie : movie [ \\' year \\']) >>> for movie in sorted _ by _ year : . .. print ( str ( movie [ \\' year \\']) + \\' \\' + movie [ \\' title \\']. upper ( ) ) . .. 1964 mary poppins 1995 braveheart 2014 interstella 이상 으로 웹 의 정보 를 요청 하 는 기본 방법 을 알아보 았 다 . 겨우 한 행 짜리 파이썬 명령 으로 웹 에서 정보 를 요청 할 수 있 다 . 복잡 한 인터넷 통신 과정 은 파이썬 라이브러리 , 운영 체제 , 네트워크 인프라 가 대신 처리 해 준다 . 웹 에서 데이터 를 수집 하 는 방법 을 더 자세히 알 고 배우 고 싶 다면 『 파이썬 으로 웹 크롤러 만들 기 』( 라이언 미첼 저 , 한선 용 역 , 한 빛 미디어 ) 를 읽 어 보 면 많 은 도움 이 될 것 이 다 . 11 . 5 . 3 url 다루 기 url 은 인터넷 공간 에 존재 하 는 자원 을 가리키 기 위한 절대 주소 다 . url 을 작성 하 는 양식 은 다음 과 같이 정해져 있 다 . 프로토콜 : / / 계정 : 패스워드 @ 호스트 : 포트 번호 / 하위 경로 ? 질 의 조건 # 색인 이 양식 에서 가장 자주 사용 되 는 요소 는 프로토콜 , 호스트 , 하위 경로 다 . 그 외 의 요소 는 생략 될 때 가 많 다 . 프로토콜 : 자원 에 접근 하 기 위한 통신 방법 을 나타낸다 . 웹 에서 는 http 와 https 가 사용 된다 . https 는 http 에 ssl 이 라는 암 · 복호화 단계 를 적용 하 여 보안 통신 을 수행 하 는 프로토콜 이 다 . 와 가 사용 된다 . https 는 http 에 ssl 이 라는 암 · 복호화 단계 를 적용 하 여 보안 통신 을 수행 하 는 프로토콜 이 다 . 호스트 : 자원 이 위치 한 네트워크 ( 또는 컴퓨터 ) 의 도메인 주소 또는 ip 주소 . 하위 경로 : 한 호스트 는 여러 개 의 자원 을 제공 할 수 있 다 . 그 하위 자원 을 가리키 기 위해 호스트 이름 뒤 에 / wiki / python _( programming _ language ) 와 같이 표기 한다 . 와 같이 표기 한다 . 질 의 조건 : 자원 을 조회 할 때 선택 적 으로 입력 하 는 세부 조건 이 다 . 예 를 들 어 , 동일 한 자원 이 여러 페이지 로 나뉘 어 있 는 경우 에 세 번 째 페이지 를 ? page = 3 과 같 은 형식 으로 표기 할 수 있 다 . 그림 11 - 4 url 구성 의 예 url 분할 · 수정 · 재결합 파이썬 에서 url 을 조작 할 때 는 urllib . parse 모듈 을 사용 한다 . 이 모듈 의 함수 urllib . parse . urlsplit ( ) 를 이용 하 면 url 을 여러 부분 으로 나눌 수 있 다 . 코드 11 - 81 url 을 여러 부분 으로 나누 기 >>> import urllib . parse >>> url = [ URL ] >>> url _ parts = urllib . parse . urlsplit ( url ) # url 나누 기 >>> url _ parts [ 0 ] # 프로토콜 확인 \\' https \\' >>> url _ parts [ 1 ] # 호스트 확인 \\' python . bakyeono . net \\' >>> url _ parts [ 2 ] # 하위 경로 확인 \\'/ data / movies . json \\' urllib . parse . urlsplit ( ) 함수 는 나눈 url 부분 들 을 튜플 에 담 아 반환 한다 . url 의 각 부분 을 수정 하 려면 튜플 을 리스트 로 변경 해 두 어야 한다 . 수정 을 마친 후 다시 하나 의 url 로 합칠 때 는 urllib . parse . urlunsplit ( ) 함수 를 사용 하 면 된다 . 다음 코드 는 나눈 url 에서 하위 경로 를 수정 한 후 다시 합쳐 본 것 이 다 . 코드 11 - 82 나눈 url 을 수정 한 뒤 다시 합치 기 >>> url _ parts = list ( url _ parts ) >>> url _ parts [ 2 ] = \\'/ chapter - 11 . html \\' >>> urllib . parse . urlunsplit ( url _ parts ) \\'[ URL ] 퍼센트 인코딩 url 에 사용 할 수 있 는 문자 는 영문자 , 숫자 , 몇몇 기호 뿐 이 다 . 그 밖 의 문자 ( 한글 · 한자 · 특수 문자 등 ) 는 사용 할 수 없 다 . 위키백과 의 파이썬 문서 를 가리키 는 [ URL ] 이 라는 url 을 urllib . request . urlopen ( ) 함수 로 요청 하 면 ‘ 파이썬 ’ 이 라는 한글 때문 에 오류 가 발생 한다 . 코드 11 - 83 url 에 한글 이 섞여 있 으면 요청 할 때 오류 가 발생 한다 . >>> urllib . request . urlopen ( \\'[ URL ] unicodeencodeerror : \\' ascii \\' codec can \\' t encode characters in position 10 - 12 : ordinal not in range ( 128 ) 이 를 피하 기 위해서 는 url 에서 아스키 코드 가 아닌 문자 들 을 퍼센트 인코딩 ( percent encoding ) 이 라는 형식 으로 바꾸 어야 한다 . 우리 가 사용 하 는 웹 브라우저 는 퍼센트 인코딩 을 자동 으로 수행 해 준다 . 파이썬 에서 는 urllib . parse . quote ( ) 함수 로 한글 텍스트 를 퍼센트 인코딩 으로 변환 한 문자열 을 구할 수 있 다 . 코드 11 - 84 한글 텍스트 를 퍼센트 인코딩 하 기 >>> urllib . parse . quote ( \\' 파이썬 \\') \\'% ed % 8 c % 8 c % ec % 9 d % b 4 % ec % 8 d % ac \\' 퍼센트 인코딩 된 텍스트 를 다시 일반 텍스트 로 되돌릴 때 는 urllib . parse . unquote ( ) 함수 를 사용 한다 . 코드 11 - 85 퍼센트 인코딩 된 텍스트 를 되돌리 기 >>> urllib . parse . unquote ( \\'% ed % 8 c % 8 c % ec % 9 d % b 4 % ec % 8 d % ac \\') \\' 파이썬 \\' url 에서 한글 이 포함 된 부분 을 퍼센트 인코딩 하 여 요청 하 면 , 요청 이 정상 적 으로 수행 된다 . 코드 11 - 86 url 에 한글 이 들어간 문서 요청 하 기 >>> base _ url = \\'[ URL ] >>> path = urllib . parse . quote ( \\'/ wiki / 파이썬 \\') >>> url = base _ url + path >>> urllib . request . urlopen ( url ) . read ( ) . decode ( \\' utf - 8 \\') ( 요청 에 성공 하 여 html 문서 가 화면 에 출력 된다 . 출력 결과 생략 . ) 11 . 5 . 4 웹 서버 로서 정보 제공 하 기 이번 에 는 웹 서버 의 역할 이 되 어 , 웹 클라이언트 의 요청 이 오 기 를 기다리 다가 요청 이 왔 을 때 적절 한 응답 을 하 도록 해 보 자 . 웹 서버 프로그램 의 실행 과정 웹 서버 프로그램 이 어디 에선가 들어온 요청 을 받 아 응답 하 기 까지 거치 는 절차 를 단순히 정리 해 봤 다 . 수신 대기 ( listen ) : 클라이언트 의 요청 이 오 기 를 기다린다 . 중계 ( route ) : 요청 을 받 으면 , 요청 메시지 ( url , 메 서드 등 ) 를 해석 하 여 그 에 해당 하 는 기능 ( 함수 ) 을 호출 한다 . 실행 : 중계 과정 에서 호출 된 기능 을 실제로 처리 한다 . 이 과정 에서 데이터베이스 시스템 과 같 은 프로그램 외부 의 자원 을 활용 하 기 도 한다 . 출력 결과 가공 ( render ) : 실행 된 결과 를 일정 한 형식 으로 가공 한다 . 이 과정 에서 템플 릿 ( 미리 준비 한 양식 에 세부 사항 을 채워 넣 는 방법 ) 도구 를 활용 하 기 도 한다 . 응답 : 실행 된 결과 를 클라이언트 에게 되돌려준다 . 복잡 한 웹 서버 프로그램 은 위 의 각 절차 마다 수많 은 세부 절차 를 수행 한다 . 하지만 지금 은 웹 서버 가 어떤 일 을 하 는지 느껴볼 정도 로 만 간단 하 게 구현 해 볼 것 이 다 . 간단 한 웹 서버 만들 기 표준 라이브러리 를 이용 해 간단 한 웹 서버 를 만들 수 있 다 . http . server 모듈 에 웹 서버 를 만들 때 필요 한 기능 이 들 어 있 다 . http . server . httpserver : 통신 채널 을 열 고 , 클라이언트 의 요청 을 수신 대기 하 는 클래스 . http 프로토콜 보다 낮 은 수준 에서 통신 과정 을 처리 해 준다 . : 통신 채널 을 열 고 , 클라이언트 의 요청 을 수신 대기 하 는 클래스 . http 프로토콜 보다 낮 은 수준 에서 통신 과정 을 처리 해 준다 . http . server . basehttprequesthandler : 요청 받 은 내용 을 해석 하 여 처리 하 기 위한 뼈대 클래스 . 이 클래스 를 확장 해 중계 · 실행 · 응답 내용 을 정의 할 수 있 다 . 코드 11 - 87 은 이 두 클 래스 를 이용 해 간단 한 웹 서버 를 구현 한 것 이 다 . 코드 11 - 87 get 요청 을 처리 해 주 는 간단 한 웹 서버 import http . server class httprequesthandler ( http . server . basehttprequesthandler ) : \"\"\" http 요청 을 처리 하 는 클래스 \"\"\" def do _ get ( self ) : # ❶ \"\"\" http get 요청 을 처리 한다 . \"\"\" self . route ( ) def route ( self ) : # ❷ \"\"\" 요청 url 의 path 에 따라 요청 을 처리 할 함수 를 중계 한다 . \"\"\" if self . path == \\'/ hello \\': self . hello ( ) else : self . reponse _ 404 _ not _ found ( ) def hello ( self ) : # ❸ \"\"\" 200 ok 상태 코드 와 인삿말 을 응답 한다 . \"\"\" self . response ( 200 , \\' 안녕 하 세요 ? \\') def reponse _ 404 _ not _ found ( self ) : # ❹ \"\"\" 404 not found 상태 코드 와 오류 메시지 를 응답 한다 . \"\"\" self . response ( 404 , \\' 요청 하 신 문서 를 찾 을 수 없 습니다 . \\') def response ( self , status _ code , body ) : # ❺ \"\"\" 응답 메시지 를 전송 한다 . \"\"\" # 상태 코드 전송 self . send _ response ( status _ code ) # 헤더 전송 self . send _ header ( \\' content - type \\', \\' text / plain ; charset = utf - 8 \\') self . end _ headers ( ) # 본문 전송 self . wfile . write ( body . encode ( \\' utf - 8 \\')) # 요청 받 을 주소 ( 요청 을 감시 할 주소 ) address = \\' localhost \\', 8000 # 요청 대기 하 기 listener = http . server . httpserver ( address , httprequesthandler ) # ❻ print ( f \\'[ URL ] 주소 에서 요청 대기 중 . ..\\') listener . serve _ forever ( ) # ❼ 요청 을 받 았 을 때 실행 할 동작 을 http . server . basehttprequesthandler 클래스 를 확장 해 정의 했 다 . ❶ do _ get ( ) 메 서드 는 미리 정의 하 도록 약속 된 메 서 드 다 . 클라이언트 가 get http 메서 드로 요청 을 보냈 을 때 저절로 호출 된다 . 이 외 의 나머지 메 서 드 는 임의 로 정의 한 것 이 다 . ❷ route ( ) 메 서 드 는 요청 한 url 의 하위 경로 ( self . path ) 에 따라 적절 한 함수 를 실행 하 도록 중계 한다 . ❸ hello ( ) 메 서 드 는 실행 과 출력 결과 가공 을 맡 는 역할 을 할 수 있 는데 , 프로그램 이 단순 해서 별다른 일 은 하 지 않 는다 . 그냥 정상 적 인 응답 을 뜻 하 는 200 상태 코드 와 인삿말 을 응답 한다 . ❹ reponse _ 404 _ not _ found ( ) 메 서 드 는 사용 자 가 요청 한 문서 가 존재 하 지 않 음 을 뜻 하 는 404 상태 코드 와 오류 메시지 를 응답 한다 . ❺ response ( ) 는 실제로 응답 을 수행 하 는 메 서 드 다 . http 응답 메시지 규칙 에 따라 상태 코드 , 헤더 , 본문 을 순서 대로 출력 한다 . 자세 한 내용 은 부록 을 참고 하 기 바란다 . ❻ http . server . httpserver 클래스 를 인 스턴스 화 하 여 서버 인 스턴스 를 생성 할 수 있 다 . 인자 로 는 이 서버 가 요청 을 받 은 주소 와 요청 을 처리 할 처 리기 ( 위 에서 정의 한 httprequesthandler ) 를 전달 한다 . ❼ 서버 인 스턴스 의 serve _ forever ( ) 메서 드 를 실행 하 면 서버 가 실행 되 고 클라이언트 의 요청 을 계속 기다린다 . 요청 이 오 면 httprequesthandler . do _ get ( ) 에 정의 한 대로 적절히 응답 도 해 준다 . 서버 의 실행 을 중지 하 려면 ctrl + c 키 를 누르 면 된다 . 서버 프로그램 을 실행 하 고 , 웹 브라우저 의 주소 창 에 [ URL ] 라는 url 을 입력 해 접속 해 보 자 . 인사 가 잘 출력 되 는가 ? 비록 매우 단순 하 지만 , 이 프로그램 은 다른 웹 서버 가 요청 을 받 아 응답 하 는 절차 와 크 게 다르 지 않 다 . 그림 파일 을 제공 하 는 웹 서버 는 요청 된 파일 의 경로 를 url 에서 확인 하 여 서버 에서 읽 어 들여 그 내용 을 응답 한다 . 위 의 웹 서버 프로그램 에 그림 파일 을 읽 어 들여 내보내 는 기능 을 추가 하 면 그런 기능 을 만들 수 있 다 . 게시판 을 서비스 하 는 웹 서버 는 사용 자 가 업로드 한 정보 를 데이터베이스 에 저장 해 두 었 다가 사용 자 가 요청 했 을 때 데이터베이스 의 내용 을 읽 어 응답 한다 . 웹 서버 에 데이터베이스 또는 파일 에 정보 를 읽 고 쓰 는 기능 을 연동 하 면 게시판 서비스 도 만들 수 있 다 . 실무 에서 는 웹 프레임워크 ( web framework ) ( 웹 서버 프로그램 의 뼈대 와 부 가 기능 을 미리 만들 어 놓 은 라이브러리 ) 를 이용 해 웹 서버 를 개발 할 때 가 많 다 . 웹 사이트 · 웹 서버 를 제대로 만들 어 보 고 싶 다면 파이썬 웹 프레임워크 인 ‘ 장고 ( django ) ’ 를 배워 보 기 를 권한다 . 교재 로 는 『 파이썬 웹 프로그래밍 : 장고 로 배우 는 쉽 고 빠른 웹 개발 』( 김석훈 저 , 한 빛 미디어 ) 과 『 장고 걸스 튜토리얼 』([ URL ] 추천 한다 .',\n",
       "       '이번 글 에서 는 이항 분포 , 다항 분포 , 베타 분포 , 디리클레 분포 에 대해 살펴보 도록 하 겠 습니다 . 이번 글 역시 고려대 강필성 교수 님 강의 와 위키피디아 를 정리 했 음 을 먼저 밝힙니다 . 그럼 시작 하 겠 습니다 . 이항 분포 성공 확률 이 $ p $ 인 베르누이 시행 을 $ n $ 번 반복 시행 할 때 성공 횟수 를 나타내 는 확률변수 $ x $ 의 분포 를 이항 분포 ( binomial distribution ) 이 라고 합니다 . 이항 분포 의 확률 질량 함수 는 다음 과 같 습니다 . 이항 분포 의 확률 질량 함수 를 시각 화 하 면 다음 그림 과 같 습니다 . ( 출처 : 위키피디아 ) $ x $ 의 기대 값 과 분산 은 다음 과 같 습니다 . 베타 분포 베타 분포 ( beta distribution ) 란 두 매개변수 $ α $ 와 $ β $ 에 대해 $[ 0 , 1 ] $ 에서 정의 되 는 연속 확률 분포 들 의 가족 을 가리킵니다 . 베타 분포 의 확률 밀도 함수 는 다음 과 같 습니다 . 베타 분포 의 확률 밀도 함수 인 감마함수 $ γ $ 는 다음 과 같이 정의 됩니다 . $ α $, $ β $ 값 에 따라 베타 분포 의 모양 또한 달라지 는데요 . 다음 그림 을 참고 하 시 면 좋 을 것 같 습니다 . ( 출처 ) 다항 분포 다항 분포 ( multinomial ) 란 여러 개 의 값 을 가질 수 있 는 독립 확률 변수 들 에 대한 확률분포 를 가리킵니다 . 여러 번 의 독립 시행 에서 각각 의 값 이 특정 횟수 가 나타날 확률 을 말 합니다 . 어떤 시행 에서 $ k $ 가지 의 값 이 나타날 수 있 고 , 그 값 이 나타날 확률 을 각각 $ p _ 1 , p _ 2 , … , p _ k $ 라고 할 때 $ n $ 번 의 시행 에서 $ i $ 번 째 값 이 $ x _ i $ 회 나타날 확률 은 다음 과 같 습니다 . 즉 다항 분포 의 확률 질량 함수 는 아래 와 같 습니다 . 예 를 들 어 보 겠 습니다 . 전체 말뭉치 의 단어 개수 가 $ v $ 개이 고 , 첫 번 째 단어 가 말뭉치 에 등장 할 확률 이 $ p _{ v 1 }$, 두 번 째 단어 는 $ p _{ v 2 }$,…,$ v $ 번 째 단어 는 $ p _{ vv }$ 라고 가정 해 보 겠 습니다 . 여기 에서 말뭉치 에서 단어 를 $ n $ 개 뽑 을 때 첫 번 째 단어 가 나타날 횟수 는 $ x _ 1 $,…$ v $ 번 째 단어 는 $ x _ v $ 가 됩니다 . 디리클레 분포 디리클레 분포 란 $ k $ 차원 의 실수 벡터 중 벡터 의 요소 가 양수 이 며 모든 요소 를 더 한 값 이 1 인 경우 에 확률 값 이 정의 되 는 연속 확률분포 입니다 . 2 이상 의 자연수 $ k $ 와 양 의 상수 $ α _ 1 , … , α _ k $ 에 대하 여 디리클레 분포 의 확률 밀도 함수 는 다음 과 같이 정의 됩니다 . $ b ( α ) $ 는 다음 과 같 습니다 . 3 차원 디리클레 분포 의 모양 은 다음 과 같 습니다 . 왼쪽 위 에서부터 시계 방향 으로 $ α $=( 6 , 2 , 2 ) , ( 3 , 7 , 5 ) , ( 6 , 2 , 6 ) , ( 2 , 3 , 4 ) 켤레 사전 분포 사후 확률 분포 $ p ( θ $|$ x ) $ 가 사전 확률 분포 $ p ( θ ) $ 와 같 은 가족 군 으로 묶일 때 그 사후 확률 / 사전 확률 을 모두 묶 어 켤레 분포 ( conjugate distributions ) , 그 사전 확률 분포 를 켤레 사전 분포 ( conjugate prior distribution ) 라고 합니다 . 사전 확률 과 사후 확률 이 동일 한 분포 를 따른다면 계산 이 매우 편해 지 기 때문 에 베이즈 통계학 에서 많이 쓴다고 합니다 . 그 관계 를 따지 면 다음 과 같 습니다 .',\n",
       "       'question iptime a 5004 ns 사용 중 입니다 . 외부 에서 nas 에 연결 하 려 할 때 맥 에서 크롬 을 사용 하 여 ftp : / / nas 주소 로 연결 하 면 접속 , 파일 탐색 , 파일 다운 잘 됩니다 . 그런데 맥 파인더 에서 ftp : / / nas 주소 로 하 면 접속 , 파일 탐색 은 되 는데 파일 을 다운 받 을 수 가 없 습니다 . xbmc 에서 는 접속 되 고 nas 안 의 폴더 는 나오 는데 파일 들 은 안 뜹니다 ;; 어떻 게 해결 할까요 ;; 부탁 드립니다 . advice finder 의 ftp 기능 은 매우 한정 적 입니다 . 오직 읽 기 권한 만 부여 되 고 ‘ 새로 고침 ’ 기능 도 지원 되 지 않 아 변동 사항 을 실시간 으로 확인 할 수 도 없 습니다 . 또한 ftp 서버 의 문제 셋 을 utf - 8 로 지정 하 지 않 았 다면 , 접속 장애 가 자주 발생 하 고 , 윈도 공유 ( smb ) 를 통하 여 저장 한 한글 명 파일 은 기본 적 으로 utf - 8 이 아닌 euc - kr 로 저장 되 므로 , ftp 서버 의 문자 셋 을 utf - 8 으로 지정 한다 해도 , finder 에서 다운로드 ( 복사 ) 할 때 에러 가 발생 합니다 . ( 애당초 파일 을 nas 에 저장 할 때 , ftp 서버 의 문자 셋 을 utf - 8 으로 지정 하 고 , utf - 8 지원 을 지원 하 는 ftp 클라이언트 로 업로드 한 한글 명 파일 은 정상 적 으로 finder 에서 다운로드 가능 ) 여하튼 , ftp 기능 이 매우 제한 적 인 finder 로 고민 하 지 말 고 , 그냥 ftp 전용 클라이언트 사용 을 추천 합니다 . 업로드 / 다운로드 / 폴더 병합 / 다양 한 문자 셋 / 새로 고침 등등 , ftp 원격 파일 관리 에 관한 모든 기능 을 지원 합니다 .',\n",
       "       '1 . 이걸 왜 쓰 나요 ? 저 는 집 에서 일 하 는 프리랜서 출판 번역가 입니다 . 번역 을 전업 으로 한 지 는 만 13 년 이 되 어 갑니다 . 그 전 에 는 두 군데 직장 에서 칠 년 을 일 했 습니다 . 둘 다 매일 출퇴근 하 여 여덟 시간 씩 일 하 는 사무직 이 었 습니다 . 두 번 째 회사 를 다니 면서 퇴근 후 저녁 과 주말 에 번역 하 기 시작 했 고 , 그렇게 약 이 년 간 여섯 권 을 번역 했 지만 , 두 일 을 병행 하 기 어려워서 회사 를 그만두 었 습니다 . 이후 전업 으로 110 권 의 책 을 번역 했 습니다 . 프리랜서 가 된 뒤 에 는 줄곧 집 에서 일 했 습니다 . 집 밖 에서 작업 공간 을 얻 어 일 한 적 이 딱 한 번 두 달 정도 있 었 지만 , 타인 과 공유 하 는 공간 에서 일 하 는 것 이 제게 맞 지 않 는다는 것 을 느끼 고 이후 에 는 시도 하 지 않 았 습니다 . 혼자 쓰 는 작업실 은 비용 부담 이 커서 시도 하 지 않 았 습니다 . 가끔 집 이 갑갑 하 면 카페 에 나가 서 일 하 지만 , 그건 일 이 라기 보다 는 기분 전환 활동 에 가깝 습니다 . 그리고 저 는 혼자 삽니다 . 즉 , 저 는 침대 에서 일어난 뒤 책상 으로 출근 하 는 생활 을 13 년 해 왔 습니다 . 지금 소개 하 는 40 + 20 작업 법 은 제 가 집 에서 일 하 면서 쓰 기 시작 한 방법 입니다 . 전 에 는 회사 를 다녔 기 에 스스로 일과 를 100 % 편성 할 여지 도 필요 도 없 었 지만 , 출퇴근 도 동료 도 없이 혼자 집 에서 일 하 려니 스스로 규율 을 정하 고 지켜야 할 필요 를 느꼈 습니다 . 처음 40 + 20 작업 법 을 궁리 한 것 은 ‘ 매일 일 하 는 시간 을 확보 하 자 ’ 는 이유 에서 였 습니다 . 회사 다닐 때 매일 여덟 시간 일 했으니 , 번역 이 직업인 한 이 일 도 매일 여덟 시간 하 기 로 정했 습니다 . 그런데 출판 번역 은 여느 회사 일 에 비해 리듬 이 느 립니 다 . 보통 월 단위 로 마감 이 있 고 , 매일 참석 해야 할 회의 같 은 것 은 없 고 , 전화 통화 처럼 실시간 처리 해야 할 업무 도 드 뭅니다 . 저 는 물론 바로 그 이유 에서 이 직업 을 택했 지만 , 그래도 어느 정도 구속 을 두 고 일 하 지 않 으면 여유만만 하 다는 생각 에서 게으름 을 부리 다가 마감 을 지키 지 못할 것 같 았 습니다 . 그런데 그냥 ‘ 하루 여덟 시간 작업 법 ’ 이 아니 라 ‘ 40 + 20 작업 법 ’ 이 된 것 은 , 하루 의 업무 일과 중 에 휴식 시간 을 편성 해 두 지 않 으면 금세 몸 이 축난다는 걸 깨달 았 기 때문 입니다 . 똑같이 책상 에 앉 아서 하 는 일 이 라도 회사 에서 는 회의 하 러 가 고 , 동료 와 커피 마시 고 , 옆 팀 에 가 고 , 하여간 움직일 일 이 많 습니다 . 하지만 집 에서 일 할 때 는 , 원한다면 , 여덟 시간 논스톱 으로 앉 아 있 을 수 있 습니다 . 그리고 그러면 곧 몸 이 아픕니다 . 허리 디스크 와 목 디스크 를 얻 게 됩니다 . 저 는 척추관 협착증 으로 허리 가 아프 고 다리 가 저리 기 시작 했 습니다 . 어깨 도 아팠 습니다 . 밤 에 자 다가 통증 때문 에 깰 정도 였으니 , 회사 다닐 때 나 지금 보다 훨씬 상태 가 나빴 습니다 . 40 + 20 작업 법 은 , 그래서 , 일 이 아무리 잘 되 더라도 간간이 잠시 일어나 서 쉬 지 않 으면 난 머지않아 더 는 책상 에 앉 지 도 못하 게 되 겠 구나 하 는 위기감 의 소산 이 었 습니다 . 닥친 일 을 최대한 빨리 해내 어 프리랜서 로서 클라이언트 의 신뢰 를 잃 지 않 는 것 도 중요 하 지만 , 그러 다 병 을 키워서 아예 일 을 못 하 게 되 면 그것 도 안 된다는 생각 . 한편 으로 는 거꾸로 , 만성 적 으로 몸 이 아파도 부득이 일 해야 하 는 상황 이 라면 쉬엄쉬엄 하 는 방법 을 알 고 있 어야 한다는 생각 . 처음 엔 집중 시간 을 확보 하 려고 쓰 기 시작 했 던 40 + 20 작업 법 은 곧 휴식 시간 을 확보 하 기 위한 목적 으로 무게 중심 이 옮겨졌 습니다 . 서두 가 길 지요 . 이 작업 법 이 제 사정 에 맞춘 것 임 을 강조 하 고 싶 어서 , 굳이 배경 을 시시콜콜 적 었 습니다 . 프리랜서 라도 출퇴근 하 는 분 , 동료 와 일 하 는 분 , 도저히 40 분 단위 로 끊 을 수 없 는 작업 을 하 는 분 , 아예 책상 에 앉 지 않 는 분 등등 저 와 사정 이 다른 분 에게 는 이 방법 이 무 소용 하 고 무의미 할 것 입니다 . 그렇 다면 꼭 쓸 것 도 없 잖아 싶 기 도 합니다만 , 트위터 에서 이 방법 을 소개 했 을 때 제 생각 보다 많 은 분 들 이 관심 을 보이 셨 던 게 동기 입니다 . 제 어떤 사정 이 이 방법 을 유용 한 것 으로 만들 었 는지 더 구체 적 으로 밝힌다면 , 이 방법 을 쓸 필요 가 없 는 분 이 든 한 번 시도 해 보 면 좋 을 분 이 든 각자 의 판단 을 더 정확히 내릴 수 있 을 것 같 습니다 . 긴 서두 에 비해 본론 은 “ 애걔 ” 싶 게 짧 을 것 입니다 . 참 , 저 는 40 + 20 의 한 주기 를 ‘ 사이클 ’ 이라고 불렀 지만 , 어느 트친 께서 그걸 ‘ kmn ’ 이 라는 단위 로 명명 해 주 셨 습니다 . 그냥 ‘ 사이클 ’ 보다 는 고유 의 기호 가 낫 겠 기 에 쑥스럽 지만 그걸 쓰 겠 습니다 . 2 . 40 + 20 작업 법 은 어떻게 하 는 건가요 ? 1 ) 하루 에 몇 kmn 을 하 겠 다고 정한다 ( 예 : 8 kmn ) 2 ) 쪽지 에 그 횟수 만큼 숫자 를 쓴다 ( 예 : ➀➁➂➃➄➅➆➇). 3 ) 몇 시 든 좋 으니 정각 에 자리 에 앉 는다 ( 예 : 오전 10 시 ) . 4 ) 40 분 후 알려 주 도록 설정 된 타이머 를 켠다 . 5 ) 40 분 간 집중 해서 작업 한다 . 6 ) 타이머 가 울리 면 무조건 일어난 뒤 , 1 kmn 을 했 다고 표시 한다 ( 예 : ➊➁➂➃➄➅➆➇). 7 ) 20 분 쉬 면서 다른 일 을 한다 . 8 ) 다시 정각 이 되 면 ( 예 : 오전 11 시 ) 무조건 자리 에 앉 는다 . 9 ) 4 ) ~ 8 ) 을 목표 횟수 만큼 반복 한다 ( 예 : ➊➋➌➍➎➏➐➑). 10 ) 하루 일 을 마감 한다 ( 예 : 오후 6 시 ) . 3 . 40 + 20 작업 법 에서 기억 할 점 1 ) 일 할 때 집중 합니다 . 2 ) 쉴 때 긴장 을 풉니다 . 3 ) 일 할 때 다른 문제 를 걱정 하 지 마세요 . 4 ) 쉴 때 일 을 걱정 하 지 마세요 . 5 ) 가급적 정각 에 시작 하 세요 . 6 ) 앱 에 의존 하 지 마세요 . 7 ) 하루 에 10 kmn 이상 하 지 마세요 . 1 ) 일 할 때 집중 하 기 : 40 분 동안 다른 일 은 아무것 도 하 지 마세요 . 저 는 전화 가 와도 안 받 고 , 문자 도 답신 하 지 않 고 , 어지간 해서 는 일어나 지 않 습니다 . 그러 기 는 어렵 더라도 , 최대한 일 만 하 세요 . 마지막 십 분 은 머리 가 안 돌아가 도 , 애초 에 집중 이 안 되 어서 일어나 고 싶 어도 , 그런 마음 을 이겨 보 세요 . 집중 은 자리 에 앉 는다고 자동 으로 되 는 게 아니 죠 . 몸 과 마음 이 집중 하 는 데 길들 도록 , 한동안 은 집중 에 집중 해야 합니다 . 가령 점심 을 먹 고 나 서 다시 앉 았 을 때 같 은 상황 에서 는 이전 보다 집중 하 기 가 훨씬 어렵 죠 . 그래도 애써야 합니다 . 2 ) 쉴 때 긴장 풀기 : 20 분 동안 은 가급적 책상 에서 멀 어 지 세요 . 한 자세 로 40 분 앉 아 있 느라 굳 은 몸 을 스트레칭 으로 풀 어 주 세요 . 혹은 집안일 을 하 거나 , 문자 를 확인 하 거나 , 트위터 타임 라인 을 보 세요 . 중요 한 건 반드시 휴식 하 는 시간 을 확보 하 는 것 입니다 . 일 이 잘 될수록 타이머 가 울렸 을 때 일어나 기 어렵 습니다 . ‘ 리듬 탔 을 때 더 해야 하 는데 ’ ‘ 쉬 다가 다시 앉 았 을 때 갑자기 안 되 면 어떡 해 ’ 하 는 걱정 이 들 죠 . 그래도 쉬 어야 합니다 . 3 ) 일 할 때 다른 문제 를 걱정 하 지 말 것 : 일 할 때 문자 나 메일 이 오 면 그걸 당장 보 고 답해야 할 것 같 죠 . 하지만 세상 에 겨우 몇 십 분 을 미룬다 고 해서 큰일 날 일 은 거의 없 습니다 . ‘ 도서관 에 대출 연장 하 는 걸 깜박 했 네 ’ 하 는 생각 이 들 면 , 그걸 또 잊 기 전 에 당장 처리 해야 할 것 같 죠 . 그럴 땐 옆 에 둔 종이 에 ‘ 도서관 대출 연장 ’ 이라고 메모 하 고 넘어가 세요 . 메모 한 순간 머릿속 에서 는 비워 질 테 고 , 그 일 자체 는 쉬 는 시간 에 하 면 됩니다 . 다른 문제 에 대한 생각 이나 활동 을 허용 하 기 시작 하 면 집중 이 되 기 어렵 습니다 . 4 ) 쉴 때 일 을 걱정 하 지 말 것 : 어렵사리 엉덩이 를 떼 고 일어나 더라도 머릿속 에 일 생각 이 가득 할 때 가 있 죠 . ‘ 아까 그 문장 에서 는 “ 자칫 ” 이 아니 라 “ 하마터면 ” 을 쓰 는 게 옳 을 것 같 아 ’ ‘ 이런 사례 도 끼워 넣 으면 더 좋 은 글 이 될 것 같 아 ’ 하 는 아이디어 가 떠오릅니다 . 그래도 휴식 시간 중 에 도로 앉 지 는 마세요 . 떠오른 아이디어 를 잊 을 게 영 걱정 되 면 , 차라리 20 분 간 스트레칭 을 하 면서 머릿속 으로 그 아이디어 를 계속 굴리 세요 . 번득 무슨 생각 이 들 었 다고 매번 도로 앉 아 버리 면 영영 못 쉽니다 . 당장 쏟 아 내 야 할 것 같 은 마음 으로 쏟 아 낸 작업 이 나중 에 만족 스러운 경우 도 드 뭅니다 . 오히려 뭘 빼먹 기 쉽 습니다 . 휴식 도 애써야 합니다 . 일 을 했 다 말 았 다 덜컹덜컹 하 는 게 아니 라 고삐 를 바투 쥐 었 다 슬쩍 풀 었 다 하 는 거 라고 생각 하 세요 . 5 ) 가급적 정각 에 시작 할 것 : 물론 굳이 40 + 20 이 아니 라도 됩니다 . 하지만 40 + 20 으로 설정 하 는 것 의 장점 이 있 습니다 . 그 전 에 우선 , 40 + 20 이나 50 + 10 처럼 한 시간 단위 로 주기 를 설정 하 지 않 고 가령 35 + 5 이나 60 + 20 으로 설정 한다면 , 시간 을 계산 하 기 가 좀 복잡 해집니다 . 한 시간 단위 에서 는 타이머 가 하나 만 있 으면 됩니다 . 40 분 짜리 타이머 로 일어날 시각 만 알 면 될 뿐 , 20 분 휴식 이 끝난 걸 알려 주 는 타이머 는 없 어도 됩니다 . 그러면 어떻게 아 느냐고요 ? 감 으로 알 수 있 습니다 . 어느 집 이 든 시계 가 곳곳 에 있 죠 . 일어나 서 다른 활동 을 하 다가 ‘ 슬슬 20 분 이 끝나갈 텐데 ’ 싶 은 시점 에 시계 를 보 세요 . 그러면 아마 몇 분 남 았 거나 넘 었 을 거 예요 . 그때 앉 을 준비 를 하 거나 바로 앉 으면 됩니다 . 정각 에 시작 하 는 게 좋 은 이유 도 이것 입니다 . 정각 이 아니 라 가령 10 시 30 분 에 시작 해서 오후 6 시 30 분 에 끝내 도 되 지만 , 시계 를 봤 을 때 ‘ 정각 이 되 어 가네 ’ 하 고 깨닫 는 편 이 ‘ 45 분 이 되 어 가 네 , 근데 몇 분 에 앉 기 로 했 더라 ? ’ 하 고 생각 하 는 편 보다 인지 가 빠르 고 , 따라서 신경 쓸 일 이 줍니다 . 6 ) 앱 에 의존 하 지 말 것 : 위 의 5 ) 와 연결 되 는 이야기 입니다 . 주기 를 한 시간 단위 로 설정 하 지 않 거나 정각 에서 시작 하 지 않 으면 , 추가 로 인지 하 고 기억 할 요소 가 발생 합니다 . 혹은 , 타이머 가 하나 이상 필요 합니다 . 일어날 때 를 알려 주 는 타이머 와 앉 을 때 를 알려 주 는 타이머 가 다 필요 하 죠 . ‘ 포 모도 로 ’ 앱 같 은 생산 성 관리 도구 가 필요 한 게 이 때문 입니다 . 하지만 제일 좋 은 방법 은 아예 어떤 앱 에 도 , 어떤 수단 에 도 꼭 필요 한 것 이상 은 의존 하 지 않 는 것 입니다 . 단기 작업 에서 는 가령 ‘ 포레스트 ’ 앱 처럼 동기 부여 를 통해 집중력 을 키워 주 는 수단 이 도움 이 될 테 지만 , 장기 적 으로 는 ? 아니요 , 아닙니다 . 집중 하 려고 도구 를 쓰 는 것 인데 , 그 도구 가 조금 이 라도 번거 로워서는 안 됩니다 . 최소한 의 조작 , 최소한 의 인지 적 부담 이 좋 습니다 . 그냥 소리 로 알려 주 는 타이머 하나 만 써도 어떤 땐 얼마나 번거 로운지 모릅니다 . 게다가 타이머 소리 를 못 듣 는 일 도 비일비재 합니다 . 너무 집중 해서 못 듣 기 도 하 고 , 소리 를 듣 긴 했 지만 ‘ 오 분 만 더 하 고 일어나 자 ’ 하 다가 이내 잊 기 도 합니다 . 그러 니 ‘ 소리 를 들으면 무조건 일어난다 ’ 이상 으로 복잡 한 인지 나 조작 을 요구 하 는 수단 은 장기 적 으로 본 말 전도 가 되 기 쉽 습니다 . 일단 리듬 이 몸 에 익 으면 , 타이머 하나 만 으로 작업 해도 어렵 지 않 습니다 . 7 ) 하루 에 10 kmn 이상 하 지 말 것 : 하루 에 8 kmn 을 하 면 실질 업무 시간 은 5 시간 20 분 아니 냐고요 ? 맞 습니다 . 하지만 하루 8 시간 근무 하 는 회사원 의 실질 업무 시간 은 보통 이 보다 더 짧 을 겁니다 . 20 분 의 휴식 도 일 한 시간 으로 헤아리 세요 . 이 작업 법 은 하루 의 업무 를 잘 계획 하 기 위한 방법 인 동시 에 그 보다 더 장기 적 으로 한 달 , 일 년 , 십 년 , 평생 의 업무 를 계획 하 기 위한 방법 이 기 도 합니다 . 오늘 12 kmn 을 하 면 내일 은 4 kmn 밖에 못 하 기 쉽 다는 걸 잊 지 마세요 . 그 보다 는 오늘 8 kmn 을 하 고 내일 도 8 kmn 을 하 는 식 으로 고르 게 가 는 편 이 총 시간 은 같 더라도 장기 적 으로 지속 가능 한 리듬 입니다 . 집중력 도 체력 이 고 , 체력 은 화수분 이 아니 니까요 . 4 . 40 + 20 작업 법 은 어떨 때 특히 유용 한 가요 ? 1 ) 자투리 시간 을 활용 할 때 2 ) 몸 이나 마음 이 아플 때 3 ) 일 이 너무 지루 할 때 4 ) 일 의 진척 이 더뎌서 조바심 날 때 5 ) 일 의 진척 이 빨라서 성급 해질 때 6 ) 작업량 을 기록 하 고 싶 을 때 7 ) 가사 노동 과 병행 할 때 1 ) 자투리 시간 을 활용 할 때 : 쓸 수 있 는 시간 이 적 을수록 마음 이 조급 해져서 결국 그 조차 제대로 활용 하 지 못하 기 쉽 습니다 . 그럴 때 이 방법 을 쓰 세요 . 가령 , 오후 1 시 에 점심 약속 이 있 어서 12 시 에 나가 야 하 는데 오전 에 두 시간 만 일 하 고 싶 다고 하 죠 . 계획 이 없 다면 , 십 분 도 맘 편히 앉 아 있 기 어렵 습니다 . ‘ 선크림 을 언제 바르 지 ? ’ ‘ 11 시 30 분 에 일어나 면 되 겠 지 ? ’ ‘ 아직 여유 있 나 ? ’ 하 고 끊임없이 조바심 하 며 시계 를 보 게 됩니다 . 이때 , ‘ 오전 9 시 30 분 부터 11 시 30 분 까지 딱 2 kmn 만 하 자 ’ 하 고 생각 합시다 . 그러면 최소한 80 분 은 일 하 게 됩니다 . 그리고 사실 은 11 시 30 분 이 아니 라 11 시 10 분 에 일어나 게 되 지요 . 따라서 외출 을 준비 할 시간 이 넉넉 하 고 , 일 하 는 동안 에 는 외출 준비 에 대한 잡념 을 떨칠 수 있 고 , 약속 에 도 늦 지 않 습니다 . 2 ) 몸 이나 마음 이 아플 때 : 몸 이나 마음 이 아파서 쉬 고 싶 지만 사정 상 그럴 수 없 을 때 , 저 는 ‘ 오늘 하루 는 딱 4 kmn 만 하 자 ’ 하 고 생각 합니다 . 그러면 훨씬 가벼운 마음 으로 자리 에 앉 을 수 있 고 , 일 을 적 게 해도 죄책감 이 덜 듭니다 . 어떻 게 해서든 4 kmn 을 하 는 것 자체 가 애쓴 일 이 란 걸 저 는 시작 할 때 부터 알 고 있 었 으니까요 . 사담 이 지만 , 제 가 우울증 때문 에 엄청 무 기력 했 던 시기 가 몇 차례 있 었 어요 . 아침 에 침대 에서 도저히 일어나 질 못해서 하루 에 16 시간 씩 울 면서 누워 만 있 었 죠 . 그때 도 매일 이렇게 생각 했 습니다 . ‘ 오늘 은 딱 2 kmn 만 하 자 , 일 은 전혀 못 해도 괜찮 아 , 그저 2 kmn 만 하 면 돼 . ’ 그러 다가 그 시간 이 길 어 지 고 , 어느새 일 이 되 고 , 그러 면서 나 아 지 더군요 . 하루 종일 책상 에 붙 어 있 으면서 도 일 을 거의 못 하 는 것 보다 는 2 kmn 이 라도 내 가 쏟 는 시간 을 의식 해서 앉 아 있 는 편 이 집중력 회복 에 훨씬 도움 이 됩니다 . 전자 는 ‘ 내 가 그래도 책상 에 종일 붙 어 있 었잖 아 ’ 하 는 자기 변명 을 낳 지만 , 후자 는 ‘ 내 가 오늘 은 겨우 2 kmn 을 했 지만 내일 은 3 kmn 을 할 거 고 , 어차피 오늘 은 이 정도 밖에 못 하 는 날 이 었 어 ’ 하 는 건강 한 자기 위안 을 줍니다 . 3 ) 일 이 너무 지루 할 때 : 집중 이 문제 가 아니 라 일 이 너무 지루 해서 자꾸 일어나 고 싶 을 때 , 혹은 머릿속 이 너무 과열 되 어 터질 것 같 을 때 , 이때 야말로 20 분 휴식 의 진가 를 경험 할 수 있 습니다 . 이럴 때 40 분 일 하 고 나 면 ‘ 더 는 못 해 먹 겠 다 , 오늘 은 이 만 때려 치울 까 ’ 하 는 생각 이 절로 들 지만 , 그래도 아무튼 정해진 대로 일단 쉬 면서 몸 을 움직이 고 머리 를 비우 면 놀랍 게 도 20 분 이 흐른 뒤 에 는 ‘ 1 kmn 정도 는 꾸역꾸역 더 할 수 있 겠 다 ’ 하 는 생각 이 듭니다 . 휴식 이 너무 짧 으면 그런 생각 이 안 들 어요 . 하지만 20 분 은 충분히 깁니다 . 4 ) 일 의 진척 이 더뎌서 조바심 날 때 : 이것 은 2 ) 와 좀 비슷 한 상황 입니다 . 일 이 더뎌서 미칠 것 같 아도 안달복달 하 며 앉 아만 있 는다고 해서 되 는 건 아무것 도 없 습니다 . 자기 혐오 만 깊 어 지 죠 . 휴식 이 사치 가 아닌가 싶 어도 , 이런 때 일수록 이 작업 법 에서 벗어나 지 말 아야 합니다 . 그러면 이렇게 생각 할 수 있 습니다 . ‘ 오늘 8 kmn 을 했 구나 . 여전히 진척 이 더뎌서 일 이 밀렸 지만 , 아무튼 나 는 오늘 할 일 을 마쳤 어 . 이 이상 은 능력 밖 이 야 . 애초 에 내 가 소요 시간 이나 난이도 를 오판 한 것 이 니까 , 오늘 쉬 지 않 고 집착 한다고 해서 해결 할 순 없 어 . 지금 내 가 할 수 있 는 일 은 매일 꾸준히 하 는 것 뿐 이 야 . ’ 이런 날 이 며칠 쌓이 면 , 그만큼 진도 도 나갑니다 . 5 ) 일 의 진척 이 빨라서 성급 해질 때 : 가끔 은 거꾸로 인 때 도 있 죠 . 지금 제 가 이 글 을 쓰 면서 그렇 습니다 . ‘ 40 + 20 작업 법 을 설명 하 는 글 은 4 kmn 이 면 쓰 겠 지 ? ’ 저 는 신나 게 키보드 를 두드렸 습니다 . 쓸 말 이 쉼 없이 떠올라서 쉬 고 싶 지 않 았 고 , 안 쉬 어도 될 것 같 았 고 , 쉬 지 않 는다면 3 kmn 만 에 도 끝낼 수 있 을 것 같 았 습니다 . 하 지만 그럴 리 없 죠 . 어쨌든 쉬 면서 생각 해 보 니 , 빠뜨린 말 이 있 었 습니다 . 그리고 또 아니요 , 모든 일 은 예상 시간 의 두 배 가 들 기 마련 입니다 . 저 는 지금 4 kmn 이 아니 라 6 kmn 째 쓰 고 있 습니다 . 애초 에 이만큼 소요 될 일 을 한 순간 속도 가 난다고 해서 3 kmn 으로 줄이 려고 해 봐야 허리 만 아픕니다 . 속도 가 날 때 내처 해 버리 고 싶 은 마음 이 정말 소요 시간 을 줄여 주 는 결과 로 이어지 는 경우 는 드 뭅니다 . 나중 에 가 서 ‘ 어차피 이만큼 시간 을 쏟 을 바 에 야 쉬엄쉬엄 할걸 ’ 해 봐야 이미 허리 는 아픕니다 . 6 ) 작업량 을 기록 하 고 싶 을 때 : ‘ 대충 오전 10 시 ~ 오후 6 시 까지 책상 에 붙 어 있 으면서 이 일 을 해냈 다 ’ 는 것 과 ‘ 오전 10 시 ~ 오후 6 시 까지 8 kmn 으로 이 일 을 끝냈 다 ’ 는 것 사이 에 는 차이 가 있 습니다 . 전자 의 방법 으로 가늠 한 작업량 은 오류 가 있 기 쉽 습니다 . 하지만 후자 의 방법 을 쓰 면 , 몇 가지 메모 를 추가 하 는 것 만 으로 도 금세 시간 별 세부 작업 기록 을 얻 을 수 있 습니다 . 7 ) 가사 노동 과 병행 할 때 : 프리랜서 라도 집 밖 에서 일 하 는 분 , 집 에서 일 하 더라도 가사 노동 을 나눌 동거인 이 있 거나 해서 혼자 맘대로 해버릴 수 는 없 는 분 에게 는 적용 되 지 않 는 항목 입니다 . 하지만 저 처럼 집 에서 일 하 는 데 다가 가사 노동 도 전담 하 는 분 이 라면 , 이 작업 법 으로 일 과 가사 노동 을 얼마간 병행 할 수 있 습니다 . 가사 노동 을 저녁 으로 미뤄 본들 어차피 저녁 에 내 가 해야 할 뿐 이 라면 , 가능 한 한 낮 에 짬짬이 해 두 는 편 이 좋 습니다 . 일 한 뒤 지친 몸 으로 는 더 하 기 싫 을 테 니까요 . 그리고 20 분 은 꽤 길 어서 , 정리 정돈 수준 의 가사 노동 은 다 할 수 있 습니다 . 그렇게 해서 깨끗 해진 집 은 업무 공간 이 기 도 하 므로 , 휴식 과 업무 의 질 이 둘 다 좋 아 집니다 . 부록 1 . 20 분 쉴 때 뭘 하 나요 ? 1 ) 노래 듣 기 2 ) 스트레칭 3 ) 맨 손 운동 4 ) 간식 먹 기 5 ) 집안일 6 ) 전화 통화 나 문자 나 메신저 7 ) 책 몇 쪽 읽 기 1 ) 노래 듣 기 : 저 는 약 5 ~ 10 분 짜리 곡 을 하나 골라서 브라우저 의 유튜브 탭 이나 플레이어 에 늘 열 어 둡니다 . 40 분 경과 를 알리 는 타이머 가 울리 면 , 자리 에서 일어나 는 동시 에 곡 을 재생 합니다 . 노래 를 들으면서 스트레칭 을 하 죠 . 그러면 휴식 시간 의 경과 를 가늠 하 기 가 쉽 고 , 긴장 이 잘 풀리 고 , 기분 이 좋 아 집니다 . 2 ) 스트레칭 : 저 는 거실 에 늘 요가 매트 를 펼쳐 둡니다 . 그랬 다가 휴식 시간 이 되 면 무조건 그리로 가 고 봅니다 . 20 분 휴식 이 늘 반가운 건 아닙니다 . 내처 쉴 수 있 다면 모를까 , 조만간 다시 책상 에 앉 아야 하 는 걸 아 니까 마음 이 무겁 습니다 . 그리고 스트레칭 도 ‘ 해야 하 는 일 ’ 이 니 , 하 기 싫 을 때 가 많 습니다 . 사실 늘 하 기 싫 습니다 . 스트레칭 을 해 줘야 몸 이 아프 지 않 고 일 도 더 잘 된다는 걸 아 니까 하 려고 애쓸 뿐 입니다 . 따라서 , 어떻게 몸 을 풀 까 궁리 하 는 단계 를 아예 없애 도록 스트레칭 에 도 루틴 이 있 으면 좋 습니다 . 십 분 쯤 이어지 는 스트레칭 동작 을 정해 두 면 좋 겠 죠 . 저 는 요가 를 배운 걸 요긴 하 게 씁니다 . 요가 에 는 ‘ 플로우 ’ 가 있 죠 . 한편 , 눕 는 것 은 좋 지 않 습니다 . 힘들 면 자연히 벌렁 눕 고 싶 지만 , 실제로 저 는 자주 그러 지만 , 그냥 누워 있 는 건 스트레칭 보다 피로 를 푸 는 데 좋 지 않 습니다 . 다시 일어나 기 도 너무 어렵 습니다 . 누워서 눈 을 감 고 있 는 건 좋 지만 , 가급적 안 눕 고 눈 을 풀 어 주 려고 애씁니다 . 3 ) 맨 손 운동 : 늘 매트 가 펼쳐져 있 으면 그 위 에서 팔 벌려 뛰 기나 플 랭크 를 할 수 도 있 습니다 . 물론 저 는 안 합니다 . 4 ) 간식 먹 기 : 사과 처럼 간편 하 게 먹 을 수 있 는 걸 서 서 먹 으면서 창밖 도 구경 하 고 그럽니다 . 5 ) 집안일 : 설거지 , 방 하나 청소기 로 돌리 기 , 서랍 하나 정리 하 기 , 저녁 에 내버릴 재활용품 정리 하 기 , 세탁기 돌리 기 , 빨래 널 기 , 빨래 개기 , 저녁 에 먹 을 채소 씻 기 , 커피 내리 기 . 6 ) 전화 통화 나 문자 나 메신저 : 반면 책상 에 계속 앉 아서 이메일 을 쓰 는 것 은 좋 지 않 습니다 . 7 ) 책 몇 쪽 읽 기 : 일 이 머리 를 과열 시키 지 않 는 것 이 라면 , 이때 서서 책 을 몇 쪽 읽 을 수 도 있 습니다 . 쉬 는 동안 추리 소설 을 한 챕터 씩 읽 으면 정말 감질나 고 재밌 습니다 . 부록 2 . 40 + 20 작업 법 을 매일 어떻게 기록 하 나요 ? 저 는 이 사진 과 같이 이면지 에 기록 합니다 . 사생활 이 덜 드러난 메모 로 골라 보 았 지만 그래도 부끄럽 네요 . 6 월 17 일 월요일 에 는 일 이 잘 되 었 는지 10 kmn 을 했 습니다 . 6 월 19 일 수요일 에 는 8 kmn 을 하 겠 다고 계획 했 지만 4 kmn 밖에 못 했 네요 . 빨간 가위표 나 줄표 는 처리 했 다는 뜻 입니다 . 제 가 손 으로 기록 하 는 건 이게 편하 기 때문 입니다 . 메모 앱 등 도 시도 해 봤 지만 , 과하 다고 판단 했 습니다 . 이런 메모 또한 작업 을 돕 는 수단 일 뿐 이 니 , 수단 자체 에 들이 는 품 은 가급적 줄여야 좋 습니다 . 만약 에 매일 의 작업 시간 을 기록 했 다가 나중 에 통계 를 내 고 싶 다면 , 그때 는 손 으로 쓰 지 말 고 앱 이나 스프레드시트 를 활용 하 는 편 이 좋 겠 죠 . 하지만 저 는 이 메모 를 그냥 버립니다 . 굳이 ‘ 발전 된 ’ 생산 성 관리 도구 를 쓰 는 데 집착 할 필요 는 없 다고 생각 합니다 . 손 으로 쓰 는 것 도 기술 입니다 . 오래 되 고 검증 된 기술 입니다 . 그 보다 더 세련 된 기술 을 써야 할 필요 가 생기 면 그때 배우 면 됩니다 . 제 생각 이 지만 , 수단 에 필요 이상 공 을 들이 면 일 에 집중 하 지 못합니다 . ‘ 청소기 ’ ‘ 택배 받 기 ’ 등 사 적 인 일정 도 적혀 있 는 건 , 그날 잊 지 말 고 처리 해야 할 집안일 이나 여타 활동 을 함께 적 어 두 면 역시 머릿속 이 한결 정돈 되 기 때문 입니다 . ‘ 내 가 청소기 를 어제 돌렸 던가 ? ’ ‘ 오늘 꼭 해야 한다고 생각 한 일 이 있 었 는데 그게 뭐 지 ? ’ 하 는 잡념 이 사라집니다 . 메모 작성 이 강박 이나 부담 이 되 지 않 을 정도 로 만 하 면 됩니다 . 부록 3 . 장기 적 으로 작업 을 어떻게 기록 하 나요 ? 이면지 에 기록 했 다가 나중 에 버려도 되 는 항목 , 심지어 버리 고 깡그리 잊 어야 머릿속 이 깨끗 해진다고 까지 말 할 수 있 는 항목 , 그런 게 아닌 것 도 물론 있 습니다 . 그런 건 따로 작업 노트 에 기록 합니다 . 저 는 작업 노트 를 이 사진 과 같 은 방식 으로 씁니다 . 얼마 전 [ 미스테리아 24 호 ] 에 싣 기 위해서 ‘ 발란 데르 의 첫 번 째 사건 ’ 이 라는 단편 소설 을 번역 했 을 때 의 기록 입니다 . ‘ 참고 자료 읽 기 ’ ‘ 일독 ’ ‘ 재독 ’ ‘ 타임 테이블 작성 ’ ‘ 번역 ’ ‘ 퇴고 ’ ‘ 메일 로 송고 ’ 로 단계 를 나눠서 적 었 네요 . 번역 중 에 는 하루 에 원서 로 몇 쪽 ( p . ) 을 옮겼 는지 도 적 었 습니다 . 퇴고 도 하루 에 몇 쪽 을 했 는지 적 었 습니다 . 작업 을 다 끝낸 뒤 에 는 원서 가 몇 쪽 이 었 는지 , 그걸 번역 하 니 원고지 로 는 몇 매였 고 a 4 로 는 몇 매였 는지 도 적 었 습니다 . 이렇게 적 어 두 면 , 나중 에 또 이 와 비슷 한 글 을 번역 하 게 되 었 을 때 이 기록 을 바탕 으로 소요 시간 을 예측 할 수 있 습니다 . 일정표 외 에 도 작업 하 는 도중 에 중간중간 떠올린 생각 , 편집자 에게 추후 전달 할 사항 , 옮긴 이 후기 에 적 으면 좋 겠 다 싶 은 생각 등 도 적 어 둡니다 . 필요 하 다면 매일 몇 kmn 씩 했 는지 도 적 을 수 있 겠 지만 , 저 는 그것 까진 필요 하 지 않 아서 안 적 습니다 . 무엇 을 기록 해야 하 는지 는 일 의 성격 마다 다르 겠 죠 . 저 는 이런 작업 노트 를 12 권 째 쓰 고 있 습니다 . 부록 4 . 어떤 타이머 를 쓰 나요 ? 저 는 개 를 좋아하 는지라 , 늑대 짖 는 소리 로 “ 아우 우우우우 월 월 월 ! ” 하 고 시간 을 알려 주 는 ‘ 하 울러 타이머 howler timer ’ 앱 을 씁니다 . 엄청 단순 한 타이머 라 더 좋 습니다 . 저 는 스크린 샷 처럼 바탕 화면 에 늘 이 타이머 를 띄워 두 고 , 꼭 일 할 때 가 아니 라도 컴퓨터 앞 에 앉 으면 무조건 시작 버튼 을 누릅니다 . 웹 서핑 이나 인터넷 쇼핑 을 하 더라도 아무 튼 40 분 뒤 에 는 반드시 자리 에서 일어나 서 스트레칭 하 기 위해서 입니다 . 물론 그럴 때 는 일 할 때 보다 훨씬 자주 일어나 는 데 실패 합니다 .',\n",
       "       '- 우리 는 특정 변수 에 중요 한 영향 을 미치 는 변수 들 을 찾 고 , 그 들 이 각각 목표 로 하 는 변수 에 어떻 게 영향 을 미치 는지 파악 하 고 , 나아가 이 를 예측 하 기 위해서 회귀분석 을 사용 한다 . 하지만 만약 우리 가 비만 의 정도 인 bmi 지수 에 영향 을 미치 는 요인 과 그 정도 를 파악 하 고자 하 는데 \" bmi 지수 는 커피 를 마신 양 의 세제곱 을 한 값 에 크림 을 마신 양 의 제곱 을 한 것 과 미약 한 정도 의 관련 이 있 습니다 . \" 라고 이야기 한다면 말 하 는 자신 도 그것 이 의미 하 는 것 을 이해 하 기 힘들 것 이 다 . 그래서 가장 단순 하 게 생각 할 수 있 는 것 은 단순 한 선형 관계 이 다 . 단순 한 선형 관계 는 변수 들 사이 의 관계 를 이해 하 기 쉽 게 나타낼 수 있 기 때문 에 다소 정밀 한 예측 이 아니 라도 많이 사용 된다 . ( 정밀도 또한 그렇게 나쁘 지 않 은 경우 가 많 다 . ) 그렇 게 해서 회귀분석 을 수행 하 면 패키지 에서 필요 한 값 들 을 출력 해 준다 . 남 은 것 은 이 값 들 을 해석 하 는 것 이 다 . 여기 서 어떤 변수 가 유의 한지 , 그 변수 에 대한 추정 값 은 무엇 이 며 추정 값 에 대한 표준 오 차 는 어느 정도 인지 , 모형 은 적절 한 지 등 을 확인 할 수 있 다 . 그 중 에서 모형 이 잘 적합 되 었 는지 판단 할 때 r - squared 또는 adjusted r - squared 를 사용 하 고 , 모형 이 통계 적 으로 적절 한지 판단 할 때 f - 통계량 을 사용 한다고 알려져 있 다 . 사실 이 내용 으로 보 았 을 때 , 그 의미 가 잘 구분 이 되 지 않 는다 . 그냥 보 면 r 제곱 값 이나 f 값 이나 다 모형 이 적절 한지 보 는 것 같 은데 왜 둘 을 따로 쓸까 ? 특히 f 값 은 유의 한 정도 로 크 지만 r - squared 값 은 작 은 경우 는 무엇 을 의미 할까 ? 결론 부터 말 하 자면 두 값 은 모형 이 적절 한지 를 말 해 주 는 값 이 지만 각각 의미 하 는 바 가 다르 다 . f - 통계량 값 은 자유도 로 조정 된 설명 된 변동 과 설명 되 지 않 는 변동 의 비 를 나타낸 것 이 다 . 이 값 은 결국 이 관계 를 선형 으로 볼 수 있 는가 없 는가 를 의미 한다 ( 즉 , 회귀 계수 가 유의 한가 ? ). r - squared 값 은 전체 변동 에 대해 모형 이 설명 하 는 변동 의 비 를 나타낸다 . 이 값 은 자료 들 이 우리 가 설정 한 회귀 직선 주위 에 얼마나 밀집 되 어 있 는지 를 의미 하 는 것 이 다 . 이 값 이 낮 다는 것 은 선형 에서 많이 퍼져 있 는 것 이 다 . 그래서 f 값 은 유의 하 지만 , r - squared 값 이 아주 낮 은 경우 에 는 1 ) x 가 y 에 미치 는 영향 은 여전히 유의 하 다 . 2 ) 하지만 우리 가 추정 한 회 귀식 에서 각 값 들 의 분산 이 커서 예측 에 대해서 는 신뢰 하 기 힘들 다 . 라고 결론 지 을 수 있 겠 다 . 참고 ) [ URL ]',\n",
       "       \"웹 크롤링 강의 를 배우 면서 가장 유용 한 패키지 두 개 를 꼽 으라고 하 면 beautifulsoup 와 selenium 이 라고 할 수 있 겠 다 . 설 연휴 전 에 강의 를 들 어 배웠었 지만 설 연휴 동안 일 하 면서 복습 도 . .. 공부 도 . .. 쉬 다 보 니 연휴 가 끝나 니 머리 가 백지상태 처럼 되 었었 다 . . 그래서 다시 토이 프로젝트 처럼 복습 차원 겸 다시 웹 크롤링 예제 를 만들 어 보 려고 한다 . 요즘 노 마드 코더 아카데미 를 이용 해서 웹 크롤링 에 대한 다른 강의 를 또 듣 고 있 는데 패스트 캠퍼스 와 는 다른 방법 을 쓰 는 거 같 기 도 해서 신기 하 기 도 했 지만 더 어지러워 진 것 같 다 . .. 이번 에 하 기 로 한 것 은 ' 사람 인 ' 이 라는 채용 정보 사이트 에서 ' 데이터 엔지니어 ' 를 검색 하 고 나오 는 ' 채용 정보 ' 와 ' 채용 마감 시간 ' 이렇게 2 가지 정보 를 각각 연속 적 으로 크롤링 해 보 았 다 . 다음 페이지 까지 크롤링 해 보 는 건 다음 토이 프로젝트 때 해 보 려고 한다 . 그리고 요즘 anaconda 를 이용 해 가상 환경 을 만들 어 vscode 에 코딩 을 작성 하 고 있 다 . 필요 한 모듈 import 우선 가장 중요 하 다고 볼 수 있 는 필요 한 모듈 을 임포 트 했 다 . 4 번 째 줄 부터 차례 로 모듈 에 대해 설명 하 자면 , 1 . 크롬 웹 드라이버 를 이용 하 기 위한 모듈 2 . 브라우저 를 실행 시켜 데이터 를 가져오 거나 페이지 이 동시 대기 시간 을 갖 기 위한 모듈 3 , 4 , 5 브라우저 가 접속 하 고 접속 해서 다른 페이지 로 이동 하 거나 커서 를 이동해 클릭 할 때 까지 기다려 주 는 모듈 6 . 크롬 브라우저 를 이용 하 기 위한 모듈 7 . html 을 파싱 하고 원 하 는 데이터 를 갖 고 오 기 위한 뷰티풀 수프 모듈 크롬 브라우저 로 접속 options 모듈 에서 add _ argument 라는 추가 인자 를 이용 해 headless 모드 를 설정 할 수 있 다 . 여기 서 헤드 리스 란 , 브라우저 를 윈도우 창 에 띄우 지 않 고 내부 적 으로 실행 하 는 옵션 이 다 . 그리고 implicitly _ wati ( 몇 초 ) 를 입력 하 여 브라우저 에 접속 할 때 까지 내부 에서 대기 를 해 준다 . 여기 서 주석 처리 한 브라우저 사이즈 설정 은 헤드 리스 모드 를 풀 면 윈도우 창 에 뜨 는 브라우저 창 사이즈 를 조절 해 준다 . 그리고 get 방식 을 이용 하 여 해당 url 인자 를 넣 고 접속 을 요청 한다 . bs 4 를 이용 해당 url 에 접속 해서 . page _ source 함수 를 이용 해 전체 html 을 살펴보 자 . . 출력 내용 을 보 면 난해 하 다 . . 그래서 이 를 위해 뷰티풀 수프 를 초기 화 주 고 해당 url 의 html 을 파싱 한다 . 그리고 해당 url 로 가 서 크롬 개발자 도구 를 이용 해 css 선택 자 를 이용 해서 채용 정보 를 가져온다 . 중간 에 잘 했 는지 살펴보 기 위해서 cru _ list 를 출력 해 본다 . 채용 정보 와 채용 마감 시간 출력 그리고 for 문 을 이용 해서 채용 정보 와 채용 마감 시간 을 출력 하 고 print ( ) 공백 두 번 으로 한 건 의 채용 정보 와 채용 마감 시간 을 나누 어 준다 . 그리고 마지막 으로 브라우저 종료 를 시켜 준다 . 결과 를 출력 하 면 밑 의 사진 과 같이 출력 된다 . 결과 출력 터미널 밑 에 더 데이터 가 존재 하 지만 전체 결과물 에 대한 사진 을 업로드 하 는 건 별로 의미 가 없 다고 생각 되 어서 . . 맨 위 화면 만 캡쳐 해서 올렸 다 . 이렇게 몇 줄 안 되 는 코드 를 작성 하 는 데 에 도 2 시간 이 넘 게 걸린 것 같 다 . .. 다음 에 는 한 페이지 만 이 아닌 여러 페이지 까지 선택 해서 출력 해 보 겠 다 .\",\n",
       "       '거의 동시 에 딥 러닝 과 강화 학습 에 관한 리뷰 페이퍼 가 각각 공개 되 었 습니다 . 하나 는 “ on the origin of deep learning “ ( 1702 . 07800 pdf ) 로 80 페이지 가 넘 습니다 . 퍼셉트론 부터 시작 해서 최근 의 뉴 럴 네트워크 의 다양 한 기술 들 을 요약 하 고 있 습니다 . 볼츠만 머신 , 딥 빌 리프 , cnn , rnn , gan , 최적화 등 다양 한 주제 를 망라 하 고 있 습니다 . 시작 을 아리스토텔레스 까지 거슬러 올라간 건 애교 로 봐야 할까요 ? 🙂 다른 하나 는 “ deep reinforcement learning : an overview “ ( 1701 . 07274 pdf ) 입니다 . dqn , policy gradient 와 강화 학습 이 적용 된 다양 한 어플리케이션 을 소개 하 고 있 습니다 . 레퍼런스 만 절반 이 라 강화 학습 이론 자체 보다 는 관련 리소스 를 확인 하 는 용도 로 좋 을 것 같 습니다 .',\n",
       "       '작년 장애 인 평등 법 에 따라 온라인 에 무료 로 공개 된 버클리 대학 의 컨텐츠 가 삭제 될 것 이 라는 뉴스 가 있 었 습니다 . 이 삭제 조치 가 이번 달 3 월 15 일 부터 유투 브 와 아이튠즈 u 에 대해 시행 된다는 기사 가 게재 되 었 습니다 . 혹시 유투 브 에 있 는 버클리 강의 중 에 필요 한 것 이 있 다면 다운 받 아 놓 는 게 좋 습니다 . 이 조치 가 강화 학습 강의 를 진행 하 고 있 는 cal esg 에 도 적용 되 는 것 인지 는 확실 하 지 않 습니다 . 혹시 모르 니 미리 받 아 두 는 것 도 나쁘 지 는 않 을 것 같 습니다 . edx 에 있 는 강의 에 는 영향 을 받 지 않 습니다 . ( 업데이트 ) 파이썬 의 youtube - dl 패키지 를 이용 하 면 손쉽 게 동영상 리스트 를 다운 받 을 수 있 습니다 . 아래 명령 은 cs 294 : deep rl 동영상 리스트 로 부 터 강의 동영상 을 모두 다운 받 는 명령 입니다 . 동영상 에 자동 으로 생성 되 는 캡션 이 있 으면 같이 다운 받 습니다 . 이 자막 은 기본 파일 형식 에 vtt 인데 저 는 vlc 로 재생 이 됩니다 . $ pip install youtube - dl $ youtube - dl -- yes - playlist -- write - auto - sub [ URL ]',\n",
       "       '지난번 에 는 gatsby 로 새로운 프로젝트 를 생성 하 고 , 타입 스크립트 와 prettier 설정 을 진행 했 습니다 . 이번 에 는 gatsby 의 기능 을 이용 해서 동적 으로 페이지 를 생성 하 는 기능 을 구현 해 보 겠 습니다 . 일반 적 으로 는 pages 폴더 에 컴포넌트 를 추가 하 는 방식 으로 페이지 를 추가 할 수 있 지만 , 블로그 처럼 파일 을 읽 어서 각각 하나 의 페이지 로 만들 기 위해서 는 gatsby 에서 제공 하 는 파일 시스템 플러그인 을 기본 으로 하 고 , 마크 다운 해석 과 관련 된 플러그인 도 필요 합니다 . 그래서 이번 글 에서 는 플러그인 을 사용 하 지 않 고 , gatsby 에서 제공 하 는 api 를 사용 해 페이지 만드 는 방법 을 먼저 체험 해 본 다음 , 플러그인 을 사용 하 여 마크 다운 파일 을 블로그 포스트 로 만드 는 작업 을 진행 해 보 겠 습니다 . createpages api 를 사용 하 여 페이지 만들 기 일단 해 보 기 일단 gatsby 에서 페이지 를 어떻게 만들 수 있 는지 알아봅시다 . createpages 는 gatsby 의 node api 입니다 . 따라서 , gatsby - node . js 파일 을 수정 해야 합니다 . 기존 에 작성 되 어 있 던 주석 은 지우 고 아래 와 같이 내용 을 적 은 뒤 , exports . createpages = ( ) => { console . log ( \\' i will create a page ! \\' ) ; } ; 다시 gatsby develop 명령 을 실행 해 보 겠 습니다 . success processing types - 0 . 082 s success building schema - 0 . 277 s i will create a page ! success createpages - 0 . 019 s success createpagesstatefully - 0 . 067 s 정상 적 으로 로그 가 표시 되 는 것 을 확인 했 습니다 . 타입 스크립트 설정 타입 스크립트 를 너무 좋 아 하 는 저 는 gatsby - node . js 파일 도 타입 스크립트 로 작성 하 고 싶 습니다 . 지난 시간 에 타입 스크립트 플러그인 을 구성 했으니 이 파일 도 타입 스크립트 파일 로 작성 하 면 잘 작동 할까요 ? 파일 의 확장자 를 ts 로 변경 하 고 다시 실행 해 보 면 그렇 지 않 다는 것 을 알 수 있 습니다 . success processing types - 0 . 080 s success building schema - 0 . 261 s success createpages - 0 . 013 s / / no . .. success createpagesstatefully - 0 . 059 s success onpreextractqueries - 0 . 014 s 여러 레퍼런스 를 찾아보 고 , 기존 에 타입 스크립트 기반 으로 된 스타터 에서 는 어떻게 구현 했 는지 찾아본 결과 아래 와 같이 구성 하 면 된다는 것 을 알 게 되 었 습니다 . gatsby - node . js 파일 은 자바 스크립트 확장자 를 그대로 사용 하 되 , ts - node 를 패키지 를 설치 한 뒤 gatsby - node . js 상단 에서 require ( ) 후 register ( ) 를 호출 합니다 . 단 , createpages 와 같 은 api 는 별도 의 타입 스크립트 파일 로 작성 한 뒤 사용 합니다 . 일단 변경 했 던 확장자 는 다시 js 파일 로 변경 한 뒤 , ts - node 패키지 를 설치 하 겠 습니다 . $ yarn add - d ts - node 이후 gatsby - node . js 파일 상단 에 아래 와 같이 추가 합니다 . require ( \\' ts - node \\' ) . register ( ) ; exports . createpages = ( ) => { console . log ( \\' i will create a page ! \\' ) ; } ; 그리고 createpages 함수 를 별도 의 타입 스크립트 파일 로 작성 해야 하 는데 , 저 는 src 폴더 안 에 lib 폴더 를 만들 어 준 다음 그곳 에 파일 을 작성 하 겠 습니다 . ( / src / lib / createpages . ts ) export async function createpages ( ) { console . log ( \\' i will create a page ! \\' ) ; console . log ( \\' typescript ! \\' ) ; } 다시 gatsby - node . js 파일 로 돌아와서 , 기존 에 작성 된 부분 을 지우 고 새로 작성 한 타입 스크립트 함수 를 사용 하 도록 하 겠 습니다 . require ( \\' ts - node \\' ) . register ( ) ; const { createpages } = require ( \\'./ src / lib / createpages \\' ) ; exports . createpages = createpages ; 다시 gatsby develop 를 실행 해 보 면 작성 했 던 로그 가 표시 되 는 것 을 확인 할 수 있 습니다 . success processing types - 0 . 068 s success building schema - 0 . 229 s i will create a page ! typescript ! success createpages - 0 . 020 s success createpagesstatefully - 0 . 058 s 페이지 추가 해 보 기 타입 스크립트 로 createpages api 를 사용 할 준비 가 되 었 습니다 . createpages 함수 가 호출 될 때 하나 의 인자 를 받 고 , 그 인자 안 에 actions 나 graphql 를 포함 한 헬퍼 함수 들 이 들 어 있 습니다 . 이 인자 에 대한 타입 선언 은 다행히 도 gatsby 에 포함 되 어 있 습니다 . 아래 와 같이 createpagesargs 타입 을 사용 하 면 됩니다 . import { createpagesargs } from \\' gatsby \\' ; export async function createpages ( { actions } : createpagesargs ) { } 그 중 에 저 는 actions 라는 것 을 미리 분해 할당 해 두 었 습니다 . actions 는 무엇 일까요 ? gatsby 는 내부 적 으로 리덕 스 를 사용 하 여 내부 상태 를 관리 합니다 . 이 상태 를 조작 하 기 위한 , 리 액트 에서 리덕 스 를 사용 할 때 처럼 액션 생성자 와 dispatch ( ) 가 결합 된 함수 들 이 들 어 있 는 객체 입니다 . 이전 버전 의 gatsby 로 구성 된 경우 boundactioncreators 라는 이름 으로 사용 하 고 있 을 수 있 습니다 . 이 는 v 2 로 넘어오 면서 이름 이 변경 되 었 고 , 하위 호환 성 을 위해 아직 까지 는 여전히 유지 하 고 있 는 것 으로 확인 됩니다 . ( 참고 링크 ) actions 내 에 있 는 것 중 에서 createpage 액션 을 사용 하 여 페이지 를 추가 해 보 겠 습니다 . import { createpagesargs } from \\' gatsby \\' ; const pages = [ { id : 1 , content : \\' gatsby 로 블로그 만들 기 \\' } , { id : 2 , content : \\' 거기 에 타입 스크립트 적용 해 보 기 \\' } , { id : 3 , content : \\' 확실히 어렵 네요 \\' } , ] ; export async function createpages ( { actions } : createpagesargs ) { const { createpage } = actions ; pages . foreach ( page => { createpage ( { path : page . id . tostring ( ) , context : page , component : \\'\\' } ) ; } ) ; } 이 코드 에서 아직 component 부분 이 빈 문자열 로 만 되 어 있 습니다 . 이 상태 로 실행 하 면 오류 를 반환 힙 니다 . your site \\' s \" gatsby - node . js \" created a page and didn \\' t pass the path to the component . the page object passed to createpage : { \" path \": \" 1 \", \" context \": { \" id \": 1 , \" content \": \" gatsby 로 블로그 만들 기 \" }, \" component \": \"\" } see the documentation for the \" createpage \" action — [ URL ] component 부분 에 는 이 내용 이 표시 될 컴포넌트 의 절대 경로 를 입력 해야 합니다 . 우리 는 아직 블로그 게시 글 을 표시 할 컴포넌트 가 없 기 때문 에 간단 하 게 만들 어 보 겠 습니다 . 블로그 게시 글 이 공통 적 으로 사용 하 는 템플 릿 컴포넌트 가 필요 합니다 . src 폴더 내 의 templates 폴더 를 만들 고 , posttemplate . tsx 파일 을 만들 겠 습니다 . import react from \\' react \\' ; import layout from \\'../ components / layout \\' ; const posttemplate : react . fc = react . memo ( props => { return ( < layout > < code > < pre > { json . stringify ( props , null , 4 ) } ) ; } ) ; posttemplate . displayname = \\' posttemplate \\' ; export default posttemplate ; 아직 정확히 어떤 데이터 가 전달 되 는지 모르 기 때문 에 props 의 모든 내용 을 출력 하 는 템플 릿 입니다 . 컴포넌트 를 만들 었 으니 다시 createpages 함수 내 의 component 부분 에 이 컴포넌트 의 경로 를 입력 하 겠 습니다 . import { createpagesargs } from \\' gatsby \\' ; import path from \\' path \\' ; const pages = [ { id : 1 , content : \\' gatsby 로 블로그 만들 기 \\' } , { id : 2 , content : \\' 거기 에 타입 스크립트 적용 해 보 기 \\' } , { id : 3 , content : \\' 확실히 어렵 네요 \\' } , ] ; export async function createpages ( { actions } : createpagesargs ) { const { createpage } = actions ; pages . foreach ( page => { createpage ( { path : page . id . tostring ( ) , context : page , component : path . resolve ( __ dirname , \\'../ templates / posttemplate . tsx \\' ) , } ) ; } ) ; } 저장 한 뒤 , gatsby develop 을 다시 실행 해 보 겠 습니다 . 정상 적 으로 실행 된 뒤 마지막 에 표시 되 는 페이지 수 가 늘어났 음 을 확인 할 수 있 습니다 . 브라우저 에 [ [ URL ] 를 입력 하 면 아래 와 같이 , 만들 어 둔 템플 릿 컴포넌트 에 props 가 표시 되 는 것 을 확인 할 수 있 습니다 . 마크 다운 파일 을 블로그 게시 글 로 표시 하 기 이번 에 는 마크 다운 파일 을 작성 하 고 이 파일 들 을 플러그인 이 불러온 다음 createpages 함수 에서 createpage 액션 을 사용 하 여 페이지 로 만들 어 보 겠 습니다 . 이 기능 을 구현 하 기 위해서 gatsby - transformer - remark 플러그인 을 설치 하 겠 습니다 . $ yarn add gatsby - transformer - remark 정확 하 게 는 gatsby - source - filesystem 플러그인 을 같이 사용 해야 하 기 때문 에 같이 설치 해야 하 지만 , 이미 설치 되 어 있 기 때문 에 따로 설치 를 하 지 않 겠 습니다 . 그 다음 , gatsby - config . js 파일 을 수정 하 여 , 설치 한 마크다운 플러그인 을 적용 합니다 . plugins : [ { resolve : \\' gatsby - source - filesystem \\' , options : { name : \\' posts \\' , path : ` ${ __ dirname } / posts ` , } , } , ` gatsby - transformer - remark ` , ] , 먼저 gatsby - source - filesystem 플러그인 을 사용 하 여 마크 다운 파일 이 위치 할 폴더 를 읽 도록 하 고 , 이 마크 다운 파일 을 해석 하 여 html 으로 변환 하 는 gatsby - transformer - remark 플러그인 을 사용 하 였 습니다 . 마크 다운 파일 은 src 폴더 보 다는 별도 의 폴더 를 사용 하 는 게 낫 다고 판단 되 어 posts 폴더 를 프로젝트 루트 폴더 내 에 만들 었 습니다 . 테스트 를 위해 마크 다운 파일 하나 를 추가 하 였 습니다 . ( / posts / test . md ) --- title : 테스트 --- # hi ! 마크다운 으로 작성 한 게 시 글 입니다 . gatsby develop 을 다시 실행 한 다음 , 내장 되 어 있 는 graphiql 브라우저 를 실행 해 봅시다 . 좌측 의 explorer 영역 을 보 면 allmarkdownremark 라는 스키마 가 추가 된 것 을 확인 할 수 있 습니다 . 대충 어떤 필드 가 있 는지 확인 한 다음 , 보 고 싶 은 항목 을 체크 하 여 쿼리 를 날려 보 겠 습니다 . 작성 한 마크다운 에 대한 데이터 가 표시 되 는 것 을 볼 수 있 습니다 . 분명 이 쿼리 를 createpages 함수 내 에서 사용 한 뒤 , 이 결과 값 을 페이지 로 만들 어야 합니다 . 바로 해 봅시다 . createpages 함수 내용 을 아래 와 같이 변경 합니다 . export async function createpages ( { actions , graphql } : createpagesargs ) { const { createpage } = actions ; const { data , errors } = await graphql ( ` { allmarkdownremark { edges { node { html frontmatter { title } } } } } ` ) ; if ( errors ) { throw errors ; } data . allmarkdownremark . edges . foreach ( ( { node } : any ) => { createpage ( { path : node . frontmatter . title , context : { html : node . html , title : node . frontmatter . title , } , component : path . resolve ( __ dirname , \\'../ templates / posttemplate . tsx \\' ) , } ) ; } ) ; } createpagesargs 에 는 graphql 쿼리 를 요청 할 수 있 는 graphql 이 있 습니다 . 이것 을 사용 해서 아까 확인 했 던 쿼리 를 넣 어 준 다음 , 오류 가 발생 하 면 errors 를 throw 합니다 . 정상 적 으로 쿼리 를 받 아 왔 다면 , data . allmarkdownremark . edges 에 는 변환 된 마크다운 과 관련 된 데이터 가 들 어 있 을 것 입니다 . 이 데이터 와 createpage 액션 을 사용 해서 페이지 를 추가 했 습니다 . 저장 후 gatsby develop 을 다시 실행 한 다음 , path 로 지정 한 대로 제목 을 입력 하 면 . .. 사진 과 같이 마크다운 으로 작성 한 내용 이 표시 되 는 것 을 확인 할 수 있 습니다 ! 다음 에 는 타입 스크립트 와 의 미묘 한 불 일치 를 해결 하 는 내용 을 다뤄 보 겠 습니다 .',\n",
       "       '이번 에 는 최상위 주소 로 들어갔 을 때 , 최근 에 작성 한 게 시 글 목록 을 표시 하 는 기능 과 utterances 위젯 을 활용 하 여 덧 글 기능 을 구현 해 보 겠 습니다 . 지금 index . tsx 파일 에 는 기본 으로 작성 된 내용 이 있 으니 먼저 이 내용 을 지우 고 임시 로 내용 을 채웠 습니다 . 그 다음 , 목록 에 표시 할 내용 을 가져오 기 위한 graphql 쿼리 를 작성 해 보 겠 습니다 . graphql 쿼리 작성 graphiql 를 사용 하 여 쿼리 작성 이번 에 사용 할 스키마 는 createpages 함수 에서 사용 했 던 allmarkdownremark 스키마 입니다 . 그러나 가져오 는 내용 에 차이 를 둘 것 입니다 . 전체 내용 의 일부분 을 가져오 기 위해 excerpt 항목 을 가져오 고 frontmatter 중 에서 는 제목 title , 이동 할 경로 path , 작성 일자 date 를 가져오 겠 습니다 . 또한 최근 작성 일 기준 으로 가져오 기 위해 [ frontmatter . date ] ( [ URL ] 를 내림 차 순 으로 정렬 하 겠 습니다 . 이렇게 작성 한 쿼리 는 아래 사진 처럼 데이터 를 반환 합니다 . usestaticquery 훅 사용 하 기 gatsby 내 의 컴포넌트 에서 는 어떻 게 graphql 쿼리 를 사용 할까요 ? staticquery 컴포넌트 를 사용 하 거나 아니 면 pagequery 를 활용 할 수 있 지만 , 더욱 간편 하 게 하 기 위해 usestaticquery 훅 을 사용 해서 진행 해 보 겠 습니다 . 위 에서 만들 어 둔 쿼리 를 gatsby 패키지 에 포함 되 어 있 는 graphql 과 함께 사용 합니다 . 저 는 쿼리 이름 을 따라서 latestpostlistquery 라는 이름 으로 만들 었 습니다 . const latestpostlistquery = graphql ` query latestpostlistquery { allmarkdownremark ( sort : { order : desc , fields : frontmatter ___ date }) { edges { node { excerpt ( truncate : true , prunelength : 200 ) frontmatter { title path date ( formatstring : \" yyyy - mm - dd hh : mm : ss \") } id } } } } ` ; 그 다음 , index . tsx 컴포넌트 내 에서 usestaticquery 를 사용 하 여 쿼리 를 가져온 뒤 , 데이터 를 가공 하 여 알맞 게 표시 합니다 . 여기 서 타입 스크립트 의 장점 을 살리 기 위해 usestaticquery 훅 에 도 query 제너릭 타입 을 지정 합니다 . const indexpage : react . fc = ( ) => { const data = usestaticquery < query > ( latestpostlistquery ) ; return ( < layout > < seo title = \" home \" / > < h 1 > 최근 작성 한 게 시 글 목록 < ul > { data . allmarkdownremark . edges . map ( ( { node } ) => ( < li key = { node . id } > < h 2 > < link to = { node . frontmatter . path } > { node . frontmatter . title } < h 3 > { node . frontmatter . date } < p > { node . excerpt } < hr / > ) ) } ) ; } ; posttemplate 수정 내친김 에 , 지난번 에 만들 어 두 었 던 posttemplate 컴포넌트 를 수정 해서 제목 , 작성 시간 , 내용 이 표시 되 도록 수정 하 겠 습니다 . const posttemplate : react . fc < iposttemplateprops > = react . memo ( props => { const { title , date , html } = props . pagecontext ; return ( < layout > < h 2 > { title } < h 4 > { date } < hr / > < div dangerouslysetinnerhtml = { { __ html : html } } / > ) ; } ) ; 확인 게시 글 목록 이 표시 되 는지 확인 해 볼까요 ? 게시 글 내용 이 잘 표시 됩니다 ! 🙌 어떻 게 작동 하 는 걸까 ? 🤔 궁금 점 이 생겼 습니다 . 일반 적 으로 graphql 은 \\' 동적 \\' 인 시간 에 , 언제 실행 될 지 모르 지만 그 때 에 서버 에 쿼리 를 요청 하 는 것 으로 이해 할 수 있 습니다 . 그러나 gatsby 는 \\' 정적 \\' 사이트 생성기 입니다 . 결과물 또한 정적 으로 빌 드 된 파일 이 나옵니다 . 이 궁금증 에 대한 해답 은 gatsby 공식 문서 중 관련 파트 에 나와 있 습니다 . graphql 은 태그 리터럴 함수 입니다 . gatsby 가 이 함수 를 배후 에서 ( 보이 지 않 는 곳 에서 ) 특정 방식 을 통해 처리 합니다 . 정리 하 자면 , gatsby 가 빌 드 하 는 과정 에서 , 코드 에 작성 해 둔 graphql 쿼리 는 구문 분석 을 위해 원본 코드 에서 제거 됩니다 . 정확히 는 , 추상 문법 트리 ( ast ) 로 변환 하 는 작업 을 통해 graphql 로 작성 한 태그 리터럴 은 원본 소스 에서 제거 됩니다 . 이건 우리 가 흔히 알 고 있 는 방식 대로 graphql 쿼리 가 실행 되 지 않 는 것 을 뜻 합니다 . utterances 위젯 설치 문제점 utterances 위젯 을 사용 하 기 위해서 는 github 에 공개 된 저 장소 를 만들 어야 합니다 . 저 는 추후 에 blog 라는 이름 으로 업로드 할 예정 이 기 때문 에 , blog 라는 이름 으로 저 장소 를 만들 었 습니다 . 그 다음 [ URL ] 에서 github 앱 을 설치 합니다 . 테마 나 이슈 연결 방식 에 대한 설정 은 해당 사이트 내 에서 설정 할 수 있 습니다 . 그러 면 붙여 넣 을 수 있 는',\n",
       "       '안드로이드 앱 분석 시작 방법 일반 앱 을 분석 하 기 위해 설치 파일 인 안드로이드 설치 파일 인 apk 을 알 아야 한다 . apk ( android package ) > 안드로이드 플랫폼 에서 어플리케이션 설치 를 위해 배포 되 는 패키지 파일 > 압축 zip 파일 포맷 형태 로 구성 > 주요 구성 요소 - androidmanifest . xml : 앱 에 대한 정보 및 실행 권한 등 의 정보 를 가지 는 xml - classes . dex : 달 빅 가상 머신 에서 동작 하 는 바이너리 실행 파일 - / res : 리소스 파일 폴더 - meta _ inf : 인증 파일 압축 파일 형식 이 기 때문 에 압축 프로그램 으로 확인 가능 하 다 . 또한 압축 해제 도 가능 하 다 . dex ( dalvik executable ) > 달 빅 가상 머신 에 맞 게 클래스 파일 을 바이트 코드 로 변환 한 파일 이 다 . > apk 파일 에 포함 된 classes . dex 파일 이 이 에 해당 한다 . > 자바 코드 를 컴파일 하 여 클래스 파일 을 만든 후 다시 dex 도구 로 압축 한 것 이 다 . apk 분석 을 위한 툴 준비 dex 2 jar : [ URL ] jd - gui : [ URL ] dex 2 jar : dex 파일 을 jar 파일 로 변환 해 주 는 툴 jd - jui : java decompile tool dex 2 jar 로 apk 디 컴파일 > command : dex 2 jar . bat [ apk file or dex file ] > 위 와 같이 간단히 명령어 를 입력 하 면 file _ dex 2 jar . jar 파일 이 같 은 디렉 토리 에 생 성 이 된다 . jar 파일 디 컴파일 툴 > jd - gui 를 이용 해서 jar 파일 을 열 어 본다 . > 소스 가 보이 는 것 을 확인 할 수 있 다 . 소스 분석 방법 은 보통 main 함수 부터 시작 하 지만 안드로이드 앱 은 브로드 캐스트 를 받 거나 서비스 되 는 부분 도 있 기 때문 에 분석 이 필요 한 곳 을 찾 아서 진행 하 면 된다 . apktool 을 이용 한 apk 디 컴파일 apktool : [ URL ] command : java - jar apktool _ 2 . 1 . 1 . jar d [ apk _ file ] [ result _ dir _ name ] apktool 에 d 옵션 decompile 옵션 을 통해 apk 디 컴파일 을 진행 한다 . 그리고 결과 파일 은 아래 와 같이 생성 된다 . 내부 리소스 가 풀리 고 , dex 파일 이 smali 디렉 토리 내부 에 디 컴파일 되 어 떨어지 게 된다 . * apktool 을 이용 한 apk 리 패 키 징 command : java - jar apktool _ 2 . 1 . 1 . jar b [ decompiled _ apk _ result _ dir _ name ] b 옵션 으로 리 패 키 징 ( build ) 가 가능 하 다 . 빌드 가 완료 되 면 디렉 토리 내 에 dist 폴더 에 apk 파일 이 생 성 이 된다 . 이렇게 생성 된 apk 는 sign 되 어 있 지 않 아 keystore 로 sign 후 에 설치 및 테스트 가 가능 하 다 . * 처음 보 는 apk 에 main activity 를 어떻게 찾 을까 ? main activity 를 찾 는 이유 는 일반 적 인 c / c ++ 에서 소스 를 분석 할 때 main 함수 부터 시작 해 나가 는데 안드로이드 에서 는 처음 실행 되 는 main activity 에 oncreate 함수 부터 시작 되 기 때문 이 다 . 그런데 main activity 는 개발자 마음대로 이름 을 변경 할 수 있 다 . 그러면 처음 실행 되 는 activity 를 어떻게 찾 는가 ? 모든 activity 는 androidmanifest . xml 에 등록 이 되 어 있 어야 사용 이 가능 하 다 . apktool 을 이용 하 여 디 컴파일 하 면 androidmanifest . xml 파일 도 같이 나온다 . 이 파일 에 부분 을 모두 찾 는다 . 그리고 해당 태그 하위 에 태그 에 런처 카테고리 태그 를 사용 한 액티비티 를 찾 으면 된다 . 해당 태그 가 있 다면 액티비티 태그 에 android : name 을 찾 는다 . 해당 name 이 처음 구동 되 는 activity name 이 다 . 출처 : [ URL ]',\n",
       "       '파이썬 파트 15 . 클래스 와 객체 지향 프로그래밍 자료 형 ( data type ) 자료 형 확인 및 검사 # type ( ) 함수 를 통한 자료 형 확인 >>> s = \\' hello \\' >>> type ( s ) < class \\' str \\'> # string 문자열 >>> f = 3 . 14 >>> type ( f ) # floating point 부동소수점 # isinstace ( ) 함수 를 통한 자료 형 검사 >>> isinstance ( 42 , int ) true 자료 형 종류 < class \\' list \\'> # 리스트 # 딕셔너리 # 튜플 # 정수 # 소수 인 스턴스 ( instance ) 의 이해 클래스 함수 나 변수 들 을 모아 놓 은 집합체 인 스턴스 클래스 에 의해 생성 된 객체 인 스턴스 각자 자신 의 값 을 가지 고 있 다 . list 1 = [ 1 , 2 , 3 ] list 2 = [ 1 , 2 , 3 ] if list 1 is list 1 : # 둘 이 같 은 인 스턴스 인지 확인 print ( \" 당연히 list 1 과 list 1 은 같 은 인 스턴스 입니다 . \" ) if list 1 == list 2 : # 둘 이 같 은 값 을 가지 는지 확인 print ( \" list 1 과 list 2 의 값 은 같 습니다 . \" ) if list 1 is list 2 : print ( \" 그리고 list 1 과 list 2 는 같 은 인 스턴스 입니다 . \" ) else : print ( \" 하 지만 list 1 과 list 2 는 다른 인 스턴스 입니다 . \" ) # 당연히 list 1 과 list 1 은 같 은 인 스턴스 입니다 . # list 1 과 list 2 의 값 은 같 습니다 . # 하 지만 list 1 과 list 2 는 다른 인 스턴스 입니다 . class 와 instance 의 개념 클래스 ( class ) 만들 기 클래스 와 인 스턴스 를 이용 하 면 데이터 와 코드 를 사람 이 이해 하 기 쉽 게 포장 할 수 있 다 . 클 래스 를 사용 하 는 이유 는 현실 의 개념 을 더 쉽 게 코드 에서 표현 하 기 위해서 이 다 . 클래스 선언 # 인간 클래스 작성 class human ( ) : \\'\\'\\' 사람 \\'\\'\\' 인 스턴스 생성 # human 클래스 의 인 스턴스 로 person 1 , person 2 생성 person 1 = human ( ) person 2 = human ( ) # 인간 클래스 의 인 스턴스 가 person 2 에 생긴다 . # 리스트 클래스 의 인 스턴스 를 만드 는 예 a = list ( ) isinstance ( a , list ) # true # 리스트 의 다양 한 기능 을 사용 할 수 있 었 던 건 리스트 에 이미 기능 들 이 구현 되 어 있 기 때문 이 다 . 클래스 의 특성 만들 기 예시 person 1 . language = \\' 한국어 \\' person 2 . language = \\' english \\' person 1 . name = \\' 서울 사람 \\' person 2 . name = \\' 인도 사람 \\' def speak ( person ) : print ( \\'{} 이 {} 로 말 을 합니다 \\' . format ( person . name , person . language ) ) human . speak = speak person 1 . speak ( ) # 서울 사람 이 한국어 로 말 을 합니다 person 2 . speak ( ) # 인도 사람 이 english 로 말 을 합니다 모델링 ( modeling ) 클래스 로 현실 의 개념 을 표현 하 는 것 class human ( ) : \\'\\'\\' 인간 클래스 \\'\\'\\' def create _ human ( name , weight ) : person = human ( ) person . name = name person . weight = weight return person human . create = create _ human person = human . create ( \\' 몽키 \\' , 50 ) def eat ( person ) : person . weight += 0 . 1 print ( \\'{} 가 먹 어서 {} kg 이 되 었 습니다 . \\' . format ( person . name , person . weight ) ) def walk ( person ) : person . weight -= 0 . 1 print ( \\'{} 가 걸어서 {} kg 이 되 었 습니다 . \\' . format ( person . name , person . weight ) ) human . eat = eat human . walk = walk person . walk ( ) person . eat ( ) person . walk ( ) 메소드 ( method ) 메소드 는 함수 와 비슷 하 다 . 클 래스 에 묶여서 클래스 의 인 스턴스 와 관계 되 는 일 을 하 는 함수 클래스 내부 에 함수 를 포함 시킨 예 class human ( ) : \\'\\'\\' 인간 \\'\\'\\' def create ( name , weight ) : # 다음 강의 에서 자세히 설명 person = human ( ) person . name = name person . weight = weight return person def eat ( self ) : # 메소드 의 첫 번 째 매개변수 이름 은 self 를 많이 사용 한다 . self . weight += 0 . 1 print ( \"{} 가 먹 어서 {} kg 이 되 었 습니다 \" . format ( self . name , self . weight ) ) def walk ( self ) : self . weight -= 0 . 1 print ( \"{} 가 걸어서 {} kg 이 되 었 습니다 \" . format ( self . name , self . weight ) ) person = human . create ( \" 철수 \" , 60 . 5 ) person . eat ( ) self 메소드 의 첫 번 째 인자 인 스턴스 의 매개변수 를 전달 할 때 는 self 매개변수 는 생략 하 고 전달 특수 한 메소드 초기 화 함수 __ init __ : 인 스턴스 를 만들 때 자동 으로 실행 되 는 함수 문자열 화 함수 __ str __ : 인 스턴스 자체 를 출력 할 때 의 형식 을 지정 해 주 는 함수',\n",
       "       '관심 답글 0 개 의 새로운 코멘트 가 있 습니다 . 더 보 기 현재 귀하 의 네트워크 와 아마존 파일 서버 ( 서울 ) 의 접속 이 원활 하 지 않 은 것 같 습니다 . 네트워크 관리 팀 혹은 isp 회사 ( 파워콤 , skb 등 ) 에 문의 해 보 시 는 것 도 좋 습니다 .',\n",
       "       '× 이 페이지 에 대한 피드백 을 남겨 주 세요 답장 받 을 이메일 주소 하 고 싶 은 말 ※ 피드백 은 저자 에게 e - 메일 로 전달 됩니다 .',\n",
       "       '목차 보 기 \" 점프 투 플라스크 \" 는 \" 파 이보 \" 라는 이름 의 파이썬 게시판 ( python board ) 서비스 를 만들 어 가 는 과정 을 설명 한 플라스크 입문서 이 다 . 파이썬 설치 부터 시작 하 여 서비스 운영 까지 웹 프로그래밍 의 처음 부터 끝 까지 모든 것 을 알 수 있 도록 구성 하 였 다 . 이 책 을 따라 하 다 보 면 다음 과 같 은 웹 사이트 가 만들 어 진다 . ( 최종 결과물 ) 파이썬 전반 에 대한 질문 과 답변 은 최근 오픈 한 파이썬 게시판 서비스 인 파 이보 를 활용 하 도록 하 자 . 책 을 따라 하 다 생기 는 질문 은 파 이보 의 완성 형 인 아래 사이트 를 활용 하 도록 하 자 .',\n",
       "       '목차 보 기 andrew ng 교수 님 coursera 강의 내용 정리 노트 입니다 . 본래 개인 적 으로 정리 하 는 것 이 목적 었 어서 강의 내용 을 모두 포함 하 지 는 않 으며 , 강의 에 없 는 내용 이 라도 필요 한 설명 은 보충 하 고 있 습니다 . 영어 강의 가 익숙 하 지 않 으신 분 들 께서 국문 보조 교재 로 참고 하 실 수 있 을 것 같 아서 공개 하 였 습니다 . tensorflow 로 딥 러닝 시스템 구현 을 원하 시 는 분 은 sung kim 교수 님 \" 모두 를 위한 딥 러닝 \" 강의 를 참고 하 셔도 좋 습니다 . 이 강의 를 본 노트 에 추가 하 는 계획 은 중단 되 었 습니다 . 대신 , pytorch 로 구현 하 는 방법 을 업데이트 하 고 있 습니다 . ( 2020 년 3 월 현재 ) 내용 상 오류 / 피드백 또는 질문 은 댓글 로 부탁 드립니다 . # 머신 러닝 # 기계 학습 # machinelearning # machine _ learning # python # tensorflow',\n",
       "       'gatsby 는 react 를 기반 으로 한 정적 사이트 생성기 ( jekyll ( ruby ) , hexo ( node . js ) , hugo ( go ) 등 이 있 다 . ) 이 며 , pwa , hot reloading , ssr 등 다양 한 기능 을 제공 한다 . 더 자세 한 내용 은 이 링크 에서 참고 할 수 있 다 . gatsby cli 와 gatsby 스타터 다운 받 기 $ npm i - g gatsby - cli $ gatsby new < > [ URL ] $ cd < > $ npm run dev 기본 구조 살펴보 기 프로젝트 는 다음 과 같 은 구조 로 이루어져 있 다 . src / ├ ── components │ ├ ── . .. # many of shared sections │ └ ── layout . jsx # general layout for page ├ ── constants ├ ── containers # to connect states to react component ├ ── html . jsx # page template for page ├ ── pages # pages of your web site │ ├ ── 404 . jsx │ └ ── index . js ├ ── postcomponents # react application that will be added in page │ └ ── . .. ├ ── resources # asset files │ └ ── images ├ ── store # to use redux │ ├ ── . .. │ └ ── index . js ├ ── templates # template for creating page with file system │ └ ── . .. └ ── utils # utilities └ ── . .. post 작성 하 기 $ mkdir src / pages / < > $ touch src / pages / < >/ index . md 이 마크 다운 파일 들 은 gatsby - source - filesystem 에 의해 불려 지 게 되 며 , gatsby - transformer - remark 에 의해 html 파일 로 변환 된다 . 이 들 은 빌드 타임 에 호출 되 며 , gatsby - node . js 의 createpages 를 참고 하 면 된다 . 주 의 사항 < >/ src / pages 경로 에 . sample . md 파일 이 있 는데 , 이 파일 을 지우 면 graphql 쿼리 의 frontmatter 프로 퍼티 의 category , images 등 을 가져올 수 없 다는 에러 가 발생 한다 . . sample . md 파일 은 더미 데이터 의 역할 을 하 여 frontmatter 의 필드 를 생성 한다고 보 면 된다 . 마크 다운 파일 의 기본 구성 요소 --- path : \"/ hello - world / \" category : \" sample \" tags : [\" tag \", \" should \", \" be \", \" array \"] title : \" hello , world ! \" date : \" 2018 - 08 - 15 t 00 : 00 : 00 . 000 z \" summary : \" you can create your own blog with gatsby ! \" --- content of this page path 는 페이지 를 생성 하 기 위해 반드시 필요 한 속성 으로 값 은 유일 한 값 을 가져야 한다 . 는 페이지 를 생성 하 기 위해 필요 한 속성 으로 값 은 유일 한 값 을 가져야 한다 . category 는 카테고리 페이지 를 생성 하 게 해 주 며 , / categories / < >/< > 와 같 은 페이지 에 접근 할 수 있 게 된다 . 는 카테고리 페이지 를 생성 하 게 해 주 며 , 와 같 은 페이지 에 접근 할 수 있 게 된다 . tags 는 태그 페이지 를 생성 하 게 해 주 며 , / tags / < >/< > 와 같 은 페이지 에 접근 할 수 있 게 된다 . 는 태그 페이지 를 생성 하 게 해 주 며 , 와 같 은 페이지 에 접근 할 수 있 게 된다 . title 는 페이지 의 제목 , summary 는 페이지 의 요약 된 내용 이 다 . 아래 이미지 에서 각각 빨간 줄 과 파란 줄 에 해당 된다 . 는 페이지 의 제목 , 는 페이지 의 요약 된 내용 이 다 . 아래 이미지 에서 각각 빨간 줄 과 파란 줄 에 해당 된다 . date 는 글 이 작성 된 날짜 로 포스트 들 은 이 값 을 기반 으로 정렬 된다 . ( 이 는 gray - matter 를 참고 하 면 더 자세 한 작동 원리 를 알 수 있 다 . ) 이 값 들 은 src / templates / post . jsx 의 query 에 의해 불려 지 게 되 며 , [ URL ] 에서 쿼리 를 직접 실행 해 볼 수 있 다 . 포스트 에 이미지 추가 하 기 images : [\"(< >) path _ to / image \"] [ URL ] 혹은 [ URL ] 를 포함 한 절대 경로 를 사용 하 거나 , src / resources 를 기준 으로 한 상대 경로 를 할당 해 준다 . ( components / post / index . jsx 의 145 번 째 줄 을 보 면 , if condition ? < > : \\'< >\\' 와 같이 이미지 를 불러온다 . ) 포스트 에 리 액트 애플리케이션 추가 하 기 --- path : \"/ inject - app / \" category : \" sample \" tags : [\" tag \", \" must \", \" be \", \" array \"] title : \" injecting react application \" date : \" 2018 - 08 - 15 t 00 : 00 : 00 . 000 z \" summary : \" you can inject react application into post \" components : [{ rootid : \\' sample - component \\', # < div id = \" sample - component \" > must be in contents filename : \\' sample \\', # this will render src / postcomponents / sample / index . jsx }] --- 1 . ... < div id = \" sample - component \" > 2 . ... 추가 할 리 액트 애플리케이션 의 파일 의 경로 와 , 렌 더 될 태그 의 id 값 을 포함 한 객체 를 배열 안 에 넣 어 준다 . 그리고 글 중간 에 리 액트 애플리케이션 을 삽입 하 고 싶 은 곳 에 이 id 를 가진 태그 를 추가 해 준다 . 포스트 에 트윗 추가 하 기 --- path : \"/ inject - tweet / \" category : \" sample \" tags : [\" tag \", \" must \", \" be \", \" array \"] title : \" injecting tweet \" date : \" 2018 - 08 - 15 t 00 : 00 : 00 . 000 z \" summary : \" you can inject tweet into post \" tweets : [{ rootid : \\' sample - tweet \\', # < div id = \" sample - tweet \" > must be in contents userid : \\' twitter \\', # twitter user id tweetid : \\' 977557540199456775 \\', # tweet id }] --- 1 . ... < div id = \" sample - tweet \" > 2 . ... 추가 할 트윗 을 작성 한 사람 과 해당 트윗 의 id , 그리고 렌 더 될 태그 의 id 값 을 포함 한 객체 를 배열 안 에 넣 어 준다 . 그리고 리 액트 애플리케이션 을 삽입 했 던 것 처럼 사용 하 면 된다 . 포스트 에 코드 추가 하 기 하이 라이팅 을 하 고자 하 는 코드 의 앞 뒤 로 ` 를 연달 아 3 개 를 붙여 넣 어 주 면 , gatsby - remark - prismjs 에 의해 하이 라이팅 이 된다 . 포트폴리오 추가 하 기 $ mkdir src / resources / < > $ touch src / resources / < >/ index . md --- type : \" portfolio \" title : \" gatsby advanced blog \" date : \" 2018 - 08 - 15 t 00 : 00 : 00 . 000 z \" path : \"/ portfolios / portfolio - 1 / \" images : [ \" test - 1 / 1 . png \", \" test - 1 / 2 . png \", ] --- # gatsby advanced blog ## what i did - develop gatsby advanced blog ## libraries / tools - reactjs - redux - redux saga - . .. [ go to web site →]([ URL ] path 는 페이지 를 생성 하 기 위해 반드시 필요 한 속성 으로 값 은 유일 한 값 을 가져야 한다 . 는 페이지 를 생성 하 기 위해 필요 한 속성 으로 값 은 유일 한 값 을 가져야 한다 . type 은 페이지 의 형식 을 지정 할 수 있 는 값 으로 여기 에서 는 portfolio 라고 할당 한다 . 은 페이지 의 형식 을 지정 할 수 있 는 값 으로 여기 에서 는 라고 할당 한다 . title 는 포트폴리오 의 제목 이 다 . 는 포트폴리오 의 제목 이 다 . images 는 포트폴리오 에 첨부 하 고자 하 는 이미지 들 로 , 포스트 와 같 은 형태 의 값 을 가진다 . 이미지 는 배열 에 추가 된 순서 로 렌더링 이 된다 . 는 포트폴리오 에 첨부 하 고자 하 는 이미지 들 로 , 포스트 와 같 은 형태 의 값 을 가진다 . 이미지 는 배열 에 추가 된 순서 로 렌더링 이 된다 . 포트폴리오 들 은 data 값 을 기반 으로 정렬 된다 . 우선 적 으로 보여 줄 포트폴리오 에 큰 값 을 준다 . 포트폴리오 는 포트 폴 레오 페이지 에서 보여 지 게 되 며 , 포트폴리오 가 4 개 이상 일 경우 홈페이지 메인 에서 도 보여 지 게 된다 . ( src / components / home 에서 확인 할 수 있 으며 , 어떻게 렌더링 할 지 는 수정 하 면 된다 . ) resume 추가 하 기 --- type : \" resume \" title : \" resume \" date : \" 2000 - 01 - 01 t 00 : 00 : 00 . 000 z \" path : \"/ resume / \" --- ## experience - engineer at ooo ∙ 2000 . 01 ~ present - develop something - maintain something ## education - b . s . in computer science engineering at ooo - 2000 . 01 ~ 2000 . 01 ## projects - gatsby advanced blog ( [ URL ] ∙ 2000 . 01 ~ present - integrate redux - use redux , redux saga , reselect . .. ## skills - javascript - es 2015 + - reactjs - lodash - css - sass - less path 는 페이지 를 생성 하 기 위해 반드시 필요 한 속성 으로 값 은 유일 한 값 을 가져야 한다 . 는 페이지 를 생성 하 기 위해 필요 한 속성 으로 값 은 유일 한 값 을 가져야 한다 . type 은 페이지 의 형식 을 지정 할 수 있 는 값 으로 여기 에서 는 resume 라고 할당 한다 . 기타 기능 gnb 의 오른쪽 에선 포스트 의 제목 , 요약 된 내용 , 태그 , 카테고리 등 으로 검색 을 할 수 있 다 . 코드 를 추가 하 면 , 코드 를 복사 할 수 있 는 버튼 이 자동 으로 생성 된다 . 배포',\n",
       "       'baekjoon online judge 프로그래밍 문제 를 풀 고 온라인 으로 채점 받 을 수 있 는 곳 입니다 .',\n",
       "       '코로나 19 가 사기 라고 믿 었 던 남성 이 부인 을 코로나 로 잃 었 다 사진 출처 , facebook 사진 설명 , 브라이언 과 이달 세상 을 떠난 그 의 아내 에린 신종 코로나 바이러스 감염증 ( 코로나 19 ) 이 사기 라는 잘못 된 주장 을 믿 었 던 플로리다 의 택시 기사 가 코로나 19 로 부인 을 잃 었 다 . 브라이언 리 히 친 슨 과 에린 은 코로나 19 가 조작 된 것 으로 5 g 무선 통신 과 관련 있 거나 그냥 독감 과 비슷 하 다는 주장 을 온라인 에서 읽 었 다 . 부부 는 코로나 19 예방 을 위한 보건 지침 도 따르 지 않 았 고 , 5 월 초 증상 이 생겼 을 때 도 도움 을 요청 하 지 않 았 다 . 브라이언 은 회복 됐 지만 46 세 의 부인 은 중태 에 빠졌 고 , 이달 코로나 19 로 인한 심장 합병증 으로 사망 했 다 . 브라이언 은 지난 7 월 코로나 19 관련 거짓 정보 의 피해 에 대한 bbc 탐사 보도 의 일환 으로 bbc 와 인터뷰 했 다 . 당시 그 의 부인 은 병원 에서 인공호흡 장치 의 도움 을 받 고 있 었 다 . 인명 을 앗 아 간 음모론 브라이언 은 자신 과 아내 가 코로나 19 에 대해 어떤 확연 한 생각 을 갖 고 있 던 건 아니 었 다고 말 했 다 . 부부 는 코로나 19 가 5 g 무선 통신 기술 과 연관 된 사기 라고 생각 했 다가 , 진짜로 있 긴 하 지만 심각 하 진 않 은 병 이 라고 생각 했 다 . 부부 는 페이스북 에서 그런 이야기 들 을 접했 다 . 사진 출처 , facebook 사진 설명 , 부부 는 페이스북 에서 코로나 19 가 가짜 라는 음모론 을 접했 다고 한다 “ 우린 정부 가 코로나 19 를 사용 해서 우릴 혼란 스럽 게 만든다고 생각 했 어요 . 아님 5 g 와 관련 이 있 거나 요 . ” 그러나 부부 가 5 월 에 몸져 누운 후 브라이언 은 페이스북 에 자신 이 코로나 19 에 대해 온라인 에서 읽 은 것 들 로 실상 을 잘못 알 게 됐 다고 썼 다 . “ 바깥 에 나가 게 되 면 제발 지혜 롭 게 행동 하 시 고 저 처럼 바보 같이 행동 해서 저 와 제 아내 에게 일어난 일 이 당신 에게 도 일어나 는 일 이 없 길 바랍니다 . ” 그 는 널리 공유 된 글 에서 이렇게 썼 다 . bbc 의 탐사 보도 팀 은 지난 5 월 코로나 19 에 대한 거짓 정보 가 폭행 , 방화 , 사망 사건 에 도 연루 됐 음 을 발견 했 다 . 의사 를 비롯 한 전문가 들 은 온라인 에서 나도 는 소문 이나 음모론 , 잘 못 된 건강 정보 가 간접 적 으로 해 를 끼칠 수 있 음 을 경고 해 왔 다 . 특히 sns 에서 유포 되 는 백신 반대 음모 론 의 해로움 에 대한 지적 이 많 았 다 . sns 업체 들 도 자사 의 플랫폼 에서 유포 되 는 거짓 정보 를 막 기 위해 여러 가지 시도 를 하 고 있 지만 비판 론 자 들 은 더 많 은 노력 이 필요 하 다고 주장 한다 .',\n",
       "       '걱정 이 그렇게 나쁘 지만은 않 은 이유 사진 출처 , getty images 사진 설명 , 어떤 경우 에 는 걱정 이 커다란 혜택 을 주 기 도 한다 케이트 스위니 는 자신 을 \" 프로 걱정 러 \" 라고 말 했 다 . 자신 이 통제 할 수 없 는 것 들 을 걱정 하 느라 큰 손해 를 본다고 했 다 . 신종 코로나 바이러스 감염증 ( 코로나 19 ) 확산 중 에 부모 가 사회 적 거리 두기 를 잘 하 고 있 는지 에 대해 노심 초사 하 는 것 을 예 로 들 었 다 . 많 은 사람 이 자잘 한 걱정거리 로 골머리 를 앓 는다 . 하지만 스위니 에게 는 걱정 이 진로 선택 의 동기 가 됐 다 . 걱정 이 많 던 그 는 미국 캘리포니아 리버사이드 대학 에서 걱정 과 스트레스 를 연구 하 는 심리학자 가 됐 다 . 그 는 \" 모든 사람 이 자신 의 삶 을 연구 발판 으로 삼 는 건 아니 다 \" 라며 웃 었 다 . 하지만 그 는 자신 의 경험 에서 영감 을 얻 었 고 , 시험 이나 건강 관리 등 다양 한 상황 에서 걱정 도 유익 할 수 있 다는 점 을 발견 했 다 . 다양 한 걱정 들 걱정 은 부정 적 인 뜻 과 중립 적 인 뜻 을 가지 고 있 다 . 기후 변화 를 연구 하 는 심리학자 들 은 걱정 을 위험 요소 를 줄이 기 위해 어떤 행동 을 끌어내 는 감정 상태 라고 묘사 한다 . 반면 미래 에 대해 불쾌 한 감정 이 쉽 게 사라지 지 않 는 것 으로 규정 하 는 심리학자 들 도 있 다 . 분명 걱정 은 여러 해 로운 점 을 가지 고 있 다 . 어떤 학자 들 은 걱정 은 \" 제한 된 틀 안 에 가두 는 특징 \" 이 있 어서 , 하나 를 걱정 하 면 다른 것 들 을 생각 하 지 못 하 는 경우 가 있 다고 말 하 기 도 한다 . 사진 출처 , getty images 사진 설명 , 호주 산불 에 대한 건설 적 인 걱정 은 화재 가 발생 시 행동 방안 을 만들 게 해준다 과 한 걱정 은 정신 과 육체 에 악영향 을 준다 . 걱정 때문 에 수면 장애 를 경험 하 거나 \\' 혹시 암 이 면 어떡 하 지 ? \\' 라는 생각 에 검진 을 회피 하 는 것 또한 걱정 때문 이 다 . 걱정 으로 인해 여러 가지 문제 가 생길 수 있 다 . 무슨 일 만 있 으면 자동 으로 극단 적 인 상황 을 떠올려 걱정 하 는 것 은 불안 장애 와 관련 있 다 . 엑 시터 대학 의 임상 심리학자 인 에드워드 왓킨스 는 \" 하나 의 주제 에 초점 을 맞춘 걱정 보다 여러 다른 것 들 을 걱정 하 는 것 이 더욱 해로울 수 있 다 \" 고 말 했 다 . 그러나 유익 한 결과 를 가져오 는 걱정 도 있 다 . 산불 이 빈번 한 호주 의 한 주 에서 는 건설 적 인 걱정 이 산불 대비 를 유도 시켰 다 . 학업 성적 에 대해 걱정 을 많이 하 는 사람 이 금연 시도 를 더 많이 한다는 연구 도 있 다 . 그리고 기후 변화 에 대한 우려 가 기후 정책 지지 를 예측 할 수 있 는 가장 강력 한 변수 라는 연구 결과 도 있 다 . 걱정 은 미래 에 보 고 하 는 것 이 기 때문 에 , 행동 변화 를 끌어낼 잠재력 이 있 다 . 왓킨스 는 이 를 세 가지 로 설명 했 다 . \" 어떤 것 을 걱정 하 면 , 이 에 대처 하 기 위해 특정 한 행동 이 필요 하 다는 동기 부여 가 생길 수 있 어요 . 그리고 걱정 스러운 문제 가 해결 될 때 까지 그것 에 대응 해야 한다고 계속 생각 하 게 되 죠 . 또 걱정 하 다 보 면 , 효과 적 인 대비책 을 찾 아서 문제 를 해결 할 수 도 있 습니다 . \" 사진 출처 , getty images 사진 설명 , \\' 기후 변화 에 대한 개인 의 우려 정도 \\' 는 기후 정책 에 대한 지지 여부 를 예측 하 는 가장 강력 한 변수 가 된다 왓킨스 는 스트레스 와 성과 의 관계 처럼 , 걱정 과 무 기력 도 \\' u 자 \\' 형태 의 상관 관계 를 보인다고 말 했 다 . 걱정 이 너무 적 으면 , 동기 부여 가 되 지 않 는다 . 반면 걱정 이 너무 많 으면 , 무기력 해져서 아무것 도 하 지 못한다는 것 이 다 . 기후 위기 를 예 로 들 어 보 자 . 기후 위기 에 대해 극도 로 비관 적 인 우려 는 \\' 이제 다 틀렸 다 \\' 는 듯 무기력 한 반응 을 낳 을 수 있 다 . 반면 심각 성 에 공감 하 는 정도 의 걱정 이 라면 , 기후 변화 를 막 기 위해 행동 할 것 이 다 . 스위니 는 걱정 에 도 기능 이 있 다고 말 했 다 . \" 걱정 은 신호 입니다 . 우리 에게 다가올 수 있 는 어떤 것 에 관해 관심 을 주 게 만드 는 것 이 죠 . 나쁜 일 이 일어나 는 것 을 막 거나 , 최소한 대비 하 게끔 해 주 는 것 입니다 . \" 코로나 19 팬데 믹 초기 에 나온 한 연구 에서 도 이러 한 점 이 확인 됐 다 . 연 구진 은 사람 들 이 코로나 19 에 대해 걱정 하 는 정도 를 평가 해서 , \\' 위험 에 대한 감정 적 인식 지표 \\' 로 삼 았 다 . 연구 결과 , 바이러스 에 감염 된 적 이 있 거나 이타 적 인 행동 에 가치 를 두 는 이 들 이 코로나 19 걱정 을 더 많이 했 다 . 그리고 더 많이 걱정 할수록 , 손 씻기 나 마스크 착용 , 사회 적 거리 두 기 준 수 같 은 예방 적 행동 을 더 적극 적 으로 하 는 것 으로 나타났 다 . 걱정 을 잘 하 기 위한 절차 코로나 19 에서 힘든 것 중 하나 는 불 확실 성 이 다 . 건설 적 인 걱정 은 자신 이 걱정 하 는 대상 에 정해진 시간 이 있 는 경우 에 더 쉽 게 나타난다 . 예 를 들 어 스위니 는 2016 년 미국 대선 을 보 고 굉장히 걱정 스러워졌 다 . 그래서 2 년 후 중간 선거 를 앞두 고 , 사람 들 에게 투표 를 독려 하 기 위해 500 장 이 넘 는 엽서 를 보내 며 자신 의 걱정 을 달랬 다 . 사진 출처 , getty images 사진 설명 , 마음속 불편 함 의 원인 을 해결 하 려는 조치 로 이어질 때 는 걱정 도 이 점 을 지니 게 된다 스위니 가 했 던 것 은 부정 적 인 결과 가 예상 되 는 상황 에서 평 정심 을 유지 하 려는 노력 이 었 다 . 걱정 했 던 일 이 다가올 때 도 최대한 긍정 적 인 감정 상태 를 유지 하 려 한다면 , 실제로 그 일 이 벌어진다 해도 보다 쉽 게 받아들일 수 있 다는 것 이 다 . 물론 많 은 사람 은 나름 의 이유 를 가지 고 자신 이 통제 할 수 없 는 것 들 을 걱정 한다 . 하지만 이런 상황 에서 걱정 해 봐야 더 할 수 있 는 게 없 다는 걸 이해 하 면 , 걱정 을 줄이 는 데 도움 을 줄 수 있 다 . 스위니 는 이 를 3 가지 단계 로 설명 한다 . 걱정 에 \\' 무엇 에 대한 걱정 인지 \\' 꼬리표 를 붙여라 문제 를 해결 하 기 위해 할 수 있 는 행동 을 정리 하 라 만약 할 수 있 는 조치 를 다 했 다면 , \\' 몰입 \\' 이나 \\' 명상 \\' 등 의 심리 상태 를 조절 하 기 위한 노력 을 해라 스위니 는 다른 일 에 몰입 하 는 것 이 코로나 19 스트레스 극복 에 특히 유용 했 다고 말 했 다 . 스위니 와 동료 연구 진 은 격리 되 지 않 은 중국인 들 의 심리 적 건강 상태 에 대한 기초 적 인 연구 를 수행 했 다 . 그 결과 집중 은 외로움 을 줄이 고 건강 에 도움 이 되 는 행동 들 과 관련 이 높 게 나타났 다 . 명상 도 정신 건강 에 많 은 혜택 을 주 지만 , 중국 에서 나온 연구 에 따르 면 명상 은 외로움 이나 건강 에 도움 이 덜한 행동 과 관련 이 높 다고 한다 . 이 를 두 고 스위니 는 뭔가 에 집중 하 면 시간 이 빨리 흘러간다고 느끼 게 하 지만 , 명상 은 지속 적 인 불 확실 성 을 주목 하 게 만드 는 것 이 아닌가 추정 했 다 . 명상 은 걱정거리 가 짧 게 지속 하 는 상황 에서 유용 하 다 . 반면 집중 은 걱정 의 끝 이 보이 지 않 는 상황 에 대한 적응력 을 높여 준다 . 사진 출처 , getty images 사진 설명 , 2016 년 선거 때 스위니 는 사람 들 에게 투표 를 독려 하 는 엽서 를 쓰 게 했 다 왓킨스 는 \" 기존 연구 에 따르 면 코로나 19 에 대한 적절 한 걱정 은 사회 적 거리 두기 에 대한 이해 와 준수 로 이어질 수 있 다 \" 고 말 했 다 . \" 반면 지나친 걱정 이나 우려 는 효과 적 인 조처 를 하 기 어렵 게 만들 수 도 있 습니다 . \" 예 를 들 어 , 봉쇄 령 이 끝 나 일터 로 돌아가 는 것 이 걱정 된다면 , 위험 요소 를 마냥 걱정 할 것 이 아니 라 통근 시 사회 적 거리 를 유지 하 고 위험 을 줄일 수 있 는 구체 적 인 계획 을 세워야 한다는 거 다 . 왓킨스 는 \" 전자 는 더 큰 공포 를 불러올 것 이 고 , 후자 는 더 많 은 준비 와 상황 에 대한 통제 를 가능 하 게 할 것 \" 이라고 말 했 다 . 스위니 의 경험 을 예 로 들 면 , 그 는 봉쇄 기간 동안 대부분 신중 한 낙관 론 을 가졌 다 . 그러 면서 도 일 주일 에 한 번 정도 는 상황 이 악화 될 가능 성 은 없 는지 따져 봤 다 . 걱정 의 수위 를 조절 한 것 이 다 . \\' 바바 둑 ( the babadook ) \\' 이 라는 공포 영화 가 있 다 . 이 영화 에 는 육체 를 갖 게 된 커다란 슬픔 이 괴물 로 등장 한다 . 대부분 의 공포 영화 와 달리 주인공 은 바바 둑 을 해칠 수 없 고 , 해쳐서 도 안 된다는 것 을 깨닫 게 된다 . 바바 둑 자체 가 주인공 이 잃어버린 가족 을 애 도 하 고 기억 하 게 해 주 는 매개 이 기 때문 이 다 . 그렇 다고 마냥 슬픔 에 좌우 되 는 것 도 좋 지 않 다 . 결국 영화 속 주인공 은 이 괴물 과 불안 한 균형 을 갖 고 살아간다 .',\n",
       "       '코로나 19 : \\' 세컨드 웨이브 \\' 란 무엇 인가 ? 정말 다가오 고 있 나 ? 사진 출처 , getty images 코로나 19 사태 가 끝나 려면 아직 멀 었 다 . 몇몇 나라 는 여전히 대 규모 전염 과 싸우 고 있 고 바이러스 를 어느 정도 통제 하 고 있 는 나라 들 도 \\' 세컨드 웨이브 \\' 를 우려 하 고 있 다 . 100 여 년 전 스페인 독감 당시 에 는 처음 발병 사태 때 보다 세컨드 웨이브 가 더 치명 적 이 었 다 . 세컨드 웨이브 는 피할 수 없 는 것 일까 ? 그렇 다면 얼마나 심각 해질 수 있 는 걸까 ? 먼저 , 세컨드 웨이브 란 무엇 인가 ? 바다 의 파도 를 떠올려 보 자 . 확진 자 의 수 는 오르내리 기 를 반복 하 는데 하나 의 주기 를 코로나 바이러스 의 \\' 웨이브 \\' 라 할 수 있 다 . 세컨드 웨이브 에 대한 공식 적 인 정의 가 있 는 건 아니 다 . \" 완전히 과학 적 인 개념 은 아니 에요 . 웨이브 하나 를 어떻게 정의 하 느냐는 자의 적 입니다 . \" 워윅 대학교 의 마이크 틸 드 슬리 박사 는 bbc 에 말 했 다 . 사진 출처 , getty images 어떤 이 는 확진 자 수 가 증가 하 면 무조건 세컨드 웨이 브라 말 하 지만 보통 은 퍼스트 웨이브 가 좀 굴곡 이 있 는 경우 다 . 현재 미국 의 몇몇 주 에서 발생 하 는 상황 이 이렇 다 . 한 웨이브 가 끝 났 다고 하 려면 바이러스 가 통제 가 되 고 확진 자 의 수 가 현저히 떨어져야 한다 . 세컨드 웨이브 가 시작 되 는 것 은 신규 감염 이 꾸준히 증가 할 때 다 . 24 일 간 확진 자 가 하나 도 안 나오 다가 첫 확진 자 가 나온 뉴질랜드 나 50 일 째 감염 이 없 었 다가 다시 확진 자 발생 이 시작 된 중국 은 아직 이런 상황 이 아니 다 . 그러나 몇몇 과학자 들 은 이란 의 현재 상황 이 세컨드 웨이브 와 유사 하 다고 주장 한다 . 세컨드 웨이브 는 무엇 으로 촉발 되 나 ? 봉쇄 를 너무 과하 게 해제 하 는 것 이 원인 이 될 수 있 다 . 봉쇄 는 전 세계 적 으로 큰 피해 를 입혔 다 . 직업 도 줄 었 고 사람 들 의 건강 과 어린이 들 의 교육 에 도 영향 을 미치 지만 바이러스 를 통제 할 수 는 있 었 다 . \" 궁극 의 문제 는 일상 의 혼란 을 최소 화 하 면서 어떻게 통제 를 유지 하 느냐 죠 . \" 런던 위 생 열 대 의학 대학원 의 애덤 쿠차 스키 는 말 한다 . 봉쇄 를 얼마나 해제 할 수 있 는가 를 확신 할 수 있 는 사람 은 없 다 . 때문 에 봉쇄 가 단계 적 으로 해제 되 고 있 는 것 이 며 접촉 추적 앱 이나 마스크 같 은 바이러스 통제 의 기법 들 이 도입 되 고 있 는 것 이 다 . 사진 출처 , getty images 사진 설명 , 영국 내 봉쇄 에 일부 해제 되 면서 노 위치 에서 는 사람 들 이 쇼핑 을 즐기 고 있 다 \" 영국 과 인접 국가 에서 는 전염 이 통제 가능 한 시점 이상 으로 봉쇄 가 해제 될 경우 전염병 의 재발 이 매우 빨리 일어날 수 있 습니다 . \" 쿠차 스키 박사 는 말 한다 . 도축장 에서 발생 한 전염 으로 650 명 이 확진 판정 을 받 은 독일 에서 는 이미 시작 된 상황 이 다 . 집단 감염 을 빠르 게 파악 하 고 해당 지역 을 봉쇄 해 바이러스 의 전파 를 막 을 수 있 다면 심각 한 문제 는 아니 다 . 그러나 그렇 지 못하 면 세컨드 웨이브 로 이어질 수 있 다 . 코로나 19 에 대한 대처 로 많 은 찬사 를 받 았 던 한국 은 그런 집단 감염 발생 으로 인해 해제 했 던 일부 조치 를 다시 도입 해야 했 다 . 세컨드 웨이브 가 처음 창궐 사태 와 똑같이 진행 될까 ? 만일 그렇게 되 면 정말 심각 한 상황 이 될 것 이 다 . 코로나 19 팬데 믹 이 시작 됐 을 때 의 r 값 ( 각각 의 확진 자 가 감염 시키 는 다른 사람 들 의 수 의 평균 ) 은 3 이 었 다 . 이 는 바이러스 가 빠르 게 전염 되 고 있 었 음 을 의미 한다 . 그러나 우리 의 행동 양식 이 바뀌 었 고 사회 적 거리 두 기 도 실천 하 고 있 기 때문 에 r 값 이 다시 그만큼 높 아 지 기 란 어렵 다 . 쿠차 스키 박사 는 말 했 다 . \" 어떤 나라 도 모든 조치 를 다 해제 하 고 예전 으로 돌아가 진 않 습니다 . \" \" 코로나 바이러스 통제 가 안 되 고 있 는 브라질 이나 인도 에서 도 r 값 은 3 . 0 이 못 돼요 . \" 확진 자 수 가 다시 증가 한다 하 더라도 그 속도 는 상대 적 으로 느릴 것 이 다 . 그러나 이론 적 으로 세컨드 웨이브 는 첫 창궐 때 보다 더 많 은 사람 들 을 감염 시킬 수 있 다 . 많 은 사람 들 이 여전히 취약 하 기 때문 이 다 . \" 하지만 만일 확진 자 수 가 다시 증가 하 면 세컨드 웨이브 를 막 기 위해 봉쇄 를 다시 시작 할 수 있 습니다 . 언제나 가능 한 옵션 이 죠 . \" 틸 드 슬리 박사 는 말 한다 . 세컨드 웨이브 는 언제 발생 할까 ? 겨울 이 면 더 심해질까 ? 쿠차 스키 박사 는 봉쇄 조치 가 해제 되 고 있 어 바로 다음 주 나 다음 달 에 도 지역 단위 로 감염 이 재발 할 수 있 다고 말 한다 . 그러나 이것 이 세컨드 웨이브 가 반드시 온다는 걸 의미 하 진 않 는다 . 틸 드 슬리 박사 는 이렇게 말 한다 . \" 봉쇄 조치 가 상당히 완화 되 면 8 월 말 이나 9 월 초 에 세컨드 웨이브 가 올 수 있 죠 . \" 다른 종류 의 코로나 바이러스 가 겨울 에 더 잘 전염 되 기 때문 에 겨울 이 중대 한 고비 가 될 수 있 다 . 바이러스 를 겨우 통제 하 고 있 는 상황 이 라면 작 은 계절 적 요인 하나 로 도 전염 확산 으로 이어질 수 있 다 . \" 계절 이 봄 이 라 다행 이 었 죠 . \" 노팅엄 대학교 조너선 볼 바이러스학 교수 는 말 한다 . \" 세컨드 웨이브 는 거의 피할 수 없 습니다 . 앞 으로 겨울 이 오 기 때문 에 특히 그래요 . \" \" 정부 의 숙제 는 확진 자 수 의 정점 이 의료 체계 를 마비 시킬 정도 가 되 지 않 도록 하 는 것 입니다 . \" 바이러스 가 약해져서 문제 가 안 될 수 도 있 을까 ? 세컨드 웨이브 가 치명 적 이 지 않 으리라는 반론 의 근거 로 는 바이러스 가 보다 사람 들 에게 잘 전염 되 기 위해 치명 성 이 떨어지 게 된다는 게 있 다 . 에이즈 를 유발 하 는 hiv 조차 도 점차 약해 지 는 것 으로 보인다 . 바이러스 가 숙주 를 죽이 지 않 을 정도 로 약해 지 면 더 잘 전파 된다는 게 이 이론 의 핵심 이 다 . \" 하지만 그건 늘 보장 되 는 게 아니 에요 . 바이러스 연구자 들 이 내놓 는 게으른 변명 이 라 할 수 있 습니다 . \" 볼 교수 는 말 한다 .',\n",
       "       '\\' 재택근무 의 일상 화 \\'... 코로나 19 가 바꿀 사무실 의 미래 신종 코로나 바이러스 감염증 ( 코로나 19 ) 도 진정 되 는 날 이 올 것 이 다 . 종식 될 수 도 있 다 . 하지만 우리 의 삶 이 코로나 19 이전 으로 돌아갈 수 있 을지 는 모르 겠 다 . 코로나 19 사태 로 건축가 들 은 우리 가 사 는 건물 에 대해 다시 생각 하 고 있 다 . 미래 의 모습 은 어떨까 ? 밑 으로 스크롤 해 보 자 . 애니메이션 켜 기 레일라 를 소개 한다 . 2025 년 , 레일라 는 주 4 회 집 에서 일 한다 . 재택근무 가 일상 이 된 건 2020 년 봉쇄 조치 이후 부터 다 . 출근 하 는 날 이 면 , 레일라 는 오전 6 시 30 분 에 집 을 나선다 . 오전 7 시 , 회사 에 도착 한 레일라 . 출근 인원 을 분산 시키 기 위해 근무자 마다 출근 시간 이 조금 씩 다르 다 . 출근 날 은 주로 회의 가 많 다 . 다른 업무 는 굳이 회사 에서 하 지 않 아도 할 수 있 기 때문 이 다 . 레일라 회사 의 사무실 은 여러 회사 가 입주 한 큰 건물 안 에 있 었 다 . 지금 은 사무실 규모 를 줄여 작 은 건물 을 단독 으로 사용 하 고 있 다 . 회사 건물 1 층 에 는 열 스캐너 가 자리 잡 고 있 다 . 36 . 5 도 . 정상 체온 이 다 . 그 옆 에 는 얼굴 인식 카메라 가 있 다 . 카메라 가 레일라 를 직원 으로 인식 하 자 , 회사 출입문 이 열렸 다 . 그 가 손 으로 직접 작동 해야 하 는 건 없 다 . 모든 것 이 비대 면 으로 진행 된다 . \" 4 층 이요 . \" 우리 에게 익숙 한 엘리베이터 버튼 이 사라졌 다 . 음성 으로 목적지 를 인지 한다 . 엘레 베 이터 는 최대 2 인 까지 만 탈 수 있 다 . 4 층 에서 복도 를 따라 내려가 문 을 통과 하 면 사무실 이 나온다 . 예전 보다 복도 가 넓 어 져 직원 들 간 일정 거리 를 유지 하 는 것 이 더 수월 해졌 다 . 바이러스 가 건물 내 에서 전파 할 가능 성 을 줄이 기 위한 설계 다 . 들어가 기 전 문 앞 에 있 는 손 소독 제 를 사용 하 는 것 은 이제 습관 이 됐 다 . 책상 에 앉 은 레일라 . 책상 패널 을 포함 해 대부분 의 가구 는 항균 기능 이 있 는 소재 로 만들 어 졌 다 . 청소 도 쉽 고 항균 기능 이 뛰어나 기 때문 이 다 . 그 는 커피 를 타 기 위해 부엌 으로 향한다 . 부엌 가구 의 손잡이 는 구리 로 돼 있 다 . 구리 는 가격 이 비싸 지만 , 자연 적 으로 바이러스 의 확산 을 억제 하 는 효과 가 있 기 때문 이 다 . 회사 내 냉방 시스템 은 균 과 바이러스 를 박멸 하 기 위해 자외선 을 사용 한다 . 또 세균 이 번식 하 는 것 을 억제 하 기 위해 건물 주변 에 고정 된 센서 와 웨어 러블 센서 를 활용 해 일정 습도 를 유지 한다 . 전 에 는 개방 형 사무실 이 었 지만 , 코로나 19 사태 이후 사무실 설계 도 바뀌 었 다 . 그래도 책상 의 왼편 칸막이 는 투명 한 플라스틱 으로 제작 돼 동료 들 의 얼굴 을 볼 수 있 다 . 칸막이 는 바닥 에 고정 돼 있 지만 , 위쪽 은 분리 가 가능 하 다 . 발병 위험 이 높 으면 칸막이 가 올라가 고 , 위험 이 가라앉 으면 뗄 수 있 는 구조 다 . 레일라 의 책상 앞 에 는 여러 식물 이 있 다 . 여기저기 설치 된 플라스틱 칸막이 에 싫증 을 느낀 직원 들 의 고충 이 반영 됐 다 . 식물 이 없 었 을 땐 , 사무실 이 마치 병원 같 았 다 . 레일라 는 식물 이 좋 다 . 오전 은 새 프로젝트 에 대해 회의 를 하 며 보냈 다 . 동료 들 과 직접 대면 하 는 회의 였 지만 , 서로 사회 적 거리 를 두 고 진행 했 다 . 이런 회의 때문 에 레일라 는 주 1 회 회사 에 직접 출근 한다 . 온라인 으로 하 는 것 보다 직접 만나 서 회의 했 을 때 더 좋 은 결과 가 나오 기 때문 이 다 . 벌써 오후 4 시 다 . 퇴근 할 시간 이 다 . 2020 년 봉쇄 이후 레일 라는 친구 와 함께 도시 외곽 으로 이사 했 다 . 출퇴근 길 이 길 어 졌 지만 , 일 주일 에 한 번 뿐 이 라 개의 치 않 는다 . 집 이 넓 어 졌 다 . 레일라 의 개인 공간 도 넓 어 졌 다는 뜻 이 다 . 처음 에 봉쇄 령 이 내려졌 을 때 , 재택근무 가 몇 주간 지속 할 것 이 라 생각 했 다 . 부엌 식탁 과 노트북 만 있 으면 할 수 있 겠 지 생각 했 던 때 다 . 하지만 몇 주 는 몇 달 이 됐 고 , 몇 달 은 몇 년 이 됐 다 . 분리 된 사무실 공간 이 필요 하 다는 것 을 느꼈 지만 , 전 에 살 던 아파트 는 너무 작 았 다 . 레일라 는 새로 이사 한 집 2 층 침실 한 켠 에 사무실 공간 을 마련 했 다 . 높이 를 조절 할 수 있 는 책상 과 의자 를 장만 했 고 , 업무 문서 를 보관 할 수 있 는 서랍 도 샀 다 . 전 에 는 몰랐 던 조명 의 중요 성 도 느꼈 다 . 천장 에 핀 조명 을 설치 하 고 좋 은 책상 램프 도 하나 장 만 했 다 . 레일라 는 요즘 이중창 을 설치 하 기 위해 돈 을 모으 고 있 다 . 지금 집 이 도로변 에 있 어 바깥 소음 에 집중 이 깨 질 때 가 종종 있 기 때문 이 다 . 전 에 는 소음 문제 때문 에 돈 을 쓸 것 이 라고 상상 도 못 했 다 . 다락방 증축 과 정원 에 따로 사무실 을 짓 는 것 도 고려 했 지만 , 그 는 일단 2 층 침실 에 마련 한 사무실 공간 에 만족 한다 . 레일라 가 주로 생활 하 는 공간 의 많 은 것 이 바뀌 었 다 . 많 은 사람 도 그렇 게 느낄 것 이 다 . 레일라 를 소개 한다 . 2025 년 , 레일라 는 주 4 회 집 에서 일 한다 . 재택근무 가 일상 이 된 건 2020 년 봉쇄 조치 이후 부터 다 . 출근 하 는 날 이 면 , 레일라 는 오전 6 시 30 분 에 집 을 나선다 . 오전 7 시 , 회사 에 도착 한 레일라 . 출근 인원 을 분산 시키 기 위해 근무자 마다 출근 시간 이 조금 씩 다르 다 . 출근 날 은 주로 회의 가 많 다 . 다른 업무 는 굳이 회사 에서 하 지 않 아도 할 수 있 기 때문 이 다 . 레일라 회사 의 사무실 은 여러 회사 가 입주 한 큰 건물 안 에 있 었 다 . 지금 은 사무실 규모 를 줄여 작 은 건물 을 단독 으로 사용 하 고 있 다 . 회사 건물 1 층 에 는 열 스캐너 가 자리 잡 고 있 다 . 36 . 5 도 . 정상 체온 이 다 . 그 옆 에 는 얼굴 인식 카메라 가 있 다 . 카메라 가 레일라 를 직원 으로 인식 하 자 , 회사 출입문 이 열렸 다 . 그 가 손 으로 직접 작동 해야 하 는 건 없 다 . 모든 것 이 비대 면 으로 진행 된다 . \" 4 층 이요 . \" 우리 에게 익숙 한 엘리베이터 버튼 이 사라졌 다 . 음성 으로 목적지 를 인지 한다 . 엘레 베 이터 는 최대 2 인 까지 만 탈 수 있 다 . 4 층 에서 복도 를 따라 내려가 문 을 통과 하 면 사무실 이 나온다 . 예전 보다 복도 가 넓 어 져 직원 들 간 일정 거리 를 유지 하 는 것 이 더 수월 해졌 다 . 바이러스 가 건물 내 에서 전파 할 가능 성 을 줄이 기 위한 설계 다 . 들어가 기 전 문 앞 에 있 는 손 소독 제 를 사용 하 는 것 은 이제 습관 이 됐 다 . 책상 에 앉 은 레일라 . 책상 패널 을 포함 해 대부분 의 가구 는 항균 기능 이 있 는 소재 로 만들 어 졌 다 . 청소 도 쉽 고 항균 기능 이 뛰어나 기 때문 이 다 . 그 는 커피 를 타 기 위해 부엌 으로 향한다 . 부엌 가구 의 손잡이 는 구리 로 돼 있 다 . 구리 는 가격 이 비싸 지만 , 자연 적 으로 바이러스 의 확산 을 억제 하 는 효과 가 있 기 때문 이 다 . 회사 내 냉방 시스템 은 균 과 바이러스 를 박멸 하 기 위해 자외선 을 사용 한다 . 또 세균 이 번식 하 는 것 을 억제 하 기 위해 건물 주변 에 고정 된 센서 와 웨어 러블 센서 를 활용 해 일정 습도 를 유지 한다 . 전 에 는 개방 형 사무실 이 었 지만 , 코로나 19 사태 이후 사무실 설계 도 바뀌 었 다 . 그래도 책상 의 왼편 칸막이 는 투명 한 플라스틱 으로 제작 돼 동료 들 의 얼굴 을 볼 수 있 다 . 칸막이 는 바닥 에 고정 돼 있 지만 , 위쪽 은 분리 가 가능 하 다 . 발병 위험 이 높 으면 칸막이 가 올라가 고 , 위험 이 가라앉 으면 뗄 수 있 는 구조 다 . 레일라 의 책상 앞 에 는 여러 식물 이 있 다 . 여기저기 설치 된 플라스틱 칸막이 에 싫증 을 느낀 직원 들 의 고충 이 반영 됐 다 . 식물 이 없 었 을 땐 , 사무실 이 마치 병원 같 았 다 . 레일라 는 식물 이 좋 다 . 오전 은 새 프로젝트 에 대해 회의 를 하 며 보냈 다 . 동료 들 과 직접 대면 하 는 회의 였 지만 , 서로 사회 적 거리 를 두 고 진행 했 다 . 이런 회의 때문 에 레일라 는 주 1 회 회사 에 직접 출근 한다 . 온라인 으로 하 는 것 보다 직접 만나 서 회의 했 을 때 더 좋 은 결과 가 나오 기 때문 이 다 . 벌써 오후 4 시 다 . 퇴근 할 시간 이 다 . 2020 년 봉쇄 이후 레일 라는 친구 와 함께 도시 외곽 으로 이사 했 다 . 출퇴근 길 이 길 어 졌 지만 , 일 주일 에 한 번 뿐 이 라 개의 치 않 는다 . 집 이 넓 어 졌 다 . 레일라 의 개인 공간 도 넓 어 졌 다는 뜻 이 다 . 처음 에 봉쇄 령 이 내려졌 을 때 , 재택근무 가 몇 주간 지속 할 것 이 라 생각 했 다 . 부엌 식탁 과 노트북 만 있 으면 할 수 있 겠 지 생각 했 던 때 다 . 하지만 몇 주 는 몇 달 이 됐 고 , 몇 달 은 몇 년 이 됐 다 . 분리 된 사무실 공간 이 필요 하 다는 것 을 느꼈 지만 , 전 에 살 던 아파트 는 너무 작 았 다 . 레일라 는 새로 이사 한 집 2 층 침실 한 켠 에 사무실 공간 을 마련 했 다 . 높이 를 조절 할 수 있 는 책상 과 의자 를 장만 했 고 , 업무 문서 를 보관 할 수 있 는 서랍 도 샀 다 . 전 에 는 몰랐 던 조명 의 중요 성 도 느꼈 다 . 천장 에 핀 조명 을 설치 하 고 좋 은 책상 램프 도 하나 장 만 했 다 . 레일라 는 요즘 이중창 을 설치 하 기 위해 돈 을 모으 고 있 다 . 지금 집 이 도로변 에 있 어 바깥 소음 에 집중 이 깨 질 때 가 종종 있 기 때문 이 다 . 전 에 는 소음 문제 때문 에 돈 을 쓸 것 이 라고 상상 도 못 했 다 . 다락방 증축 과 정원 에 따로 사무실 을 짓 는 것 도 고려 했 지만 , 그 는 일단 2 층 침실 에 마련 한 사무실 공간 에 만족 한다 . 레일라 가 주로 생활 하 는 공간 의 많 은 것 이 바뀌 었 다 . 많 은 사람 도 그렇 게 느낄 것 이 다 .'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_model.documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02985899,  0.00702338,  0.03298181, ..., -0.02406671,\n",
       "        -0.01011761, -0.01616236],\n",
       "       [ 0.04705388,  0.01554895,  0.05243341, ..., -0.0263309 ,\n",
       "        -0.02338754, -0.00619072],\n",
       "       [-0.02621372, -0.05594452,  0.04307705, ...,  0.00522114,\n",
       "        -0.03448213, -0.00088639],\n",
       "       ...,\n",
       "       [ 0.05135854, -0.01419439,  0.02774981, ..., -0.01838074,\n",
       "        -0.01491925,  0.03540744],\n",
       "       [-0.00080602, -0.01290679, -0.02836154, ..., -0.01359722,\n",
       "        -0.00042282,  0.00497828],\n",
       "       [ 0.01520054, -0.00225542,  0.05499439, ...,  0.02658116,\n",
       "        -0.0401808 ,  0.00094629]], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_model.topic_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 512)\n",
      "[['세계' '시장' '미국' '방송' '인터넷' '기업' '삼성전자' '분야' '한국' '최근' '서비스' '전자' '가능'\n",
      "  '국내' '통신' '세포' '산업' '사업' '기술' '위성' 'tv' '연구원' '우주' '사람' '아니' '제품' '개발'\n",
      "  '과학' 'it' '업체' '박사' '연구' '교수' 'lg' '만들' 'lcd' '공룡']\n",
      " ['과학' '박사' '연구원' '교수' '우주' '기술' '분야' '연구' '가능' '세계' '사람' '아니' '한국' '세포'\n",
      "  '최근' '공룡' '전자' 'it' '위성' '삼성전자' '인터넷' '만들' '업체' '미국' 'tv' '제품' '통신'\n",
      "  '기업' '산업' '개발' 'lg' '방송' '국내' '사업' '서비스' '시장' 'lcd']\n",
      " ['공룡' '과학' '우주' '연구원' '세계' '교수' '위성' '한국' '분야' '연구' '박사' '아니' '기술' '최근'\n",
      "  '가능' '인터넷' '사람' '국내' '방송' '통신' 'tv' '만들' 'it' '미국' '제품' '전자' '서비스' '세포'\n",
      "  '삼성전자' '개발' '산업' 'lcd' '시장' 'lg' '기업' '사업' '업체']\n",
      " ['세포' '과학' '연구' '연구원' '세계' '최근' '박사' '제품' '방송' '교수' '우주' '시장' '만들' '사람'\n",
      "  '가능' '통신' '위성' '공룡' '개발' '아니' '인터넷' 'tv' '전자' '분야' '기업' '사업' '국내' '서비스'\n",
      "  '삼성전자' 'it' '기술' '산업' '업체' 'lcd' '한국' 'lg' '미국']\n",
      " ['삼성전자' 'tv' 'lcd' '한국' '국내' 'lg' '방송' '제품' '기업' '산업' '사업' '세계' '전자'\n",
      "  '업체' '시장' '최근' '인터넷' '미국' '서비스' '세포' '연구원' '기술' '위성' '가능' '개발' '분야'\n",
      "  '과학' '우주' '통신' '연구' 'it' '교수' '아니' '만들' '사람' '공룡' '박사']\n",
      " ['방송' 'tv' '인터넷' '통신' '국내' '서비스' '분야' '세포' '한국' '전자' '기술' '산업' '최근' '위성'\n",
      "  '미국' '시장' '가능' '아니' '사업' 'lg' '우주' 'it' '세계' '과학' '사람' '제품' '기업' '삼성전자'\n",
      "  '만들' '교수' '박사' '개발' 'lcd' '업체' '연구' '연구원' '공룡']\n",
      " ['한국' '기술' '분야' '국내' '산업' '삼성전자' '연구원' '과학' 'tv' '개발' '전자' '최근' '미국'\n",
      "  '방송' '가능' '세포' '사람' '세계' '우주' '위성' '시장' '사업' '연구' 'lg' '업체' '박사' '통신'\n",
      "  '인터넷' '교수' '기업' 'it' '제품' '만들' '아니' '서비스' 'lcd' '공룡']\n",
      " ['분야' '기술' '삼성전자' '우주' '위성' '한국' '최근' '연구원' '과학' '전자' '개발' '서비스' '교수'\n",
      "  '미국' '세포' '제품' '국내' '사람' '산업' '연구' 'lg' '시장' '가능' '기업' '사업' '박사' 'it'\n",
      "  '아니' 'lcd' '세계' '통신' '방송' 'tv' '인터넷' '업체' '만들' '공룡']\n",
      " ['한국' '연구원' '세계' '과학' '산업' '분야' '위성' '최근' '만들' '우주' '연구' '기술' '국내' '가능'\n",
      "  '기업' '인터넷' '교수' '미국' '사람' '개발' '사업' '시장' '방송' '박사' '전자' '업체' '공룡' '통신'\n",
      "  '세포' 'lg' '서비스' 'it' '아니' 'tv' '삼성전자' 'lcd' '제품']\n",
      " ['삼성전자' 'lg' '한국' '세포' '사업' '기업' '세계' '시장' '위성' '국내' 'lcd' 'tv' '전자'\n",
      "  '최근' '기술' '사람' '통신' '미국' '업체' '산업' '분야' '과학' '우주' 'it' '제품' '가능' '연구원'\n",
      "  '아니' '교수' '방송' '만들' '서비스' '개발' '인터넷' '박사' '연구' '공룡']\n",
      " ['과학' '사람' '기술' '공룡' '박사' '우주' '개발' '세포' '교수' '아니' '연구' '세계' '위성' '가능'\n",
      "  '분야' '제품' '연구원' '시장' '기업' '최근' 'it' '서비스' 'tv' '인터넷' '통신' '방송' '만들'\n",
      "  '미국' '산업' '전자' '한국' '업체' '국내' '삼성전자' '사업' 'lg' 'lcd']\n",
      " ['방송' '한국' '통신' 'tv' '세포' '연구원' '세계' '산업' '인터넷' '교수' '우주' '삼성전자' '시장'\n",
      "  '기업' '위성' '사람' '국내' '분야' '가능' '과학' '전자' '아니' 'it' '최근' 'lg' '서비스' '사업'\n",
      "  '미국' '업체' 'lcd' '공룡' '기술' '제품' '박사' '개발' '만들' '연구']\n",
      " ['통신' '한국' '시장' '방송' '삼성전자' '기술' '서비스' '기업' '최근' 'tv' '세포' '국내' '사업'\n",
      "  '미국' '위성' 'lg' '인터넷' '세계' '과학' '업체' '가능' '산업' '분야' '전자' '우주' '사람' 'it'\n",
      "  '만들' '제품' '아니' 'lcd' '공룡' '연구원' '연구' '개발' '박사' '교수']\n",
      " ['우주' '위성' '방송' '세계' '한국' '분야' '연구원' '과학' '통신' '국내' 'tv' '삼성전자' '인터넷'\n",
      "  '미국' '가능' '사람' '기술' '박사' '최근' '공룡' '아니' '서비스' '교수' '만들' '산업' '개발' 'it'\n",
      "  '전자' 'lg' '제품' '세포' '연구' 'lcd' '사업' '기업' '업체' '시장']\n",
      " ['과학' '연구원' '기술' '우주' '분야' '연구' '세계' '가능' '한국' '만들' '아니' '사람' '교수' '미국'\n",
      "  '위성' '최근' '박사' 'tv' '인터넷' '통신' 'it' '기업' '국내' '세포' 'lg' '산업' '전자'\n",
      "  '삼성전자' '업체' '공룡' '방송' '개발' '제품' '사업' 'lcd' '서비스' '시장']\n",
      " ['우주' '위성' '과학' '기술' '분야' '방송' '개발' '한국' '통신' '산업' '미국' '삼성전자' '국내'\n",
      "  '인터넷' '세계' '가능' '연구원' '최근' 'tv' '박사' '서비스' '아니' '기업' '사업' '연구' '만들'\n",
      "  '세포' '전자' '사람' '시장' '제품' '업체' '공룡' 'lg' 'it' '교수' 'lcd']\n",
      " ['한국' '산업' '연구원' '삼성전자' '과학' '최근' '기술' '개발' '세계' '국내' '위성' '전자' '방송'\n",
      "  '분야' '우주' '만들' '통신' '가능' '세포' '연구' '기업' '교수' '사람' '사업' '서비스' '업체' '제품'\n",
      "  '박사' 'tv' '공룡' '인터넷' '아니' '시장' '미국' 'lg' 'it' 'lcd']]\n"
     ]
    }
   ],
   "source": [
    "# print(tm_model._get_document_vectors().shape)\n",
    "# print(tm_model._find_topic_words_and_scores(tm_model.topic_vectors)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_documents_topics() missing 1 required positional argument: 'doc_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-1bc53da9765c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_documents_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_documents_topics() missing 1 required positional argument: 'doc_ids'"
     ]
    }
   ],
   "source": [
    "tm_model.get_documents_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01363029 -0.01991915  0.04504409  0.02407508  0.01376904 -0.04487069\n",
      " -0.0501462   0.01771512  0.06055494  0.03132546  0.00167156 -0.01354191\n",
      " -0.04926852 -0.04723667  0.02061645  0.00910815  0.0515699   0.03017685\n",
      "  0.00478582 -0.00490824  0.01557587  0.05236544  0.03524302 -0.01078077\n",
      " -0.06293938  0.0377364  -0.04593203 -0.02032631  0.04425114  0.0342423\n",
      " -0.05263076 -0.04710222 -0.02094551 -0.00366892 -0.03232541  0.02412808\n",
      "  0.05387568 -0.06604341 -0.04893659  0.02671479  0.02434639  0.05341553\n",
      "  0.06431236 -0.05173559 -0.02426996 -0.06137962 -0.06070521 -0.05711925\n",
      "  0.0098163  -0.02262174  0.00625316 -0.04437137  0.00638726  0.02271413\n",
      "  0.00860899 -0.06365182 -0.05120245 -0.01136659 -0.035421    0.01471635\n",
      " -0.01154089  0.05643941 -0.06728089 -0.03204541 -0.06299563 -0.04325141\n",
      "  0.03700682 -0.06595489 -0.04798143 -0.01816374  0.02889401  0.05745589\n",
      "  0.06328942  0.01973328  0.05269263 -0.03141433  0.04302338 -0.00578488\n",
      "  0.0165673  -0.06828705 -0.05433786 -0.06635506  0.05647564  0.05335071\n",
      "  0.00760595 -0.06642032 -0.05581543 -0.00131573 -0.00915358 -0.05213858\n",
      " -0.06190529 -0.05732939  0.01297563 -0.05962148  0.04694974 -0.01039596\n",
      " -0.06528583  0.04427559  0.01638068 -0.03096394  0.06567523  0.06845835\n",
      "  0.05359941 -0.06703021  0.01255529 -0.05296704 -0.05493863 -0.04070129\n",
      "  0.05221946 -0.03625362 -0.04113041 -0.02780945  0.05900778  0.05664241\n",
      "  0.03810279 -0.05515189  0.03623498 -0.04415971 -0.05173733 -0.04023113\n",
      "  0.01062155  0.06557977 -0.02707424  0.01365432  0.03378823  0.02124841\n",
      " -0.06044256  0.0546628   0.0184576   0.05246835  0.00351761 -0.06689875\n",
      " -0.02809818 -0.01015935  0.02425782  0.06552173 -0.0021719   0.01944046\n",
      "  0.02817567 -0.05660447 -0.05619526 -0.04274677  0.06842313 -0.02989987\n",
      "  0.06690515 -0.01983217  0.06521423  0.05561723  0.05582393  0.00379368\n",
      "  0.05299155  0.05374188 -0.05620781 -0.00687604 -0.04399097 -0.01350754\n",
      " -0.04855683 -0.05285167 -0.01638683 -0.0684055   0.05470555 -0.06616651\n",
      " -0.0444346   0.06073424 -0.02654312 -0.0327699   0.00078815 -0.05980303\n",
      " -0.02319714 -0.06181751  0.02684313  0.04234289 -0.06291986 -0.0579179\n",
      "  0.03723458 -0.05903252 -0.06747174  0.05012577 -0.06546114  0.06515872\n",
      "  0.03825897 -0.06542284  0.03774213 -0.04266234 -0.02807538  0.06443265\n",
      "  0.0653471   0.06650076  0.00651384  0.00658624  0.00264022  0.01882824\n",
      "  0.03949293 -0.01919753 -0.0327461   0.06228111 -0.06106074  0.0246224\n",
      "  0.06794465  0.04558272 -0.05951048  0.03989472  0.05190785 -0.05623369\n",
      "  0.05175347 -0.05356956  0.05144126 -0.00468162  0.05200877 -0.00043523\n",
      "  0.04865511  0.06029855 -0.04252432 -0.01965701 -0.00733332  0.03317092\n",
      "  0.06011989  0.05477721 -0.06714658  0.0027789  -0.04196199  0.04007749\n",
      " -0.0621348   0.04020136  0.06432262  0.03839839 -0.04627448  0.0531104\n",
      " -0.06449142  0.0001874   0.02551968 -0.03007897 -0.0511442   0.05256502\n",
      "  0.06155086 -0.01231239 -0.05879326 -0.06688957  0.05025498 -0.03591006\n",
      "  0.03963555 -0.05793114  0.00531767  0.04645041 -0.02073377  0.05992267\n",
      "  0.01613174  0.05606455  0.04935526 -0.04963713  0.02497433 -0.02096506\n",
      "  0.06751174  0.00053122  0.01544561  0.04978251 -0.00845901  0.01207564\n",
      " -0.01945521  0.04761278  0.04939481  0.02273871 -0.02847383  0.01917966\n",
      "  0.05325417  0.00289779 -0.05732446  0.06003469  0.04024586  0.02590001\n",
      " -0.04882852  0.00741154 -0.05383781  0.04986101  0.06507899 -0.00745134\n",
      " -0.02784945 -0.0619474  -0.05499258 -0.05216453  0.00640449 -0.05655666\n",
      " -0.01430728 -0.06732277 -0.05614338  0.05479905 -0.05762859  0.04674116\n",
      " -0.01813276  0.00716258  0.01054791 -0.00959565 -0.05219453 -0.03806918\n",
      "  0.04873884  0.0535657   0.03548144  0.00504707  0.02097076  0.0338862\n",
      "  0.06666565  0.04465266  0.00495764 -0.05211437  0.00727589  0.00636124\n",
      "  0.06463202  0.05053067  0.03443672 -0.03971153 -0.04975086  0.04258556\n",
      "  0.01114763 -0.00247645  0.05337224  0.06163573 -0.00853419 -0.02532462\n",
      "  0.06576648  0.01902831  0.04814262  0.06056915  0.05403603 -0.05965139\n",
      " -0.06497959 -0.05083432  0.03187074 -0.01627418 -0.04118592 -0.02598251\n",
      " -0.06357506  0.01072772 -0.0375135   0.06412148 -0.01111785 -0.02957319\n",
      " -0.03918961  0.04080909 -0.02672542 -0.05664456 -0.06092806 -0.02371833\n",
      " -0.02685051 -0.02024592  0.01059767 -0.01528028 -0.0353278  -0.04442181\n",
      " -0.02218292  0.04332242  0.02711435  0.02877405  0.04825282  0.04224299\n",
      " -0.04575479 -0.06682866 -0.06656653 -0.04367344 -0.06042102 -0.04893849\n",
      "  0.04655564  0.06487166  0.06623098  0.04929872 -0.0618421  -0.01886838\n",
      " -0.06164251 -0.03163889  0.04932656 -0.06280312  0.00833752  0.0663511\n",
      " -0.02529679 -0.02187606  0.02911795  0.06193011 -0.01351979 -0.04110033\n",
      "  0.01739694 -0.04800561 -0.01265464  0.04109144  0.00066859 -0.03910526\n",
      "  0.06789353  0.03567355  0.0094826  -0.06798665  0.0547407   0.06480825\n",
      " -0.01612883 -0.03107888  0.00824317  0.03711125 -0.04446217 -0.05382054\n",
      " -0.06113481  0.06068288 -0.03216669  0.0441639   0.05461362  0.05795449\n",
      "  0.061164    0.02053573  0.03903985  0.01475496  0.01594504  0.03884716\n",
      " -0.02765373  0.0276245  -0.01774841  0.01708528  0.04502236 -0.05138289\n",
      " -0.01813455  0.01607808 -0.00608915  0.04652955 -0.0579262   0.05542452\n",
      "  0.05701568  0.03242694 -0.02171118  0.04839549  0.0588658  -0.00350965\n",
      "  0.05063039 -0.04536155 -0.02089897 -0.06712635 -0.02820493 -0.06411369\n",
      " -0.04988338 -0.04438442  0.0661443   0.00885074  0.06168917  0.04597647\n",
      " -0.06453554 -0.0005538  -0.02693656  0.04361711  0.04517706  0.04496058\n",
      " -0.05128263 -0.03723117 -0.04127546 -0.0615273  -0.02905441 -0.05147128\n",
      "  0.01924235  0.04054885  0.02537428  0.04316028 -0.06838498  0.03757624\n",
      "  0.03660567 -0.04614763 -0.05374474 -0.0615197  -0.04542021 -0.04074546\n",
      "  0.05320344 -0.05569834 -0.06400681 -0.05547243  0.02362889  0.00752834\n",
      "  0.04969601 -0.06639656  0.04069447  0.03390338 -0.06637332 -0.05070114\n",
      "  0.001642   -0.05172762 -0.05735407  0.0170481  -0.05802334  0.02697633\n",
      "  0.03092724  0.068472    0.06092393  0.01405904  0.0502843  -0.042645\n",
      " -0.00538866 -0.06711887 -0.03745775 -0.03883034 -0.01391623  0.00860734\n",
      "  0.06273974  0.02169422 -0.01798495 -0.01877537 -0.06821411  0.05803244\n",
      " -0.01532304  0.00523025  0.02128368 -0.06069167  0.02725637  0.0099433\n",
      " -0.06646405 -0.06217664 -0.06590158 -0.06058577 -0.03323439  0.04689366\n",
      " -0.0280162   0.00648742]\n",
      "[ 0.03570546 -0.04038736  0.06366683  0.05527616 -0.05064357 -0.04873145\n",
      " -0.06780619  0.00993097  0.06768023  0.0613388  -0.04100049 -0.02912378\n",
      " -0.03609756 -0.06275897  0.02145115 -0.06639454 -0.01605073  0.0260074\n",
      "  0.06262999  0.06292391 -0.06370495 -0.04483874  0.03658512  0.01187386\n",
      " -0.0670934   0.03149919  0.01927348 -0.05821849  0.06485763 -0.05640697\n",
      "  0.01075812 -0.04260699 -0.02544101 -0.01485009 -0.04098564  0.03421283\n",
      "  0.06170218 -0.05943874 -0.03415859  0.06003818 -0.03890269  0.0582884\n",
      "  0.05991232  0.02116419  0.04415868  0.01614048 -0.06639198 -0.05971587\n",
      " -0.00712608  0.02584383  0.00283012 -0.05611929 -0.00548743  0.02026265\n",
      "  0.01736546 -0.06527563 -0.04103472 -0.04947305  0.05170396  0.05469002\n",
      "  0.06507485  0.06441228 -0.0525122  -0.02753312 -0.03077728  0.05042244\n",
      " -0.03675728 -0.0327176   0.00031509 -0.02356273  0.0425477   0.04624965\n",
      " -0.00407445  0.0331548   0.04835906 -0.01666235  0.01231585  0.05160013\n",
      "  0.03073031 -0.06795404 -0.05667757 -0.04810016  0.04709166  0.0489479\n",
      " -0.03985743 -0.06219587 -0.06707548  0.02567673  0.05533186 -0.05663026\n",
      " -0.05046406  0.00781683 -0.06781666 -0.06640091  0.03204789  0.03311835\n",
      " -0.06689044  0.0568338   0.0343798   0.01999276  0.06167026  0.06720558\n",
      "  0.04454643 -0.06789809 -0.0463082  -0.05527669 -0.0228068  -0.02383047\n",
      " -0.01783309  0.00805463 -0.00364829 -0.06031594  0.05785329  0.02277781\n",
      "  0.0311404  -0.06767017 -0.00360251 -0.06317528 -0.06408196 -0.03551571\n",
      " -0.00707141  0.04650003  0.00914764 -0.01687458 -0.04419782 -0.06360056\n",
      " -0.03966542 -0.04683867  0.00936755  0.0533221   0.03318741 -0.048805\n",
      "  0.00769817 -0.03129486  0.02694885  0.06212061  0.05349945  0.00946121\n",
      " -0.02314287 -0.04702932 -0.00180823 -0.03414883  0.06770758 -0.05866361\n",
      "  0.06419353  0.04997741  0.06116694  0.04732024  0.02698636 -0.01696115\n",
      "  0.05269146  0.058631   -0.02306387 -0.0255001  -0.04884921  0.00248725\n",
      " -0.0144939  -0.06555119  0.01603381 -0.06698862  0.06140179 -0.03866305\n",
      "  0.01119183  0.06304269 -0.03741306  0.01829749  0.00932533 -0.04754899\n",
      " -0.03695756 -0.04644808  0.03217049  0.06166704 -0.03251575 -0.02545406\n",
      "  0.03368162 -0.06245891 -0.04692071  0.06583966 -0.04266512  0.06218716\n",
      "  0.00227888 -0.06412365  0.0447952  -0.06384134 -0.04268484  0.03382823\n",
      "  0.0474205   0.05413604  0.06204464  0.05409494  0.05787932 -0.00084398\n",
      "  0.05847182  0.03548146 -0.04381193  0.05582908 -0.06529848  0.03363869\n",
      "  0.06798653 -0.01544255 -0.06476676  0.05642961  0.05069977 -0.0412111\n",
      "  0.04386314  0.06255069  0.01367389  0.03162775  0.00379562  0.06166088\n",
      "  0.01506148  0.03428059  0.0176977  -0.05930696 -0.0057242   0.03066904\n",
      "  0.04158032  0.00168195 -0.01651431  0.03245433 -0.02445452  0.03579647\n",
      " -0.00348363 -0.00195458  0.04426552 -0.00743607 -0.05822628  0.06117744\n",
      " -0.0350332   0.03709128  0.06076342 -0.02862372 -0.01936498  0.04834168\n",
      "  0.05681591  0.01614775 -0.0576069  -0.03040436  0.06123655 -0.0321424\n",
      "  0.06555508 -0.02039911  0.03537162 -0.05091664  0.05376641  0.06184313\n",
      "  0.02326639  0.0569913   0.04972356  0.00269519  0.00923793 -0.05371353\n",
      "  0.06813631  0.0428766   0.03530295  0.00291181 -0.00900536  0.0096201\n",
      " -0.04173281  0.04747274  0.05717287  0.0268567   0.00290232  0.06001826\n",
      " -0.02174442  0.0577798   0.00062463  0.05580898  0.06286578 -0.0468182\n",
      " -0.03370664 -0.04277254  0.00581472  0.0144617   0.06512635 -0.00053067\n",
      " -0.05783167 -0.02879251 -0.05744712 -0.04627343  0.05391914 -0.00362241\n",
      " -0.02406281  0.0408726  -0.04841255  0.05538286 -0.0490186   0.04325362\n",
      " -0.0046184  -0.00368337 -0.02647964 -0.0573606  -0.01626773  0.04761904\n",
      "  0.05706656  0.05977457  0.00928928 -0.02215532 -0.06665976  0.05760258\n",
      "  0.03614786 -0.04585627  0.02543708 -0.05055232 -0.01621593 -0.00733597\n",
      " -0.04245737  0.06185273  0.0237057   0.0263669  -0.06097653  0.02649673\n",
      "  0.01390455 -0.01099067  0.05216787  0.06274474 -0.00940126  0.04628225\n",
      "  0.04435104  0.04273358  0.03716962  0.05918057 -0.05403951 -0.05873065\n",
      " -0.02607212 -0.06285886 -0.01410537  0.06092818 -0.06692189  0.01904774\n",
      " -0.01321972  0.01372986 -0.02230556  0.06297336  0.06738079 -0.02305712\n",
      " -0.05011299  0.04201225 -0.00907091 -0.00091198 -0.06635447  0.00995667\n",
      " -0.04667834 -0.04206144  0.01595947 -0.00419563 -0.02041593 -0.03861995\n",
      "  0.00413816  0.06086054 -0.05841019 -0.05091402 -0.04116587  0.00286495\n",
      " -0.05519534 -0.06689232 -0.05753534  0.03817976 -0.05788944 -0.06568152\n",
      " -0.00881913  0.06529604  0.05943185 -0.00690441 -0.00481897  0.03560498\n",
      " -0.06305238 -0.01746957  0.02484153 -0.00702181 -0.04552637  0.02350474\n",
      "  0.01490522 -0.04332682  0.05808669  0.0668248  -0.00059726  0.0323806\n",
      "  0.01124401 -0.04663681 -0.02440917  0.06442767  0.05359411 -0.00731942\n",
      "  0.03667099  0.00011343  0.01895348 -0.06743959  0.05339009  0.05402583\n",
      " -0.05046941  0.03787379  0.01358413  0.03487195 -0.06591902 -0.05875276\n",
      " -0.01361888  0.05760192 -0.0079365   0.00953613  0.05290454  0.06077892\n",
      " -0.00104292 -0.01758347  0.06459815  0.0190931  -0.0644427   0.06283548\n",
      " -0.0638911   0.0004879  -0.00538505  0.02879171 -0.0607376  -0.05801518\n",
      "  0.01917796  0.020256    0.02314197  0.03794474  0.01264746 -0.0104678\n",
      "  0.06736152 -0.00919765  0.01156474  0.01197666  0.06404538  0.0640099\n",
      "  0.01971735 -0.02519976 -0.02705502 -0.06564905 -0.05665581  0.02443049\n",
      " -0.0535924  -0.01119727  0.06043147  0.06170039  0.06288867  0.06779344\n",
      " -0.06431308 -0.01498257 -0.06458796  0.0636925   0.0406761  -0.0212399\n",
      " -0.00432124 -0.0371916  -0.00133679  0.00475779  0.02774296  0.02476042\n",
      "  0.01565673  0.02217537  0.05876649 -0.00359695 -0.06562738 -0.03865632\n",
      " -0.05752015  0.00045508 -0.06471337 -0.04598291  0.02085225 -0.00368686\n",
      "  0.06122348 -0.05276948  0.01926613 -0.0549175  -0.03709987 -0.03154084\n",
      "  0.00668229 -0.05374625  0.02516058  0.012687   -0.06529232 -0.04858756\n",
      "  0.02960497 -0.05482958 -0.06009455  0.06661598 -0.04510973 -0.036704\n",
      " -0.01612167  0.06814979  0.02724682  0.05654552 -0.04804791 -0.01888908\n",
      " -0.0182231  -0.0676719   0.01671786 -0.04979705  0.05666237  0.03901709\n",
      "  0.06510818 -0.00636761  0.05250731 -0.03762697 -0.06666052  0.03303079\n",
      "  0.06451133  0.01852803  0.05647919 -0.0582304   0.04278003  0.05395385\n",
      " -0.06605394 -0.06103019 -0.01745701 -0.05490088 -0.06490374  0.04341716\n",
      " -0.0511877  -0.02680932]\n",
      "[ 0.03762595 -0.03379878  0.06168468  0.01745564 -0.00296919 -0.0307933\n",
      " -0.00491422 -0.03616938  0.01126016  0.04733198 -0.01161566 -0.00816921\n",
      " -0.01889802  0.05174425  0.0005268   0.04871963  0.03909217  0.04309103\n",
      "  0.01022622 -0.02239457  0.05560995  0.04117811  0.06060608 -0.05852623\n",
      " -0.0676011   0.00578126 -0.06478176 -0.03803774  0.06531239 -0.00951718\n",
      " -0.02876478 -0.05975885  0.0049671  -0.04216349  0.03661545  0.04960091\n",
      "  0.062187   -0.06127903  0.04212268 -0.03381177  0.06373234  0.06435487\n",
      "  0.06677942 -0.02651718 -0.03294906 -0.06404092 -0.05503612  0.0467201\n",
      " -0.03448168 -0.05973079  0.00426056  0.00928855  0.02570832 -0.03070509\n",
      "  0.04544093 -0.0561071  -0.06587708  0.05091397 -0.05161421 -0.0285559\n",
      "  0.00317406  0.06400895 -0.06228504 -0.03449016 -0.05064964  0.02220089\n",
      "  0.06852883 -0.02676501 -0.06087106 -0.02790763 -0.01398367  0.0603003\n",
      "  0.0679549   0.00713007 -0.01778242 -0.06579222  0.05243659  0.02448587\n",
      " -0.05720202 -0.06904656 -0.02235344 -0.05892548  0.03524141  0.05832212\n",
      "  0.06084066 -0.06101641  0.02058145  0.02107326 -0.02417056 -0.01692243\n",
      " -0.05423177 -0.06262499  0.06134607 -0.03302815  0.03564399 -0.03723541\n",
      " -0.07020012  0.05303068  0.00279107 -0.05199636  0.06599866  0.06485895\n",
      "  0.0296427  -0.04378289  0.06440698 -0.04601053  0.01831237 -0.03058647\n",
      "  0.06933101  0.0419914   0.0041085  -0.06490698  0.00196226  0.06768448\n",
      "  0.03061155 -0.05532854 -0.01465891 -0.07038841 -0.0427323  -0.05287208\n",
      "  0.01651424  0.01400444 -0.02090982 -0.02398409  0.05984424  0.00870985\n",
      " -0.05179891  0.05315055  0.05836765  0.05896885 -0.0316698  -0.06812219\n",
      " -0.00661518 -0.02775918  0.04925454  0.06912319  0.06002979 -0.01537559\n",
      "  0.04584933 -0.06609573  0.05913591 -0.03451412  0.05974604 -0.05620825\n",
      "  0.06302627 -0.01882593  0.0023667   0.05333871  0.05364818 -0.00787519\n",
      "  0.05981978  0.03140195 -0.0542149   0.00438515 -0.04281366 -0.04814406\n",
      "  0.00907644 -0.06348249 -0.02656295 -0.05996022  0.06378648 -0.07014248\n",
      "  0.00108548  0.06846458  0.01370698 -0.04188428 -0.03799959  0.00559741\n",
      "  0.02479573 -0.06468587  0.00768624 -0.01099596 -0.0627747   0.00381171\n",
      "  0.03476408 -0.03243258 -0.06578934  0.06530877  0.04554977  0.05767341\n",
      "  0.05633961 -0.06836391 -0.04025561 -0.06742387  0.03632028  0.05921121\n",
      "  0.02549451  0.04630595 -0.05610815  0.02342407  0.03467217  0.04291143\n",
      "  0.02236935  0.05401829 -0.05826479  0.02839821 -0.06595437  0.0547036\n",
      "  0.06982747 -0.05044576 -0.04797305  0.01504485  0.06845998 -0.05897609\n",
      "  0.03315558  0.02964625 -0.00217993 -0.02853452  0.05597955 -0.01804489\n",
      "  0.01496805  0.03983507 -0.0384505   0.05285147 -0.05731782  0.0395199\n",
      "  0.05765908 -0.03998161 -0.04670609 -0.0541747  -0.01369588  0.0599861\n",
      "  0.00312475  0.02985592  0.0687459   0.00861866 -0.04912528  0.03060876\n",
      " -0.04319791 -0.05302856  0.04915013 -0.00328859 -0.042035    0.05530529\n",
      "  0.02084303  0.01074553 -0.06399874 -0.0690344   0.06768222  0.04518506\n",
      "  0.02329776 -0.06043987  0.04476951 -0.02200523 -0.01283814  0.06128474\n",
      " -0.02780619 -0.01216504 -0.0158369  -0.0330169   0.04645    -0.04784492\n",
      "  0.06776495  0.02509642  0.02139862  0.06552652 -0.03021553  0.04517881\n",
      " -0.04474536  0.0667799  -0.02410795 -0.022344   -0.01158533  0.06401289\n",
      "  0.03415518 -0.0128714  -0.03549328  0.06154922  0.01910309  0.01492525\n",
      " -0.04127127  0.01243902 -0.06743785  0.0579638   0.05486413 -0.01811822\n",
      " -0.00966584 -0.0669451  -0.04698226 -0.00205543  0.02874875 -0.0492391\n",
      " -0.02960165  0.05081314 -0.06800999  0.03697062 -0.05624455  0.0235042\n",
      " -0.03568117  0.01169359  0.0457043   0.04117656 -0.01416705 -0.03910553\n",
      "  0.06210054  0.02928284  0.04759416  0.04254198  0.04743074  0.00476373\n",
      "  0.04218208 -0.01185839  0.03993675 -0.00085582  0.00296145 -0.03442466\n",
      "  0.03288475  0.05074449 -0.01887921 -0.00234899 -0.01869543  0.00882422\n",
      " -0.00948597 -0.02764943  0.06053874  0.06242661 -0.01120162 -0.01759853\n",
      "  0.06696633 -0.0113891   0.06724887  0.06081261 -0.01026479 -0.02781836\n",
      " -0.0316007  -0.06764698  0.02379206 -0.01498161 -0.06930741 -0.03217114\n",
      " -0.06963892  0.04630153 -0.02838521  0.06303475 -0.03339678 -0.03832341\n",
      " -0.03660411 -0.01342951  0.00522898 -0.05815095 -0.04412461  0.02580828\n",
      "  0.02319221 -0.04685888  0.01681153 -0.02632814  0.00299907  0.0321389\n",
      "  0.03810296  0.06109396  0.04288554 -0.00674909  0.01015147  0.01211487\n",
      "  0.00921324 -0.06153116 -0.04208866 -0.03301594  0.04084406 -0.04998659\n",
      "  0.05722737  0.06583969  0.06468561 -0.01910094 -0.05871388  0.04091652\n",
      " -0.06351987 -0.03362075  0.0004858  -0.06054885  0.0597989   0.03640315\n",
      "  0.00037257 -0.06250201  0.03703053  0.0679469   0.04520812  0.00283533\n",
      " -0.01985253 -0.03934909  0.00778021  0.04905034 -0.06413893 -0.0582378\n",
      "  0.06984723  0.06670026 -0.02366983 -0.06883858  0.05416619  0.04828943\n",
      "  0.00605441 -0.0053507   0.06037273  0.05680045  0.02796493 -0.06289056\n",
      " -0.04327359  0.0637817  -0.03334464 -0.00328552  0.05290712  0.04777388\n",
      "  0.04288577  0.03797913  0.06555326  0.06531995  0.06718867 -0.006333\n",
      " -0.0579782  -0.01263778  0.03976097  0.04296241 -0.00757965 -0.00951605\n",
      "  0.01466216  0.04370638 -0.05108894  0.03619818 -0.01775394 -0.01158601\n",
      "  0.04229978  0.04507323 -0.01910699  0.06463816  0.06162639  0.04070415\n",
      " -0.02392902  0.00035948 -0.01874433 -0.06886862 -0.01290912  0.05964538\n",
      "  0.04194544 -0.01334817  0.04151685  0.0389955   0.01806612  0.05484668\n",
      " -0.0663758   0.02035856 -0.06117111  0.04403921  0.04610905  0.02141852\n",
      " -0.059857   -0.06138664 -0.01716102 -0.02639349  0.00837269 -0.01501826\n",
      " -0.06594184  0.01585881  0.03825169 -0.02152411 -0.06999698  0.02683458\n",
      "  0.05651284 -0.03845289 -0.06743114 -0.06350968 -0.03478931 -0.04070118\n",
      "  0.02477157 -0.03211695 -0.02543628 -0.04727257  0.04870286 -0.01928134\n",
      "  0.0567738  -0.04530418  0.06144112 -0.00769729 -0.06131975 -0.04212108\n",
      "  0.00902118 -0.0642045   0.0418572   0.02078412 -0.0544614  -0.02448312\n",
      "  0.01099166  0.07041448  0.0113637  -0.02036504  0.06357421 -0.02861542\n",
      "  0.04420842 -0.06959767 -0.05373563 -0.06331881 -0.00212518  0.00352027\n",
      "  0.0631782   0.05326461 -0.018044   -0.0425572  -0.04784966 -0.00605367\n",
      "  0.02106008  0.04430222 -0.03490682 -0.05766341  0.05122456  0.0089339\n",
      " -0.06561066 -0.06484442 -0.0209748  -0.05763682 -0.02554482  0.03517766\n",
      " -0.01880877 -0.00893921]\n",
      "[ 4.4017643e-02  1.7774746e-02  5.5890318e-02 -8.6570270e-03\n",
      " -2.4462281e-02 -4.4808578e-02  4.7083106e-02  3.9845295e-02\n",
      "  5.6034900e-02  4.8975740e-02 -9.2518507e-03 -5.3706747e-02\n",
      " -5.2687831e-02 -5.4384373e-02 -2.1392908e-02  5.3163491e-02\n",
      "  5.5805489e-02  2.8000800e-02  1.4868825e-02  4.9447801e-02\n",
      " -5.0809238e-02 -2.5587553e-02  5.5486891e-02  2.2391176e-02\n",
      " -5.4907750e-02  5.5329870e-02 -4.9187910e-02 -5.3757638e-02\n",
      "  5.5082150e-02  1.6108846e-02 -1.8320115e-02  1.4582442e-02\n",
      " -3.6112994e-02 -5.0222962e-03  8.8719791e-03  2.5100937e-02\n",
      "  5.4844640e-02 -5.5824284e-02 -5.6046311e-02 -3.2581285e-02\n",
      " -4.9422730e-02  5.5160400e-02  5.5972654e-02 -1.9937636e-02\n",
      "  1.6369572e-02 -5.2188974e-02 -5.6033138e-02  3.6427725e-02\n",
      "  4.3823227e-02 -3.5219379e-02  3.4802210e-02  5.5801943e-02\n",
      "  2.4290491e-02 -5.4788865e-02 -2.4201073e-02 -5.4882716e-02\n",
      " -1.4189209e-02  3.5919700e-02  2.1569900e-02  1.9822247e-02\n",
      " -1.1089124e-02  5.5941153e-02 -5.6082051e-02 -5.0027549e-02\n",
      " -4.8579130e-02 -1.1064159e-02 -2.0335689e-02 -5.5692937e-02\n",
      " -5.3156760e-02 -5.6032952e-02  4.8034847e-02 -1.7743964e-02\n",
      "  2.9000323e-02 -1.8501041e-02 -1.7350955e-02 -5.5998746e-02\n",
      "  4.9409874e-02  1.4712659e-02  4.6541365e-03 -5.6096688e-02\n",
      " -5.4813117e-02 -5.2414801e-02  5.4544620e-02  5.2730300e-02\n",
      "  5.4628376e-02 -5.5900332e-02 -5.3815838e-02  2.7632793e-02\n",
      "  3.4975123e-02  1.9356661e-02 -5.5747259e-02 -5.3565875e-02\n",
      "  1.4261325e-02 -4.3001525e-02  5.1461160e-02 -5.6705941e-03\n",
      " -5.6020454e-02  3.1984523e-02 -1.4996317e-02 -4.2747058e-02\n",
      "  5.6011606e-02  5.6099378e-02  3.7752446e-02 -5.6059480e-02\n",
      " -5.3862557e-02 -5.4527331e-02 -4.6261545e-02 -5.4148339e-02\n",
      "  5.0366815e-02 -4.2685278e-02  1.7511262e-02 -4.7092959e-02\n",
      "  4.5821849e-02 -1.0026673e-02  5.5403039e-02 -5.6105137e-02\n",
      "  5.6006148e-02 -5.6105226e-02 -3.0718781e-02 -5.4551180e-02\n",
      " -5.3842571e-02  5.4733075e-02  4.3520667e-02 -5.0940085e-02\n",
      " -2.3189655e-02 -5.1154584e-02  5.1414151e-02 -3.6318619e-02\n",
      " -4.1578434e-02  2.1958884e-02 -1.3290370e-02 -5.3358842e-02\n",
      "  5.0039027e-02 -4.5335524e-02  3.9400104e-03  5.5720162e-02\n",
      "  5.4066021e-02  2.7421664e-02  3.9304487e-02 -5.0063532e-02\n",
      "  5.1754836e-02 -5.4644901e-02  5.5996105e-02 -5.0907791e-02\n",
      "  5.5383496e-02  5.2897587e-02  5.3277161e-02  4.8866682e-02\n",
      "  4.1465864e-02  5.5800077e-02  5.4180909e-02  5.5979107e-02\n",
      " -5.5618070e-02 -3.3867903e-02  3.3386409e-02 -2.9794671e-02\n",
      " -4.8649598e-02 -4.1616559e-02  4.7723848e-02 -5.1386848e-02\n",
      "  5.4001115e-02 -1.3277489e-02  4.2581156e-02  5.6003820e-02\n",
      "  5.4348674e-02  4.4540748e-02  4.1945353e-02 -5.1682282e-02\n",
      " -1.9288640e-02 -5.2374534e-02 -3.2016691e-02  3.0846570e-02\n",
      " -4.0746711e-02  2.5634628e-02  5.4600026e-02 -5.5693533e-02\n",
      " -5.5799223e-02  5.6069449e-02 -5.5393271e-02  5.6046236e-02\n",
      "  5.4519746e-02 -5.5278700e-02  5.1245227e-02 -5.6059543e-02\n",
      " -2.0899218e-02  4.3586522e-02  4.9386539e-02  5.6043878e-02\n",
      "  5.4995015e-02  5.0361052e-02  5.4183211e-02  5.5932015e-02\n",
      "  5.5114515e-02 -5.6603532e-03 -5.5955186e-02  2.0315105e-02\n",
      " -5.4423593e-02 -4.1674800e-02  5.6098253e-02 -3.2511342e-02\n",
      " -3.6671985e-02  5.6046631e-02 -1.3814097e-02  4.1301567e-02\n",
      "  5.5907831e-02 -5.4118205e-02  2.7554885e-02  4.6774186e-02\n",
      "  5.2593194e-02 -7.3571112e-03  5.4696832e-02  3.5076894e-02\n",
      " -1.2071716e-02  1.8658366e-02  5.3758044e-02  5.5794757e-02\n",
      "  5.1706895e-02  4.9315859e-02 -5.5705063e-02 -2.5365427e-02\n",
      " -2.1907303e-02  4.2281736e-02 -5.5370919e-02 -8.7211449e-03\n",
      "  5.5243444e-02  2.9508026e-02 -5.6084234e-02  5.5825204e-02\n",
      " -5.4232404e-02  4.0225424e-02  3.3684701e-02  1.6781621e-02\n",
      " -3.6027718e-02  4.7655642e-02  4.5246389e-02 -2.1905417e-02\n",
      "  5.3741146e-02 -5.6073077e-02  5.4492388e-02  2.8018741e-02\n",
      " -4.0946752e-02 -4.4471856e-02  3.3040516e-02 -5.2453477e-02\n",
      "  4.6395544e-02  3.9095797e-02  4.6932444e-02  5.5674676e-02\n",
      "  5.3338759e-02  2.1401577e-02 -7.7223191e-03 -5.0075475e-02\n",
      "  5.6106314e-02  4.2252935e-02 -3.2384783e-02  2.8873464e-02\n",
      "  1.0667718e-02  5.4520987e-02 -5.6092490e-02  3.9417598e-02\n",
      "  1.6480172e-02 -1.3370125e-05 -1.6509008e-02  5.0458465e-02\n",
      "  5.3189170e-02  4.8525352e-02 -2.0294269e-03  5.5911534e-02\n",
      " -1.9683152e-02  6.5557812e-03 -3.4796182e-02 -4.3507952e-02\n",
      " -5.1430557e-02  5.2920967e-02  5.5221025e-02  5.4707590e-02\n",
      " -5.2781425e-02 -5.5246349e-02 -5.4231357e-02 -5.3738475e-02\n",
      "  5.0691765e-02 -5.5321939e-02  2.6919935e-02 -4.7965869e-02\n",
      " -5.6085397e-02  4.3767929e-02 -5.4834817e-02 -3.5277199e-02\n",
      " -2.7054880e-02 -5.1946599e-02  5.4037947e-02 -7.0777624e-03\n",
      " -5.2569937e-02 -3.0142579e-02  5.5250220e-02  4.9721193e-02\n",
      "  2.9084045e-02 -2.2577925e-02 -1.3616095e-02  4.3600366e-02\n",
      "  5.5073004e-02 -1.3124522e-02  5.3898007e-02 -3.5329610e-02\n",
      "  4.4241406e-02  5.0241418e-02 -2.0004287e-02  5.4143868e-02\n",
      "  1.2471851e-02  4.4625089e-02 -5.0012901e-02  2.8302113e-02\n",
      " -5.6000352e-02 -9.0987131e-04  5.4390088e-02  5.5910699e-02\n",
      " -4.3155465e-02 -2.1906612e-02  5.5937864e-02  2.9865388e-02\n",
      "  5.4513868e-02  4.5791913e-02 -5.4775026e-02 -3.6105927e-02\n",
      " -5.6087311e-02 -4.7015216e-02  4.9735937e-02  4.5794971e-02\n",
      " -4.7528703e-02  7.1832160e-03 -4.7295362e-02 -2.8046731e-02\n",
      " -2.4967887e-02  2.7759474e-02  2.7998840e-02 -3.9328065e-02\n",
      "  1.6895778e-02  1.6868543e-02 -4.9764801e-02 -4.8110984e-02\n",
      " -5.5326838e-02  2.0888425e-02 -5.0054811e-02 -5.4278258e-02\n",
      " -3.8537020e-03 -1.9552333e-02 -4.1482121e-02  9.1693141e-03\n",
      "  4.8242215e-02  5.5542439e-02 -5.5795126e-02  5.4894522e-02\n",
      "  5.1219441e-02  5.4240245e-02 -5.5452149e-02 -5.6019019e-02\n",
      " -5.4323040e-02 -4.2687986e-02 -5.5936456e-02 -5.5058289e-02\n",
      "  4.3226313e-02  7.2056456e-03  5.5496719e-02 -4.5802679e-02\n",
      " -5.4969903e-02 -5.3582121e-02 -5.5765979e-02 -4.4125929e-02\n",
      "  3.1496786e-02 -5.0261497e-02  5.6098398e-02 -2.6985101e-02\n",
      "  6.4156479e-03 -5.2759666e-02  5.4342084e-02  3.4595851e-02\n",
      "  1.5756987e-02 -5.2205455e-02  4.4548880e-02 -5.5078372e-02\n",
      "  3.3175785e-02  5.2563384e-02  5.6094274e-02  2.8651141e-02\n",
      "  5.6072637e-02  5.5725396e-02  4.9861029e-02 -5.6098327e-02\n",
      "  5.5810533e-02  5.5753354e-02 -3.5182014e-02  5.3669948e-02\n",
      "  8.3896145e-03  3.4735024e-02 -5.3463761e-02 -5.1542901e-02\n",
      " -3.8794197e-02  5.6063950e-02  4.4801671e-02  1.0421091e-02\n",
      "  5.6091174e-02  5.5512693e-02  5.4444131e-02  6.1522806e-03\n",
      " -5.4592237e-02  4.9317397e-02  1.0759429e-02  5.4642439e-02\n",
      " -2.9932868e-02  3.7841160e-02  3.3296982e-03 -4.5127362e-02\n",
      "  4.3964148e-03 -3.1417284e-02 -1.9926878e-03  4.7013298e-02\n",
      " -4.1188002e-02 -3.2722838e-03 -5.5232335e-02  4.5251235e-02\n",
      "  5.5506140e-02  5.8983389e-04  5.5275016e-02 -2.5347180e-03\n",
      "  5.5603996e-02  4.5274027e-02  5.5717915e-02 -5.4982178e-02\n",
      " -2.2303045e-02 -5.6038603e-02  3.2841012e-02  4.8852261e-02\n",
      "  1.2406608e-02 -3.2819591e-02  5.5980135e-02  5.6105562e-02\n",
      "  5.5669051e-02 -3.8945556e-02 -5.5972975e-02 -5.4894771e-02\n",
      " -5.2283224e-02  5.4964978e-02  2.8941114e-02  3.1570226e-02\n",
      " -5.2072123e-02  5.4638598e-02 -3.4679048e-02 -4.7482606e-02\n",
      "  4.0871046e-02  4.2872302e-02 -3.6653098e-02  4.8886400e-02\n",
      "  3.6389641e-02  3.2874629e-02 -5.5914890e-02  2.9745195e-03\n",
      " -5.0081715e-02 -3.3428922e-02 -1.8510245e-02 -5.2303087e-02\n",
      " -1.1897297e-02  3.6101160e-03  4.0793389e-02 -3.2839675e-02\n",
      " -1.5786542e-02 -3.0959073e-02  4.1402936e-02 -2.2477796e-03\n",
      "  5.5324789e-02 -5.6087468e-02  3.8470816e-02  5.0254107e-02\n",
      " -5.2466128e-02 -3.8571216e-02  3.3221204e-02 -5.4274693e-02\n",
      "  4.9978275e-02  5.6046791e-02 -5.3570867e-02 -1.0381354e-02\n",
      " -5.3221624e-02  5.6106418e-02  9.5762182e-03  5.5165753e-02\n",
      "  5.2954458e-02 -4.6066418e-02 -4.6681803e-02 -5.5927679e-02\n",
      " -2.5665049e-02 -5.5606335e-02  5.3387672e-02  3.4338783e-02\n",
      "  4.7709648e-02  3.3730965e-02  2.3171954e-02 -4.2266607e-02\n",
      " -5.5776395e-02  3.0844461e-02  4.7381070e-02 -5.5265561e-02\n",
      "  1.9830119e-02 -5.5946771e-02  3.7674978e-02  4.4382352e-02\n",
      " -5.5867504e-02 -5.4639224e-02 -5.5680055e-02 -4.9033333e-02\n",
      " -5.4055121e-02 -1.7544774e-02 -4.3262992e-02 -3.8814086e-02]\n",
      "[ 0.05130197  0.00555507  0.05428161  0.01811442  0.05644044 -0.05684426\n",
      "  0.02423629  0.04961492  0.00164332 -0.02312557  0.04850696 -0.05426551\n",
      " -0.03390833  0.009533    0.03277924  0.05443885  0.05048668 -0.03084977\n",
      " -0.00392031  0.04742486  0.02689571  0.04216355  0.056625    0.03452659\n",
      " -0.05675862  0.05509256 -0.0439727   0.02864201  0.05275982  0.04895553\n",
      " -0.05647977  0.03401364 -0.05515054 -0.04855385 -0.01953275  0.00480599\n",
      "  0.05132729 -0.05439515 -0.03478332 -0.05524455  0.05474291  0.05487764\n",
      "  0.05631793 -0.05588815  0.01409779 -0.05314312 -0.04885961 -0.05441074\n",
      " -0.00153337 -0.05658538  0.03281993 -0.05656577 -0.05224532  0.05339254\n",
      "  0.01030181 -0.05384607 -0.05401232 -0.02971963 -0.02026802  0.04322752\n",
      " -0.04721549  0.0568298  -0.04565873 -0.05553498 -0.05578822  0.01002185\n",
      " -0.03299073 -0.05588822  0.03710052 -0.05075877  0.05607574  0.03584712\n",
      "  0.05677179  0.02978992  0.01835582  0.01457273  0.02142989  0.02546138\n",
      "  0.04944101 -0.05686384 -0.05680715 -0.05409811  0.04275072  0.05543181\n",
      "  0.05271965 -0.05127601 -0.05660573 -0.01289179  0.04464551 -0.04952431\n",
      " -0.05639667 -0.05299452 -0.05377971 -0.0355716   0.05532487  0.0216367\n",
      " -0.05685361 -0.0073579  -0.03946688 -0.02344857  0.05251954  0.05685284\n",
      "  0.05420518 -0.05620978 -0.04077866 -0.05152148 -0.05685705 -0.05637706\n",
      " -0.01880272  0.02061755  0.0453471   0.05554039  0.05448594  0.01606592\n",
      "  0.04473599 -0.05676066  0.05586407 -0.05686356 -0.04615042  0.04348307\n",
      " -0.01702188  0.05495266 -0.04508484 -0.05455212 -0.04414323  0.05580997\n",
      " -0.05674859 -0.04902766  0.02966292  0.0386963   0.05027972 -0.0567549\n",
      " -0.01329017 -0.0122939  -0.00879588  0.0567855  -0.04277759 -0.01174881\n",
      "  0.05601025 -0.05253184  0.05677465 -0.05079494  0.05087459 -0.03786492\n",
      "  0.05614839 -0.0548832   0.0498087   0.05579576  0.05404875  0.05661477\n",
      "  0.04977735  0.05601716 -0.05596035  0.0358641  -0.05646349 -0.03353928\n",
      " -0.05652782 -0.03547963 -0.05320703 -0.05680935  0.0551437  -0.05680828\n",
      " -0.03269525  0.0544454  -0.05465392  0.02839665 -0.04798332 -0.05669513\n",
      "  0.02558979 -0.0562583   0.05608778  0.00577659 -0.05573328  0.02750342\n",
      "  0.05682867 -0.05331158 -0.05677471  0.05624802 -0.0561447   0.05575473\n",
      "  0.03255399 -0.05670391  0.04807302 -0.04161501  0.05259317  0.05326949\n",
      "  0.04840178  0.05674741 -0.04347431 -0.03006557  0.02895175  0.05047724\n",
      "  0.05651329 -0.0434501  -0.05499253  0.04381117  0.01368715 -0.00714262\n",
      "  0.05674126 -0.02055698 -0.04241116  0.01908504 -0.00190885 -0.05356781\n",
      " -0.02670623  0.02891831  0.05682365  0.03980712 -0.05167837  0.05669427\n",
      " -0.00613787 -0.04362975 -0.05504671  0.00898444  0.01495874 -0.02150487\n",
      "  0.0332751   0.03765778 -0.05495345 -0.02783719  0.00206791  0.04226835\n",
      " -0.00263936  0.0482798   0.05260134  0.01561037 -0.05610687  0.05644053\n",
      " -0.05572386 -0.04528933 -0.03430781 -0.0362942   0.05142272  0.05340838\n",
      "  0.0558171  -0.0080241  -0.04981211 -0.05685357  0.0563691  -0.05259731\n",
      " -0.01254373 -0.04696663  0.01663625  0.04549456  0.0568171   0.04214612\n",
      "  0.05647432  0.0387068  -0.03467861 -0.04965739  0.00556123 -0.00883566\n",
      "  0.05594587  0.05123855 -0.03422193  0.00082151 -0.04282563  0.01872276\n",
      " -0.05489152  0.04072762 -0.04601786  0.04389492 -0.03982656  0.05535438\n",
      "  0.05638548 -0.0348309  -0.02454707  0.05682808 -0.04066426 -0.04929024\n",
      " -0.03219156 -0.04034818 -0.04851759 -0.02535167  0.05647711  0.0171617\n",
      " -0.04504711 -0.05684933 -0.0551364  -0.05457583 -0.00930805 -0.03194806\n",
      "  0.05630921 -0.03040944 -0.05651911 -0.04441059 -0.05598392  0.05662603\n",
      " -0.0319781   0.02928312  0.03172712 -0.03377679 -0.04546403 -0.033726\n",
      "  0.03899534  0.05409586  0.00499789 -0.02441658  0.04232712  0.03160453\n",
      "  0.05540241  0.0378384   0.00072389 -0.02915572  0.01048217  0.05326036\n",
      "  0.05180778  0.0216904   0.0275816   0.00793395 -0.0360522   0.0537535\n",
      "  0.04305958  0.05486768  0.056512    0.05504811  0.0187085  -0.04928751\n",
      "  0.05678633 -0.0160486   0.01981033 -0.02489838  0.05527968 -0.0568327\n",
      " -0.04041376 -0.03145496  0.03741443 -0.02378714 -0.04491391 -0.05503916\n",
      " -0.05664239 -0.05073369 -0.05353039  0.05680083  0.05247037 -0.02270816\n",
      " -0.004659    0.03296679 -0.05474103 -0.05473065 -0.05596552 -0.00735696\n",
      " -0.0135236  -0.01873536 -0.05377724 -0.01754338 -0.0106095   0.02139281\n",
      "  0.05664711  0.05635059  0.03858208  0.009913    0.05447444 -0.05686241\n",
      " -0.01823936 -0.05661782 -0.0557564   0.00189757 -0.05679226 -0.05657675\n",
      "  0.01721353 -0.05323407  0.0566245   0.02782708 -0.05523834 -0.00246168\n",
      " -0.00903111 -0.05252172  0.0291273  -0.03410778 -0.03126389 -0.04016232\n",
      "  0.04389479  0.017784    0.05428491  0.05583313 -0.05183011 -0.03315704\n",
      "  0.05634193  0.0194157   0.04696694  0.00693607 -0.03161018 -0.05512359\n",
      "  0.05684664  0.05655087  0.05536031 -0.05682424  0.05576677  0.05685296\n",
      " -0.01471134 -0.05187036 -0.05234827  0.05292941 -0.05519705 -0.03783018\n",
      " -0.05432748  0.04053634  0.01931187 -0.00812234  0.05187998  0.05597354\n",
      "  0.05682147  0.01298713  0.02494722  0.04769717  0.05303349  0.05270398\n",
      "  0.04464711  0.0471136  -0.05117119 -0.04382453 -0.02882067 -0.02166134\n",
      "  0.05665449 -0.00418368 -0.02388124  0.04689482 -0.04042552  0.01768196\n",
      "  0.04194227  0.0226609   0.02014199 -0.00757774  0.05267942  0.05064243\n",
      "  0.05553306  0.0041507  -0.04594652 -0.05622537  0.02319571  0.05640781\n",
      "  0.00087707 -0.03839893  0.05638886  0.00981326  0.05638236  0.00867747\n",
      " -0.05675557 -0.05433893  0.05116492 -0.0349814  -0.05100018 -0.02920358\n",
      " -0.04984138 -0.01901593 -0.02611644 -0.05587972  0.02838175 -0.04813928\n",
      " -0.04583557  0.05550933  0.05660204  0.00081451 -0.05686163  0.04800044\n",
      "  0.01302193 -0.05661777 -0.04726049 -0.0448642   0.04637852 -0.0168864\n",
      "  0.0543339  -0.01940586  0.05291132 -0.04051561 -0.0528341   0.05175284\n",
      "  0.05661711 -0.05686282  0.04089522  0.03792392 -0.05158578 -0.05542913\n",
      " -0.0480663  -0.0561756  -0.01706768  0.00313707 -0.05555438  0.04710651\n",
      " -0.0389756   0.05686387  0.05168333  0.05618296  0.05334899 -0.05604164\n",
      " -0.02491896 -0.05632992 -0.03232662 -0.05023864  0.03499633 -0.00977043\n",
      "  0.03375904  0.05650403  0.03744106 -0.05652542 -0.05632544  0.0366356\n",
      "  0.03683221 -0.05259031 -0.03373561 -0.05608906  0.0386862  -0.05543337\n",
      " -0.05682001 -0.05586529  0.02821129 -0.0424305   0.00543138  0.03944864\n",
      " -0.03332467 -0.02730652]\n",
      "[-3.40819545e-02 -5.17089628e-02 -2.30872333e-02  4.54305597e-02\n",
      " -5.73511459e-02 -5.55852391e-02 -5.38202599e-02 -5.74170128e-02\n",
      "  5.67932576e-02  4.82030660e-02  1.64879188e-02 -2.86357012e-02\n",
      " -5.27475141e-02  4.25427780e-02 -8.65841936e-03  5.28340489e-02\n",
      " -2.23506447e-02  4.93760780e-02  5.83726279e-02  5.12394346e-02\n",
      "  7.50667928e-03 -3.80178913e-02  4.95547131e-02 -4.59261127e-02\n",
      " -5.85239418e-02  5.85186556e-02 -8.33408255e-03 -4.85556796e-02\n",
      "  7.68052833e-03  2.17157584e-02  6.86484389e-03 -4.18537706e-02\n",
      " -5.66502623e-02 -2.13461481e-02 -5.74530065e-02 -2.83268560e-02\n",
      "  5.74431419e-02 -5.57237677e-02 -2.37471201e-02  5.04991934e-02\n",
      " -5.50720580e-02  4.03495133e-02  5.76697886e-02 -3.33164074e-02\n",
      " -3.90273035e-02  1.60742905e-02 -5.28986864e-02 -5.33115417e-02\n",
      "  1.76898446e-02 -5.84862195e-02 -1.14311567e-02 -3.07469945e-02\n",
      " -5.19616082e-02  5.65679260e-02 -9.21364917e-05 -5.84877618e-02\n",
      " -5.66748865e-02  4.30946276e-02 -1.55879455e-02  3.62146571e-02\n",
      " -2.56136749e-02  5.84724545e-02 -5.76488078e-02 -2.42203865e-02\n",
      "  4.23367321e-02  3.35112289e-02  3.99531610e-02 -5.02892844e-02\n",
      " -5.59192821e-02 -3.06983013e-02  3.73510718e-02  5.13824672e-02\n",
      "  5.69067486e-02  4.21630740e-02  5.39784059e-02 -5.55632077e-02\n",
      "  5.79398759e-02  5.45426719e-02 -5.07349372e-02 -5.86514547e-02\n",
      " -5.75561002e-02 -3.87081392e-02  1.84274465e-02  5.23211360e-02\n",
      " -4.31485549e-02 -5.18495440e-02 -5.78475446e-02  3.37553062e-02\n",
      "  4.59134355e-02 -5.44484481e-02 -4.56077643e-02 -3.57285291e-02\n",
      " -2.53388509e-02 -5.85722066e-02  3.68003920e-02 -3.47124934e-02\n",
      " -5.67768030e-02  5.49088530e-02  5.76462857e-02 -5.76616563e-02\n",
      "  5.80370128e-02  5.86481504e-02  5.28480038e-02 -4.98759933e-02\n",
      "  1.61676835e-02 -4.40788716e-02 -5.46566546e-02 -5.33350036e-02\n",
      " -4.76362444e-02 -1.09350234e-02 -2.87077390e-02 -5.79737946e-02\n",
      "  4.84323911e-02  4.55055796e-02 -2.56190188e-02  2.22777035e-02\n",
      " -5.25797531e-02 -5.27923368e-02 -5.46071194e-02 -4.44643311e-02\n",
      "  1.34796649e-03  5.72570600e-02  2.07785368e-02 -1.84527524e-02\n",
      "  5.66618964e-02 -8.29804689e-03 -4.62636985e-02  5.37607297e-02\n",
      " -3.34755145e-02  4.78627905e-02 -1.93178263e-02 -5.71224429e-02\n",
      " -5.85106090e-02 -4.94493879e-02  5.44535741e-02  5.81007786e-02\n",
      " -4.70455401e-02 -4.38467180e-03  2.60789525e-02 -5.84149510e-02\n",
      " -5.78171872e-02 -5.74291460e-02  5.86503036e-02 -1.69089418e-02\n",
      "  5.81192896e-02  1.74887236e-02  4.61951792e-02  5.84741682e-02\n",
      "  2.38698106e-02 -4.31218073e-02  5.85542992e-02  5.75503148e-02\n",
      "  1.81687977e-02 -4.88520712e-02 -1.74249765e-02 -2.74141766e-02\n",
      " -5.80882654e-02 -5.71181811e-02  2.63919719e-02 -5.86527437e-02\n",
      "  5.69302998e-02 -2.58965101e-02 -5.75929731e-02  4.95240651e-02\n",
      " -2.83701457e-02 -5.05004935e-02 -4.29881886e-02 -5.03503866e-02\n",
      "  2.14007590e-02 -3.70127819e-02  2.95746028e-02  2.68319971e-03\n",
      " -3.74197699e-02 -1.57208741e-03 -4.29206975e-02 -4.91365865e-02\n",
      " -5.51537015e-02  5.82500622e-02 -5.34888580e-02  5.68597950e-02\n",
      "  4.18691635e-02 -5.82319424e-02  4.30319495e-02  2.09322907e-02\n",
      " -5.63077740e-02  1.37201864e-02  4.22730520e-02  5.83512224e-02\n",
      "  4.97305989e-02  5.73493615e-02  5.66017739e-02 -4.59361002e-02\n",
      "  5.95683279e-03  2.89384648e-02 -5.83688729e-02  5.64673953e-02\n",
      " -5.57069890e-02  1.03411647e-02  5.85356206e-02 -8.80012847e-03\n",
      " -5.84287010e-02 -5.36819920e-03  3.46249528e-02 -4.77038622e-02\n",
      "  3.95477638e-02 -4.77918684e-02  5.70451804e-02 -4.63104621e-02\n",
      "  2.62904800e-02  3.24727483e-02  9.63104703e-03  5.42646833e-02\n",
      " -5.57138585e-02 -5.73683493e-02  5.46445400e-02  1.15887560e-02\n",
      "  5.81486821e-02 -4.32135398e-03 -5.72310649e-02  4.49712984e-02\n",
      " -4.21946906e-02  5.63504919e-02  4.97373790e-02 -2.29474320e-03\n",
      "  5.49741015e-02 -9.84422956e-03 -4.57744673e-02  4.48823720e-02\n",
      " -2.01178361e-02  4.06570546e-02  1.46818589e-02 -4.71863449e-02\n",
      " -5.56691848e-02  5.85670881e-02 -8.91973637e-03 -5.53598851e-02\n",
      " -4.91400473e-02 -4.04463969e-02  5.77809699e-02 -5.84143139e-02\n",
      "  1.85925290e-02 -5.18933609e-02 -3.59343588e-02  4.38394956e-02\n",
      "  5.73894233e-02  3.06594856e-02  4.74482998e-02  5.78311123e-02\n",
      "  3.55388504e-03 -5.13347052e-03 -1.72009319e-02 -4.82259504e-02\n",
      "  5.84563389e-02 -2.51305420e-02 -3.08470391e-02  5.72574772e-02\n",
      " -4.39585559e-02  5.52681126e-02  1.70043893e-02  4.92698662e-02\n",
      " -3.82526815e-02 -4.23448682e-02 -3.40173580e-02  5.72549850e-02\n",
      "  5.11029847e-02 -1.65691948e-03 -5.82918525e-02  5.32527342e-02\n",
      "  4.73163873e-02  4.80427742e-02 -2.46047080e-02 -3.02422624e-02\n",
      "  2.32750899e-03  5.14358990e-02  9.96679068e-03  5.84507696e-02\n",
      " -3.48844007e-02 -3.05965655e-02 -5.80315478e-02 -1.17497072e-02\n",
      "  3.20591591e-03 -5.57789467e-02  2.10613050e-02 -5.84629402e-02\n",
      " -5.83739057e-02  4.24919091e-02  6.53672358e-03  5.58529496e-02\n",
      " -4.95680235e-02  2.06627268e-02 -3.79887931e-02 -5.43539673e-02\n",
      " -5.49760051e-02  4.51372266e-02  5.78189716e-02  5.46998680e-02\n",
      " -2.82784868e-02  3.74313928e-02  1.50223146e-03  5.86416312e-02\n",
      "  5.78983910e-02 -3.67867835e-02 -3.79415900e-02 -1.81865133e-02\n",
      " -1.33345900e-02  2.23671971e-03  5.42935468e-02  5.65657057e-02\n",
      "  3.05180289e-02  1.96940023e-02 -5.55142872e-02  3.95074189e-02\n",
      "  3.47994082e-02 -1.86991144e-03  5.85858822e-02  5.85243814e-02\n",
      " -1.91768371e-02 -4.96012643e-02  5.61022162e-02 -5.51814139e-02\n",
      "  5.84579110e-02  3.07107549e-02 -4.78387922e-02 -5.48692420e-02\n",
      " -4.94412445e-02 -9.80413426e-03  4.34672795e-02 -2.93992441e-02\n",
      " -5.80208898e-02  1.39629357e-02 -4.84883264e-02 -1.71500258e-02\n",
      " -5.59824631e-02  5.83235770e-02  5.06428070e-02 -3.81951518e-02\n",
      " -2.05941796e-02 -4.25818749e-02 -1.13553507e-02 -3.08532231e-02\n",
      " -5.73150888e-02 -4.63538878e-02 -4.95991446e-02 -5.23416400e-02\n",
      "  5.66254966e-02  5.45897409e-02 -2.65505034e-02 -4.57643569e-02\n",
      "  5.83802462e-02  5.34313433e-02  5.49608283e-02  4.33895625e-02\n",
      " -3.60647067e-02 -9.78226867e-03 -5.34136705e-02 -5.46282716e-02\n",
      " -5.76478429e-02  1.12318862e-02 -2.91010016e-04 -5.59077747e-02\n",
      "  3.33165340e-02 -1.99577655e-03  5.70669584e-02 -2.78753806e-02\n",
      " -5.81029058e-02  4.95655499e-02 -5.85999750e-02  2.45617833e-02\n",
      "  5.61202951e-02  4.04366925e-02  5.40700965e-02 -9.74328868e-05\n",
      " -2.59658005e-02 -4.56799194e-02 -2.14176886e-02  5.86304441e-02\n",
      " -2.62669120e-02 -5.13624437e-02  1.95540227e-02 -5.02701402e-02\n",
      "  4.33921367e-02  3.24641280e-02  4.33720499e-02 -1.55302684e-03\n",
      "  4.79589105e-02 -1.09997643e-02  1.54168839e-02 -5.86513616e-02\n",
      "  5.48513234e-02  4.14517783e-02 -3.41697745e-02 -6.40830491e-03\n",
      " -3.33298324e-03  4.50298563e-02 -5.79577275e-02 -5.77808842e-02\n",
      " -8.40731710e-03  5.85643053e-02  4.02276665e-02  2.78052371e-02\n",
      "  2.69949101e-02  5.65936007e-02  5.61591610e-02  4.65545021e-02\n",
      "  5.77911809e-02  5.65983430e-02  2.94354353e-02  9.27972491e-04\n",
      " -2.94317994e-02  3.24147679e-02  5.21944910e-02 -3.47256064e-02\n",
      "  4.60717343e-02 -4.88434955e-02 -2.97207907e-02  3.52746807e-02\n",
      "  3.13354507e-02  4.26665805e-02 -5.46356514e-02  5.30438460e-02\n",
      "  5.80475293e-02 -9.73804016e-03  2.50384375e-03  5.72490692e-02\n",
      "  5.59542067e-02 -4.05978458e-03 -1.41235553e-02 -7.30877137e-03\n",
      " -2.96897180e-02 -4.24236804e-02 -9.90008563e-03 -5.10836728e-02\n",
      " -5.85524850e-02 -3.59909423e-03  5.03037609e-02  3.50161716e-02\n",
      "  5.85575439e-02  5.83471023e-02 -5.71865961e-02 -4.29064110e-02\n",
      " -3.31979357e-02  2.46647429e-02  5.62303104e-02  6.01365324e-03\n",
      " -5.33155613e-02 -3.52457277e-02 -5.77320419e-02 -5.02704605e-02\n",
      " -5.82060702e-02 -3.81657705e-02  2.45444030e-02 -5.00371046e-02\n",
      "  5.74007370e-02  4.58339490e-02 -5.46743944e-02  4.82888222e-02\n",
      "  5.13090342e-02 -1.67288948e-02 -3.31584774e-02 -1.24259079e-02\n",
      "  7.65779754e-03 -5.34026250e-02  5.07829115e-02 -5.04861772e-02\n",
      "  9.66447592e-03 -4.90255356e-02 -4.75698970e-02 -5.06927073e-02\n",
      "  4.99162078e-02 -5.86053804e-02  5.71644306e-02  5.37753552e-02\n",
      " -5.82648292e-02  5.07338569e-02  1.51468487e-02 -3.23018953e-02\n",
      " -5.71567900e-02 -4.09838138e-03 -5.19513041e-02 -5.76676503e-02\n",
      "  5.63030019e-02  5.86528145e-02 -3.45439911e-02  3.66402157e-02\n",
      "  2.39221416e-02 -1.08007519e-02  1.14930579e-02 -5.85594922e-02\n",
      " -5.83243370e-02 -5.63665144e-02  1.46974912e-02  5.33026867e-02\n",
      "  5.84402643e-02  5.09569645e-02  5.43675348e-02 -3.37691717e-02\n",
      " -5.84718250e-02  2.44261790e-02  4.77690324e-02 -2.86499457e-03\n",
      "  1.36320712e-02 -5.84861338e-02  1.79009624e-02  3.96402329e-02\n",
      " -5.85048199e-02 -5.84338568e-02 -5.69968335e-02 -5.84134497e-02\n",
      " -5.81981391e-02  3.17648351e-02  5.31385317e-02 -2.67889649e-02]\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(tm_model.cluster.labels_):\n",
    "    #print(label)\n",
    "    if label == 1:\n",
    "        print(tm_model._get_document_vectors()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 512)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_model.topic_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 512)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_model._get_document_vectors().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otDEGL3TNQ1n"
   },
   "source": [
    "- topic_words: For each topic the top 50 words are returned, in order of semantic similarity to topic.\n",
    "\n",
    "- word_scores: For each topic the cosine similarity scores of the top 50 words to the topic are returned.\n",
    "\n",
    "- topic_nums: The unique index of every topic will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "B8ZdncdKeJiX"
   },
   "outputs": [],
   "source": [
    "# # !pip install hickle\n",
    "# import hickle as hkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepo.topic_model import TopicModel\n",
    "from prepo import utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>contents</th>\n",
       "      <th>url</th>\n",
       "      <th>crawl_at</th>\n",
       "      <th>is_news</th>\n",
       "      <th>clip_at</th>\n",
       "      <th>contents_prep</th>\n",
       "      <th>contents_prep_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bivariate Probit and Logit Models</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThere are no videos fo...</td>\n",
       "      <td>https://sites.google.com/site/econometricsacad...</td>\n",
       "      <td>2020-11-04 12:36:11.015926</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-05 13:58:24</td>\n",
       "      <td>bivariate probit and logit models . there are ...</td>\n",
       "      <td>bivariate probit and logit models . there are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variance inflation factor</td>\n",
       "      <td>None</td>\n",
       "      <td>In statistics, the variance inflation factor (...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Variance_inflati...</td>\n",
       "      <td>2020-11-04 12:36:12.470149</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-05 14:09:24</td>\n",
       "      <td>variance inflation factor . in statistics , th...</td>\n",
       "      <td>it turns out that the square of this standard ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Statistical Analysis with Missing Data</td>\n",
       "      <td>None</td>\n",
       "      <td>Praise for the First Edition of Statistical An...</td>\n",
       "      <td>http://onlinelibrary.wiley.com/book/10.1002/97...</td>\n",
       "      <td>2020-11-04 12:36:13.857509</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-05 17:24:55</td>\n",
       "      <td>statistical analysis with missing data . prais...</td>\n",
       "      <td>statistical analysis with missing data . prais...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>DATA ANALYSIS NOTES: LINKS AND GENERAL GUIDELI...</td>\n",
       "      <td>https://www.princeton.edu/~otorres/Stata/statn...</td>\n",
       "      <td>2020-11-04 12:36:18.837473</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-08 22:23:54</td>\n",
       "      <td>data analysis . data analysis notes : links an...</td>\n",
       "      <td>!! data analysis : annotated output exploring ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>고지방 식이가 뇌에도 영향을 준다?</td>\n",
       "      <td>2017-11-05 01:00:11+09:00</td>\n",
       "      <td>지방은 사실 반드시 필요한 영양소다. 여러 필수 지방산은 우리가 생존하는 데 있어 ...</td>\n",
       "      <td>http://ppss.kr/archives/47698</td>\n",
       "      <td>2020-11-04 12:36:23.706657</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-11-09 01:26:38</td>\n",
       "      <td>고지방 식이 가 뇌 에 도 영향 을 준다 ? . 지방 은 사실 반드시 필요 한 영양...</td>\n",
       "      <td>루이지애나 주립 대학 의 연구자 들 은 저널 ‘ biological psychiat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>MULTI GPU환경에서 ETRI 한국어 BERT모델 활용한 Korquad 학습 방법</td>\n",
       "      <td>None</td>\n",
       "      <td>We use optional third-party analytics cookies ...</td>\n",
       "      <td>https://github.com/domyounglee/korbert-mecab-m...</td>\n",
       "      <td>2020-11-04 12:51:16.270920</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-15 20:21:09</td>\n",
       "      <td>multi gpu 환경 에서 etri 한국어 bert 모델 활용 한 korquad ...</td>\n",
       "      <td>multi gpu 환경 에서 etri 한국어 bert 모델 활용 한 korquad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>NLP 비전공자가 챗봇 프로젝트를 구현하기까지</td>\n",
       "      <td>2019-11-16 16:12:00+09:00</td>\n",
       "      <td>안녕하세요. Universtiy of California, San Diego에서 P...</td>\n",
       "      <td>https://brunch.co.kr/@ljh0113m/1</td>\n",
       "      <td>2020-11-04 12:51:16.492966</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-15 20:21:56</td>\n",
       "      <td>nlp 비 전공 자 가 챗 봇 프로젝트 를 구현 하 기 까지 . 안녕 하 세요 . ...</td>\n",
       "      <td>우선 , 멀티 캠퍼스 교육 과정 을 통해 각각 의 다른 전공 과 배경 을 가지 고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>Topic Modeling with BERT</td>\n",
       "      <td>2020-10-06 06:48:38.700000+00:00</td>\n",
       "      <td>Image by the author.\\n\\nTopic Modeling with BE...</td>\n",
       "      <td>https://towardsdatascience.com/topic-modeling-...</td>\n",
       "      <td>2020-11-04 12:51:19.294852</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-15 20:24:59</td>\n",
       "      <td>topic modeling with bert . image by the author...</td>\n",
       "      <td>moreover , i wanted to use transformer - based...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>Building a personal knowledge base — Blog — Ki...</td>\n",
       "      <td>None</td>\n",
       "      <td>I try to unload all information that has any m...</td>\n",
       "      <td>https://kirillmaltsev.net/blog/personal-knowle...</td>\n",
       "      <td>2020-11-04 12:51:20.621195</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-19 18:09:14</td>\n",
       "      <td>building a personal knowledge base — blog — ki...</td>\n",
       "      <td>in this blog post , i ’ m going to describe my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>Topic Modeling with BERT</td>\n",
       "      <td>2020-10-05 13:03:29+00:00</td>\n",
       "      <td>Image by the author.\\n\\nTopic Modeling with BE...</td>\n",
       "      <td>https://www.google.co.kr/amp/s/mc.ai/topic-mod...</td>\n",
       "      <td>2020-11-04 12:51:22.993020</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-19 18:25:08</td>\n",
       "      <td>topic modeling with bert . image by the author...</td>\n",
       "      <td>moreover , i wanted to use transformer - based...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0                    Bivariate Probit and Logit Models   \n",
       "1                            Variance inflation factor   \n",
       "2               Statistical Analysis with Missing Data   \n",
       "3                                        Data Analysis   \n",
       "4                                  고지방 식이가 뇌에도 영향을 준다?   \n",
       "..                                                 ...   \n",
       "529    MULTI GPU환경에서 ETRI 한국어 BERT모델 활용한 Korquad 학습 방법   \n",
       "530                          NLP 비전공자가 챗봇 프로젝트를 구현하기까지   \n",
       "531                           Topic Modeling with BERT   \n",
       "532  Building a personal knowledge base — Blog — Ki...   \n",
       "533                           Topic Modeling with BERT   \n",
       "\n",
       "                         publish_date  \\\n",
       "0                                None   \n",
       "1                                None   \n",
       "2                                None   \n",
       "3                                None   \n",
       "4           2017-11-05 01:00:11+09:00   \n",
       "..                                ...   \n",
       "529                              None   \n",
       "530         2019-11-16 16:12:00+09:00   \n",
       "531  2020-10-06 06:48:38.700000+00:00   \n",
       "532                              None   \n",
       "533         2020-10-05 13:03:29+00:00   \n",
       "\n",
       "                                              contents  \\\n",
       "0    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThere are no videos fo...   \n",
       "1    In statistics, the variance inflation factor (...   \n",
       "2    Praise for the First Edition of Statistical An...   \n",
       "3    DATA ANALYSIS NOTES: LINKS AND GENERAL GUIDELI...   \n",
       "4    지방은 사실 반드시 필요한 영양소다. 여러 필수 지방산은 우리가 생존하는 데 있어 ...   \n",
       "..                                                 ...   \n",
       "529  We use optional third-party analytics cookies ...   \n",
       "530  안녕하세요. Universtiy of California, San Diego에서 P...   \n",
       "531  Image by the author.\\n\\nTopic Modeling with BE...   \n",
       "532  I try to unload all information that has any m...   \n",
       "533  Image by the author.\\n\\nTopic Modeling with BE...   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://sites.google.com/site/econometricsacad...   \n",
       "1    https://en.wikipedia.org/wiki/Variance_inflati...   \n",
       "2    http://onlinelibrary.wiley.com/book/10.1002/97...   \n",
       "3    https://www.princeton.edu/~otorres/Stata/statn...   \n",
       "4                        http://ppss.kr/archives/47698   \n",
       "..                                                 ...   \n",
       "529  https://github.com/domyounglee/korbert-mecab-m...   \n",
       "530                   https://brunch.co.kr/@ljh0113m/1   \n",
       "531  https://towardsdatascience.com/topic-modeling-...   \n",
       "532  https://kirillmaltsev.net/blog/personal-knowle...   \n",
       "533  https://www.google.co.kr/amp/s/mc.ai/topic-mod...   \n",
       "\n",
       "                      crawl_at  is_news             clip_at  \\\n",
       "0   2020-11-04 12:36:11.015926    False 2015-11-05 13:58:24   \n",
       "1   2020-11-04 12:36:12.470149    False 2015-11-05 14:09:24   \n",
       "2   2020-11-04 12:36:13.857509    False 2015-11-05 17:24:55   \n",
       "3   2020-11-04 12:36:18.837473    False 2015-11-08 22:23:54   \n",
       "4   2020-11-04 12:36:23.706657    False 2015-11-09 01:26:38   \n",
       "..                         ...      ...                 ...   \n",
       "529 2020-11-04 12:51:16.270920    False 2020-10-15 20:21:09   \n",
       "530 2020-11-04 12:51:16.492966    False 2020-10-15 20:21:56   \n",
       "531 2020-11-04 12:51:19.294852    False 2020-10-15 20:24:59   \n",
       "532 2020-11-04 12:51:20.621195    False 2020-10-19 18:09:14   \n",
       "533 2020-11-04 12:51:22.993020    False 2020-10-19 18:25:08   \n",
       "\n",
       "                                         contents_prep  \\\n",
       "0    bivariate probit and logit models . there are ...   \n",
       "1    variance inflation factor . in statistics , th...   \n",
       "2    statistical analysis with missing data . prais...   \n",
       "3    data analysis . data analysis notes : links an...   \n",
       "4    고지방 식이 가 뇌 에 도 영향 을 준다 ? . 지방 은 사실 반드시 필요 한 영양...   \n",
       "..                                                 ...   \n",
       "529  multi gpu 환경 에서 etri 한국어 bert 모델 활용 한 korquad ...   \n",
       "530  nlp 비 전공 자 가 챗 봇 프로젝트 를 구현 하 기 까지 . 안녕 하 세요 . ...   \n",
       "531  topic modeling with bert . image by the author...   \n",
       "532  building a personal knowledge base — blog — ki...   \n",
       "533  topic modeling with bert . image by the author...   \n",
       "\n",
       "                                     contents_prep_sum  \n",
       "0    bivariate probit and logit models . there are ...  \n",
       "1    it turns out that the square of this standard ...  \n",
       "2    statistical analysis with missing data . prais...  \n",
       "3    !! data analysis : annotated output exploring ...  \n",
       "4    루이지애나 주립 대학 의 연구자 들 은 저널 ‘ biological psychiat...  \n",
       "..                                                 ...  \n",
       "529  multi gpu 환경 에서 etri 한국어 bert 모델 활용 한 korquad ...  \n",
       "530  우선 , 멀티 캠퍼스 교육 과정 을 통해 각각 의 다른 전공 과 배경 을 가지 고 ...  \n",
       "531  moreover , i wanted to use transformer - based...  \n",
       "532  in this blog post , i ’ m going to describe my...  \n",
       "533  moreover , i wanted to use transformer - based...  \n",
       "\n",
       "[534 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_info_prep_df = utils.load_obj(DATA_DIR, 'choi_urls/docs_info_prep_df.pkl')\n",
    "docs_info_prep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Bivariate Probit and Logit Models',\n",
       "  'publish_date': None,\n",
       "  'contents': '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThere are no videos for this topic, but if you understand probit and logit models, you can learn this topic by viewing the handouts and programs.',\n",
       "  'url': 'https://sites.google.com/site/econometricsacademy/econometrics-models/bivariate-probit-and-logit-models',\n",
       "  'crawl_at': Timestamp('2020-11-04 12:36:11.015926'),\n",
       "  'is_news': False,\n",
       "  'clip_at': Timestamp('2015-11-05 13:58:24'),\n",
       "  'contents_prep': 'bivariate probit and logit models . there are no videos for this topic , but if you understand probit and logit models , you can learn this topic by viewing the handouts and programs .'},\n",
       " {'title': 'Variance inflation factor',\n",
       "  'publish_date': None,\n",
       "  'contents': \"In statistics, the variance inflation factor (VIF) is the quotient of the variance in a model with multiple terms by the variance of a model with one term alone.[1] It quantifies the severity of multicollinearity in an ordinary least squares regression analysis. It provides an index that measures how much the variance (the square of the estimate's standard deviation) of an estimated regression coefficient is increased because of collinearity. Cuthbert Daniel claims to have invented the concept behind the variance inflation factor, but did not come up with the name.[2]\\n\\nDefinition [ edit ]\\n\\nConsider the following linear model with k independent variables:\\n\\nY = β 0 + β 1 X 1 + β 2 X 2 + ... + β k X k + ε.\\n\\nThe standard error of the estimate of β j is the square root of the j + 1 diagonal element of s2(X′X)−1, where s is the root mean squared error (RMSE) (note that RMSE2 is a consistent estimator of the true variance of the error term, σ 2 {\\\\displaystyle \\\\sigma ^{2}} ); X is the regression design matrix — a matrix such that X i, j+1 is the value of the jth independent variable for the ith case or observation, and such that X i,1 , the predictor vector associated with the intercept term, equals 1 for all i. It turns out that the square of this standard error, the estimated variance of the estimate of β j , can be equivalently expressed as:[3][4]\\n\\nvar ^ ( β ^ j ) = s 2 ( n − 1 ) var ^ ( X j ) ⋅ 1 1 − R j 2 , {\\\\displaystyle {\\\\widehat {\\\\operatorname {var} }}({\\\\hat {\\\\beta }}_{j})={\\\\frac {s^{2}}{(n-1){\\\\widehat {\\\\operatorname {var} }}(X_{j})}}\\\\cdot {\\\\frac {1}{1-R_{j}^{2}}},}\\n\\nwhere R j 2 is the multiple R2 for the regression of X j on the other covariates (a regression that does not involve the response variable Y). This identity separates the influences of several distinct factors on the variance of the coefficient estimate:\\n\\ns 2 : greater scatter in the data around the regression surface leads to proportionately more variance in the coefficient estimates\\n\\n: greater scatter in the data around the regression surface leads to proportionately more variance in the coefficient estimates n : greater sample size results in proportionately less variance in the coefficient estimates\\n\\n: greater sample size results in proportionately less variance in the coefficient estimates var ^ ( X j ) {\\\\displaystyle {\\\\widehat {\\\\operatorname {var} }}(X_{j})}\\n\\nThe remaining term, 1 / (1 − R j 2) is the VIF. It reflects all other factors that influence the uncertainty in the coefficient estimates. The VIF equals 1 when the vector X j is orthogonal to each column of the design matrix for the regression of X j on the other covariates. By contrast, the VIF is greater than 1 when the vector X j is not orthogonal to all columns of the design matrix for the regression of X j on the other covariates. Finally, note that the VIF is invariant to the scaling of the variables (that is, we could scale each variable X j by a constant c j without changing the VIF).\\n\\nvar ^ ( β ^ j ) = s 2 [ ( X T X ) − 1 ] j j {\\\\displaystyle {\\\\widehat {\\\\operatorname {var} }}({\\\\hat {\\\\beta }}_{j})=s^{2}[(X^{T}X)^{-1}]_{jj}}\\n\\nNow let r = X T X {\\\\displaystyle r=X^{T}X} , and without losing generality, we reorder the columns of X to set the first column to be X j {\\\\displaystyle X_{j}}\\n\\nr − 1 = [ r j , j r j , − j r − j , j r − j , − j ] − 1 {\\\\displaystyle r^{-1}={\\\\begin{bmatrix}r_{j,j}&r_{j,-j}\\\\\\\\r_{-j,j}&r_{-j,-j}\\\\end{bmatrix}}^{-1}}\\n\\nr j , j = X j T X j , r j , − j = X j T X − j , r − j , j = X − j T X j , r − j , − j = X − j T X − j {\\\\displaystyle r_{j,j}=X_{j}^{T}X_{j},r_{j,-j}=X_{j}^{T}X_{-j},r_{-j,j}=X_{-j}^{T}X_{j},r_{-j,-j}=X_{-j}^{T}X_{-j}}\\n\\nBy using Schur complement, the element in the first row and first column in r − 1 {\\\\displaystyle r^{-1}} is,\\n\\nr 1 , 1 − 1 = [ r j , j − r j , − j r − j , − j − 1 r − j , j ] − 1 {\\\\displaystyle r_{1,1}^{-1}=[r_{j,j}-r_{j,-j}r_{-j,-j}^{-1}r_{-j,j}]^{-1}}\\n\\nThen we have,\\n\\nvar ^ ( β ^ j ) = s 2 [ ( X T X ) − 1 ] j j = s 2 r 1 , 1 − 1 = s 2 [ X j T X j − X j T X − j ( X − j T X − j ) − 1 X − j T X j ] − 1 = s 2 [ X j T X j − X j T X − j ( X − j T X − j ) − 1 ( X − j T X − j ) ( X − j T X − j ) − 1 X − j T X j ] − 1 = s 2 [ X j T X j − β ^ ∗ j T ( X − j T X − j ) β ^ ∗ j ] − 1 = s 2 1 R S S j = s 2 ( n − 1 ) var ^ ( X j ) ⋅ 1 1 − R j 2 {\\\\displaystyle {\\\\begin{aligned}&{\\\\widehat {\\\\operatorname {var} }}({\\\\hat {\\\\beta }}_{j})=s^{2}[(X^{T}X)^{-1}]_{jj}=s^{2}r_{1,1}^{-1}\\\\\\\\={}&s^{2}[X_{j}^{T}X_{j}-X_{j}^{T}X_{-j}(X_{-j}^{T}X_{-j})^{-1}X_{-j}^{T}X_{j}]^{-1}\\\\\\\\={}&s^{2}[X_{j}^{T}X_{j}-X_{j}^{T}X_{-j}(X_{-j}^{T}X_{-j})^{-1}(X_{-j}^{T}X_{-j})(X_{-j}^{T}X_{-j})^{-1}X_{-j}^{T}X_{j}]^{-1}\\\\\\\\={}&s^{2}[X_{j}^{T}X_{j}-{\\\\hat {\\\\beta }}_{*j}^{T}(X_{-j}^{T}X_{-j}){\\\\hat {\\\\beta }}_{*j}]^{-1}\\\\\\\\={}&s^{2}{\\\\frac {1}{\\\\mathrm {RSS} _{j}}}\\\\\\\\={}&{\\\\frac {s^{2}}{(n-1){\\\\widehat {\\\\operatorname {var} }}(X_{j})}}\\\\cdot {\\\\frac {1}{1-R_{j}^{2}}}\\\\end{aligned}}}\\n\\nHere β ^ ∗ j {\\\\displaystyle {\\\\hat {\\\\beta }}_{*j}} is the coefficient of regression of dependent variable X j {\\\\displaystyle X_{j}} over covariate X − j {\\\\displaystyle X_{-j}} . R S S j {\\\\displaystyle \\\\mathrm {RSS} _{j}} is the corresponding residual sum of squares.\\n\\nCalculation and analysis [ edit ]\\n\\nWe can calculate k different VIFs (one for each X i ) in three steps:\\n\\nStep one [ edit ]\\n\\nFirst we run an ordinary least square regression that has X i as a function of all the other explanatory variables in the first equation.\\n\\nIf i = 1, for example, equation would be\\n\\nX 1 = α 0 + α 2 X 2 + α 3 X 3 + ⋯ + α k X k + e {\\\\displaystyle X_{1}=\\\\alpha _{0}+\\\\alpha _{2}X_{2}+\\\\alpha _{3}X_{3}+\\\\cdots +\\\\alpha _{k}X_{k}+e}\\n\\nwhere α 0 {\\\\displaystyle \\\\alpha _{0}} is a constant and e is the error term.\\n\\nStep two [ edit ]\\n\\nThen, calculate the VIF factor for β ^ i {\\\\displaystyle {\\\\hat {\\\\beta }}_{i}} with the following formula :\\n\\nV I F i = 1 1 − R i 2 {\\\\displaystyle \\\\mathrm {VIF} _{i}={\\\\frac {1}{1-R_{i}^{2}}}}\\n\\nwhere R2 i is the coefficient of determination of the regression equation in step one, with X i {\\\\displaystyle X_{i}} on the left hand side, and all other predictor variables (all the other X variables) on the right hand side.\\n\\nStep three [ edit ]\\n\\nAnalyze the magnitude of multicollinearity by considering the size of the VIF \\u2061 ( β ^ i ) {\\\\displaystyle \\\\operatorname {VIF} ({\\\\hat {\\\\beta }}_{i})} . A rule of thumb is that if VIF \\u2061 ( β ^ i ) > 10 {\\\\displaystyle \\\\operatorname {VIF} ({\\\\hat {\\\\beta }}_{i})>10} then multicollinearity is high[5] (a cutoff of 5 is also commonly used[6]).\\n\\nSome software instead calculates the tolerance which is just the reciprocal of the VIF. The choice of which to use is a matter of personal preference. .\\n\\nInterpretation [ edit ]\\n\\nThe square root of the variance inflation factor indicates how much larger the standard error increases compared to if that variable had 0 correlation to other predictor variables in the model.\\n\\nExample\\n\\nIf the variance inflation factor of a predictor variable were 5.27 (√5.27 = 2.3), this means that the standard error for the coefficient of that predictor variable is 2.3 times larger than if that predictor variable had 0 correlation with the other predictor variables.\\n\\nImplementation [ edit ]\\n\\nvif function in the car R package\\n\\nfunction in the car R package ols_vif_tol function in the olsrr R package\\n\\nfunction in the olsrr R package PROC REG in SAS System\\n\\nin SAS System variance_inflation_factor function in statsmodels Python package\\n\\nfunction in statsmodels Python package estat vif in Stata\\n\\nReferences [ edit ]\\n\\nFurther reading [ edit ]\",\n",
       "  'url': 'https://en.wikipedia.org/wiki/Variance_inflation_factor',\n",
       "  'crawl_at': Timestamp('2020-11-04 12:36:12.470149'),\n",
       "  'is_news': False,\n",
       "  'clip_at': Timestamp('2015-11-05 14:09:24'),\n",
       "  'contents_prep': 'it turns out that the square of this standard error , the estimated variance of the estimate of β j , can be equivalently expressed as : [ 3 ] [ 4 ] var ^ ( β ^ j ) = s 2 ( n − 1 ) var ^ ( x j ) ⋅ 1 1 − r j 2 , {\\\\ displaystyle {\\\\ widehat {\\\\ operatorname { var } }}({\\\\ hat {\\\\ beta }}_{ j })={\\\\ frac { s ^{ 2 }}{( n - 1 ) {\\\\ widehat {\\\\ operatorname { var } }}( x _{ j })}}\\\\ cdot {\\\\ frac { 1 }{ 1 - r _{ j }^{ 2 }}},} where r j 2 is the multiple r 2 for the regression of x j on the other covariates ( a regression that does not involve the response variable y ) . step two [ edit ] then , calculate the vif factor for β ^ i {\\\\ displaystyle {\\\\ hat {\\\\ beta }}_{ i }} with the following formula : v i f i = 1 1 − r i 2 {\\\\ displaystyle \\\\ mathrm { vif } _{ i }={\\\\ frac { 1 }{ 1 - r _{ i }^{ 2 }}}} where r 2 i is the coefficient of determination of the regression equation in step one , with x i {\\\\ displaystyle x _{ i }} on the left hand side , and all other predictor variables ( all the other x variables ) on the right hand side . . interpretation [ edit ] the square root of the variance inflation factor indicates how much larger the standard error increases compared to if that variable had 0 correlation to other predictor variables in the model .'}]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list, y_list = get_node_locs(in_df)\n",
    "locations = [{'x':x, 'y':y} for x,y in zip(temp1,temp2)]\n",
    "for idx, data in enmerate(user_docs_df[:2].to_dict('records')):\n",
    "    temp.append({'data': data,\n",
    "                'position': locations[idx]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_docs_df = docs_info_prep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-10 18:07:44,503 - top2vec - INFO - Pre-processing documents for training\n",
      "INFO:top2vec:Pre-processing documents for training\n",
      "2020-11-10 18:07:47,259 - top2vec - INFO - Downloading universal-sentence-encoder-multilingual model\n",
      "INFO:top2vec:Downloading universal-sentence-encoder-multilingual model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f3aaf3760e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f3aaf3760e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2020-11-10 18:07:50,565 - top2vec - INFO - Creating joint document/word embedding\n",
      "INFO:top2vec:Creating joint document/word embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 12 calls to <function recreate_function.<locals>.restored_function_body at 0x7f3b9582a680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 12 calls to <function recreate_function.<locals>.restored_function_body at 0x7f3b9582a680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2020-11-10 18:08:46,876 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "INFO:top2vec:Creating lower dimension embedding of documents\n",
      "2020-11-10 18:08:50,409 - top2vec - INFO - Finding dense areas of documents\n",
      "INFO:top2vec:Finding dense areas of documents\n",
      "2020-11-10 18:08:50,430 - top2vec - INFO - Finding topics\n",
      "INFO:top2vec:Finding topics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f3b79033200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f3b79033200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 53s, sys: 45 s, total: 3min 38s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# embedding_model은 tf hub를 사용하여 한 번 받으면 캐싱되어 그 이후에는 재다운 받지 않음\n",
    "# universal-sentence-encoder-multilingual\n",
    "# https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\n",
    "# 16 languages (Arabic, Chinese-simplified, Chinese-traditional, English, French, German, Italian, Japanese, Korean, Dutch, Polish, Portuguese, Spanish, Thai, Turkish, Russian) \n",
    "my_tm_model = TopicModel(user_docs_df['contents_prep'], \n",
    "                   doc_ids=user_docs_df.index,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic_idxes': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "        68, 69, 70, 71, 72]),\n",
       " 'topics_words': array([['matplotlib', 'dataframe', 'multiprocessing', ..., 'computing',\n",
       "         'simulations', 'parameters'],\n",
       "        ['sklearn', '강좌', 'tutorial', ..., 'github', 'elementary',\n",
       "         'teacher'],\n",
       "        ['scientist', 'fiction', 'scientists', ..., 'darwin',\n",
       "         'scientific', 'triggered'],\n",
       "        ...,\n",
       "        ['ssh', 'github', 'stdout', ..., '파이썬', 'implements', 'toolbox'],\n",
       "        ['apk', '컴파일', '컴파일러', ..., 'vtk', 'divided', 'coded'],\n",
       "        ['statistical', 'statistically', 'statistics', ..., 'estimators',\n",
       "         'quantitatively', 'graphql']], dtype='<U15'),\n",
       " 'topic_vectors': array([[-0.05679963, -0.01546854, -0.02621393, ..., -0.0410732 ,\n",
       "         -0.00353565,  0.0369381 ],\n",
       "        [-0.02787645,  0.03232538, -0.01870996, ..., -0.03196584,\n",
       "          0.00633717,  0.01794319],\n",
       "        [ 0.01862625,  0.01766907,  0.00037081, ..., -0.05771567,\n",
       "          0.03381516,  0.05057104],\n",
       "        ...,\n",
       "        [-0.05510569, -0.01897993, -0.00938602, ..., -0.00840072,\n",
       "          0.00642213, -0.01539957],\n",
       "        [-0.00908122,  0.02369968,  0.00763151, ..., -0.01518037,\n",
       "         -0.03169709, -0.01469716],\n",
       "        [-0.06242323,  0.03635243, -0.02661472, ..., -0.03631612,\n",
       "         -0.03755377,  0.01262765]], dtype=float32)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tm_model.get_topics_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_tm_model.get_topics_info()['topics_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'topic_idx': 0,\n",
       "  'topic_words': array(['matplotlib', 'dataframe', 'multiprocessing', 'tensorflow',\n",
       "         'dataset', 'ggplot', 'numpy', 'datasets', 'matlab', 'subprocess',\n",
       "         'computationally', 'lineplot', 'algorithms', 'scatterplot',\n",
       "         'computational', 'computation', 'algorithmic', 'parametric',\n",
       "         '파라미터', 'algorithm', 'correlations', 'correlation', 'mxmatrix',\n",
       "         'sklearn', 'graphql', 'quantitative', 'calculations', 'data',\n",
       "         'computed', 'nonparametric', '회귀분석', 'calculation', 'segmentation',\n",
       "         'integrating', 'morphometry', 'optimize', 'subset', 'integrative',\n",
       "         'optimization', 'bmatrix', '알고리즘', 'multivariate', 'convolutional',\n",
       "         'quantitatively', 'statistics', 'integration', 'optimizing',\n",
       "         'computing', 'simulations', 'parameters'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.67996278e-02, -1.54685425e-02, -2.62139291e-02,  1.01699894e-02,\n",
       "         -3.97130512e-02, -5.64770885e-02,  1.10536600e-02,  1.23515204e-02,\n",
       "          4.61482741e-02,  8.31255969e-03,  3.82925607e-02, -6.80339290e-03,\n",
       "          5.50212041e-02, -8.29468668e-03, -4.00021151e-02,  2.60453522e-02,\n",
       "          1.53215844e-02,  3.73314731e-02,  4.51578274e-02,  3.95651981e-02,\n",
       "          4.99827089e-03,  7.58900773e-03,  1.40906579e-03,  3.96746397e-02,\n",
       "         -5.68318777e-02, -5.57468943e-02,  3.71871218e-02, -2.51191817e-02,\n",
       "          3.60671803e-02, -5.52935041e-02, -4.03246805e-02,  1.43619569e-03,\n",
       "          2.52699526e-03, -5.48331514e-02,  1.64807625e-02,  1.95544567e-02,\n",
       "         -1.54796550e-02, -4.02573720e-02,  1.96881853e-02,  8.68451595e-03,\n",
       "         -1.00033935e-02,  8.98922514e-03, -1.56490318e-02, -3.70849892e-02,\n",
       "         -2.53674537e-02, -4.26840000e-02,  5.35079837e-02, -1.73481405e-02,\n",
       "         -3.39561850e-02,  6.09836960e-03, -4.93847467e-02, -3.92369665e-02,\n",
       "         -9.75969527e-03, -4.92651854e-03,  4.18840423e-02, -5.67832179e-02,\n",
       "         -2.40983833e-02,  2.04626210e-02,  9.24448203e-03,  4.82969768e-02,\n",
       "          8.60192254e-03,  5.38535900e-02, -1.06796417e-02, -3.48298289e-02,\n",
       "          1.85195487e-02, -1.42225754e-02,  9.19285603e-03,  9.01497714e-03,\n",
       "          5.15719689e-02,  6.20557601e-03, -3.28272842e-02,  5.80249261e-03,\n",
       "          9.26262047e-03, -2.12035533e-02, -3.55192088e-02, -2.58607101e-02,\n",
       "          2.01850571e-02,  4.36125696e-02, -2.12892108e-02, -5.69051839e-02,\n",
       "         -5.69232516e-02,  1.63062606e-02, -2.82651465e-02, -1.25616435e-02,\n",
       "          2.22305562e-02, -3.33761945e-02, -3.19635533e-02, -9.24879126e-03,\n",
       "         -4.59142122e-03, -4.02634926e-02, -1.18016510e-03,  7.14593893e-03,\n",
       "         -1.63102765e-02, -4.49604020e-02,  2.73368452e-02,  4.06335331e-02,\n",
       "          1.34116458e-02,  2.16069221e-02,  4.06498872e-02,  4.03615739e-03,\n",
       "          5.17539904e-02,  2.79644001e-02,  1.59699973e-02,  3.24622705e-03,\n",
       "          3.53855118e-02,  1.90074109e-02, -4.65268679e-02, -3.31582241e-02,\n",
       "          3.07255797e-02,  3.91609259e-02,  4.34323360e-04, -5.46524003e-02,\n",
       "         -2.55047879e-03, -4.99971174e-02,  3.69245224e-02,  2.01167446e-02,\n",
       "         -1.77724771e-02,  8.28960352e-03, -3.02838292e-02,  2.06197537e-02,\n",
       "         -2.17677862e-03,  2.45754533e-02,  3.29535380e-02,  4.71650586e-02,\n",
       "          4.12244834e-02, -1.28533971e-02, -8.10952578e-03,  1.89418234e-02,\n",
       "         -2.33610030e-02,  1.18666766e-02, -4.30409051e-02,  1.90752782e-02,\n",
       "          5.68153597e-02, -1.17166783e-03,  1.21237738e-02,  5.05033508e-02,\n",
       "         -2.96404678e-02, -2.23512705e-02,  4.89043929e-02,  5.34680709e-02,\n",
       "         -2.09044758e-02, -3.94243188e-02,  1.67858023e-02,  4.87514492e-03,\n",
       "          6.58764364e-03, -3.10863275e-02, -3.31780128e-02,  5.39196841e-02,\n",
       "          3.50507125e-02,  1.76927878e-03,  3.98301966e-02,  4.11444828e-02,\n",
       "         -1.54571785e-02, -4.56231833e-02,  1.10148462e-02, -2.75163222e-02,\n",
       "         -1.10030901e-02, -7.12995837e-03,  1.82975642e-02, -5.70954662e-03,\n",
       "          4.86728437e-02, -2.11139228e-02,  4.52726185e-02, -7.11376430e-04,\n",
       "         -9.24929697e-03, -2.78841890e-02, -1.32282870e-02, -1.97958350e-02,\n",
       "          5.80846798e-03,  3.25180404e-02,  6.41830312e-03, -4.83835526e-02,\n",
       "          6.88701263e-03, -1.28443644e-03,  2.38757636e-02,  5.44670299e-02,\n",
       "         -5.39549030e-02,  1.28330300e-02, -4.14933227e-02,  4.53282669e-02,\n",
       "          3.63827869e-02, -1.38256606e-02, -1.13009810e-02, -6.70909462e-03,\n",
       "         -4.71543856e-02, -2.95777488e-02,  5.00564016e-02,  5.44995591e-02,\n",
       "         -7.72678433e-03, -2.59673540e-02,  1.24014937e-03, -4.25162502e-02,\n",
       "          5.00657149e-02,  2.08236780e-02,  6.15463918e-03,  2.35243887e-02,\n",
       "         -5.51946945e-02, -1.23997936e-02,  4.83434871e-02,  4.07050960e-02,\n",
       "         -2.70069242e-02,  2.53879726e-02,  9.05461144e-03, -4.22502086e-02,\n",
       "         -2.09917612e-02, -2.22957712e-02,  2.32982896e-02,  8.49223230e-03,\n",
       "         -2.69729402e-02,  2.40823906e-02, -2.20831074e-02, -6.67623128e-04,\n",
       "         -3.95528711e-02, -8.53267126e-03,  5.16889431e-02, -3.11967172e-02,\n",
       "         -7.56035233e-03, -5.32191060e-02,  8.05650558e-03, -4.35676239e-02,\n",
       "         -5.83764678e-03,  4.18818183e-02,  7.23163551e-03, -1.36594493e-02,\n",
       "         -5.62920235e-02,  1.87898148e-02, -4.55382727e-02, -6.23021601e-03,\n",
       "          1.51972314e-02,  2.64928751e-02, -2.26893425e-02,  5.63408099e-02,\n",
       "         -1.12202242e-02, -1.34242349e-03,  1.57604052e-03,  3.21114063e-02,\n",
       "         -2.29072087e-02,  3.76215987e-02,  3.18180621e-02, -4.56070043e-02,\n",
       "          3.75445746e-02,  3.73098478e-02, -2.54746657e-02,  1.42807271e-02,\n",
       "         -7.04563316e-03, -5.67982085e-02,  9.43275355e-03, -1.51263755e-02,\n",
       "          3.09278420e-03, -3.26914079e-02, -3.99425998e-02, -4.56851907e-02,\n",
       "         -1.67219026e-03,  2.71071680e-02, -9.58704762e-03,  1.47528341e-02,\n",
       "         -4.05874895e-03, -1.71088160e-03,  5.28718997e-03, -1.85524989e-02,\n",
       "         -4.81576240e-03,  5.31717390e-03, -3.74003351e-02, -4.53363024e-02,\n",
       "          7.96668697e-03, -5.64266369e-02, -3.07578128e-02,  2.26486987e-03,\n",
       "          2.89810039e-02,  2.58839373e-02, -3.39223258e-02, -4.26028296e-02,\n",
       "         -4.21336405e-02,  3.24072316e-02, -3.12362146e-02, -1.21446382e-02,\n",
       "         -3.94330919e-02,  2.80666649e-02, -3.95796224e-02,  3.89117748e-03,\n",
       "         -2.70577669e-02,  2.94999648e-02,  4.54418547e-02,  8.93976819e-03,\n",
       "         -2.65238918e-02,  3.18363085e-02, -4.98784818e-02, -4.05609310e-02,\n",
       "          7.38692889e-03,  2.07899250e-02,  4.20142114e-02,  2.95990091e-02,\n",
       "          1.77058410e-02,  4.55228500e-02, -5.48222624e-02, -6.39242679e-03,\n",
       "         -4.10063677e-02,  3.53514738e-02,  1.11016096e-03,  5.34637459e-02,\n",
       "         -6.75581768e-03,  1.06325010e-02, -1.71512235e-02, -5.46524823e-02,\n",
       "         -5.05225845e-02, -3.09929699e-02, -3.24286111e-02, -4.91063765e-05,\n",
       "          2.02353634e-02,  1.53887998e-02, -2.36993302e-02,  1.09686768e-02,\n",
       "          2.68458277e-02, -1.68877468e-02,  2.67484579e-02,  2.39047874e-02,\n",
       "          1.75400767e-02, -2.73964144e-02,  2.31148042e-02, -4.12390009e-02,\n",
       "          2.57965047e-02, -2.33903322e-02, -2.67834961e-02, -2.35526524e-02,\n",
       "          2.86304066e-03,  5.48587833e-03, -1.61208361e-02, -3.85834053e-02,\n",
       "         -3.39511111e-02,  1.80262439e-02, -4.93078157e-02, -3.26660983e-02,\n",
       "         -3.26520465e-02, -2.54017990e-02, -1.93320829e-02,  2.70584263e-02,\n",
       "          1.48614896e-02,  2.84992205e-03, -5.68120778e-02, -8.46423022e-03,\n",
       "         -4.09290269e-02, -2.51841033e-03,  3.44665945e-02, -3.74568813e-02,\n",
       "          4.02052514e-03,  2.40032487e-02,  5.05332574e-02,  3.76013643e-03,\n",
       "         -2.40895096e-02,  2.36076280e-03,  4.17103656e-02,  4.89132106e-03,\n",
       "          2.21470860e-03, -4.62887585e-02, -3.18344496e-02, -2.03828551e-02,\n",
       "          4.75420579e-02,  4.36775722e-02, -3.53105962e-02, -5.36588021e-02,\n",
       "          1.84606332e-02, -3.72483805e-02,  4.14428972e-02, -3.79816107e-02,\n",
       "         -3.14361639e-02,  1.55854607e-02,  3.59717645e-02,  4.44247685e-02,\n",
       "         -9.36450530e-03,  2.23633312e-02, -1.65704098e-02,  4.94766571e-02,\n",
       "         -3.46307233e-02,  3.71230319e-02,  3.87535407e-03, -4.29549403e-02,\n",
       "         -3.88500914e-02, -3.28392126e-02, -4.37989943e-02, -2.72374917e-02,\n",
       "         -1.14930039e-02, -4.78131287e-02,  1.45218866e-02, -1.91315450e-02,\n",
       "         -5.06890081e-02,  4.15114723e-02,  4.51064892e-02, -5.61563075e-02,\n",
       "          2.92033739e-02, -1.65627245e-02, -2.32816841e-02, -1.22216521e-02,\n",
       "         -4.11723815e-02,  1.54085997e-02, -2.41916697e-03,  7.09761353e-03,\n",
       "          2.54099555e-02,  2.26731878e-02, -1.66972056e-02,  1.23017849e-02,\n",
       "          4.09875251e-02,  1.12026259e-02,  5.26848659e-02,  1.42772943e-02,\n",
       "         -4.28403206e-02, -1.34631498e-02,  1.64770354e-02, -4.98163737e-02,\n",
       "          3.65518555e-02, -1.63588375e-02,  1.07569702e-03,  2.03282293e-02,\n",
       "          4.44671214e-02, -2.00654846e-02,  3.35455723e-02, -1.08435592e-02,\n",
       "          3.20929177e-02,  4.28957865e-02,  2.17517512e-03,  4.35899682e-02,\n",
       "          4.77672890e-02, -1.64723303e-02,  3.68558504e-02,  3.68761644e-02,\n",
       "          2.08278801e-02,  1.92922689e-02,  3.51627357e-02, -3.35195810e-02,\n",
       "         -1.27981501e-02,  1.69443190e-02, -3.63669358e-02, -9.66065843e-03,\n",
       "         -1.24992300e-02,  1.49047691e-02,  4.25762357e-03, -9.60130990e-03,\n",
       "         -1.03815896e-02,  1.23201200e-04, -5.50421551e-02,  8.44747107e-03,\n",
       "         -4.59832549e-02, -8.93350970e-03,  1.07872263e-02, -5.30481674e-02,\n",
       "         -1.33180069e-02, -4.95904312e-02,  5.02866432e-02, -7.17703300e-03,\n",
       "         -1.67073663e-02,  3.62711474e-02,  4.63005435e-03, -1.72831677e-02,\n",
       "         -3.42781469e-02,  6.27817679e-03, -4.63957712e-02, -3.18682902e-02,\n",
       "          3.97121869e-02,  4.29398231e-02,  1.39440447e-02,  5.18031791e-02,\n",
       "          4.40523308e-03, -5.23354299e-02, -1.65286101e-02, -4.11272645e-02,\n",
       "          1.13734957e-02, -4.88395356e-02, -2.77616046e-02, -4.50319685e-02,\n",
       "          5.58585227e-02, -1.81476939e-02,  4.60748263e-02,  3.11341695e-02,\n",
       "         -4.15346306e-03,  4.66685463e-03, -4.99621518e-02, -3.87737690e-03,\n",
       "          4.88120277e-04, -8.65939818e-03,  1.04340166e-02, -2.66646333e-02,\n",
       "          5.20810299e-02,  5.01371808e-02, -1.94880366e-02, -2.98118481e-04,\n",
       "         -1.56162893e-02, -2.41140742e-02, -1.14611750e-02, -5.68906069e-02,\n",
       "          1.51564581e-02,  7.02176569e-03, -3.20176804e-03,  1.35583831e-02,\n",
       "         -5.80800232e-03, -1.04549816e-02, -6.65340852e-03, -2.83191223e-02,\n",
       "         -8.30992125e-03, -4.55363952e-02,  4.01821025e-02,  2.76928209e-02,\n",
       "          1.69333983e-02, -2.17618980e-02,  5.37460484e-02,  8.38807505e-03,\n",
       "         -2.77305972e-02, -5.68480864e-02, -1.62891056e-02,  1.58295296e-02,\n",
       "          3.28350603e-03, -4.10731956e-02, -3.53565486e-03,  3.69380973e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 1,\n",
       "  'topic_words': array(['sklearn', '강좌', 'tutorial', 'teach', '학습', 'teaching',\n",
       "         'textbooks', 'classes', 'learner', 'taught', 'learning', 'learns',\n",
       "         'courses', 'tensorflow', '클래스', 'learn', '강의', 'basic',\n",
       "         'undergraduate', 'class', '전공', '배울', '연습', '과정',\n",
       "         'multiprocessing', '수업', 'training', 'students', 'faculty',\n",
       "         'student', 'fundamental', 'studying', 'education', 'introduction',\n",
       "         'professor', 'trained', 'techniques', 'resource', 'formation',\n",
       "         'learned', 'ubuntu', 'bootstrap', '공부', 'pdf', 'school', '커널',\n",
       "         'fluent', 'github', 'elementary', 'teacher'], dtype='<U15'),\n",
       "  'topic_vector': array([-2.78764497e-02,  3.23253796e-02, -1.87099613e-02,  3.98227982e-02,\n",
       "          4.57126740e-03, -3.18197384e-02,  1.82363000e-02, -1.82647258e-04,\n",
       "          3.46239433e-02,  2.71359365e-03,  2.10316032e-02,  2.00178567e-03,\n",
       "          1.79926902e-02, -1.34528689e-02, -5.91535084e-02,  1.20864669e-02,\n",
       "          1.18586300e-02, -3.20259929e-02,  1.99191682e-02,  3.93888839e-02,\n",
       "          7.67706661e-04,  2.01436486e-02,  1.45329516e-02,  3.82901691e-02,\n",
       "         -3.47048901e-02, -3.44152190e-02, -3.55729135e-03, -9.60858539e-03,\n",
       "         -2.24907305e-02, -4.61354963e-02, -4.56443056e-02,  7.43781682e-04,\n",
       "          7.04675540e-03, -4.61514927e-02, -1.77508537e-02,  1.43983513e-02,\n",
       "          2.18487363e-02, -3.29425633e-02, -9.26194899e-03, -1.62685048e-02,\n",
       "          1.16112235e-03,  1.20928669e-02, -2.63841823e-03,  3.43094207e-03,\n",
       "         -2.76872646e-02,  4.59156372e-02, -1.80306192e-02, -1.14812497e-02,\n",
       "         -3.02062966e-02,  1.85244195e-02,  1.50569249e-02, -1.44317001e-02,\n",
       "         -1.60809141e-02,  1.54609950e-02,  3.43643539e-02, -5.42754494e-02,\n",
       "          2.92029306e-02,  3.35290167e-03, -1.69482902e-02,  7.18681375e-03,\n",
       "         -5.65718208e-03,  4.83190417e-02,  2.10709125e-02, -2.18849164e-02,\n",
       "          2.08050273e-02,  3.49428831e-03,  3.75434719e-02, -9.62973945e-03,\n",
       "          5.90424985e-03,  2.81218998e-02,  3.44522181e-03,  9.14285239e-03,\n",
       "          1.43792313e-02,  1.85476318e-02,  2.68225335e-02,  1.74646713e-02,\n",
       "         -2.30634101e-02, -2.64241314e-03,  3.31436358e-02, -6.75394759e-02,\n",
       "         -7.10064173e-02, -9.98243317e-03, -4.31089476e-02,  1.28389327e-02,\n",
       "          2.87059397e-02, -2.08793767e-02, -8.39519408e-03, -1.07897073e-02,\n",
       "          4.02939543e-02,  1.16890687e-02, -2.46529561e-02,  1.15807978e-02,\n",
       "          1.23311384e-02, -4.22732942e-02,  3.19904238e-02,  3.14376913e-02,\n",
       "         -4.50533368e-02,  1.44270565e-02, -5.75951580e-03, -2.34412216e-03,\n",
       "          3.22138667e-02,  3.88240553e-02,  5.32146264e-03, -1.83908213e-02,\n",
       "          1.90668516e-02, -3.16719972e-02, -5.72007932e-02,  1.20516494e-03,\n",
       "         -2.13999010e-04,  1.20904809e-02,  9.38756019e-03, -4.27519530e-02,\n",
       "          1.62005145e-02, -1.17864916e-02,  5.49477525e-03, -5.29666729e-02,\n",
       "         -2.47459840e-02,  3.71356718e-02,  1.21632265e-02, -1.04425186e-02,\n",
       "          5.27978688e-03,  3.44512723e-02,  1.81919411e-02,  1.77727155e-02,\n",
       "         -1.73331238e-02, -3.18892114e-02, -3.23978476e-02,  1.55681884e-02,\n",
       "         -5.68468822e-05, -3.62138152e-02, -3.22155505e-02, -2.94484086e-02,\n",
       "          3.93949859e-02,  4.20601591e-02,  6.00362616e-03,  6.17562495e-02,\n",
       "         -9.54321027e-03, -3.59205948e-03,  4.37274091e-02,  9.87301022e-03,\n",
       "         -3.37586412e-03,  1.07141510e-02,  1.90913118e-02,  4.14308794e-02,\n",
       "          3.18637257e-03,  1.12902876e-02,  1.45783070e-02,  2.71545388e-02,\n",
       "         -1.94750517e-03,  3.72262970e-02,  4.04025912e-02,  1.82984211e-02,\n",
       "         -2.51107253e-02, -2.72058658e-02,  2.18845196e-02, -2.07635065e-04,\n",
       "         -3.07016000e-02, -3.10750734e-02, -3.36395204e-02, -2.61705425e-02,\n",
       "          3.30220088e-02, -3.62836546e-03,  1.10045923e-02,  1.04980376e-02,\n",
       "         -7.10955635e-03, -6.00444200e-03, -4.08582995e-03, -2.76137199e-02,\n",
       "          1.96378063e-02,  3.44962552e-02, -1.12840263e-02, -6.54455507e-04,\n",
       "         -1.24993706e-02,  1.45320678e-02, -9.24862269e-03,  6.52165711e-03,\n",
       "         -4.01078612e-02,  1.96261723e-02, -4.29140702e-02,  3.89600284e-02,\n",
       "         -2.53766365e-02,  1.73540860e-02, -2.27226429e-02,  1.33121796e-02,\n",
       "         -4.37390581e-02, -2.18339032e-03,  4.92895879e-02,  4.26880941e-02,\n",
       "         -2.41613723e-02,  3.58168148e-02,  2.88637597e-02,  7.20734941e-03,\n",
       "          4.69541550e-02,  2.20839065e-02, -6.90131541e-03,  2.34657563e-02,\n",
       "         -6.51050871e-03, -1.13102281e-02,  3.23952958e-02,  1.64988376e-02,\n",
       "         -1.85385849e-02, -8.88824835e-03, -3.37165296e-02, -3.52105796e-02,\n",
       "          1.37774181e-02,  1.35093220e-02,  2.83632260e-02, -2.52482444e-02,\n",
       "          2.41091177e-02,  6.14477135e-03, -5.45090344e-03, -1.91638339e-02,\n",
       "         -4.48439308e-02,  6.45207427e-03,  1.72100887e-02,  8.76177195e-03,\n",
       "          1.43029038e-02, -2.20227037e-02, -1.72197912e-02,  7.63039477e-03,\n",
       "         -4.84094629e-03,  3.00540514e-02,  2.02154983e-02, -1.24555966e-02,\n",
       "         -2.09274106e-02, -9.64669697e-03, -4.19153236e-02, -1.40047595e-02,\n",
       "          1.42148118e-02,  1.46590453e-02,  1.82438176e-02,  2.32436564e-02,\n",
       "          1.40402354e-02,  5.94630279e-03,  3.83111797e-02,  3.94914113e-02,\n",
       "         -1.74870361e-02,  2.03690249e-02,  5.54822572e-02, -1.70698799e-02,\n",
       "         -3.89565527e-02, -2.93675922e-02, -4.70688706e-03,  4.60543809e-03,\n",
       "          1.04511445e-02,  6.53051492e-03,  2.84804627e-02, -3.94418277e-02,\n",
       "          9.92783438e-03, -3.69780846e-02, -1.57226790e-02, -2.06953902e-02,\n",
       "          8.13626871e-03, -1.95507035e-02,  1.02945575e-02,  1.10175200e-02,\n",
       "          2.66403519e-02, -9.28416010e-03, -1.57616404e-03,  3.21100354e-02,\n",
       "          8.44056485e-04,  2.27321442e-02, -2.71037556e-02, -2.65876856e-02,\n",
       "          2.09749471e-02, -1.19351558e-02,  3.23181320e-03,  3.08700018e-02,\n",
       "          3.39244828e-02,  1.83869693e-02,  2.11947449e-02, -3.40844840e-02,\n",
       "         -3.66741163e-03, -8.27204064e-03,  2.26729214e-02,  1.08984625e-02,\n",
       "          1.28901098e-02,  7.69188628e-03, -4.30486351e-02, -1.87596418e-02,\n",
       "         -5.24170743e-03, -3.65851889e-03, -1.81715097e-02, -1.02604637e-02,\n",
       "         -2.89113494e-03,  2.06675511e-02, -4.81100939e-02, -7.49040768e-03,\n",
       "         -2.47808639e-02,  8.85781273e-03,  7.42741209e-03,  1.13203842e-02,\n",
       "          8.08851328e-05,  2.54535899e-02, -4.48647328e-02,  9.66411736e-03,\n",
       "         -4.17409725e-02,  2.53101513e-02,  2.33622659e-02,  3.76069285e-02,\n",
       "          2.27723420e-02, -8.92159063e-03,  2.25742767e-03, -3.81514207e-02,\n",
       "          2.56559364e-02, -7.97427632e-03,  2.89422162e-02,  1.48225278e-02,\n",
       "          3.76764908e-02,  2.24972814e-02,  8.18190398e-04, -3.06547973e-02,\n",
       "         -2.05888301e-02, -3.25465053e-02,  4.12814878e-02,  3.89778987e-02,\n",
       "          1.19832968e-02,  8.70438851e-03,  3.52202281e-02, -2.50481386e-02,\n",
       "          2.14403253e-02,  3.40732075e-02, -1.13753416e-02, -4.64980118e-03,\n",
       "          1.03824446e-02, -1.43491812e-02,  1.28151737e-02, -3.27045321e-02,\n",
       "          3.37042585e-02, -1.46231186e-02, -3.75696346e-02,  1.16188638e-02,\n",
       "         -3.17291170e-02, -5.07651530e-02, -1.32896407e-02, -6.58370461e-03,\n",
       "         -6.13539945e-03,  4.58294898e-03, -4.90275882e-02, -1.80815514e-02,\n",
       "         -2.73416974e-02,  2.88856775e-02, -3.65069769e-02, -3.28339357e-03,\n",
       "         -2.39407290e-02,  3.20657552e-03, -7.01921061e-04,  1.66166835e-02,\n",
       "          1.41118094e-02, -7.76720978e-03,  1.31972949e-03,  6.54570234e-04,\n",
       "          7.16006290e-03, -4.17549796e-02, -1.31829344e-02,  9.10133030e-03,\n",
       "          9.30387992e-03,  3.00425589e-02,  1.58553966e-03, -2.21075043e-02,\n",
       "          1.94776747e-02, -1.45940986e-02,  3.43712270e-02, -3.76016237e-02,\n",
       "         -2.28188597e-02,  6.55826926e-03, -5.27924951e-03,  6.10819645e-03,\n",
       "         -3.39907259e-02,  7.35176913e-03,  5.03447838e-04,  1.31154340e-02,\n",
       "         -3.44005413e-02,  2.52353419e-02, -1.10907368e-02, -2.00747326e-02,\n",
       "         -1.63042247e-02, -3.44155170e-02, -7.35386508e-04, -4.52808626e-02,\n",
       "         -2.66020242e-02, -8.93763080e-03,  5.74660208e-03, -2.51983572e-02,\n",
       "         -6.04557479e-03,  5.22860773e-02, -1.54012954e-02, -4.07482944e-02,\n",
       "          3.86706479e-02,  4.56471965e-02, -4.69428115e-03, -5.05657643e-02,\n",
       "         -2.12461483e-02,  3.59831424e-03, -2.20885593e-03, -4.21601012e-02,\n",
       "          1.05439853e-02,  2.10640412e-02, -2.39413790e-02,  6.71619270e-03,\n",
       "          2.39876378e-02,  3.66092995e-02,  2.30412856e-02, -3.08079403e-02,\n",
       "         -2.52453294e-02,  3.10076512e-02, -3.57263442e-03, -3.42469513e-02,\n",
       "          6.53723907e-03,  1.87595654e-02,  1.17653795e-02,  1.10922325e-02,\n",
       "          4.56724241e-02, -2.35856399e-02,  1.07128741e-02,  3.17046270e-02,\n",
       "          6.58022519e-03,  7.98751041e-03, -1.52729964e-02, -6.57087564e-03,\n",
       "          3.26289944e-02,  2.21360475e-02,  5.97848184e-03,  3.28582786e-02,\n",
       "          4.46005203e-02,  1.15660215e-02, -1.59629937e-02, -1.85612552e-02,\n",
       "         -4.35501244e-03, -4.51078750e-02,  2.19054054e-02,  1.56379566e-02,\n",
       "          5.11443242e-04, -1.33399218e-02,  2.44123153e-02,  9.59937461e-03,\n",
       "          1.37261581e-03,  2.07642689e-02, -3.99951376e-02, -2.59372611e-02,\n",
       "         -4.42525074e-02,  3.64915952e-02,  1.52882840e-02, -4.95920144e-02,\n",
       "          1.64605514e-03, -3.10381725e-02,  4.78006452e-02,  2.12399904e-02,\n",
       "          4.36761230e-02,  1.00755626e-02,  3.02797966e-02,  2.79042367e-02,\n",
       "         -2.70903949e-02,  2.04329770e-02, -3.86469774e-02,  3.15755121e-02,\n",
       "          4.59920838e-02, -9.11625661e-03, -2.30676737e-02,  2.54017655e-02,\n",
       "          1.84941776e-02, -8.70632241e-04,  1.15641998e-02, -2.14006454e-02,\n",
       "         -3.55943441e-02, -5.55333346e-02, -3.21459435e-02,  2.19108108e-02,\n",
       "          6.16504252e-02, -2.87519190e-02,  2.54666694e-02,  3.22018377e-02,\n",
       "          6.28533354e-03, -3.53793241e-02, -1.21999010e-02, -2.78775040e-02,\n",
       "          4.56936704e-03, -2.28414219e-03, -2.95968857e-02, -3.15530822e-02,\n",
       "          2.39018202e-02,  3.35574299e-02, -1.15553048e-02,  3.52333412e-02,\n",
       "          2.74917763e-02,  3.40017602e-02,  4.85674152e-03, -6.36199564e-02,\n",
       "         -1.37843983e-02, -1.86428800e-02,  1.72481383e-03,  2.26236004e-02,\n",
       "          2.55679227e-02, -9.58491489e-03, -1.66677628e-02, -7.41285970e-04,\n",
       "         -2.29800679e-02, -6.53965818e-03, -2.87979608e-04,  2.82597318e-02,\n",
       "          1.37251150e-02, -3.17253098e-02,  3.25976945e-02,  1.05618443e-02,\n",
       "         -4.16076519e-02, -3.31113786e-02,  1.12446276e-02, -2.08767578e-02,\n",
       "         -1.06488857e-02, -3.19658369e-02,  6.33717049e-03,  1.79431904e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 2,\n",
       "  'topic_words': array(['scientist', 'fiction', 'scientists', 'literature', '소설', 'writer',\n",
       "         'deviance', 'authors', '문학', 'scholars', '과학자', 'zimbardo',\n",
       "         'professor', 'prisoners', 'scholar', 'author', 'psychological',\n",
       "         'neuroscientist', 'psychiatric', '교수', 'psychosis', '학문',\n",
       "         'neuroscientists', 'neurosciences', 'critically', 'heuristics',\n",
       "         'feminist', 'psychology', '작가', 'parkinsonism', 'perhaps', '저자',\n",
       "         'novel', 'schmitz', 'readers', '논문', 'published', '일종',\n",
       "         'psychiatry', 'plausible', 'neurosci', 'neuroscience', 'harvard',\n",
       "         'neurocultures', 'prison', 'psychotherapy', 'academic', 'darwin',\n",
       "         'scientific', 'triggered'], dtype='<U15'),\n",
       "  'topic_vector': array([ 1.86262485e-02,  1.76690724e-02,  3.70813912e-04, -1.76500026e-02,\n",
       "         -1.32420929e-02,  5.56802675e-02, -5.85669791e-03,  4.19967016e-03,\n",
       "          3.46872993e-02,  1.76373851e-02, -2.58743223e-02,  1.31796498e-03,\n",
       "          5.00702225e-02, -5.72398026e-03, -4.65449952e-02, -2.71550212e-02,\n",
       "         -7.63870263e-03, -5.40957302e-02,  8.28749966e-03,  3.05928458e-02,\n",
       "         -4.25138324e-02, -5.11558242e-02,  5.06251343e-02,  1.48656266e-02,\n",
       "         -5.94146736e-02,  2.09331326e-02,  2.01697219e-02, -8.45281407e-03,\n",
       "          1.18331797e-02, -3.98845673e-02,  2.76725758e-02,  1.70649812e-02,\n",
       "          1.87104531e-02, -2.99101602e-02,  2.09926758e-02, -2.05249973e-02,\n",
       "          7.71724200e-03, -7.58142676e-03, -2.61342935e-02, -3.84222791e-02,\n",
       "         -1.21561410e-02,  1.19642103e-02,  5.66085577e-02,  1.33390035e-02,\n",
       "         -1.45184780e-02,  6.76754222e-04,  2.81645674e-02, -3.87139507e-02,\n",
       "          1.13169095e-02, -2.33649984e-02, -3.01411987e-04, -1.51217831e-02,\n",
       "          1.10796653e-02,  1.71921570e-02,  1.05631370e-02, -5.88753000e-02,\n",
       "          4.42309864e-02, -1.32703213e-02,  1.80252735e-02,  1.18678911e-02,\n",
       "         -1.07237017e-02,  5.71822859e-02,  9.71562881e-03, -5.12542017e-02,\n",
       "         -2.75806971e-02, -7.78038008e-03,  2.22357754e-02, -2.95919590e-02,\n",
       "         -7.82908872e-03,  3.19364704e-02, -1.50735918e-02,  1.71957314e-02,\n",
       "          1.42622339e-02, -2.31992826e-02, -5.76085830e-03,  6.70003286e-03,\n",
       "         -2.60361321e-02,  1.88670936e-03,  1.38350111e-02, -5.95252588e-02,\n",
       "         -5.95270321e-02, -1.43833328e-02, -4.08545882e-02,  3.82074155e-02,\n",
       "         -6.81730360e-03, -1.14405248e-02, -8.52970686e-03, -2.89252922e-02,\n",
       "         -1.38213215e-02,  2.50158142e-02, -4.14674468e-02, -3.35341878e-02,\n",
       "         -4.91435789e-02, -1.94418859e-02,  1.36562800e-02, -7.73131568e-03,\n",
       "          4.81439941e-02,  4.16839942e-02,  4.64058109e-03,  2.85884831e-02,\n",
       "         -2.71608331e-03,  5.10411151e-03, -2.16407087e-02,  1.75472926e-02,\n",
       "         -2.82715587e-03, -3.17187198e-02, -4.32865061e-02,  1.15668830e-02,\n",
       "         -2.06841547e-02,  1.85461026e-02,  3.56607810e-02, -2.43803933e-02,\n",
       "         -1.45572852e-02,  3.05723473e-02,  3.59589942e-02, -2.37782337e-02,\n",
       "          3.90512258e-04, -1.13128368e-02, -1.91892181e-02,  4.23786007e-02,\n",
       "          1.81747489e-02,  4.49815206e-02,  2.16851067e-02,  1.50280036e-02,\n",
       "         -5.84121794e-03,  4.16154750e-02,  7.17809051e-03, -8.47025588e-03,\n",
       "         -2.31164019e-03,  2.31717601e-02, -3.17879394e-02, -1.78941581e-02,\n",
       "         -1.07992196e-03,  1.21301394e-02,  4.24519501e-04,  5.93193360e-02,\n",
       "          8.03107512e-04, -8.74808058e-03,  4.95869406e-02,  1.36586977e-02,\n",
       "          8.38162098e-03,  2.14361846e-02,  1.02557754e-02,  3.20070796e-02,\n",
       "          1.94724221e-02, -1.91231223e-03,  5.08872084e-02, -6.91433111e-03,\n",
       "          2.73476131e-02, -3.97945084e-02,  3.55517678e-02, -2.57032756e-02,\n",
       "         -6.63134363e-03, -1.27019454e-02, -1.45724704e-02,  2.00963952e-03,\n",
       "          7.04935379e-03, -1.64166149e-02, -3.60389240e-02,  1.11110946e-02,\n",
       "          3.57067659e-02, -2.91660242e-02, -1.10502671e-02, -4.34413878e-03,\n",
       "         -2.20317505e-02, -1.39432466e-02,  1.98894572e-02,  2.75196438e-03,\n",
       "         -1.99215654e-02, -1.16919624e-02, -5.02582826e-02,  2.67015155e-02,\n",
       "          1.38551127e-02,  4.09009913e-03, -2.77852491e-02,  3.54101881e-02,\n",
       "         -5.01235649e-02,  2.34711394e-02,  6.00011880e-03,  2.24580746e-02,\n",
       "          8.51922017e-03,  9.48004145e-03,  1.76160410e-02, -3.50764468e-02,\n",
       "         -8.84951092e-03, -5.93831879e-04,  2.05346756e-02,  5.94641902e-02,\n",
       "          3.44298445e-02,  2.60505173e-02, -5.31011308e-03, -3.91643904e-02,\n",
       "          3.62281464e-02, -1.36911832e-02,  7.99026713e-03,  3.39696184e-02,\n",
       "         -2.14425270e-02, -7.08346837e-04, -1.16462372e-02,  9.91821755e-03,\n",
       "         -4.81988769e-03,  1.05875349e-02, -6.14159228e-03, -4.66828533e-02,\n",
       "          2.26191077e-02,  1.25714252e-03,  2.42580548e-02,  3.57399099e-02,\n",
       "          1.78566445e-02,  3.95402685e-02,  7.37281633e-04, -2.53635067e-02,\n",
       "          3.21717858e-02,  5.93053456e-03,  1.81788839e-02,  7.27414759e-03,\n",
       "          1.13937175e-02, -4.80307899e-02,  2.16924604e-02,  7.07909372e-03,\n",
       "         -3.56098600e-02,  6.43578963e-03,  4.48624827e-02,  1.93230174e-02,\n",
       "         -8.31545389e-04, -2.96371970e-02, -1.63377710e-02, -1.05824787e-02,\n",
       "         -4.83552180e-02, -3.22520994e-02,  8.72206129e-03, -4.05953499e-03,\n",
       "         -2.28275340e-02,  1.00545324e-02,  3.34686153e-02, -1.05089778e-02,\n",
       "         -3.28198192e-03,  1.70600209e-02,  4.92954217e-02, -1.84131693e-02,\n",
       "          4.29792213e-04, -6.84242137e-03,  3.26226987e-02,  1.85256656e-02,\n",
       "          2.78751198e-02,  2.16209963e-02,  5.09724841e-02, -1.06941885e-03,\n",
       "          1.28402431e-02, -4.32331767e-03,  9.06995963e-03, -1.78066399e-02,\n",
       "          7.93063361e-03, -2.53524855e-02,  4.33839811e-03, -2.93720019e-04,\n",
       "         -6.97498210e-03,  1.49009433e-02, -2.84298044e-02,  4.39162292e-02,\n",
       "         -2.65138177e-03,  4.38605882e-02, -4.70044138e-03, -1.38560003e-02,\n",
       "          1.31162917e-02, -5.83087578e-02, -1.54869258e-02,  3.19541246e-02,\n",
       "          1.10977911e-03, -2.22860612e-02, -4.68520867e-03,  6.27929228e-04,\n",
       "         -1.38983829e-02, -2.85775289e-02,  4.45591547e-02,  6.86152559e-03,\n",
       "         -1.71109978e-02,  9.59859882e-03, -5.79380989e-02, -3.42498012e-02,\n",
       "         -2.69751344e-02,  2.68726308e-05,  2.76074577e-02,  4.04439634e-03,\n",
       "         -1.05860201e-03,  3.16203944e-02, -4.77750152e-02, -1.00845695e-02,\n",
       "          1.52167128e-02, -9.02425870e-03, -1.24341631e-02,  4.51460741e-02,\n",
       "          1.12131145e-02,  2.95268130e-02,  4.19811979e-02,  3.37273963e-02,\n",
       "          2.41246615e-02, -3.46372515e-04, -1.68170221e-02,  3.64637040e-02,\n",
       "          2.18764450e-02,  2.39526033e-02, -1.13885449e-02, -3.63755040e-02,\n",
       "          4.70109982e-03, -1.54253244e-02, -2.46210024e-02,  4.96390499e-02,\n",
       "          1.93566997e-02, -1.11103598e-02, -2.20410153e-03, -3.99093004e-03,\n",
       "         -9.19608772e-03, -2.61160806e-02,  4.35085185e-02,  4.02692109e-02,\n",
       "          1.64050069e-02, -6.36047509e-04,  1.07903192e-02, -4.39682715e-02,\n",
       "         -7.59429717e-03, -1.80471758e-03, -8.23516923e-04,  3.17645818e-02,\n",
       "         -3.03969588e-02,  6.09833654e-03, -6.68901205e-03, -2.02080682e-02,\n",
       "          5.04908673e-02,  2.75287740e-02, -1.34546692e-02,  1.96790486e-03,\n",
       "         -2.69544427e-03, -3.16727646e-02, -4.86806734e-03,  1.04704974e-02,\n",
       "         -1.12666935e-02, -1.95557121e-02, -5.69648072e-02, -1.55735351e-02,\n",
       "         -2.41593793e-02,  1.62900519e-02, -3.53440866e-02, -3.49337682e-02,\n",
       "         -1.99707057e-02,  9.87410918e-03,  5.31676635e-02, -1.92393623e-02,\n",
       "         -1.58819370e-02, -1.79662630e-02,  3.18362005e-02, -8.39486439e-03,\n",
       "          6.01337943e-03,  9.17110406e-03, -1.69553719e-02,  3.67244193e-03,\n",
       "         -2.24872101e-02,  2.26342063e-02, -3.95237794e-03,  1.79427098e-02,\n",
       "         -1.44143580e-02,  1.15072364e-02,  5.27660847e-02,  3.90671641e-02,\n",
       "          2.15385146e-02, -4.71755397e-03, -7.51845632e-03,  4.99321031e-04,\n",
       "         -1.49832964e-02,  2.56832466e-02, -1.99259594e-02,  4.14817668e-02,\n",
       "          1.49039319e-02,  1.72964390e-02,  1.86922811e-02,  4.30838652e-02,\n",
       "         -5.10016717e-02,  1.41781466e-02,  1.14640407e-02, -2.43015904e-02,\n",
       "         -2.13401727e-02, -2.09558127e-03, -1.00375898e-02,  6.49195863e-03,\n",
       "          1.57231087e-04,  5.95178679e-02, -3.38518037e-03, -5.91997392e-02,\n",
       "          5.92383929e-02,  3.74224894e-02, -5.06350351e-03, -4.81188744e-02,\n",
       "          2.80093811e-02, -2.03383248e-03,  2.47345287e-02,  2.27671340e-02,\n",
       "          2.58334018e-02,  7.38951057e-05,  1.75579209e-02, -1.93080232e-02,\n",
       "          1.19610736e-02,  3.71348821e-02, -1.43179540e-02,  1.42637547e-02,\n",
       "          8.34761304e-04, -5.89327002e-03, -1.46015370e-02, -1.22711370e-02,\n",
       "         -1.80572364e-02,  3.48666869e-02,  5.57534210e-02,  1.06452713e-02,\n",
       "          4.47000489e-02, -1.07573764e-02,  1.48127163e-02,  4.53460738e-02,\n",
       "          2.73427460e-02,  2.56495737e-02, -2.50393618e-02, -1.16277095e-02,\n",
       "          2.68215965e-02,  2.04647072e-02, -2.49902699e-02,  2.17139404e-02,\n",
       "          5.71167246e-02,  3.60561092e-03, -1.39505332e-02,  7.39561301e-03,\n",
       "         -5.15383147e-02, -2.81921076e-03,  4.25705314e-02, -5.11151785e-03,\n",
       "         -2.90804561e-02, -2.28934363e-02,  8.87779333e-03, -3.53919864e-02,\n",
       "          7.42253754e-03, -1.02588497e-02, -5.83785065e-02,  2.13852432e-02,\n",
       "         -1.50456904e-02,  3.99392396e-02,  1.43698566e-02, -5.56760766e-02,\n",
       "          3.72113772e-02,  2.39877794e-02,  5.85139506e-02,  1.87573507e-02,\n",
       "          2.78038494e-02,  2.53415247e-03,  7.89751485e-03,  3.54540348e-02,\n",
       "          1.14413444e-02,  1.06518548e-02, -1.38267241e-02, -8.39461864e-05,\n",
       "          1.25915669e-02,  5.30330511e-03,  2.83764470e-02, -1.16514228e-02,\n",
       "          7.11390562e-03, -2.10631806e-02,  2.88145593e-03, -1.61977336e-02,\n",
       "         -5.90230934e-02, -5.75318672e-02, -4.54568118e-02,  3.31448130e-02,\n",
       "         -3.58218923e-02,  1.48284519e-02, -2.39654835e-02,  4.04901356e-02,\n",
       "         -2.42482908e-02,  1.25986710e-03, -2.96903006e-03,  1.02857053e-02,\n",
       "          3.75774540e-02, -6.41972898e-03, -1.35262432e-02,  6.78290101e-03,\n",
       "          1.71367601e-02,  5.88874109e-02, -3.35683972e-02,  5.11184148e-03,\n",
       "         -1.71501469e-02, -4.21478087e-03, -3.41067947e-02, -5.88423647e-02,\n",
       "         -1.70563627e-02, -4.11707237e-02,  1.66186187e-02,  2.35514063e-02,\n",
       "          4.09766622e-02, -2.72124005e-03,  9.26389452e-03,  3.44288722e-02,\n",
       "         -1.67730097e-02, -7.86677483e-05, -2.80069280e-02, -3.09002266e-04,\n",
       "         -1.11501515e-02, -3.60190347e-02,  5.14206812e-02, -2.36557554e-02,\n",
       "         -5.10717556e-02, -5.60248876e-03, -3.84723126e-06,  1.19275758e-02,\n",
       "         -4.63581197e-02, -5.77156655e-02,  3.38151604e-02,  5.05710393e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 3,\n",
       "  'topic_words': array(['신한은행', '대출', '신용', '융자', '은행원', 'accounting', '은행', '금융', '전세금',\n",
       "         '신청', 'bonds', '계좌', '소득', '급여', '무소득', 'accounted', 'accounts',\n",
       "         'application', '경제', '보증금', 'applications', '방정식', '주식', 'fund',\n",
       "         'documents', '투자', 'shares', 'asset', 'hypotheses', 'payments',\n",
       "         'investment', 'income', 'account', 'credit', '환율', '포트폴리오', '예금',\n",
       "         '기금', '이자', '주택', '영수증', 'benefits', '수수료', 'economic',\n",
       "         'extracellular', 'defaults', '자금', '원금', 'interest', '반환'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-2.44655795e-02,  1.87208820e-02, -4.47691791e-02,  1.02918716e-02,\n",
       "          3.98519114e-02,  3.54162268e-02, -3.91775882e-03, -1.93766095e-02,\n",
       "         -1.92846861e-02,  9.09097586e-03, -2.65773106e-02, -6.07403833e-03,\n",
       "          3.78586613e-02,  7.04554468e-03,  1.57877300e-02,  2.81073507e-02,\n",
       "          1.10865729e-02, -3.56978625e-02,  4.84297797e-02,  5.51064461e-02,\n",
       "          7.90814962e-03, -6.00456726e-03, -2.70422362e-02,  3.01440768e-02,\n",
       "         -5.68384714e-02, -2.31782477e-02, -1.68647524e-02,  1.36405136e-02,\n",
       "          1.75417680e-02, -3.36114913e-02, -1.44672869e-02,  1.44217927e-02,\n",
       "          2.93854382e-02, -3.57233621e-02,  3.20908315e-02, -1.91395283e-02,\n",
       "          2.23917719e-02, -2.77010314e-02,  2.32549105e-02,  4.48017102e-03,\n",
       "         -2.31885128e-02, -2.05973946e-02,  1.97868645e-02,  3.45322751e-02,\n",
       "         -2.04939842e-02, -5.24631143e-02,  1.16144633e-02, -2.51111649e-02,\n",
       "          3.18296440e-02,  6.56016264e-03, -4.24192939e-03,  1.37064205e-02,\n",
       "          9.28398594e-03, -1.84797440e-02,  4.97514419e-02, -5.49539439e-02,\n",
       "          2.24500299e-02, -3.71529460e-02, -2.12843716e-02, -2.19600555e-03,\n",
       "          1.10034738e-02,  5.74329384e-02, -7.06207100e-03, -5.19330008e-03,\n",
       "         -3.50066423e-02,  2.95240227e-02,  3.82095724e-02, -1.82034343e-03,\n",
       "         -1.72073077e-02, -4.19810824e-02,  4.81952820e-03,  1.89728644e-02,\n",
       "          1.18673146e-02,  3.70384101e-03,  1.20833889e-03,  2.78614629e-02,\n",
       "         -2.03398224e-02,  2.48709042e-02,  1.28585165e-02, -5.86372949e-02,\n",
       "         -5.90886921e-02,  6.90173684e-03,  6.09017489e-03,  1.45163490e-02,\n",
       "          7.27756554e-03, -2.58666836e-02, -4.19364199e-02, -3.69445719e-02,\n",
       "          1.02933729e-02, -1.97611074e-03, -4.09190841e-02,  1.11890789e-02,\n",
       "         -1.46574259e-03, -1.73149649e-02,  2.96740495e-02,  1.57708246e-02,\n",
       "          1.98891275e-02,  3.20700519e-02,  3.44792759e-04,  2.20383368e-02,\n",
       "         -1.36023009e-04,  3.38097997e-02,  5.18696755e-03,  1.44733191e-02,\n",
       "          2.63065882e-02, -1.77738164e-02, -4.30266112e-02, -1.07013825e-02,\n",
       "          3.50517556e-02,  5.88737521e-03,  2.38084868e-02,  3.21202446e-03,\n",
       "          2.31813025e-02,  1.56846773e-02,  3.88318412e-02,  4.86937612e-02,\n",
       "          2.40701474e-02,  9.20402672e-05, -5.08890860e-02, -1.56305998e-03,\n",
       "         -8.01112130e-03, -3.40619832e-02,  8.49652663e-03, -1.48555395e-04,\n",
       "          2.15821527e-02, -1.32380985e-02, -3.08856554e-02,  4.05901596e-02,\n",
       "         -3.50395069e-02,  1.25841247e-02, -5.18569872e-02, -3.75722423e-02,\n",
       "          5.04593775e-02,  9.96382907e-03, -3.31403315e-02,  5.88410124e-02,\n",
       "          4.11016913e-03, -3.34851332e-02,  5.15129790e-02, -4.91756052e-02,\n",
       "          2.77593900e-02,  9.83337034e-03, -1.69919953e-02, -1.31354267e-02,\n",
       "          2.61332747e-02, -1.31720835e-02,  2.06881445e-02,  6.48106914e-03,\n",
       "          3.65169756e-02,  2.33458467e-02,  3.20976451e-02, -2.96286843e-03,\n",
       "         -3.44057865e-02,  1.90797374e-02,  3.05220913e-02, -2.47536838e-04,\n",
       "          8.69343244e-03, -3.47413048e-02,  7.62310019e-03, -1.76629182e-02,\n",
       "          3.62418853e-02, -3.49706747e-02,  1.48494411e-02, -1.10303033e-02,\n",
       "          2.86748800e-02, -3.74589637e-02,  2.13385429e-02, -2.13006474e-02,\n",
       "         -7.57466070e-03, -2.99481917e-02,  2.00851634e-02, -1.04767866e-02,\n",
       "         -1.13805884e-03, -1.67716853e-02,  2.39676889e-02,  4.82358970e-02,\n",
       "          2.52343211e-02, -2.66919993e-02,  6.19738130e-03,  3.32216248e-02,\n",
       "          3.80162448e-02, -3.18564288e-02, -2.39881873e-02,  2.58317590e-03,\n",
       "         -2.64653508e-02, -3.13276355e-03,  3.86394821e-02,  5.50050735e-02,\n",
       "          1.09160226e-02, -4.95630279e-02, -1.80922877e-02,  2.15861220e-02,\n",
       "          3.91781703e-02, -2.50428375e-02, -3.97969335e-02,  3.11965682e-02,\n",
       "          3.13841831e-03,  2.09084786e-02,  6.24698214e-03,  7.14677479e-03,\n",
       "         -5.67383599e-03, -3.53284925e-02, -1.40888728e-02, -4.04377207e-02,\n",
       "         -3.09110829e-03, -1.02410624e-02,  1.23901721e-02,  7.86101166e-03,\n",
       "         -1.45471524e-02,  3.69498320e-02,  4.08471795e-03,  1.42767432e-03,\n",
       "         -5.25453575e-02, -1.46077434e-02, -1.43984072e-02, -1.86628755e-02,\n",
       "          3.86741273e-02, -1.84253033e-03, -4.01899852e-02,  2.16142777e-02,\n",
       "         -2.05599964e-02, -3.44385616e-02,  1.27200056e-02, -9.01908055e-03,\n",
       "         -3.12040262e-02, -3.03772204e-02, -1.54688228e-02,  4.81476542e-03,\n",
       "         -9.99605749e-03,  5.57838939e-03,  2.57201158e-02, -5.78875281e-02,\n",
       "          1.33239394e-02,  1.88087579e-02, -8.23560113e-04, -1.27181392e-02,\n",
       "         -1.35735627e-02,  3.69257182e-02,  1.42384972e-02,  3.06083038e-02,\n",
       "         -3.51123437e-02, -3.56521793e-02,  1.92531236e-02, -1.42634660e-02,\n",
       "          5.32873198e-02,  3.41333859e-02,  4.64106910e-02,  1.84647869e-02,\n",
       "          1.60646234e-02, -1.04152756e-02, -8.30734801e-03,  1.11261215e-02,\n",
       "         -3.12823765e-02, -9.28072073e-03,  4.37223306e-03,  1.84221077e-03,\n",
       "         -2.17415532e-03,  2.93385563e-03, -2.03674715e-02,  5.37234955e-02,\n",
       "          1.57353356e-02,  1.52611583e-02, -2.40065623e-02,  1.56878345e-02,\n",
       "          3.96852046e-02, -5.80016337e-02,  4.25773226e-02,  4.02399972e-02,\n",
       "          2.06344295e-02, -4.14945278e-03,  3.31165157e-02, -1.59181934e-02,\n",
       "          2.74405163e-02,  8.25439766e-03,  4.16998044e-02,  1.71288121e-02,\n",
       "          9.44427028e-03, -2.00730618e-02, -5.68856746e-02, -4.64009121e-02,\n",
       "         -5.89316934e-02, -2.64025126e-02, -1.35532161e-02, -1.97908301e-02,\n",
       "          2.47342717e-02,  1.75949407e-03, -4.98081595e-02,  2.25385744e-02,\n",
       "         -4.46008295e-02, -5.31896064e-03, -9.72884335e-03,  3.37657519e-02,\n",
       "          9.13962722e-03, -3.70572731e-02,  2.35714056e-02,  1.32645611e-02,\n",
       "         -3.83522408e-03, -3.74370255e-02, -1.20321400e-02, -2.83817537e-02,\n",
       "         -5.17838029e-03,  1.61678232e-02, -1.15668271e-02, -3.46632414e-02,\n",
       "          1.99689362e-02, -7.51706678e-03,  2.93095354e-02,  8.35757586e-04,\n",
       "          1.15809012e-02, -2.59905849e-02,  3.79096530e-02, -1.58400647e-02,\n",
       "          8.23928881e-03,  1.61939468e-02,  5.36476113e-02,  4.66256589e-02,\n",
       "          8.50919355e-03, -3.95367928e-02, -1.75945722e-02,  2.00278051e-02,\n",
       "          1.87458266e-02,  3.77736203e-02,  9.38998477e-04, -8.34330637e-03,\n",
       "          1.19082322e-02,  1.23663628e-02, -7.88596459e-03, -3.21307853e-02,\n",
       "          2.75087617e-02, -5.18696569e-03, -2.51833480e-02, -3.35370563e-02,\n",
       "         -1.50628900e-02, -3.15523893e-02,  5.66297695e-02, -3.56058367e-02,\n",
       "         -9.90677997e-03,  1.98334455e-02, -3.31607908e-02, -3.47205997e-02,\n",
       "         -3.78442951e-03,  1.16864182e-02, -1.46036008e-02, -1.87924765e-02,\n",
       "         -1.38699671e-03,  7.56056653e-03, -2.36510150e-02, -1.20310308e-02,\n",
       "          1.45051023e-02,  1.22981975e-02,  5.24908975e-02, -6.71580248e-03,\n",
       "          4.26474176e-02,  1.22925257e-02, -4.39389087e-02,  4.79588881e-02,\n",
       "         -3.40485945e-02,  1.92534216e-02, -4.01127227e-02, -3.07262167e-02,\n",
       "          3.72090675e-02, -1.87924262e-02,  3.07626091e-02,  6.20991131e-03,\n",
       "          8.07957817e-03,  2.15856675e-02, -6.27202820e-03,  1.99713800e-02,\n",
       "         -1.95286479e-02,  8.80865287e-03, -9.86480992e-03,  1.17524089e-02,\n",
       "         -4.24257405e-02,  4.00105165e-03,  3.62237892e-03,  9.14725568e-03,\n",
       "          9.42487177e-03, -3.11637409e-02,  4.15176526e-02, -1.50110421e-03,\n",
       "         -1.08689070e-03,  3.57914604e-02,  3.24021727e-02,  2.16970015e-02,\n",
       "          1.21515589e-02,  4.72670421e-02,  1.33406948e-02, -5.65964505e-02,\n",
       "          5.48418798e-02,  4.40544337e-02, -2.38141920e-02,  3.33103798e-02,\n",
       "         -3.38484556e-03,  3.23656276e-02,  2.55102925e-02,  1.14093879e-02,\n",
       "          1.26386546e-02, -1.01625388e-02,  1.63461100e-02,  1.88390315e-02,\n",
       "          2.14400981e-02,  2.10420508e-03,  3.90727334e-02,  4.49180417e-03,\n",
       "          8.69517494e-03, -1.33016277e-02, -2.09678151e-02, -4.04216954e-03,\n",
       "          2.63090208e-02,  1.90742332e-02,  2.75058043e-03,  1.03691947e-02,\n",
       "          2.58411244e-02, -1.40598575e-02,  1.66789312e-02,  4.18117233e-02,\n",
       "          2.30063461e-02,  3.96248624e-02, -1.23209116e-04, -1.55656738e-02,\n",
       "          7.22827273e-04,  2.56927181e-02,  4.90445867e-02,  4.11989465e-02,\n",
       "          3.07913255e-02, -1.84389446e-05,  3.57111283e-02, -3.64375487e-02,\n",
       "         -5.27397217e-03, -3.50544527e-02,  2.10211258e-02,  4.15818542e-02,\n",
       "          1.20626353e-02, -1.58114377e-02,  4.04477045e-02,  7.68353930e-03,\n",
       "          2.76366957e-02,  1.89683717e-02, -5.71521260e-02, -9.80228186e-03,\n",
       "          5.17928265e-02,  2.72612795e-02, -7.34278280e-03, -4.45388146e-02,\n",
       "         -1.77490432e-02,  1.23618264e-02,  4.08556648e-02, -4.90556359e-02,\n",
       "          1.05952732e-02,  4.04023416e-02,  3.08284983e-02,  2.87143197e-02,\n",
       "          3.48911397e-02, -2.18621059e-03, -3.57006565e-02,  1.21158073e-02,\n",
       "         -1.26861932e-03, -8.20222497e-03,  1.54401027e-02,  4.58926382e-03,\n",
       "          3.50658670e-02, -9.87343863e-03, -7.35821156e-03, -1.58281848e-02,\n",
       "          1.26814581e-02, -5.14855757e-02,  3.58618274e-02, -1.84443258e-02,\n",
       "          4.10001948e-02, -9.82044172e-03,  3.75047699e-02, -1.34530114e-02,\n",
       "         -2.97572576e-02, -2.48145442e-02, -3.95597480e-02, -2.50518359e-02,\n",
       "         -1.55024407e-02,  7.50564039e-03, -2.08618715e-02, -2.94962287e-04,\n",
       "          3.53553072e-02,  5.93502782e-02, -4.23192373e-03, -1.56142730e-02,\n",
       "          3.04621030e-02, -1.02948034e-02,  3.92464735e-02, -5.54138981e-02,\n",
       "         -7.49015389e-03, -1.74422339e-02,  1.25637949e-02,  6.86690351e-03,\n",
       "         -1.18489955e-02, -1.59902144e-02, -6.44414627e-04, -3.28273252e-02,\n",
       "         -2.85099726e-02, -2.10124571e-02, -4.10014484e-03,  3.62353064e-02,\n",
       "          2.39490271e-02, -1.92637020e-03,  5.34014441e-02,  2.65857894e-02,\n",
       "         -5.52095361e-02, -4.39361222e-02,  1.46652246e-02,  1.51606044e-02,\n",
       "          1.74552610e-03, -4.78820689e-02,  1.30529581e-02,  1.98790301e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 4,\n",
       "  'topic_words': array(['psychological', 'psychiatry', 'psychiatric', 'psychosis',\n",
       "         'psychology', 'psychotherapy', 'neurosciences', 'psychol', '심리',\n",
       "         'neuroscience', 'mental', 'neurosci', 'neuroscientist',\n",
       "         'depression', 'neuroscientists', 'neuroscientific',\n",
       "         'schizophrenia', 'neurological', 'neuro', 'alzheimers',\n",
       "         'alzheimer', 'brainstem', 'neurology', 'neurol', 'neuronal',\n",
       "         'depressive', 'neuroethics', 'neuroimage', 'neurofeminism',\n",
       "         'neurons', 'neurobiological', 'neuron', '정신', 'cerebrospinal',\n",
       "         'depressed', 'intellectual', 'neuroimaging', 'brain', '학문',\n",
       "         'neurobiology', 'brains', 'neurofeminist', 'forebrain',\n",
       "         'disorders', 'bipolar', 'neural', 'midbrain', 'cognitive', '우울증',\n",
       "         '자극'], dtype='<U15'),\n",
       "  'topic_vector': array([-2.06130762e-02,  3.26484479e-02, -2.69851554e-03, -3.91907357e-02,\n",
       "         -8.72625504e-03,  5.13072349e-02, -3.27420942e-02,  2.10554618e-02,\n",
       "          4.10827734e-02,  2.85309125e-02, -2.36457866e-02, -2.00575683e-02,\n",
       "          8.34624842e-03, -1.14384079e-02, -3.54470573e-02,  2.16184258e-02,\n",
       "          1.63537096e-02, -5.02049066e-02, -2.73579237e-04,  5.03920279e-02,\n",
       "         -2.95631588e-02, -5.35210520e-02,  1.88117977e-02,  2.85491720e-02,\n",
       "         -5.83904386e-02, -3.76173831e-03,  9.99852456e-03, -1.18977539e-02,\n",
       "          2.29285122e-03, -4.96892780e-02,  4.34598449e-04,  1.42614963e-02,\n",
       "         -7.56984251e-03, -4.23903912e-02,  2.41831858e-02, -3.58548909e-02,\n",
       "          2.85939798e-02, -1.56387920e-03, -1.80889554e-02, -4.16503660e-02,\n",
       "         -4.38124128e-03,  8.55377130e-03,  5.22076823e-02,  8.35828390e-03,\n",
       "         -3.90517451e-02, -3.54696508e-03, -3.14415037e-03, -1.63533408e-02,\n",
       "          1.98995695e-02, -1.64698213e-02,  4.10126410e-02, -6.98415795e-03,\n",
       "          2.87196655e-02, -2.47157197e-02, -7.96299055e-03, -5.80086075e-02,\n",
       "          4.23482284e-02, -2.61869598e-02, -5.62493736e-03,  4.52119559e-02,\n",
       "         -3.95525210e-02,  5.65870069e-02, -1.92512032e-02, -4.88491282e-02,\n",
       "         -8.46357364e-03,  1.80653427e-02,  1.84840448e-02, -3.97670679e-02,\n",
       "         -3.43002677e-02, -6.18191855e-03,  2.86239907e-02,  1.67280734e-02,\n",
       "          3.65551449e-02, -4.26143445e-02,  1.03030577e-02, -1.92909185e-02,\n",
       "          3.33552733e-02,  4.00636867e-02, -4.54105400e-02, -6.00603968e-02,\n",
       "         -6.11560307e-02, -3.99757661e-02, -1.09630497e-02,  3.58072743e-02,\n",
       "         -2.22368650e-02, -4.31527058e-03, -3.31191458e-02,  3.26329120e-03,\n",
       "          1.69806276e-02,  3.25371586e-02, -3.99638079e-02, -2.85660382e-02,\n",
       "         -4.21762094e-02, -3.54006104e-02,  1.20615475e-02,  1.77849904e-02,\n",
       "          5.90631329e-02,  4.67601456e-02,  1.14963949e-02,  1.32629415e-03,\n",
       "         -7.56133068e-03, -4.20543225e-03, -1.26998601e-02,  2.58527640e-02,\n",
       "          1.16384830e-02,  3.75026055e-02, -5.27107939e-02,  1.65006926e-03,\n",
       "         -2.78074518e-02,  4.46042605e-02,  9.34055075e-03, -4.24302369e-02,\n",
       "         -1.63293691e-04,  3.34719755e-02,  3.95804308e-02, -4.21186462e-02,\n",
       "          5.48020564e-03,  2.52560563e-02, -4.22898903e-02,  1.13649368e-02,\n",
       "          1.06815016e-02,  3.76670323e-02,  4.22665365e-02,  1.72443166e-02,\n",
       "         -8.31487216e-03,  3.21763009e-02,  2.06135660e-02,  2.45337561e-02,\n",
       "         -2.59778965e-02,  2.51617059e-02, -4.84786779e-02, -4.13896516e-03,\n",
       "          2.63455808e-02,  3.26409824e-02,  1.69570129e-02,  5.93199022e-02,\n",
       "         -2.87792762e-03, -2.16551553e-02,  5.53111173e-02,  1.65234376e-02,\n",
       "          2.62179747e-02,  1.82635710e-02,  6.88150106e-03,  2.81899497e-02,\n",
       "          3.52254994e-02,  2.86708609e-03,  4.29879241e-02,  2.11553704e-02,\n",
       "          1.43000223e-02,  1.45674879e-02,  5.66167384e-02,  2.98300013e-02,\n",
       "         -8.32103845e-03,  2.91095814e-03, -2.21078042e-02, -1.53445150e-03,\n",
       "         -9.54922102e-03, -1.90865882e-02, -2.06434205e-02, -3.02898902e-02,\n",
       "          3.89266871e-02, -4.23331484e-02, -2.42480952e-02,  7.94705655e-03,\n",
       "         -9.22596455e-03, -4.22035903e-02,  2.47595012e-02, -1.02559635e-02,\n",
       "         -2.81127822e-02, -5.16913412e-03, -3.50065567e-02,  7.16130016e-03,\n",
       "         -7.19834073e-03,  5.20111760e-03, -1.51929716e-02,  1.27827739e-02,\n",
       "         -8.79544858e-03,  1.27661759e-02, -4.06921059e-02,  2.99643632e-02,\n",
       "          4.01269458e-02,  1.85757112e-02,  3.57125560e-03, -2.66506989e-02,\n",
       "         -2.63048597e-02,  9.01968870e-03,  1.02183139e-02,  5.96523024e-02,\n",
       "          2.93804538e-02,  4.93446784e-03,  3.58252637e-02, -3.41743194e-02,\n",
       "          2.24691126e-02, -1.20496247e-02, -1.85072552e-02,  7.50430999e-03,\n",
       "         -1.23452290e-03,  8.55401903e-03,  3.63066457e-02,  1.14958519e-02,\n",
       "         -2.29318012e-02,  1.23948036e-02,  1.41009688e-02, -2.71208007e-02,\n",
       "          2.45738998e-02, -4.01080921e-02, -3.56201292e-03,  2.04930790e-02,\n",
       "          2.36185379e-02,  1.94948185e-02,  1.04280636e-02, -2.78794952e-02,\n",
       "          2.37139147e-02, -6.77085045e-05,  2.60481611e-02,  5.89284161e-03,\n",
       "         -9.11146752e-04, -2.36467998e-02, -7.31417211e-03,  2.72897780e-02,\n",
       "         -5.49882166e-02,  4.47316952e-02,  4.27474007e-02,  1.29593192e-02,\n",
       "         -3.81120644e-03, -4.84079383e-02, -3.14196497e-02, -1.41109386e-02,\n",
       "         -3.98532636e-02, -3.95720042e-02,  2.39050705e-02, -3.18877436e-02,\n",
       "         -1.35289850e-02,  4.64875363e-02,  3.01569570e-02, -7.89994374e-03,\n",
       "         -9.19483043e-03,  3.29617271e-03,  5.41774072e-02, -1.53339794e-02,\n",
       "         -3.20065022e-02, -3.26287281e-03,  3.17184888e-02,  3.71285938e-02,\n",
       "          4.62390780e-02,  3.05849090e-02,  3.77674066e-02,  1.36577124e-02,\n",
       "          3.81644182e-02, -1.07871201e-02, -1.06749579e-03, -2.28912309e-02,\n",
       "          1.67446714e-02, -3.24647762e-02,  3.40310559e-02, -1.91974770e-02,\n",
       "         -1.52213788e-02,  2.25130916e-02, -3.76742594e-02,  2.55258270e-02,\n",
       "         -1.49787609e-02,  3.70213129e-02, -3.70507836e-02,  3.48142795e-02,\n",
       "          4.20165621e-02, -4.47194241e-02, -3.19449902e-02,  4.58636731e-02,\n",
       "         -1.78474709e-02,  7.87105784e-03,  2.79268138e-02,  4.64160834e-03,\n",
       "          1.60477292e-02, -5.12099005e-02,  4.54131402e-02,  3.68327126e-02,\n",
       "         -2.11292189e-02,  1.58131402e-02, -5.64906634e-02, -3.79134044e-02,\n",
       "         -1.45735973e-02,  4.12118854e-03,  1.87902320e-02,  2.30610967e-02,\n",
       "         -2.38662846e-02,  5.69749763e-03, -3.18390168e-02, -9.43247415e-03,\n",
       "         -8.53532273e-03, -2.31697559e-02,  9.09864251e-03,  2.79386132e-03,\n",
       "          1.01654520e-02,  3.35193165e-02,  3.94167900e-02,  2.28496734e-02,\n",
       "          1.67540275e-02,  3.76179107e-02,  2.96788625e-02,  4.70297933e-02,\n",
       "          6.35765307e-03,  2.74288133e-02, -3.67035791e-02, -4.89810146e-02,\n",
       "          1.56347677e-02, -3.97989679e-05, -1.33864135e-02,  3.74841727e-02,\n",
       "          3.63093838e-02,  1.07979272e-02,  2.13646243e-04, -3.69164981e-02,\n",
       "          4.76117106e-03,  1.67329200e-02,  4.73755859e-02,  5.08139767e-02,\n",
       "         -2.27795858e-02, -2.02722028e-02,  5.42196967e-02, -2.64391322e-02,\n",
       "         -3.12400647e-02, -4.70081344e-02, -6.92928515e-05,  2.10522488e-02,\n",
       "         -2.33970061e-02, -6.94577349e-04, -1.29606780e-02, -1.10594491e-02,\n",
       "          3.89363617e-02,  1.32753216e-02, -8.16421583e-03, -2.95962170e-02,\n",
       "         -4.20922078e-02, -3.55219394e-02, -3.19236666e-02, -1.25077749e-02,\n",
       "         -2.37366930e-02, -1.64422113e-02, -3.98523025e-02,  7.17880379e-04,\n",
       "         -5.07572554e-02, -1.64814871e-02,  1.01625165e-02, -3.51432972e-02,\n",
       "          2.67924070e-02,  2.90307999e-02,  3.69179510e-02, -7.25034019e-03,\n",
       "         -2.05188692e-02,  4.91241179e-03,  4.63020755e-03,  1.79154275e-03,\n",
       "          1.48979239e-02,  4.40603942e-02, -4.49982239e-03,  3.94171700e-02,\n",
       "          1.76031608e-02,  3.30984555e-02, -3.03428173e-02, -3.37260477e-02,\n",
       "         -1.07386371e-03,  1.00577353e-02,  5.25449365e-02,  3.09188962e-02,\n",
       "         -1.13878613e-02,  1.57027598e-02, -3.74629945e-02,  2.11965460e-02,\n",
       "         -5.58833592e-03, -4.83389449e-04,  1.15684476e-02,  2.58004721e-02,\n",
       "          2.28386223e-02,  8.14198330e-03,  2.60870755e-02,  1.83851309e-02,\n",
       "         -3.54150962e-03,  1.54709956e-02,  4.23863567e-02, -2.09446475e-02,\n",
       "          1.25953965e-02, -1.63663737e-02,  2.54389886e-02,  4.09596004e-02,\n",
       "         -1.52406329e-02,  5.94244152e-02,  2.14121360e-02, -5.66206463e-02,\n",
       "          5.88372238e-02,  4.55816053e-02, -1.31405250e-03, -2.80607883e-02,\n",
       "          3.34681720e-02,  4.89178933e-02,  1.72574713e-03,  1.66985784e-02,\n",
       "          2.90897433e-02, -6.73657190e-03,  1.18581140e-02,  2.26538945e-02,\n",
       "          3.15704197e-02,  5.82961403e-02,  1.31849553e-02,  7.81229278e-03,\n",
       "         -6.70333160e-03,  1.19197667e-02,  4.16368013e-03, -2.31057927e-02,\n",
       "          2.12540645e-02,  4.25937288e-02,  3.73074561e-02,  5.34125092e-03,\n",
       "          1.12532184e-03,  3.12232152e-02, -1.19464044e-02,  5.39887771e-02,\n",
       "          1.75023992e-02, -1.10262008e-02,  4.04002564e-03, -4.22245590e-03,\n",
       "         -7.21337926e-03, -5.52732684e-03,  2.26050988e-02,  2.76738629e-02,\n",
       "          5.01640104e-02, -1.28577407e-02,  8.45055375e-03, -1.66563001e-02,\n",
       "         -5.19088507e-02, -5.16266096e-03,  1.13699771e-02,  1.45501494e-02,\n",
       "          1.91523507e-03, -2.98943929e-02,  1.11192456e-02, -2.86691710e-02,\n",
       "         -3.22327903e-03, -1.35514596e-02, -5.73543049e-02,  3.47623937e-02,\n",
       "          9.84180626e-03,  1.40893105e-02, -1.11545688e-02, -4.47298847e-02,\n",
       "          2.12881882e-02,  2.83761304e-02,  2.66773477e-02,  3.78399789e-02,\n",
       "          4.16623652e-02,  4.16183136e-02, -1.82123836e-02,  2.51275841e-02,\n",
       "         -7.71910651e-03,  2.29808036e-02, -3.27379443e-02, -2.36491561e-02,\n",
       "         -8.54404923e-03,  3.87081224e-03,  3.47305685e-02, -2.47574821e-02,\n",
       "         -2.22945074e-03, -2.69966535e-02, -4.02382948e-02, -3.97419333e-02,\n",
       "         -1.95892192e-02, -5.71525060e-02, -5.46190776e-02,  9.03979782e-03,\n",
       "         -1.92012768e-02,  4.46892809e-03,  4.94474592e-03,  3.86885852e-02,\n",
       "         -3.99978273e-02,  3.15136164e-02, -9.21271089e-03, -1.82041097e-02,\n",
       "          1.11371437e-02, -6.17735879e-03, -3.39260362e-02,  1.18828528e-02,\n",
       "          3.00638843e-02,  6.07362390e-02, -2.67503560e-02,  5.34721790e-03,\n",
       "          5.72323799e-03, -1.89085472e-02, -2.49738824e-02, -5.72263934e-02,\n",
       "         -2.02342682e-02, -5.01113795e-02,  2.98920628e-02,  9.24187247e-03,\n",
       "          3.74016576e-02, -3.86806927e-03,  2.39352044e-02, -2.21327562e-02,\n",
       "         -4.48451526e-02,  1.98444556e-02,  2.18097344e-02,  2.95833847e-03,\n",
       "          1.42057156e-02, -2.68677752e-02,  4.52365577e-02, -6.32932177e-03,\n",
       "         -4.77911830e-02, -2.56034248e-02,  3.58302332e-02, -7.61313410e-03,\n",
       "         -1.63527895e-02, -4.11759652e-02,  7.39670871e-03,  1.99940875e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 5,\n",
       "  'topic_words': array(['undergraduate', 'neuroscience', 'neurosciences', 'graduate',\n",
       "         'neurosci', '전공', 'university', 'neurobiology', 'sciences', 'phd',\n",
       "         'neuroscientific', '대학원', 'neuroscientist', 'academic', '대학교',\n",
       "         'neurol', 'neuro', 'neuroscientists', 'neuronal', '졸업', 'courses',\n",
       "         'degree', 'neural', 'neuron', 'neurons', 'scholarship',\n",
       "         'neurobiol', 'stanford', 'neurobiological', 'faculty', 'college',\n",
       "         '학문', 'scholar', 'neuroethics', 'forebrain', 'scientist',\n",
       "         'neurology', 'study', 'neurological', '공학', 'cerebrospinal',\n",
       "         'degrees', 'neuroimage', '대학', '과정', 'apply', 'institute', '뉴런',\n",
       "         'classes', 'recruitment'], dtype='<U15'),\n",
       "  'topic_vector': array([-6.19370444e-03,  4.84620221e-02,  1.31824426e-02,  4.54325229e-04,\n",
       "          1.93348173e-02,  2.16386616e-02,  1.22736394e-02,  3.14326324e-02,\n",
       "          2.64332804e-04, -1.09307021e-02,  1.19448956e-02, -2.64641624e-02,\n",
       "          9.17194935e-04,  3.81188802e-02, -3.39496508e-02,  1.50201470e-02,\n",
       "          1.70629118e-02, -5.33059798e-02,  3.09318919e-02,  3.51641700e-02,\n",
       "         -3.28436829e-02, -1.50725478e-02,  4.61919531e-02,  3.65209170e-02,\n",
       "         -6.06682263e-02,  5.06891077e-03, -1.63500551e-02,  3.29537243e-02,\n",
       "         -2.17550918e-02, -2.36603152e-02, -1.23434355e-02,  2.90588308e-02,\n",
       "         -2.89482307e-02, -3.72870304e-02,  2.03737002e-02, -1.08077852e-02,\n",
       "          2.82373582e-03,  1.59150362e-02,  1.17821926e-02,  1.16746062e-02,\n",
       "         -1.94240678e-02,  3.90140638e-02,  4.15603630e-02, -2.71317223e-03,\n",
       "         -5.95730282e-02,  6.44751787e-02,  1.49974823e-02,  8.50111526e-03,\n",
       "         -2.52530500e-02, -2.82400195e-02, -7.42926914e-03, -2.17442773e-02,\n",
       "          2.65153330e-02,  4.42572730e-03,  1.11012273e-02, -3.20263878e-02,\n",
       "         -5.60735539e-03,  1.99700352e-02,  1.91126540e-02,  1.42650548e-02,\n",
       "         -3.36001553e-02,  5.15665375e-02, -3.42159495e-02, -3.92929725e-02,\n",
       "         -6.94296835e-03,  1.99064445e-02,  4.42468598e-02, -4.53046709e-02,\n",
       "         -6.99724955e-03, -5.24840727e-02,  3.22824158e-02,  1.74445119e-02,\n",
       "          1.62101462e-02,  2.64350530e-02,  4.08598296e-02, -2.86040246e-03,\n",
       "          3.28148752e-02,  9.61835030e-03,  8.31655413e-03, -5.79497442e-02,\n",
       "         -6.66795745e-02, -4.39244211e-02,  1.01810154e-02,  3.26597653e-02,\n",
       "         -8.71031731e-03, -2.94444747e-02, -3.51569280e-02,  2.11197753e-02,\n",
       "          2.09922418e-02, -7.16922246e-03, -3.12314909e-02, -2.49335542e-02,\n",
       "         -3.39497849e-02, -3.32303606e-02,  3.79787944e-02,  1.11847334e-02,\n",
       "         -5.78205691e-05,  3.43565084e-02,  3.05221565e-02,  1.47553682e-02,\n",
       "          2.05484610e-02,  1.62656028e-02, -9.73630510e-03, -2.54051276e-02,\n",
       "         -1.55479051e-04,  1.63491983e-02, -7.02232569e-02, -3.37183215e-02,\n",
       "          6.91617781e-04,  3.37395519e-02,  1.47168403e-02, -1.26821855e-02,\n",
       "          3.52852494e-02,  1.05034467e-02,  3.28136459e-02, -7.10808113e-02,\n",
       "         -2.47120764e-03,  1.42742544e-02, -5.27611421e-03,  4.25264575e-02,\n",
       "         -9.94570553e-03,  5.35721891e-02,  1.40924370e-02, -1.37578277e-02,\n",
       "          2.64609884e-02, -1.43985515e-02, -1.59460271e-03, -4.27079387e-02,\n",
       "         -3.46149243e-02, -2.01905356e-03, -1.26489280e-02, -4.08483110e-02,\n",
       "          3.40100117e-02,  2.15421785e-02, -1.10539459e-02,  6.45829961e-02,\n",
       "          2.83717085e-03, -3.64116579e-02,  4.74769846e-02, -1.25005031e-02,\n",
       "          5.65529466e-02, -2.82750209e-03,  3.63856629e-02,  5.31902164e-02,\n",
       "          4.41501439e-02, -3.16091925e-02, -2.95366743e-03,  2.85918992e-02,\n",
       "         -7.03057228e-03,  4.22837473e-02,  4.64207642e-02,  3.09766214e-02,\n",
       "         -3.39744315e-02, -2.48299707e-02, -1.07692713e-02, -2.70698071e-02,\n",
       "         -1.07327523e-02, -2.37998366e-02,  4.25569434e-03, -4.30406816e-02,\n",
       "          4.43520993e-02, -2.28634663e-02, -4.27972600e-02, -6.22062525e-03,\n",
       "         -1.60340033e-02,  1.21952174e-02, -2.37891786e-02, -4.83282059e-02,\n",
       "         -5.19555919e-02, -4.83695371e-03, -2.30404604e-02, -5.57400985e-04,\n",
       "         -1.15250492e-04,  2.12211851e-02, -7.12007005e-03, -5.25478385e-02,\n",
       "         -2.25817189e-02,  5.83749451e-03, -4.59041148e-02,  2.26382948e-02,\n",
       "         -2.59220623e-03, -1.22870887e-02,  1.93193685e-02, -3.22433822e-02,\n",
       "         -2.06966661e-02,  2.41539106e-02, -2.48038284e-02,  5.61866537e-02,\n",
       "          1.64556894e-02, -2.57091299e-02,  8.93358234e-03, -1.88593511e-02,\n",
       "          1.90358106e-02, -2.32435483e-02,  3.48943635e-03,  1.75650008e-02,\n",
       "         -2.50373892e-02,  1.04830405e-02,  4.71667200e-02,  4.66278791e-02,\n",
       "         -7.35509954e-03,  1.70884896e-02, -3.13392244e-02, -3.53022963e-02,\n",
       "          6.71844464e-03, -1.26771871e-02,  3.52346487e-02, -5.13960142e-03,\n",
       "          1.88669804e-02,  2.82508247e-02, -5.62429102e-03, -1.08543262e-02,\n",
       "         -4.57585566e-02,  1.22656766e-02,  1.83870103e-02,  7.26165343e-03,\n",
       "          3.01195364e-02, -6.42958283e-03, -1.59096066e-02, -1.76856406e-02,\n",
       "         -3.45882140e-02,  4.16925512e-02,  2.93566715e-02,  7.06930459e-03,\n",
       "         -5.02032749e-02, -4.23675142e-02, -4.33704741e-02,  4.04606909e-02,\n",
       "          2.33490225e-02, -4.49472852e-03, -1.11960648e-02, -2.67865490e-02,\n",
       "         -2.77260900e-03,  2.28423290e-02,  1.53294541e-02,  3.59561294e-02,\n",
       "         -2.49243807e-02, -5.13621606e-03,  7.06654266e-02, -1.70563478e-02,\n",
       "         -5.98897338e-02,  9.16195475e-03,  5.45529928e-03, -1.31384674e-02,\n",
       "          4.91022505e-02, -7.83036277e-03,  4.69980724e-02, -8.78721569e-03,\n",
       "         -6.01171143e-03, -3.04834954e-02,  2.00854037e-02, -3.67949251e-03,\n",
       "          5.65872081e-02,  3.61618325e-02,  2.52672322e-02, -2.63496712e-02,\n",
       "          5.04585216e-03, -3.07379849e-02, -3.55956256e-02,  2.36070752e-02,\n",
       "         -2.51230821e-02,  2.88799722e-02, -9.02312750e-05,  1.31271863e-02,\n",
       "          1.76217407e-02, -1.61703043e-02, -6.50735246e-03,  1.39138093e-02,\n",
       "         -2.15792991e-02,  1.60345901e-02, -2.36819144e-02, -3.73259448e-02,\n",
       "          2.97412761e-02, -5.12725953e-03,  1.33000044e-02,  2.48665027e-02,\n",
       "         -5.42229377e-02, -1.28560432e-03, -4.28090878e-02, -3.65518928e-02,\n",
       "          1.61153506e-02,  5.24476171e-04,  2.72009894e-02, -5.68450056e-03,\n",
       "         -4.03657742e-02,  2.08830703e-02, -2.35326998e-02, -4.12844820e-03,\n",
       "         -1.13374367e-02, -2.03779005e-02,  2.58366819e-02,  3.15059163e-02,\n",
       "         -1.24700451e-02,  2.65568867e-03, -3.11283842e-02, -6.87036524e-03,\n",
       "         -2.78109610e-02,  2.98355110e-02,  4.50908532e-03,  2.84556835e-03,\n",
       "         -4.25169943e-03, -9.46035143e-03, -4.44266200e-03, -3.49032618e-02,\n",
       "         -1.37883304e-02, -3.29371393e-02, -2.40630079e-02,  1.08518638e-02,\n",
       "         -5.60060889e-03,  1.56631377e-02,  1.05082905e-02,  1.18330689e-02,\n",
       "         -1.49473492e-02, -7.51490705e-03,  2.84371302e-02,  4.80416650e-03,\n",
       "         -6.42099902e-02,  1.57760526e-03,  3.70080657e-02,  2.69070547e-03,\n",
       "          1.44074848e-02, -2.13658828e-02,  1.16141709e-02, -4.19728383e-02,\n",
       "         -2.97619123e-02,  1.98340546e-02,  4.64243516e-02, -2.42781173e-03,\n",
       "          9.20485333e-03,  5.07836416e-03, -2.93045565e-02, -3.24110128e-02,\n",
       "         -2.23083496e-02, -6.17273673e-02, -7.40274368e-03,  1.43688703e-02,\n",
       "         -1.88664142e-02, -1.05510196e-02, -3.35738808e-02, -5.86691254e-04,\n",
       "         -2.30631158e-02,  2.31465399e-02,  2.25959271e-02, -3.59722450e-02,\n",
       "          1.40066110e-02,  1.88593734e-02, -2.63935626e-02,  9.96676181e-03,\n",
       "         -1.75900720e-02,  1.35681517e-02, -9.86635685e-03, -4.31030849e-03,\n",
       "         -2.16322541e-02,  7.71150785e-03, -2.43981406e-02,  9.37811751e-03,\n",
       "         -1.41479764e-02,  1.45455161e-02, -2.76809204e-02, -4.75913547e-02,\n",
       "          3.59671749e-02, -7.57704396e-03,  3.43877524e-02, -3.15755270e-02,\n",
       "         -3.85435708e-02,  3.26808691e-02, -3.53575870e-02,  3.37752216e-02,\n",
       "         -4.29691784e-02, -2.39555668e-02,  1.66914333e-02,  9.46137588e-03,\n",
       "         -2.29851138e-02,  3.40597667e-02,  3.16466950e-02,  5.92106429e-04,\n",
       "         -2.63849329e-02, -1.84934773e-02, -4.36057225e-02, -3.34620811e-02,\n",
       "         -2.90847546e-03,  2.62594987e-02,  2.75407434e-02, -8.87887273e-03,\n",
       "         -5.82819246e-03,  4.33190493e-03,  2.34932229e-02, -5.25699370e-02,\n",
       "          5.93072735e-02,  1.50141744e-02,  5.83982049e-03, -7.61047751e-03,\n",
       "          2.56203860e-03,  2.70751342e-02, -2.97005791e-02, -3.35870124e-02,\n",
       "          2.85382923e-02,  1.65419914e-02, -3.78762037e-02,  7.00635649e-03,\n",
       "          3.93501855e-02,  4.00641710e-02,  5.28518669e-02,  7.80745002e-04,\n",
       "         -1.98627934e-02, -1.08050629e-02, -2.43329704e-02, -1.29685202e-03,\n",
       "          1.74926296e-02, -8.80515855e-03,  1.57462414e-02,  1.32904733e-02,\n",
       "          4.85638203e-03,  1.71706756e-03,  2.68469527e-02,  4.92018610e-02,\n",
       "         -2.56438125e-02, -4.95122932e-03, -1.13193551e-02, -1.04213750e-03,\n",
       "          1.59465591e-03,  5.46738971e-03,  2.33005565e-02,  3.70813906e-03,\n",
       "          4.63904031e-02,  2.73872372e-02,  5.16620018e-02, -3.89924385e-02,\n",
       "         -1.59697868e-02, -2.42080409e-02,  9.42497607e-03,  3.00437491e-02,\n",
       "          1.84740257e-02, -2.41619702e-02,  1.23512065e-02,  1.64000764e-02,\n",
       "          3.51860598e-02, -4.65746038e-03, -5.32304049e-02,  3.31955589e-02,\n",
       "         -1.73619166e-02,  3.19960490e-02,  2.57948749e-02, -2.96000913e-02,\n",
       "         -1.10675220e-03,  2.16839630e-02,  4.93457094e-02, -1.02301473e-02,\n",
       "          7.09036738e-02, -3.31525039e-03, -4.53546792e-02, -3.59331694e-04,\n",
       "          5.51268198e-02,  3.13524045e-02, -3.04028168e-02, -2.91191023e-02,\n",
       "          2.63689570e-02, -4.20780480e-03, -1.18299657e-02, -4.56981398e-02,\n",
       "         -7.47000892e-03, -3.41456346e-02,  1.95840970e-02,  1.23472512e-02,\n",
       "         -3.20204273e-02, -4.63566445e-02, -5.97268008e-02,  5.19080274e-02,\n",
       "          5.17739654e-02, -4.95521165e-02,  2.72062235e-02,  6.48693070e-02,\n",
       "         -2.89401524e-02, -6.89730467e-03, -1.27796242e-02, -3.48171517e-02,\n",
       "         -2.09420454e-02,  4.05993909e-02,  6.16720470e-04,  7.64236134e-03,\n",
       "          2.09878273e-02,  6.73403591e-02, -4.01940309e-02, -3.04228347e-02,\n",
       "          4.59268540e-02,  4.16423045e-02, -6.26308331e-03, -4.75917011e-02,\n",
       "         -4.61892039e-02, -5.74229099e-03,  3.24730389e-02, -4.38665748e-02,\n",
       "          2.75461022e-02, -1.72154140e-02,  2.34676283e-02, -4.89483476e-02,\n",
       "          1.17958961e-02,  1.06713418e-02,  1.40869208e-02, -5.48043696e-04,\n",
       "          3.07737458e-02, -5.09209186e-02,  3.65552306e-02, -2.01505069e-02,\n",
       "         -4.26830389e-02, -1.68667510e-02, -3.80955152e-02,  2.78364420e-02,\n",
       "         -4.52885255e-02, -5.37773259e-02, -2.35589314e-02,  8.00435804e-03],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 6,\n",
       "  'topic_words': array(['모델', 'models', 'modelling', 'modeling', 'model', 'modeled',\n",
       "         'covariance', 'correlation', 'mxmodel', 'correlations',\n",
       "         'matplotlib', 'variance', 'dataframe', 'statistics',\n",
       "         'multivariate', 'statistical', 'twindata', 'variances',\n",
       "         'statistically', 'datasets', 'variability', 'bivariate',\n",
       "         'variables', 'dataset', 'regression', '잠재변수', 'scatterplot',\n",
       "         'paradigms', '변수', 'probabilistic', 'statistic', 'correlated',\n",
       "         'simulations', 'coefficients', 'graphql', 'correlate', 'paradigm',\n",
       "         'correlates', 'coefficient', 'tensorflow', '통계청', 'numpy',\n",
       "         'probabilities', 'relationships', 'simulation', '통계',\n",
       "         'multiprocessing', 'variational', 'pairs', 'templates'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-0.06642684, -0.05516002, -0.01384313,  0.00537484, -0.05989685,\n",
       "         -0.03420688,  0.02601203, -0.02263514,  0.04705404,  0.01125697,\n",
       "          0.01519981,  0.05491725,  0.04817886, -0.00149519, -0.06009239,\n",
       "         -0.01133309,  0.0379829 , -0.01125236,  0.03246206,  0.02415403,\n",
       "         -0.02038855, -0.03943057, -0.03948606,  0.0208167 , -0.04606232,\n",
       "         -0.05338115, -0.00082708,  0.00796428,  0.03029463, -0.05041532,\n",
       "         -0.04939646,  0.0145187 ,  0.04101862, -0.06043636,  0.00437606,\n",
       "          0.02147336, -0.0294211 ,  0.03165406,  0.00098696,  0.04458281,\n",
       "          0.00546269, -0.01056125,  0.01124635, -0.05986785, -0.00935769,\n",
       "         -0.04298431,  0.03120092, -0.01130568, -0.00939846, -0.0440788 ,\n",
       "         -0.02693074, -0.01319269,  0.01254904, -0.0026927 ,  0.00420133,\n",
       "         -0.04605606,  0.00253569,  0.04350738, -0.01356263,  0.04045891,\n",
       "         -0.00111551,  0.04162858,  0.01787663, -0.0412739 ,  0.0372722 ,\n",
       "         -0.01709289,  0.00719034, -0.0018771 ,  0.04476508,  0.03246735,\n",
       "         -0.03744135, -0.00798896, -0.04933852, -0.04679441, -0.04747391,\n",
       "         -0.05409318,  0.00766986,  0.03481954, -0.01512088, -0.06917666,\n",
       "         -0.06836375, -0.01743356, -0.04838861,  0.00431548,  0.01494309,\n",
       "         -0.02704946, -0.0388976 , -0.04428888, -0.00679404, -0.00816801,\n",
       "          0.01110597, -0.01971492,  0.05561011, -0.06089765, -0.00522255,\n",
       "          0.05406343,  0.00071554,  0.03444996,  0.00911545,  0.02478543,\n",
       "          0.05086169, -0.00757332,  0.04093291,  0.00352356,  0.03330584,\n",
       "         -0.02305627, -0.04904337, -0.01602199,  0.02260208,  0.04139371,\n",
       "          0.02833383, -0.02212433, -0.00337683,  0.0018416 , -0.00463552,\n",
       "          0.03370826, -0.00096952, -0.00990057, -0.01345512, -0.01317964,\n",
       "          0.0133329 ,  0.00552916, -0.00490143,  0.03869481,  0.03778015,\n",
       "          0.00013217, -0.02057802,  0.03978769, -0.04842491,  0.02848648,\n",
       "         -0.04915367,  0.03406256,  0.05203306,  0.00458492,  0.0077204 ,\n",
       "          0.02166698,  0.00184306, -0.01817062,  0.02916434,  0.03270473,\n",
       "         -0.02067035, -0.03781095,  0.02525635, -0.02634026,  0.04020217,\n",
       "         -0.00280134, -0.03326364,  0.03679806,  0.00195266,  0.00503058,\n",
       "          0.06000498,  0.00436619,  0.02910187, -0.04162043,  0.05278965,\n",
       "          0.02332767, -0.03745714, -0.01024731,  0.01320899,  0.00310335,\n",
       "          0.00132354,  0.03552335,  0.00246416, -0.03358691, -0.05287679,\n",
       "         -0.008867  , -0.02873485,  0.01391159, -0.02030264,  0.04125555,\n",
       "         -0.03684458,  0.00468007,  0.01697001, -0.03521951, -0.01746804,\n",
       "          0.04011929, -0.0212078 ,  0.04036438, -0.0497597 ,  0.01987436,\n",
       "          0.045885  ,  0.0108378 ,  0.03995003, -0.01684296, -0.0515594 ,\n",
       "         -0.04612197,  0.02610284,  0.04351515, -0.03436667, -0.04272528,\n",
       "         -0.02926848,  0.00416065,  0.0446331 ,  0.00990684,  0.00562742,\n",
       "         -0.00458657, -0.06174605, -0.03383649,  0.0442023 ,  0.02794491,\n",
       "         -0.02294506,  0.00770457, -0.04395487,  0.00222609, -0.01120814,\n",
       "         -0.03301458, -0.03687612,  0.01279401, -0.01816157,  0.03892619,\n",
       "         -0.04148578,  0.00898618, -0.05175003,  0.01422716,  0.03338433,\n",
       "         -0.04562665, -0.02860419, -0.06106151,  0.03355454, -0.01321726,\n",
       "         -0.00613771,  0.00150419,  0.03472845, -0.03096501, -0.06174989,\n",
       "         -0.0037589 , -0.04560365, -0.04458533,  0.01846482,  0.01895206,\n",
       "         -0.02044361,  0.05256659, -0.02572596, -0.02128786,  0.03862689,\n",
       "          0.00448416,  0.01196541,  0.03294442,  0.01964452, -0.01521922,\n",
       "         -0.02242308,  0.02556522,  0.03082404,  0.00681102, -0.00102677,\n",
       "         -0.06452641, -0.04341594,  0.00674762,  0.01554659, -0.00326046,\n",
       "         -0.01552775, -0.02225108, -0.03257506, -0.04191685, -0.03507406,\n",
       "         -0.01706903, -0.00531844, -0.00544611, -0.02636161, -0.03177824,\n",
       "          0.00456438,  0.01130637, -0.00398869, -0.00332226,  0.01367711,\n",
       "         -0.03307592, -0.03478144, -0.02975086,  0.00394913, -0.04872526,\n",
       "         -0.00975404, -0.03438509, -0.00794333, -0.00956575, -0.02025274,\n",
       "          0.00427038, -0.03470043,  0.03696808, -0.02949583,  0.00224178,\n",
       "         -0.04559194,  0.03609704,  0.00858451, -0.00732881, -0.02268911,\n",
       "          0.03305667, -0.01050359, -0.0222851 , -0.01462831,  0.05198847,\n",
       "          0.03400542,  0.06246168,  0.04539986,  0.00811825, -0.05609075,\n",
       "          0.03401529, -0.02325658,  0.0176572 ,  0.02090226,  0.03847427,\n",
       "         -0.05447605,  0.02818609, -0.01979677, -0.04416503, -0.06039542,\n",
       "         -0.00585332, -0.03297004,  0.01578514, -0.01773314,  0.0427937 ,\n",
       "         -0.02709779,  0.01384933, -0.05531768, -0.01761897,  0.00518453,\n",
       "          0.0515471 ,  0.05432703, -0.02690906,  0.01701678,  0.01108964,\n",
       "          0.01790606, -0.01220025, -0.05024064, -0.01684327, -0.02003094,\n",
       "          0.01008496, -0.02809025, -0.02473231, -0.01855764, -0.00359067,\n",
       "         -0.02159745, -0.02483226, -0.00548027, -0.05823201, -0.02712476,\n",
       "          0.02623675, -0.00735999, -0.05139236, -0.06597159, -0.03856295,\n",
       "         -0.01683167, -0.014328  ,  0.03757919, -0.01584165, -0.03573759,\n",
       "          0.03684819,  0.05239287,  0.01888115, -0.03926862,  0.00683335,\n",
       "          0.00999625,  0.03244827,  0.02589311, -0.02018004,  0.01049742,\n",
       "          0.01501963,  0.01438416,  0.0441961 , -0.03989864, -0.04248631,\n",
       "         -0.01211572, -0.03496957,  0.02716856, -0.03001565, -0.04299881,\n",
       "          0.00975776,  0.01035821,  0.01553457, -0.00932392,  0.06823687,\n",
       "          0.02558164,  0.04195413, -0.02776893,  0.01445571, -0.02542551,\n",
       "         -0.05461539,  0.01389356, -0.02293449, -0.03433614, -0.05664377,\n",
       "          0.04420481, -0.04329896, -0.01473427, -0.02298378, -0.03255732,\n",
       "          0.05417912, -0.02346412, -0.04314407,  0.02656285, -0.00640291,\n",
       "          0.03695311, -0.03181775, -0.04827339,  0.06105908, -0.05460409,\n",
       "         -0.00328057,  0.04018454, -0.01919817, -0.02623934, -0.01563619,\n",
       "          0.00798314,  0.04884152,  0.03912404, -0.01592784, -0.03393168,\n",
       "          0.01121947, -0.00523402, -0.03721055,  0.03485174, -0.00999245,\n",
       "          0.00541139, -0.01038465,  0.02453609,  0.0047089 ,  0.03357184,\n",
       "          0.01030901,  0.01759856, -0.00397092,  0.04796625, -0.0129384 ,\n",
       "          0.00702409, -0.042693  ,  0.00320353,  0.04305915,  0.03822888,\n",
       "          0.002288  , -0.00078877, -0.02541034, -0.00454788, -0.01760989,\n",
       "         -0.02250178, -0.00103684,  0.00787772, -0.00484957, -0.02611941,\n",
       "          0.04524368,  0.04828869,  0.01415937, -0.04794409,  0.01809503,\n",
       "         -0.00821769, -0.00141288,  0.01154154, -0.05041526,  0.03757073,\n",
       "         -0.02604778,  0.03299936,  0.02817196,  0.00109828,  0.00376097,\n",
       "         -0.01437637, -0.02077916, -0.02636954, -0.02457777, -0.04978528,\n",
       "         -0.04922418,  0.01477303,  0.01355938,  0.05128902,  0.03209243,\n",
       "         -0.02119293, -0.02442748, -0.00893849, -0.04714037,  0.04212205,\n",
       "         -0.02374253,  0.02148616, -0.05187466,  0.06144117, -0.00913   ,\n",
       "          0.03905754,  0.01975889,  0.0076592 ,  0.03019875, -0.04631919,\n",
       "         -0.02164397,  0.01581312, -0.00445456, -0.02105462, -0.02483925,\n",
       "          0.05239993,  0.01100063, -0.03863286, -0.0001574 ,  0.01544183,\n",
       "         -0.0005924 , -0.01557303, -0.05496467, -0.03921745, -0.03937381,\n",
       "          0.03607693,  0.02971185,  0.01692798,  0.0041432 , -0.0100812 ,\n",
       "         -0.01690031, -0.00503969, -0.02593777,  0.01642814, -0.00283726,\n",
       "          0.0216183 , -0.02743655,  0.0405871 ,  0.00623301,  0.0017185 ,\n",
       "         -0.05429688,  0.00047045, -0.0220044 , -0.01016571, -0.03629503,\n",
       "         -0.02004735,  0.03769601], dtype=float32)},\n",
       " {'topic_idx': 7,\n",
       "  'topic_words': array(['neurosciences', 'neuroscience', 'neuroscientific', 'neurons',\n",
       "         'neuron', 'neuroscientists', 'neuronal', 'neurosci', 'scientists',\n",
       "         'neurobiology', 'neuroscientist', 'neuro', 'scientist', 'brains',\n",
       "         'neurology', 'neurobiological', 'neurological', 'brainstem',\n",
       "         'neural', 'brain', 'neurol', 'neurogenesis', '뉴턴', 'alzheimers',\n",
       "         'scientific', '뉴런', 'neuroimaging', 'alzheimer', 'neurobiol', '과학',\n",
       "         'science', 'neurosurg', 'neuroimage', 'neuroethics',\n",
       "         'neurocultures', 'forebrain', 'intelligence', 'cerebrospinal',\n",
       "         '신경망', '과학자', '신경', 'cerebral', 'sciences', 'biology',\n",
       "         'researchers', 'mathematics', 'intelligent', 'theories', 'nucleus',\n",
       "         'neurofeminist'], dtype='<U15'),\n",
       "  'topic_vector': array([-8.54175945e-04,  4.74130437e-02,  3.81577504e-03,  2.32784636e-02,\n",
       "         -2.21952293e-02,  3.95175517e-02,  4.19132644e-03,  6.72833016e-03,\n",
       "          2.86187176e-02,  4.66577895e-02, -8.68692622e-03,  1.79548208e-02,\n",
       "          4.69331406e-02,  3.28302793e-02, -5.25863580e-02,  5.50219137e-03,\n",
       "          2.67897802e-03, -5.26769757e-02,  2.34684790e-03,  4.58900258e-02,\n",
       "         -1.44515187e-03, -5.17095402e-02,  3.14495787e-02,  3.10915541e-02,\n",
       "         -5.44386692e-02,  2.44442485e-02,  4.48332503e-02,  7.82082882e-03,\n",
       "          2.60175951e-02, -4.79496345e-02,  6.38849614e-03,  1.16273444e-02,\n",
       "          3.83305778e-05, -5.36484718e-02,  2.70687770e-02, -3.47200818e-02,\n",
       "         -1.05253374e-02, -3.32688279e-02,  1.49229961e-02, -5.39419390e-02,\n",
       "         -1.47338612e-02, -1.05202058e-02,  5.43251112e-02,  8.71299859e-03,\n",
       "         -3.72231305e-02,  3.41026038e-02,  4.79911529e-02,  2.83035878e-02,\n",
       "         -5.52256068e-04, -9.60014574e-03,  1.96572058e-02, -1.47674438e-02,\n",
       "          1.49014909e-02,  1.53557509e-02,  2.58432534e-02, -5.37005477e-02,\n",
       "          4.59203310e-02,  7.01190811e-03,  2.38043573e-02,  2.64689196e-02,\n",
       "         -2.86637750e-02,  5.39988093e-02, -1.76857132e-02, -2.21595727e-02,\n",
       "          1.85094140e-02, -2.50014532e-02,  4.58694585e-02, -4.24359106e-02,\n",
       "         -4.62958179e-02, -2.96336692e-02, -1.49829090e-02, -3.85932950e-03,\n",
       "          1.75482444e-02, -5.44894766e-03, -1.08963531e-02, -1.75654311e-02,\n",
       "          1.49726421e-02,  3.83282043e-02, -3.32043879e-02, -5.44275716e-02,\n",
       "         -5.44430278e-02, -3.83284502e-02, -1.22832423e-02,  4.83688042e-02,\n",
       "         -4.81919087e-02,  2.92015669e-04,  2.24319082e-02, -2.45351959e-02,\n",
       "          4.65937965e-02,  4.07115482e-02, -4.93459143e-02, -2.78090071e-02,\n",
       "         -3.94615047e-02, -4.19982187e-02, -7.79920444e-03,  3.39863300e-02,\n",
       "          5.43153696e-02,  4.27904688e-02,  2.81415917e-02,  1.33350417e-02,\n",
       "          8.79634731e-03,  4.35976405e-03,  3.34322453e-04,  5.74724749e-03,\n",
       "          1.50359506e-02,  4.55362862e-03, -5.33775650e-02, -2.48118653e-03,\n",
       "         -4.89926257e-04,  4.89168838e-02,  2.45993433e-04, -5.36102727e-02,\n",
       "         -3.93049344e-02,  3.03779542e-02,  4.80868854e-02, -5.43986857e-02,\n",
       "          4.83722019e-04,  1.84442531e-02, -4.42037061e-02,  2.41000950e-02,\n",
       "          1.40428380e-03,  5.37648387e-02,  2.49580536e-02, -5.54822478e-03,\n",
       "         -1.39264138e-02,  4.90988977e-02,  2.19185092e-02, -1.89884007e-03,\n",
       "         -4.66949232e-02,  1.70067251e-02, -4.29217629e-02,  1.86975319e-02,\n",
       "         -4.26394530e-02,  4.41505089e-02, -4.72030900e-02,  5.35180755e-02,\n",
       "         -2.22106408e-02, -2.57814694e-02,  5.19881584e-02,  9.19508748e-03,\n",
       "          5.17206304e-02,  5.16135897e-03,  3.22114117e-02,  2.12249495e-02,\n",
       "          5.10775968e-02, -9.21799708e-03,  1.37611642e-03,  2.46185753e-02,\n",
       "         -9.44760907e-03,  1.28992666e-02,  5.42627349e-02,  2.71111969e-02,\n",
       "         -1.40261604e-02, -5.20405546e-02,  5.34807239e-03,  3.14759724e-02,\n",
       "         -3.40035036e-02, -3.48827280e-02, -5.07246219e-02, -3.89771461e-02,\n",
       "          4.79881391e-02, -4.51245718e-02, -4.84270342e-02,  1.35392798e-02,\n",
       "          1.35510862e-02, -2.76618768e-02,  3.84552144e-02, -9.46672261e-03,\n",
       "         -5.42061515e-02,  3.89941931e-02, -3.46860811e-02, -2.30722176e-03,\n",
       "          4.01395150e-02,  5.37756830e-03, -2.90996097e-02,  1.95806790e-02,\n",
       "         -4.09331359e-03,  1.12791238e-02, -4.94065993e-02,  1.16318241e-02,\n",
       "         -7.59925228e-03,  2.47528888e-02, -2.33592689e-02, -6.47549285e-03,\n",
       "         -9.62247420e-03, -5.41720539e-03,  8.72671232e-03,  5.42547368e-02,\n",
       "          2.37644073e-02,  5.31187244e-02,  1.41139822e-02, -2.04818733e-02,\n",
       "         -6.29242277e-03, -3.41720469e-02, -4.79256138e-02,  3.89173664e-02,\n",
       "         -2.40036286e-02,  2.30484363e-02,  5.33425547e-02,  2.44008936e-02,\n",
       "          4.10143286e-03,  1.39776226e-02,  3.80094387e-02, -4.62720282e-02,\n",
       "          2.21870001e-02, -2.32762676e-02, -2.05087569e-02,  3.16595510e-02,\n",
       "          3.05393687e-03,  3.27250846e-02,  1.41704101e-02, -1.20127723e-02,\n",
       "         -2.53402013e-02,  1.76242366e-03,  1.78871453e-02, -2.23143511e-02,\n",
       "         -1.93027221e-02, -4.71550599e-02, -1.02455067e-02,  4.65277955e-03,\n",
       "         -3.61075029e-02,  4.36186418e-02,  5.04175983e-02,  1.99042987e-02,\n",
       "         -4.28278521e-02, -2.80958433e-02, -5.38947321e-02,  4.79855649e-02,\n",
       "          2.81456560e-02, -1.73153561e-02,  1.89759564e-02,  4.28036936e-02,\n",
       "         -1.73384603e-02,  3.50394547e-02,  1.86360478e-02, -2.45236065e-02,\n",
       "          1.42649645e-02, -2.91836844e-03,  4.39960286e-02, -2.27134135e-02,\n",
       "         -2.49121822e-02,  1.66096948e-02,  1.25082815e-02,  1.40233850e-02,\n",
       "          3.45050246e-02,  8.57312046e-03,  3.68580706e-02,  1.26398867e-02,\n",
       "         -1.76676493e-02,  2.23364551e-02, -4.06190716e-02, -3.55526619e-02,\n",
       "          5.41096255e-02, -5.89545676e-03,  2.46877521e-02,  2.92918067e-02,\n",
       "          3.74656320e-02, -2.43779644e-03, -2.09254306e-02,  4.44639325e-02,\n",
       "         -2.07851697e-02,  3.36940549e-02, -1.84385397e-03,  3.13801952e-02,\n",
       "          4.22219299e-02, -5.41397110e-02, -4.58081290e-02,  3.32285203e-02,\n",
       "         -7.51606794e-03,  4.29621004e-02,  2.15870980e-02, -1.60573181e-02,\n",
       "         -3.41434255e-02, -1.93572845e-02,  4.50755358e-02, -1.13187861e-02,\n",
       "         -5.29710315e-02,  3.70301530e-02, -5.37751578e-02, -5.05500138e-02,\n",
       "         -1.63596980e-02, -2.81777028e-02,  3.28706689e-02,  2.34100390e-02,\n",
       "         -1.50293261e-02,  4.62196842e-02, -3.03909034e-02, -4.29572053e-02,\n",
       "          2.73003094e-02, -4.87301275e-02,  1.85988098e-02,  7.28477316e-04,\n",
       "          1.92445819e-03,  1.66539755e-02,  2.71063782e-02, -9.60523915e-03,\n",
       "          2.64629088e-02,  5.18292785e-02,  3.27076353e-02,  5.43935560e-02,\n",
       "         -4.75112349e-03,  1.71613507e-02,  1.94158610e-02, -5.30121587e-02,\n",
       "         -1.31497514e-02, -3.74502353e-02, -2.56769489e-02,  2.87466086e-02,\n",
       "          4.89951782e-02,  3.88478637e-02,  4.14393842e-03, -5.20546809e-02,\n",
       "          1.45756258e-02, -2.23362166e-02,  4.91262041e-02,  3.28153297e-02,\n",
       "         -4.97184061e-02, -1.55696005e-03,  5.25069237e-02, -2.29933523e-02,\n",
       "          1.15071768e-02, -4.69891168e-02, -2.47866213e-02,  2.99993064e-02,\n",
       "         -5.43963090e-02, -4.11846377e-02,  3.27472650e-02,  4.31843065e-02,\n",
       "          4.48463224e-02,  3.25821117e-02, -2.68277358e-02, -1.20834364e-02,\n",
       "         -4.09339890e-02, -3.86679955e-02, -1.24323983e-02,  7.16041028e-03,\n",
       "         -5.11444397e-02, -4.47433554e-02, -5.30385338e-02,  2.48727463e-02,\n",
       "         -2.58672982e-02,  2.19314341e-02,  1.49825746e-02, -4.91932705e-02,\n",
       "          3.33683304e-02,  3.71982343e-02,  5.37131615e-02, -5.04754670e-02,\n",
       "         -3.28194350e-02,  2.04236154e-02,  1.80769060e-02,  1.25788469e-02,\n",
       "         -3.99586596e-02,  3.74178290e-02, -4.82191816e-02,  2.19114386e-02,\n",
       "         -7.64396321e-03,  4.63024005e-02, -4.85627027e-03, -3.87275591e-02,\n",
       "         -1.43933687e-02, -1.08863413e-02,  4.96413447e-02,  5.26556605e-03,\n",
       "         -1.80906765e-02,  3.22885811e-02, -5.27847223e-02,  4.43315767e-02,\n",
       "         -1.69240925e-02,  6.84767868e-03,  1.63796898e-02,  2.14330368e-02,\n",
       "         -2.28346474e-02,  2.01625787e-02,  1.24040460e-02, -5.25348180e-04,\n",
       "         -3.88545766e-02,  3.13218907e-02,  3.40248481e-03,  1.21632386e-02,\n",
       "          4.20038262e-03, -2.40887459e-02,  8.85336287e-03,  3.43518070e-04,\n",
       "         -4.74007316e-02,  5.44358455e-02,  4.54431586e-02, -5.43551333e-02,\n",
       "          5.43993600e-02,  2.02725865e-02,  3.32316644e-02, -2.42101345e-02,\n",
       "          3.06295138e-02,  2.13242769e-02,  7.91875180e-03,  4.09506150e-02,\n",
       "          4.92672324e-02, -1.48479277e-02, -2.27604974e-02,  3.60370502e-02,\n",
       "          1.66708827e-02,  4.71649058e-02,  2.64557991e-02,  2.77412105e-02,\n",
       "         -1.26289958e-02, -5.11436863e-03,  1.57742202e-02, -2.59539969e-02,\n",
       "          9.60629957e-04,  3.11536882e-02,  4.97275181e-02, -2.41287481e-02,\n",
       "         -4.56691487e-03,  3.22598517e-02,  1.27500696e-02,  5.42523079e-02,\n",
       "          4.79610823e-02, -4.69334945e-02, -3.32848332e-03,  4.51229028e-02,\n",
       "          7.55543401e-03, -2.80231684e-02,  2.65174787e-02,  3.94576155e-02,\n",
       "          5.19577265e-02,  5.36314677e-03, -5.32324100e-03, -4.61338870e-02,\n",
       "         -4.69830744e-02,  4.12256792e-02, -1.18312025e-02,  2.59376820e-02,\n",
       "         -1.53541071e-02, -2.61807758e-02, -8.11219215e-03, -7.78081920e-03,\n",
       "          2.85364091e-02, -3.19843851e-02, -5.44117056e-02,  4.23220657e-02,\n",
       "         -2.19027940e-02,  2.45424937e-02,  1.79589130e-02, -5.29305898e-02,\n",
       "          7.18640210e-03, -2.27405727e-02,  4.60132547e-02,  4.06590141e-02,\n",
       "          3.91938947e-02,  1.62283275e-02, -5.11137769e-02, -1.19683165e-02,\n",
       "          3.18222530e-02, -2.72508506e-02,  1.63555332e-02, -3.99514250e-02,\n",
       "          3.41820940e-02,  1.45848617e-02, -2.30138097e-02,  6.85038837e-03,\n",
       "          1.02643133e-03, -4.87721302e-02, -1.20594334e-02, -4.11867015e-02,\n",
       "         -1.45403976e-02, -3.71248238e-02, -4.72760759e-02, -4.90231952e-03,\n",
       "         -7.51346443e-03, -8.80919583e-03, -2.36836765e-02,  3.60977873e-02,\n",
       "         -5.41736968e-02,  4.27619601e-03, -4.16986132e-03,  1.04148155e-02,\n",
       "          4.15445603e-02,  1.71595141e-02, -1.98114254e-02, -5.16838254e-03,\n",
       "          3.89390700e-02,  5.44425137e-02, -5.37771285e-02, -2.60386597e-02,\n",
       "          2.81965118e-02, -1.33168036e-02,  3.02690156e-02, -5.21167144e-02,\n",
       "         -4.07902561e-02, -6.05196645e-03,  5.05799241e-02,  1.54317031e-02,\n",
       "          4.31758240e-02, -1.73376855e-02, -4.53688502e-02,  7.76783680e-04,\n",
       "         -2.79598441e-02,  6.83998049e-04,  7.04620685e-03, -1.27417536e-03,\n",
       "         -1.54900709e-02, -4.24796045e-02,  4.90371399e-02, -4.14362215e-02,\n",
       "         -2.01674588e-02, -3.27814855e-02, -1.18045742e-02, -4.80069919e-03,\n",
       "         -4.86282781e-02, -5.43880686e-02,  5.13886400e-02,  3.88512947e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 8,\n",
       "  'topic_words': array(['neural', 'neurobiology', 'neurosciences', 'neurobiological',\n",
       "         'neuroscience', 'neurosci', 'neuronal', 'neurons', 'neuron',\n",
       "         'computational', 'neuroscientists', 'computing', '알고리즘',\n",
       "         'neuroscientist', 'neuro', 'neurol', 'neuroscientific',\n",
       "         'neurological', 'neurogenesis', 'computation', 'algorithms',\n",
       "         'neurobiol', 'computationally', 'neuroethics', 'neurocultures',\n",
       "         'neuroimaging', 'neurology', 'algorithmic', 'brainstem',\n",
       "         'algorithm', 'neuroimage', 'intelligence', 'probabilistic',\n",
       "         'computers', 'technology', 'cognitive', 'networks', 'clustering',\n",
       "         'neurosurg', '신경망', 'biology', 'computed', 'sklearn', 'brains',\n",
       "         'cerebrospinal', 'brain', 'forebrain', 'genome', 'computer',\n",
       "         'automated'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.05355863,  0.05466759, -0.00591001,  0.01750312, -0.02061409,\n",
       "         -0.01908107,  0.0184817 , -0.02653746,  0.04703543,  0.02915571,\n",
       "         -0.00753597,  0.01895838,  0.0439945 ,  0.00421045, -0.05391626,\n",
       "          0.01913887,  0.02160811, -0.03901644,  0.02295238,  0.04240113,\n",
       "          0.00144853, -0.04918227,  0.02303501,  0.04252379, -0.06150599,\n",
       "         -0.01670309,  0.05280387,  0.03353229, -0.0296168 , -0.01008106,\n",
       "          0.0180891 ,  0.04824412,  0.03952715, -0.05204409, -0.02844626,\n",
       "         -0.02920659, -0.00980716, -0.04604972, -0.01008516, -0.02887975,\n",
       "         -0.00981568,  0.04283929,  0.04937094,  0.0092685 , -0.0514154 ,\n",
       "          0.02527407,  0.04569638,  0.0141725 , -0.03219013, -0.01879191,\n",
       "          0.03153866, -0.03578518, -0.01347572,  0.00973262,  0.00772781,\n",
       "         -0.04357771,  0.01101222,  0.00984013,  0.02871944,  0.01748493,\n",
       "         -0.039298  ,  0.05458868, -0.03081134, -0.05404458, -0.03818858,\n",
       "         -0.00506097,  0.04119292, -0.04527904, -0.01484357, -0.00278156,\n",
       "         -0.02155579,  0.00496304, -0.00668965,  0.01046941,  0.02786228,\n",
       "          0.00397466,  0.0132629 ,  0.00045673,  0.01076051, -0.05968222,\n",
       "         -0.06147381, -0.05410185,  0.02179851,  0.02850213, -0.01023991,\n",
       "         -0.00039167,  0.01265517,  0.01118497,  0.03282766,  0.02988002,\n",
       "         -0.04618897, -0.01471345, -0.0278877 , -0.05507213,  0.02844598,\n",
       "          0.04991439,  0.03481555,  0.03951721,  0.02107108,  0.0017311 ,\n",
       "          0.03871261,  0.0453448 ,  0.00616466, -0.05382119,  0.03021476,\n",
       "         -0.03015754, -0.05864298,  0.00735484,  0.02309027,  0.03726665,\n",
       "         -0.01147491, -0.04852475, -0.03950948, -0.00801622,  0.04736621,\n",
       "         -0.05452477,  0.01212421,  0.00808645, -0.03418791,  0.02455525,\n",
       "          0.00440504,  0.04835623,  0.03757298, -0.02328213,  0.03136406,\n",
       "         -0.01094171,  0.00703895, -0.00274358, -0.00642334, -0.01088747,\n",
       "         -0.04038473,  0.00551945,  0.02302918,  0.02481682, -0.02689245,\n",
       "          0.0603006 , -0.03947062, -0.03622957,  0.04690379,  0.01608017,\n",
       "          0.06016969,  0.03041469,  0.0573774 ,  0.03046784,  0.04035531,\n",
       "         -0.00059126, -0.04440768,  0.04862855, -0.02238952,  0.01766153,\n",
       "          0.03035836,  0.04185925, -0.02304197, -0.05344694,  0.02036491,\n",
       "          0.01763385, -0.03430096, -0.04521992, -0.00687503, -0.0253838 ,\n",
       "          0.05339491, -0.03897687, -0.04767575,  0.00412755, -0.01954789,\n",
       "          0.00913281,  0.00519118, -0.00650156, -0.0520355 ,  0.03919232,\n",
       "         -0.04688108, -0.00461066, -0.01015675,  0.01428159, -0.01250236,\n",
       "          0.00061817, -0.01846617,  0.00114103, -0.04003825,  0.00766385,\n",
       "          0.00083199,  0.01987254,  0.00702524, -0.01928267, -0.03607697,\n",
       "          0.04562698,  0.02341258,  0.0547411 ,  0.01965679,  0.03714567,\n",
       "         -0.01100987, -0.01510489,  0.04988946,  0.00559728, -0.02530441,\n",
       "          0.03522052, -0.04707787,  0.04040836,  0.04151618,  0.04056238,\n",
       "         -0.01955944,  0.02546882, -0.0283279 , -0.03776226,  0.02721238,\n",
       "         -0.01396007, -0.02250191, -0.00621899,  0.0417532 ,  0.01019334,\n",
       "          0.01781245,  0.00230587, -0.03429838,  0.02128932,  0.04974978,\n",
       "         -0.03550704,  0.0127511 , -0.04066289, -0.01093448, -0.04909985,\n",
       "          0.01198014,  0.03048074,  0.00632505, -0.02231427, -0.04519484,\n",
       "         -0.03258849, -0.06028663,  0.03066481,  0.00849929,  0.03740614,\n",
       "         -0.04529071,  0.03973295, -0.0232624 ,  0.03566154,  0.04564315,\n",
       "          0.03472815,  0.01637173,  0.04411795,  0.06028027, -0.02343297,\n",
       "         -0.02208973,  0.02198391, -0.00414073, -0.0103757 ,  0.01455659,\n",
       "         -0.01936439,  0.04984043, -0.00373951,  0.00017451, -0.00289783,\n",
       "         -0.04800158, -0.02927778,  0.05865073, -0.01951897,  0.03294956,\n",
       "         -0.02304542,  0.00469255, -0.01544279, -0.01118646, -0.03415733,\n",
       "         -0.01704197,  0.01003245, -0.00223961,  0.00116055, -0.00973511,\n",
       "         -0.05930268, -0.00470784,  0.03858538, -0.01192497,  0.02726768,\n",
       "          0.00697586, -0.02918369, -0.02074073, -0.03459285,  0.03047401,\n",
       "          0.02411752, -0.05393714,  0.03258631, -0.05099403, -0.03980071,\n",
       "         -0.02766311, -0.02472977,  0.01768511,  0.03753169, -0.03532213,\n",
       "          0.04596264, -0.02001321, -0.03642523,  0.0226117 ,  0.01413127,\n",
       "          0.05039843,  0.01148648, -0.00509364, -0.0080198 , -0.04770562,\n",
       "         -0.00750887, -0.00626848,  0.04056101,  0.0186744 ,  0.05954165,\n",
       "         -0.00693634,  0.00450498,  0.02189988, -0.0486383 , -0.02918322,\n",
       "         -0.01810043, -0.01932804,  0.03997418,  0.00256277,  0.04918023,\n",
       "         -0.02903192, -0.01408419, -0.03631079, -0.03102837,  0.02366499,\n",
       "          0.0248224 , -0.0416773 ,  0.00797661,  0.05133274, -0.02131616,\n",
       "          0.03075488, -0.02343515, -0.01777821, -0.02384082, -0.05466253,\n",
       "         -0.01626236,  0.0284676 , -0.01188036,  0.01375493,  0.03255055,\n",
       "         -0.01153243, -0.03675548, -0.00181781, -0.02909945, -0.01342892,\n",
       "         -0.00651855, -0.04284098, -0.03074558, -0.05849952,  0.00222248,\n",
       "         -0.05384487,  0.01297668, -0.00342311, -0.04442638,  0.00795231,\n",
       "          0.03828537,  0.03277666,  0.02645356, -0.00732998,  0.01909404,\n",
       "         -0.01363015, -0.0261973 ,  0.02013914,  0.03498997, -0.05453309,\n",
       "         -0.00197019,  0.00793317,  0.03574317, -0.02753242, -0.0100679 ,\n",
       "          0.0259025 , -0.00956252,  0.03814594, -0.03756042, -0.03371515,\n",
       "          0.0453866 , -0.00820592,  0.04388488, -0.01564193, -0.03520288,\n",
       "          0.04373429,  0.03771686, -0.04051211,  0.04748642,  0.02645681,\n",
       "         -0.03960174, -0.04960159, -0.01700523, -0.03109816, -0.04747253,\n",
       "         -0.00770501,  0.00090086,  0.03501638,  0.01901225, -0.01196   ,\n",
       "          0.05773129,  0.03990341, -0.04739168,  0.06049754, -0.00224615,\n",
       "          0.01954099, -0.04296089, -0.00984725,  0.02975962, -0.03023896,\n",
       "         -0.00659366,  0.03902425, -0.00936345, -0.05296391,  0.0087696 ,\n",
       "          0.03788595,  0.0462536 ,  0.04839984,  0.01807116, -0.04129293,\n",
       "          0.01595773,  0.03047234, -0.02194223,  0.02326249,  0.01400047,\n",
       "          0.02283285, -0.00520678,  0.00536951,  0.01235184,  0.02568098,\n",
       "          0.05790976,  0.00990857, -0.01520698, -0.01121715,  0.03278255,\n",
       "          0.01187116, -0.03653223,  0.04170495,  0.04532191,  0.05581173,\n",
       "          0.01514855,  0.02593588, -0.05478922, -0.04677129, -0.01688228,\n",
       "         -0.01169886,  0.01419829, -0.01994748, -0.00854904,  0.02802922,\n",
       "          0.04092822,  0.02949585, -0.01150406, -0.06089367,  0.03592983,\n",
       "         -0.00418305,  0.02663699,  0.011153  , -0.05463131, -0.01184389,\n",
       "         -0.02926525,  0.01025835,  0.03281492,  0.05328565,  0.00160424,\n",
       "         -0.03469338, -0.03089939, -0.02283238,  0.00961868, -0.01835297,\n",
       "         -0.01605448,  0.04419915, -0.00457564,  0.00714004,  0.02856637,\n",
       "         -0.00778269, -0.05232185, -0.01151477, -0.0359045 ,  0.01222688,\n",
       "         -0.05616957, -0.05438576,  0.00496748,  0.05087968, -0.05688353,\n",
       "          0.00778593,  0.05688154, -0.01881551, -0.03081747,  0.01015175,\n",
       "         -0.03658934, -0.01881875,  0.03205336,  0.02860896, -0.00378552,\n",
       "          0.04325617,  0.06180069, -0.04057111,  0.03420781,  0.04928984,\n",
       "         -0.04094565,  0.01709433, -0.0465135 , -0.05803546, -0.00932988,\n",
       "          0.04301386,  0.03408052,  0.02535915,  0.00516678,  0.01740706,\n",
       "         -0.03848797, -0.0048752 , -0.01028355,  0.00413775, -0.00089333,\n",
       "          0.04136317, -0.05806582,  0.05548314, -0.04141028, -0.04166441,\n",
       "         -0.05582402, -0.02978062, -0.01055524, -0.04063574, -0.06139908,\n",
       "          0.03523293,  0.02050911], dtype=float32)},\n",
       " {'topic_idx': 9,\n",
       "  'topic_words': array(['대중교통', 'stations', 'station', '지하철', 'population', 'trains', '인구',\n",
       "         '직원', 'workers', 'populations', 'employees', '서울', '통계청', '노동자',\n",
       "         '열차', 'staff', '평양', '서울시', '서울대', 'train', '기차', '대중',\n",
       "         'statistic', 'seoul', 'metro', '공공', 'statistics', '학회',\n",
       "         'statistically', '복지', 'community', 'statistical', '병원', 'society',\n",
       "         '산업', '통계', 'employee', 'regularization', '직장인', '면역',\n",
       "         'uniformity', '정리', '사회', '노동', 'widespread', 'job', 'colleagues',\n",
       "         'communications', '뉴스', 'daily'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.01630189,  0.00664857, -0.00458566,  0.02788934,  0.02406366,\n",
       "          0.03792121, -0.03259746,  0.01502277,  0.03334042,  0.04290975,\n",
       "         -0.02650789, -0.03554223,  0.01772133, -0.00148689, -0.0300325 ,\n",
       "         -0.00288824,  0.0208513 , -0.04071221,  0.00376289,  0.05457772,\n",
       "          0.03615469, -0.04849959,  0.01809195, -0.00106766, -0.0604768 ,\n",
       "         -0.02806856,  0.01513524, -0.00595937,  0.0329197 , -0.05227873,\n",
       "         -0.028952  , -0.03614845,  0.02698877, -0.0317355 ,  0.03476623,\n",
       "         -0.01245607, -0.0128223 , -0.05942839, -0.0215564 , -0.01611219,\n",
       "         -0.03211059,  0.01366229,  0.01458985, -0.05528877,  0.03160141,\n",
       "         -0.05215083, -0.01250718, -0.03931113, -0.03094389,  0.00912946,\n",
       "         -0.00291842, -0.0009536 ,  0.03818351, -0.04162896,  0.0241455 ,\n",
       "         -0.0598363 ,  0.02471637,  0.00739489, -0.02182759,  0.00400884,\n",
       "          0.01974404,  0.05255464,  0.00897264, -0.038824  ,  0.00353121,\n",
       "         -0.02582853,  0.01136129, -0.03352443, -0.01286657,  0.01696959,\n",
       "          0.01792177,  0.03956638,  0.02489237,  0.00582855, -0.01781557,\n",
       "          0.03627556,  0.01779132, -0.00855922, -0.01740964, -0.0625442 ,\n",
       "         -0.06441057, -0.01953451,  0.04530112,  0.02405845, -0.02654593,\n",
       "         -0.00489473, -0.0424104 , -0.00817991,  0.01378809, -0.02032526,\n",
       "         -0.02751655,  0.01136232, -0.03824484,  0.0029233 ,  0.0145306 ,\n",
       "         -0.01455277,  0.02727089,  0.04126726,  0.00787694, -0.00717367,\n",
       "          0.01231484,  0.00012009, -0.00435371, -0.00745832, -0.03002018,\n",
       "         -0.00851814, -0.03068419, -0.02271364, -0.02344842, -0.00712135,\n",
       "          0.0201551 ,  0.01162476,  0.03883506,  0.001968  ,  0.03602534,\n",
       "         -0.03869605,  0.01388233,  0.01544753, -0.04208399, -0.0328365 ,\n",
       "          0.00159898, -0.00644821,  0.03166908, -0.03393056,  0.03279993,\n",
       "          0.02783921,  0.02667863,  0.0388229 , -0.02581632,  0.03327832,\n",
       "         -0.05318246, -0.00353097, -0.00163447,  0.03424753,  0.00897777,\n",
       "          0.06233722,  0.03491061, -0.02191334,  0.05762454,  0.0393002 ,\n",
       "          0.04022329, -0.02746535,  0.02906498,  0.03341375,  0.02263395,\n",
       "         -0.02426726,  0.04126089,  0.00506088,  0.03424374,  0.01425708,\n",
       "          0.0117354 ,  0.03369201, -0.04769828, -0.00848047,  0.03571666,\n",
       "         -0.03816021, -0.01766161, -0.00292522,  0.0224778 , -0.03530188,\n",
       "          0.03475883, -0.05151524,  0.02992129,  0.03729595, -0.0029831 ,\n",
       "         -0.02308809,  0.04774211, -0.00422315, -0.02838361, -0.03922897,\n",
       "         -0.00195323,  0.00697083, -0.01382047,  0.03046856,  0.03978502,\n",
       "          0.05435226, -0.00689379, -0.03804496, -0.03374878,  0.04048643,\n",
       "          0.00812216, -0.01465571,  0.01615782, -0.02326495, -0.00506961,\n",
       "         -0.00804442,  0.02579441,  0.05380888, -0.00307151,  0.0008416 ,\n",
       "         -0.02694706, -0.00975965, -0.01058344, -0.02447634, -0.00935516,\n",
       "          0.02042535, -0.0054821 ,  0.02292341,  0.00997623,  0.00315603,\n",
       "         -0.05898832,  0.00451713, -0.02001   , -0.06099134, -0.03074832,\n",
       "         -0.00671796,  0.04323968,  0.02152547,  0.00828453,  0.04822297,\n",
       "         -0.01959518,  0.03403522, -0.04948822, -0.00729661, -0.0124478 ,\n",
       "          0.04245323,  0.00235144, -0.04332197, -0.04309003,  0.02426924,\n",
       "         -0.04964356,  0.03821641, -0.00220542,  0.00987982, -0.00512662,\n",
       "         -0.01202575, -0.02051982,  0.03186577, -0.01536573,  0.00959158,\n",
       "          0.0300602 , -0.03946655, -0.00288164, -0.02633789,  0.02297993,\n",
       "         -0.02852353,  0.00862266,  0.00770312,  0.0297647 ,  0.02093896,\n",
       "          0.02966559, -0.01576563,  0.04401666, -0.00274624,  0.03094789,\n",
       "          0.00385222,  0.02403314,  0.02399103,  0.00850239, -0.04081386,\n",
       "         -0.04237876, -0.0393475 , -0.02695984,  0.06302447,  0.0080745 ,\n",
       "         -0.00693986,  0.03931424, -0.01829292, -0.03334525,  0.05464091,\n",
       "          0.0259628 ,  0.02499609, -0.03185414, -0.01889825, -0.02435839,\n",
       "         -0.04981505, -0.04088058,  0.04818898,  0.01204096,  0.02618704,\n",
       "         -0.04897741, -0.01957536,  0.01509089, -0.01227018, -0.02366523,\n",
       "          0.02107232,  0.01021876, -0.00787447, -0.05878616, -0.01128928,\n",
       "          0.02608347, -0.03453811,  0.02172426, -0.03764174, -0.00424945,\n",
       "         -0.0182958 , -0.05550748, -0.00154128, -0.01577293, -0.04858876,\n",
       "         -0.01420715,  0.01549801,  0.0027165 ,  0.03206109, -0.02354488,\n",
       "          0.0200551 , -0.01826848,  0.00474374,  0.01138033,  0.01305974,\n",
       "          0.04508253,  0.02849875, -0.01222473, -0.01617517,  0.00965415,\n",
       "         -0.04354412,  0.01899099,  0.02425863,  0.03770144, -0.03776906,\n",
       "         -0.00736586,  0.01614907, -0.03370961,  0.04735804,  0.04905672,\n",
       "          0.02152721, -0.05263252,  0.00731561,  0.01759483,  0.01634288,\n",
       "         -0.02390043, -0.00175821, -0.020401  ,  0.03465402,  0.01940226,\n",
       "         -0.02230778,  0.02016784,  0.02529552, -0.00969874,  0.0242465 ,\n",
       "         -0.00834475, -0.03363405, -0.03112357,  0.01567912, -0.04665064,\n",
       "         -0.04433567, -0.03037233,  0.01811802, -0.05766033, -0.02476936,\n",
       "         -0.02908926, -0.00912502,  0.00524182,  0.00546543, -0.03202353,\n",
       "          0.00191504,  0.02000218,  0.0013873 ,  0.01603971,  0.03062688,\n",
       "         -0.01798717, -0.04734528,  0.01820499,  0.03180876,  0.00792345,\n",
       "          0.03218988, -0.03596488,  0.03150716, -0.02458635, -0.04595415,\n",
       "          0.04175863,  0.00864743,  0.04653348,  0.00459303,  0.00044116,\n",
       "         -0.00261173, -0.03306198, -0.00621011,  0.04834999,  0.01404485,\n",
       "          0.01813017,  0.0522845 , -0.01519687,  0.04415917,  0.03616634,\n",
       "         -0.01310049, -0.00027366, -0.00166139,  0.00965682,  0.03436011,\n",
       "          0.00099036,  0.03175118,  0.02531252,  0.02974531,  0.02255752,\n",
       "          0.02183399, -0.00935729, -0.05575386,  0.05982503,  0.00480058,\n",
       "         -0.00822988,  0.021584  , -0.0015063 ,  0.00317977,  0.00441997,\n",
       "         -0.02791359,  0.00401896,  0.0398755 , -0.01703798,  0.05028626,\n",
       "          0.02772109,  0.0376035 ,  0.05728728, -0.02758127, -0.02648826,\n",
       "         -0.02227092, -0.04734048, -0.00060041, -0.03758816,  0.02305294,\n",
       "          0.04166868, -0.00468622,  0.00888353,  0.01485024,  0.00253013,\n",
       "          0.03883067,  0.03666018,  0.00889261, -0.0091008 , -0.03237364,\n",
       "         -0.00442261,  0.03772347, -0.04194406,  0.05078231,  0.01822145,\n",
       "         -0.03763965,  0.04427078, -0.04469894, -0.01002828, -0.01671195,\n",
       "         -0.00255486, -0.0125922 ,  0.03510106, -0.03611298,  0.03952536,\n",
       "         -0.02176877,  0.03738925,  0.04805391, -0.05635595,  0.03901723,\n",
       "          0.01315152,  0.03776481,  0.00203075, -0.05131603,  0.04619992,\n",
       "          0.03202273,  0.05442312, -0.03481387,  0.01946813,  0.05544067,\n",
       "          0.01945898,  0.02814887,  0.04505673,  0.02713101, -0.04075955,\n",
       "         -0.013086  ,  0.04209518, -0.01334816,  0.02061685, -0.00448981,\n",
       "         -0.0170391 ,  0.00145852, -0.00912065, -0.00669036,  0.02935944,\n",
       "         -0.05392603, -0.03327261,  0.03043972,  0.01681045, -0.01178704,\n",
       "          0.03724261,  0.02374176,  0.00826476,  0.0258101 , -0.0357    ,\n",
       "         -0.03192386,  0.04008029, -0.03379284, -0.03658637, -0.01752609,\n",
       "          0.0376891 ,  0.05693747, -0.02032989, -0.02123818, -0.00074924,\n",
       "          0.00394998,  0.0367443 , -0.05482785, -0.0302629 , -0.00782215,\n",
       "          0.03706335,  0.04489986,  0.03584267, -0.02227052, -0.00905468,\n",
       "         -0.01254844, -0.021148  ,  0.01641892,  0.03932972,  0.03588645,\n",
       "          0.01392885,  0.00873094,  0.05382195,  0.01944973, -0.0584232 ,\n",
       "         -0.04519848,  0.03237567, -0.00680438, -0.01022605, -0.04360682,\n",
       "         -0.01581609, -0.02441059], dtype=float32)},\n",
       " {'topic_idx': 10,\n",
       "  'topic_words': array(['함수', 'function', 'python', 'cython', 'functions', '변수', 'numpy',\n",
       "         'varlambda', 'functional', 'args', 'kwargs', '파이썬', '기능',\n",
       "         'subprocess', 'functionally', 'compiler', 'stdout', '잠재변수',\n",
       "         'operatorname', '프로그래밍', 'variables', 'func', 'parameter',\n",
       "         'integer', '코딩', 'variable', '파라미터', 'matplotlib', 'dict',\n",
       "         'multiprocessing', 'keyword', 'java', 'programming', 'parameters',\n",
       "         'compile', 'gcc', 'javascript', '컴파일러', 'integers', 'functioning',\n",
       "         'foldername', 'feature', 'syntax', '자바', 'keywords',\n",
       "         'dysfunctional', 'name', 'features', 'coded', '컴파일'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.04370644,  0.01262759, -0.04284199, -0.01375303,  0.01207036,\n",
       "         -0.05617554,  0.00057319,  0.02752553,  0.05667169, -0.04525178,\n",
       "         -0.01044363,  0.05281058,  0.03853972, -0.0403895 , -0.05672569,\n",
       "         -0.0131895 ,  0.02067605, -0.02564979,  0.04204746,  0.04907052,\n",
       "          0.00412305, -0.01239187,  0.03948484,  0.04319189, -0.05677094,\n",
       "         -0.02765316,  0.00293893,  0.0164372 ,  0.02995052, -0.01207849,\n",
       "          0.01264524,  0.02670744, -0.01774894, -0.05300754,  0.00310642,\n",
       "         -0.03671889, -0.02892238, -0.00468184, -0.00759775,  0.02472478,\n",
       "          0.01025999, -0.04635558,  0.03406765,  0.01788829, -0.02759263,\n",
       "          0.02886936,  0.04584022, -0.011264  , -0.00933814,  0.02852326,\n",
       "         -0.0095684 , -0.0105624 , -0.04372532, -0.02191726, -0.00769027,\n",
       "         -0.04552295,  0.00925086,  0.03877254,  0.0513279 ,  0.00831369,\n",
       "          0.00402699,  0.04577871, -0.03393795, -0.02841187, -0.02152562,\n",
       "          0.04625791,  0.02559494, -0.03599259, -0.00704199, -0.03842508,\n",
       "         -0.02943389,  0.02038392, -0.0342216 , -0.04109881,  0.01050622,\n",
       "         -0.03387181, -0.0243051 ,  0.01694912,  0.05180665, -0.05796974,\n",
       "         -0.05801397, -0.02590699,  0.02212075, -0.0184252 ,  0.02757349,\n",
       "          0.01346622,  0.03061506, -0.03279522,  0.02172488,  0.00372323,\n",
       "         -0.02304608, -0.01174483,  0.03986084, -0.01586813,  0.04012841,\n",
       "          0.00420197, -0.05494342,  0.03387372,  0.0335767 ,  0.00288608,\n",
       "         -0.0351244 ,  0.01514087,  0.01849942,  0.03691948,  0.04937271,\n",
       "          0.04758544,  0.00733687, -0.04003494, -0.02448694,  0.03072573,\n",
       "          0.02809628, -0.02964548,  0.02290491, -0.00514678,  0.04027542,\n",
       "         -0.04318976, -0.01395981, -0.0147707 , -0.008231  ,  0.04353437,\n",
       "         -0.03739963, -0.01550579,  0.01188429,  0.03165501,  0.03618925,\n",
       "         -0.02377412, -0.03051579,  0.04036411, -0.0083941 ,  0.03320913,\n",
       "         -0.03224917,  0.0388957 ,  0.05131706,  0.00524093, -0.04888661,\n",
       "          0.01617733,  0.02301663,  0.01492763,  0.03242088,  0.00700512,\n",
       "          0.00754282,  0.03350161,  0.01003503, -0.00089818,  0.02666311,\n",
       "          0.02995545, -0.03058914,  0.02794397,  0.02497019, -0.01671671,\n",
       "          0.05060564,  0.03807094, -0.03860801,  0.0202835 , -0.00209803,\n",
       "         -0.02899863, -0.02432377,  0.01146571, -0.01458008, -0.03058309,\n",
       "          0.04087842,  0.02880321,  0.00677516,  0.03265348, -0.00574055,\n",
       "         -0.01878886,  0.0218159 ,  0.00814476, -0.02868048,  0.0341905 ,\n",
       "          0.0220276 , -0.01485626,  0.02649851,  0.01758159, -0.01381303,\n",
       "          0.02750951, -0.01603432, -0.02471293, -0.03729188,  0.03620227,\n",
       "         -0.01393911,  0.04887238, -0.01764122, -0.02951248, -0.03867206,\n",
       "          0.01332323,  0.0193122 ,  0.05624547,  0.0114689 , -0.04914887,\n",
       "          0.03765084, -0.03237326,  0.03305496, -0.00905341, -0.04713875,\n",
       "         -0.02495374, -0.01824748, -0.00168541, -0.01132509, -0.01969966,\n",
       "          0.04627497,  0.01179057, -0.0301451 ,  0.00486017, -0.02977802,\n",
       "          0.02060526,  0.05526847, -0.02412437,  0.04191672,  0.01087037,\n",
       "          0.01390463,  0.05349716,  0.00152002,  0.00781077,  0.03320351,\n",
       "         -0.01477143, -0.03157871, -0.00636741,  0.0004415 ,  0.01627447,\n",
       "         -0.02555763, -0.02253702,  0.03508961,  0.00141071, -0.05356885,\n",
       "         -0.0328032 ,  0.02413516, -0.03358457, -0.00392901, -0.02343652,\n",
       "          0.04010229,  0.05648591,  0.02015175, -0.01234211, -0.00496248,\n",
       "          0.00557103, -0.02526559,  0.00512204, -0.03629379,  0.00024077,\n",
       "          0.0138687 ,  0.02738914, -0.017436  ,  0.0052053 ,  0.02226416,\n",
       "         -0.05172134,  0.03539711,  0.00847009, -0.02012322,  0.01079493,\n",
       "         -0.01242045,  0.00033124, -0.01478943,  0.01694608,  0.04789843,\n",
       "         -0.00388738,  0.00797331, -0.03328227, -0.00585209,  0.00386837,\n",
       "          0.03559442,  0.00167412, -0.0311434 , -0.03299554,  0.03850779,\n",
       "         -0.05250837, -0.01580067, -0.0016952 , -0.00632117,  0.01638499,\n",
       "          0.01967094, -0.04234635, -0.01183778, -0.00047389,  0.02615334,\n",
       "          0.03099764, -0.04205549,  0.00934233, -0.03264266, -0.03038637,\n",
       "         -0.0243913 ,  0.02546207, -0.01377705,  0.02777086, -0.0424406 ,\n",
       "          0.0447332 , -0.0375908 , -0.00183173,  0.00126074,  0.01371424,\n",
       "         -0.0213982 , -0.00204459, -0.00218948,  0.04434771, -0.04865866,\n",
       "          0.02932824, -0.00264396,  0.01796687, -0.01807418,  0.00892729,\n",
       "          0.02492975, -0.02963583, -0.01218152, -0.05453821,  0.0012997 ,\n",
       "          0.00721699, -0.03546105, -0.00395316, -0.03998971,  0.00708396,\n",
       "          0.0376282 ,  0.03057193, -0.00503156, -0.03432789, -0.03753749,\n",
       "          0.00527539, -0.03063864, -0.01742526,  0.0254976 , -0.03241625,\n",
       "         -0.02655639,  0.00446131,  0.01917428,  0.00015525, -0.04891602,\n",
       "         -0.04201576, -0.02220686, -0.03925972,  0.0433998 , -0.02251793,\n",
       "         -0.03910486, -0.05080926, -0.05128693, -0.03772351, -0.01664443,\n",
       "          0.03366254, -0.0179835 , -0.01525911, -0.04420167, -0.01870846,\n",
       "          0.03131099, -0.02749614,  0.02980513, -0.0112609 ,  0.00946111,\n",
       "          0.02442637,  0.01580542,  0.02800896,  0.03912541,  0.03659464,\n",
       "         -0.03549793,  0.04361572,  0.00123064,  0.01366761, -0.02767074,\n",
       "         -0.00033501,  0.00662871,  0.00379272, -0.04114223, -0.04482224,\n",
       "         -0.00474803,  0.01278165,  0.00919071, -0.01591657,  0.03646509,\n",
       "         -0.0293307 ,  0.02686137,  0.0449232 , -0.01148054,  0.02879749,\n",
       "          0.00251477, -0.03251725, -0.04723926, -0.04622578,  0.01817467,\n",
       "         -0.02514326, -0.0294935 ,  0.04358016, -0.04872224, -0.04036414,\n",
       "         -0.02623714, -0.04423511,  0.00850097,  0.00101619, -0.03649215,\n",
       "          0.00146993,  0.01403724, -0.05807235,  0.05107904,  0.0416011 ,\n",
       "          0.04910406,  0.00186146, -0.00774694,  0.02991592, -0.04298896,\n",
       "         -0.01438442,  0.02764669, -0.01499198, -0.01881621,  0.02950441,\n",
       "          0.03957093,  0.03354529,  0.0519212 , -0.0290349 ,  0.03187039,\n",
       "          0.03207603, -0.04754355, -0.02587303, -0.00972788, -0.02999834,\n",
       "         -0.00815306, -0.00333549,  0.04246624, -0.03806715,  0.02470652,\n",
       "         -0.02774367,  0.05295606,  0.04362513, -0.01027635,  0.03570711,\n",
       "          0.03012496,  0.04072031,  0.03724558,  0.04338975, -0.02984242,\n",
       "          0.05728269,  0.03281113, -0.01420985, -0.0012406 ,  0.01091459,\n",
       "          0.0284533 ,  0.01529165,  0.0322983 ,  0.0201099 ,  0.03221107,\n",
       "          0.02556096,  0.00191494, -0.02283169, -0.05121179,  0.00196118,\n",
       "         -0.032056  ,  0.02351999,  0.02439091, -0.04146594, -0.01921327,\n",
       "         -0.01217936,  0.04372861, -0.02161065,  0.04634321,  0.00360937,\n",
       "          0.02273873, -0.00949775, -0.05712622,  0.04124606,  0.04247039,\n",
       "         -0.03990082,  0.02487097, -0.0170701 , -0.00177404,  0.0461795 ,\n",
       "         -0.01463012,  0.01095964,  0.01348704, -0.03627239, -0.03479246,\n",
       "         -0.00069568, -0.01178109, -0.0422925 ,  0.05127185, -0.02155888,\n",
       "         -0.01148209, -0.03643344, -0.0012748 , -0.00708873, -0.04426904,\n",
       "          0.00121681,  0.01783681,  0.01115552,  0.00242329,  0.03760754,\n",
       "         -0.00027962,  0.02567652, -0.02621429,  0.03516482, -0.0329294 ,\n",
       "          0.04095899, -0.01261182, -0.05243792,  0.00303702, -0.03920184,\n",
       "          0.00104766,  0.03027396, -0.04740419,  0.01506559,  0.00361036,\n",
       "         -0.00065578, -0.01995333, -0.0450814 ,  0.03654931,  0.04336918,\n",
       "         -0.03675047, -0.00034407,  0.05237257, -0.03300173, -0.03683133,\n",
       "         -0.05793606,  0.04040812, -0.03633243,  0.00495133, -0.02743729,\n",
       "          0.02202715, -0.02198873], dtype=float32)},\n",
       " {'topic_idx': 11,\n",
       "  'topic_words': array(['regression', 'correlation', 'statistical', 'statistically',\n",
       "         'correlations', 'covariance', '모델', 'models', 'variance',\n",
       "         'modelling', 'statistics', 'probabilistic', 'model', '통계청',\n",
       "         'variances', 'statistic', 'predictor', 'correlated', 'correlates',\n",
       "         'predictive', 'coefficient', 'correlate', '통계', 'probability',\n",
       "         'modeled', 'predictors', 'coefficients', 'predicts', 'populations',\n",
       "         'predicting', '회귀분석', 'normalization', 'nonparametric', 'predict',\n",
       "         'clustering', '관계', 'estimator', 'relationship', 'replication',\n",
       "         'ratio', 'proportional', 'paradigm', '추정', 'relationships',\n",
       "         'modeling', 'paradigms', 'regressors', 'demographic', 'relation',\n",
       "         'regressor'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.0623419 , -0.01578586, -0.03157091, -0.00568523, -0.03854634,\n",
       "          0.0178907 ,  0.01877877, -0.02087759,  0.04445074,  0.02374084,\n",
       "         -0.03625689,  0.02965275,  0.05150903,  0.01488623, -0.06212788,\n",
       "         -0.02735045,  0.00590188, -0.03405323,  0.00457899,  0.02543478,\n",
       "         -0.04638826, -0.05137062, -0.0600846 ,  0.04667662, -0.06239542,\n",
       "         -0.05138206,  0.03507155,  0.04825993, -0.01670673, -0.0304992 ,\n",
       "         -0.04795673,  0.02990029,  0.02311119, -0.05401896, -0.01670245,\n",
       "         -0.00654964, -0.05446208,  0.02141891,  0.02461852,  0.04284255,\n",
       "          0.01609173,  0.00159921,  0.05096944, -0.0585417 , -0.03986552,\n",
       "         -0.04864731,  0.06012962, -0.01771159, -0.04708357, -0.03534533,\n",
       "         -0.00407683, -0.03000537,  0.04457443, -0.03033642,  0.05001967,\n",
       "         -0.05550871,  0.02672865,  0.03152739, -0.0220647 ,  0.04629928,\n",
       "          0.03102999,  0.04136699, -0.00380959, -0.0488642 ,  0.00479585,\n",
       "         -0.00559775,  0.03718216, -0.01454762, -0.01866434, -0.00532408,\n",
       "         -0.04752919,  0.00117025, -0.01971328, -0.0520377 , -0.06060219,\n",
       "         -0.04976626,  0.04240533,  0.04071027,  0.004649  , -0.06123679,\n",
       "         -0.06253383, -0.04715341,  0.03067681,  0.01219714, -0.01183718,\n",
       "         -0.02273228, -0.05436798, -0.03909887, -0.00664481, -0.02818964,\n",
       "         -0.04076869, -0.03349781,  0.04713859, -0.06073358,  0.04598835,\n",
       "          0.06170654,  0.04048144,  0.02150369,  0.01744251,  0.03749913,\n",
       "          0.04184554, -0.0237358 ,  0.05322261,  0.01720806,  0.00382727,\n",
       "         -0.0583097 , -0.04888614, -0.03073252,  0.00275149,  0.05000873,\n",
       "          0.0573953 , -0.05674643, -0.04866048,  0.01555427,  0.02910705,\n",
       "          0.03889942,  0.04742647, -0.00416698, -0.04405178,  0.01623587,\n",
       "         -0.01258832,  0.03062514,  0.01329577,  0.02609771,  0.03974892,\n",
       "          0.04336992, -0.04088372,  0.06105657, -0.05990989,  0.04112906,\n",
       "         -0.05996026,  0.02352367,  0.05912992,  0.04743765, -0.02942401,\n",
       "          0.03945773, -0.02310796,  0.01159639,  0.03809636,  0.02212792,\n",
       "          0.00656287, -0.04578263,  0.01197708, -0.05068645,  0.02922101,\n",
       "          0.01651631, -0.05327729,  0.03827781,  0.0293026 ,  0.04474716,\n",
       "          0.03311404, -0.0285458 , -0.0290114 , -0.04191886,  0.03440971,\n",
       "         -0.04511892,  0.00335096, -0.00117673, -0.00860145, -0.00779611,\n",
       "         -0.00720898, -0.01803177, -0.01722923, -0.05531755, -0.0370964 ,\n",
       "         -0.02141059,  0.00466076,  0.01244176, -0.04192809,  0.0557871 ,\n",
       "         -0.0409085 , -0.00898366,  0.02029847, -0.02502703, -0.01738285,\n",
       "          0.00512216,  0.05063906,  0.04934286, -0.05476795,  0.03660097,\n",
       "          0.03406924, -0.00623071, -0.01206915,  0.02120458, -0.05589093,\n",
       "         -0.04668677,  0.05142437,  0.05741924, -0.05211037, -0.0552368 ,\n",
       "         -0.03923826,  0.02761304,  0.00562112, -0.02483498, -0.01141213,\n",
       "          0.00422241, -0.06171021, -0.05418983,  0.06048423,  0.03450182,\n",
       "         -0.02292997,  0.01475086, -0.05876588,  0.01556209, -0.00209578,\n",
       "         -0.04763799, -0.06160424,  0.03053187, -0.01992182,  0.05969425,\n",
       "         -0.00930607,  0.01372265, -0.0620907 , -0.00350654,  0.04982023,\n",
       "         -0.03359808, -0.05026475, -0.04155926, -0.01950197, -0.01892594,\n",
       "          0.02749396,  0.01071142,  0.0212185 ,  0.0144205 , -0.06111495,\n",
       "          0.01047987, -0.05648766, -0.00994529, -0.0314419 ,  0.03828377,\n",
       "         -0.00509517,  0.05581585, -0.05433665, -0.02507623,  0.00873462,\n",
       "         -0.00949117, -0.00558581,  0.03212111, -0.00704951, -0.02278493,\n",
       "          0.0278774 , -0.00140889, -0.05369036,  0.01148491,  0.03072459,\n",
       "         -0.05494231, -0.00303373,  0.01278508, -0.02774532,  0.02696718,\n",
       "         -0.01773732, -0.05137331,  0.00102901, -0.04110313, -0.04033358,\n",
       "         -0.01558651, -0.01631879,  0.00379707,  0.00347236,  0.00392809,\n",
       "          0.02892368,  0.02376726, -0.03376615, -0.0166994 ,  0.02173544,\n",
       "         -0.06154732, -0.02165104,  0.00031373,  0.00679594, -0.03024908,\n",
       "          0.00614857, -0.03561462, -0.03955416, -0.05339449, -0.01364204,\n",
       "          0.00420254, -0.05650173,  0.0522879 , -0.06052729, -0.00062457,\n",
       "         -0.05828768, -0.01449621,  0.03994019,  0.00326666, -0.00836494,\n",
       "          0.06096378, -0.0141549 , -0.03855417, -0.01565417,  0.0576115 ,\n",
       "          0.04244962,  0.05588655,  0.05920469, -0.01630413, -0.05036315,\n",
       "          0.03493499, -0.01225753,  0.01667584,  0.05121638,  0.04710865,\n",
       "         -0.05832429,  0.05321354, -0.0282549 , -0.06000172, -0.06244382,\n",
       "         -0.00337723, -0.00097701,  0.0062164 , -0.02388311,  0.00782925,\n",
       "         -0.04794846, -0.03800746, -0.04426162, -0.0263939 ,  0.02952464,\n",
       "          0.02867663,  0.05016802, -0.03397223,  0.0052106 , -0.02090559,\n",
       "          0.02572464, -0.01067397, -0.05445641, -0.02367494, -0.04983596,\n",
       "          0.01636109, -0.00503993, -0.00155501, -0.00133489,  0.00552853,\n",
       "         -0.00274027, -0.05222179,  0.00595654, -0.03141171, -0.04643679,\n",
       "          0.01074144, -0.05162505, -0.02725756, -0.06215018, -0.03978758,\n",
       "         -0.04882267, -0.01255186,  0.03384922, -0.02111336, -0.03378822,\n",
       "          0.04678512,  0.05463013,  0.01630171, -0.04851968,  0.01849751,\n",
       "          0.02890169,  0.00743954, -0.01030096,  0.00963988,  0.03972001,\n",
       "          0.01150678,  0.00603288,  0.02706692, -0.05907433, -0.04388186,\n",
       "          0.05551484, -0.05440478,  0.00179919, -0.02169617, -0.05101086,\n",
       "          0.00921651, -0.00232291,  0.03067057, -0.02205227,  0.06169757,\n",
       "          0.04619638,  0.05925778, -0.05296424,  0.04292117, -0.0233328 ,\n",
       "         -0.05517516,  0.02569134,  0.01849226, -0.04622987, -0.05597867,\n",
       "          0.02114684, -0.05715135,  0.00035994, -0.03444789, -0.02437865,\n",
       "          0.05307686,  0.01679777, -0.02758176,  0.03885261, -0.04382838,\n",
       "          0.05342385, -0.03172776, -0.03267207,  0.06030539, -0.02612159,\n",
       "          0.00577831,  0.02060626, -0.01863469, -0.05265526,  0.00580699,\n",
       "          0.01014999,  0.05210616,  0.05261469,  0.01091154, -0.05550288,\n",
       "          0.04025297,  0.02218101, -0.04251497, -0.00525256, -0.03361447,\n",
       "         -0.01120439, -0.01677448, -0.03040076, -0.02310687, -0.00168775,\n",
       "          0.04110165,  0.02283038,  0.00807638,  0.05036217, -0.00167698,\n",
       "         -0.03165067, -0.05927949, -0.01989612,  0.06042651,  0.04722838,\n",
       "          0.02437181, -0.02448612, -0.05288522,  0.02821915,  0.01124865,\n",
       "         -0.04326838,  0.02702071,  0.00892784, -0.04296647,  0.05708141,\n",
       "          0.05295886,  0.04295122,  0.02212605, -0.06182247,  0.04546348,\n",
       "         -0.02214689, -0.02103596,  0.00173703, -0.05779403,  0.02346736,\n",
       "         -0.0233205 ,  0.03528949,  0.04309482, -0.02748825, -0.00036346,\n",
       "         -0.04397373, -0.04210825,  0.00900449, -0.03372484, -0.05346601,\n",
       "         -0.05740747, -0.01021102,  0.02553094,  0.02297139,  0.05181819,\n",
       "          0.02209236, -0.05076416, -0.01668005, -0.05755535,  0.04182119,\n",
       "         -0.03616417,  0.02146747, -0.058753  ,  0.06012714,  0.01546843,\n",
       "          0.02027956,  0.03440209, -0.01453887, -0.00405906, -0.05399947,\n",
       "         -0.00163248,  0.03524174, -0.00646438, -0.02230013, -0.02636095,\n",
       "          0.0385227 ,  0.06211935, -0.046134  , -0.0127444 ,  0.02836742,\n",
       "          0.02459574, -0.01252649, -0.05412373, -0.03231831,  0.01309   ,\n",
       "          0.03984902,  0.04008793, -0.03613183, -0.0143296 , -0.02578243,\n",
       "         -0.00669117,  0.01310043, -0.04259513,  0.02909099, -0.0145097 ,\n",
       "         -0.00947626, -0.05408368,  0.0621976 , -0.04118674, -0.03878609,\n",
       "         -0.05921866,  0.01827925, -0.05002147,  0.00415074, -0.04564871,\n",
       "         -0.02288385,  0.03949549], dtype=float32)},\n",
       " {'topic_idx': 12,\n",
       "  'topic_words': array(['contribute', 'arxiv', 'contributes', 'supporting', 'contribution',\n",
       "         'funding', 'contributions', 'support', 'contributing', '지원',\n",
       "         'funded', 'grant', 'contributed', 'promote', 'supported',\n",
       "         'supports', 'fund', 'volunteer', 'community', '혁명', 'volunteered',\n",
       "         'helping', 'initiatives', '기금', 'initiative', 'giving', 'helps',\n",
       "         'organizations', 'beneficial', 'volunteers', '자원', 'benefit',\n",
       "         'groups', 'don', 'helped', 'participate', 'foundation', 'give',\n",
       "         'organization', 'we', 'spreading', 'welcome', 'spread', 'increase',\n",
       "         '우리', 'reinforcement', 'receive', 'campaign', 'receives',\n",
       "         'grouped'], dtype='<U15'),\n",
       "  'topic_vector': array([-2.30429731e-02, -1.84213743e-02,  4.26628627e-03,  1.85566954e-04,\n",
       "          6.21661395e-02,  5.42237163e-02, -3.43691139e-03, -2.55322158e-02,\n",
       "         -7.66043039e-03, -2.76557580e-02, -2.12925673e-03,  2.15303134e-02,\n",
       "         -3.14220712e-02, -1.55064603e-02, -1.84884705e-02, -4.37692693e-03,\n",
       "          9.70826764e-03, -8.12394619e-02,  4.17281538e-02,  1.55225182e-02,\n",
       "         -3.35737392e-02,  3.99655886e-02,  2.19829790e-02, -3.29223578e-03,\n",
       "          2.38474086e-02,  3.12923938e-02,  6.54007494e-02, -5.38249388e-02,\n",
       "         -2.29663327e-02, -3.93128395e-02, -7.17377216e-02,  3.99581268e-02,\n",
       "         -3.84413674e-02, -3.15908864e-02,  3.46412137e-02,  2.12599616e-03,\n",
       "          2.13016346e-02,  1.95896495e-02,  2.33350769e-02, -5.35733299e-03,\n",
       "          2.79733688e-02,  6.28001019e-02, -4.18968759e-02,  1.09602567e-02,\n",
       "         -5.82716651e-02, -3.58894430e-02, -3.66111621e-02, -4.48302403e-02,\n",
       "          2.65604630e-02,  5.65985069e-02, -5.95344678e-02, -1.40016479e-02,\n",
       "          5.19351438e-02, -2.95175351e-02, -5.17868847e-02, -3.28779593e-02,\n",
       "          2.11820677e-02,  4.80902046e-02, -6.36549890e-02, -7.16288835e-02,\n",
       "         -4.89333458e-03,  1.80006828e-02,  5.04966378e-02, -7.23360404e-02,\n",
       "         -2.95477509e-02, -4.94268239e-02,  6.15974329e-02,  3.33950073e-02,\n",
       "          6.68939650e-02, -2.08814293e-02,  1.85457561e-02,  1.51059339e-02,\n",
       "          1.21618137e-02,  6.75958814e-04,  2.86923908e-02, -6.48540482e-02,\n",
       "         -2.49090604e-02,  1.42032076e-02, -4.67026234e-02, -5.73545545e-02,\n",
       "         -5.61378412e-02, -3.63142490e-02, -6.49945736e-02, -7.07011223e-02,\n",
       "         -2.41482221e-02, -4.15225290e-02,  4.94435290e-03,  9.50608589e-03,\n",
       "          2.72049569e-02, -2.67783273e-03,  4.03121933e-02,  1.83694623e-02,\n",
       "          1.74924117e-02,  3.11417244e-02,  1.71655081e-02,  1.53391659e-02,\n",
       "          7.16795921e-02,  1.91645287e-02,  2.87938267e-02,  9.65780765e-03,\n",
       "          3.97852361e-02, -3.77351940e-02,  7.33397305e-02, -4.48730811e-02,\n",
       "          9.86797269e-03,  4.36099023e-02, -5.68572283e-02,  6.95997477e-02,\n",
       "          3.07429712e-02, -5.51327737e-03, -2.74867993e-02,  7.53127113e-02,\n",
       "          5.93920276e-02, -4.29334678e-03, -3.45838144e-02, -1.09285004e-02,\n",
       "         -4.19348404e-02,  6.73868060e-02, -3.12808715e-02,  2.07897462e-02,\n",
       "         -2.89928894e-02, -2.50482280e-02,  9.11609549e-03, -2.52554752e-02,\n",
       "         -5.45002520e-02, -4.36696894e-02, -1.56379137e-02, -3.52344438e-02,\n",
       "         -3.27697545e-02, -4.45691943e-02,  2.83233076e-02, -4.43752557e-02,\n",
       "          5.30932620e-02, -5.13836276e-03, -1.79336667e-02,  7.89736658e-02,\n",
       "         -2.31555328e-02, -2.31959317e-02, -1.44780148e-02,  2.98046786e-03,\n",
       "          1.87797751e-02,  6.76292032e-02,  2.08238624e-02,  1.99443772e-02,\n",
       "         -6.62810206e-02, -5.92762306e-02,  5.82434088e-02,  2.34717503e-02,\n",
       "         -4.51854095e-02, -4.22375314e-02,  5.82215637e-02, -4.73716147e-02,\n",
       "          1.14946365e-02, -3.50038754e-03, -3.60583365e-02, -2.52234638e-02,\n",
       "          6.53954744e-02,  1.14997691e-02,  2.02754475e-02,  3.93302478e-02,\n",
       "          2.52685752e-02, -3.35956216e-02,  3.00807431e-02, -2.60489509e-02,\n",
       "          5.65684773e-02,  1.27388341e-02, -1.45583497e-02,  3.59806046e-02,\n",
       "          5.39617054e-03, -1.86447110e-02, -8.25799908e-03, -3.42598557e-02,\n",
       "         -5.57724237e-02, -9.22072865e-03, -7.11691901e-02, -6.44035041e-02,\n",
       "         -7.58102015e-02, -2.44334079e-02, -6.57866150e-02,  6.69757724e-02,\n",
       "         -8.21164437e-03, -4.42309864e-02, -5.62619120e-02,  4.61671837e-02,\n",
       "         -5.91085739e-02, -1.14684626e-02, -1.17290951e-02,  1.64245404e-02,\n",
       "         -2.96602994e-02,  2.49070972e-02,  2.13857442e-02,  4.52350676e-02,\n",
       "         -1.18177505e-02,  2.70482674e-02, -3.72325256e-02,  1.17811477e-02,\n",
       "          4.52075619e-03,  5.02947010e-02, -3.12483311e-03,  7.52689168e-02,\n",
       "          4.77813184e-02, -5.99449407e-03,  4.30857530e-03,  1.19331740e-02,\n",
       "          1.80549715e-02,  1.08764526e-02, -2.51280889e-02,  2.95092468e-03,\n",
       "         -1.96863562e-02, -1.23769790e-02,  4.15594578e-02,  3.03019630e-03,\n",
       "          1.89011917e-05,  4.21707407e-02, -2.50769779e-02, -8.40658881e-03,\n",
       "         -8.80829990e-03, -2.06212439e-02, -3.72863859e-02, -1.81779638e-03,\n",
       "         -3.30557674e-02,  2.30990984e-02, -8.17923341e-04, -3.78614850e-03,\n",
       "          1.87622551e-02, -4.30223942e-02,  3.06092668e-02,  3.31567265e-02,\n",
       "         -2.67401878e-02, -3.13177630e-02, -4.83690873e-02,  1.48212276e-02,\n",
       "         -6.97139204e-02,  6.78050071e-02, -1.29393712e-02,  8.12805817e-02,\n",
       "          7.30019622e-03,  5.49365906e-03,  1.69933103e-02, -2.35910923e-03,\n",
       "         -5.69208339e-03,  8.24307185e-03,  1.43954568e-02, -3.89251374e-02,\n",
       "          5.17096743e-03,  7.24879745e-03, -5.96800186e-02, -2.98131891e-02,\n",
       "         -1.79305337e-02, -7.77051896e-02,  7.67937377e-02, -2.52025798e-02,\n",
       "          5.84942549e-02,  1.28794024e-02, -1.53796505e-02,  4.95104454e-02,\n",
       "          5.30881211e-02,  6.05456671e-03, -5.33591732e-02,  2.98886392e-02,\n",
       "          1.26339104e-02, -3.47470976e-02, -2.94011533e-02,  2.83640735e-02,\n",
       "         -3.76083911e-03,  5.74987568e-02,  3.35455053e-02, -2.14908198e-02,\n",
       "         -2.03521252e-02, -4.15559039e-02, -1.72393210e-02,  9.06090997e-03,\n",
       "         -7.15504810e-02, -3.30804326e-02,  5.03640883e-02,  1.04411915e-02,\n",
       "         -8.15151911e-03,  7.42172357e-03, -4.35894802e-02,  1.53834466e-04,\n",
       "         -5.35157248e-02,  5.97867072e-02, -2.63392385e-02, -6.32966543e-03,\n",
       "          4.89018932e-02,  5.85312136e-02, -6.45877197e-02,  3.72746959e-02,\n",
       "         -7.65100271e-02, -5.87439686e-02,  6.73783049e-02,  3.79209742e-02,\n",
       "         -5.32817021e-02,  9.35340486e-03, -4.14371714e-02,  1.24337450e-02,\n",
       "          1.59090646e-02, -2.76200287e-02, -3.71254049e-02,  4.22155559e-02,\n",
       "         -4.71767187e-02, -1.26785291e-02, -7.92661458e-02, -4.69300076e-02,\n",
       "         -7.85330236e-02, -2.95646042e-02,  2.61690356e-02, -4.54909131e-02,\n",
       "          2.14327406e-02, -2.50184219e-02,  3.32445316e-02,  1.48829948e-02,\n",
       "          4.76512089e-02, -1.57427974e-02,  6.35247082e-02, -1.49020217e-02,\n",
       "         -5.07561490e-02,  2.75738128e-02, -2.88677868e-02, -3.75477038e-02,\n",
       "          4.12594974e-02, -2.62493901e-02, -5.94206080e-02,  1.67490505e-02,\n",
       "         -4.74208817e-02,  2.59954967e-02,  4.91922908e-02, -3.89938131e-02,\n",
       "          2.58092098e-02,  4.00356911e-02,  1.01257628e-03,  2.62112785e-02,\n",
       "         -6.80712052e-03,  1.16219483e-02,  3.19906650e-03,  2.97142137e-02,\n",
       "          5.66617623e-02,  4.14072536e-04, -1.81366690e-02,  3.01987045e-02,\n",
       "          4.10784148e-02,  1.02195339e-02, -4.74469215e-02,  2.43596323e-02,\n",
       "         -2.64498815e-02,  5.90120330e-02, -6.05137572e-02,  6.61787111e-03,\n",
       "          1.72319878e-02, -1.91554017e-02,  2.89109722e-02,  4.12927717e-02,\n",
       "          1.49295460e-02,  7.31223673e-02, -2.57479977e-02,  6.95553515e-03,\n",
       "          2.87074503e-02, -6.81434432e-03,  2.04550810e-02, -5.81029356e-02,\n",
       "         -2.73904130e-02, -2.90193018e-02,  5.49036544e-04,  3.11908051e-02,\n",
       "          1.32439584e-02,  7.40507618e-02, -4.55671288e-02, -7.64112324e-02,\n",
       "         -3.41197662e-02,  6.71560466e-02, -5.46376929e-02,  6.55260384e-02,\n",
       "         -6.58004284e-02,  1.89305488e-02,  2.11881399e-02,  4.33084555e-02,\n",
       "          3.60636972e-02, -5.24260327e-02,  5.37096858e-02, -3.87343466e-02,\n",
       "          6.12693466e-03,  3.83911771e-03, -7.20814914e-02, -4.41249683e-02,\n",
       "         -5.70025370e-02, -1.98118463e-02,  5.80113791e-02,  1.24335233e-02,\n",
       "         -3.90657634e-02, -3.93071994e-02, -3.38386372e-02,  1.12964613e-02,\n",
       "          2.73497924e-02, -1.09939314e-02,  1.95901468e-02,  4.45862114e-02,\n",
       "         -4.98852283e-02, -3.16374488e-02,  3.82893905e-02,  5.91835454e-02,\n",
       "          5.88717014e-02,  7.48501122e-02,  4.68480065e-02,  3.77820921e-03,\n",
       "         -4.78024706e-02,  4.17806953e-02, -2.26580016e-02,  3.14907506e-02,\n",
       "          8.36006179e-03, -4.26780991e-02,  7.47028738e-02,  3.37149352e-02,\n",
       "          8.62288196e-03,  2.05457825e-02,  2.44791359e-02,  3.19111645e-02,\n",
       "          1.81119554e-02,  2.59418190e-02,  3.79848927e-02,  2.84407884e-02,\n",
       "          2.33516144e-03,  6.77952617e-02, -1.89012811e-02, -3.15713361e-02,\n",
       "          3.76534909e-02, -3.98693681e-02,  6.10154234e-02, -6.15844466e-02,\n",
       "          1.63539983e-02, -3.86488102e-02, -1.27038723e-02,  6.14421554e-02,\n",
       "         -2.68209744e-02,  5.92145734e-02,  3.83765176e-02, -2.63102967e-02,\n",
       "         -1.99657753e-02,  5.47727421e-02,  7.26410304e-04, -4.67465743e-02,\n",
       "          5.97556774e-03,  3.10279559e-02,  1.86158698e-02, -5.30637428e-02,\n",
       "          2.00401284e-02,  7.94865936e-02,  4.70658652e-02, -3.02286260e-02,\n",
       "         -1.77521049e-03,  7.07310438e-02, -4.75229397e-02, -1.71305332e-02,\n",
       "          1.59224123e-02, -2.69245123e-04, -4.68543917e-02, -4.67905141e-02,\n",
       "         -5.47945686e-03, -2.45795585e-02, -2.96954848e-02, -3.57295722e-02,\n",
       "          4.87774387e-02,  1.56771280e-02, -3.98840681e-02,  1.32883424e-02,\n",
       "         -1.57583244e-02, -4.01442200e-02,  3.18913758e-02,  3.51160169e-02,\n",
       "          7.15602469e-03, -5.47537804e-02,  7.04526603e-02,  7.27087446e-03,\n",
       "          8.15900788e-03,  4.03764145e-03,  6.01813896e-03, -2.83590257e-02,\n",
       "          1.26551529e-02,  2.54063942e-02,  3.85390818e-02, -2.81277820e-02,\n",
       "          1.48005355e-02,  6.00524396e-02, -3.44600752e-02, -6.05346449e-02,\n",
       "          7.07807392e-02, -3.00081410e-02,  3.62515971e-02, -7.01949075e-02,\n",
       "         -2.74147559e-02, -7.87812099e-03, -2.30868906e-02, -3.87553573e-02,\n",
       "          7.74711091e-03,  1.29150413e-02,  2.03637332e-02, -7.17421900e-03,\n",
       "          5.40923998e-02, -2.79397219e-02, -4.83876243e-02,  2.53020450e-02,\n",
       "          9.79459472e-03,  9.95509047e-03,  4.62095216e-02,  5.49100786e-02,\n",
       "          4.41277400e-03, -1.90118235e-03, -5.58283329e-02, -6.07427806e-02,\n",
       "         -7.45446682e-02, -4.00414243e-02, -2.31921934e-02, -2.56446656e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 13,\n",
       "  'topic_words': array(['dataframe', 'statistical', 'dataset', 'statistics',\n",
       "         'statistically', '통계청', 'statistic', '통계', 'datasets',\n",
       "         'multivariate', 'ggplot', 'variance', 'numpy', 'matplotlib',\n",
       "         'covariance', 'coefficient', 'stats', 'scatterplot', 'variances',\n",
       "         'coefficients', 'data', 'probabilistic', 'estimator',\n",
       "         'quantitative', 'stat', 'regression', 'correlation', 'estimates',\n",
       "         'computation', 'correlations', 'calculations', 'computationally',\n",
       "         'estimators', 'variables', 'computed', 'variability',\n",
       "         'calculation', 'computational', 'multiprocessing', '데이터', '추정',\n",
       "         'numerical', 'probability', '변수', 'lineplot', 'estimated',\n",
       "         'intervals', 'numeric', 'estimation', 'sklearn'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.05578581,  0.02003517,  0.00800766,  0.02927572, -0.0195936 ,\n",
       "         -0.03320533, -0.00133056, -0.01567387,  0.05529318,  0.0290281 ,\n",
       "          0.03890438,  0.00134708,  0.05392554,  0.00582569, -0.05578794,\n",
       "          0.00126979,  0.0025646 , -0.03613665,  0.0290552 ,  0.05152569,\n",
       "         -0.02731229, -0.03583947, -0.00763551,  0.05361304, -0.05556523,\n",
       "         -0.05484816,  0.01323454,  0.00807173,  0.00762423, -0.04483946,\n",
       "         -0.04966331,  0.02660083,  0.01719183, -0.05432819,  0.0199943 ,\n",
       "          0.01322243, -0.01926082,  0.00025837, -0.0247983 , -0.00137984,\n",
       "         -0.00245498,  0.02544658,  0.01398493, -0.04031675, -0.01329655,\n",
       "         -0.03867476,  0.05150284,  0.01524565, -0.0234386 , -0.02801782,\n",
       "          0.01839988, -0.01056413, -0.00773609, -0.01839838,  0.04750027,\n",
       "         -0.05047584, -0.0060521 ,  0.01998622,  0.0087065 ,  0.02498821,\n",
       "          0.0296347 ,  0.04466139,  0.03054516, -0.03745882, -0.00145467,\n",
       "         -0.01142874,  0.01952135, -0.02242564,  0.00079138,  0.0107855 ,\n",
       "         -0.03438161, -0.00981789, -0.00074675, -0.02761082, -0.03188311,\n",
       "         -0.04377341,  0.02235627,  0.04410781, -0.02370679, -0.0559742 ,\n",
       "         -0.05597582, -0.04631384, -0.01508469,  0.02361425,  0.02429208,\n",
       "         -0.03074071, -0.0472795 , -0.0095777 , -0.02151285, -0.0340877 ,\n",
       "         -0.03141083, -0.00312245,  0.03207383, -0.01587434,  0.04755064,\n",
       "          0.0427078 , -0.01484637,  0.01079555,  0.00541446,  0.02281191,\n",
       "          0.0287488 ,  0.01880511,  0.03526594, -0.02331282,  0.01157425,\n",
       "         -0.04272666, -0.02896529,  0.00602601, -0.00537004,  0.05120556,\n",
       "          0.02835139, -0.03252411, -0.04348569, -0.01895436,  0.03669683,\n",
       "         -0.00156067, -0.00995314, -0.01889484, -0.00797905, -0.01377054,\n",
       "         -0.03576419,  0.03180999,  0.0037068 ,  0.03258638,  0.0455164 ,\n",
       "          0.01890275, -0.04189786,  0.01248406, -0.04031349,  0.02358608,\n",
       "         -0.05313254,  0.00783492,  0.0538912 ,  0.02975815, -0.03600388,\n",
       "          0.02718554,  0.00367027, -0.02216069,  0.05390401,  0.0407082 ,\n",
       "         -0.01227594, -0.01669049,  0.03575079,  0.01429585,  0.00198626,\n",
       "          0.01720184, -0.03000202,  0.0395428 , -0.0123539 , -0.00061894,\n",
       "          0.0314786 ,  0.00938866,  0.00330288, -0.02590584,  0.03003015,\n",
       "         -0.01852184,  0.01177364, -0.03358321,  0.00729291, -0.01977069,\n",
       "          0.03896331, -0.02015506, -0.00299941, -0.0153772 , -0.03454242,\n",
       "         -0.02279279, -0.01030635,  0.02271078, -0.02353657,  0.04300678,\n",
       "         -0.02288807,  0.002739  ,  0.01832556,  0.03153318,  0.02511629,\n",
       "          0.05173474, -0.03493915,  0.02108254, -0.0400341 ,  0.05012888,\n",
       "          0.02080152, -0.0128654 ,  0.0137304 , -0.01944864, -0.05174805,\n",
       "         -0.03477606,  0.04641822,  0.05539915, -0.01229919, -0.05110402,\n",
       "          0.01484006, -0.02563661,  0.04693113, -0.02504059, -0.01307098,\n",
       "          0.0258694 , -0.04153692, -0.0167427 ,  0.03163895,  0.02226142,\n",
       "         -0.00352459, -0.00525428, -0.04136848, -0.03277777, -0.02540016,\n",
       "         -0.02776634, -0.03619009, -0.01930771, -0.02953395,  0.04852454,\n",
       "         -0.00361538,  0.02757173, -0.05288889, -0.01681747,  0.04072057,\n",
       "          0.0014031 , -0.00020327, -0.05514757,  0.00318438, -0.02189547,\n",
       "          0.00382771, -0.00127159,  0.00598642, -0.03321634, -0.05141265,\n",
       "          0.00452301, -0.03401585, -0.01677879,  0.01201563, -0.00797143,\n",
       "         -0.00374829,  0.04160448, -0.02079354, -0.03394673,  0.02341579,\n",
       "          0.00844412, -0.00500302,  0.0315791 ,  0.04103929, -0.00582875,\n",
       "         -0.01542189,  0.02455398, -0.0075058 ,  0.04563638, -0.00137116,\n",
       "         -0.05145943, -0.02160923,  0.00089981, -0.00679877,  0.03048059,\n",
       "         -0.04507245, -0.0325774 , -0.01197645, -0.02210852,  0.00426564,\n",
       "         -0.01684634, -0.00199843, -0.03082117,  0.00390055,  0.00064924,\n",
       "          0.03533278,  0.002963  , -0.03339745, -0.02156032,  0.02147333,\n",
       "         -0.05230975, -0.02210071, -0.01361636, -0.02257604,  0.01418194,\n",
       "         -0.04238211, -0.05010563, -0.02324279, -0.04216183, -0.00193088,\n",
       "         -0.00589049, -0.05450188,  0.02672668, -0.04862049,  0.00544899,\n",
       "         -0.05117762, -0.00100279,  0.0229548 ,  0.03232847, -0.0319582 ,\n",
       "          0.0258893 , -0.0366533 , -0.05130404, -0.04053621,  0.02135151,\n",
       "          0.02288496,  0.04505775,  0.03996503,  0.00681153, -0.04932898,\n",
       "          0.02930696, -0.03138802,  0.0355341 ,  0.04641153,  0.0416343 ,\n",
       "         -0.02485065,  0.04554034, -0.03281011, -0.0556503 , -0.0542752 ,\n",
       "         -0.00046227, -0.00120572,  0.01168724, -0.01809751,  0.0248299 ,\n",
       "          0.00870421, -0.02098524, -0.04056066, -0.00128484,  0.01848197,\n",
       "          0.0497864 ,  0.02517767, -0.02474356,  0.02097329, -0.02147542,\n",
       "          0.01277082, -0.00085052, -0.02245536,  0.02551944, -0.03370941,\n",
       "         -0.01724018, -0.02314414, -0.03218792, -0.00129302,  0.01088022,\n",
       "         -0.01173472, -0.05270124, -0.02700531, -0.04759889, -0.04208201,\n",
       "          0.0297079 ,  0.00951214, -0.00270293, -0.05574226, -0.03664428,\n",
       "         -0.04181374, -0.02950326,  0.05106803, -0.00542787, -0.01483142,\n",
       "          0.03910409,  0.0470959 ,  0.02790784, -0.03309206, -0.01574933,\n",
       "          0.03725794, -0.00606003,  0.03456494, -0.02002724, -0.02463787,\n",
       "          0.01635483,  0.01235623,  0.042454  , -0.04974425, -0.03779184,\n",
       "          0.00922254, -0.021681  ,  0.03941479, -0.00755371, -0.03932242,\n",
       "         -0.00460787,  0.01381459,  0.04742837,  0.02447738,  0.04843833,\n",
       "          0.03334791,  0.0184606 , -0.00266252,  0.01892983, -0.00976583,\n",
       "         -0.04059945,  0.02578402, -0.02903776, -0.05402232, -0.03449545,\n",
       "          0.00372937, -0.04817638,  0.01803675,  0.00678339, -0.04799945,\n",
       "          0.05274161,  0.0217784 , -0.04868528,  0.04421894, -0.00743952,\n",
       "          0.03284191, -0.02855702, -0.04177846,  0.03675042, -0.04011416,\n",
       "          0.0386329 ,  0.04573913,  0.01001336, -0.04874559,  0.04530157,\n",
       "          0.02522813,  0.05554796,  0.01758107, -0.04434889, -0.01279661,\n",
       "          0.01220787, -0.02765509, -0.03290909,  0.01704756, -0.01575145,\n",
       "         -0.00996834,  0.01882325,  0.03224552, -0.05017087,  0.02297588,\n",
       "          0.01929798,  0.04767865,  0.01485335,  0.02521414,  0.00978499,\n",
       "         -0.00495191, -0.05341345,  0.03267437,  0.04518597,  0.04674965,\n",
       "          0.03748201, -0.01349301, -0.03195763, -0.00106503, -0.03210539,\n",
       "         -0.0466724 , -0.00194529,  0.00878185, -0.00848497,  0.02715866,\n",
       "          0.02317868,  0.03747541,  0.00020575, -0.05459918,  0.03274901,\n",
       "         -0.00103605,  0.02479544, -0.01698498, -0.05497105,  0.02168588,\n",
       "         -0.00089089,  0.0519226 , -0.01989485,  0.02483473,  0.02196736,\n",
       "          0.01874745, -0.00501723, -0.03104358, -0.00366999, -0.05317537,\n",
       "         -0.01480261,  0.03754166,  0.03113929,  0.02605629,  0.03394959,\n",
       "         -0.02181721,  0.01947776,  0.00085363, -0.03614822,  0.05208452,\n",
       "         -0.04300387, -0.00163425, -0.05001574,  0.05513214,  0.00527446,\n",
       "          0.01939849,  0.02729473,  0.03630118,  0.01760801, -0.04463272,\n",
       "         -0.02661191,  0.03914495, -0.04329525, -0.03659811,  0.00071273,\n",
       "          0.04064826,  0.04411687, -0.0545599 , -0.02675527,  0.01510273,\n",
       "          0.00612961, -0.02031715, -0.05570126, -0.00041842, -0.02186185,\n",
       "          0.02338872, -0.04427868, -0.0103081 , -0.01325441,  0.00454752,\n",
       "         -0.03512799,  0.00967548, -0.05014008,  0.04388912,  0.02994641,\n",
       "          0.00276708, -0.05387991,  0.0516452 , -0.00885972, -0.02618898,\n",
       "         -0.05529771, -0.03040785, -0.01644322, -0.00557251, -0.045617  ,\n",
       "          0.01484627,  0.03497736], dtype=float32)},\n",
       " {'topic_idx': 14,\n",
       "  'topic_words': array(['neuronal', 'neural', 'neurobiological', 'neurons', 'neuron',\n",
       "         'neurosciences', 'neurobiology', 'neurosci', 'neuroscience',\n",
       "         'neuro', 'neuroethics', 'neurological', 'neuroimaging', 'neurol',\n",
       "         'neuroimage', 'neuroscientific', 'neurogenesis', 'neurology',\n",
       "         'neurobiol', 'clustering', 'correlated', 'neuroscientists',\n",
       "         'neurosurg', 'neuroscientist', 'correlates', 'correlations',\n",
       "         'correlation', 'correlate', 'brainstem', 'somatosensory',\n",
       "         'datasets', 'neurocultures', 'clusters', '신경망', 'brains',\n",
       "         'cerebrospinal', 'alzheimers', 'computationally', 'coefficient',\n",
       "         'computational', 'statistically', 'brain', 'cerebral',\n",
       "         'coefficients', 'dataset', 'networks', 'cluster', 'probabilistic',\n",
       "         'forebrain', 'statistical'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.21193147e-02,  4.43359688e-02, -3.26683111e-02,  4.51862216e-02,\n",
       "         -4.24755253e-02,  1.45532638e-02, -3.28618512e-02,  6.28254842e-03,\n",
       "          2.68006232e-02,  5.16176708e-02, -1.43918172e-02, -1.80241559e-02,\n",
       "          3.79895084e-02, -5.18664066e-03, -3.73034775e-02,  3.16943116e-02,\n",
       "         -1.10884325e-03, -4.17771414e-02,  3.41306590e-02,  3.81341577e-02,\n",
       "         -2.26781033e-02, -4.23222557e-02, -3.10062785e-02,  5.19790128e-02,\n",
       "         -5.39118387e-02, -4.40420620e-02,  4.42947745e-02,  4.55870666e-02,\n",
       "          7.24477833e-03,  1.01622557e-02, -1.24716675e-02,  3.75457183e-02,\n",
       "          3.51500250e-02, -5.30135557e-02, -2.71621533e-03, -2.89599262e-02,\n",
       "         -4.56448235e-02, -6.34135213e-03,  1.10817002e-02, -1.30928671e-02,\n",
       "         -3.59052904e-02,  2.65131090e-02,  4.65962477e-02, -2.97184405e-03,\n",
       "         -4.61214669e-02,  3.47702987e-02,  4.76101078e-02,  3.31863314e-02,\n",
       "         -1.55819105e-02, -3.61517891e-02,  2.97654569e-02,  4.97596618e-03,\n",
       "          7.70177121e-06, -1.63814295e-02,  2.85797231e-02, -3.41370814e-02,\n",
       "         -3.13301431e-03,  3.21088769e-02,  1.14258844e-02,  5.34594469e-02,\n",
       "         -2.66583171e-02,  4.51857187e-02, -1.92351341e-02, -5.24388142e-02,\n",
       "         -3.44027206e-02, -6.57695858e-03,  4.12866548e-02, -3.49338166e-02,\n",
       "         -2.44575012e-02, -3.27037908e-02, -3.82117666e-02,  1.57522075e-02,\n",
       "         -1.17041841e-02, -4.88895252e-02, -1.57054476e-02, -1.87409222e-02,\n",
       "          3.12321037e-02,  3.33754495e-02, -3.78007255e-02, -4.62603346e-02,\n",
       "         -5.32949157e-02, -5.26885428e-02,  3.84523533e-02,  3.13308872e-02,\n",
       "         -2.73535904e-02,  1.00536570e-02, -3.68066840e-02,  2.32593156e-02,\n",
       "         -4.61011601e-04,  3.45288515e-02, -4.48187068e-02, -4.66371365e-02,\n",
       "         -1.93193424e-02, -5.34802116e-02, -9.57197044e-03,  5.26638888e-02,\n",
       "          3.78369689e-02,  5.24790958e-02,  2.07646582e-02, -7.22021237e-03,\n",
       "          3.57147790e-02, -6.08627871e-03,  3.51001360e-02, -1.12331361e-02,\n",
       "          1.69953611e-02,  9.35427099e-03, -5.24600856e-02,  1.73776187e-02,\n",
       "          2.89482530e-02,  5.35325892e-02,  3.42749171e-02, -5.33657596e-02,\n",
       "         -4.36751209e-02, -3.55460383e-02,  4.83900607e-02, -4.46240567e-02,\n",
       "          2.86185257e-02,  3.49497683e-02, -3.80935445e-02,  3.58384363e-02,\n",
       "         -4.56453189e-02,  4.41479869e-02,  4.91347387e-02, -2.91257072e-02,\n",
       "          3.72388996e-02, -3.84567818e-03,  4.48612645e-02,  1.34879006e-02,\n",
       "         -4.08257321e-02,  5.16162924e-02, -4.68005352e-02,  1.28046675e-02,\n",
       "          4.11824919e-02,  5.17700575e-02, -3.91181521e-02,  5.31180017e-02,\n",
       "         -4.24661450e-02, -4.49897302e-03,  5.05626574e-02,  3.36007439e-02,\n",
       "          5.09337448e-02,  2.68098544e-02,  5.00206165e-02,  1.27220890e-02,\n",
       "          3.94931063e-02, -2.17900556e-02, -5.35519049e-02,  3.76322567e-02,\n",
       "          2.28380263e-02,  5.23591973e-02,  3.66021879e-02,  2.53102574e-02,\n",
       "         -6.94637652e-03, -5.09696491e-02,  7.06981029e-03, -3.21694799e-02,\n",
       "          2.80342363e-02, -4.14432921e-02,  4.94635431e-03, -3.94839048e-02,\n",
       "          4.70886715e-02, -5.00157550e-02, -4.86793630e-02, -2.88732443e-02,\n",
       "         -1.16636101e-02, -2.17539556e-02,  2.47950256e-02,  9.99081787e-03,\n",
       "         -5.18248603e-02,  4.57650386e-02, -4.61578965e-02, -1.04765166e-02,\n",
       "          9.27088689e-03, -1.66696105e-02, -3.86260822e-02,  5.31755621e-03,\n",
       "          1.93516053e-02,  4.01150919e-02, -1.20802587e-02,  4.26110290e-02,\n",
       "          3.87744643e-02, -1.63074974e-02, -3.17945406e-02, -3.45142931e-02,\n",
       "         -4.28971164e-02, -6.72457740e-03,  2.00730693e-02,  4.78880890e-02,\n",
       "         -2.09938735e-04,  4.96652350e-02, -3.09258364e-02, -2.35480685e-02,\n",
       "          1.77199673e-02, -2.68727057e-02, -1.63168255e-02,  2.85223182e-02,\n",
       "         -4.95864339e-02,  3.82541008e-02,  5.40122204e-02,  3.58974561e-02,\n",
       "         -3.69825549e-02,  4.42740247e-02, -2.86509879e-02, -3.34003754e-02,\n",
       "          1.64395012e-02, -4.96029928e-02, -5.39232530e-02, -1.89746618e-02,\n",
       "          3.84074934e-02,  1.95613187e-02,  2.86055747e-02,  1.06842048e-03,\n",
       "         -3.36604901e-02,  4.57874779e-03,  5.22789843e-02, -2.54326202e-02,\n",
       "          2.34375782e-02, -4.73937429e-02, -4.04564803e-03, -4.79085036e-02,\n",
       "          9.21777915e-03,  2.50818040e-02,  4.10185345e-02,  2.44311951e-02,\n",
       "         -5.05515076e-02, -1.73451006e-02, -5.39007783e-02,  1.97825152e-02,\n",
       "          1.34479599e-02, -7.37598864e-03, -2.65563168e-02,  4.87793423e-02,\n",
       "         -5.18347733e-02,  4.99501303e-02,  2.98862122e-02,  1.22473342e-02,\n",
       "          1.60443932e-02,  5.18601239e-02,  4.91150543e-02, -3.22063975e-02,\n",
       "          2.14777756e-02,  4.46127281e-02, -3.60933430e-02,  1.58234425e-02,\n",
       "          4.19111773e-02, -4.96547855e-02,  4.57907207e-02,  3.27378395e-03,\n",
       "          1.46893843e-03,  4.58499752e-02, -5.04657067e-02, -3.64580713e-02,\n",
       "          4.87554781e-02,  1.99556854e-02,  3.29439975e-02, -4.18179817e-02,\n",
       "          9.90743283e-03,  2.58121490e-02, -2.60767005e-02, -2.79801358e-02,\n",
       "         -1.69516709e-02,  3.90868373e-02, -2.92279813e-02,  2.23340858e-02,\n",
       "          4.89387428e-03, -5.17702512e-02, -9.24439728e-03,  3.30465063e-02,\n",
       "          3.22301500e-02,  4.42642905e-02, -6.48935419e-03, -8.44035484e-03,\n",
       "         -2.17369758e-02, -4.90048751e-02, -4.64301882e-03,  3.57374921e-02,\n",
       "         -5.08520566e-02,  4.81330641e-02, -4.72628698e-02, -2.38663424e-02,\n",
       "         -3.92362103e-02, -3.42269018e-02, -1.43666668e-02,  4.46473248e-02,\n",
       "         -8.68350826e-03,  5.22958413e-02, -5.05604073e-02, -5.17338552e-02,\n",
       "          9.15390439e-03,  2.50859447e-02,  3.45932692e-02,  2.60514785e-02,\n",
       "          3.84208262e-02, -3.81972529e-02, -5.09651639e-02, -2.70236470e-02,\n",
       "          3.70496511e-03,  2.91554313e-02,  4.18451056e-02,  5.18948622e-02,\n",
       "         -4.98933792e-02,  3.27530615e-02,  7.46198650e-03, -3.23587842e-02,\n",
       "         -5.37807085e-02, -5.33194430e-02, -3.73458639e-02,  4.23201844e-02,\n",
       "         -3.76406834e-02,  3.60341743e-02, -5.25002368e-02, -1.94877349e-02,\n",
       "         -1.37502188e-02, -4.13737781e-02,  3.58163118e-02,  3.22302990e-02,\n",
       "         -2.92019714e-02, -2.77170707e-02,  2.34140754e-02, -4.73212972e-02,\n",
       "          3.35483365e-02, -4.93600406e-02, -3.02433409e-02,  3.64202224e-02,\n",
       "         -5.10862060e-02, -4.13922742e-02,  1.95106901e-02, -1.71478949e-02,\n",
       "         -1.00719985e-02,  3.03226002e-02, -3.26001979e-02, -4.27762382e-02,\n",
       "         -2.55059469e-02, -4.24651848e-03, -5.22233136e-02, -1.90329254e-02,\n",
       "         -4.97094281e-02, -4.86640334e-02, -5.17906211e-02,  2.53306497e-02,\n",
       "         -5.19397520e-02, -2.57262005e-03,  2.28341967e-02, -4.21793424e-02,\n",
       "          6.87752245e-03,  5.13905212e-02,  5.37136570e-02,  1.91289522e-02,\n",
       "         -4.03945409e-02,  3.54031324e-02,  4.22599986e-02, -4.93268715e-03,\n",
       "          1.23987719e-03,  5.31055257e-02, -1.98463760e-02,  2.63896007e-02,\n",
       "          4.43082228e-02,  1.83284748e-02, -4.58546616e-02, -4.10482064e-02,\n",
       "          5.02222776e-02, -2.07094252e-02,  4.80332486e-02, -3.69968601e-02,\n",
       "         -4.63906303e-02,  3.24947461e-02, -2.79133599e-02,  4.08940502e-02,\n",
       "         -3.71100493e-02,  1.05380807e-02,  4.75601815e-02,  5.13012968e-02,\n",
       "         -3.93760279e-02,  5.19073606e-02, -1.32864283e-03, -5.37696443e-02,\n",
       "         -3.36995386e-02,  1.28467102e-02, -3.96559499e-02, -5.26473038e-02,\n",
       "          4.05971594e-02,  1.67569984e-02,  3.34782079e-02,  1.08686816e-02,\n",
       "         -3.41274515e-02,  5.33819981e-02,  4.19724621e-02, -4.10628803e-02,\n",
       "          5.16826510e-02, -2.45437827e-02,  3.50338295e-02, -2.90316045e-02,\n",
       "         -1.83748696e-02,  5.14829159e-02, -4.09532189e-02,  1.68419015e-02,\n",
       "          4.17788737e-02, -3.33167724e-02, -5.30510545e-02,  2.75171511e-02,\n",
       "          4.71699052e-02,  2.96366084e-02,  4.50211801e-02,  3.70829664e-02,\n",
       "         -5.27421758e-02,  2.31104698e-02,  6.11594552e-03, -2.03644745e-02,\n",
       "          3.18211429e-02, -9.66900866e-03,  3.49689126e-02, -1.86254811e-02,\n",
       "         -1.15272598e-02,  3.97553630e-02,  1.23067992e-02,  5.33132032e-02,\n",
       "          1.59671158e-02, -4.36579287e-02,  4.40556929e-02,  3.36098969e-02,\n",
       "         -2.52905656e-02, -5.33904321e-02,  4.41987552e-02,  5.21844737e-02,\n",
       "          5.12254611e-02,  1.43927177e-02, -1.84686445e-02, -5.29457889e-02,\n",
       "         -4.78259847e-02, -4.42701112e-03, -5.11816069e-02,  2.11153048e-04,\n",
       "         -3.08931582e-02, -3.83877791e-02,  3.27557139e-02,  5.01674749e-02,\n",
       "          2.47101393e-02, -6.92503294e-03, -5.39557412e-02,  4.92860191e-02,\n",
       "         -1.62442122e-02,  1.65741779e-02,  1.82697885e-02, -5.31487502e-02,\n",
       "          4.18034121e-02, -2.95392573e-02, -2.87424922e-02,  3.76342759e-02,\n",
       "          2.78303046e-02,  2.82260738e-02, -4.99015041e-02, -3.65451947e-02,\n",
       "         -2.33325865e-02, -6.37768675e-03, -4.14174870e-02, -1.85682327e-02,\n",
       "          3.75892334e-02,  4.31079604e-02, -1.77562665e-02,  5.12908921e-02,\n",
       "         -2.39860173e-02, -5.02945483e-02, -4.90655787e-02, -4.82348613e-02,\n",
       "          3.60225812e-02, -5.08466586e-02, -2.91887559e-02, -2.29536705e-02,\n",
       "          5.37208878e-02, -3.21726426e-02,  1.97209418e-02,  5.39872535e-02,\n",
       "         -1.18369586e-03,  1.62540954e-02,  1.37177957e-02, -1.79798007e-02,\n",
       "         -2.16084672e-03,  2.35940851e-02, -1.97572801e-02,  1.51164113e-02,\n",
       "          4.80681695e-02,  5.40467799e-02, -5.00971302e-02,  1.66139484e-03,\n",
       "          2.44397540e-02, -4.59605195e-02,  1.63587984e-02, -4.83120866e-02,\n",
       "         -5.35156094e-02, -3.37752141e-02,  4.60836217e-02,  4.48941961e-02,\n",
       "         -2.67487075e-02,  1.28102815e-02, -4.11613509e-02, -3.63960303e-02,\n",
       "         -1.93066299e-02, -1.85394082e-02,  4.65060882e-02,  4.12294976e-02,\n",
       "          3.16663869e-02, -5.40020280e-02,  5.39005920e-02, -2.04622485e-02,\n",
       "         -5.06760068e-02, -5.38234487e-02, -2.42509395e-02, -2.00743582e-02,\n",
       "         -4.69414778e-02, -5.36947250e-02,  1.26916897e-02, -8.11895542e-03],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 15,\n",
       "  'topic_words': array(['neurogenesis', 'neurological', 'neuronal', 'neuro',\n",
       "         'neuroscientific', 'neurobiology', 'neurol', 'neural',\n",
       "         'neurobiological', 'neurology', 'neurosci', 'neurosciences',\n",
       "         'neuroimaging', 'neurons', 'neuroscience', 'cerebrospinal',\n",
       "         'neuron', 'neuroethics', '근육', 'neuroimage', 'neuroscientists',\n",
       "         'neurobiol', 'neuroscientist', 'midbrain', '신경망', 'developmental',\n",
       "         'brainstem', 'cerebral', 'dorsal', 'nucleus', 'brain', 'neurosurg',\n",
       "         'dorsolateral', 'morphological', 'occipital', 'synapses', 'brains',\n",
       "         '신경', 'neurocultures', 'neurofeminism', 'neurofeminist',\n",
       "         'pathophysiology', '자극', 'forebrain', '뉴런', 'spines', 'cerebellum',\n",
       "         'pathology', 'nuclei', 'anatomical'], dtype='<U15'),\n",
       "  'topic_vector': array([-4.51108627e-02, -5.27766347e-03, -3.37054506e-02, -1.54829575e-02,\n",
       "         -3.62044759e-02,  3.82751748e-02,  1.76415108e-02,  9.75094363e-03,\n",
       "          1.39126822e-03,  3.55868600e-02, -7.17859156e-03, -3.63646299e-02,\n",
       "          2.52434611e-02, -1.64958881e-03, -4.89844754e-02,  2.38047969e-02,\n",
       "          3.90854068e-02, -5.53221535e-03,  2.73257829e-02,  3.13745216e-02,\n",
       "          1.16248140e-02, -3.54615413e-02, -4.02690237e-03,  3.33947316e-02,\n",
       "         -5.80541417e-02, -2.87984181e-02, -1.86446495e-02,  2.75080111e-02,\n",
       "          4.53376248e-02, -4.44831699e-02, -4.16495800e-02,  3.71766314e-02,\n",
       "          4.10929043e-03, -5.71681447e-02,  1.14771323e-02, -4.85334508e-02,\n",
       "         -3.26827094e-02,  1.71819720e-02,  8.74344260e-03, -4.00529429e-02,\n",
       "          7.22042890e-03,  2.88738944e-02,  2.95098796e-02, -5.67951379e-03,\n",
       "         -6.14184700e-03, -2.81979777e-02,  4.48477603e-02,  1.14515387e-02,\n",
       "          4.60855290e-02, -2.29175035e-02,  1.87831111e-02, -3.41535769e-02,\n",
       "          2.89116660e-03,  1.68009773e-02,  2.00038347e-02, -5.34323677e-02,\n",
       "          3.65255140e-02,  2.88719330e-02,  2.31325869e-02,  1.46540590e-02,\n",
       "         -1.62793361e-02,  5.53822443e-02, -4.13155518e-02, -2.94789579e-02,\n",
       "         -1.57236971e-03,  1.61225293e-02,  1.92046165e-02, -4.09943536e-02,\n",
       "          1.60110891e-02, -3.34627065e-03, -2.01354530e-02, -9.57581506e-04,\n",
       "          4.31399466e-03, -4.63698506e-02, -4.10169885e-02, -2.54276730e-02,\n",
       "         -1.33430883e-02,  3.11815366e-02, -2.81099156e-02, -5.89934066e-02,\n",
       "         -5.99180870e-02, -3.83611172e-02,  3.04394793e-02,  3.19623128e-02,\n",
       "         -8.49590730e-03, -1.32642342e-02, -3.71571854e-02,  1.60354953e-02,\n",
       "         -2.78793019e-03, -6.92294771e-03, -2.84474362e-02, -4.61430922e-02,\n",
       "         -4.65932153e-02, -5.30974753e-02,  1.73883252e-02,  5.19388989e-02,\n",
       "          5.26441522e-02,  5.41000590e-02,  3.06843519e-02,  2.84403302e-02,\n",
       "          3.15420106e-02,  4.02008407e-02, -3.68503965e-02,  3.79736610e-02,\n",
       "          1.52689414e-02,  5.97268157e-02, -5.28773889e-02, -3.04639470e-02,\n",
       "          1.27079077e-02,  2.56783590e-02,  2.13722717e-02, -2.80846264e-02,\n",
       "         -1.76966190e-02,  4.45072614e-02,  1.38161331e-02, -4.01867228e-03,\n",
       "          2.05906238e-02,  2.91440114e-02, -4.36595678e-02, -3.90671752e-03,\n",
       "         -3.35858688e-02,  4.05452996e-02,  4.13997918e-02, -4.52559255e-03,\n",
       "         -1.19713312e-02,  2.84601282e-02,  5.39945364e-02,  4.98184450e-02,\n",
       "         -4.02229205e-02,  5.02931252e-02, -3.64233963e-02, -3.20471972e-02,\n",
       "          2.95382366e-02,  2.21609157e-02, -3.24840955e-02,  5.79401851e-02,\n",
       "         -3.05788815e-02,  2.13519149e-02,  5.04399538e-02,  1.98999904e-02,\n",
       "          4.10047546e-02, -4.85674366e-02,  4.28540036e-02, -2.03882586e-02,\n",
       "          5.11930101e-02,  3.06099653e-02, -1.18417125e-02,  3.67876552e-02,\n",
       "         -7.04587903e-03,  1.05910860e-02,  4.94285002e-02,  5.57120033e-02,\n",
       "         -4.21114974e-02, -2.83249542e-02, -4.28431202e-04, -3.90645210e-03,\n",
       "          8.94970354e-03, -4.59766835e-02,  2.31096931e-02, -2.76366808e-02,\n",
       "          2.64633335e-02, -3.09997573e-02, -3.30768712e-02, -9.61551163e-03,\n",
       "         -7.03915115e-03, -3.69950086e-02, -4.09937277e-02, -1.05298059e-02,\n",
       "         -4.98629734e-02,  4.01972011e-02, -2.26513967e-02, -1.93517469e-02,\n",
       "          1.19613409e-02, -2.62284055e-02, -3.73636894e-02,  1.79530941e-02,\n",
       "          4.55750190e-02,  3.07640359e-02, -3.17185186e-02,  1.90505609e-02,\n",
       "          1.01101995e-02, -5.81688955e-02, -2.69886926e-02, -2.99295280e-02,\n",
       "          3.39850970e-02, -6.07835921e-03, -1.01162260e-02,  4.32639085e-02,\n",
       "          2.51296479e-02, -2.43322924e-02,  6.41769916e-03, -1.00201480e-02,\n",
       "         -1.79178491e-02, -4.21564188e-03, -4.86363284e-02, -1.04079014e-02,\n",
       "         -3.72902267e-02,  1.53664760e-02,  5.63481636e-02, -2.52077100e-03,\n",
       "         -1.90333426e-02,  3.61154042e-02,  4.19531763e-02, -1.84055343e-02,\n",
       "          3.60096283e-02, -3.71106416e-02, -4.12250906e-02, -1.79790817e-02,\n",
       "          3.53592560e-02, -2.54757120e-03, -7.89561775e-03,  3.53418943e-03,\n",
       "         -3.47878896e-02, -2.67384034e-02,  4.28195745e-02, -9.49054956e-03,\n",
       "          2.18016673e-02, -2.81117931e-02, -2.05498245e-02,  2.08712146e-02,\n",
       "         -3.12017333e-02,  2.63845380e-02,  5.01230769e-02,  2.71491781e-02,\n",
       "         -5.45577332e-02, -3.55755538e-02, -5.59783503e-02,  3.74795608e-02,\n",
       "          8.24453030e-03, -2.39491984e-02, -1.29233748e-02,  4.71701026e-02,\n",
       "         -2.39073392e-02,  2.81342473e-02,  2.67506894e-02,  2.43503321e-03,\n",
       "          1.29411500e-02,  6.69183768e-03,  5.44740930e-02, -2.08986830e-02,\n",
       "         -2.26393882e-02, -3.73156415e-03, -7.17707619e-04, -7.30419485e-03,\n",
       "          3.00694369e-02, -3.49069089e-02,  1.98898651e-02,  1.62432808e-02,\n",
       "          2.63558999e-02,  7.25194486e-03, -5.45344315e-03, -5.63997366e-02,\n",
       "          3.23090144e-02,  3.34120616e-02, -3.20089906e-02,  3.66955064e-02,\n",
       "          2.43024323e-02,  5.82072698e-03, -3.45513485e-02,  4.75013778e-02,\n",
       "          1.85230207e-02,  3.98956388e-02,  8.28137388e-04,  3.22729312e-02,\n",
       "          2.01657936e-02, -5.91189191e-02, -4.31382582e-02,  2.70136464e-02,\n",
       "          1.67145804e-02,  3.37036848e-02,  8.38261191e-03, -5.08665368e-02,\n",
       "         -3.61264274e-02,  5.78232296e-03, -4.32872623e-02, -2.11406077e-05,\n",
       "         -4.22758013e-02,  3.77331451e-02, -5.70557564e-02,  5.92098047e-04,\n",
       "         -2.55870540e-02, -8.87093879e-03,  1.80843696e-02, -4.98695066e-04,\n",
       "         -2.37799659e-02,  2.08246764e-02, -4.28838134e-02, -3.54348533e-02,\n",
       "          4.29665437e-03, -1.62431505e-02,  2.59139854e-02, -4.05177614e-03,\n",
       "          4.13963348e-02, -1.85241494e-02, -2.90627405e-02, -1.78324673e-02,\n",
       "          2.59156898e-03,  2.60579363e-02,  1.74926054e-02,  2.18770653e-02,\n",
       "         -2.49941293e-02, -3.19995061e-02,  2.42856629e-02, -2.94118449e-02,\n",
       "         -1.45991296e-02, -2.25716047e-02, -2.53512058e-02,  2.20237067e-03,\n",
       "          4.08122456e-03,  4.86216620e-02, -5.20869233e-02, -3.55176441e-02,\n",
       "          1.83818471e-02, -4.10283618e-02,  4.39418219e-02,  4.26829234e-02,\n",
       "          4.61639389e-02, -3.85495462e-02,  1.60745741e-03, -2.63772234e-02,\n",
       "          4.80994135e-02, -6.00743741e-02,  1.35618132e-02,  2.85196044e-02,\n",
       "         -4.43124063e-02,  2.76266690e-03,  3.95021588e-02, -1.08738132e-02,\n",
       "         -5.84993698e-03,  4.49318513e-02, -4.24114317e-02, -1.73968803e-02,\n",
       "         -4.09566797e-02, -2.51262877e-02,  1.01899700e-02, -1.26314266e-02,\n",
       "         -4.04602475e-02, -2.55735163e-02, -3.43139246e-02,  1.61050614e-02,\n",
       "         -1.35390721e-02,  3.50125553e-03, -3.21802944e-02, -3.42547633e-02,\n",
       "          1.59199201e-02,  2.71714516e-02,  5.03573306e-02, -3.53325829e-02,\n",
       "          1.95274577e-02,  2.91465726e-02,  3.87439132e-02,  3.22015537e-03,\n",
       "         -1.63260307e-02,  7.97877274e-03,  2.11462136e-02,  2.25127507e-02,\n",
       "         -3.44359614e-02,  1.17995329e-02, -2.05910336e-02, -4.79736403e-02,\n",
       "          1.83201693e-02, -4.29028571e-02,  2.96444856e-02, -2.29588244e-02,\n",
       "         -2.92919055e-02, -2.65355315e-02, -4.31640297e-02, -1.79866347e-02,\n",
       "         -3.44722867e-02, -4.19211201e-03,  4.14087698e-02,  1.60987712e-02,\n",
       "         -2.36944929e-02, -2.38925591e-02,  1.69062018e-02, -5.05948588e-02,\n",
       "          8.17098131e-04,  1.82417929e-02,  2.42693312e-02, -2.00742651e-02,\n",
       "          2.65172329e-02, -3.35756093e-02,  1.15734981e-02,  2.08871327e-02,\n",
       "          3.46161760e-02,  4.68224213e-02,  2.28619408e-02, -5.69984838e-02,\n",
       "          5.82031943e-02,  1.60542410e-02,  3.21419425e-02, -3.84915248e-02,\n",
       "          2.34995913e-02,  5.56245372e-02, -3.95220667e-02, -3.21771353e-02,\n",
       "          5.36950976e-02, -1.93837623e-04, -4.95893732e-02,  3.54734361e-02,\n",
       "          3.55352201e-02,  2.56852079e-02,  2.49027703e-02, -1.76817253e-02,\n",
       "          3.44534032e-02,  2.51029022e-02,  8.28257762e-03, -2.61036772e-02,\n",
       "          2.79982314e-02,  2.19667070e-02,  3.47708240e-02, -3.96735817e-02,\n",
       "          5.51848859e-03,  5.99547215e-02,  1.27465799e-02,  5.81853390e-02,\n",
       "          2.02851035e-02, -4.18905094e-02,  5.15698940e-02,  7.98051991e-03,\n",
       "         -3.59920114e-02, -5.53034060e-03,  5.01118451e-02,  3.23352180e-02,\n",
       "          4.86479662e-02,  1.77429151e-02, -2.72436868e-02, -1.70716383e-02,\n",
       "         -5.08705862e-02, -7.27513665e-03, -5.38001209e-02, -8.33265949e-03,\n",
       "         -2.27659717e-02,  7.32556963e-03,  5.50892809e-03,  3.20807807e-02,\n",
       "          1.99086480e-02, -3.90839987e-02, -5.55077121e-02,  2.58018151e-02,\n",
       "         -7.91379134e-04,  9.89379920e-03,  2.04544235e-02, -5.09835333e-02,\n",
       "          2.34261379e-02, -4.22907621e-02, -9.18869860e-03,  4.48011979e-02,\n",
       "          1.98245030e-02,  8.57070275e-03,  2.10245699e-02, -1.67592075e-02,\n",
       "          4.66110185e-03, -1.19455867e-02, -4.77867611e-02,  3.56133824e-04,\n",
       "          3.65055650e-02,  2.71166395e-02, -3.38022225e-02,  2.16468647e-02,\n",
       "         -2.08973866e-02, -2.39975136e-02,  2.72103082e-02, -3.09091210e-02,\n",
       "          3.90122347e-02, -4.41259295e-02, -1.65515449e-02,  2.82428656e-02,\n",
       "          5.81789352e-02, -1.87207572e-02, -2.50826981e-02,  4.01302651e-02,\n",
       "         -3.02267410e-02, -4.42424156e-02,  1.38611756e-02,  3.47060114e-02,\n",
       "         -8.04355647e-03, -3.52399461e-02, -3.25764269e-02,  9.52315703e-03,\n",
       "          2.83826552e-02,  6.00572377e-02, -2.22118814e-02,  2.72566453e-02,\n",
       "          3.56159136e-02, -2.75593325e-02,  2.59305406e-02, -5.67723438e-02,\n",
       "         -2.83395983e-02, -2.30760351e-02,  3.12214568e-02,  3.51804793e-02,\n",
       "          7.98149407e-03,  4.33679111e-02, -2.62682289e-02,  1.28277056e-02,\n",
       "         -3.30776684e-02, -7.53007084e-03, -1.08654369e-02,  4.32809852e-02,\n",
       "          1.98763814e-02, -2.88870260e-02,  5.90213276e-02,  4.15549194e-03,\n",
       "         -5.38972877e-02, -5.44885509e-02,  7.31389411e-03, -2.61411294e-02,\n",
       "         -4.11023647e-02, -5.32347932e-02,  2.53769085e-02,  6.95173768e-03],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 16,\n",
       "  'topic_words': array(['cookies', 'sklearn', 'analytics', '브라우저', 'browser', 'javascript',\n",
       "         'github', 'chrome', 'firefox', 'analytical', 'multiprocessing',\n",
       "         'learning', 'websites', 'sites', 'correlations', 'percentage',\n",
       "         'learns', 'tracking', 'analyses', 'kakao', 'proteins', 'selenium',\n",
       "         'empirical', 'percent', '사이트', 'parametric', 'analyze',\n",
       "         'kakaotalk', 'learner', 'analyzed', 'khtml', 'correlation',\n",
       "         'analysis', 'urllib', 'cognitive', 'dependencies',\n",
       "         'methodological', 'pie', 'links', '변수', '잠재변수', '분석',\n",
       "         'proportions', 'algorithms', 'dataset', 'parse', 'cognitively',\n",
       "         'practices', 'dependency', '학습'], dtype='<U15'),\n",
       "  'topic_vector': array([-2.76515558e-02,  3.55911441e-02,  1.96721568e-03,  1.03799682e-02,\n",
       "          2.09030584e-02, -5.47314733e-02,  2.67581642e-02, -3.82308811e-02,\n",
       "          5.35147190e-02,  5.20873070e-02,  9.46199521e-03,  2.75316946e-02,\n",
       "          1.58382487e-02,  1.50975538e-02, -5.09179346e-02,  3.57006378e-02,\n",
       "          1.24043077e-02,  2.45512743e-03,  2.23757233e-02,  3.92555371e-02,\n",
       "          4.16131169e-02,  2.13036109e-02, -2.89790239e-02,  2.67940722e-02,\n",
       "         -6.67369440e-02, -5.05266413e-02, -2.77299657e-02,  3.05195292e-03,\n",
       "         -5.79823256e-02, -4.27260362e-02, -3.56266499e-02,  3.17689776e-02,\n",
       "         -2.33277632e-03, -6.00370951e-02, -2.96288561e-02,  4.36845683e-02,\n",
       "          6.02502301e-02,  9.63539642e-05,  2.11897865e-02,  2.36743279e-02,\n",
       "         -6.16942765e-03, -1.67600140e-02, -5.80965690e-02, -7.84677081e-03,\n",
       "          1.17277466e-02,  2.38774391e-03, -3.06166578e-02,  3.80152613e-02,\n",
       "         -6.07654639e-02, -1.41675277e-02, -2.52622068e-02, -5.50879445e-03,\n",
       "         -1.71343498e-02,  1.77532658e-02, -1.52602531e-02, -7.51512796e-02,\n",
       "          1.70609411e-02,  1.65042654e-02, -4.16495986e-02, -1.28922956e-02,\n",
       "         -4.03903844e-03,  4.62627858e-02,  1.69543568e-02, -4.59189191e-02,\n",
       "         -7.84765463e-03,  3.45915221e-02,  2.81207357e-02, -3.44060957e-02,\n",
       "         -1.25879850e-02, -1.51887834e-02, -3.33344713e-02, -4.87205051e-02,\n",
       "          4.40234115e-04, -2.68088765e-02,  3.99151035e-02, -1.17646821e-03,\n",
       "          2.90246271e-02,  4.68730032e-02,  2.92775361e-03, -7.78520480e-02,\n",
       "         -7.75525197e-02, -6.53812289e-02, -4.95084748e-02, -7.69778015e-03,\n",
       "         -4.29370180e-02,  1.19515341e-02, -2.05152445e-02, -2.25072410e-02,\n",
       "          1.59106608e-02,  5.77299483e-03, -1.12415897e-02,  1.92100387e-02,\n",
       "          2.97251865e-02, -1.19091487e-02, -1.56020485e-02,  5.45579381e-02,\n",
       "         -2.13194359e-02,  2.83804201e-02, -4.01394665e-02, -1.79972053e-02,\n",
       "          4.06973511e-02,  2.53622327e-02,  8.54110066e-03,  4.85508703e-03,\n",
       "          3.10339201e-02, -2.18381956e-02, -5.49090132e-02,  6.16128519e-02,\n",
       "          6.93638474e-02,  3.67277674e-02,  8.90469085e-03, -2.84523461e-02,\n",
       "          2.49143615e-02, -1.28508089e-02,  3.43351848e-02, -3.82866375e-02,\n",
       "         -2.36500637e-03, -1.87578090e-02,  5.35245985e-02,  5.76262083e-03,\n",
       "         -1.70476511e-02, -5.57371899e-02,  1.29046133e-02, -2.98044980e-02,\n",
       "          2.79177167e-02, -1.69125926e-02, -2.59069726e-02, -3.44602540e-02,\n",
       "         -7.15355575e-03, -2.18028650e-02, -3.88441384e-02,  2.13943720e-02,\n",
       "          6.46508634e-02, -6.10109977e-03, -2.69743782e-02,  4.84899506e-02,\n",
       "         -5.23761893e-03, -5.35944887e-02,  1.97145678e-02, -7.36842863e-03,\n",
       "          2.09771954e-02,  3.62992398e-02, -3.56310345e-02,  2.35428438e-02,\n",
       "         -4.08617258e-02,  4.75069368e-03, -8.60499498e-03,  1.69217754e-02,\n",
       "         -2.59487499e-02, -1.03004149e-03,  1.90846268e-02,  2.78494786e-02,\n",
       "          1.62283834e-02, -2.98763905e-02,  1.07593993e-02, -2.92518605e-02,\n",
       "         -6.45326823e-03, -2.23310404e-02,  3.50508429e-02, -6.71401666e-03,\n",
       "          3.68608236e-02, -5.76797910e-02,  6.23591207e-02, -2.01412644e-02,\n",
       "          3.34319063e-02,  3.90060828e-03,  2.70414278e-02,  2.12251320e-02,\n",
       "         -2.82394923e-02, -1.38846971e-02,  7.75039289e-03, -3.88153754e-02,\n",
       "         -1.27159441e-02, -4.04057205e-02, -5.40838167e-02,  1.65980980e-02,\n",
       "         -5.80438562e-02, -1.13856877e-04, -4.55101468e-02,  5.77637739e-02,\n",
       "          3.35884579e-05,  3.81146781e-02,  3.50667536e-03,  2.89877673e-04,\n",
       "         -1.73136592e-02,  1.36540774e-02,  3.80471139e-03,  2.29514930e-02,\n",
       "          5.25966100e-03,  3.44508290e-02,  3.70164923e-02, -3.64378914e-02,\n",
       "          4.30852585e-02,  8.21109489e-03, -1.21087842e-02, -3.92441638e-02,\n",
       "          3.88786830e-02, -7.84784835e-03,  3.71690579e-02, -3.57321873e-02,\n",
       "          3.01367734e-02, -5.25196940e-02,  1.84203556e-03, -2.07261238e-02,\n",
       "         -1.32397451e-02, -1.45523800e-02,  5.88766187e-02, -1.70338228e-02,\n",
       "         -5.40921651e-03,  8.51133605e-04, -1.98219642e-02,  1.32755758e-02,\n",
       "         -4.05580131e-03,  3.06467079e-02,  3.53846475e-02, -5.17567843e-02,\n",
       "         -3.36823612e-02, -6.20309263e-02, -4.76615457e-03,  1.04173487e-02,\n",
       "          8.20760708e-03, -5.65715581e-02,  2.18077973e-02, -4.41832729e-02,\n",
       "         -5.60209416e-02, -1.55859990e-02, -5.95602393e-02, -4.47004773e-02,\n",
       "          5.44645563e-02, -2.52709072e-03, -4.48199250e-02,  4.72500585e-02,\n",
       "          5.07587418e-02, -1.34453727e-02,  4.92423549e-02,  6.34028837e-02,\n",
       "          7.91210774e-03,  1.32740312e-03,  6.07683808e-02, -5.07431738e-02,\n",
       "         -3.43562402e-02, -8.54890887e-03,  4.39287759e-02, -1.28931981e-02,\n",
       "         -4.26798016e-02, -6.19660355e-02,  2.16388311e-02, -1.55614680e-02,\n",
       "         -3.48019674e-02, -1.00232027e-02, -3.52539774e-03, -7.15924203e-02,\n",
       "         -2.65172478e-02, -2.58925781e-02,  4.39548418e-02, -6.06912896e-02,\n",
       "         -2.62761712e-02,  7.50248060e-02,  1.17791649e-02, -2.78511606e-02,\n",
       "          7.77690299e-03,  1.21959485e-02, -1.36520313e-02, -4.95535880e-02,\n",
       "         -4.36636545e-02,  9.62632988e-03, -2.68526077e-02,  5.59564978e-02,\n",
       "         -1.26439170e-03,  2.09520105e-02,  1.60786777e-03, -4.89247451e-03,\n",
       "         -1.58150550e-02,  4.54376861e-02,  4.93016951e-02,  3.00077293e-02,\n",
       "         -1.75941922e-03,  2.49943808e-02, -3.71051431e-02,  1.74697360e-03,\n",
       "         -1.18758511e-02,  3.12606432e-02,  1.55854542e-02, -6.74058078e-03,\n",
       "          2.16158945e-02, -4.97690886e-02, -6.00922666e-03,  8.31274688e-03,\n",
       "         -1.98324546e-02,  3.18608880e-02,  1.35009484e-02,  4.75435928e-02,\n",
       "         -9.87852085e-03,  4.17991020e-02, -6.27973974e-02, -5.62036131e-03,\n",
       "         -6.79842234e-02,  6.25396073e-02,  2.22659996e-03,  5.91301061e-02,\n",
       "          2.71094567e-03,  3.86977792e-02,  9.70948301e-03, -1.94972462e-03,\n",
       "         -3.73179279e-02, -3.91018577e-03,  9.45930369e-03,  1.84825920e-02,\n",
       "          3.41188088e-02,  2.00619195e-02,  5.16472831e-02, -6.89113420e-03,\n",
       "         -5.43545820e-02,  1.23618199e-02, -6.87694363e-03,  3.38583104e-02,\n",
       "         -1.16989287e-02,  3.56929116e-02, -5.09140734e-03,  1.04238596e-02,\n",
       "          5.21688461e-02, -2.32115574e-02,  1.17032062e-02,  2.29148492e-02,\n",
       "          2.85911430e-02, -4.46495041e-02,  1.17018307e-02, -2.36408245e-02,\n",
       "          4.51801680e-02, -3.57104256e-03, -4.54197871e-03, -3.49453501e-02,\n",
       "          2.16934439e-02, -2.75278054e-02,  2.39890590e-02,  1.00470018e-02,\n",
       "          3.60354520e-02, -2.29905103e-03, -6.43507764e-02, -3.93122882e-02,\n",
       "         -2.89273690e-02,  3.15073840e-02, -5.07989675e-02, -1.35760615e-02,\n",
       "         -1.11830141e-02,  3.83598991e-02, -4.40358231e-03,  5.02013462e-03,\n",
       "         -2.92061102e-02, -1.40411453e-02, -7.49264583e-02,  1.30534498e-02,\n",
       "         -9.86676384e-03,  9.61728767e-03, -5.00386283e-02,  1.82916243e-02,\n",
       "         -3.11651491e-02,  3.37957256e-02,  1.28639592e-02, -3.48821562e-03,\n",
       "          1.45852799e-03, -2.57121399e-02,  3.37970592e-02, -5.37563898e-02,\n",
       "          3.62341315e-03, -1.76486857e-02, -1.95393488e-02, -4.00762670e-02,\n",
       "         -3.26507315e-02, -2.33229622e-02, -4.21004146e-02,  3.96187752e-02,\n",
       "         -4.03978191e-02,  8.42921995e-03,  2.21642833e-02, -3.51825096e-02,\n",
       "          2.26658322e-02, -3.23498100e-02,  7.46994978e-03, -1.54385082e-02,\n",
       "          1.51684880e-02,  1.45345777e-02,  1.02643399e-02,  5.51530644e-02,\n",
       "         -3.32139917e-02,  3.72153968e-02,  5.12280799e-02, -4.22143079e-02,\n",
       "          1.07604004e-02,  8.97566509e-03,  4.03561108e-02, -4.65472564e-02,\n",
       "         -3.80833894e-02,  2.03629006e-02,  2.44116765e-02, -3.57277542e-02,\n",
       "         -1.08438646e-02,  1.44575406e-02,  2.45118309e-02, -2.62219552e-03,\n",
       "         -1.11108925e-02,  1.66183384e-03,  5.41797206e-02,  3.20401937e-02,\n",
       "          5.80111984e-03, -1.41798556e-02,  5.81872091e-03,  5.01982030e-03,\n",
       "          8.31991807e-03, -4.75697964e-02,  2.78426032e-03,  2.68439041e-03,\n",
       "          2.10843589e-02, -2.56653763e-02,  2.59875879e-02,  1.18021183e-02,\n",
       "          3.40590328e-02, -3.15320827e-02, -1.74689870e-02, -3.39003690e-02,\n",
       "          3.59709263e-02, -2.47664973e-02,  8.40300601e-03,  6.14084937e-02,\n",
       "         -6.62932219e-03,  4.23301309e-02, -3.26333307e-02,  2.64748894e-02,\n",
       "         -2.85004340e-02, -6.35944754e-02, -3.41814421e-02,  5.64264394e-02,\n",
       "         -1.77384187e-02,  1.30684441e-02, -1.77714583e-02,  1.91782620e-02,\n",
       "          4.54549398e-03,  1.65450834e-02, -3.46847586e-02,  1.53212659e-02,\n",
       "         -2.75665000e-02,  4.87982891e-02,  7.10302405e-03, -6.29757494e-02,\n",
       "          2.63011679e-02, -2.69784089e-02,  6.77981973e-02,  3.61807179e-03,\n",
       "          1.54731190e-02,  2.42431071e-02,  2.85699572e-02,  2.68289633e-02,\n",
       "         -6.08398989e-02, -1.86575316e-02, -4.95979749e-02, -3.52552310e-02,\n",
       "          3.77665497e-02, -3.57041471e-02, -1.26705160e-02,  4.13714275e-02,\n",
       "         -1.09107560e-02,  1.06068212e-03, -2.10085101e-02, -5.28519973e-02,\n",
       "          4.97492589e-02, -4.39487398e-02,  3.14410478e-02, -1.96183287e-03,\n",
       "          5.33159524e-02, -3.11650839e-02,  5.18003292e-02,  4.88864854e-02,\n",
       "          2.49796212e-02,  2.58215293e-02, -1.99912209e-02, -3.21686417e-02,\n",
       "          2.84338333e-02,  1.27515364e-02,  6.79436512e-03,  1.74925793e-02,\n",
       "          5.46649657e-02,  3.68263014e-02, -1.93917509e-02,  2.77459733e-02,\n",
       "          2.02639517e-03,  1.16016902e-02,  1.05388649e-02, -6.33649379e-02,\n",
       "         -4.36847471e-03,  2.32669096e-02,  1.37919514e-02,  1.08176349e-02,\n",
       "          4.79192734e-02, -4.57016714e-02, -1.15218535e-02,  9.25409701e-03,\n",
       "          2.78806817e-02, -3.67262177e-02,  1.81402415e-02,  5.08738402e-03,\n",
       "          8.31060950e-03, -2.06994894e-03,  3.76468115e-02,  3.07712727e-03,\n",
       "         -3.03638950e-02, -6.03724569e-02, -6.09463304e-02,  4.14672820e-03,\n",
       "         -3.16084325e-02, -1.57423504e-02,  3.93746905e-02,  5.31729590e-03],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 17,\n",
       "  'topic_words': array(['statistically', 'probabilistic', 'statistical', 'statistics',\n",
       "         'statistic', 'selective', 'probability', 'selectively', '통계청',\n",
       "         'multivariate', 'predictive', 'randomized', 'coefficient',\n",
       "         'covariance', 'variance', 'classifier', 'selection', 'chosen',\n",
       "         'clustering', '통계', 'coefficients', 'probabilities', 'predictor',\n",
       "         'selecting', 'variances', 'unbiased', 'normalization',\n",
       "         'qualitative', 'variability', 'regression', 'correlation',\n",
       "         'predictors', 'classifiers', 'clusters', 'optimal', 'cluster',\n",
       "         'selected', 'predicts', 'correlations', 'stats', 'sample',\n",
       "         'classification', 'adaptive', 'quantitative', 'choices',\n",
       "         'categorical', 'select', 'choosing', 'choose', 'optimization'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-5.10260388e-02, -8.43911432e-03, -5.00735827e-02, -1.67543925e-02,\n",
       "         -3.47325020e-02, -3.93095091e-02,  2.60752942e-02, -3.56495008e-02,\n",
       "          1.94817223e-02,  1.95593573e-02, -1.54585745e-02,  2.99312957e-02,\n",
       "          5.00316247e-02, -3.01962486e-03, -5.09273224e-02, -5.07243946e-02,\n",
       "          2.82873586e-03, -3.43032554e-02,  4.65247445e-02, -1.58835948e-03,\n",
       "         -4.01090980e-02, -3.58880684e-02, -5.09326234e-02,  5.10083213e-02,\n",
       "         -5.10280505e-02, -5.05685732e-02,  4.18967381e-02, -2.41599288e-02,\n",
       "         -2.33540870e-02, -2.54522897e-02, -4.63501029e-02,  2.11743489e-02,\n",
       "          2.68565658e-02, -5.07668853e-02, -5.07029817e-02,  4.88846470e-03,\n",
       "         -5.04041426e-02,  2.14962605e-02,  1.07911304e-02,  5.09782359e-02,\n",
       "         -1.40257401e-03, -4.65105549e-02,  4.90066893e-02, -4.75315377e-02,\n",
       "         -4.36090641e-02,  1.06067788e-02,  5.08946776e-02,  1.99963208e-02,\n",
       "         -5.04748039e-02, -3.04491306e-03, -1.96701232e-02, -3.70159522e-02,\n",
       "          4.63303030e-02, -3.48925032e-02,  4.81166132e-02, -5.04394174e-02,\n",
       "         -1.97967738e-02,  5.01880534e-02, -9.45535954e-03,  5.05858175e-02,\n",
       "         -3.16340141e-02,  4.03673127e-02,  1.05749574e-02, -4.95020859e-02,\n",
       "         -2.50105616e-02,  1.00875590e-02,  2.01469427e-03,  3.33366776e-03,\n",
       "          6.84519624e-03, -4.98696463e-03, -3.01029682e-02,  2.81298272e-02,\n",
       "         -4.57974337e-02, -4.08908129e-02, -4.64439504e-02, -5.05882874e-02,\n",
       "          4.66049239e-02,  4.93538082e-02,  4.29173559e-03, -5.10260276e-02,\n",
       "         -5.10280505e-02, -4.36475165e-02, -2.23854743e-02, -1.92531422e-02,\n",
       "         -1.66529976e-02, -1.73030291e-02, -3.73863578e-02, -2.29355134e-02,\n",
       "         -3.18019725e-02, -2.15112977e-02, -4.56476733e-02, -4.84036133e-02,\n",
       "          3.87664549e-02, -5.09941503e-02,  4.09228243e-02,  5.10244593e-02,\n",
       "          1.74074862e-02,  5.05922027e-02,  9.47202649e-03,  5.03199026e-02,\n",
       "          5.03296033e-02, -2.92217135e-02,  4.90137190e-02, -1.92136914e-02,\n",
       "          3.40816379e-02, -4.92431596e-02, -5.00155576e-02, -2.54813936e-02,\n",
       "          2.27836315e-02,  5.09616211e-02,  5.01114056e-02, -5.09117953e-02,\n",
       "         -2.97546797e-02, -1.92649700e-02,  4.72984388e-02, -1.16175180e-02,\n",
       "          2.11471021e-02,  3.18036671e-03, -4.93855551e-02,  3.95937450e-02,\n",
       "         -3.62314880e-02,  3.05427164e-02,  4.98904288e-02, -1.96626671e-02,\n",
       "          3.04770358e-02, -3.68965343e-02, -2.32500713e-02,  5.06023765e-02,\n",
       "         -5.05501851e-02,  4.39604521e-02, -5.10118380e-02,  3.44563574e-02,\n",
       "          5.05708046e-02,  4.88604940e-02, -1.04083018e-02,  5.03465049e-02,\n",
       "         -3.72387245e-02, -3.94625887e-02,  4.43173945e-02, -3.07383984e-02,\n",
       "          1.29763754e-02, -4.82337922e-02,  3.18616964e-02, -4.98018451e-02,\n",
       "          4.40949574e-02, -1.09578790e-02, -5.09217866e-02,  4.90904301e-02,\n",
       "          4.64347228e-02,  3.89478691e-02,  4.50852439e-02, -2.99868919e-02,\n",
       "         -4.56750616e-02, -2.71406919e-02,  2.73239203e-02, -4.66712452e-02,\n",
       "          4.64843139e-02, -2.68882141e-03,  3.12458426e-02, -2.75948253e-02,\n",
       "          3.08778733e-02, -4.90929857e-02,  2.43003238e-02, -5.08339219e-02,\n",
       "         -4.44338396e-02, -4.75712530e-02,  4.15296219e-02, -4.07571718e-02,\n",
       "         -4.76551577e-02,  5.09181134e-02, -5.08250371e-02, -1.14157964e-02,\n",
       "          4.84835580e-02, -3.90567668e-02, -2.89134542e-03,  4.05698195e-02,\n",
       "          3.32470722e-02,  4.90656160e-02, -4.80314605e-02,  4.76053730e-02,\n",
       "          4.71594408e-02, -4.35824180e-03, -4.45483848e-02, -2.92005055e-02,\n",
       "         -5.10107279e-02, -2.58422233e-02,  2.99996547e-02,  5.03901355e-02,\n",
       "         -3.09212320e-02, -4.92963716e-02,  3.97779942e-02,  1.16260387e-02,\n",
       "          4.62738872e-02, -2.95803137e-02, -5.33610675e-03,  5.08427732e-02,\n",
       "         -5.09233065e-02,  2.67937686e-02,  5.10213152e-02,  4.89265770e-02,\n",
       "         -1.22782495e-02, -1.76041573e-03, -5.00698090e-02,  1.29160527e-02,\n",
       "         -3.90662476e-02, -2.74092313e-02, -5.10019064e-02, -1.10457838e-02,\n",
       "         -2.00886484e-02,  4.13911715e-02,  3.30206677e-02,  1.33047402e-02,\n",
       "         -5.10270596e-02,  1.23386923e-02,  4.12090421e-02, -5.05142398e-02,\n",
       "          4.37156111e-03, -5.01839519e-02,  1.86180472e-02, -5.03855124e-02,\n",
       "          3.08722146e-02,  1.93987172e-02,  2.70533375e-02, -4.91686836e-02,\n",
       "         -5.08244820e-02,  3.85783091e-02, -5.07827178e-02, -9.98196006e-03,\n",
       "         -6.69943448e-03, -1.54083939e-02, -1.73106976e-02,  5.09759784e-02,\n",
       "         -3.06557715e-02, -5.72168874e-03, -1.27846049e-02, -1.02951471e-02,\n",
       "         -2.16463339e-02,  5.08701093e-02,  1.67473517e-02, -1.92382634e-02,\n",
       "          1.56055512e-02,  2.31380723e-02, -4.24480671e-03, -6.20779302e-03,\n",
       "          4.28687260e-02, -5.07137887e-02,  2.77995877e-02, -4.17572856e-02,\n",
       "         -2.27514305e-03, -2.12897044e-02,  1.53019857e-02, -3.11061479e-02,\n",
       "         -2.03757342e-02,  5.42161148e-03, -3.94345000e-02, -2.72589680e-02,\n",
       "         -4.38347794e-02, -1.50218997e-02, -3.09247579e-02, -4.98241223e-02,\n",
       "         -3.48011963e-02,  1.18202092e-02, -5.09170592e-02, -3.27096954e-02,\n",
       "          4.56787422e-02, -5.10200188e-02,  1.39570776e-02,  3.07958908e-02,\n",
       "          2.77111437e-02,  2.33982038e-02,  4.83942330e-02,  3.54982913e-03,\n",
       "         -2.88439877e-02, -4.71275672e-02, -1.47509528e-02,  3.23631838e-02,\n",
       "         -4.98207510e-02,  4.53831032e-02, -5.10245338e-02, -3.09289638e-02,\n",
       "         -4.76005264e-02,  4.10266705e-02,  2.98283286e-02,  3.91135737e-02,\n",
       "         -1.94039103e-02,  5.09326980e-02, -5.08984625e-02, -4.93522659e-02,\n",
       "         -3.05890925e-02,  5.07606268e-02,  3.52803767e-02,  3.01371161e-02,\n",
       "          5.10146134e-02, -1.31506082e-02, -4.81481217e-02,  5.82882110e-03,\n",
       "         -3.81497219e-02,  4.32347693e-02,  3.37219462e-02,  5.01877293e-02,\n",
       "         -4.95182052e-02,  5.09505160e-02, -2.54344288e-02, -5.10058627e-02,\n",
       "         -5.10280132e-02, -4.69571166e-02, -4.03689556e-02, -2.08101869e-02,\n",
       "         -2.07311325e-02,  2.68088188e-02, -5.06555364e-02,  7.73308426e-03,\n",
       "         -4.45073061e-02, -2.47478727e-02,  3.67381498e-02,  4.41610441e-02,\n",
       "          3.79871055e-02, -4.83872332e-02,  4.23349813e-02, -4.50823680e-02,\n",
       "         -3.18518793e-03, -2.23296974e-02, -2.86504142e-02,  2.06452869e-02,\n",
       "         -1.26542095e-02, -2.21077986e-02, -4.46357653e-02, -2.59161592e-02,\n",
       "          2.72679627e-02, -9.09284316e-03, -1.20744985e-02, -5.01763895e-02,\n",
       "         -1.31351622e-02, -2.82576531e-02, -1.59038752e-02,  2.22564265e-02,\n",
       "         -5.06741777e-02, -4.68308255e-02, -5.10272980e-02, -4.39778194e-02,\n",
       "         -4.82324138e-02,  2.24301778e-02,  3.54404040e-02, -5.04056923e-02,\n",
       "         -2.26518530e-02,  5.08044846e-02,  5.05381636e-02,  4.93535511e-02,\n",
       "         -6.06741931e-04,  8.72604578e-05,  5.03153317e-02, -1.68167062e-05,\n",
       "         -2.99065057e-02,  6.45229733e-03,  2.82616504e-02, -3.19029726e-02,\n",
       "         -3.80308256e-02,  4.66346033e-02, -5.03688529e-02, -3.37370709e-02,\n",
       "          5.07617481e-02, -5.09500690e-02,  2.88876388e-02, -2.51364671e-02,\n",
       "         -4.98651639e-02,  1.37520153e-02, -3.08617204e-02,  4.54878025e-02,\n",
       "         -7.21383560e-03,  3.90558727e-02,  2.91926023e-02,  5.09397611e-02,\n",
       "         -2.98181809e-02,  5.10144643e-02,  2.21288021e-04, -5.05081639e-02,\n",
       "          9.35448892e-03, -5.79541549e-03, -5.03265262e-02, -3.73496749e-02,\n",
       "          3.08585055e-02, -4.76959050e-02,  7.77410949e-03, -2.12063305e-02,\n",
       "         -5.06881885e-02,  5.07801995e-02,  3.68755534e-02, -4.39005271e-02,\n",
       "          4.64104190e-02, -2.90495269e-02,  3.29514854e-02, -1.45277558e-02,\n",
       "         -2.52923016e-02,  5.08054085e-02, -4.54049818e-02, -1.12527818e-03,\n",
       "          2.39702221e-02, -5.70022175e-03, -4.97095771e-02,  3.50781865e-02,\n",
       "          3.39966789e-02,  4.67797704e-02,  5.03668711e-02,  5.71622467e-03,\n",
       "         -5.09636328e-02,  3.87723325e-03,  3.83967273e-02, -2.48814318e-02,\n",
       "          3.46658453e-02, -4.97093387e-02, -2.98704710e-02, -3.31790335e-02,\n",
       "         -2.38220133e-02,  3.77465524e-02,  4.46753912e-02,  4.48411256e-02,\n",
       "          3.87558565e-02,  3.33784856e-02,  4.97306809e-02, -3.37849781e-02,\n",
       "         -2.44111978e-02, -5.06729372e-02, -7.63615244e-04,  5.08785360e-02,\n",
       "          4.36904170e-02,  2.48097610e-02, -2.75642090e-02, -3.87651660e-02,\n",
       "          1.39998943e-02,  3.13961022e-02, -4.74886894e-02, -1.29742771e-02,\n",
       "         -3.66565511e-02, -4.28283028e-02,  4.59186286e-02,  4.98053357e-02,\n",
       "          4.86398265e-02,  4.66810837e-02, -5.10247573e-02,  1.48404539e-02,\n",
       "         -4.31788415e-02, -2.02796198e-02, -3.94096076e-02, -5.10174856e-02,\n",
       "          2.67341081e-02, -3.25971060e-02,  1.27603021e-02,  2.60926038e-02,\n",
       "         -1.60293728e-02,  2.22005583e-02, -1.47967441e-02, -4.37960513e-02,\n",
       "          4.49312441e-02, -4.82999459e-02, -4.87519577e-02, -3.73050943e-02,\n",
       "         -2.57948749e-02,  4.85234521e-02, -4.10481952e-02,  5.10067865e-02,\n",
       "         -2.86196116e-02, -5.09752445e-02,  7.40182633e-03, -5.10272272e-02,\n",
       "          4.92051952e-02, -5.08025810e-02,  9.87821259e-03, -4.93946560e-02,\n",
       "          5.08815423e-02,  2.38346122e-02,  2.53839698e-02,  5.09023182e-02,\n",
       "         -7.46401120e-03,  2.75787823e-02, -4.84071486e-02,  2.52028704e-02,\n",
       "          3.11906282e-02, -1.64523441e-02, -2.70414855e-02,  1.15569811e-02,\n",
       "          4.78928499e-02,  5.10280132e-02, -4.37599793e-02,  1.57358907e-02,\n",
       "          3.98755893e-02,  3.33265141e-02, -2.41180491e-02, -5.00615612e-02,\n",
       "         -3.30003873e-02,  1.78278983e-02,  4.66373600e-02,  3.84837575e-02,\n",
       "         -9.54009779e-03, -1.40996801e-03, -3.72082330e-02, -4.67689522e-02,\n",
       "          3.74496169e-02, -5.04081734e-02,  4.11762856e-02,  4.49434705e-02,\n",
       "          1.25347851e-02, -4.90975194e-02,  5.10278344e-02, -2.93112900e-02,\n",
       "         -3.35436538e-02, -5.09323664e-02,  4.21484299e-02, -4.58885506e-02,\n",
       "         -3.24299261e-02, -4.49515767e-02, -4.97451164e-02,  2.96487845e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 18,\n",
       "  'topic_words': array(['statistical', 'dataset', 'statistically', 'covariance',\n",
       "         'dataframe', 'coefficient', 'statistics', 'variance', 'statistic',\n",
       "         'coefficients', 'datasets', 'correlation', 'regression',\n",
       "         'variances', 'correlations', 'probabilistic', 'sklearn',\n",
       "         'scatterplot', '통계청', 'matplotlib', 'computed', 'ggplot',\n",
       "         'clustering', 'computationally', 'computation', '비율', '통계',\n",
       "         'computational', 'stats', 'nonparametric', 'data', 'calculations',\n",
       "         'numpy', 'multivariate', 'variability', 'calculation', 'matlab',\n",
       "         'percentage', 'ratio', 'variables', 'tensorflow', 'probability',\n",
       "         'multiprocessing', 'populations', 'cluster', 'calculate',\n",
       "         'clusters', 'stat', '효율', 'calculated'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.89039773e-02, -1.57254003e-02, -2.15463452e-02, -8.13707523e-03,\n",
       "         -3.31731550e-02, -4.59157713e-02, -1.15714129e-02, -4.60382923e-02,\n",
       "          4.72909212e-02,  4.49951924e-02,  1.77271049e-02,  1.91931687e-02,\n",
       "          5.38099855e-02, -3.02209854e-02, -5.88488020e-02, -9.74611193e-03,\n",
       "          3.53010069e-03,  3.45146656e-03,  2.33885404e-02,  3.41886133e-02,\n",
       "          1.58030000e-02, -3.68431956e-02, -3.82125527e-02,  4.84437421e-02,\n",
       "         -4.54978198e-02, -4.18907031e-02,  2.62328647e-02, -2.31995657e-02,\n",
       "          7.28468876e-04, -5.07340394e-02, -5.52302599e-02,  2.95964349e-03,\n",
       "         -6.61326852e-03, -5.65448999e-02,  1.25269620e-02, -3.11363279e-03,\n",
       "         -3.87328789e-02,  2.33009551e-03, -2.25047208e-02,  4.68322150e-02,\n",
       "         -1.07408352e-02, -9.65123065e-03,  1.49576403e-02, -4.44211513e-02,\n",
       "         -2.22298410e-02, -5.19040301e-02,  5.03796712e-02,  2.20809169e-02,\n",
       "         -5.23262843e-02,  2.33490653e-02,  9.74780135e-03, -3.01210415e-02,\n",
       "          1.25537412e-02, -1.17367981e-02,  3.23587582e-02, -5.89778498e-02,\n",
       "          2.06989385e-02,  3.42597924e-02,  2.87742191e-03,  5.86877987e-02,\n",
       "          3.15309055e-02,  5.45376129e-02,  2.05762126e-02, -4.00646403e-02,\n",
       "         -9.40587930e-03, -1.77866500e-03, -3.72222392e-04,  1.76458107e-03,\n",
       "          2.79863421e-02,  2.26599583e-03, -5.31513281e-02,  8.89978837e-05,\n",
       "         -2.23595276e-02, -3.04122008e-02, -4.79911491e-02, -5.10779209e-02,\n",
       "          2.66582258e-02,  1.57853719e-02, -2.80940975e-03, -6.02801442e-02,\n",
       "         -6.03073388e-02, -4.74249683e-02, -5.05217463e-02, -2.28265021e-02,\n",
       "         -4.79795970e-03, -2.73206197e-02, -4.53478619e-02, -2.00633481e-02,\n",
       "          1.75848547e-02, -3.37764397e-02, -2.02593626e-03, -3.13371643e-02,\n",
       "         -1.41622322e-02, -5.22051007e-02,  3.13088335e-02,  5.84145784e-02,\n",
       "          1.53989671e-03,  2.33306084e-02,  2.50154100e-02,  3.13482322e-02,\n",
       "          3.92279178e-02, -1.93561148e-02,  4.83590253e-02, -1.61948986e-02,\n",
       "          2.81592607e-02, -4.25065085e-02, -4.80982438e-02, -1.02373874e-02,\n",
       "          9.75851156e-03,  5.71474284e-02,  3.60393226e-02, -4.45257723e-02,\n",
       "         -1.70512963e-02, -6.99184183e-03,  2.09310632e-02, -4.77969646e-03,\n",
       "          1.33535694e-02, -2.78843809e-02,  2.96255946e-03, -5.68319578e-03,\n",
       "         -1.48816826e-02,  4.38932627e-02,  1.19851436e-02,  2.02805549e-02,\n",
       "          4.95074987e-02, -2.90490687e-04, -2.78724656e-02,  4.74369079e-02,\n",
       "         -3.98789421e-02,  4.33400795e-02, -5.76154962e-02,  3.54460329e-02,\n",
       "          5.90325817e-02,  1.66937858e-02, -1.66445691e-02,  3.47437710e-02,\n",
       "          1.11070853e-02, -3.78259495e-02,  5.37406690e-02,  5.20448238e-02,\n",
       "         -2.24889182e-02, -2.62993500e-02,  2.75707319e-02, -3.96959260e-02,\n",
       "          5.71706705e-03,  2.08787303e-02, -4.51118834e-02,  4.34709117e-02,\n",
       "          2.27073077e-02,  2.26718169e-02,  4.18146066e-02,  2.90163867e-02,\n",
       "         -1.22154402e-02, -4.01323736e-02,  8.48367717e-03, -3.69350389e-02,\n",
       "          2.36010719e-02, -4.19966225e-03,  1.25992149e-02, -1.18314419e-02,\n",
       "          3.95954363e-02, -5.47762681e-03,  2.36876495e-02, -4.15969267e-02,\n",
       "         -5.51851913e-02, -2.46799625e-02, -2.79780403e-02, -5.57566294e-04,\n",
       "         -2.96888463e-02,  5.45995310e-02, -3.76858898e-02, -9.62167978e-03,\n",
       "          3.87201346e-02, -4.51292144e-03,  1.74798518e-02,  4.50336002e-02,\n",
       "         -4.49364819e-03,  3.12149171e-02, -5.17699756e-02,  4.47766259e-02,\n",
       "          1.73675716e-02, -2.62783747e-02, -1.69344246e-04,  1.89331605e-03,\n",
       "         -5.30850142e-02, -9.12016537e-03,  5.52346669e-02,  5.42033687e-02,\n",
       "          8.73834454e-03, -4.38913181e-02, -1.10796168e-02,  1.99271133e-03,\n",
       "          4.50975299e-02, -3.20969559e-02, -2.55273804e-02,  4.48005386e-02,\n",
       "         -5.85439913e-02, -1.82659272e-03,  5.60150780e-02,  8.74026027e-03,\n",
       "         -2.32499596e-02,  3.45917209e-03, -2.02569049e-02, -2.30303919e-03,\n",
       "         -2.50324681e-02, -2.14194935e-02, -2.67894827e-02,  1.96922701e-02,\n",
       "         -3.36245522e-02,  3.70278955e-02, -7.70811876e-03,  3.45896818e-02,\n",
       "         -5.68496808e-02,  1.06629394e-02,  4.53880727e-02, -3.01753264e-03,\n",
       "          4.37670480e-03, -5.40745519e-02,  3.93871441e-02, -2.63678227e-02,\n",
       "          2.57528163e-02,  2.79222801e-02,  2.16323733e-02, -3.87659855e-02,\n",
       "         -5.94819635e-02,  3.46309580e-02, -4.41759415e-02, -2.08108909e-02,\n",
       "          5.87466592e-03, -3.59726697e-02, -1.12192044e-02,  5.79899251e-02,\n",
       "          8.95940699e-04, -9.90807172e-03,  4.02366444e-02,  4.13259603e-02,\n",
       "         -4.23677117e-02,  5.16043380e-02,  2.64018541e-04, -1.83978565e-02,\n",
       "         -1.96648180e-03,  3.85906473e-02, -1.55185321e-02,  1.22131705e-02,\n",
       "          3.25458474e-03, -5.91409467e-02, -1.91615932e-02,  7.28358841e-03,\n",
       "          5.82534354e-03, -1.49579793e-02, -1.50245139e-02, -5.18757030e-02,\n",
       "         -3.99245927e-03, -1.26547124e-02, -2.40609795e-02, -1.93463005e-02,\n",
       "         -1.88363381e-02, -8.97798967e-03,  2.12007901e-03, -3.90445553e-02,\n",
       "         -3.16542313e-02,  1.48924496e-02, -2.84652803e-02, -3.96035463e-02,\n",
       "          2.85343267e-02, -5.10555319e-02, -8.31291359e-03, -8.34669173e-03,\n",
       "         -7.81815313e-03,  2.40994729e-02, -4.22882810e-02, -4.34315018e-02,\n",
       "         -3.93483378e-02, -4.59813848e-02, -1.39961001e-02,  1.38350949e-02,\n",
       "         -4.98058386e-02,  3.69997881e-02, -3.95167321e-02,  6.74465718e-03,\n",
       "         -5.26901521e-02,  3.68600264e-02,  4.01801243e-02,  8.75852723e-03,\n",
       "         -2.22413093e-02,  4.88182530e-02, -4.49693017e-02, -5.37002422e-02,\n",
       "         -3.38789709e-02,  4.93261889e-02,  5.19650690e-02,  5.79332486e-02,\n",
       "          4.45812978e-02,  4.92072012e-03, -5.81856444e-02,  3.03432327e-02,\n",
       "         -3.34497541e-02,  3.04047670e-03,  5.22673726e-02,  5.01148552e-02,\n",
       "         -4.23217714e-02,  5.81567287e-02, -5.38749294e-03, -5.79797477e-02,\n",
       "         -5.75126596e-02, -8.74883030e-03, -1.87206529e-02,  5.19733271e-03,\n",
       "         -6.39513228e-03,  3.72969434e-02, -1.74330994e-02, -1.68866850e-02,\n",
       "         -2.91114934e-02,  6.80438895e-03,  7.91523978e-03,  2.72202529e-02,\n",
       "          1.64692439e-02, -2.31953841e-02,  1.41514409e-02, -1.36808492e-02,\n",
       "          6.93282858e-03, -3.99737768e-02, -3.12509276e-02,  3.45505551e-02,\n",
       "         -4.02584299e-02, -1.82904527e-02, -3.36657465e-02, -1.79159995e-02,\n",
       "          2.53235549e-02,  7.68524176e-03, -3.82569991e-02, -3.73074859e-02,\n",
       "         -1.48160690e-02, -4.28197905e-02, -2.14923974e-02,  3.53928879e-02,\n",
       "         -5.67698153e-03, -2.90018264e-02, -5.86313382e-02, -1.41374033e-03,\n",
       "         -5.26324585e-02, -8.14977475e-03,  5.40985018e-02, -5.59666380e-03,\n",
       "         -2.68846564e-02,  3.75631452e-02,  5.23188151e-02,  3.86977866e-02,\n",
       "         -9.47711058e-03, -3.31713408e-02,  2.84456071e-02,  5.52066462e-03,\n",
       "          3.38140968e-03,  2.27036588e-02,  8.64789076e-03,  6.05340069e-03,\n",
       "         -8.85504531e-04,  4.83508185e-02, -3.79999988e-02, -4.30856720e-02,\n",
       "          3.58408391e-02, -2.76094582e-02,  3.17792483e-02, -7.49364961e-04,\n",
       "         -4.93262485e-02,  3.04428302e-02,  1.79859549e-02,  3.99700701e-02,\n",
       "         -2.99428571e-02,  4.30075601e-02,  2.89658122e-02,  5.56629114e-02,\n",
       "         -2.34487969e-02,  5.40574193e-02, -3.25324945e-02, -5.38013540e-02,\n",
       "          3.25365253e-02, -2.93347612e-02, -4.29762974e-02, -3.69863324e-02,\n",
       "          6.98970351e-03, -5.92768826e-02,  1.42678395e-02, -2.41191387e-02,\n",
       "         -4.62155715e-02,  5.25313132e-02,  3.34569812e-02, -5.35741188e-02,\n",
       "          3.58398780e-02, -3.59317660e-02,  1.16243511e-02, -3.91603559e-02,\n",
       "         -5.03633246e-02,  4.75009754e-02, -3.09483148e-02,  2.34405622e-02,\n",
       "          2.94682793e-02,  2.24394724e-02, -4.47684377e-02,  1.54484604e-02,\n",
       "          4.24653403e-02,  5.88491037e-02,  5.49091399e-02, -1.79572012e-02,\n",
       "         -5.58411479e-02,  3.72852311e-02, -7.70202233e-03, -2.18325071e-02,\n",
       "          4.24562469e-02, -3.99359912e-02, -9.27096047e-03,  2.40757838e-02,\n",
       "         -7.85200216e-04, -1.58059411e-02,  4.21448313e-02,  3.27517502e-02,\n",
       "          2.82179005e-02,  3.98283936e-02,  3.39477435e-02,  1.05570387e-02,\n",
       "          3.70613229e-03, -3.88214104e-02,  5.41428663e-03,  4.92189229e-02,\n",
       "          4.11204658e-02,  3.19283120e-02, -1.35388672e-02, -1.81690156e-02,\n",
       "         -1.70932442e-03,  1.30195245e-02, -3.48322354e-02,  1.02089886e-02,\n",
       "         -2.91752238e-02, -1.53735280e-02,  2.95889638e-02,  1.69125702e-02,\n",
       "          4.15866598e-02, -2.48469822e-02, -5.47631606e-02,  4.02275696e-02,\n",
       "         -3.95419598e-02,  8.28133989e-03, -1.82621703e-02, -5.79057485e-02,\n",
       "         -1.84010845e-02, -1.52850850e-02,  5.77654205e-02, -1.74329430e-02,\n",
       "          3.97184049e-05,  2.13564001e-02, -6.28112070e-03, -1.22202318e-02,\n",
       "         -1.26465037e-03, -3.10687758e-02, -3.26269753e-02, -3.81948659e-03,\n",
       "          2.20673904e-02,  4.18212414e-02,  2.34245416e-02,  2.37929989e-02,\n",
       "          2.75322571e-02, -5.01005724e-02, -7.17087649e-03, -4.01562303e-02,\n",
       "          5.30596040e-02, -1.96981467e-02,  1.28323184e-02, -4.71603274e-02,\n",
       "          5.98668680e-02, -1.78401861e-02,  2.91151293e-02,  2.42965855e-02,\n",
       "         -2.96614263e-02, -2.24474128e-02, -5.13798669e-02, -3.00071891e-02,\n",
       "          3.01590040e-02,  9.47446842e-03, -2.53911279e-02, -3.66183594e-02,\n",
       "          5.35232723e-02,  4.41801883e-02, -2.59896033e-02,  2.15804894e-02,\n",
       "          2.92114206e-02,  1.66992191e-02, -2.95608081e-02, -5.77166192e-02,\n",
       "         -1.22180674e-02,  3.42091499e-03,  1.50902215e-02, -2.94790287e-02,\n",
       "         -6.60847221e-03, -4.24375236e-02,  3.94756021e-03, -3.06841135e-02,\n",
       "          1.14295986e-02, -5.63801751e-02,  3.94554473e-02,  1.67055875e-02,\n",
       "         -1.40598333e-02, -5.68677858e-02,  5.05375862e-02,  8.31393059e-03,\n",
       "         -2.26421934e-02, -5.97512648e-02,  9.60429758e-03, -3.45185474e-02,\n",
       "         -1.60029288e-02, -5.00163436e-02, -3.20222601e-02,  3.87751497e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 19,\n",
       "  'topic_words': array(['networks', '네트워크', 'network', 'neural', 'neuronal', 'algorithms',\n",
       "         '알고리즘', 'neuron', 'neurons', 'net', 'algorithmic', 'algorithm',\n",
       "         'computational', 'neurobiology', 'neurobiological', 'neurosci',\n",
       "         'neurogenesis', 'computation', 'nodes', 'neuroethics', 'neuro',\n",
       "         'computationally', 'neurobiol', 'node', 'neurol', 'neurosurg',\n",
       "         'neuroimaging', 'computing', 'recursive', 'hierarchical',\n",
       "         'neurosciences', 'sklearn', 'tensorflow', 'computed', 'neuroimage',\n",
       "         'multiprocessing', 'neuroscience', 'genome', 'lineplot',\n",
       "         'clustering', 'neurological', 'predictor', 'neuroscientist',\n",
       "         'ggplot', 'grid', 'neuroscientists', 'classification',\n",
       "         'probabilistic', 'systematic', 'graphql'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.30814677e-02,  5.48432469e-02, -4.83743884e-02,  2.49545723e-02,\n",
       "         -3.88356000e-02, -4.48589921e-02,  1.47973578e-02, -1.92868635e-02,\n",
       "          4.59840707e-02,  4.38436270e-02,  1.05097070e-02,  2.68792659e-02,\n",
       "          2.44249105e-02,  3.20120901e-02, -5.80508970e-02,  3.44882980e-02,\n",
       "          9.10820439e-03, -3.73923853e-02,  2.41445266e-02,  4.86588180e-02,\n",
       "         -1.62675772e-02, -4.44890298e-02, -2.98799276e-02,  4.93990555e-02,\n",
       "         -4.40983735e-02, -3.40271667e-02,  4.45380881e-02,  2.29915734e-02,\n",
       "         -3.99499759e-02, -2.44447216e-02, -4.46712933e-02,  2.79760696e-02,\n",
       "         -5.77038852e-03, -5.32902554e-02, -4.28250879e-02, -7.65899848e-03,\n",
       "         -3.36822532e-02, -2.57995836e-02, -2.46975049e-02, -1.35647897e-02,\n",
       "          1.30510423e-02,  4.13158461e-02,  1.67667009e-02, -1.48282889e-02,\n",
       "         -3.21187340e-02,  9.48902965e-03,  4.30394299e-02, -1.55797042e-02,\n",
       "         -3.51764783e-02,  2.37124432e-02,  1.16321398e-02, -2.95019038e-02,\n",
       "         -4.15727636e-03,  4.05657031e-02,  2.04483178e-02, -5.13450503e-02,\n",
       "          1.54080847e-02, -1.33406669e-02,  1.09128114e-02,  2.95099057e-02,\n",
       "          1.39832916e-02,  4.29324955e-02,  7.49014318e-03, -3.48900259e-02,\n",
       "         -3.70613812e-03, -1.51935034e-02,  3.40568833e-02, -1.55452481e-02,\n",
       "          1.03254505e-02,  1.50266299e-02, -3.07642631e-02,  1.11726206e-02,\n",
       "         -2.19777580e-02, -3.13832462e-02, -1.58849042e-02, -1.15216747e-02,\n",
       "          4.28857245e-02, -3.60832922e-02,  4.01014574e-02, -5.86419180e-02,\n",
       "         -5.87844625e-02, -4.98874336e-02,  3.22901160e-02,  2.89578382e-02,\n",
       "          1.47062568e-02,  7.76716508e-03, -3.82919721e-02, -5.88764157e-03,\n",
       "          3.61930728e-02, -1.78921092e-02,  6.22584019e-04, -2.79574543e-02,\n",
       "         -4.47140895e-02, -5.61449379e-02,  2.10521072e-02,  5.29878512e-02,\n",
       "          2.41589192e-02,  3.03515233e-03,  1.50722703e-02, -1.59069896e-05,\n",
       "          5.17344885e-02,  5.73698990e-02,  3.56323156e-03, -4.16667312e-02,\n",
       "          2.68640239e-02, -3.55058163e-02, -5.22975326e-02, -2.37758160e-02,\n",
       "          5.09155616e-02,  2.51459740e-02,  1.06572881e-02, -5.13680540e-02,\n",
       "         -4.65522781e-02, -1.31271994e-02,  3.54135148e-02, -6.38009328e-03,\n",
       "         -3.68611068e-02,  3.91840748e-02, -5.44458590e-02,  2.07239371e-02,\n",
       "         -3.56755219e-02,  2.84688957e-02,  3.11610196e-02, -2.37525739e-02,\n",
       "          8.28969479e-03, -3.89624527e-03, -1.26408925e-03,  3.81994667e-03,\n",
       "         -2.35477742e-02,  3.63849550e-02, -5.34354709e-02,  4.13447469e-02,\n",
       "          5.11471219e-02,  4.64141406e-02,  6.40587881e-04,  5.50291017e-02,\n",
       "         -1.33839119e-02, -7.43734464e-03,  3.71740162e-02,  3.89069244e-02,\n",
       "          3.60669270e-02, -9.58691165e-03,  5.17269187e-02, -1.08364243e-02,\n",
       "          4.59858775e-02, -2.13276036e-02, -2.67145615e-02,  3.32554691e-02,\n",
       "          9.24521312e-03,  1.80878192e-02, -2.70859171e-02,  4.85074967e-02,\n",
       "         -3.93878073e-02, -4.77888845e-02,  3.19010802e-02, -1.41827296e-02,\n",
       "         -2.95402901e-03, -3.27723399e-02, -1.08497720e-02,  2.16538250e-03,\n",
       "          5.44072874e-02, -5.90016413e-03, -4.29619923e-02, -3.68409604e-02,\n",
       "         -3.60444784e-02, -1.15402797e-02,  1.25812534e-02, -6.99097384e-03,\n",
       "         -4.61831354e-02,  5.52257374e-02, -6.23497926e-03, -3.47055718e-02,\n",
       "          1.62880234e-02,  1.43068694e-02, -4.35271338e-02,  4.74284366e-02,\n",
       "         -2.15668101e-02,  1.53092779e-02, -4.41083424e-02,  2.79027931e-02,\n",
       "          2.28979699e-02, -3.31834368e-02, -4.26305877e-03, -2.82460023e-02,\n",
       "         -4.87941951e-02, -1.96558796e-02,  3.36699262e-02,  4.70507555e-02,\n",
       "         -3.24086174e-02, -2.74162460e-02, -7.73483887e-03,  1.13354893e-02,\n",
       "          3.56634334e-02,  3.86952050e-02,  1.23428944e-02,  1.93007719e-02,\n",
       "         -5.69035709e-02,  3.38999694e-03,  5.80479652e-02,  3.62785570e-02,\n",
       "         -9.71580669e-03,  3.23782116e-02, -1.53408758e-02, -6.39753928e-03,\n",
       "         -7.41097890e-03, -5.40582761e-02, -2.31345911e-02,  1.09056365e-02,\n",
       "         -4.91196290e-04,  2.74210479e-02,  1.19528137e-02,  8.58666562e-03,\n",
       "         -5.78280166e-02, -8.79900157e-03,  5.07110059e-02,  1.92312431e-03,\n",
       "         -1.03370976e-02, -3.91482636e-02, -3.21892388e-02, -3.68031412e-02,\n",
       "          5.74368052e-04,  1.72868185e-02, -1.71418488e-02,  5.21452632e-04,\n",
       "         -5.39745316e-02,  2.68396717e-02, -5.37069589e-02,  4.46096063e-03,\n",
       "         -1.14848958e-02,  3.16474400e-02, -1.48352729e-02,  4.92516235e-02,\n",
       "         -4.65026423e-02,  2.68572476e-02,  3.78766283e-02,  9.51372366e-03,\n",
       "         -2.39702989e-03,  3.31714638e-02,  4.33934554e-02, -5.10620959e-02,\n",
       "          2.14587227e-02,  4.76081967e-02, -3.79628092e-02,  8.58781114e-03,\n",
       "          6.49478426e-03, -4.57529388e-02,  3.41761820e-02, -5.12133539e-02,\n",
       "         -1.94400474e-02, -2.28405111e-02, -5.24634533e-02, -5.39437309e-02,\n",
       "          4.84129861e-02,  1.77947842e-02,  5.74491359e-03,  3.20196748e-02,\n",
       "          3.50397639e-02, -3.98223288e-04, -4.77230847e-02, -3.03359423e-03,\n",
       "         -3.56932916e-02,  2.23165005e-03, -4.14330065e-02, -3.85136269e-02,\n",
       "         -7.84203131e-03, -3.98211256e-02, -5.45051182e-03,  2.45119072e-02,\n",
       "          2.24633180e-02,  2.77631246e-02, -4.70748777e-03, -3.24036293e-02,\n",
       "         -3.98409106e-02, -3.95652875e-02, -2.95971986e-02,  2.32311636e-02,\n",
       "         -2.10374743e-02,  3.87394130e-02, -4.76689264e-02, -1.72611363e-02,\n",
       "         -4.61336076e-02, -3.02411206e-02,  2.58415118e-02,  4.82356101e-02,\n",
       "         -8.21364392e-03,  4.01341766e-02, -4.57972027e-02, -2.96912231e-02,\n",
       "         -3.19752702e-03,  9.68019478e-03,  5.20040467e-02,  1.61276497e-02,\n",
       "          1.20249307e-02, -7.74384988e-03, -5.35229258e-02,  2.06782855e-02,\n",
       "         -4.01452603e-03, -3.65852676e-02,  3.16997096e-02,  5.35194427e-02,\n",
       "         -2.48615481e-02,  2.88300682e-04, -1.74062280e-03, -5.52098490e-02,\n",
       "         -5.41249365e-02, -2.76698377e-02, -3.69573236e-02,  1.66998263e-02,\n",
       "         -1.27299139e-02,  1.71038546e-02, -4.03003357e-02,  4.44667116e-02,\n",
       "         -2.66323332e-02, -4.12696078e-02,  3.24546620e-02,  2.96148676e-02,\n",
       "         -3.71097564e-03, -4.41580415e-02,  2.99577080e-02, -4.10120562e-02,\n",
       "          2.53879502e-02, -2.15798076e-02, -3.65330838e-02, -1.21989725e-02,\n",
       "         -1.75073706e-02,  2.35047601e-02,  3.13876383e-03, -3.70017812e-02,\n",
       "         -3.05581465e-02,  1.55372657e-02, -4.29195426e-02, -2.40238700e-02,\n",
       "          2.08837911e-02, -2.14758106e-02, -2.16392037e-02, -1.08834105e-02,\n",
       "         -3.43574248e-02, -2.57455297e-02, -5.75735420e-02,  5.26112355e-02,\n",
       "         -5.31703234e-02, -4.72611375e-03, -4.13220711e-02,  1.03880186e-02,\n",
       "          1.54670030e-02,  5.20830825e-02,  3.26532610e-02,  4.34858464e-02,\n",
       "          8.51489510e-03,  1.91306379e-02,  2.29497645e-02,  2.91830953e-02,\n",
       "         -1.23545639e-02,  1.25023420e-03, -3.84492055e-02,  4.08495255e-02,\n",
       "          2.08910983e-02,  3.32690962e-02, -1.23837069e-02, -3.87536697e-02,\n",
       "          4.69117090e-02, -3.35280336e-02,  4.98788841e-02, -3.26266214e-02,\n",
       "         -5.01784459e-02, -1.75680686e-02,  2.55126916e-02,  3.98353226e-02,\n",
       "         -2.74847001e-02,  3.04035451e-02, -1.16777699e-02,  5.28727323e-02,\n",
       "         -4.79497574e-02,  3.37585546e-02,  2.69785989e-02, -4.74798940e-02,\n",
       "         -3.59648541e-02, -1.42389024e-02, -5.55191040e-02, -3.49004678e-02,\n",
       "         -2.27626152e-02, -1.40861431e-02,  5.18112481e-02,  2.46260501e-02,\n",
       "         -3.71371321e-02,  5.02363741e-02,  1.50896255e-02, -4.86062206e-02,\n",
       "          5.25924899e-02, -2.84356177e-02,  1.20690325e-02, -4.89934944e-02,\n",
       "         -3.06495558e-02,  4.30356339e-02, -1.69402305e-02,  1.83233581e-02,\n",
       "          1.59294363e-02, -1.74896233e-03, -5.83717860e-02,  2.97438055e-02,\n",
       "          5.56950271e-02,  2.82336138e-02,  5.67321144e-02, -1.89296007e-02,\n",
       "         -5.68014458e-02,  2.67729890e-02,  5.19263279e-03, -3.10095269e-02,\n",
       "          4.73618135e-02,  2.53649317e-02, -9.06720571e-03, -1.73761919e-02,\n",
       "          2.74944250e-02, -1.68734547e-02,  2.53261365e-02,  3.47811878e-02,\n",
       "          1.75763909e-02,  2.75763385e-02, -9.71066859e-03,  2.75835060e-02,\n",
       "          2.00741850e-02, -7.01825414e-03,  4.32166457e-02,  5.16916923e-02,\n",
       "          4.51557003e-02,  2.58736759e-02,  2.62847096e-02, -4.24515009e-02,\n",
       "         -3.60041559e-02, -8.80753435e-03, -4.74247597e-02, -4.28311601e-02,\n",
       "         -1.47429015e-02,  1.34599293e-02,  3.36660072e-02,  3.62757444e-02,\n",
       "          1.96067654e-02,  1.70894898e-02, -4.59627807e-02,  2.71718465e-02,\n",
       "         -3.34164537e-02, -7.62156351e-03, -5.96941449e-03, -4.94142324e-02,\n",
       "         -1.60392076e-02, -3.52603793e-02,  2.25137211e-02, -1.17438957e-02,\n",
       "          2.55522318e-02,  2.55137607e-02, -4.72587906e-02, -3.79544869e-02,\n",
       "         -2.05676816e-03, -4.38323952e-02, -4.06457931e-02, -4.13464829e-02,\n",
       "          4.13847603e-02,  4.04346809e-02,  2.43537966e-02,  4.33866978e-02,\n",
       "          4.99935374e-02, -5.07086888e-02, -2.77990550e-02, -5.03856540e-02,\n",
       "          5.78540750e-02, -5.40020727e-02,  1.96729647e-03, -1.39418999e-02,\n",
       "          5.65941036e-02, -4.65077274e-02,  1.51381586e-02,  5.44670373e-02,\n",
       "         -3.22767980e-02, -2.36655120e-04, -2.16971003e-02,  6.36639539e-03,\n",
       "          2.87225842e-02,  2.86926795e-03, -6.41670870e-03, -2.83599235e-02,\n",
       "          2.28898078e-02,  4.52526882e-02, -2.79220380e-02,  3.46767046e-02,\n",
       "          4.33710068e-02, -3.22042704e-02, -1.89176872e-02, -5.38694002e-02,\n",
       "         -5.06980270e-02,  4.23997231e-02,  4.45919782e-02,  3.21994647e-02,\n",
       "         -9.82756494e-04, -1.80250313e-02, -2.63693724e-02, -1.00777894e-02,\n",
       "          4.21621930e-03, -3.35072652e-02,  2.28140093e-02,  2.40240917e-02,\n",
       "          5.04279695e-02, -5.92232049e-02,  5.42769283e-02,  2.58878060e-03,\n",
       "         -4.38988656e-02, -5.61177097e-02, -5.34021892e-02, -2.72990670e-03,\n",
       "         -4.34354097e-02, -4.74282391e-02, -3.74116376e-03, -2.71146046e-03],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 20,\n",
       "  'topic_words': array(['python', '파이썬', 'cython', 'subprocess', 'matplotlib', 'stdout',\n",
       "         'multiprocessing', 'numpy', 'bashrc', 'github', 'scipy', 'pip',\n",
       "         'kwargs', 'tensorflow', 'path', 'directory', 'paths', 'filename',\n",
       "         '컴파일', 'anaconda', 'pipeline', 'preprocessing', '컴파일러',\n",
       "         'pipelines', 'commands', 'processes', 'mxpath', 'dependencies',\n",
       "         'lineplot', 'grep', 'urllib', 'foldername', 'sklearn', 'files',\n",
       "         'plugins', 'xpath', 'compile', 'linux', '명령어', 'args', 'nipype',\n",
       "         '변수', 'regex', 'gcc', '패키지', 'ggplot', '스크립트', 'compiler',\n",
       "         'command', '명령'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.08458018e-02, -3.11698578e-02, -2.11949814e-02,  9.90178902e-03,\n",
       "         -2.24181209e-02, -5.92371225e-02, -1.88447852e-02,  3.56214829e-02,\n",
       "          5.85311130e-02, -2.63356161e-03,  3.92627530e-02,  2.78408034e-03,\n",
       "          4.76583578e-02,  1.72204319e-02, -2.90245004e-02, -2.81664934e-02,\n",
       "          4.38391566e-02,  2.56790966e-02,  4.97816466e-02,  4.41605076e-02,\n",
       "          4.66524325e-02,  2.20692419e-02,  9.31939017e-03,  4.23078313e-02,\n",
       "         -5.69014326e-02, -3.69180515e-02,  8.05492792e-03, -1.16839651e-02,\n",
       "          3.25572640e-02, -5.65029047e-02, -2.21177209e-02,  4.01380062e-02,\n",
       "         -1.12934941e-02, -5.26150987e-02, -1.08480742e-02, -5.90334553e-03,\n",
       "         -2.07434893e-02, -1.29962964e-02,  1.72024257e-02, -3.80111448e-02,\n",
       "         -3.57850976e-02, -2.01011058e-02, -1.26325879e-02,  1.89520922e-02,\n",
       "          1.49631023e-03, -2.76256930e-02,  4.18243110e-02, -1.32600395e-02,\n",
       "         -3.02176233e-02,  3.67960590e-03, -3.72951888e-02, -4.28630225e-02,\n",
       "         -1.45448223e-02, -1.64885651e-02,  2.07203757e-02, -5.57923615e-02,\n",
       "          3.61297536e-03,  5.77150658e-02,  4.78844233e-02,  2.51667891e-02,\n",
       "         -2.02878863e-02,  3.41326073e-02, -4.45644045e-03, -4.36584875e-02,\n",
       "         -2.06035711e-02, -4.47157845e-02, -7.24334875e-03, -3.03186160e-02,\n",
       "          5.33582196e-02, -2.75577698e-02, -4.65459824e-02,  1.04815830e-04,\n",
       "         -1.50887622e-02, -3.52045037e-02, -4.69549559e-02, -4.57142256e-02,\n",
       "         -3.08199134e-02, -3.06721721e-02,  3.92274223e-02, -5.96923232e-02,\n",
       "         -5.91856502e-02,  2.40828935e-02,  7.13688508e-03, -2.57706810e-02,\n",
       "          2.29412708e-02, -2.10634358e-02,  8.25883355e-03, -3.44540402e-02,\n",
       "          1.12548070e-02,  2.09393594e-02,  2.65100575e-03, -5.01556434e-02,\n",
       "          1.44908857e-02,  1.18812472e-02,  3.32126953e-02,  2.03068275e-02,\n",
       "         -5.43945841e-02,  3.54880504e-02,  4.78047505e-02, -2.17408575e-02,\n",
       "          1.34198498e-02,  4.03707810e-02, -2.61649787e-02,  2.69751884e-02,\n",
       "          4.54835370e-02,  1.45650757e-02, -1.55384755e-02, -7.02771638e-03,\n",
       "         -1.72284860e-02,  3.40557806e-02,  3.03923581e-02, -4.93858233e-02,\n",
       "          5.57081448e-03, -5.01352511e-02,  3.28156427e-02,  1.59644242e-02,\n",
       "         -4.82762456e-02,  1.15577281e-02, -8.37426912e-03,  2.40738923e-03,\n",
       "         -4.41420153e-02,  8.80028121e-03, -1.42044099e-02,  4.72775437e-02,\n",
       "          5.07095121e-02,  1.76375564e-02, -7.53270462e-03,  1.96249820e-02,\n",
       "          2.67933514e-02, -5.05619869e-03, -2.63437387e-02,  2.61302721e-02,\n",
       "          5.46140075e-02,  5.29128835e-02, -5.54376617e-02, -3.59524670e-03,\n",
       "          2.28401534e-02, -1.82689615e-02,  4.41790856e-02,  4.14556563e-02,\n",
       "         -1.85397197e-03, -4.50620893e-03,  1.28034549e-02,  2.05219947e-02,\n",
       "          2.25055180e-02, -8.65924172e-03, -3.34832780e-02,  4.59121503e-02,\n",
       "          4.51635988e-03, -2.13939417e-02,  2.29136180e-02,  3.50917317e-02,\n",
       "         -2.41118502e-02, -1.76225062e-02, -4.62815464e-02, -3.43660638e-02,\n",
       "         -3.89098227e-02,  2.64165793e-02, -3.41688432e-02,  3.44003215e-02,\n",
       "          9.92334331e-04, -1.14733037e-02,  5.58988079e-02, -1.45506421e-02,\n",
       "          3.34913470e-02,  3.63299018e-03, -6.99809473e-03,  6.29344909e-03,\n",
       "          2.74903048e-02,  2.67762132e-02,  4.87421937e-02, -2.00749934e-02,\n",
       "          1.71476360e-02,  4.14366350e-02, -1.13834012e-02,  3.12086288e-02,\n",
       "         -5.69612384e-02,  1.63181070e-02, -5.59507720e-02,  5.11925034e-02,\n",
       "          5.75374439e-03,  3.17772217e-02, -4.57213586e-03,  7.74067407e-03,\n",
       "         -3.42112482e-02,  2.07326524e-02, -6.32644165e-03,  4.91937697e-02,\n",
       "          2.66525447e-02,  2.81014107e-02,  1.01161953e-02, -2.25533079e-02,\n",
       "          5.48423529e-02, -1.45599591e-02, -4.47114371e-02, -6.02114806e-03,\n",
       "          1.18790101e-02, -3.26758213e-02,  2.30838619e-02, -1.71277858e-02,\n",
       "          1.12913931e-02,  9.36517678e-03, -2.59649213e-02,  9.28866025e-03,\n",
       "         -3.14080343e-02,  3.89538705e-04,  3.99205349e-02, -4.22218181e-02,\n",
       "          5.39759127e-03, -4.28031012e-03, -2.36721728e-02,  4.60923202e-02,\n",
       "          5.05003072e-02, -3.80055532e-02,  2.94557270e-02, -2.11053509e-02,\n",
       "         -1.63215362e-02, -1.60734542e-02, -2.78733461e-03, -2.31025219e-02,\n",
       "         -1.58419237e-02,  1.62203163e-02,  2.41852719e-02, -7.60447653e-03,\n",
       "         -5.52719049e-02, -4.26056758e-02, -6.04080455e-03,  4.26540785e-02,\n",
       "         -2.45126579e-02,  2.58746855e-02,  2.12404388e-03,  5.59862815e-02,\n",
       "          3.74711193e-02, -3.29208039e-02,  1.57297088e-03,  3.17350193e-03,\n",
       "          1.18118506e-02, -1.47690335e-02,  3.06071751e-02, -1.64717939e-02,\n",
       "          1.39002511e-02,  1.07403891e-02,  9.56090260e-03,  1.92010347e-02,\n",
       "         -1.23785799e-02, -5.93213961e-02, -1.22816330e-02,  3.74257751e-02,\n",
       "          1.95811335e-02, -8.70707911e-03, -5.29676601e-02, -2.69750543e-02,\n",
       "         -2.47591455e-02,  3.29728015e-02,  5.70936762e-02, -2.32101027e-02,\n",
       "          1.33366901e-02, -4.20497917e-02,  5.30222710e-03, -1.57709401e-02,\n",
       "          3.12757306e-02,  5.28640077e-02, -4.19284664e-02, -4.47949842e-02,\n",
       "          2.68947389e-02, -4.72609326e-02, -3.47373709e-02, -2.51610279e-02,\n",
       "          3.37128043e-02,  3.80563103e-02,  3.70657560e-03, -4.48224954e-02,\n",
       "          9.29206796e-03,  3.78024578e-02,  2.38632392e-02,  1.25360880e-02,\n",
       "         -1.47030298e-02, -3.74175608e-02, -2.52599828e-02,  6.81040157e-03,\n",
       "          3.69711183e-02,  9.91453789e-03,  2.71130935e-03, -2.12431382e-02,\n",
       "         -6.81989593e-03,  7.76449544e-03, -5.15699498e-02,  9.55389906e-03,\n",
       "          3.31050977e-02,  1.86029635e-02,  2.52187848e-02,  2.65467279e-02,\n",
       "         -8.03687237e-03,  4.65497077e-02, -5.96677177e-02,  2.26367265e-02,\n",
       "         -4.87515628e-02,  4.72906344e-02, -1.58053599e-02,  5.49448244e-02,\n",
       "          9.60973185e-03, -2.57587023e-02, -4.12644073e-02, -2.63521932e-02,\n",
       "          4.43371907e-02, -2.80277599e-02, -2.00058557e-02, -3.62719968e-02,\n",
       "         -2.76185609e-02, -1.36372298e-02,  2.82393824e-02,  2.38314215e-02,\n",
       "         -4.21088713e-04,  2.61075739e-02, -3.53850313e-02,  3.26221511e-02,\n",
       "          3.26840542e-02, -1.43938977e-02,  2.41605155e-02, -3.34106907e-02,\n",
       "         -4.61198203e-02, -1.40564237e-02, -9.01872851e-03, -1.09903142e-03,\n",
       "         -1.74522586e-02,  1.49338096e-02, -5.23012951e-02, -3.53798009e-02,\n",
       "          3.42714489e-02, -2.49014776e-02, -4.43198942e-02, -4.75528166e-02,\n",
       "         -5.72107658e-02, -1.59443319e-02, -2.28034686e-02,  3.27426605e-02,\n",
       "          4.08146642e-02, -1.91405546e-02, -5.51315024e-02, -2.93741208e-02,\n",
       "         -2.85278820e-02,  4.65149321e-02, -3.23185697e-02, -4.61322665e-02,\n",
       "         -2.31171679e-02, -2.50612888e-02, -1.45431841e-02,  3.64006534e-02,\n",
       "          1.05712367e-02,  3.18610994e-03, -2.03266484e-03, -2.89421082e-02,\n",
       "          2.40206160e-02, -5.45226596e-02,  2.63177305e-02,  2.40015965e-02,\n",
       "          3.95880081e-02,  1.80094577e-02,  3.29113342e-02, -4.49526086e-02,\n",
       "         -1.19544370e-02,  1.21911485e-02,  2.25443747e-02, -8.03447235e-03,\n",
       "          5.73503599e-03, -1.40076401e-02,  3.82178761e-02,  1.79773141e-02,\n",
       "         -2.17550360e-02, -2.09001242e-03, -3.25164832e-02, -3.22539883e-04,\n",
       "         -2.78971661e-02,  1.62860304e-02,  3.79006006e-02, -4.95669730e-02,\n",
       "         -2.95065325e-02,  1.38896797e-02,  5.52456011e-04, -4.71532419e-02,\n",
       "         -4.53268513e-02, -4.90474887e-02, -1.52045805e-02, -5.48688769e-02,\n",
       "         -1.61301587e-02,  1.46902008e-02,  4.98615466e-02, -5.68498559e-02,\n",
       "         -8.33536405e-03,  4.33579870e-02, -2.44040787e-02, -1.55633001e-03,\n",
       "         -2.99320780e-02, -2.63429247e-02, -1.53874028e-02, -4.16227579e-02,\n",
       "          3.30169313e-02,  3.64071503e-02, -2.24115755e-02,  2.98369098e-02,\n",
       "          1.50062712e-02, -3.84745561e-02,  5.77138327e-02, -1.68869644e-02,\n",
       "          4.04524207e-02, -1.03814423e-03,  2.36887634e-02, -5.51605783e-02,\n",
       "          3.29105295e-02, -3.21857259e-02, -3.07802344e-04,  5.06609958e-03,\n",
       "          2.59273052e-02, -3.83616909e-02,  3.68225351e-02, -3.32944281e-02,\n",
       "          3.84154953e-02,  2.92599648e-02, -2.27132011e-02,  3.63552086e-02,\n",
       "          4.03266922e-02,  1.67081766e-02,  4.62484956e-02,  3.81187424e-02,\n",
       "         -4.36821282e-02,  9.71168000e-03,  3.11134923e-02, -9.06306691e-03,\n",
       "          8.51102266e-03,  2.98396386e-02,  2.44260821e-02,  1.16346506e-02,\n",
       "          2.81388201e-02, -1.25560481e-02,  2.72505544e-02,  4.09282139e-03,\n",
       "          7.90711120e-03, -1.64256953e-02, -4.55132052e-02, -2.19719764e-02,\n",
       "         -4.26427238e-02,  3.52728888e-02,  4.02536755e-03, -4.89438958e-02,\n",
       "         -2.25460362e-02, -5.21577187e-02,  5.45516945e-02, -7.48328399e-04,\n",
       "          2.76354868e-02, -2.94673424e-02,  4.01180983e-02,  2.90558655e-02,\n",
       "         -4.82892171e-02, -2.74333265e-02,  4.10312079e-02, -2.26726998e-02,\n",
       "          5.13431691e-02, -1.29264584e-02, -2.58095805e-02,  5.14280498e-02,\n",
       "         -1.47115281e-02, -1.62103549e-02, -1.70753933e-02, -4.42295000e-02,\n",
       "          6.27054786e-03, -4.65042777e-02, -1.41193648e-03, -1.72700845e-02,\n",
       "          5.03005311e-02, -5.11380546e-02,  5.31427078e-02, -1.11204451e-02,\n",
       "          1.43361967e-02, -3.18050794e-02, -4.89392057e-02, -4.47927602e-02,\n",
       "         -3.03205159e-02,  3.23348423e-03,  3.54658552e-02,  2.59300601e-02,\n",
       "          7.01474166e-03, -2.02800296e-02,  1.06513025e-02, -1.36564886e-02,\n",
       "         -3.32450196e-02,  5.44878915e-02, -8.03199690e-03, -4.36113738e-02,\n",
       "          4.18606069e-04, -3.67805660e-02, -3.11760064e-02,  1.99065562e-02,\n",
       "         -3.97577323e-02,  1.86368488e-02,  4.75077368e-02, -3.83728230e-03,\n",
       "         -4.89025377e-02, -5.36450967e-02,  5.52161075e-02,  4.28819843e-02,\n",
       "         -4.84299622e-02,  4.79348898e-02,  3.26631926e-02, -2.81417221e-02,\n",
       "         -2.21949425e-02, -5.99179864e-02,  2.21189912e-02, -1.54373374e-05,\n",
       "         -2.74869502e-02, -1.91047452e-02,  8.74932331e-04,  5.73606836e-03],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 21,\n",
       "  'topic_words': array(['dataset', 'dataframe', 'xticklabels', 'datasets', 'matplotlib',\n",
       "         'covariance', 'numpy', 'graphql', 'mxmatrix', 'scatterplot',\n",
       "         'matlab', 'regex', 'groups', 'groupby', 'group', 'ggplot',\n",
       "         'grouping', 'grouped', 'mxalgebra', 'sklearn', 'populations',\n",
       "         'clustering', 'regression', '그룹', 'lineplot', 'tensorflow',\n",
       "         'variance', 'cluster', 'varlambda', 'associative', 'data',\n",
       "         'bmatrix', 'clusters', 'cbind', 'statistics', 'variables',\n",
       "         'variances', 'statistic', 'multivariate', 'terminology',\n",
       "         'information', 'query', 'genome', 'statistical', 'mxpath',\n",
       "         'operatorname', 'correlations', 'toolkit', 'dictionary',\n",
       "         'vertexcount'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.05278918, -0.04578067,  0.00717752, -0.0002225 , -0.03542446,\n",
       "         -0.05177481, -0.00687403, -0.01107826,  0.05260559, -0.02577019,\n",
       "         -0.01503336,  0.02155487,  0.05145107, -0.04275711, -0.0488429 ,\n",
       "         -0.01484045, -0.00337938, -0.00996176,  0.02288456,  0.05128549,\n",
       "          0.02259381, -0.02465022, -0.01724368,  0.05101829, -0.05245398,\n",
       "         -0.05193287,  0.0481248 , -0.04751742,  0.05219521, -0.0504264 ,\n",
       "         -0.05159834,  0.03312026, -0.04296022, -0.05072231, -0.00171655,\n",
       "         -0.04661524, -0.01456449, -0.00792009, -0.04398877,  0.045305  ,\n",
       "         -0.02904285, -0.03706111,  0.02255095, -0.05260586, -0.04141843,\n",
       "         -0.05042543,  0.05168058, -0.02644123, -0.03232393,  0.00779518,\n",
       "         -0.01877608,  0.00149782, -0.00265297, -0.04625591,  0.02848199,\n",
       "         -0.05249423,  0.0121003 ,  0.04318392,  0.01551802,  0.0527298 ,\n",
       "          0.01095162,  0.05277049,  0.04254624,  0.02110707,  0.00681259,\n",
       "          0.00695078, -0.03479616,  0.04506451,  0.05186308,  0.01461363,\n",
       "          0.01303188, -0.02848638,  0.01297999, -0.04587908, -0.01498062,\n",
       "         -0.05136365,  0.03882473,  0.043811  , -0.01326592, -0.05279738,\n",
       "         -0.05280035, -0.02476527,  0.01120395, -0.03236273,  0.009843  ,\n",
       "          0.02045768, -0.01795994, -0.02170803,  0.01422749, -0.04261771,\n",
       "          0.01969489, -0.01268647, -0.03745851, -0.04537968,  0.02554978,\n",
       "          0.05221263, -0.00807223,  0.01485377,  0.04166929,  0.01491493,\n",
       "          0.05226487, -0.02391832,  0.04910564,  0.00569915,  0.04507478,\n",
       "          0.03772797, -0.01807737, -0.04972372,  0.03827911,  0.00591091,\n",
       "          0.01096316, -0.01938385, -0.00211504, -0.03785875,  0.04537189,\n",
       "         -0.03130518,  0.00306772, -0.03972703, -0.01002377,  0.01293758,\n",
       "          0.0222469 ,  0.00219595,  0.02037457,  0.0376409 ,  0.04976153,\n",
       "         -0.00690714, -0.00548853,  0.01654342, -0.02740554,  0.00429657,\n",
       "         -0.04959339,  0.03347963,  0.05279844, -0.0139161 , -0.00049308,\n",
       "          0.04083088,  0.01027923, -0.0166114 ,  0.05073336,  0.03169471,\n",
       "         -0.02704732, -0.01548767, -0.0224311 , -0.04753315,  0.05257316,\n",
       "          0.01056027, -0.02674055,  0.01843478,  0.04863518, -0.04113402,\n",
       "          0.05256585,  0.04312112,  0.021871  , -0.03396062,  0.02429314,\n",
       "         -0.03649917,  0.02409521,  0.01021746,  0.0237366 , -0.0197399 ,\n",
       "          0.05252677,  0.00354547,  0.05219406,  0.00364512,  0.00590683,\n",
       "         -0.03339176, -0.01551703, -0.0429876 , -0.00722514,  0.0372916 ,\n",
       "          0.00296584, -0.0390572 ,  0.01536499,  0.02402126,  0.02366712,\n",
       "          0.04890757, -0.03352169,  0.01677238, -0.05271444,  0.03797173,\n",
       "         -0.00635797, -0.02848876, -0.03000445,  0.0176646 , -0.04008801,\n",
       "         -0.03152414,  0.05270561,  0.05258718,  0.03686539, -0.05257204,\n",
       "         -0.02187483, -0.03587538,  0.04989392,  0.02265582, -0.02059622,\n",
       "          0.03816142, -0.05279997, -0.0159511 ,  0.0521198 ,  0.02873459,\n",
       "          0.03676077,  0.0166714 , -0.04453316,  0.0186385 , -0.01956288,\n",
       "         -0.04247841,  0.04047888,  0.02706037, -0.03504507,  0.02121072,\n",
       "         -0.04909518,  0.02906585, -0.05279542,  0.02208155,  0.03240969,\n",
       "         -0.04115751, -0.01681729, -0.05129948,  0.03858225, -0.02027788,\n",
       "         -0.00661874, -0.01845243,  0.01913168, -0.00995306, -0.0527998 ,\n",
       "          0.00521555, -0.01891865, -0.01844589,  0.02918113, -0.02341573,\n",
       "         -0.00554794,  0.05279704,  0.02062638,  0.00660024,  0.02182205,\n",
       "          0.0315204 , -0.04370109,  0.00155506, -0.04876146, -0.03615254,\n",
       "          0.00448719,  0.03229371, -0.0085299 ,  0.0171724 , -0.02159898,\n",
       "         -0.04300657,  0.00600412, -0.02435208,  0.03774292, -0.05246119,\n",
       "         -0.00959483, -0.04430449, -0.0096064 ,  0.01566122,  0.00864211,\n",
       "          0.0101789 ,  0.00302114, -0.04457199, -0.04928058,  0.00588324,\n",
       "         -0.01194546, -0.00350915, -0.04092685, -0.05111286,  0.03279978,\n",
       "         -0.04614383, -0.04467274, -0.00484959,  0.01128075,  0.03994111,\n",
       "         -0.01413436, -0.04733499, -0.05003998, -0.04126847,  0.02642566,\n",
       "         -0.00014563, -0.03323131,  0.03885945, -0.05179315,  0.01929529,\n",
       "         -0.04335238, -0.01679809,  0.05019855, -0.03344193, -0.04296245,\n",
       "          0.04729853, -0.05196041, -0.05167008, -0.00690396,  0.05047221,\n",
       "          0.03477109,  0.0525697 ,  0.04089306,  0.04347468, -0.05261639,\n",
       "          0.00928309, -0.02923609,  0.01566814,  0.00317801,  0.01493845,\n",
       "         -0.0313579 ,  0.02195032, -0.04893419, -0.05229595, -0.05273689,\n",
       "         -0.02173571, -0.01874768, -0.01178816,  0.0079121 ,  0.05207146,\n",
       "          0.01462051, -0.03065714, -0.03858578,  0.02472332,  0.03678489,\n",
       "         -0.01453671, -0.00945301, -0.01054851, -0.00292831,  0.01663988,\n",
       "         -0.03050219,  0.00849551,  0.01228835,  0.00425914, -0.04959231,\n",
       "         -0.01899073, -0.004547  , -0.03931392,  0.00026061, -0.00551035,\n",
       "         -0.05223467, -0.0382443 , -0.02821465, -0.03832505, -0.00052917,\n",
       "          0.04699025, -0.04430214, -0.01160562, -0.04660374, -0.02821879,\n",
       "         -0.04402194, -0.05218589,  0.03719975,  0.01316211, -0.0296091 ,\n",
       "          0.04443687,  0.03849723, -0.01251923, -0.03220491, -0.03692432,\n",
       "          0.01064739,  0.03406829,  0.00122432,  0.01818999,  0.02060526,\n",
       "          0.01609759,  0.01341637,  0.01910018, -0.02259301, -0.05188349,\n",
       "         -0.00023188, -0.05076357,  0.03545158,  0.03086664, -0.02826645,\n",
       "          0.01250773,  0.05178476,  0.04268753, -0.0508626 ,  0.05244761,\n",
       "         -0.01010993,  0.00455229, -0.0335337 ,  0.04436843, -0.02343695,\n",
       "         -0.04216737, -0.01968744, -0.02423325, -0.05262467, -0.04832418,\n",
       "          0.02180587, -0.05269857,  0.01385808, -0.03830562, -0.04270145,\n",
       "          0.05008301,  0.02298501, -0.05279666,  0.05165268, -0.01616718,\n",
       "          0.00142962, -0.00849864, -0.0444035 ,  0.02976779, -0.0268736 ,\n",
       "          0.01908519,  0.01440552, -0.0383775 , -0.04289385,  0.01971154,\n",
       "          0.05159457,  0.03183774,  0.03956527, -0.01387614, -0.05126303,\n",
       "          0.01439609,  0.04663054, -0.02538847,  0.04671901,  0.0268393 ,\n",
       "         -0.01908208,  0.02423741,  0.02279631,  0.01486663,  0.04793946,\n",
       "          0.01074291,  0.03681469,  0.05073767,  0.03671351,  0.03656304,\n",
       "         -0.00046626,  0.02827759,  0.03788314,  0.05128312,  0.02701707,\n",
       "          0.02451123,  0.04367878, -0.00539072,  0.02595815, -0.03871148,\n",
       "          0.00576267, -0.00914632,  0.03550836, -0.01854095, -0.00187007,\n",
       "          0.02981152,  0.01649148, -0.00612304, -0.05268095, -0.00170125,\n",
       "         -0.04128808, -0.02727527, -0.0409059 , -0.05053409, -0.02838372,\n",
       "         -0.00999528,  0.05086929,  0.00190584,  0.01284147,  0.04086491,\n",
       "          0.01645654,  0.02179384, -0.04593394, -0.00228848, -0.01201902,\n",
       "         -0.02009564,  0.01779658,  0.00544959,  0.03209889,  0.05241107,\n",
       "         -0.02956426, -0.04469297, -0.02878486, -0.03603774,  0.00543125,\n",
       "         -0.03348981, -0.04142514, -0.05152121,  0.05236147, -0.0223876 ,\n",
       "          0.04979865, -0.04852298, -0.0003593 ,  0.02590388, -0.05179815,\n",
       "         -0.03760519,  0.02425721, -0.03217964,  0.00947851,  0.01590528,\n",
       "          0.03641982,  0.05279936, -0.02006785,  0.04347141,  0.03832814,\n",
       "          0.00154096, -0.01911603, -0.0527014 ,  0.01380115, -0.00716972,\n",
       "          0.03117482,  0.00189537, -0.04474315, -0.02464047, -0.00332198,\n",
       "         -0.04272224,  0.00699587, -0.04915196,  0.00465247,  0.01633612,\n",
       "         -0.03659897, -0.05183762,  0.05279685,  0.03205802, -0.04889498,\n",
       "         -0.05236756,  0.02101156, -0.00917917,  0.03558581, -0.03114888,\n",
       "         -0.03672883,  0.01876249], dtype=float32)},\n",
       " {'topic_idx': 22,\n",
       "  'topic_words': array(['neuroimaging', 'neuro', 'serotonin', 'neuroscientific', 'neurol',\n",
       "         'neuroimage', 'neuroethics', 'neuronal', 'neurological',\n",
       "         'correlation', 'stimuli', 'neurosciences', 'correlations',\n",
       "         'neurosci', 'neurogenesis', 'correlated', 'dopamine', 'correlates',\n",
       "         'hyperactivity', 'neuroscience', 'correlate', 'neurology',\n",
       "         'neural', '신경망', 'neurons', 'neuron', 'stimulus', 'somatosensory',\n",
       "         'neurofeminism', 'hyperactive', 'neurosurg', 'impulsivity',\n",
       "         'neuroscientists', 'syndromes', 'interaction', 'psychosis',\n",
       "         'synapses', 'sensory', 'interacting', 'neurobiological',\n",
       "         'cognitive', 'anxiety', 'neuroscientist', 'depression', 'ketamine',\n",
       "         'schizophrenia', 'syndrome', 'interactions', 'neurobiol',\n",
       "         'dissociation'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.05037579,  0.02751312, -0.03626173,  0.00029886, -0.02010414,\n",
       "          0.05073452, -0.04843111, -0.01681539, -0.00956485,  0.01748024,\n",
       "          0.00313227, -0.05036993,  0.02249875, -0.01826634, -0.05070062,\n",
       "          0.04925463, -0.0083502 ,  0.01312062,  0.03401264,  0.03762232,\n",
       "         -0.03012491, -0.04653389, -0.01372236,  0.05062717, -0.05075143,\n",
       "         -0.01240714, -0.03324818,  0.028203  ,  0.02680902,  0.02762501,\n",
       "         -0.04684914,  0.04432354, -0.02726536, -0.0507125 ,  0.05016661,\n",
       "         -0.04672453, -0.04705276,  0.02067741,  0.01187816, -0.05066826,\n",
       "         -0.03514099,  0.02595352,  0.04936657,  0.01766304, -0.04768385,\n",
       "         -0.02311795,  0.05027797,  0.01166431,  0.04988545, -0.01223941,\n",
       "          0.05055453,  0.00315861,  0.04682665, -0.02405358,  0.04052989,\n",
       "         -0.02881625,  0.01788208, -0.01661006,  0.02847608,  0.02651514,\n",
       "         -0.01343079,  0.04952061, -0.0501017 , -0.04515805, -0.04797236,\n",
       "          0.02206086,  0.00974143, -0.02276141, -0.04393538, -0.00831471,\n",
       "         -0.00356919,  0.02074777,  0.02378047, -0.05020134, -0.0378231 ,\n",
       "          0.01224544,  0.03744595,  0.03746465, -0.0285863 , -0.0506494 ,\n",
       "         -0.05075463, -0.01233379,  0.04915673,  0.04639346, -0.02561016,\n",
       "          0.01342407, -0.04721466, -0.04532531, -0.02851495, -0.05027151,\n",
       "         -0.04828491, -0.05041935, -0.02548997, -0.04962531,  0.04839603,\n",
       "          0.05005513,  0.05018438,  0.05061468,  0.04986034,  0.04719673,\n",
       "          0.02220706, -0.01944062, -0.02392725,  0.00619742,  0.02307128,\n",
       "          0.05075769, -0.05031299, -0.03136704, -0.03810744,  0.0506027 ,\n",
       "          0.05052283, -0.05071951, -0.03768805,  0.02333693,  0.04971679,\n",
       "          0.03295964,  0.05069725,  0.05031553, -0.01599974, -0.01557884,\n",
       "         -0.03250074,  0.04177898,  0.04815374,  0.04429464, -0.0328482 ,\n",
       "          0.04848322,  0.05075749,  0.02413343, -0.01826737,  0.0506631 ,\n",
       "         -0.03692119, -0.03461899,  0.0506832 ,  0.04964625, -0.03902481,\n",
       "          0.05075445, -0.03411415, -0.01604481,  0.05065688,  0.04575405,\n",
       "          0.04906178, -0.02588628,  0.04889117, -0.00313503,  0.05064181,\n",
       "          0.04273888, -0.02290999,  0.05061989,  0.04455936,  0.04941552,\n",
       "          0.04956428,  0.0329671 , -0.01741454, -0.02224818, -0.03792292,\n",
       "         -0.02429332,  0.04737303, -0.04077981,  0.0336861 , -0.03098273,\n",
       "          0.04705651, -0.04952461, -0.03446053, -0.01961632,  0.02915593,\n",
       "         -0.04426267,  0.00507392,  0.00173111, -0.04885658,  0.02297922,\n",
       "         -0.04926975, -0.05058339,  0.02190864,  0.02284073, -0.04928843,\n",
       "          0.00248081,  0.04854015,  0.03790491, -0.00081671,  0.01156627,\n",
       "         -0.00597583, -0.05067643, -0.00389438, -0.05043392,  0.03714369,\n",
       "         -0.01827961,  0.05060614,  0.04962753,  0.04708872, -0.00058289,\n",
       "         -0.04013004, -0.04181019, -0.00768411, -0.01975836, -0.0501719 ,\n",
       "         -0.03554324, -0.02085701,  0.04329229,  0.05002651, -0.0174757 ,\n",
       "         -0.02865823,  0.04829341,  0.04042501, -0.05003765,  0.0274101 ,\n",
       "         -0.05073633, -0.04955926,  0.04282079,  0.04830125,  0.02738108,\n",
       "          0.01091555, -0.04950462,  0.04201777,  0.01519892,  0.04805937,\n",
       "          0.03652678,  0.02697014, -0.03116076,  0.01412098,  0.00349305,\n",
       "         -0.01027577,  0.04864801,  0.05073651,  0.04615391, -0.04754756,\n",
       "         -0.01950126, -0.05074787,  0.03368302, -0.04196653, -0.04038982,\n",
       "          0.02944943,  0.05047504, -0.04864743,  0.02184392, -0.01128472,\n",
       "         -0.03239953,  0.01405952,  0.04486715,  0.04654826,  0.03614655,\n",
       "         -0.0079877 ,  0.01748098, -0.02699658,  0.02527635,  0.04965109,\n",
       "          0.01943534,  0.04889543, -0.04978572, -0.02170127,  0.03673437,\n",
       "          0.02152827, -0.04995831, -0.01810373, -0.02727831,  0.0166153 ,\n",
       "         -0.03790939,  0.05046915,  0.0100513 , -0.04028304,  0.02863798,\n",
       "          0.01911023,  0.04877857, -0.04071443,  0.03448217,  0.0216323 ,\n",
       "         -0.05069939, -0.03582961,  0.04959578,  0.00460168,  0.03468545,\n",
       "          0.04949781, -0.01457685, -0.0491336 , -0.03168426,  0.00621426,\n",
       "          0.0004927 , -0.05015564,  0.0231377 , -0.05061627, -0.03592735,\n",
       "         -0.02884242, -0.00421285,  0.03170384,  0.04988016, -0.02816405,\n",
       "          0.04778604, -0.05046405, -0.0500651 , -0.0211671 , -0.03232455,\n",
       "          0.04655476,  0.02927938,  0.04607547, -0.03692158, -0.04921916,\n",
       "         -0.05042873,  0.00398991,  0.04295077,  0.05035001,  0.02405169,\n",
       "         -0.04899989,  0.00459127, -0.01502758, -0.02214427, -0.03565681,\n",
       "         -0.03588776, -0.02101644,  0.02877916, -0.00256963,  0.02973482,\n",
       "         -0.05039183, -0.04641835,  0.04857212, -0.05067392,  0.05042449,\n",
       "          0.05043922,  0.02271061, -0.04755357,  0.0136287 , -0.05068891,\n",
       "          0.00091499, -0.05075769,  0.02916399,  0.0501807 ,  0.01160386,\n",
       "         -0.04786031, -0.02039801, -0.02372062, -0.00979179,  0.02738867,\n",
       "         -0.0500377 , -0.05058309, -0.0503412 ,  0.0321764 ,  0.01438925,\n",
       "         -0.01082285, -0.05021833, -0.02708922, -0.03413236,  0.05042608,\n",
       "         -0.03557936, -0.0130868 ,  0.02987068, -0.04539556,  0.02292047,\n",
       "          0.05044535,  0.04988274, -0.04988262, -0.0482419 ,  0.03303306,\n",
       "          0.04916934,  0.01803184, -0.04370536,  0.04543841,  0.05043912,\n",
       "          0.04375588,  0.03070514,  0.03179516, -0.05075533, -0.03360456,\n",
       "          0.04396691,  0.01392289,  0.04922427,  0.01209909, -0.04965453,\n",
       "          0.03456939, -0.02603918, -0.03630538, -0.03552422,  0.03387807,\n",
       "          0.0185992 ,  0.04993253,  0.02068474,  0.00528462,  0.00921337,\n",
       "         -0.04966149,  0.00372584,  0.04017162,  0.02038092, -0.01661025,\n",
       "          0.04971363, -0.01389651,  0.02791043,  0.03201074, -0.01928089,\n",
       "          0.05073816,  0.05044546, -0.04315711,  0.05066628, -0.03223638,\n",
       "          0.00691418,  0.01846546,  0.04444118,  0.05059548, -0.05057264,\n",
       "         -0.012073  ,  0.05069242, -0.04926914, -0.00750412,  0.04586911,\n",
       "          0.02653497,  0.05075142,  0.04515973,  0.04068672, -0.03552745,\n",
       "          0.00321407,  0.00291058, -0.04461873,  0.00217885,  0.01853656,\n",
       "          0.0341402 ,  0.03130837,  0.00640696,  0.05075769, -0.03478573,\n",
       "          0.05073955,  0.00192812, -0.05010371,  0.05041478,  0.04734178,\n",
       "         -0.0492184 , -0.02477599,  0.04625472,  0.01062319,  0.05074695,\n",
       "          0.00265745, -0.04444484, -0.04009671, -0.0459833 ,  0.01567457,\n",
       "         -0.05068474, -0.00867717, -0.00695806, -0.0363643 ,  0.04924702,\n",
       "          0.00772056, -0.04770406, -0.04988478, -0.05075733,  0.04021313,\n",
       "          0.01817635, -0.0283515 ,  0.02900389, -0.05003281,  0.03397373,\n",
       "         -0.04866422, -0.00322609,  0.04937099, -0.02639684,  0.01156315,\n",
       "         -0.04292148, -0.02795357, -0.0356637 ,  0.01045426, -0.04841788,\n",
       "         -0.0250814 ,  0.03312303,  0.04892859, -0.04293336, -0.00047183,\n",
       "         -0.01709859, -0.05002154, -0.01772269, -0.04013295,  0.04970714,\n",
       "         -0.05050281, -0.03959299, -0.03327076,  0.05074323, -0.00742657,\n",
       "          0.03437673,  0.05042422, -0.04915373,  0.00464076,  0.00558001,\n",
       "         -0.02497882, -0.04784749, -0.03051136, -0.02824604, -0.02506222,\n",
       "          0.04804194,  0.05075769, -0.02378538, -0.00734009,  0.04203874,\n",
       "         -0.05030847, -0.02983347, -0.05072284, -0.04448975, -0.03281045,\n",
       "          0.0456269 ,  0.01586879, -0.04206538,  0.03982732, -0.04273367,\n",
       "         -0.01601319, -0.04922798,  0.01162577,  0.0031175 ,  0.0502146 ,\n",
       "          0.03859459, -0.04928138,  0.0507461 , -0.04419439, -0.05036991,\n",
       "         -0.05073794,  0.03542045, -0.03196222, -0.04172929, -0.05021682,\n",
       "         -0.03447675,  0.02373009], dtype=float32)},\n",
       " {'topic_idx': 23,\n",
       "  'topic_words': array(['서울시', '서울', '서울대', 'seoul', 'korean', '평양', 'korea', '한국', '한국어',\n",
       "         '한글', '인구', '면역', '스턴스', 'population', 'mahjong', '마태오', 'city',\n",
       "         '공공', '시민', 'public', '도시', 'immune', '나누', '대중', 'ny', '회복', '조선',\n",
       "         'vienna', '면옥', '대구', '대기', 'sgacc', '대중교통', '주민', 'cities',\n",
       "         'lifetime', '다진', 'saliency', '마을', 'populations', '증상', 'station',\n",
       "         '시중', '생활', '공개', 'uniformity', '지속', 'exit', 'live', 'suffering'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([ 2.08295905e-03, -1.16534112e-02,  1.86806861e-02, -1.99136790e-02,\n",
       "          3.22917327e-02,  3.83437425e-02, -7.53659115e-04,  4.50831763e-02,\n",
       "          1.50361890e-02,  2.61990186e-02, -2.39838418e-02,  3.00275236e-02,\n",
       "         -2.51327306e-02, -1.54720722e-02,  6.15152717e-03,  4.36859429e-02,\n",
       "          1.57610718e-02, -3.16751860e-02, -8.82703159e-03,  4.15512510e-02,\n",
       "          8.74138717e-03, -1.28105953e-02,  1.59743782e-02, -3.70539092e-02,\n",
       "         -4.00589295e-02,  3.89716066e-02,  1.88830402e-03, -1.03341620e-02,\n",
       "          5.69925196e-02, -4.03907634e-02, -3.50913070e-02, -1.50155351e-02,\n",
       "          6.06175186e-03, -2.07147133e-02,  2.20903382e-02, -7.78681040e-03,\n",
       "          1.09167891e-02, -4.65197898e-02, -2.03770902e-02, -2.33434066e-02,\n",
       "         -6.15609391e-03,  4.25004996e-02, -1.73959136e-03, -4.97537442e-02,\n",
       "          1.28251538e-02, -6.66269800e-03, -5.48709445e-02, -3.16150151e-02,\n",
       "         -2.96220984e-02, -2.39528548e-02, -1.23891281e-02, -5.44572510e-02,\n",
       "          1.77887008e-02, -1.44734187e-02,  4.70957570e-02, -4.99431677e-02,\n",
       "          2.50211265e-02, -5.16721755e-02, -4.51720990e-02, -3.65048051e-02,\n",
       "          7.20238080e-03,  5.00429869e-02,  4.62193452e-02, -2.58045066e-02,\n",
       "          1.29261566e-02,  2.26052497e-02,  2.52945069e-02, -1.90807469e-02,\n",
       "         -3.64644341e-02, -1.38495853e-02,  3.15943770e-02,  5.43934815e-02,\n",
       "         -3.01130619e-02, -1.20373266e-02, -8.64989415e-04,  9.31899156e-03,\n",
       "          2.48660278e-02, -2.28049960e-02,  1.56495925e-02, -5.84022962e-02,\n",
       "         -6.93939477e-02, -4.00109440e-02,  2.90526170e-02, -7.01851910e-03,\n",
       "          5.96825080e-03, -3.82656865e-02, -6.56820014e-02,  1.12416558e-02,\n",
       "          4.83866669e-02, -3.56672332e-02,  1.82242338e-02,  3.32660116e-02,\n",
       "          1.48391584e-02,  2.30135899e-02, -1.07570337e-02, -9.11907572e-03,\n",
       "         -3.20327692e-02,  4.81989421e-02,  6.37896068e-04,  1.89677477e-02,\n",
       "         -2.21236963e-02, -1.84258800e-02,  1.11715915e-02, -2.04508733e-02,\n",
       "         -5.07562347e-02,  3.70925851e-02, -4.21769507e-02,  8.85313097e-03,\n",
       "          2.13719830e-02, -1.85548812e-02,  2.60145199e-02, -4.34635999e-03,\n",
       "          5.19171394e-02,  4.61352356e-02,  2.49934196e-02, -8.08912609e-03,\n",
       "          1.66676398e-02,  3.02485004e-03, -4.84135328e-03, -5.43139242e-02,\n",
       "         -1.73184816e-02,  3.84707842e-03,  1.00941453e-02, -5.17424457e-02,\n",
       "          3.51340137e-02, -1.00341691e-02, -2.37648562e-02,  5.36235562e-03,\n",
       "         -4.95888181e-02,  2.67921444e-02, -1.89380292e-02, -1.51498457e-02,\n",
       "          1.73590407e-02, -1.19757913e-02,  2.58794352e-02,  6.60840571e-02,\n",
       "         -1.00022685e-02, -1.66869292e-03,  5.32322377e-02,  1.10771542e-03,\n",
       "          4.06820066e-02,  2.24242005e-02, -6.77947141e-03,  2.75326427e-02,\n",
       "          3.50500233e-02, -3.77495736e-02,  4.34070192e-02, -2.81270780e-03,\n",
       "          4.00577299e-02,  1.83420125e-02,  1.07184453e-02,  3.10093183e-02,\n",
       "         -1.73390117e-02, -3.14368717e-02,  2.60004196e-02, -7.03874603e-03,\n",
       "         -4.74459827e-02,  1.70886386e-02,  1.15176281e-02, -2.40802616e-02,\n",
       "          3.86669040e-02, -6.86035678e-02,  3.62167768e-02,  4.88974862e-02,\n",
       "         -1.89642012e-02, -1.98320020e-02,  5.15782982e-02, -7.41276657e-03,\n",
       "         -1.93242785e-02, -4.21921611e-02,  3.66567932e-02, -1.42665626e-03,\n",
       "         -4.01724018e-02,  1.97940692e-02,  4.65075374e-02, -1.81550011e-02,\n",
       "         -2.66843587e-02,  2.05662791e-02, -5.14823757e-02,  5.49230315e-02,\n",
       "          4.70308699e-02, -4.02513966e-02,  2.69168913e-02,  2.28872430e-02,\n",
       "         -3.25562470e-02, -9.67984274e-03,  8.44873954e-03,  3.43020149e-02,\n",
       "         -5.10511510e-02,  1.53995643e-03,  1.88662652e-02, -5.33854589e-03,\n",
       "          5.65555587e-04, -3.72675173e-02, -2.58666445e-02,  1.10874018e-02,\n",
       "          5.07556200e-02,  8.37506086e-04, -2.42645461e-02,  4.47143912e-02,\n",
       "         -4.74712215e-02, -1.62694808e-02,  3.97472717e-02, -3.24910246e-02,\n",
       "         -1.66813005e-02,  6.93978369e-03,  2.59721000e-02, -1.10206343e-02,\n",
       "          1.78185087e-02,  5.48504032e-02, -9.89737362e-03,  2.06479803e-02,\n",
       "         -4.93722782e-03, -1.42095424e-02, -9.85256117e-03,  1.96703561e-02,\n",
       "          2.69679483e-02,  2.09947452e-02, -3.84465605e-02,  5.50404377e-02,\n",
       "         -4.80951108e-02, -3.26002459e-03,  1.45090101e-02, -1.34346381e-04,\n",
       "         -1.85468327e-03, -2.08701417e-02, -6.67103333e-03,  6.45355508e-03,\n",
       "          3.20808887e-02, -1.43484129e-02,  7.46073946e-03, -3.62365395e-02,\n",
       "         -2.48730555e-03,  9.55883414e-03,  3.96850556e-02,  4.10713516e-02,\n",
       "         -2.37977933e-02, -1.98624749e-02, -3.03620403e-03,  7.45813362e-03,\n",
       "          3.70271201e-03, -2.58613434e-02,  4.06899266e-02,  2.11497839e-03,\n",
       "          4.64517064e-02,  3.18566523e-02,  3.85024138e-02,  7.12021440e-03,\n",
       "         -1.86276771e-02, -4.40667681e-02,  5.99044142e-03, -2.28922740e-02,\n",
       "         -2.02531982e-02,  6.72551170e-02,  4.22779210e-02, -3.92717421e-02,\n",
       "         -4.07693684e-02,  3.96633781e-02, -9.25058033e-03,  6.17375709e-02,\n",
       "         -8.20751581e-03,  2.83868965e-02, -5.90370782e-02,  3.31152044e-02,\n",
       "          1.55155519e-02, -1.91773158e-02, -5.04796766e-02,  7.10431999e-03,\n",
       "          3.01726479e-02,  2.02703420e-02, -7.79685145e-03, -5.92646480e-04,\n",
       "          3.52539606e-02, -5.35143651e-02,  3.17815058e-02,  5.36473282e-03,\n",
       "          5.03688119e-02, -3.35246064e-02, -2.45936047e-02, -3.03149223e-02,\n",
       "          3.48112546e-02,  8.09529144e-03,  9.33664013e-03, -2.74364352e-02,\n",
       "          7.39610754e-03, -3.74426804e-02, -3.37298140e-02,  4.48511392e-02,\n",
       "         -3.97556014e-02, -4.03800495e-02, -4.52970527e-02, -3.77041358e-03,\n",
       "         -1.86232943e-02, -1.84956519e-03, -2.33889930e-03,  5.45800850e-03,\n",
       "         -7.83709530e-03,  1.58491600e-02, -3.35257016e-02,  1.05794780e-02,\n",
       "         -4.38635284e-03, -2.27535460e-02, -1.70594435e-02, -1.02501421e-03,\n",
       "          3.24061476e-02, -3.20353620e-02,  3.23792808e-02, -6.30990276e-03,\n",
       "          3.66215743e-02, -2.15422716e-02,  1.97597966e-02,  1.01992013e-02,\n",
       "         -2.87685096e-02,  3.21123190e-02,  3.97897698e-02,  2.69256383e-02,\n",
       "         -4.96312492e-02, -1.74241129e-03,  2.42489129e-02,  3.95418145e-02,\n",
       "          1.20100267e-02, -2.14796271e-02, -3.91064771e-02,  3.78964841e-02,\n",
       "          2.00063810e-02, -1.18691130e-02,  2.19159517e-02,  4.72231619e-02,\n",
       "          3.25447917e-02, -1.67056117e-02, -1.86621975e-02, -2.70724129e-02,\n",
       "         -4.09791209e-02, -9.53988731e-03, -3.39469500e-02, -2.42963508e-02,\n",
       "          8.09264462e-03,  3.95697914e-02, -4.83196266e-02, -2.10654084e-02,\n",
       "         -1.20819360e-02,  9.26704612e-03, -2.87005529e-02, -2.40519643e-04,\n",
       "         -4.88270670e-02,  3.75585221e-02, -1.09439269e-02,  2.12528910e-02,\n",
       "          5.06212600e-02,  1.01934718e-02,  1.99413560e-02,  1.19545190e-02,\n",
       "          2.32731346e-02,  2.78292149e-02, -7.53204757e-03,  1.35688679e-02,\n",
       "         -4.32426482e-02,  3.47078033e-02, -5.18604107e-02, -3.90824489e-02,\n",
       "          3.34704816e-02, -2.08433568e-02,  5.31305633e-02, -1.13118915e-02,\n",
       "          2.25492548e-02, -1.17451139e-03, -5.80462702e-02, -2.61088405e-02,\n",
       "          2.63270661e-02, -2.84739374e-03, -9.53207724e-04,  2.35116389e-02,\n",
       "         -9.56962258e-03,  1.46802692e-02,  1.56822149e-02,  9.42229666e-03,\n",
       "          2.52658334e-02, -1.14136674e-02,  5.22953868e-02,  1.19967209e-02,\n",
       "          4.96747810e-03,  3.63500416e-02, -3.80108170e-02,  4.46338356e-02,\n",
       "         -1.86685380e-02,  9.51257069e-03, -3.11923232e-02, -2.88973618e-02,\n",
       "          7.06760818e-03,  4.95605208e-02, -2.48327982e-02, -7.58259604e-03,\n",
       "          1.01113161e-02,  4.19772118e-02,  6.05338078e-04, -3.79891805e-02,\n",
       "         -4.43882011e-02,  3.91682498e-02,  3.90174799e-02, -1.09593272e-02,\n",
       "         -2.88321450e-02,  4.11768816e-02,  5.30130155e-02, -4.53396700e-03,\n",
       "         -1.25910463e-02, -3.50473193e-03,  8.64971150e-03,  1.96343306e-02,\n",
       "         -1.47073446e-02, -4.89074700e-02, -1.88451505e-03, -2.05235090e-02,\n",
       "         -1.79736931e-02,  3.57764424e-03,  1.05064027e-02,  4.50158529e-02,\n",
       "         -3.32166180e-02,  3.49387228e-02,  1.17634842e-02, -2.65059099e-02,\n",
       "          1.41540324e-04,  3.88068818e-02, -3.65403630e-02,  5.45613728e-02,\n",
       "         -6.13648444e-06,  6.59780204e-03,  4.98472638e-02, -2.40468811e-02,\n",
       "         -1.96924843e-02, -3.65672521e-02,  1.71436723e-02, -1.75793264e-02,\n",
       "          2.66205464e-02, -4.35242020e-02,  2.84663364e-02, -2.26524249e-02,\n",
       "          8.93311575e-03,  5.27004339e-02, -5.46749420e-02,  2.65966151e-02,\n",
       "         -9.23509430e-03,  4.16369848e-02, -3.86231616e-02, -3.45561169e-02,\n",
       "          1.13697350e-02,  3.56603526e-02,  4.93008383e-02, -1.05649640e-03,\n",
       "          3.08263605e-03,  4.80546318e-02, -6.59950590e-03,  6.59547448e-02,\n",
       "          4.59145494e-02,  1.04816854e-02, -6.95171505e-02,  2.60290634e-02,\n",
       "          6.56957319e-03, -2.23266035e-02, -2.61652973e-02, -2.85020825e-02,\n",
       "          5.20127751e-02, -3.27693485e-02, -1.65023692e-02,  6.52885577e-03,\n",
       "          1.42248869e-02, -5.40224314e-02, -4.72513475e-02,  4.60252464e-02,\n",
       "          9.56146326e-03, -5.43020293e-03,  4.60333489e-02, -2.63167489e-02,\n",
       "          1.26988851e-02,  4.45667841e-03, -2.45577786e-02, -4.89478894e-02,\n",
       "          9.05987713e-03, -7.93163199e-03,  1.03556579e-02,  1.18238234e-03,\n",
       "          4.03770022e-02,  3.82442623e-02,  3.88088822e-03, -2.36943085e-02,\n",
       "          9.13474616e-03,  4.46280427e-02,  2.68773343e-02, -5.70507012e-02,\n",
       "         -4.17934172e-02, -1.38164731e-02,  6.86661294e-03, -1.45199522e-03,\n",
       "          4.14391197e-02, -5.79654658e-03,  3.58865224e-02, -2.21069027e-02,\n",
       "         -1.42456712e-02,  2.40578447e-02,  3.88315320e-02,  3.75346951e-02,\n",
       "         -2.95166504e-02,  7.94021133e-03,  4.37360676e-03,  1.16089853e-02,\n",
       "         -4.56269197e-02, -1.46791087e-02,  2.12442651e-02,  1.51028736e-02,\n",
       "          1.20384479e-02, -1.16761671e-02, -2.46279445e-02, -4.43716235e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 24,\n",
       "  'topic_words': array(['python', 'cython', 'numpy', '파이썬', 'matplotlib', 'scipy',\n",
       "         'multiprocessing', '컴파일러', '컴파일', '프로그래밍', 'compiler',\n",
       "         'tensorflow', 'integer', 'dataframe', 'subprocess', 'compile',\n",
       "         'integers', '코딩', 'dataset', 'programming', 'computation',\n",
       "         'sklearn', '함수', 'computational', 'stdout', 'algorithmic',\n",
       "         'varlambda', 'algorithms', 'coding', 'dict', 'github',\n",
       "         'computationally', 'lineplot', 'module', 'algorithm', 'modules',\n",
       "         'kwargs', '변수', 'encoding', 'nipype', 'anaconda', 'ggplot',\n",
       "         'syntax', 'decoding', 'javascript', 'optimize', 'byte', 'gcc',\n",
       "         'matlab', '인코딩'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.06445038, -0.01557459, -0.03842976,  0.02299641,  0.02404317,\n",
       "         -0.06738981, -0.02462531,  0.02197473,  0.06211847, -0.02794441,\n",
       "          0.01324966,  0.02941648,  0.05045409,  0.02707959, -0.05906941,\n",
       "          0.01674856,  0.04764776, -0.00586752,  0.02728052,  0.02712746,\n",
       "          0.04674028, -0.02057878, -0.01572901,  0.05439034, -0.06194891,\n",
       "         -0.05644411, -0.01170722,  0.00319715,  0.0516565 , -0.04081007,\n",
       "         -0.04273213,  0.01907429,  0.00185108, -0.0644478 ,  0.02456154,\n",
       "          0.03283964, -0.03575269,  0.02837526,  0.03794304,  0.00288724,\n",
       "         -0.02395051, -0.01987262, -0.01498572,  0.02017158, -0.03503773,\n",
       "         -0.00747831,  0.04786327,  0.00069899, -0.04866751,  0.01799605,\n",
       "          0.02890207, -0.02942206, -0.03556488,  0.01912664,  0.02719843,\n",
       "         -0.0517794 , -0.00951974,  0.05820505,  0.05916383, -0.03099472,\n",
       "          0.00430561,  0.00633937, -0.00309324, -0.04337212,  0.02659534,\n",
       "         -0.02874974, -0.0291971 , -0.02263153,  0.05751237, -0.03232131,\n",
       "         -0.03485392,  0.0269344 , -0.00877444,  0.00305345,  0.00057333,\n",
       "         -0.03087187,  0.01331782, -0.00481957,  0.05555355, -0.06511824,\n",
       "         -0.0668755 ,  0.00653709, -0.05381369,  0.02564777,  0.03705471,\n",
       "         -0.01325674,  0.01891211, -0.00588216,  0.00173476,  0.03286109,\n",
       "         -0.02316395, -0.01377802,  0.03555489,  0.01834153,  0.04502099,\n",
       "          0.04701607, -0.04985439,  0.05627751,  0.01749785, -0.00983735,\n",
       "          0.03803623, -0.01785203, -0.03068819, -0.0309629 ,  0.0240401 ,\n",
       "          0.01534291, -0.01915679,  0.00057215,  0.03626787,  0.02375838,\n",
       "         -0.01979193, -0.01398881,  0.02623678, -0.04001541,  0.03644298,\n",
       "         -0.00448253, -0.05578746, -0.04462193, -0.00726863,  0.02931701,\n",
       "         -0.05172837,  0.02198782, -0.00463262,  0.02095644,  0.03627549,\n",
       "         -0.01084505, -0.02510689,  0.01058322, -0.02808071,  0.02173511,\n",
       "         -0.05144144,  0.01800885,  0.06483933,  0.02996743, -0.0445423 ,\n",
       "          0.03749337, -0.02118404,  0.00770121,  0.02226097,  0.02758362,\n",
       "          0.02847747, -0.02202255,  0.02122272,  0.03715159, -0.01045184,\n",
       "         -0.01233996, -0.03593197,  0.04894871, -0.00645312, -0.00219927,\n",
       "          0.04006291,  0.03940817, -0.02806684, -0.02895987, -0.02570957,\n",
       "         -0.02292253, -0.03600868, -0.03554256, -0.04824683, -0.01633703,\n",
       "          0.02525382,  0.001285  ,  0.0400929 , -0.00972826, -0.01950176,\n",
       "          0.02239976, -0.01185895,  0.02296738, -0.0189001 ,  0.02804386,\n",
       "          0.04385331,  0.00381898,  0.02659892,  0.02409944, -0.02635675,\n",
       "          0.03170497, -0.0381496 ,  0.00923329, -0.05817709,  0.04902419,\n",
       "          0.01652876,  0.05362011,  0.02952147, -0.0130684 , -0.05656212,\n",
       "         -0.00638377,  0.01477425,  0.03236774,  0.00203691, -0.0074196 ,\n",
       "         -0.00858442, -0.00177632,  0.04604571, -0.01679069, -0.01228264,\n",
       "          0.03321922, -0.04360342, -0.01978301,  0.05067251,  0.0298354 ,\n",
       "          0.02250663,  0.020474  , -0.03217204, -0.00570275, -0.0309584 ,\n",
       "          0.03580045,  0.04392596, -0.05365613,  0.02002415,  0.01093755,\n",
       "         -0.03986611,  0.03839092, -0.01878436, -0.04010363,  0.00420722,\n",
       "          0.01236312,  0.02597697, -0.03847412,  0.02827433, -0.01140032,\n",
       "          0.00155843,  0.03948813,  0.01293882, -0.0112638 , -0.06347017,\n",
       "          0.01111438, -0.02037634,  0.01397328,  0.02229026,  0.04017542,\n",
       "         -0.01473149,  0.06163965,  0.03781484, -0.0007962 ,  0.00663234,\n",
       "          0.02022668,  0.00725213,  0.02841301,  0.00159545, -0.00278287,\n",
       "          0.01198906,  0.01893496,  0.00024478,  0.01764955, -0.01564332,\n",
       "         -0.06739632, -0.00879772,  0.01020236, -0.00390476, -0.02926993,\n",
       "         -0.00844105, -0.05019194, -0.0141341 , -0.03358885,  0.02966878,\n",
       "         -0.01082603,  0.04774799, -0.04519906,  0.04170971, -0.01910361,\n",
       "          0.0523621 ,  0.03383479, -0.01507867, -0.04487519,  0.03237129,\n",
       "         -0.04788532, -0.02607768,  0.04533854,  0.02490259,  0.02621693,\n",
       "          0.00956452, -0.05545029, -0.01681262,  0.00370512, -0.02530707,\n",
       "          0.01919285, -0.04080142, -0.04002854, -0.05542278, -0.02616588,\n",
       "         -0.02298154,  0.01500905, -0.03016049,  0.02028263, -0.04887439,\n",
       "         -0.00651666, -0.01677055, -0.02010524,  0.02979915,  0.01663382,\n",
       "          0.00070557,  0.03239836,  0.02531383,  0.05685252, -0.06718606,\n",
       "          0.02982873, -0.02792625,  0.03726421,  0.00765337,  0.05195496,\n",
       "         -0.02395674, -0.04005847, -0.04492481, -0.04832135, -0.01885089,\n",
       "          0.01040806, -0.02565683,  0.00398633, -0.01421314,  0.04537249,\n",
       "          0.03168771,  0.01920008, -0.00440439,  0.01052798, -0.00484678,\n",
       "          0.00120321,  0.03981591, -0.00792718, -0.01926899,  0.0116438 ,\n",
       "          0.0041977 , -0.00862923,  0.00818697, -0.00933218,  0.00505294,\n",
       "          0.01681181, -0.05188019, -0.02953878,  0.04396463,  0.00199567,\n",
       "          0.01237922, -0.02706004, -0.0566368 ,  0.03103504,  0.01264071,\n",
       "          0.02316263, -0.01391875, -0.03596222, -0.06542501, -0.04320259,\n",
       "          0.00369628,  0.00043317,  0.02842244, -0.01269355, -0.00147193,\n",
       "         -0.02844855,  0.02281543,  0.02291913,  0.01866153,  0.02129412,\n",
       "          0.02697401,  0.00412804,  0.00236125, -0.03116569, -0.02460177,\n",
       "          0.02582876, -0.01643773,  0.02047092,  0.0192748 , -0.02425497,\n",
       "         -0.01782858,  0.00145154, -0.0178061 , -0.03292672,  0.00931275,\n",
       "         -0.03440777,  0.02615798,  0.01904251,  0.02073124,  0.04111581,\n",
       "         -0.02452476,  0.00936476, -0.03737237, -0.01944735,  0.01594247,\n",
       "         -0.01768565, -0.01191473,  0.01254713, -0.06057805, -0.03779184,\n",
       "         -0.03711881, -0.0564195 ,  0.0061253 , -0.04140354, -0.01113585,\n",
       "          0.02611557,  0.0323134 , -0.05081402,  0.01896607,  0.04937722,\n",
       "          0.04433732, -0.01487275, -0.02479277,  0.01375378, -0.03484798,\n",
       "          0.01257966, -0.03361004,  0.01956664, -0.02698856,  0.01302319,\n",
       "          0.02099668, -0.0066842 ,  0.06117492, -0.05205924,  0.03578361,\n",
       "          0.00132357,  0.02651726, -0.04865474,  0.02190564, -0.03580547,\n",
       "         -0.00368125,  0.04792557,  0.03650022, -0.02274366,  0.01169147,\n",
       "         -0.03902846,  0.0475347 ,  0.04522429, -0.03779208,  0.04767759,\n",
       "          0.02996274, -0.0230626 ,  0.03612642,  0.05621251, -0.00885351,\n",
       "          0.03642438, -0.01465365,  0.00378475,  0.00866101,  0.03311005,\n",
       "         -0.00293514,  0.03292955, -0.01183788,  0.00769445, -0.02014176,\n",
       "          0.02826204,  0.03123486,  0.0137079 , -0.04129295,  0.02114523,\n",
       "         -0.04937647,  0.02516164, -0.00036374, -0.05844945, -0.00362686,\n",
       "         -0.02434597,  0.06234141,  0.00174461,  0.02836847, -0.01014289,\n",
       "          0.00144524,  0.01059691, -0.04960268,  0.00525441,  0.03906875,\n",
       "         -0.0447528 ,  0.04713768, -0.01114171,  0.01499771,  0.04475436,\n",
       "          0.00596187, -0.01970323,  0.02206982, -0.04485257,  0.02067214,\n",
       "         -0.0372257 ,  0.00714321, -0.03669661,  0.06095026, -0.05308767,\n",
       "          0.0218576 ,  0.01963729,  0.01016041, -0.02351788, -0.05112628,\n",
       "         -0.02402739, -0.01992659, -0.00996689, -0.00999826, -0.03067971,\n",
       "          0.02131617, -0.02463305, -0.00182284, -0.00571979, -0.0348992 ,\n",
       "          0.03886432,  0.0396454 , -0.05021127,  0.05045696, -0.02100086,\n",
       "          0.00443013,  0.0256885 , -0.06166576, -0.02566522,  0.02046305,\n",
       "         -0.01305585, -0.05009478, -0.05518679,  0.04762413,  0.0525313 ,\n",
       "         -0.0209984 , -0.00381468,  0.03550903, -0.04158431, -0.01144223,\n",
       "         -0.06728131,  0.00923227, -0.03461444, -0.02649112, -0.04672401,\n",
       "          0.03494228,  0.00732079], dtype=float32)},\n",
       " {'topic_idx': 25,\n",
       "  'topic_words': array(['ubuntu', 'xorg', '커널', '부팅', '우분투', 'linux', 'sudo', 'nvidia',\n",
       "         'kernel', 'boot', 'gedit', 'grub', 'gpu', 'bashrc', 'stdout',\n",
       "         'sli', 'config', 'terminal', 'partition', '터미널', 'default', 'cpu',\n",
       "         '윈도우', 'bootstrapping', 'canonical', 'lightdm', 'bootstrap',\n",
       "         'gnome', 'disable', 'windows', 'htop', '노트북', 'glm', 'ssd',\n",
       "         'defaults', 'synaptic', 'bash', 'command', '명령', 'hd', 'firefox',\n",
       "         'gtx', 'commands', 'unix', 'endogenous', 'intel', 'openmx',\n",
       "         'adaboost', 'usb', 'tensorflow'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.05676873,  0.02182494,  0.01319205,  0.04238226,  0.01542241,\n",
       "         -0.05907666,  0.02080083,  0.01260529,  0.03983574, -0.04346159,\n",
       "          0.00046192, -0.01519902,  0.03343892,  0.01602395,  0.01905626,\n",
       "         -0.01675507, -0.00113479, -0.00115254,  0.05009684,  0.04753691,\n",
       "          0.0311862 ,  0.02688412, -0.0050454 ,  0.03271241, -0.05471092,\n",
       "         -0.04303241,  0.03038615, -0.03457103,  0.05393799, -0.04971934,\n",
       "          0.01916377,  0.01221591, -0.02541213, -0.05488065, -0.04577015,\n",
       "          0.00847111,  0.05418471, -0.0298815 ,  0.05911789,  0.04183827,\n",
       "         -0.04096339,  0.05649307,  0.03703154, -0.00054161,  0.02537465,\n",
       "         -0.04771272,  0.05104657, -0.05323483, -0.05873562, -0.03202259,\n",
       "          0.0060969 ,  0.01424473,  0.0589928 , -0.01594134,  0.0197943 ,\n",
       "         -0.05267138, -0.01782674,  0.04446159, -0.03963812,  0.01499539,\n",
       "          0.03003419,  0.05369703,  0.04961788, -0.04953213,  0.00525333,\n",
       "         -0.03350282,  0.00892694, -0.02219123,  0.04928136, -0.00604072,\n",
       "         -0.01851975,  0.04285763,  0.02154832,  0.04214216, -0.04782859,\n",
       "          0.02063543, -0.03813526, -0.05016178, -0.04816138, -0.05911059,\n",
       "         -0.05914164,  0.02194279, -0.04013512, -0.04392757,  0.01201766,\n",
       "          0.03164995, -0.02302686, -0.0364194 ,  0.04101795, -0.03033973,\n",
       "         -0.00349718, -0.02502   ,  0.01319999,  0.01744079,  0.05360557,\n",
       "         -0.02977867, -0.05625229, -0.00240712,  0.01610258,  0.00260859,\n",
       "          0.02378339, -0.01398317,  0.03547825,  0.03959908, -0.00534584,\n",
       "         -0.02007728, -0.04093026, -0.04201532,  0.05533556,  0.02660432,\n",
       "         -0.0301254 , -0.05557083, -0.01277106, -0.00290162,  0.02835352,\n",
       "         -0.00189136,  0.02599584,  0.044279  , -0.01341453,  0.02556286,\n",
       "         -0.03108438, -0.00909768,  0.00024719, -0.01681397, -0.03259959,\n",
       "          0.04985589, -0.03799113,  0.05578588,  0.03644778, -0.01179749,\n",
       "         -0.03079013,  0.00251315,  0.05501488,  0.01928968,  0.03763832,\n",
       "          0.04289072,  0.05673721, -0.00925182,  0.04760491,  0.01683361,\n",
       "          0.04759552, -0.01424525,  0.01666536,  0.04322812, -0.00098231,\n",
       "         -0.00175486,  0.03690808,  0.03462964,  0.03471024,  0.02294215,\n",
       "          0.05627367, -0.00402365, -0.0466483 , -0.01980836,  0.03693225,\n",
       "          0.02815755, -0.00353659,  0.01946295,  0.02006119, -0.05888583,\n",
       "          0.04670144,  0.03362789,  0.04566309, -0.02787275, -0.03292283,\n",
       "         -0.04051331, -0.05240184, -0.04210192,  0.04842084,  0.01711343,\n",
       "          0.02131104, -0.02865871, -0.04097225, -0.02549944, -0.00600426,\n",
       "          0.05174804, -0.04346414, -0.05264318, -0.00341825,  0.04375266,\n",
       "          0.01956434,  0.03001429, -0.0105826 , -0.04227449, -0.05444782,\n",
       "         -0.02194408, -0.0001911 ,  0.0571598 ,  0.00504935,  0.05914018,\n",
       "         -0.00465113, -0.03055525,  0.02076091,  0.00130823, -0.05111704,\n",
       "          0.02986956, -0.05112392,  0.00552747,  0.02083456, -0.01476379,\n",
       "         -0.0094949 , -0.02561832, -0.00281684, -0.01107166, -0.01774984,\n",
       "         -0.02852682,  0.01327233,  0.03978461, -0.02551896,  0.0337865 ,\n",
       "          0.0230274 ,  0.02932661,  0.03886849,  0.0369132 ,  0.02020209,\n",
       "          0.00481562,  0.01509796, -0.01642057, -0.0356496 ,  0.04421978,\n",
       "         -0.00976211,  0.04910814,  0.01750849,  0.01174139, -0.05871246,\n",
       "         -0.00915569, -0.05678687,  0.00906101, -0.01152085, -0.03556774,\n",
       "         -0.03741615,  0.05602089,  0.03308507,  0.05603028,  0.00758736,\n",
       "          0.05575129, -0.05437125,  0.04929529, -0.03299859, -0.00908674,\n",
       "         -0.02134965, -0.01843846,  0.02784918,  0.02866165,  0.04222521,\n",
       "          0.02121515,  0.040123  , -0.05132569,  0.03345398,  0.03836288,\n",
       "         -0.02622963,  0.01207202,  0.01966085, -0.01217502, -0.01157473,\n",
       "          0.00419272, -0.02239508, -0.05294216,  0.0044812 , -0.00081024,\n",
       "          0.03749883,  0.04955659, -0.00158579,  0.05329644,  0.0351129 ,\n",
       "         -0.04273903,  0.02582238,  0.01616733, -0.0030582 ,  0.00570458,\n",
       "          0.03754129,  0.00662031, -0.02453223,  0.0297137 , -0.01908736,\n",
       "         -0.02570757,  0.04133585, -0.03794466, -0.03615273,  0.0508117 ,\n",
       "          0.00847427,  0.02160812, -0.05071009, -0.00274131, -0.01761007,\n",
       "          0.05642278, -0.05635185,  0.03613161, -0.02634502, -0.03093909,\n",
       "         -0.00874035, -0.01273247, -0.00526479,  0.00703713, -0.05913312,\n",
       "          0.04324697, -0.05538071,  0.00472387, -0.0333338 , -0.04774409,\n",
       "          0.04859396, -0.03144954, -0.02337408, -0.02397003,  0.03369404,\n",
       "          0.01031934, -0.02557578, -0.03010272,  0.02546104,  0.01654816,\n",
       "          0.02792973, -0.03582765, -0.01510543,  0.02403829,  0.00518888,\n",
       "          0.04048865,  0.03866965, -0.0252017 ,  0.00528006, -0.02687453,\n",
       "          0.01944989,  0.04662491,  0.00235418,  0.03028915,  0.05303305,\n",
       "          0.04598005, -0.05593306, -0.05622916, -0.02469344, -0.01529377,\n",
       "         -0.04434499, -0.04684443, -0.04148595,  0.02650024, -0.00146563,\n",
       "          0.01918749,  0.02920209,  0.01192708, -0.05170275, -0.03128223,\n",
       "         -0.01798277,  0.05564598, -0.03039745, -0.03163704,  0.04730058,\n",
       "          0.02344487, -0.0180518 ,  0.04293409, -0.02313912, -0.01569623,\n",
       "          0.02688809,  0.0022135 ,  0.02805974, -0.04304187,  0.05194457,\n",
       "          0.00987907, -0.02945595,  0.02077111, -0.01693616, -0.02958298,\n",
       "         -0.019948  ,  0.03741038,  0.04366383,  0.02823032,  0.0254592 ,\n",
       "         -0.04330408, -0.05038011,  0.02732421, -0.0430293 ,  0.03539765,\n",
       "          0.01780232,  0.05054979,  0.01615415, -0.03154948, -0.00582654,\n",
       "         -0.02196936, -0.01918426,  0.0452688 ,  0.0586699 , -0.00861342,\n",
       "         -0.03047104, -0.03491659, -0.007821  , -0.04436903,  0.03199248,\n",
       "          0.04271763, -0.05751121, -0.05898432,  0.00660783, -0.00482421,\n",
       "         -0.01481772, -0.04082256,  0.03190555,  0.01461871, -0.03179338,\n",
       "         -0.00543996, -0.0154804 ,  0.02009661,  0.01932026,  0.02597699,\n",
       "          0.04301204,  0.00155045,  0.04450513,  0.0301532 ,  0.02039775,\n",
       "          0.01948134,  0.00465155, -0.03620654,  0.04711483,  0.05261777,\n",
       "         -0.04264972,  0.03159038,  0.01226231,  0.02962088,  0.00023404,\n",
       "          0.01721486, -0.01340364,  0.05407075, -0.01703283, -0.0215326 ,\n",
       "          0.0537765 ,  0.01486189,  0.03132725,  0.03334776,  0.01747037,\n",
       "         -0.00157505,  0.03382643, -0.02807655,  0.02679281, -0.01729825,\n",
       "          0.05256884,  0.04159045,  0.04760338,  0.03237735,  0.0138126 ,\n",
       "         -0.00718159,  0.03642745,  0.03309241, -0.04736164,  0.02401795,\n",
       "         -0.05714398, -0.02029662,  0.00548441, -0.01509134, -0.00570267,\n",
       "          0.01179669,  0.04566677,  0.05166794,  0.05904169,  0.01287238,\n",
       "          0.04293395,  0.0524262 , -0.05676937, -0.04068785, -0.00931756,\n",
       "         -0.01311345,  0.04719431, -0.00115735,  0.03276158,  0.04160525,\n",
       "          0.02279898,  0.02693097,  0.04342466,  0.05493355,  0.03038574,\n",
       "         -0.05578208,  0.03548237,  0.05863454,  0.04924982, -0.01241245,\n",
       "          0.04009654, -0.05530976, -0.01266101,  0.00075392, -0.03522727,\n",
       "          0.01836693,  0.00068633, -0.04516213,  0.00758069, -0.0275369 ,\n",
       "         -0.0465747 ,  0.0412434 , -0.01794344, -0.02129749,  0.02765446,\n",
       "         -0.00827554,  0.05287941, -0.05636635,  0.0032894 , -0.05229377,\n",
       "          0.03328551,  0.04483163,  0.00635687, -0.02266671,  0.03396329,\n",
       "         -0.0228658 , -0.04768711,  0.01195026, -0.02966646,  0.02658371,\n",
       "          0.02128654,  0.05330038,  0.0383826 ,  0.04717506, -0.04181463,\n",
       "         -0.05140767, -0.0219209 ,  0.03124443,  0.01563923,  0.00604354,\n",
       "          0.00291526,  0.02248729], dtype=float32)},\n",
       " {'topic_idx': 26,\n",
       "  'topic_words': array(['statistical', 'statistics', 'statistically', 'regression', '통계',\n",
       "         'correlations', 'correlation', '통계청', 'nonparametric', 'analytics',\n",
       "         'parametric', 'variance', 'statistic', 'models', 'analysis',\n",
       "         'variances', '모델', '잠재변수', 'analytical', '파라미터', 'modelling',\n",
       "         'multivariate', 'datasets', 'probabilistic', 'correlate',\n",
       "         'correlates', 'dataset', 'covariance', '예측', 'paradigms',\n",
       "         'coefficient', '회귀분석', 'coefficients', 'predictor', 'dataframe',\n",
       "         'correlated', 'predictive', 'predicts', 'predictors', 'model',\n",
       "         'parameters', 'nonlinear', 'simulations', 'matplotlib', 'paradigm',\n",
       "         'variability', 'predictions', 'analyses', 'stats', 'predict'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-0.0522671 ,  0.02608768, -0.03717323,  0.02791709, -0.00329302,\n",
       "         -0.03098722,  0.02524988, -0.01308336,  0.04625243,  0.0372391 ,\n",
       "          0.016268  ,  0.04134946,  0.05189579,  0.02298155, -0.04428283,\n",
       "         -0.03902395, -0.01288959, -0.02549703,  0.03152321,  0.01538218,\n",
       "         -0.01562333, -0.03065434, -0.04945215,  0.01959965, -0.0613331 ,\n",
       "         -0.03824121,  0.02468367,  0.00636689, -0.03428888, -0.04004652,\n",
       "         -0.02219102,  0.02719324,  0.04335445, -0.05161449, -0.03185223,\n",
       "          0.02912225,  0.01174244,  0.03586689,  0.01405094,  0.03491967,\n",
       "         -0.00065485,  0.03220695,  0.03890114, -0.03781734,  0.00648285,\n",
       "         -0.04284802,  0.04876124,  0.03977057, -0.0201898 , -0.04920673,\n",
       "         -0.03683889, -0.02565819, -0.00411503, -0.00112037,  0.04516775,\n",
       "         -0.05572852,  0.01304196,  0.03551786,  0.02998987,  0.03136605,\n",
       "          0.02905038,  0.05259757,  0.03641154, -0.0543947 ,  0.02780917,\n",
       "         -0.03522425,  0.04509471, -0.02132003, -0.02379759,  0.01286532,\n",
       "         -0.05148305,  0.01995536,  0.00593704, -0.0209478 , -0.02841546,\n",
       "         -0.04566255,  0.03620531,  0.05222311, -0.00487049, -0.06032053,\n",
       "         -0.06188962, -0.04596283, -0.03270145,  0.04123916,  0.03359915,\n",
       "         -0.01158953, -0.02707856, -0.02400838,  0.0018683 ,  0.02563566,\n",
       "         -0.0375071 , -0.04536049,  0.0203346 , -0.0592706 ,  0.02446913,\n",
       "          0.06022892, -0.02683422,  0.03317736,  0.01026534,  0.02711837,\n",
       "          0.03319406, -0.00919676,  0.0399489 ,  0.01519853,  0.03662445,\n",
       "         -0.03336513, -0.05896223,  0.03322715,  0.01079557,  0.04396528,\n",
       "          0.04988496, -0.02391122, -0.05374551, -0.03089746,  0.03144285,\n",
       "         -0.02272428,  0.018579  , -0.03281099,  0.00884721,  0.03657348,\n",
       "         -0.02667541, -0.01426066,  0.02153736,  0.0408042 ,  0.03818392,\n",
       "          0.02119807, -0.03246089,  0.01430261, -0.02454623,  0.01642984,\n",
       "         -0.06033862, -0.01706971,  0.05554169,  0.03761101,  0.00935399,\n",
       "          0.05711456,  0.03545092, -0.01659942,  0.0505612 ,  0.03693934,\n",
       "         -0.03193154, -0.02309242,  0.00778609, -0.00548994, -0.00212831,\n",
       "         -0.01785952, -0.05104912,  0.05629048,  0.01398907,  0.02255028,\n",
       "          0.05444954, -0.02471753, -0.02172309, -0.04078444,  0.01997106,\n",
       "         -0.04726255,  0.01789304, -0.03909428,  0.01552797,  0.00118989,\n",
       "          0.03045315, -0.03515008, -0.0075484 , -0.04150771, -0.03248512,\n",
       "         -0.00330232, -0.02742137,  0.02168552, -0.04223649,  0.05374031,\n",
       "         -0.03729897, -0.01572336,  0.02068556,  0.00527754, -0.01388866,\n",
       "          0.00991749, -0.0125901 ,  0.04128653, -0.05062503,  0.04151049,\n",
       "          0.03698581, -0.00765096,  0.01739077, -0.02646157, -0.04430131,\n",
       "         -0.02068549,  0.00839586,  0.04766819, -0.0341722 , -0.02437992,\n",
       "          0.02372862,  0.00174907,  0.04763737, -0.00263132,  0.02244477,\n",
       "          0.00540723, -0.05330013, -0.01497691,  0.04630528, -0.00662746,\n",
       "         -0.0416784 ,  0.00714914, -0.05438956, -0.02678909, -0.03838107,\n",
       "         -0.01092195, -0.02329683, -0.03392061, -0.02008266,  0.03964204,\n",
       "         -0.01626495, -0.00157528, -0.05350239,  0.00211983,  0.04785012,\n",
       "         -0.00393244, -0.03854204, -0.04714084, -0.02809356, -0.049214  ,\n",
       "          0.00250011,  0.03061624,  0.03019982, -0.01655559, -0.05577999,\n",
       "         -0.01953682, -0.05823259, -0.05712291,  0.01786163,  0.01624732,\n",
       "         -0.04442598,  0.03879895, -0.04252164, -0.01512467,  0.04849234,\n",
       "          0.03110302,  0.0150595 ,  0.04135713,  0.05266131, -0.00797876,\n",
       "          0.00499303,  0.0139338 , -0.01376567,  0.01146242,  0.05246621,\n",
       "         -0.04762333,  0.03443411,  0.02273011,  0.00213574, -0.01347306,\n",
       "         -0.0255974 , -0.04872496,  0.00167811, -0.03821719,  0.01794497,\n",
       "         -0.05164891, -0.03450928,  0.01739189, -0.03473403, -0.01560481,\n",
       "          0.00570801,  0.00959434, -0.02693623, -0.04187981,  0.02398147,\n",
       "         -0.05291677, -0.02028373, -0.00219526, -0.000259  , -0.00684197,\n",
       "          0.033303  , -0.01182946, -0.01745839,  0.00090289,  0.02322808,\n",
       "          0.03444009, -0.05255064,  0.05367345, -0.04182332, -0.00839157,\n",
       "         -0.05873159,  0.00152388,  0.02941035, -0.00314959, -0.01677566,\n",
       "          0.04904303, -0.02639334,  0.00653812, -0.04233386,  0.05370222,\n",
       "          0.0288082 ,  0.03573948,  0.03585844,  0.01365892, -0.05073879,\n",
       "          0.04034305, -0.01185861,  0.03267812,  0.02780219,  0.05606539,\n",
       "         -0.01238677,  0.05427498, -0.044774  , -0.05609316, -0.06234154,\n",
       "         -0.01925866, -0.01035898,  0.02512909, -0.02758993,  0.03925719,\n",
       "         -0.03603002,  0.00315279, -0.05851879, -0.05124941,  0.03825873,\n",
       "          0.03576684,  0.03749542, -0.03678378,  0.02482039, -0.03533617,\n",
       "         -0.01862564,  0.02459173, -0.03566698, -0.00974638, -0.02942359,\n",
       "         -0.02671499, -0.01753026, -0.03035003, -0.0053819 ,  0.01583359,\n",
       "         -0.02957324, -0.03966787,  0.01622515, -0.05577578, -0.04160253,\n",
       "          0.02026064, -0.0262702 , -0.03059461, -0.05792309, -0.04699514,\n",
       "         -0.05395535, -0.01305695, -0.00288357, -0.03953933, -0.02569505,\n",
       "          0.04336741,  0.04033167,  0.04516107, -0.0474906 , -0.00319308,\n",
       "         -0.02489861, -0.02818459,  0.02959481, -0.03176034, -0.02064713,\n",
       "          0.02890751,  0.00557268,  0.01692287, -0.04098853, -0.02469124,\n",
       "          0.03630963, -0.02955   ,  0.04902435, -0.0296078 , -0.02371472,\n",
       "          0.01989821,  0.02185283,  0.04012132, -0.02078876,  0.02447571,\n",
       "          0.03722749,  0.04257644, -0.03983551,  0.03412092, -0.00059541,\n",
       "         -0.05604874,  0.02922223, -0.01022582, -0.03084419, -0.05838508,\n",
       "          0.00910478, -0.02836809,  0.00153858, -0.00414618, -0.04117587,\n",
       "          0.04636634, -0.02405031, -0.03922236,  0.04416222,  0.0289655 ,\n",
       "          0.02133818, -0.04574928, -0.03891239,  0.05830691, -0.04786352,\n",
       "          0.00401298,  0.04577429,  0.0201026 , -0.04929747, -0.00177053,\n",
       "          0.02748363,  0.05175341,  0.06048317, -0.00963033, -0.04242819,\n",
       "         -0.00040717,  0.00351275,  0.00705423, -0.03036749, -0.00960953,\n",
       "          0.01318059, -0.00891648,  0.01789918, -0.05072404,  0.01498193,\n",
       "          0.0454703 ,  0.00944115,  0.01018518,  0.01187004, -0.01048855,\n",
       "         -0.00645452, -0.05514569,  0.00180108,  0.06010446,  0.04036022,\n",
       "          0.01322465, -0.02912034, -0.04738839, -0.02761916, -0.03423923,\n",
       "         -0.01491978,  0.0216051 , -0.04450247, -0.00277295,  0.03631219,\n",
       "          0.0393029 ,  0.04554836,  0.01037314, -0.05802326, -0.00064732,\n",
       "         -0.00880269,  0.0259083 ,  0.01005784, -0.05007752,  0.00321296,\n",
       "         -0.0401965 ,  0.0479853 ,  0.01214319,  0.00314054,  0.02770563,\n",
       "         -0.00660022, -0.03897157, -0.04530133, -0.02953154, -0.03827358,\n",
       "         -0.00730885,  0.03549545,  0.01428937,  0.02631241,  0.03533294,\n",
       "         -0.00485985, -0.01603761, -0.00706836, -0.05663612,  0.02902563,\n",
       "         -0.04969779,  0.03065976, -0.04612011,  0.05747672, -0.04973424,\n",
       "          0.04400321,  0.05229125,  0.01095065, -0.00870052, -0.03604996,\n",
       "         -0.04916251,  0.04080125, -0.00271364, -0.05072665, -0.0311462 ,\n",
       "          0.05703933,  0.06175905, -0.02907855,  0.00433267,  0.03884365,\n",
       "          0.01420621, -0.01425387, -0.05296838, -0.02790373,  0.00133278,\n",
       "          0.00781487,  0.01623106,  0.03352382,  0.00952554, -0.0006716 ,\n",
       "         -0.03571875,  0.01972812, -0.04342207,  0.02677779, -0.00826673,\n",
       "          0.0267065 , -0.05285612,  0.05813214, -0.02585937, -0.04427554,\n",
       "         -0.04789763,  0.0179667 , -0.04315333, -0.02300901, -0.04224576,\n",
       "          0.00336402,  0.03156571], dtype=float32)},\n",
       " {'topic_idx': 27,\n",
       "  'topic_words': array(['probabilistic', '분포', 'probability', 'distribution',\n",
       "         'distributions', 'statistical', '확률', 'distributed',\n",
       "         'statistically', 'variance', 'covariance', 'variances',\n",
       "         'statistic', 'statistics', 'randomized', 'scatterplot',\n",
       "         'multivariate', 'exponential', 'coefficient', 'approximation',\n",
       "         '통계청', 'probabilities', 'gaussian', 'discrete', 'computationally',\n",
       "         'median', 'coefficients', 'computation', '통계', 'uniformity',\n",
       "         'calculation', 'mathematical', 'divergence', 'stochastic',\n",
       "         'predictive', 'proportional', 'numpy', 'calculations',\n",
       "         'hypothesis', 'computed', 'mathematics', '추정', 'theorem',\n",
       "         'predictor', 'computational', 'random', 'asymptotic',\n",
       "         'differential', 'convergence', 'predicts'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.48300147e-02, -1.02132568e-02, -9.30313487e-03, -1.08323293e-03,\n",
       "         -1.34143345e-02,  2.38540806e-02,  8.07906594e-03, -1.77853741e-04,\n",
       "          5.02386689e-02,  1.10848583e-02,  1.82856340e-02,  2.15929877e-02,\n",
       "          3.94055657e-02,  2.84955464e-02, -5.89306578e-02, -6.07079593e-04,\n",
       "         -1.76810734e-02, -7.00017577e-03,  4.17054929e-02,  4.94140089e-02,\n",
       "         -5.49110444e-03, -2.16157641e-02, -1.73716303e-02,  3.34404893e-02,\n",
       "         -4.69737090e-02,  1.34113515e-02, -1.04753925e-02, -2.46943384e-02,\n",
       "         -2.45073847e-02, -3.22976559e-02, -5.86095229e-02,  2.78619193e-02,\n",
       "          3.02408524e-02, -5.28232157e-02,  4.57409769e-04, -7.20642321e-03,\n",
       "         -5.37183806e-02, -5.49403317e-02, -4.72245179e-03, -6.42268034e-03,\n",
       "          4.17300984e-02,  4.68894374e-04,  2.61705872e-02, -2.31843125e-02,\n",
       "         -4.27545514e-03, -3.91283631e-02,  2.94558499e-02, -1.13841062e-02,\n",
       "         -5.18172830e-02, -2.80023110e-03, -8.73954035e-03, -3.96202542e-02,\n",
       "          2.75617093e-03,  2.57520173e-02,  5.72497360e-02, -5.57058267e-02,\n",
       "          5.62032359e-03,  3.12370695e-02, -3.18699032e-02,  1.82248838e-02,\n",
       "          4.68551274e-03,  4.28463630e-02,  4.95675653e-02, -2.20558159e-02,\n",
       "          2.04840489e-02,  2.18541957e-02,  1.66954901e-02,  6.54370151e-03,\n",
       "          3.36416773e-02,  2.00630128e-02, -1.12862503e-02, -3.64195183e-02,\n",
       "         -1.99517962e-02, -2.19601803e-02, -3.71208079e-02, -3.22143771e-02,\n",
       "          2.35415529e-02, -1.12894634e-02, -2.50656647e-03, -5.48944250e-02,\n",
       "         -5.39836250e-02, -3.06297392e-02, -1.52525026e-02,  2.94975843e-02,\n",
       "         -1.21075697e-02, -3.36531401e-02, -5.67195117e-02, -4.25019711e-02,\n",
       "         -4.84536104e-02, -4.98315990e-02, -3.21483910e-02, -5.71151823e-03,\n",
       "          1.04112495e-02, -5.40909097e-02,  4.16291989e-02,  5.24013191e-02,\n",
       "          1.49963535e-02,  2.98312935e-03,  4.10604738e-02, -6.02309592e-05,\n",
       "          5.17003685e-02,  2.10297061e-03,  3.04312650e-02, -2.44859252e-02,\n",
       "         -1.07789086e-02, -5.82607873e-02, -3.11665256e-02, -3.49818356e-02,\n",
       "          2.54398938e-02,  5.66038713e-02,  5.06952368e-02, -5.30929118e-02,\n",
       "         -4.52326760e-02,  1.99427661e-02,  3.43017317e-02,  3.30830440e-02,\n",
       "          2.19658017e-02,  2.40349285e-02, -4.91200835e-02, -9.89995897e-06,\n",
       "         -3.76655608e-02,  4.49669808e-02,  1.39021501e-02,  2.01675817e-02,\n",
       "          6.90786587e-03,  5.49929449e-03, -4.79248352e-02,  7.01656565e-03,\n",
       "         -4.11188230e-02,  2.63492856e-02, -5.41735925e-02,  3.21253911e-02,\n",
       "          5.58278337e-02,  8.45751911e-03, -2.46065110e-02,  3.74471135e-02,\n",
       "          2.71938276e-03,  6.58193044e-03,  5.25526367e-02, -3.58419195e-02,\n",
       "          5.39652118e-03, -2.11720653e-02,  5.00536561e-02, -2.32401062e-02,\n",
       "          3.76245454e-02,  8.93250573e-03, -2.45973542e-02,  1.15223005e-02,\n",
       "          2.60467790e-02,  4.99337837e-02,  3.14424820e-02, -4.04963968e-03,\n",
       "         -3.94323468e-03, -5.05045243e-02,  3.30611020e-02, -8.84490088e-03,\n",
       "         -1.85088608e-02, -7.22850114e-03,  3.25051807e-02,  4.56308350e-02,\n",
       "          5.12759648e-02, -1.09545421e-02,  1.67625584e-02, -2.30873600e-02,\n",
       "         -2.46440340e-02, -3.66858672e-03, -1.66314363e-03, -1.66865680e-02,\n",
       "          3.21765468e-02,  4.54647318e-02, -3.16905491e-02,  4.06262167e-02,\n",
       "          1.29992180e-02,  2.27872599e-02,  4.66517312e-03,  4.88036610e-02,\n",
       "          3.01984213e-02,  9.84537788e-03, -3.77482697e-02,  8.23218934e-03,\n",
       "          4.80613951e-03, -2.79375520e-02, -1.58134066e-02,  2.55256612e-02,\n",
       "         -4.07045595e-02, -2.78558321e-02,  3.84580828e-02,  4.64577600e-02,\n",
       "          3.02579012e-02, -4.94237021e-02, -8.91664810e-03,  6.55102078e-03,\n",
       "          5.29538617e-02, -1.82377975e-02,  1.14407353e-02,  1.70015804e-02,\n",
       "         -5.35213575e-02, -4.55465913e-02,  4.08537872e-02, -2.13350467e-02,\n",
       "         -1.21651813e-02,  5.46548376e-03, -1.60582736e-02, -2.14335658e-02,\n",
       "         -1.14976978e-02, -3.42347845e-02, -2.55268347e-02,  3.25171277e-06,\n",
       "         -1.77751444e-02,  2.35216040e-02, -1.50508480e-03,  1.56831071e-02,\n",
       "         -5.89637570e-02,  1.55093195e-03,  4.76413779e-03, -7.60752987e-03,\n",
       "          1.94192305e-02, -1.45805301e-02,  1.02505125e-02,  6.29514270e-03,\n",
       "         -3.24533023e-02, -1.63680632e-02,  4.08740640e-02, -6.64061541e-03,\n",
       "         -5.01005650e-02,  1.32758403e-03, -5.01234494e-02,  1.35036204e-02,\n",
       "          2.56115142e-02,  2.87298057e-02,  1.70630086e-02,  5.49583361e-02,\n",
       "         -3.06893815e-03, -3.32050361e-02, -1.07151223e-02, -1.34317484e-02,\n",
       "          1.09054577e-02,  3.88066769e-02,  9.71597619e-03,  2.99150012e-02,\n",
       "          3.48029193e-03, -4.05034199e-02,  2.15583239e-02,  2.63095908e-02,\n",
       "          3.57482582e-02, -1.99820939e-02,  2.12982856e-02, -1.23724863e-02,\n",
       "         -1.94730628e-02,  1.79156549e-02, -4.03273478e-02, -3.30328383e-02,\n",
       "         -4.06103721e-03,  1.86363645e-02, -4.86488901e-02, -1.42587274e-02,\n",
       "          3.58865876e-03, -3.46077532e-02, -2.75729708e-02,  3.04528465e-03,\n",
       "          2.56904159e-02,  3.70385908e-02, -1.23932706e-02, -1.83466412e-02,\n",
       "          3.61580998e-02, -4.07123007e-02,  8.11652467e-03, -1.29995178e-02,\n",
       "         -5.29235974e-03,  3.88906822e-02, -3.18584889e-02, -2.17941254e-02,\n",
       "         -3.24125513e-02, -4.65211347e-02, -2.88331173e-02,  4.70678555e-03,\n",
       "         -2.64271908e-02,  6.00741524e-03, -4.40294333e-02, -1.25967665e-02,\n",
       "         -3.31004299e-02,  3.25879604e-02,  2.54201535e-02,  3.87770310e-02,\n",
       "         -2.89385356e-02,  1.23488177e-02, -2.76947320e-02, -3.25085595e-02,\n",
       "          1.27365673e-03, -1.16542652e-02, -2.22118013e-02,  3.36072817e-02,\n",
       "          2.17035189e-02,  1.00420648e-02, -3.41390297e-02,  7.15975976e-03,\n",
       "         -3.43296826e-02, -1.95051804e-02,  5.58510609e-02,  4.76250760e-02,\n",
       "         -5.55648208e-02,  2.30794884e-02, -3.10146790e-02, -4.93002422e-02,\n",
       "         -5.80516495e-02,  1.81616191e-03,  4.45418879e-02, -2.43935678e-02,\n",
       "         -1.40851652e-02,  1.75165068e-02, -1.16872287e-03, -4.20074649e-02,\n",
       "         -5.61482459e-02, -4.23574112e-02,  2.95817908e-02,  3.98073308e-02,\n",
       "         -5.75813465e-06, -3.73447686e-02,  1.48403272e-02, -4.18141037e-02,\n",
       "          8.99314042e-03,  1.99179184e-02, -4.90014292e-02,  3.74039970e-02,\n",
       "         -3.12316623e-02,  2.47770119e-02, -4.75629419e-02, -1.29675334e-02,\n",
       "          2.89493073e-02, -1.29212653e-02, -4.33865935e-02, -3.26032974e-02,\n",
       "          2.49271635e-02, -2.34436598e-02,  2.67774449e-03, -1.51279951e-02,\n",
       "          1.83534231e-02,  2.31751986e-02, -5.48417531e-02, -5.23899309e-02,\n",
       "         -1.23311020e-02,  6.45171292e-03,  1.78365279e-02,  1.77889969e-02,\n",
       "          8.51399638e-03,  4.72148359e-02,  2.72993483e-02, -1.72525384e-02,\n",
       "          5.06835803e-03,  4.02173623e-02,  2.90091299e-02,  2.81541795e-02,\n",
       "         -8.68092012e-03,  7.19786808e-03,  1.82805434e-02,  2.40826607e-02,\n",
       "         -2.33869441e-02,  9.49936267e-03, -2.60299668e-02, -1.74022987e-02,\n",
       "          3.52605321e-02, -5.49162179e-02,  4.63476330e-02, -2.39307079e-02,\n",
       "         -4.26697433e-02,  2.65345499e-02, -3.63301020e-03,  2.63220370e-02,\n",
       "         -1.29769817e-02,  2.71158610e-02,  2.36813333e-02,  4.78625447e-02,\n",
       "          9.60360654e-03,  3.83594632e-02,  1.75440162e-02, -3.44619006e-02,\n",
       "          1.20139439e-02, -3.31591815e-03, -5.45809940e-02, -4.82160226e-02,\n",
       "          3.63612697e-02, -4.60651629e-02,  3.04249786e-02,  1.55124562e-02,\n",
       "         -1.46365669e-02,  5.62491715e-02,  4.11938429e-02, -4.64328714e-02,\n",
       "          3.68799567e-02,  3.01672388e-02, -1.27133988e-02,  5.40246675e-03,\n",
       "         -4.69610468e-03,  3.02541647e-02, -2.58196462e-02,  2.41510682e-02,\n",
       "          3.20381671e-02,  2.47313231e-02, -2.36261562e-02,  2.34686527e-02,\n",
       "          2.55881939e-02,  4.93824147e-02,  5.64823262e-02,  1.99073516e-02,\n",
       "         -3.55828181e-02,  3.46620157e-02, -3.36446427e-03, -3.83735672e-02,\n",
       "         -2.09283680e-02, -1.29240341e-02,  1.60121731e-03, -1.28739793e-03,\n",
       "          2.33253278e-02, -1.79535225e-02,  9.58206598e-03,  3.97808701e-02,\n",
       "         -7.21087307e-03,  2.74636485e-02,  3.52133587e-02,  3.94257382e-02,\n",
       "         -2.30336040e-02, -5.73935285e-02, -3.92504930e-02,  5.43622933e-02,\n",
       "          5.30057624e-02,  1.89296007e-02, -9.06460546e-03, -1.60195027e-02,\n",
       "          2.61228140e-02, -4.10871655e-02, -9.98203643e-03,  3.02870683e-02,\n",
       "         -2.95890160e-02, -3.58058028e-02,  4.64974977e-02,  2.22070795e-02,\n",
       "          4.88334568e-03,  3.37080583e-02, -5.74365146e-02, -2.23402772e-03,\n",
       "         -3.09783649e-02, -1.83752435e-03, -3.62107009e-02, -5.48670106e-02,\n",
       "          5.45356385e-02, -2.56465115e-02,  3.73052657e-02, -2.97858217e-03,\n",
       "          1.98408160e-02,  3.82492840e-02, -1.71074681e-02,  2.89761424e-02,\n",
       "          2.60192975e-02, -2.76059285e-02, -5.54112084e-02, -3.26817110e-02,\n",
       "          3.37167340e-03,  3.06790639e-02,  2.69672684e-02,  5.44515774e-02,\n",
       "         -1.98007561e-04, -1.46476496e-02,  3.56050022e-02, -5.59686050e-02,\n",
       "          4.85353246e-02, -5.54472879e-02, -2.02797614e-02, -4.88644801e-02,\n",
       "          5.47793210e-02, -1.19994562e-02,  3.39887589e-02, -1.44160995e-02,\n",
       "         -3.86115164e-02,  4.56579402e-02, -4.13347520e-02, -1.66442841e-02,\n",
       "          2.51282658e-03, -4.78334725e-02, -1.30123943e-02, -2.65323892e-02,\n",
       "          3.01035456e-02,  5.04500940e-02, -1.36185726e-02, -2.57891715e-02,\n",
       "          4.91168946e-02,  4.18765396e-02,  1.21572930e-02, -5.65659627e-02,\n",
       "          8.44505057e-03,  7.72980042e-03,  6.14564354e-03, -2.91502886e-02,\n",
       "          4.27133441e-02, -1.35305955e-03, -8.98658298e-04, -1.79885663e-02,\n",
       "          4.36447561e-04, -4.35408391e-03,  3.49862762e-02,  1.92519231e-03,\n",
       "          3.00891511e-02, -5.50972298e-02,  5.60244918e-02,  7.72677176e-03,\n",
       "         -3.10064312e-02, -5.09424768e-02,  3.46236527e-02, -4.49443460e-02,\n",
       "         -2.32959315e-02, -3.23798656e-02, -2.20015030e-02,  3.00182290e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 28,\n",
       "  'topic_words': array(['mathbf', 'mathematics', 'mathrm', 'matlab', '수학', 'mathematical',\n",
       "         'math', 'mathcal', 'calculation', 'nonlinear', 'calculations',\n",
       "         'geometric', 'computational', 'asymptotic', 'nonparametric', '선형',\n",
       "         'computation', 'computationally', 'parametric', 'symmetric',\n",
       "         'computed', 'linearity', 'probabilistic', 'gaussian', 'matrices',\n",
       "         'coefficient', 'theorem', 'calculated', 'linear', 'calculating',\n",
       "         'coefficients', 'calculate', 'matplotlib', 'lineplot',\n",
       "         'statistics', 'scatterplot', 'numerical', '계산', 'statistical',\n",
       "         'curve', '방정식', '알고리즘', 'morphometry', 'mathbb', 'quadratic',\n",
       "         'exponential', 'graph', 'statistically', 'estimator',\n",
       "         'multiplication'], dtype='<U15'),\n",
       "  'topic_vector': array([-4.55291271e-02, -3.69782448e-02, -3.26697193e-02, -3.83162335e-03,\n",
       "         -1.48466080e-02,  2.80055795e-02,  3.02872509e-02,  2.24264245e-02,\n",
       "          4.99503314e-02,  1.89315248e-02,  8.18970054e-03,  9.28276218e-03,\n",
       "          3.19511071e-02,  1.80742200e-02, -5.35205193e-02, -2.30585206e-02,\n",
       "         -1.31092174e-02, -3.80304456e-02,  3.25511992e-02,  4.69124950e-02,\n",
       "         -1.64021067e-02, -2.19402779e-02,  9.78981983e-03,  3.40441093e-02,\n",
       "         -4.32511382e-02, -2.18499545e-02,  5.26135154e-02, -5.20071713e-03,\n",
       "          9.29365028e-03, -4.28644828e-02, -5.35178818e-02, -4.27990500e-03,\n",
       "          4.00527287e-03, -5.31541184e-02,  3.84368561e-02, -1.20254578e-02,\n",
       "         -2.23242603e-02, -3.60942855e-02,  2.55478863e-02, -1.99715495e-02,\n",
       "         -2.83557642e-02, -3.76426913e-02,  2.50232983e-02, -3.66847217e-02,\n",
       "          2.35643610e-03, -2.16208603e-02,  4.73639965e-02, -1.46337831e-02,\n",
       "         -1.66178141e-02, -4.71081166e-03,  4.46717109e-04, -9.16358829e-03,\n",
       "          4.30782139e-02,  8.75403266e-03,  3.69207039e-02, -5.33936433e-02,\n",
       "          1.53755778e-02,  1.59653998e-03,  5.68946172e-03,  2.32578609e-02,\n",
       "          9.54387151e-03,  4.05232199e-02,  3.55848484e-02, -8.20422079e-03,\n",
       "          2.25872397e-02, -2.76429038e-02, -1.62796844e-02,  1.03502870e-02,\n",
       "          4.29094136e-02,  4.79218885e-02, -3.22658606e-02,  3.32586914e-02,\n",
       "          1.48037011e-02, -2.28627939e-02, -4.94253710e-02, -1.26539599e-02,\n",
       "          2.35151518e-02,  3.09726950e-02, -1.30923735e-02, -5.35238944e-02,\n",
       "         -5.35251535e-02, -1.84591617e-02, -2.33648671e-03,  1.85313709e-02,\n",
       "          1.78308152e-02, -2.14162823e-02, -2.02674586e-02, -3.44851874e-02,\n",
       "         -4.18765247e-02, -3.16147991e-02, -2.53331363e-02, -1.14597091e-02,\n",
       "         -4.12563682e-02, -4.68709059e-02,  4.74892966e-02,  3.18643041e-02,\n",
       "          4.97179814e-02,  1.19670331e-02,  3.01749371e-02, -3.51122878e-02,\n",
       "          5.35004027e-02,  3.84854674e-02,  4.35626172e-02, -3.12773883e-02,\n",
       "          1.89143661e-02, -3.69654335e-02,  1.43616004e-02, -2.31147110e-02,\n",
       "          3.63786221e-02,  4.63752113e-02,  2.49495246e-02, -3.64065589e-03,\n",
       "         -4.38838527e-02,  2.27244794e-02,  2.33607572e-02, -1.31898690e-02,\n",
       "         -2.86157560e-02,  1.33211790e-02, -5.24498746e-02,  1.59673933e-02,\n",
       "         -6.12351578e-03,  4.05801870e-02,  3.31307319e-03,  3.76184797e-03,\n",
       "          2.27402654e-02,  3.17119434e-02, -3.99952754e-02,  3.71506475e-02,\n",
       "          2.23697182e-02,  3.51378135e-02, -4.79465462e-02,  2.29768045e-02,\n",
       "          3.96899320e-02,  1.35354195e-02,  9.74647421e-03,  2.79625189e-02,\n",
       "          4.11994848e-03,  1.87478624e-02,  5.06850779e-02,  4.40218579e-03,\n",
       "          3.76277491e-02, -2.89998366e-03,  3.66970226e-02, -3.44828144e-02,\n",
       "          5.09467013e-02, -3.82061899e-02, -2.37760879e-02, -1.29623860e-02,\n",
       "          2.31478848e-02,  2.35022604e-02,  7.96484202e-03,  2.05772687e-02,\n",
       "         -3.06795258e-02, -3.49546932e-02,  3.69092226e-02, -3.47438976e-02,\n",
       "          1.27423955e-02,  1.93592776e-02, -3.01666316e-02, -4.55693901e-03,\n",
       "          4.08595167e-02, -9.10970289e-03, -1.72232669e-02, -2.54654847e-02,\n",
       "         -2.73852441e-02,  1.27168465e-02,  4.07295069e-03, -1.76727809e-02,\n",
       "          1.93026048e-04,  4.03706692e-02,  2.99307872e-02, -1.13614891e-02,\n",
       "          3.09745204e-02,  4.88040186e-02, -2.55012754e-02,  3.30912024e-02,\n",
       "          2.77115535e-02,  2.09859349e-02, -1.41026424e-02,  1.06487563e-02,\n",
       "          4.22485769e-02, -3.05208266e-02, -2.35782880e-02, -6.10520248e-04,\n",
       "         -5.22781536e-02, -3.34479138e-02,  4.66844551e-02,  5.28912432e-02,\n",
       "          4.63391561e-03, -4.23250273e-02,  1.95368426e-03,  5.60494955e-04,\n",
       "          3.67610194e-02, -1.46730514e-02,  4.92266333e-03,  4.41361852e-02,\n",
       "         -5.35214543e-02, -1.82764772e-02,  4.82905693e-02,  2.68377755e-02,\n",
       "         -1.97844654e-02,  5.82201313e-03, -4.09216210e-02, -3.24828923e-03,\n",
       "          1.74897478e-03, -5.79741178e-03, -2.69063376e-02,  5.33685274e-02,\n",
       "         -5.14566265e-02, -6.69150474e-03, -1.72044467e-02, -2.72760657e-03,\n",
       "         -5.35251535e-02, -1.08641367e-02,  2.64244676e-02, -3.49018350e-02,\n",
       "         -1.57274920e-02, -2.01401412e-02,  1.41747529e-02,  1.37456516e-02,\n",
       "          3.95041751e-03,  2.77912114e-02,  2.93937270e-02, -3.39195179e-03,\n",
       "         -4.60979640e-02,  1.12676872e-02, -3.58597301e-02,  1.38592506e-02,\n",
       "          2.96260528e-02,  3.83341610e-02, -2.83605196e-02,  5.35035394e-02,\n",
       "          6.44374546e-03,  2.62835668e-03, -3.10353003e-02,  1.57285575e-02,\n",
       "         -1.21245813e-02,  1.75717026e-02, -3.54352035e-02,  2.60017021e-03,\n",
       "         -1.46881258e-02, -6.44483929e-03, -5.86357247e-03,  1.89052685e-03,\n",
       "          4.03653160e-02, -5.89355407e-03,  1.70853082e-02,  8.10766220e-03,\n",
       "          4.43551242e-02,  3.38095538e-02, -2.95648240e-02, -2.71386504e-02,\n",
       "          3.50254923e-02,  1.11187678e-02, -2.55077183e-02,  1.66082066e-02,\n",
       "          1.18517000e-02,  6.51401794e-03, -2.31975112e-02, -7.98807479e-03,\n",
       "          8.24896526e-03,  2.31911298e-02, -4.39401390e-03, -4.08233282e-05,\n",
       "          4.59122881e-02, -4.87453640e-02, -2.61107348e-02, -2.34076176e-02,\n",
       "         -2.85569821e-02,  1.37627339e-02,  4.52047586e-03, -3.74450609e-02,\n",
       "         -4.52419482e-02, -5.34584932e-02,  2.37943814e-03,  4.71854210e-02,\n",
       "         -5.29781692e-02,  3.91140878e-02, -5.09756282e-02,  2.53232773e-02,\n",
       "         -4.86484580e-02, -7.73371314e-04,  3.53338309e-02,  3.33394445e-02,\n",
       "         -2.41490062e-02,  2.99827009e-02, -4.72046398e-02, -8.60196166e-03,\n",
       "         -2.19392348e-02,  1.04428362e-02,  4.64810468e-02,  3.03569995e-02,\n",
       "          1.21654849e-02,  5.16982600e-02, -3.22865471e-02,  3.00260466e-02,\n",
       "         -4.78772447e-02,  2.63260175e-02,  3.42066474e-02,  4.20769118e-02,\n",
       "         -2.06637532e-02,  2.28197314e-02, -4.56767045e-02, -5.28943762e-02,\n",
       "         -5.35251498e-02,  1.32616265e-02,  9.18805075e-04, -8.49517877e-04,\n",
       "         -3.54573764e-02,  1.14958500e-02, -2.24725511e-02, -1.30068907e-03,\n",
       "         -3.71531770e-02, -4.44203354e-02,  1.60411410e-02,  1.79248583e-02,\n",
       "          3.70454267e-02, -4.97232154e-02, -6.81523094e-03, -1.10791577e-02,\n",
       "          1.26853818e-02,  2.41122805e-02, -3.39247063e-02,  4.18472519e-05,\n",
       "          4.16080875e-04,  1.51532311e-02, -1.17862439e-02,  1.42636904e-02,\n",
       "         -3.10623664e-02, -2.20132452e-02, -4.97860387e-02, -2.15066634e-02,\n",
       "          4.15841527e-02, -6.08703261e-03,  3.30720916e-02,  1.39436852e-02,\n",
       "         -2.86669862e-02, -1.23561639e-02, -2.81477999e-02, -1.99356396e-02,\n",
       "         -3.94323990e-02, -1.12700360e-02,  2.07387675e-02,  6.83803763e-03,\n",
       "         -1.22989118e-02,  3.00214384e-02,  3.42033468e-02,  3.87409166e-03,\n",
       "         -1.91169791e-02,  1.05778947e-02,  5.00868596e-02, -1.16700828e-02,\n",
       "         -3.82471085e-02,  2.43317080e-03,  6.98523875e-03,  5.15064560e-02,\n",
       "         -2.61043459e-02,  3.40907350e-02, -4.15163599e-02, -1.06717991e-02,\n",
       "         -1.28689837e-02, -5.18660583e-02,  1.86823513e-02, -1.58577096e-02,\n",
       "         -4.29635048e-02,  3.45592462e-02, -8.58846679e-03,  3.04658990e-02,\n",
       "         -5.14352098e-02,  3.51080932e-02,  3.52209434e-02,  8.21093470e-03,\n",
       "         -1.71471946e-02,  5.13874181e-02, -1.35664435e-04,  1.35015668e-02,\n",
       "         -3.01237553e-02,  2.00693309e-02, -5.34143820e-02, -3.54975797e-02,\n",
       "          3.06673367e-02, -3.26705314e-02,  2.44331229e-02,  2.53689382e-02,\n",
       "         -3.28894444e-02,  4.26711813e-02, -8.33559257e-04, -5.33599183e-02,\n",
       "          5.14476635e-02,  2.25522853e-02, -2.92336363e-02,  2.81923618e-02,\n",
       "          4.68548480e-03,  4.14378904e-02, -2.81156190e-02, -4.42798017e-03,\n",
       "          1.00400252e-02, -1.55650824e-02, -4.49804403e-02, -3.98100307e-03,\n",
       "          5.88783575e-03,  2.19643582e-02,  4.45449650e-02, -6.93478668e-03,\n",
       "         -8.10323283e-03,  1.30961770e-02, -5.80759021e-03, -4.97776866e-02,\n",
       "          1.90539416e-02,  3.47043537e-02,  7.55210686e-03,  7.39717763e-03,\n",
       "          3.13201360e-02, -1.07001541e-02,  4.77966629e-02,  1.31690213e-02,\n",
       "          3.20188177e-04,  5.09706102e-02,  3.22611518e-02,  2.48844456e-02,\n",
       "          2.92447470e-02, -5.29760160e-02, -6.69103954e-03,  3.83906625e-02,\n",
       "          5.26753925e-02,  3.38312313e-02,  1.68743189e-02, -3.21354554e-03,\n",
       "          9.34528001e-03, -1.24698430e-02, -7.12638255e-03, -3.18957755e-04,\n",
       "         -3.46630439e-03,  2.77963444e-03,  3.40733416e-02,  4.00019027e-02,\n",
       "         -2.33161007e-03,  2.29829699e-02, -5.21884486e-02,  2.32348479e-02,\n",
       "         -5.00636101e-02,  1.25240367e-02, -4.75004278e-02, -5.23445196e-02,\n",
       "          8.04524403e-03, -4.06417511e-02,  5.28537221e-02, -7.13327434e-03,\n",
       "          3.51893716e-02,  2.41564997e-02, -2.10376866e-02,  2.90090982e-02,\n",
       "         -1.48531245e-02, -1.10973846e-02, -3.97839174e-02, -1.57971215e-02,\n",
       "         -2.89221834e-02,  3.79441492e-02,  3.55895832e-02,  5.14297746e-02,\n",
       "          1.05952928e-02, -6.43187109e-03,  4.62028645e-02, -4.52111475e-02,\n",
       "          5.34881949e-02, -4.48779762e-02, -2.95639373e-02, -1.97624210e-02,\n",
       "          5.32630458e-02, -2.89459731e-02,  3.61063853e-02,  2.32679788e-02,\n",
       "         -5.29210009e-02,  3.01573239e-02, -5.21341003e-02, -2.04453282e-02,\n",
       "          3.59578207e-02, -4.90894429e-02,  1.05119031e-02, -1.75603032e-02,\n",
       "         -1.70736969e-03,  4.95439842e-02, -2.14118026e-02,  1.88587606e-03,\n",
       "          3.58119011e-02,  2.23601963e-02,  3.59840915e-02, -5.18549308e-02,\n",
       "         -2.78199208e-03,  3.08020432e-02,  3.11385095e-02,  7.68516818e-03,\n",
       "          2.18607448e-02,  2.39584111e-02,  1.51008172e-02, -3.72597612e-02,\n",
       "         -1.87308043e-02,  1.14854472e-02,  1.54998694e-02,  1.12294024e-02,\n",
       "          4.05194350e-02, -2.37393174e-02,  5.31640351e-02,  2.07883120e-02,\n",
       "         -2.20858026e-02, -3.61854956e-02,  1.91908441e-02, -2.73127891e-02,\n",
       "         -2.89185136e-03, -3.33435945e-02, -1.83069985e-02,  2.91103236e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 29,\n",
       "  'topic_words': array(['chrome', 'browser', '크롬', '브라우저', 'firefox', 'mozilla',\n",
       "         'javascript', 'webgl', 'safari', 'webdriver', 'selenium', 'proxy',\n",
       "         'urllib', 'html', 'khtml', 'css', 'extension', '홈페이지', 'url',\n",
       "         'xorg', 'google', 'linewidth', 'varlambda', 'web', 'toolkit', '구글',\n",
       "         'applewebkit', 'websites', 'bootstrap', 'unicode', 'supported',\n",
       "         'github', 'ctrl', 'protocol', 'covid', 'reliable', 'compatible',\n",
       "         'div', 'createpage', 'multiprocessing', 'sites', 'ubuntu',\n",
       "         'plugins', 'dataframe', 'java', 'optimization', 'compatibility',\n",
       "         '인터넷', 'darknet', 'optimized'], dtype='<U15'),\n",
       "  'topic_vector': array([-2.83456985e-02,  1.46043738e-02, -1.42146870e-02, -1.77511759e-02,\n",
       "         -5.93517022e-03, -6.08881861e-02,  2.24254001e-02,  7.22983433e-03,\n",
       "          3.40970382e-02, -8.94297194e-03, -1.40857510e-02, -1.00585101e-02,\n",
       "          3.61084230e-02, -4.58072312e-02,  3.90576161e-02,  4.30642962e-02,\n",
       "          1.65724624e-02, -1.43801272e-02,  7.34661473e-03,  4.06282581e-02,\n",
       "          3.60175930e-02,  3.75172459e-02, -2.32986975e-02,  4.18026261e-02,\n",
       "         -5.53082116e-02, -5.77533133e-02,  1.85155179e-02,  1.15290778e-02,\n",
       "         -6.74355626e-02, -3.56060974e-02,  1.41224610e-02, -6.33518072e-03,\n",
       "          3.25913616e-02, -5.60093969e-02, -2.68302988e-02,  5.33531746e-03,\n",
       "          6.24036305e-02, -1.62656028e-02,  3.59361954e-02, -3.24923731e-02,\n",
       "         -3.87126096e-02, -1.17092682e-02,  2.07291115e-02, -4.31607999e-02,\n",
       "          1.79038271e-02, -1.46410652e-02,  1.17854709e-02, -2.13431870e-03,\n",
       "         -3.43988538e-02,  2.18699966e-02, -1.23360278e-02,  1.25111574e-02,\n",
       "          6.23157173e-02, -2.90810261e-02,  1.02490222e-03, -3.13833691e-02,\n",
       "          2.51432713e-02, -1.22773892e-03,  1.10170171e-02,  7.73896091e-03,\n",
       "          1.91441234e-02,  5.39607853e-02,  4.30854820e-02, -3.85300554e-02,\n",
       "          2.04886403e-02, -2.85023078e-02, -3.76578304e-03, -2.97292625e-03,\n",
       "          1.53726367e-02, -7.17044517e-04,  4.57768649e-04,  3.04853413e-02,\n",
       "         -1.69650707e-02, -1.58415865e-02, -1.08122183e-02,  1.48626538e-02,\n",
       "         -1.47149852e-02,  4.08874787e-02,  1.04279844e-02, -3.70172374e-02,\n",
       "         -6.68303072e-02, -4.81054522e-02, -3.28843854e-02,  2.72667338e-03,\n",
       "          1.68930124e-02,  3.63091938e-02,  3.99255985e-03, -2.58895904e-02,\n",
       "         -2.62576211e-02, -1.45787867e-02, -2.40283776e-02, -2.42638979e-02,\n",
       "         -3.94209512e-02,  4.19796370e-02,  5.82575947e-02, -2.17426103e-02,\n",
       "         -2.25866213e-03, -4.32360619e-02, -2.06794459e-02, -8.08819290e-03,\n",
       "          5.49403429e-02,  2.96562836e-02, -4.86015230e-02,  8.30260385e-03,\n",
       "          2.62311175e-02, -3.70560549e-02, -5.91647178e-02, -3.05488613e-02,\n",
       "          2.16571018e-02,  3.32390666e-02,  8.18310957e-03, -3.59131135e-02,\n",
       "          5.35856932e-04, -2.18490455e-02,  4.87600304e-02, -2.91698277e-02,\n",
       "         -2.53882948e-02, -3.30638438e-02, -9.85749345e-03, -2.75983084e-02,\n",
       "         -3.50542255e-02,  3.81315611e-02, -6.34407401e-02, -1.76649448e-03,\n",
       "          7.72498921e-03,  1.57260615e-02, -4.25078869e-02, -2.86488235e-02,\n",
       "         -4.01537679e-02, -5.60388854e-03, -4.53561880e-02,  9.02803987e-03,\n",
       "          6.64945990e-02, -2.71083470e-02,  8.43701046e-03,  5.20264842e-02,\n",
       "          9.00589395e-03, -3.14654596e-02,  4.23201807e-02,  2.86204200e-02,\n",
       "          6.47734618e-03,  6.22003945e-03, -4.01950814e-02,  4.34962548e-02,\n",
       "          2.65091751e-02,  1.98250879e-02, -2.85480712e-02,  2.68791150e-02,\n",
       "          7.70082185e-03,  3.35353278e-02,  5.41221059e-04,  7.46536814e-03,\n",
       "         -2.64066756e-02, -2.36588065e-02,  3.73106487e-02, -1.39051406e-02,\n",
       "          7.63875199e-03,  5.65259159e-03,  7.92715512e-03, -2.81949807e-02,\n",
       "          5.55196665e-02, -6.23516738e-03,  1.83007438e-02, -2.07541441e-03,\n",
       "          1.43081648e-04, -2.44036224e-02,  5.10835461e-02, -2.37152968e-02,\n",
       "         -1.11122308e-02,  1.41197639e-02, -1.27312271e-02,  1.63179357e-02,\n",
       "         -2.42511672e-03, -1.10743046e-02,  8.63401126e-03,  3.32691707e-02,\n",
       "         -3.98422964e-02,  1.30484225e-02, -2.34552566e-02,  3.43464576e-02,\n",
       "         -2.58782748e-02, -4.46418254e-03, -2.53347158e-02, -2.56268773e-02,\n",
       "         -3.50468606e-02, -8.98376293e-03,  2.93565020e-02,  3.94916795e-02,\n",
       "          2.45074946e-02,  5.80273457e-02, -3.91350454e-03, -2.30850633e-02,\n",
       "          1.10568302e-02,  2.91022658e-03, -4.68023733e-04,  2.51122285e-02,\n",
       "          4.71579023e-02, -2.96888705e-02,  3.05849854e-02, -1.43340072e-02,\n",
       "          5.87288802e-03,  2.32556518e-02, -1.74902063e-02, -5.38904173e-03,\n",
       "         -1.05200456e-02, -6.37832982e-03,  3.37078683e-02,  1.62215605e-02,\n",
       "          1.58289950e-02,  2.03888025e-02, -1.08686658e-02,  1.73281003e-02,\n",
       "          2.13078987e-02, -1.15344645e-02,  3.26427035e-02,  3.71122360e-02,\n",
       "          1.77687909e-02,  1.02728466e-02, -6.29381323e-03,  2.69978717e-02,\n",
       "         -1.85934696e-02,  4.50241305e-02,  3.71919014e-02,  2.35712994e-02,\n",
       "         -5.42683713e-02, -3.00578331e-03, -4.60991450e-02, -1.33079141e-02,\n",
       "          1.45086991e-02,  2.93825939e-03, -2.20558494e-02,  4.71840240e-02,\n",
       "          3.76239233e-02,  6.37958385e-03, -2.04442739e-02,  1.47943581e-02,\n",
       "          3.04991063e-02,  3.32867317e-02,  2.61165556e-02, -2.25648787e-02,\n",
       "         -3.64362113e-02,  5.51857101e-03, -1.84709672e-02, -2.50107679e-03,\n",
       "          1.46323321e-02, -3.80158201e-02,  1.67840626e-02,  3.95627081e-04,\n",
       "         -4.95750345e-02, -8.09888262e-03, -2.87165735e-02, -1.01112192e-02,\n",
       "         -4.48305570e-02, -4.72403951e-02,  3.17341387e-02, -2.24984232e-02,\n",
       "          3.92504828e-03,  6.56447187e-02, -4.85741831e-02, -7.14458851e-03,\n",
       "          8.87375232e-03,  2.80280244e-02, -4.69920970e-02, -4.44065928e-02,\n",
       "          3.25191654e-02, -1.70408189e-02, -2.39342283e-02,  1.82892960e-02,\n",
       "         -3.52536254e-02,  1.24892993e-02, -3.14511475e-03, -2.02020127e-02,\n",
       "         -1.81045756e-02,  5.11158109e-02,  2.96906587e-02,  1.24197230e-02,\n",
       "         -5.73206553e-03, -1.23023288e-02, -1.88757759e-02,  2.66002696e-02,\n",
       "         -3.03000212e-03,  1.91457495e-02, -3.15636732e-02, -4.98626567e-02,\n",
       "         -4.56401408e-02, -4.68056090e-02, -4.24879491e-02, -2.72843931e-02,\n",
       "         -2.26311404e-02, -1.91240478e-02, -3.59385796e-02,  1.50643410e-02,\n",
       "         -2.25121882e-02,  4.53012548e-02, -6.72924295e-02,  5.16582280e-02,\n",
       "         -6.33169860e-02,  6.31336421e-02, -2.20044553e-02,  1.57305878e-02,\n",
       "          7.67118006e-04,  1.64982192e-02, -3.65994126e-02, -4.00965400e-02,\n",
       "         -1.33465426e-02,  1.17189540e-02,  1.47812255e-03, -1.17812036e-02,\n",
       "         -9.02234111e-03,  3.20639871e-02,  2.38492582e-02, -1.42352050e-02,\n",
       "         -6.31281509e-05,  4.11912939e-03,  1.87591149e-03,  1.39075620e-02,\n",
       "          4.36437093e-02, -1.42266452e-02,  2.76487395e-02,  1.11658769e-02,\n",
       "         -8.39760806e-03,  2.32499037e-02, -2.34267339e-02, -2.78887842e-02,\n",
       "          1.04804831e-02, -1.91320162e-02,  8.00149795e-03, -2.63910349e-02,\n",
       "         -4.24767239e-03, -1.86482407e-02, -1.43632218e-02, -2.52884999e-02,\n",
       "         -2.47262660e-02, -2.57395674e-02,  1.41738085e-02,  2.27480326e-02,\n",
       "          1.67799331e-02,  1.23234587e-02, -5.42102419e-02, -1.58919243e-03,\n",
       "          8.48027412e-03,  1.90681152e-04, -1.72216650e-02, -8.32070690e-03,\n",
       "          2.59701815e-02,  2.17105728e-02,  1.77408215e-02,  2.11221352e-02,\n",
       "         -2.55068708e-02,  5.61339296e-02, -6.14307560e-02,  3.38826217e-02,\n",
       "         -2.16793809e-02, -2.32742075e-02, -3.70780868e-03, -3.49076241e-02,\n",
       "         -5.75383045e-02,  1.94635969e-02,  2.09608003e-02, -3.66271362e-02,\n",
       "         -1.85621623e-02, -5.46778850e-02,  2.74726804e-02, -1.05020804e-02,\n",
       "          7.84637406e-04, -2.18065754e-02,  2.74425689e-02,  3.50624323e-02,\n",
       "         -5.25649637e-02,  9.32935625e-03,  2.33037174e-02, -3.36763769e-04,\n",
       "          1.45317102e-02,  1.77042261e-02, -3.01586580e-03, -5.50527610e-02,\n",
       "         -2.21376698e-02, -2.38861293e-02, -4.67688171e-03, -1.75262371e-03,\n",
       "         -4.24939543e-02, -4.42858189e-02,  2.92633828e-02,  2.77669523e-02,\n",
       "          1.05067343e-02,  2.73855105e-02,  3.10046691e-02, -4.40901667e-02,\n",
       "          3.19144949e-02, -1.36121372e-02,  2.21098047e-02, -3.11369225e-02,\n",
       "          1.74121617e-03, -6.41211076e-03,  3.01410556e-02, -2.69650761e-02,\n",
       "          9.06566530e-03,  5.39557599e-02,  5.19575691e-03,  2.36242469e-02,\n",
       "          9.44689941e-03, -6.99492311e-03,  6.02174588e-02, -1.80370603e-02,\n",
       "          5.48966834e-03,  4.35852492e-03,  4.58885595e-04,  2.05672979e-02,\n",
       "          3.71390097e-02, -1.24273347e-02,  3.72935273e-03,  1.66563485e-02,\n",
       "         -5.77907683e-03,  3.08775920e-02, -2.54703835e-02,  8.19536392e-03,\n",
       "          4.68366481e-02, -5.74133284e-02, -2.24639867e-02, -3.98640223e-02,\n",
       "          2.13747267e-02, -2.31461003e-02,  2.19503250e-02,  2.70259771e-02,\n",
       "          2.97685247e-03,  4.07320000e-02,  3.00634038e-02, -5.09252697e-02,\n",
       "         -2.47686519e-03, -5.50163053e-02, -1.79768854e-03,  1.69493761e-02,\n",
       "         -5.23976563e-03, -2.23068204e-02,  1.00591294e-02,  4.86719459e-02,\n",
       "         -1.48905842e-02,  1.89077705e-02, -5.54526187e-02,  9.49074607e-03,\n",
       "         -3.94922756e-02, -1.94780100e-02,  8.76734219e-03, -4.09226716e-02,\n",
       "         -2.20484231e-02, -5.65581620e-02,  4.12861481e-02, -2.51686964e-02,\n",
       "          5.33606298e-02,  1.54836169e-02,  5.93589954e-02,  5.55738769e-02,\n",
       "         -6.33565634e-02, -1.04047665e-02,  1.00586852e-02,  2.57925759e-03,\n",
       "          5.91143733e-03, -3.96383330e-02,  3.02597433e-02,  4.17844951e-02,\n",
       "          1.92319939e-03, -2.16361824e-02,  1.47802057e-02, -2.41198558e-02,\n",
       "          3.20371650e-02, -3.75473537e-02,  7.82687124e-03,  4.41641919e-02,\n",
       "          5.22048809e-02, -5.64747443e-03,  2.27179918e-02, -8.51397682e-03,\n",
       "          4.20109183e-02,  6.73029153e-03, -2.33192388e-02, -1.36567429e-02,\n",
       "          2.45247278e-02,  4.32618661e-03, -2.17203256e-02,  1.85183231e-02,\n",
       "          8.47984757e-03,  1.63556784e-02,  3.15513760e-02, -1.48242963e-02,\n",
       "         -5.71341952e-03, -8.26392416e-03, -1.04999123e-02, -5.82702644e-02,\n",
       "          5.16836978e-02,  1.30667584e-02,  7.06464006e-03,  2.49757245e-02,\n",
       "          5.75837679e-03,  3.76274646e-03, -7.34572066e-03, -2.74234563e-02,\n",
       "         -9.96514037e-03, -5.67283444e-02,  8.32301471e-03,  2.86917742e-02,\n",
       "          2.37850901e-02,  2.28656456e-02,  3.56978588e-02,  6.13500327e-02,\n",
       "         -1.17795588e-02, -1.78703386e-02, -6.75668567e-02, -1.82482116e-02,\n",
       "         -3.82741727e-02,  6.05488336e-03,  3.01344004e-02,  1.88108813e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 30,\n",
       "  'topic_words': array(['feminist', 'women', 'females', '여성', 'gendered', 'female',\n",
       "         'gender', 'woman', 'neurofeminism', 'neurofeminist', 'males',\n",
       "         'men', 'girls', '학문', '남성', 'girl', 'periods', 'male', 'scholars',\n",
       "         'discriminant', 'studies', 'scholar', 'boys', 'cohort', 'academic',\n",
       "         'scientists', 'professor', 'gap', 'scientist', 'psychology',\n",
       "         'biology', 'equal', 'correlations', 'researchers', 'statistic',\n",
       "         'equals', 'statistics', 'researcher', 'demographic', 'sexual',\n",
       "         'sciences', 'correlation', 'groups', '구분', 'neurosciences',\n",
       "         'empirical', 'student', 'study', 'differentiated', 'subjects'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-0.01498432,  0.04351015,  0.01793095, -0.04610914, -0.00203714,\n",
       "          0.04707094, -0.0185644 , -0.00180244,  0.04816047,  0.02159483,\n",
       "          0.01232962,  0.06630258,  0.02804084, -0.02231758, -0.0497627 ,\n",
       "          0.02434867, -0.04780243, -0.05521908,  0.04068573,  0.04951791,\n",
       "         -0.00599944, -0.02967599, -0.01827449,  0.00118939, -0.04945711,\n",
       "         -0.00028961,  0.04333932,  0.01010491, -0.00745067, -0.05244317,\n",
       "          0.01258901, -0.02189822, -0.01658948, -0.04090062,  0.0325762 ,\n",
       "         -0.00994765,  0.05149499, -0.04548472, -0.04810787,  0.01452081,\n",
       "         -0.00763019,  0.00320054,  0.03659416,  0.00275308, -0.04322736,\n",
       "          0.00623479,  0.02820699,  0.01577025, -0.03060887,  0.01229475,\n",
       "          0.04852017, -0.02668451,  0.00737602, -0.00320201,  0.01875584,\n",
       "         -0.06237826,  0.01593548,  0.03301171,  0.03302271,  0.03288544,\n",
       "         -0.02084954,  0.05447712,  0.02789137, -0.04248626,  0.01853853,\n",
       "         -0.00956983,  0.04440565, -0.00863955,  0.01770507, -0.00317779,\n",
       "         -0.01545315,  0.01277331,  0.00680445, -0.06702299,  0.01156622,\n",
       "         -0.04516386,  0.02696857,  0.03580054, -0.02834372, -0.06479798,\n",
       "         -0.06648833, -0.03885051, -0.03867697,  0.05014854, -0.00632544,\n",
       "         -0.01648425, -0.01034168, -0.01396688, -0.00124994,  0.03455327,\n",
       "         -0.04713365,  0.03230739, -0.0310496 , -0.02309024, -0.0155684 ,\n",
       "          0.00750355,  0.06069914,  0.05225665, -0.02821957,  0.03003442,\n",
       "          0.02063912, -0.008616  , -0.01352471, -0.02340187,  0.03395168,\n",
       "         -0.02758698, -0.05648822,  0.02525108, -0.03684523,  0.0305103 ,\n",
       "         -0.008994  , -0.03027736, -0.02723995, -0.02921433,  0.00485893,\n",
       "         -0.04194874,  0.04568004,  0.01334179,  0.01325565,  0.03410419,\n",
       "         -0.03370756,  0.03739244,  0.02117896,  0.02607329, -0.00907491,\n",
       "          0.03214359,  0.01522289, -0.00774108, -0.04261196,  0.01211216,\n",
       "         -0.00692251,  0.00964342,  0.03117931,  0.03283293,  0.03602516,\n",
       "          0.06020831, -0.000437  , -0.03824013,  0.05739084, -0.00116525,\n",
       "          0.02971312,  0.03301974, -0.01055135,  0.02449043,  0.01594178,\n",
       "          0.00575469,  0.04091969, -0.05005785, -0.01009636, -0.04706905,\n",
       "          0.04395108, -0.01691678,  0.03331612, -0.0151019 , -0.03997907,\n",
       "         -0.01242834,  0.01582506, -0.01180428, -0.05180705, -0.01944602,\n",
       "          0.03705812, -0.04983419,  0.00846091, -0.02546469, -0.05521012,\n",
       "         -0.02773137,  0.00596405, -0.02006775,  0.05925797,  0.02111762,\n",
       "         -0.01873897, -0.00020799, -0.01029231, -0.05412016, -0.02271214,\n",
       "          0.00746651, -0.02716923,  0.044022  , -0.05456093,  0.03107147,\n",
       "          0.03357188,  0.03720733, -0.00609698, -0.02033733,  0.00435003,\n",
       "          0.0119749 ,  0.03319348,  0.05685092,  0.03055988,  0.00146993,\n",
       "         -0.00844218, -0.0265485 ,  0.0199058 , -0.01059452, -0.00720425,\n",
       "          0.0285117 , -0.02082562,  0.01995657,  0.02721447, -0.00115285,\n",
       "         -0.05268662,  0.04118684, -0.01660484, -0.01438028,  0.02079662,\n",
       "         -0.04257059,  0.00137833,  0.03645051,  0.00493149,  0.0554498 ,\n",
       "         -0.01179633, -0.04917257, -0.00288772,  0.00442826, -0.06672758,\n",
       "         -0.00748353, -0.00673751, -0.04455888,  0.00547366,  0.04892632,\n",
       "         -0.0194657 ,  0.03898278,  0.04615667,  0.01579002, -0.0432683 ,\n",
       "         -0.03343982, -0.04537189,  0.01852911, -0.0418698 , -0.05156943,\n",
       "          0.02688785, -0.02284521, -0.01815731,  0.02109557,  0.0313301 ,\n",
       "         -0.02384429,  0.0146186 , -0.01454968,  0.06089505, -0.04841346,\n",
       "         -0.05349549, -0.02979537,  0.01649026,  0.01043891,  0.02361737,\n",
       "         -0.00844906,  0.01501113,  0.01685673,  0.02979973, -0.02471073,\n",
       "         -0.01814732, -0.02307683,  0.02485401, -0.03304252,  0.01627826,\n",
       "         -0.03200987,  0.00716478,  0.00946985, -0.01002601,  0.03031325,\n",
       "         -0.01750783, -0.00087057,  0.02226189,  0.02495803,  0.01885277,\n",
       "         -0.02174157, -0.03249488,  0.01014931,  0.01431774,  0.0264438 ,\n",
       "          0.01751294, -0.01470359,  0.01217183, -0.03073448,  0.03234473,\n",
       "         -0.02642325, -0.03162965,  0.04582381, -0.04861865, -0.01690325,\n",
       "         -0.04871142, -0.01972433,  0.01987105,  0.00258771, -0.03010732,\n",
       "          0.04060971, -0.03738486, -0.01387318, -0.05879126, -0.02410357,\n",
       "          0.032117  ,  0.0418879 ,  0.03285401, -0.00509341,  0.04411162,\n",
       "          0.04376855, -0.04407139,  0.04122921,  0.01821635,  0.01435365,\n",
       "          0.00030573,  0.01289135, -0.00126974, -0.04273933,  0.02573788,\n",
       "         -0.04187467, -0.05533157,  0.03791215,  0.01693247, -0.03929162,\n",
       "          0.02445124, -0.00393093,  0.01241476,  0.00115478,  0.01810804,\n",
       "          0.0013045 ,  0.01359983, -0.0148065 ,  0.0499579 , -0.03187266,\n",
       "         -0.02959953, -0.04773761, -0.04327879,  0.00653616,  0.00915534,\n",
       "         -0.01168112,  0.03834623, -0.03618023,  0.03383116,  0.02927935,\n",
       "          0.01179213,  0.0639806 , -0.04639241, -0.05122266, -0.00557418,\n",
       "          0.03182665, -0.02088869, -0.03127354, -0.05217161, -0.00262439,\n",
       "         -0.02170602, -0.0204477 , -0.0003598 , -0.01607329, -0.01971935,\n",
       "          0.02421961,  0.04964587, -0.02146358, -0.01937257, -0.03496782,\n",
       "          0.01178345, -0.0433513 ,  0.01502236,  0.04716441, -0.04030887,\n",
       "          0.03300755, -0.03216105,  0.04869308, -0.03125795, -0.04182056,\n",
       "         -0.03209856,  0.00271408,  0.03844345, -0.00473196, -0.00375623,\n",
       "          0.02433486, -0.02588799,  0.00261993, -0.04516702, -0.00519585,\n",
       "         -0.00164856,  0.02790339,  0.0102257 , -0.01692327,  0.03847   ,\n",
       "          0.03713103,  0.01503361,  0.01408317, -0.0125503 , -0.00613984,\n",
       "         -0.00941969, -0.04257589,  0.01796384, -0.02804472, -0.00450442,\n",
       "          0.06591856,  0.01804023, -0.05520234,  0.05419236,  0.01970186,\n",
       "         -0.01902645, -0.01577337,  0.0236183 ,  0.06375567, -0.03209266,\n",
       "          0.03691226,  0.03187422, -0.02716826,  0.02346569,  0.00605949,\n",
       "          0.02461866,  0.05059422,  0.02513503,  0.0169651 , -0.01485704,\n",
       "         -0.00163925,  0.02372894, -0.03042243,  0.00662026, -0.01181369,\n",
       "          0.03454059,  0.00591928,  0.02182814, -0.04804645, -0.01513733,\n",
       "          0.05440377,  0.03120307, -0.02727048,  0.0158795 , -0.02112705,\n",
       "         -0.00239964, -0.03927861,  0.01580085,  0.02841518,  0.04655918,\n",
       "         -0.00088717, -0.01245456,  0.0133427 , -0.0564847 , -0.0350442 ,\n",
       "         -0.02292751, -0.01058171, -0.02585473, -0.04989213, -0.01880239,\n",
       "         -0.04969993,  0.02379964, -0.04062092, -0.02870577,  0.00228977,\n",
       "         -0.01941734, -0.00096004,  0.03584844, -0.04728636,  0.03290471,\n",
       "          0.06420963,  0.04521256,  0.02143327,  0.05198497, -0.00197574,\n",
       "         -0.01869367,  0.02456574,  0.00648585,  0.02617443, -0.01333658,\n",
       "          0.01285903, -0.01010136,  0.02321018,  0.05996095, -0.03568328,\n",
       "         -0.0217725 , -0.02660769, -0.01951518, -0.03035116, -0.04887196,\n",
       "         -0.05566513, -0.04250633,  0.05188423, -0.008827  ,  0.03370637,\n",
       "         -0.00927751,  0.05777879, -0.04336732, -0.00367085, -0.01275943,\n",
       "          0.03070603,  0.01920399,  0.00715389, -0.01549922,  0.01011014,\n",
       "          0.04132771,  0.06207855, -0.03419288, -0.01089614, -0.0284599 ,\n",
       "          0.03377596, -0.04443162, -0.06178065,  0.02931372, -0.00777911,\n",
       "         -0.01174353, -0.01328808, -0.01034209, -0.0217744 , -0.00780945,\n",
       "          0.01795871, -0.03716638,  0.02348183,  0.03698976,  0.00528602,\n",
       "          0.04820178, -0.04196914,  0.02433938, -0.04792107, -0.02609543,\n",
       "         -0.00218525, -0.01789394,  0.02932656, -0.03738534, -0.05103994,\n",
       "         -0.01089434,  0.03346303], dtype=float32)},\n",
       " {'topic_idx': 31,\n",
       "  'topic_words': array(['javascript', 'write', 'writing', 'java', 'script', 'written',\n",
       "         'writer', 'scripting', 'khtml', 'wrote', 'syntax', 'html', '쓰이',\n",
       "         'overwrite', 'scripts', '스크립트', 'rewrite', 'json', '자바', 'blog',\n",
       "         'js', '언어', 'selenium', 'logger', 'character', 'pseudo',\n",
       "         'language', 'author', 'webdriver', 'suicidal', '글쓰기', 'execute',\n",
       "         'varlambda', 'suicide', 'inspired', 'affective', 'rjava',\n",
       "         'copyright', 'jr', 'ngrok', 'triggered', 'facecount', 'trigger',\n",
       "         'createpages', 'enter', 'webgl', '문법', 'nonverbal', 'escape',\n",
       "         'exploit'], dtype='<U15'),\n",
       "  'topic_vector': array([-1.64734460e-02,  1.39920413e-03, -2.46624630e-02,  2.45254617e-02,\n",
       "          4.36123926e-03, -2.05407199e-02,  2.42417846e-02,  2.48076450e-02,\n",
       "          1.86687876e-02,  2.48086471e-02, -9.99082532e-03, -2.60680169e-02,\n",
       "         -2.21155654e-03, -2.01095622e-02, -5.35203218e-02,  3.13603207e-02,\n",
       "          9.94064566e-03, -6.16812743e-02,  7.54153775e-03,  5.75455464e-03,\n",
       "          4.44323430e-03,  7.93071464e-03,  2.78950538e-02, -1.51629113e-02,\n",
       "          3.87079492e-02,  9.20563284e-03, -3.91611271e-02,  1.40236476e-02,\n",
       "         -4.35037352e-02, -4.17572446e-02, -1.17679387e-02,  1.50870159e-03,\n",
       "          4.25472744e-02, -3.86426933e-02,  3.79056856e-03,  8.39980785e-03,\n",
       "          1.19959004e-02,  2.79067643e-03,  5.33888908e-03, -2.29255706e-02,\n",
       "         -3.58661301e-02,  8.04469828e-03, -4.82976846e-02, -1.92241259e-02,\n",
       "         -3.47701497e-02,  3.68070469e-04, -1.39281675e-02, -8.73165019e-03,\n",
       "         -1.15056261e-02, -2.02655997e-02,  3.70844570e-03,  1.91784725e-02,\n",
       "          1.11944703e-02,  3.69317993e-03,  8.69254291e-04,  2.47356836e-02,\n",
       "          4.14309874e-02,  1.64253730e-03, -3.52999233e-02,  2.51295213e-02,\n",
       "          1.94964558e-03,  8.23284127e-03,  1.25131896e-02, -1.12303915e-02,\n",
       "          2.23541949e-02,  7.85174500e-03,  5.93881868e-03, -2.29338240e-02,\n",
       "          8.94256402e-03,  1.68505479e-02,  4.66399034e-03,  2.08016839e-02,\n",
       "          7.44434586e-03, -1.30104348e-02,  2.60300208e-02,  3.91322188e-02,\n",
       "         -2.87560765e-02, -3.85922156e-02,  3.25975530e-02, -1.59171037e-02,\n",
       "         -8.11854973e-02, -1.60534009e-02, -3.12118977e-02, -1.80944484e-02,\n",
       "          2.79790815e-02, -2.44178120e-02, -5.67166694e-02,  3.09784710e-02,\n",
       "          2.43659150e-02,  1.41151911e-02,  1.59722082e-02, -2.13190541e-02,\n",
       "         -3.46567146e-02,  1.21491700e-02,  2.90292073e-02, -2.86564301e-03,\n",
       "         -2.21661553e-02, -2.01954786e-02, -4.40936424e-02,  5.69232414e-03,\n",
       "          2.11792383e-02, -8.47698096e-03,  1.98933557e-02, -2.78358604e-03,\n",
       "          3.35230716e-02,  2.61190608e-02,  1.14111891e-02,  8.71898979e-03,\n",
       "          3.16211283e-02, -1.04389535e-02, -1.01851532e-02, -3.38413417e-02,\n",
       "          5.71934581e-02,  5.53180687e-02,  1.41319819e-02,  1.82184875e-02,\n",
       "         -3.67582701e-02, -3.41584571e-02,  2.29844265e-03, -1.03747165e-02,\n",
       "         -1.74905676e-02, -9.10986215e-04, -2.46954267e-03,  1.94790661e-02,\n",
       "         -9.98357311e-03, -2.85707340e-02,  6.94570271e-03, -2.07300819e-02,\n",
       "          2.12842673e-02,  3.36575545e-02, -2.34416183e-02, -1.69121549e-02,\n",
       "          3.66474576e-02,  1.05791204e-02,  1.37571245e-02,  7.39316866e-02,\n",
       "         -1.09777236e-02, -3.73404031e-03,  1.96904931e-02,  6.20591873e-03,\n",
       "          2.53934395e-02,  4.02947553e-02, -3.49458642e-02, -4.22510132e-03,\n",
       "          2.70715300e-02,  3.49688195e-02, -1.59974713e-02, -4.13031839e-02,\n",
       "         -2.58519966e-02,  2.74179247e-03,  1.97673719e-02, -8.49515665e-03,\n",
       "          1.85705852e-02,  2.34458838e-02, -1.76866893e-02, -2.19192486e-02,\n",
       "         -2.46056821e-02,  3.95434396e-03, -1.61340237e-02,  4.92510647e-02,\n",
       "          4.80207764e-02, -4.48552612e-03, -7.30319461e-03, -1.33918971e-02,\n",
       "         -1.12848589e-02, -5.18124700e-02,  4.00445201e-02,  2.70849783e-02,\n",
       "          7.24240206e-04, -2.96523869e-02, -2.49390751e-02,  2.69867051e-02,\n",
       "         -2.67769620e-02, -2.82687624e-03,  1.42806182e-02,  1.75925009e-02,\n",
       "          1.23617314e-02,  2.56321076e-02,  4.00940375e-03, -5.16849523e-03,\n",
       "          2.75464654e-02,  1.88602898e-02, -2.46945079e-02, -1.20612457e-02,\n",
       "         -1.52171338e-02,  7.51319050e-04,  5.77213103e-03,  2.98017710e-02,\n",
       "          9.37614962e-03, -1.18543990e-02,  4.34816927e-02,  6.70905039e-03,\n",
       "          4.47818525e-02, -1.40770329e-02, -3.62999551e-02, -8.06111004e-03,\n",
       "          5.87662756e-02, -2.06037760e-02, -2.02393476e-02,  1.58253517e-02,\n",
       "         -5.63892489e-03,  1.14338109e-02, -1.97869446e-02,  3.12332250e-03,\n",
       "         -2.06443742e-02,  2.17721555e-02,  1.35253333e-02, -1.56981256e-02,\n",
       "         -2.41706963e-03,  2.10696529e-03,  1.95687730e-02,  1.87285971e-02,\n",
       "          4.78437491e-04, -9.39584523e-03,  1.24315554e-02,  1.11429645e-02,\n",
       "          3.12555581e-04,  2.67589632e-02,  3.02587654e-02,  6.55314326e-03,\n",
       "         -1.15211010e-02, -8.78410880e-03,  4.76411991e-02,  3.17126065e-02,\n",
       "         -7.83088244e-03, -2.01530103e-02,  6.15731673e-03,  3.13984714e-02,\n",
       "         -3.04931235e-02,  1.07706934e-02,  8.92870035e-03, -8.78886133e-03,\n",
       "          2.91992035e-02,  2.44937707e-02,  2.68081892e-02,  1.65883508e-02,\n",
       "         -2.03844830e-02,  1.49876596e-02,  5.68023510e-03, -1.83344614e-02,\n",
       "         -1.20728314e-02, -3.91683243e-02,  3.92217077e-02,  3.42083484e-04,\n",
       "         -2.56014075e-02, -2.09944379e-02, -1.09498715e-02,  8.07394739e-03,\n",
       "          3.52136008e-02,  1.23523669e-02,  4.95319106e-02, -9.81801655e-03,\n",
       "         -2.58133039e-02, -1.29032293e-02,  9.57819924e-04, -4.24502529e-02,\n",
       "          2.94773467e-03,  7.04730973e-02,  1.46936327e-02, -9.71199106e-03,\n",
       "          5.05995238e-03, -6.43361500e-03,  2.39156205e-02, -3.47638577e-02,\n",
       "          1.96078569e-02,  4.26278301e-02, -1.59718264e-02, -6.50646305e-03,\n",
       "          1.30276047e-02,  7.80159468e-03,  3.34430970e-02, -2.01714560e-02,\n",
       "          9.54389572e-03,  1.76578369e-02, -1.28380284e-02,  2.95987129e-02,\n",
       "          1.26207182e-02, -3.77976298e-02, -8.91017169e-03, -4.41527925e-03,\n",
       "         -2.01448873e-02, -3.02119758e-02, -4.46496643e-02,  1.74503401e-02,\n",
       "          1.28547093e-02, -1.17305825e-02, -3.58986929e-02,  1.58734750e-02,\n",
       "         -4.81231064e-02, -1.08022802e-02, -3.28783505e-02, -1.35350218e-02,\n",
       "          2.64279246e-02, -6.18378120e-03, -2.30057072e-02,  1.31347775e-02,\n",
       "         -5.39738573e-02, -1.97425298e-02,  5.17255701e-02, -7.96924438e-03,\n",
       "         -1.87243130e-02,  2.14906111e-02,  1.99707970e-02,  5.20168505e-05,\n",
       "         -3.26968241e-03,  1.36714801e-02, -2.24853605e-02, -4.81628291e-02,\n",
       "          3.21691148e-02,  4.51703630e-02,  1.64257754e-02, -6.64996356e-03,\n",
       "          1.39943603e-03, -4.71352413e-03,  3.99937108e-02,  1.74601879e-02,\n",
       "          1.14210770e-02, -2.80192401e-02, -1.29317502e-02, -6.57820283e-03,\n",
       "          1.65760946e-02,  2.01080218e-02,  4.71807132e-03, -2.09861225e-03,\n",
       "         -3.07504255e-02,  2.09123492e-02, -1.01823462e-02,  4.19550994e-03,\n",
       "          2.49937754e-02, -8.67543649e-03, -1.85153093e-02,  3.32427807e-02,\n",
       "         -1.27605200e-02,  3.24178860e-03,  4.31317724e-02, -6.68535521e-03,\n",
       "          5.96295809e-03,  2.21361890e-02, -7.26997033e-02,  5.09843566e-02,\n",
       "          1.45134015e-03,  1.54929524e-02,  1.75825842e-02,  1.10924328e-02,\n",
       "         -2.22876836e-02,  3.72848995e-02,  1.66011807e-02,  2.98802722e-02,\n",
       "          1.37949521e-02,  4.17878851e-03,  1.58697348e-02,  2.49607302e-03,\n",
       "          3.14409919e-02, -1.22398427e-02,  1.31515115e-02,  2.08171252e-02,\n",
       "         -4.30491716e-02, -3.68715636e-03,  4.87082318e-04, -5.39183766e-02,\n",
       "         -3.18049602e-02, -3.55974473e-02,  2.09320337e-02, -2.98555791e-02,\n",
       "          2.80000828e-03,  9.92291793e-03,  3.40534188e-02, -2.16387939e-02,\n",
       "         -2.97182575e-02, -3.65761365e-03,  2.12658811e-02, -1.96963008e-02,\n",
       "          1.78365633e-02,  1.01773003e-02,  3.09689064e-02,  4.01400635e-03,\n",
       "          1.13417087e-02, -1.31044155e-02, -2.84053981e-02, -1.67621337e-02,\n",
       "          3.05068749e-03,  3.63895558e-02,  2.34542880e-02,  5.50328977e-02,\n",
       "         -9.97478981e-03,  4.94274385e-02, -2.28027552e-02, -4.47041402e-03,\n",
       "          3.74155305e-02,  5.56017570e-02,  2.74959058e-02, -1.87430326e-02,\n",
       "         -2.01113261e-02,  2.10930910e-02,  4.49259114e-03, -4.52619940e-02,\n",
       "          2.52027046e-02, -2.07603518e-02,  1.54964970e-02,  1.84565242e-02,\n",
       "         -1.85905602e-02,  2.38493774e-02,  1.87157784e-02, -7.03887409e-03,\n",
       "          2.17869412e-02,  1.36473849e-02, -5.36799291e-03,  3.19100432e-02,\n",
       "         -8.78930371e-03, -1.32922025e-03, -7.32703134e-03,  5.72399376e-03,\n",
       "          5.01222424e-02, -3.47132422e-02, -2.62290090e-02,  2.71844938e-02,\n",
       "          2.92728096e-02, -2.30902229e-02, -2.79028472e-02, -4.00992632e-02,\n",
       "          1.82906911e-02,  2.62257340e-03, -4.68937866e-03,  3.81826721e-02,\n",
       "          4.20280285e-02,  5.22205643e-02,  1.03065250e-02,  1.72724556e-02,\n",
       "          2.49441620e-02,  1.42518906e-02, -1.54735865e-02,  2.74034888e-02,\n",
       "         -3.41279954e-02,  9.10429377e-03,  1.96227897e-02,  3.19547765e-03,\n",
       "         -5.01532434e-03, -8.19401909e-03, -3.46826054e-02,  3.14431712e-02,\n",
       "         -1.89153831e-02,  2.68176142e-02, -7.91911315e-03, -4.52906750e-02,\n",
       "          5.54955890e-03,  1.39911743e-02, -2.35798806e-02,  8.45823344e-03,\n",
       "          8.53497256e-03,  2.43420657e-02,  3.23465653e-02,  4.35795598e-02,\n",
       "          2.61440426e-02,  2.90065259e-02, -5.70359863e-02, -3.71596180e-02,\n",
       "         -3.12946886e-02, -1.32285925e-02, -2.54716333e-02, -3.68427336e-02,\n",
       "          1.02942428e-02, -1.56779513e-02, -3.99710611e-03, -9.19284939e-04,\n",
       "         -5.55075444e-02, -2.17796061e-02, -4.86098230e-03,  3.74029838e-02,\n",
       "          2.89243534e-02, -3.00837159e-02, -2.10974161e-02,  6.98476098e-03,\n",
       "         -2.77909427e-03, -3.82298082e-02, -9.67876334e-03,  3.31400670e-02,\n",
       "          1.51501282e-03, -6.38006926e-02,  1.89812761e-03,  1.51881156e-02,\n",
       "          8.25337041e-03, -4.77119274e-02, -6.34329999e-03,  1.00998944e-02,\n",
       "         -9.37832985e-03,  1.52102234e-02, -1.64415222e-02, -3.85990925e-02,\n",
       "          1.74423985e-04, -6.67505478e-03,  3.54382508e-02, -1.61276609e-02,\n",
       "         -2.36645695e-02,  1.41069843e-02,  2.77610812e-02,  4.39293571e-02,\n",
       "         -2.75354516e-02,  1.25223203e-02,  1.99814346e-02, -1.10178282e-02,\n",
       "         -1.50240632e-02,  1.17856711e-02, -3.90024260e-02,  6.29472500e-03,\n",
       "          5.54008177e-03, -2.05303114e-02, -3.00537888e-02,  2.25632940e-03,\n",
       "          8.52131564e-03,  2.37291250e-02, -5.09642297e-03, -9.52595659e-03],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 32,\n",
       "  'topic_words': array(['ggplot', 'lineplot', 'matplotlib', 'scatterplot', 'boxplot',\n",
       "         'dataframe', 'dataset', 'datasets', 'plotting', 'graphs', 'plot',\n",
       "         'xticklabels', 'chart', 'graph', 'plotted', 'subplots', 'plots',\n",
       "         'data', '그래프', 'graphql', '데이터', '그래픽', 'graphical', 'dzdata',\n",
       "         'matlab', 'graphics', 'numpy', 'histogram', 'demographic',\n",
       "         'gaussian', 'twindata', 'statistics', 'scaling', 'relplot',\n",
       "         'tensorflow', 'axis', 'significance', 'curve', 'scipy',\n",
       "         'information', 'sklearn', 'statistically', 'statistical', 'pandas',\n",
       "         '인구', 'vertexcount', 'github', 'geom', 'makerange', 'populations'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-0.05234078, -0.05150926, -0.03817349, -0.03609954, -0.04747633,\n",
       "         -0.04448361,  0.03254038,  0.04301945,  0.05366552,  0.05223268,\n",
       "          0.04947963, -0.03825789,  0.05170873, -0.00675203, -0.04407471,\n",
       "          0.00383496, -0.01735502, -0.01733572,  0.03715559,  0.05273221,\n",
       "         -0.01129261, -0.03093761,  0.01964261,  0.04915944, -0.04456063,\n",
       "         -0.04329633,  0.02661698,  0.01756577,  0.04429696, -0.05349439,\n",
       "         -0.05050888, -0.00609681, -0.01241614, -0.05178859,  0.01546284,\n",
       "         -0.01857997,  0.04234428,  0.00532102, -0.03383536, -0.03144024,\n",
       "         -0.03687598, -0.02373647, -0.01213572, -0.03576905,  0.02151244,\n",
       "         -0.0480242 ,  0.02834778, -0.03273439, -0.04589994, -0.0041779 ,\n",
       "         -0.00992435,  0.02096835, -0.01346215, -0.04289255,  0.03767961,\n",
       "         -0.04880971, -0.02538866,  0.0206125 ,  0.01652994,  0.05050542,\n",
       "          0.01042815,  0.05252474,  0.04724376, -0.02342119, -0.02499083,\n",
       "         -0.03234411, -0.01714718,  0.04161931,  0.04664836,  0.04846164,\n",
       "         -0.03604895, -0.01909287,  0.0232813 , -0.04895045, -0.04342339,\n",
       "         -0.04284949, -0.00496154, -0.01629491, -0.04074655, -0.05369813,\n",
       "         -0.0536868 , -0.00646531, -0.03008534, -0.01557619,  0.05049649,\n",
       "         -0.04575824, -0.04079926, -0.02863774, -0.02885047, -0.03436049,\n",
       "          0.03069622,  0.00684003, -0.02104063, -0.01262214,  0.03826981,\n",
       "          0.03685343,  0.01206217,  0.00699016,  0.03838716, -0.0340138 ,\n",
       "          0.04147838,  0.00605176,  0.02935612, -0.04157457,  0.03835563,\n",
       "         -0.00298715, -0.0411287 , -0.04828585,  0.0108168 ,  0.03160447,\n",
       "          0.01949707, -0.02791798, -0.02870545, -0.04581592,  0.01407956,\n",
       "          0.0059957 , -0.04732697, -0.05232681, -0.01080208, -0.00347165,\n",
       "          0.0044746 ,  0.04436349, -0.04301743,  0.05333894,  0.04636072,\n",
       "         -0.02049799,  0.01189081, -0.02506918,  0.02983287,  0.04588636,\n",
       "         -0.05054579, -0.00751468,  0.05286354,  0.02406347, -0.01135575,\n",
       "          0.01469925, -0.00880512,  0.03047084,  0.03434568,  0.04921261,\n",
       "         -0.01394481, -0.04221498,  0.02917719,  0.01886177,  0.04230889,\n",
       "         -0.0203737 , -0.03769419,  0.02779822,  0.00928981, -0.03869571,\n",
       "          0.03499923,  0.0268085 , -0.00522227, -0.0282991 , -0.00093719,\n",
       "         -0.0360208 ,  0.00697278,  0.0001509 ,  0.00438504,  0.04830642,\n",
       "          0.02445958,  0.04330889,  0.04441839, -0.01382009, -0.02153465,\n",
       "          0.00307373, -0.00812364, -0.00770256, -0.01294941,  0.05122959,\n",
       "          0.0126221 , -0.04060331,  0.01588632,  0.04641556,  0.02451274,\n",
       "          0.05017999, -0.04877558,  0.0197781 , -0.02890646,  0.03392143,\n",
       "          0.03046904, -0.02880144,  0.04178307,  0.04068058, -0.0519332 ,\n",
       "         -0.05177912,  0.05126542,  0.04911399,  0.01278991, -0.02505058,\n",
       "          0.03455158, -0.01799011,  0.04523284,  0.04789021, -0.02284126,\n",
       "         -0.02037981, -0.03828159, -0.016534  ,  0.0228716 ,  0.00473219,\n",
       "         -0.00062194, -0.00681115,  0.00698284, -0.03972038, -0.03676732,\n",
       "         -0.02277246, -0.02838884, -0.01533098, -0.02646651,  0.04265643,\n",
       "          0.02654346,  0.03992436, -0.0500384 ,  0.04136278,  0.03318333,\n",
       "          0.02052363, -0.04352544, -0.03688729,  0.04770824,  0.00373332,\n",
       "         -0.01076675,  0.04982696, -0.0264944 ,  0.01347219, -0.0530993 ,\n",
       "          0.03788216, -0.02961145, -0.04733059,  0.04364748,  0.02008022,\n",
       "         -0.02914421,  0.04745114, -0.03800136, -0.01808622,  0.03650434,\n",
       "          0.03425552, -0.02010784, -0.01435271, -0.01852827, -0.03037499,\n",
       "         -0.03040195,  0.0392661 ,  0.00641875,  0.04864245, -0.04900071,\n",
       "         -0.05093515, -0.0057447 , -0.04493263,  0.03980922, -0.02746711,\n",
       "         -0.04055886, -0.02278483, -0.02034687,  0.04858685,  0.04029271,\n",
       "         -0.02416962, -0.01297346, -0.00592719, -0.03751452,  0.02128934,\n",
       "         -0.0343205 , -0.000568  , -0.01090904, -0.05158348, -0.01034504,\n",
       "         -0.04294265, -0.00074801, -0.00974745,  0.01490832,  0.00167529,\n",
       "         -0.04827522, -0.04308587, -0.03635665, -0.04948761,  0.02279772,\n",
       "          0.02021821, -0.0433885 , -0.00213772, -0.04717701, -0.02739758,\n",
       "         -0.04859572,  0.01163609,  0.05352968,  0.04444693, -0.00874323,\n",
       "          0.01681423, -0.03937062, -0.05033132, -0.037876  ,  0.03363657,\n",
       "          0.04231273,  0.03659002,  0.03558553,  0.05238137, -0.05339628,\n",
       "          0.00493227, -0.04739506, -0.02986198, -0.0162557 ,  0.04860732,\n",
       "         -0.00460637,  0.04374367,  0.00589833, -0.04664705, -0.04299387,\n",
       "         -0.03659893,  0.00462742, -0.01304094,  0.00495712,  0.00829518,\n",
       "         -0.01345807, -0.04541007, -0.04471445,  0.03737535, -0.02642436,\n",
       "          0.02102829,  0.01576799, -0.00381804, -0.05024114,  0.01872145,\n",
       "          0.01074174,  0.00799989,  0.00123715,  0.03143233, -0.05298973,\n",
       "          0.03902645, -0.0448289 , -0.03097728, -0.04761403, -0.03645909,\n",
       "         -0.04445907, -0.01318018,  0.0062345 , -0.02677166, -0.0444542 ,\n",
       "          0.04158566,  0.04299299, -0.0030746 , -0.04740138, -0.01737391,\n",
       "         -0.05288924, -0.03749827,  0.05328244,  0.0176461 , -0.0485368 ,\n",
       "          0.02490208,  0.05258723, -0.00577882, -0.0280555 , -0.0328072 ,\n",
       "          0.01026038,  0.04969621,  0.05312675, -0.04699576,  0.02007666,\n",
       "         -0.02735595, -0.028745  ,  0.03609274, -0.01983147, -0.05022713,\n",
       "         -0.03197196, -0.02982325,  0.0440992 , -0.02116476, -0.04752366,\n",
       "         -0.01415419,  0.04326398,  0.03884886, -0.01118215,  0.04951162,\n",
       "          0.00812434,  0.04724345, -0.0215677 ,  0.0520339 ,  0.04502566,\n",
       "         -0.03678993,  0.008892  , -0.01909075, -0.05012649, -0.05324671,\n",
       "          0.01708374, -0.03695409,  0.00655041,  0.00214243, -0.04044566,\n",
       "          0.04845221,  0.03663073, -0.05341426,  0.03942025, -0.03452768,\n",
       "          0.00549592,  0.00613522, -0.03416341, -0.02899048, -0.04728066,\n",
       "          0.04213493, -0.03036547, -0.00015902, -0.00698256,  0.02260345,\n",
       "          0.05293438,  0.03762456,  0.0202696 , -0.05229217, -0.03891099,\n",
       "         -0.024653  , -0.00186379, -0.05124852,  0.0466506 ,  0.02214152,\n",
       "         -0.00843775,  0.0221838 ,  0.05365457, -0.04758104,  0.03863675,\n",
       "         -0.02152175,  0.05250993,  0.04737786,  0.01200364,  0.0327988 ,\n",
       "          0.04931132,  0.01294682,  0.04004233,  0.02770639,  0.04176014,\n",
       "          0.02293221,  0.04330394, -0.02799468,  0.02139971, -0.04091569,\n",
       "          0.02884324, -0.04902819,  0.03485438,  0.00398348, -0.00320875,\n",
       "         -0.01196478, -0.00650956,  0.02600504, -0.05319373,  0.04933015,\n",
       "         -0.03224136,  0.04523556,  0.02940635, -0.0469599 , -0.0180477 ,\n",
       "         -0.03761844,  0.05352981,  0.04903512, -0.03095896, -0.01413773,\n",
       "          0.03758071,  0.00974842, -0.04002435, -0.02014443, -0.04583839,\n",
       "         -0.03922463,  0.03730484,  0.05250157,  0.01903551,  0.05223801,\n",
       "         -0.01688773,  0.00831423,  0.01416454, -0.04260591,  0.03714408,\n",
       "         -0.04165817, -0.01354946, -0.04257429,  0.0471794 , -0.00827938,\n",
       "          0.03844175, -0.01049197,  0.04712135, -0.02081056, -0.03993339,\n",
       "         -0.0082275 ,  0.03233843, -0.0444661 , -0.00247308, -0.0004157 ,\n",
       "          0.04219307,  0.03354551, -0.02532564,  0.01982074, -0.01459183,\n",
       "          0.00155088, -0.01204253, -0.04810146,  0.04615725,  0.00185832,\n",
       "          0.02808152, -0.00224886,  0.01998416,  0.01939952, -0.02456048,\n",
       "         -0.03432982,  0.03501972, -0.03542443,  0.03938975,  0.0313454 ,\n",
       "         -0.01313446, -0.04319466,  0.03704038, -0.03054381, -0.0331091 ,\n",
       "         -0.05340914, -0.01110062, -0.02613388, -0.00297672, -0.03991032,\n",
       "          0.00288556,  0.04317818], dtype=float32)},\n",
       " {'topic_idx': 33,\n",
       "  'topic_words': array(['urllib', 'khtml', 'html', 'utf', 'url', 'cython', 'regex',\n",
       "         'python', '파이썬', '문자열', 'matplotlib', 'javascript', 'string',\n",
       "         'css', 'sklearn', 'keywords', '스크립트', 'github', '태그', 'webgl',\n",
       "         'dataframe', 'keyword', 'strings', 'encode', 'newscrawling',\n",
       "         'crawler', 'unicode', 'ascii', 'parse', 'pages', 'encoded', 'web',\n",
       "         'selenium', 'bootstrap', 'perl', 'query', 'queries', 'str',\n",
       "         'createpage', 'variables', 'varlambda', 'scrapy', 'subprocess',\n",
       "         'textrm', 'syntax', 'encoding', 'json', 'grep', 'pid', 'dict'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-0.05523615,  0.01907343,  0.02521064,  0.03832341, -0.02778972,\n",
       "         -0.0599106 ,  0.01031877,  0.02766798,  0.05423047,  0.04555256,\n",
       "          0.02934676,  0.02224264,  0.05097232,  0.04830338, -0.03054676,\n",
       "          0.00651861,  0.02537821,  0.01863577,  0.02032553,  0.03053983,\n",
       "          0.04942802,  0.04671578,  0.03215048,  0.048305  , -0.05749261,\n",
       "         -0.03169378,  0.00244257, -0.02397328, -0.06034709, -0.05107373,\n",
       "         -0.04268495,  0.00036032, -0.04965334, -0.04621191, -0.0264453 ,\n",
       "         -0.05794344,  0.05959284,  0.01330198, -0.01470072, -0.02726438,\n",
       "         -0.00962409, -0.05945475, -0.02256531,  0.00952083, -0.04141942,\n",
       "         -0.02098324,  0.00342728,  0.01207294, -0.00920252, -0.00152908,\n",
       "         -0.00157813, -0.02677053, -0.03268409, -0.03712   ,  0.03183219,\n",
       "         -0.04442784,  0.02492587,  0.05547215,  0.01475865,  0.00842114,\n",
       "          0.01545527,  0.05782137,  0.03104597, -0.04129975, -0.03903718,\n",
       "         -0.00579652,  0.03064464, -0.03489321,  0.04907867, -0.01438564,\n",
       "         -0.03248991,  0.00096338,  0.02962885, -0.05485028, -0.01571157,\n",
       "         -0.05744069,  0.00059535,  0.01225576,  0.03004303, -0.05713408,\n",
       "         -0.05891366, -0.02502582, -0.05343013, -0.04943505,  0.02716261,\n",
       "         -0.02176738, -0.02025917, -0.04508055,  0.03565232, -0.05352083,\n",
       "         -0.00880649,  0.00197318,  0.00621937,  0.00932053,  0.04246958,\n",
       "          0.00234533, -0.05317255, -0.0301092 ,  0.03189255, -0.05808796,\n",
       "          0.03654987,  0.05770524, -0.01232604,  0.02150568,  0.02927695,\n",
       "          0.03990579, -0.05000536, -0.04437821, -0.0204863 ,  0.01502255,\n",
       "          0.02450011, -0.04767977,  0.04750611, -0.04095628,  0.03460842,\n",
       "         -0.02395794, -0.05022439, -0.02698801,  0.02404998, -0.02078597,\n",
       "          0.00814669, -0.02376995, -0.00725728,  0.04962567,  0.05087327,\n",
       "         -0.01797852, -0.0015629 , -0.01221715,  0.03332232, -0.02231555,\n",
       "         -0.02237366,  0.00871506,  0.05779371,  0.02235889, -0.04672978,\n",
       "          0.04601072, -0.02376186,  0.02320402,  0.03512787,  0.00752669,\n",
       "         -0.01150569,  0.01545462, -0.0472206 ,  0.04347425,  0.05773071,\n",
       "         -0.01055131, -0.02491093,  0.01153764,  0.00775359,  0.02556081,\n",
       "          0.05625395,  0.02460567,  0.02787803, -0.01006007, -0.00502565,\n",
       "         -0.03541894, -0.03839776, -0.00210626, -0.03788668,  0.03432901,\n",
       "          0.05254068, -0.02934903,  0.04888661,  0.00485181,  0.04144685,\n",
       "         -0.05188054, -0.03594803, -0.01250845,  0.00512285,  0.04491811,\n",
       "          0.01509937, -0.04970754, -0.01331127,  0.01345033,  0.04877843,\n",
       "          0.04744778, -0.04907596, -0.02954524, -0.03749027,  0.03466446,\n",
       "          0.02047976,  0.00808732,  0.021356  ,  0.04246129, -0.00933514,\n",
       "          0.00245903,  0.05447841,  0.05174254, -0.01520045,  0.01961821,\n",
       "          0.03012332, -0.05088565,  0.05464821,  0.01565379, -0.04345432,\n",
       "          0.00964515,  0.04718047, -0.03539005,  0.03391945,  0.05010394,\n",
       "          0.02616327,  0.0267267 ,  0.02104041, -0.02258935, -0.0139945 ,\n",
       "         -0.0029247 ,  0.05406604, -0.0342303 ,  0.02706081,  0.03458457,\n",
       "          0.00857575,  0.05791786, -0.05063699,  0.00458307,  0.05067281,\n",
       "          0.00882407, -0.01810104, -0.04544647,  0.00338857,  0.00856053,\n",
       "         -0.0234852 ,  0.05220633,  0.04527896, -0.01083064, -0.05700451,\n",
       "          0.01193885,  0.03505979,  0.04257293, -0.03364698,  0.00190686,\n",
       "         -0.0091179 ,  0.05767637,  0.04913665, -0.02339361,  0.00508393,\n",
       "          0.02955254, -0.01710678, -0.00739474,  0.03406467, -0.04358355,\n",
       "          0.00058596, -0.00214166, -0.01015471,  0.02535931,  0.0220111 ,\n",
       "         -0.06038192,  0.04322481,  0.00014835,  0.00705979,  0.02426059,\n",
       "         -0.02773131, -0.05566459, -0.04853069, -0.02700755,  0.03981948,\n",
       "         -0.03405069, -0.03278484,  0.06023918, -0.01641529,  0.04973964,\n",
       "         -0.03028888,  0.0458015 , -0.0278866 , -0.05391487, -0.00807598,\n",
       "         -0.03226661, -0.05681726, -0.00340619,  0.027715  ,  0.0557025 ,\n",
       "         -0.0574877 , -0.0499552 , -0.04372736,  0.01318499,  0.02895595,\n",
       "         -0.04941616,  0.04141782, -0.00124622, -0.03477751, -0.04622955,\n",
       "         -0.03551863,  0.03367863,  0.04912101, -0.01026533, -0.02489135,\n",
       "         -0.00432911, -0.05351088, -0.02626114, -0.03980408,  0.0189052 ,\n",
       "          0.01297153, -0.0225292 ,  0.00138503,  0.04108128, -0.05819195,\n",
       "          0.03235892, -0.05784021,  0.05827018, -0.00173106,  0.03433023,\n",
       "          0.02100609,  0.00819875, -0.03482325,  0.0159279 ,  0.05447932,\n",
       "          0.00334996,  0.05136354, -0.02957633, -0.02222937,  0.0139105 ,\n",
       "          0.05878887, -0.02513708,  0.02024887,  0.005096  , -0.01141204,\n",
       "          0.02106281, -0.02062262,  0.00945891,  0.026988  ,  0.03713515,\n",
       "          0.00163314,  0.02039807,  0.01318502, -0.01015239, -0.05782456,\n",
       "         -0.05307797,  0.00753428, -0.05229808,  0.01407751, -0.05238769,\n",
       "         -0.05852022, -0.02521704, -0.05102976,  0.00194894,  0.02868593,\n",
       "          0.02023706, -0.00161904,  0.03826736, -0.04945149, -0.02723905,\n",
       "          0.0057045 , -0.02923325,  0.03078415, -0.00109661, -0.05144364,\n",
       "          0.04874569,  0.02323112,  0.03263086, -0.00858141, -0.02469208,\n",
       "         -0.04552028,  0.00268879,  0.03232034, -0.04125391,  0.02800949,\n",
       "         -0.00900697, -0.01256785, -0.00025563,  0.01798942, -0.05199611,\n",
       "         -0.01128453, -0.02180836,  0.01915305, -0.01414345,  0.00288409,\n",
       "         -0.00275115,  0.05482868,  0.02993322, -0.04260905, -0.02609362,\n",
       "         -0.02194508, -0.01991918, -0.01397587,  0.02146687, -0.00051893,\n",
       "         -0.04525744, -0.04843595, -0.02751295, -0.05487978, -0.02273325,\n",
       "         -0.05384724, -0.02700797, -0.00807155, -0.01229165, -0.02446793,\n",
       "          0.04249006,  0.03484596, -0.06010729,  0.01624219,  0.04710988,\n",
       "          0.03538369, -0.04493166, -0.00934005, -0.02374918,  0.0065659 ,\n",
       "         -0.02904341,  0.0149412 ,  0.01189196,  0.00602228,  0.0015171 ,\n",
       "          0.0350755 ,  0.00045611,  0.05501063, -0.04845309,  0.0014485 ,\n",
       "         -0.04418418,  0.02353423,  0.00197404,  0.01488252, -0.01688745,\n",
       "         -0.04149036,  0.02480158,  0.05954348,  0.01954901,  0.01626969,\n",
       "          0.02690997,  0.04869746, -0.05947168, -0.02288895, -0.01447471,\n",
       "          0.04040603,  0.05213594, -0.02511716, -0.01218952, -0.02017824,\n",
       "          0.01759704,  0.03758623,  0.01826898,  0.0309086 , -0.05113218,\n",
       "          0.04652488,  0.03096681,  0.04437553,  0.01473652,  0.03364177,\n",
       "          0.03050511, -0.04070377, -0.05885092, -0.05486823, -0.03318593,\n",
       "         -0.01453074,  0.00215606,  0.01409135, -0.04480812, -0.00953253,\n",
       "         -0.05694389,  0.05421205,  0.00243732,  0.01135656,  0.00418334,\n",
       "          0.03011946,  0.03920189, -0.06012981, -0.00956642, -0.00113194,\n",
       "          0.0241755 ,  0.04162428, -0.05486515, -0.02370737,  0.0408004 ,\n",
       "         -0.03084206,  0.00046209, -0.00898099, -0.04856095, -0.0566415 ,\n",
       "         -0.03449503, -0.02585019, -0.04056887,  0.05366243,  0.04246143,\n",
       "          0.03268243, -0.04876232,  0.04161197,  0.00540311, -0.04198716,\n",
       "         -0.04932078, -0.00400502,  0.0177197 , -0.04990782, -0.00462813,\n",
       "          0.02955885,  0.03712834,  0.0238516 ,  0.00873085, -0.03842645,\n",
       "          0.04167651, -0.01470104, -0.05890558,  0.05021081, -0.02355926,\n",
       "         -0.01675152,  0.01580495, -0.02556285,  0.0137343 , -0.04765638,\n",
       "         -0.01356947, -0.05109572, -0.03542497,  0.04300976,  0.02518218,\n",
       "         -0.04830176, -0.03172184,  0.03479997,  0.00650245, -0.05121662,\n",
       "         -0.05828598, -0.05277146,  0.03678148, -0.01187675,  0.00146251,\n",
       "          0.04218041,  0.04581072], dtype=float32)},\n",
       " {'topic_idx': 34,\n",
       "  'topic_words': array(['github', 'account', 'accounts', 'dependencies', 'development',\n",
       "         'dependency', '개발', 'projects', '프로젝트', '계좌', 'accounting',\n",
       "         'project', 'developments', 'contracts', 'gencode', 'developmental',\n",
       "         'develop', 'tensorflow', 'developers', 'git', 'encode',\n",
       "         'accounted', 'encoded', 'dev', '구글', 'repository', 'sigmoid',\n",
       "         'developed', 'developing', 'contract', 'growth', 'concerns',\n",
       "         'urllib', 'commit', '성장', 'signed', 'toolkit', 'growing',\n",
       "         'delayed', 'diseases', 'email', '발전', 'login', 'problems',\n",
       "         'applewebkit', 'token', '환경', '페이스북', 'olfactory', 'associative'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-0.06489693,  0.0171503 , -0.06933723, -0.01572601,  0.02790736,\n",
       "         -0.06431948,  0.04726911, -0.04949205,  0.06091932,  0.04748384,\n",
       "          0.04645418,  0.04157055,  0.06257089,  0.0162475 ,  0.04991234,\n",
       "         -0.00576427, -0.0192758 , -0.00133596,  0.04904762,  0.0428526 ,\n",
       "         -0.00493064,  0.03903446,  0.01352958,  0.05306488, -0.07051413,\n",
       "          0.0077599 ,  0.00486783, -0.00532932, -0.05394066, -0.05804355,\n",
       "         -0.04413022, -0.00348461,  0.02997986, -0.05643391,  0.01435021,\n",
       "         -0.01569643, -0.02221516,  0.0186454 ,  0.01701866, -0.00455902,\n",
       "         -0.03051483,  0.01672506, -0.01649003, -0.06228425, -0.01761611,\n",
       "          0.02658789,  0.00641479, -0.01866237,  0.03838533, -0.04893118,\n",
       "         -0.0261855 ,  0.04366654, -0.03980035,  0.00335311,  0.02215531,\n",
       "         -0.06595068,  0.0575014 ,  0.04742762,  0.01335573, -0.04432964,\n",
       "          0.00550878,  0.03426719,  0.04994875, -0.06076092, -0.02994324,\n",
       "          0.07126816, -0.03834032, -0.0273941 ,  0.03685188, -0.02042222,\n",
       "         -0.06762186, -0.00473362,  0.03134312, -0.01783781, -0.01096017,\n",
       "          0.03233173,  0.04846461,  0.01511251,  0.0542957 , -0.06946277,\n",
       "         -0.07120406, -0.06746354, -0.01594694, -0.01602923,  0.02875313,\n",
       "          0.00485409, -0.01250706,  0.02198925, -0.04678538,  0.04698535,\n",
       "          0.00489486,  0.02432156,  0.06255525, -0.02188565,  0.01725194,\n",
       "         -0.00409794, -0.05773721,  0.01434072,  0.03360565, -0.01928392,\n",
       "          0.00973429,  0.01601038,  0.01916878,  0.04264923,  0.0245657 ,\n",
       "         -0.00928134, -0.02829749,  0.00125911, -0.03582027,  0.04142909,\n",
       "          0.02084808, -0.01154152,  0.03024215, -0.05275289,  0.02345285,\n",
       "         -0.04353645,  0.03833906, -0.03189217, -0.06479742,  0.05946267,\n",
       "          0.05676035,  0.00192456, -0.01124677, -0.00950599,  0.03785754,\n",
       "          0.04825259, -0.02655473,  0.0036066 ,  0.04673085,  0.04377371,\n",
       "         -0.04392572, -0.021253  ,  0.06989692, -0.01846201, -0.04331727,\n",
       "          0.03424404,  0.04606327,  0.00154694,  0.02766862,  0.04001533,\n",
       "         -0.00700293,  0.04914189, -0.02891534,  0.01105772,  0.01217693,\n",
       "         -0.04989789,  0.01694313,  0.04042846,  0.04677889, -0.0040685 ,\n",
       "         -0.01073728,  0.0505422 ,  0.0015728 , -0.0679575 ,  0.02109346,\n",
       "          0.00919677, -0.01601854,  0.04606897, -0.01433021, -0.02756307,\n",
       "          0.04321175, -0.00294419,  0.06137357,  0.04901735,  0.06263255,\n",
       "         -0.03039479,  0.03143445,  0.05394793,  0.00015693, -0.0303662 ,\n",
       "          0.0310386 , -0.02183624,  0.02350677,  0.0543138 , -0.04112611,\n",
       "          0.024881  , -0.064002  ,  0.00281413, -0.06598612,  0.0602572 ,\n",
       "         -0.03336147,  0.02300869, -0.01361656,  0.01568483, -0.03827981,\n",
       "          0.01035633,  0.0590016 ,  0.05262655, -0.03212203, -0.01938885,\n",
       "         -0.04351773, -0.01990547,  0.02467847, -0.04426454, -0.05363788,\n",
       "          0.03625462,  0.07026163, -0.01674457, -0.00563582,  0.0575583 ,\n",
       "          0.01093837, -0.0175406 ,  0.00229121, -0.04837851, -0.0038748 ,\n",
       "         -0.07122163,  0.03743661, -0.01893201, -0.01072793,  0.01843252,\n",
       "         -0.06523672, -0.03708012,  0.05742003,  0.01106476, -0.00821978,\n",
       "         -0.03351717, -0.03587831, -0.0254057 , -0.01931154, -0.008463  ,\n",
       "         -0.05296636, -0.02696826,  0.01389801, -0.03835099, -0.06797322,\n",
       "         -0.01229474, -0.00813691,  0.04504893,  0.05766705, -0.06236155,\n",
       "         -0.04916444,  0.01983565, -0.01284284,  0.03235761, -0.00366345,\n",
       "          0.02549745,  0.06395438, -0.04734599,  0.06102679, -0.03647355,\n",
       "         -0.04666699, -0.00286507, -0.01147715,  0.04968517,  0.00797023,\n",
       "         -0.07001454,  0.00598536,  0.00727785, -0.0253997 ,  0.06177693,\n",
       "         -0.0421289 , -0.0131148 , -0.00062426, -0.05399175,  0.04101118,\n",
       "         -0.02112542,  0.05406903,  0.00349284,  0.01683937,  0.0505659 ,\n",
       "         -0.06575869,  0.03794521, -0.00532625, -0.03587381,  0.04921932,\n",
       "         -0.01834587, -0.05873903, -0.02365903, -0.0291316 ,  0.05555977,\n",
       "          0.03307898,  0.02197229, -0.04943321,  0.01567846,  0.0400992 ,\n",
       "         -0.01275544,  0.03919017,  0.03410559, -0.03625784, -0.03432648,\n",
       "          0.00913884,  0.02003318,  0.0485764 , -0.0077824 , -0.01580019,\n",
       "         -0.02405975, -0.05827736, -0.01836014,  0.00331347,  0.00469029,\n",
       "          0.04341451,  0.05027765, -0.05881692,  0.07150485, -0.07148039,\n",
       "          0.00965767, -0.03422124,  0.03783141, -0.01715242,  0.04991343,\n",
       "          0.02618482, -0.02771245,  0.00509152, -0.01689965, -0.00035716,\n",
       "          0.01549633,  0.01619662,  0.01203558, -0.00050159,  0.04404608,\n",
       "          0.05105584, -0.0242534 , -0.0191728 ,  0.00309254, -0.01839008,\n",
       "          0.05655923,  0.0394574 ,  0.00075924,  0.01777003,  0.0324783 ,\n",
       "          0.03655262, -0.02192642, -0.0640338 , -0.0052835 ,  0.00182399,\n",
       "          0.03155703, -0.02739396, -0.01422066,  0.03456657, -0.02563509,\n",
       "          0.00151676, -0.02983294,  0.01933739,  0.00469216,  0.06990822,\n",
       "         -0.00201109,  0.01739479, -0.02866003, -0.06718481, -0.05540049,\n",
       "          0.03943945,  0.05991956, -0.00391668, -0.06503274, -0.03892357,\n",
       "         -0.00649884,  0.0142229 ,  0.00097848,  0.02045768, -0.05350765,\n",
       "          0.0416446 , -0.0388243 , -0.02656906,  0.04724092, -0.06817829,\n",
       "         -0.04725983, -0.05406946,  0.02997236, -0.00289607, -0.04323717,\n",
       "          0.0017189 , -0.06431009,  0.01663619, -0.0262419 ,  0.036519  ,\n",
       "         -0.05143956, -0.00386341, -0.01013564, -0.0285896 , -0.05165083,\n",
       "          0.0347962 ,  0.02093562,  0.00680154, -0.01977673,  0.00431075,\n",
       "         -0.01124936, -0.00963199,  0.03321913,  0.00090021, -0.01086973,\n",
       "         -0.01674281, -0.00758468, -0.04213911,  0.01388457,  0.04919822,\n",
       "          0.03541277, -0.01394991, -0.05736592,  0.00322509,  0.03532053,\n",
       "          0.02928223,  0.01772171, -0.05059731,  0.00886197,  0.00637239,\n",
       "         -0.05176184,  0.06762631, -0.02852682, -0.00190683,  0.01172549,\n",
       "          0.04031856,  0.04410917,  0.0646968 , -0.03415474,  0.03645409,\n",
       "          0.01456817, -0.03433034, -0.02576253,  0.03104666, -0.0407694 ,\n",
       "         -0.01281517,  0.00305587,  0.03715205, -0.00244841, -0.02451625,\n",
       "         -0.01125274,  0.02406281,  0.00619767,  0.0159803 , -0.06883053,\n",
       "         -0.01866496,  0.03633169,  0.02364171, -0.00515915,  0.04165008,\n",
       "          0.01502267,  0.02607415,  0.00500062,  0.03695022, -0.04210066,\n",
       "          0.03349786,  0.00105787,  0.04501326,  0.06162719,  0.04602334,\n",
       "          0.06161183, -0.04276678, -0.04701668, -0.01120104,  0.03390913,\n",
       "          0.00732503,  0.01306153, -0.00752016, -0.05484392, -0.05845547,\n",
       "          0.06557231,  0.06991535, -0.06839918, -0.03710608,  0.06325113,\n",
       "         -0.00494238, -0.00862998, -0.06083712, -0.0122929 , -0.01298597,\n",
       "         -0.02735861,  0.04096743, -0.05460151, -0.02054623,  0.05706665,\n",
       "          0.03979012,  0.0272473 , -0.01110128, -0.03539738, -0.06292393,\n",
       "         -0.0214952 , -0.021448  ,  0.00517398,  0.06857225,  0.03085578,\n",
       "          0.06764822, -0.03273991,  0.04028012, -0.04353513, -0.0102553 ,\n",
       "         -0.0340381 ,  0.02315544,  0.04572221, -0.0014497 ,  0.0194923 ,\n",
       "          0.05326097,  0.05198541, -0.06873933,  0.0378185 ,  0.03040919,\n",
       "          0.01221317, -0.0457108 , -0.06612592,  0.03011113, -0.01346468,\n",
       "         -0.02239223,  0.02303639,  0.03744025, -0.00351258,  0.05664185,\n",
       "         -0.04006923,  0.03528665, -0.02712019,  0.04592798, -0.00880875,\n",
       "         -0.01671103, -0.00115648,  0.02066028,  0.00098094, -0.02118823,\n",
       "         -0.07153618,  0.06021253, -0.03151943, -0.06615703,  0.02283059,\n",
       "          0.00796958,  0.04123465], dtype=float32)},\n",
       " {'topic_idx': 35,\n",
       "  'topic_words': array(['xorg', 'nvidia', 'ubuntu', 'kernel', '커널', 'linux', 'gpu', 'sudo',\n",
       "         '우분투', 'gedit', 'gnome', 'gtx', 'stdout', 'sli', '드라이버', 'bashrc',\n",
       "         'driver', 'matplotlib', 'graphical', 'unix', 'tensorflow', 'cpu',\n",
       "         'disable', 'config', 'drivers', 'glm', 'lightdm', '그래픽', 'monitor',\n",
       "         'grub', 'graphics', 'vertexcount', 'mxmatrix', 'emerge', 'solved',\n",
       "         'synaptic', '부팅', 'install', 'xticklabels', 'intel', 'htop',\n",
       "         'github', 'resolve', 'boot', 'canonical', 'firefox', 'problem',\n",
       "         'derive', 'installed', 'fix'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.04259597, -0.01021695, -0.03783421,  0.02352443, -0.02937445,\n",
       "         -0.06427015,  0.04778362,  0.02527446,  0.02676579, -0.02348971,\n",
       "          0.01470462, -0.03182714,  0.05527766, -0.0001914 , -0.02064288,\n",
       "         -0.00538346,  0.00094133, -0.00261501,  0.00524286,  0.04468172,\n",
       "          0.0290726 ,  0.03869084, -0.01172856,  0.04901152, -0.04967177,\n",
       "         -0.0367036 ,  0.03977906, -0.00671091,  0.05406256, -0.0523991 ,\n",
       "          0.02478616,  0.02492676, -0.04385666, -0.05501361, -0.0312348 ,\n",
       "          0.01026384,  0.02627177,  0.01642099,  0.06455136,  0.04546694,\n",
       "         -0.03595738,  0.05053901,  0.02305719,  0.00509732,  0.04859752,\n",
       "         -0.02535882,  0.0442498 , -0.02924076, -0.06439173, -0.00786579,\n",
       "          0.00980137, -0.03911094,  0.06464944, -0.04565607,  0.00457173,\n",
       "         -0.04663985, -0.03533227,  0.05191498, -0.036309  ,  0.00466793,\n",
       "          0.0373186 ,  0.05413238,  0.0354994 , -0.05426949, -0.02296727,\n",
       "         -0.04373601,  0.02436218, -0.05025375,  0.06215092,  0.00929534,\n",
       "         -0.00523467,  0.05277697,  0.04021526,  0.01130639, -0.05587026,\n",
       "          0.03850638, -0.04698823, -0.05270131, -0.05275365, -0.05788591,\n",
       "         -0.06236883, -0.04775381, -0.03620318, -0.0504794 ,  0.0257385 ,\n",
       "          0.00497464,  0.023696  , -0.02392263,  0.03988017,  0.01466938,\n",
       "          0.04047429,  0.00207211, -0.00246633,  0.02730539,  0.05515677,\n",
       "         -0.03361567, -0.05264332,  0.03048821,  0.04219719,  0.02760825,\n",
       "          0.05374042, -0.02854019, -0.00917727, -0.00916288, -0.04250479,\n",
       "         -0.02660686, -0.03671416, -0.03710084,  0.02685524,  0.00839411,\n",
       "         -0.05199485, -0.05398531,  0.00521616,  0.01464751,  0.02140518,\n",
       "         -0.0065284 ,  0.02767069,  0.00836627, -0.04105042,  0.03960538,\n",
       "         -0.02931155, -0.0193254 , -0.03636097, -0.00523569, -0.02915488,\n",
       "          0.06032496, -0.04562483,  0.04138276,  0.03950971, -0.04472279,\n",
       "         -0.00988695,  0.03246318,  0.05511081,  0.04127204,  0.00262069,\n",
       "          0.00410819,  0.03915516,  0.02944205,  0.0496105 , -0.00118306,\n",
       "          0.04547428, -0.02519215,  0.03578031,  0.04551658, -0.00100911,\n",
       "         -0.01951048,  0.00954716,  0.04331323,  0.00904244, -0.03759494,\n",
       "          0.03880876, -0.04500198, -0.0325749 , -0.01144385,  0.00165357,\n",
       "         -0.00334796, -0.01172346,  0.04443701,  0.00026449, -0.06398112,\n",
       "          0.03247967,  0.02042786,  0.04475853, -0.03319313, -0.04256142,\n",
       "          0.00747457, -0.05424298, -0.00215648,  0.0243798 ,  0.01542704,\n",
       "         -0.01562473, -0.00705121, -0.05172499, -0.00992695, -0.00508303,\n",
       "          0.04774005, -0.04973207, -0.05728857, -0.04057327,  0.03972755,\n",
       "          0.03726283,  0.03868308, -0.03790667,  0.00676703, -0.04797033,\n",
       "         -0.01706321,  0.05372797,  0.04888429,  0.04752836,  0.0631483 ,\n",
       "          0.0065121 , -0.03000386,  0.02681927, -0.03930193, -0.0484606 ,\n",
       "          0.04081498, -0.05286068,  0.01519142, -0.0350119 , -0.01647295,\n",
       "          0.02016605, -0.04869907,  0.00626994, -0.01276183,  0.00532124,\n",
       "          0.02314301,  0.04351427,  0.02839185, -0.04419454,  0.01994946,\n",
       "          0.00624178,  0.04456781,  0.05814621,  0.00403009, -0.00904875,\n",
       "          0.01032811,  0.03239674,  0.00557506, -0.02602306,  0.0386097 ,\n",
       "          0.00626485,  0.00638342,  0.00572935,  0.03090115, -0.05799554,\n",
       "          0.02347248, -0.03265724,  0.02719424,  0.03330783, -0.03471102,\n",
       "         -0.05183161,  0.05070527, -0.00170235,  0.04674776,  0.01339914,\n",
       "          0.05598816, -0.05094992, -0.00379027, -0.00751638,  0.0079233 ,\n",
       "          0.02797088, -0.00037884,  0.04618612,  0.04945889, -0.00061915,\n",
       "          0.01906223, -0.02342052, -0.02147564,  0.04643899,  0.03399355,\n",
       "         -0.00167663,  0.02937122,  0.01818058,  0.00193168,  0.02671297,\n",
       "         -0.03991332,  0.00954372, -0.06235325, -0.01527971, -0.02648991,\n",
       "          0.0474279 ,  0.02796111, -0.02679129,  0.03875152,  0.01880639,\n",
       "         -0.0448363 ,  0.01766779, -0.00308311, -0.00695372,  0.02453216,\n",
       "          0.01578637, -0.01220891,  0.00684188,  0.01858437,  0.01539731,\n",
       "         -0.06148357,  0.00182207,  0.0127031 , -0.03430207,  0.04060718,\n",
       "          0.01905031,  0.01133872, -0.00576255, -0.0362321 , -0.01796763,\n",
       "          0.03490552, -0.05637236, -0.00703078, -0.00248345, -0.0479421 ,\n",
       "          0.0224511 , -0.01888061,  0.00075152,  0.01459833, -0.06106151,\n",
       "          0.03259161, -0.05400013, -0.03458182,  0.01078423, -0.04313989,\n",
       "          0.01869804, -0.01302856, -0.00681152, -0.00686481, -0.01810306,\n",
       "          0.04608934, -0.05135664, -0.03441451,  0.02520626,  0.04561554,\n",
       "         -0.00253745, -0.02469569, -0.05607109,  0.03451019, -0.03260366,\n",
       "          0.03885007,  0.06127134, -0.04368489, -0.03347415, -0.00046657,\n",
       "         -0.01944609,  0.04388547,  0.00295249,  0.03208377,  0.03574471,\n",
       "          0.02978979, -0.03259407, -0.02793013, -0.01131197, -0.02136376,\n",
       "         -0.03039788, -0.04454924, -0.0225403 ,  0.01141868, -0.0258226 ,\n",
       "          0.04931766,  0.02924691, -0.02009703, -0.05437426,  0.015876  ,\n",
       "          0.00132686,  0.06157131,  0.00856108, -0.02843154,  0.03260935,\n",
       "         -0.00967821,  0.00425329,  0.03821551,  0.00965083,  0.03704298,\n",
       "          0.01175006,  0.01729367, -0.0171772 , -0.06216418,  0.05760722,\n",
       "         -0.0157994 , -0.041984  ,  0.03919857, -0.00742687, -0.04290629,\n",
       "          0.04904183,  0.03339734,  0.02329868,  0.02246884,  0.04159868,\n",
       "         -0.05221119, -0.03209847, -0.00757714, -0.05246404,  0.04098429,\n",
       "          0.00724396,  0.04721848,  0.05643874, -0.03498418,  0.00724021,\n",
       "         -0.05379889, -0.01742036,  0.03884109,  0.06113622,  0.02703772,\n",
       "          0.01102741, -0.04881212, -0.02655005, -0.06331511, -0.00181565,\n",
       "          0.04504741, -0.03032913, -0.05754083, -0.04001892, -0.01376433,\n",
       "         -0.02698576, -0.02402591,  0.04873413,  0.02063747, -0.0378257 ,\n",
       "          0.01682882, -0.00199545,  0.01139906,  0.04622522,  0.0364912 ,\n",
       "          0.02365483,  0.025451  ,  0.04214261,  0.02052723,  0.00189749,\n",
       "          0.01890949,  0.0108926 , -0.0294639 ,  0.0187283 ,  0.0473428 ,\n",
       "         -0.03170913,  0.04325478, -0.02163323,  0.01597497, -0.01519981,\n",
       "          0.01637873,  0.02305861,  0.04508121, -0.00740502, -0.0331253 ,\n",
       "          0.0195637 ,  0.01123965,  0.05096135,  0.03218993, -0.00361842,\n",
       "          0.02924116,  0.044905  , -0.04000184,  0.04456891, -0.00225335,\n",
       "          0.03969874,  0.04172434,  0.04415279,  0.01277125,  0.01365296,\n",
       "         -0.03222176, -0.01222111,  0.04519144, -0.04889137,  0.01708751,\n",
       "         -0.05413134, -0.00903993, -0.04149231, -0.03370257, -0.02246571,\n",
       "          0.03027637,  0.05404279,  0.0480694 ,  0.06439295,  0.02880584,\n",
       "          0.02680854,  0.054609  , -0.05509833, -0.01995123, -0.01909107,\n",
       "         -0.05400843,  0.05955605,  0.03135085, -0.00952116,  0.04889516,\n",
       "          0.0079501 ,  0.00192103,  0.03986042,  0.05475781,  0.00211831,\n",
       "         -0.05072329, -0.01554983,  0.05969311,  0.05329858, -0.05199142,\n",
       "          0.051461  , -0.0536712 ,  0.04482022, -0.00781925, -0.03587113,\n",
       "         -0.02048575, -0.00462463, -0.0430304 ,  0.00725775,  0.01711051,\n",
       "         -0.01187521, -0.04063276, -0.01915069,  0.01616994, -0.02526943,\n",
       "          0.01805139,  0.01247278, -0.05532375, -0.01194505, -0.02602925,\n",
       "          0.0228555 ,  0.04205205,  0.0076546 , -0.0117743 , -0.00577168,\n",
       "         -0.00063606, -0.0472011 ,  0.04687549, -0.0265498 ,  0.02517771,\n",
       "         -0.00510173,  0.06305647,  0.01319254, -0.0016589 ,  0.02181289,\n",
       "         -0.0571622 , -0.01971979, -0.00206427,  0.02617447,  0.01494454,\n",
       "          0.01306254,  0.04944306], dtype=float32)},\n",
       " {'topic_idx': 36,\n",
       "  'topic_words': array(['correlation', 'correlations', 'correlated', 'correlate',\n",
       "         'correlates', '비율', 'neuroethics', 'coefficient', 'neurosci',\n",
       "         'coefficients', 'intrinsic', 'ratio', 'neurosurg', 'neuronal',\n",
       "         'median', 'neurogenesis', 'neurobiological', 'neuro',\n",
       "         'neurosciences', 'differentiated', 'neural', 'neuroimaging',\n",
       "         'probabilistic', 'neuroscience', '관계', 'clustering', 'networks',\n",
       "         'neuroscientific', 'interconnected', 'statistically', 'intervals',\n",
       "         'dataset', 'normality', 'relations', 'relation', 'distinctiveness',\n",
       "         'neurol', 'categorical', 'covariance', 'alzheimers',\n",
       "         'normalization', 'statistical', 'neurons', 'individually',\n",
       "         'somatosensory', 'neurobiol', 'relationship', 'datasets', 'neuron',\n",
       "         'cohort'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.04979423, -0.00699782, -0.04938174, -0.00224706, -0.04872973,\n",
       "          0.02410708, -0.01005018, -0.01416126, -0.01124366,  0.04977274,\n",
       "          0.00515881, -0.04523466,  0.0496552 , -0.01305616, -0.04937185,\n",
       "          0.04965221,  0.00883252, -0.0066143 ,  0.04898245,  0.02721286,\n",
       "          0.02021981, -0.04969602, -0.04977661,  0.04936011, -0.0497943 ,\n",
       "         -0.03774543,  0.04225837,  0.04173508, -0.01920646, -0.01626094,\n",
       "         -0.02696766, -0.02729221,  0.00971529, -0.04977525,  0.01507528,\n",
       "         -0.04910735, -0.04261112,  0.00489703,  0.00909895, -0.04928368,\n",
       "          0.00311429,  0.03898877,  0.04941113, -0.01017317, -0.00489268,\n",
       "         -0.04896842,  0.0497943 ,  0.01253949, -0.02228467, -0.00988696,\n",
       "         -0.00627878, -0.0294078 ,  0.03238662,  0.04768676,  0.0471958 ,\n",
       "         -0.0329397 ,  0.04467655,  0.02208186, -0.00796652,  0.04979348,\n",
       "         -0.00556166,  0.04978486, -0.04502784, -0.04608158, -0.02424906,\n",
       "         -0.03143226,  0.04694865,  0.00704082, -0.03084472,  0.00410066,\n",
       "         -0.0218678 ,  0.03117009, -0.01870045, -0.04978185, -0.04128337,\n",
       "         -0.0495808 ,  0.04973933,  0.00029494, -0.04368334, -0.04979429,\n",
       "         -0.0497943 , -0.0497138 ,  0.03651891,  0.04869475, -0.04976833,\n",
       "          0.00267977, -0.04977189,  0.01959814, -0.0289283 , -0.04979391,\n",
       "         -0.03223994, -0.04935078, -0.04439894, -0.04948599,  0.0414774 ,\n",
       "          0.04979062,  0.0459743 ,  0.04966342,  0.04051258,  0.01889719,\n",
       "          0.04977538,  0.03326607,  0.01427474, -0.02451129,  0.01763007,\n",
       "          0.00948361, -0.04979394, -0.0470758 ,  0.04370138,  0.04952628,\n",
       "          0.03415232, -0.04945174, -0.04913492, -0.0188145 ,  0.038888  ,\n",
       "         -0.00075999,  0.03592315,  0.01399622, -0.04953013,  0.02445173,\n",
       "         -0.04028364,  0.03488379,  0.04912853, -0.01321284, -0.01696167,\n",
       "          0.03875388,  0.04979426,  0.04468361, -0.04885175,  0.01461305,\n",
       "         -0.04976303, -0.02311864,  0.04968998,  0.04966447, -0.0223004 ,\n",
       "          0.04979395, -0.04903664, -0.01493779,  0.04978337,  0.04349426,\n",
       "          0.04961944, -0.00844104,  0.0497544 , -0.04017851,  0.04609225,\n",
       "          0.04629817, -0.04966392,  0.04753896,  0.04968777,  0.04963234,\n",
       "          0.04977865,  0.04855002, -0.01794872, -0.03731302, -0.00793584,\n",
       "         -0.00339003,  0.02844079, -0.01385802, -0.00631522, -0.02752547,\n",
       "          0.04576271, -0.04855713, -0.04972162, -0.03534507, -0.03308799,\n",
       "         -0.04796139, -0.04770719,  0.01550604, -0.04979077,  0.04943605,\n",
       "         -0.00933276, -0.00495677,  0.01893931,  0.00626603, -0.04102005,\n",
       "          0.04638327,  0.0497409 ,  0.04918102,  0.01655787,  0.03764713,\n",
       "          0.04911049, -0.02805564, -0.0409048 ,  0.02882689, -0.02775672,\n",
       "         -0.01081937,  0.04949299,  0.04977139, -0.02266208,  0.01310887,\n",
       "         -0.04055091, -0.0335359 , -0.02262155, -0.03725082, -0.01486897,\n",
       "          0.01724012, -0.04583972,  0.02658941,  0.04979358,  0.02342303,\n",
       "         -0.04280528,  0.04161081, -0.01295216,  0.0102524 , -0.00242949,\n",
       "         -0.04972221, -0.04979244,  0.04104111,  0.03700692,  0.0492029 ,\n",
       "          0.03040696,  0.0085657 , -0.04392242, -0.00345523,  0.04929997,\n",
       "          0.01656802,  0.02929167, -0.04979407,  0.0366482 , -0.02314689,\n",
       "          0.04778282,  0.04847639,  0.04975785,  0.04974112, -0.04882873,\n",
       "          0.01579952, -0.04979429, -0.03644601,  0.04156434, -0.0417759 ,\n",
       "         -0.02644495,  0.04615469, -0.04876705,  0.03452235,  0.02179053,\n",
       "         -0.04524534,  0.02946942,  0.04592606,  0.0497937 , -0.04899178,\n",
       "         -0.02187749,  0.03136004, -0.04950866,  0.04057929,  0.04767955,\n",
       "         -0.04928327,  0.04683134, -0.04347808, -0.02249155,  0.0234769 ,\n",
       "         -0.02811339, -0.04978583,  0.03128819, -0.01062396, -0.02791418,\n",
       "          0.01784724, -0.00929168, -0.00927966, -0.04964998,  0.03725009,\n",
       "         -0.00127904,  0.04971208, -0.04967562,  0.01544124,  0.00418465,\n",
       "         -0.0497943 , -0.04710694,  0.03531261, -0.02545764,  0.04211161,\n",
       "          0.03532691, -0.03769973, -0.04978188, -0.04540305, -0.04729864,\n",
       "         -0.02337281, -0.04319096,  0.02429013, -0.04979428,  0.02204985,\n",
       "         -0.04848061, -0.01116556,  0.049764  ,  0.04961535, -0.01061806,\n",
       "          0.04894233, -0.0483583 , -0.04879155, -0.01783365,  0.0367265 ,\n",
       "          0.04967067,  0.04976106,  0.03033422, -0.04914922, -0.04965702,\n",
       "         -0.0419294 ,  0.02591207,  0.04637533,  0.04965757,  0.04934768,\n",
       "         -0.04912698,  0.04946563, -0.03863316, -0.01636297, -0.04979426,\n",
       "         -0.02217842, -0.02410081,  0.0428757 , -0.04182995, -0.00381461,\n",
       "         -0.04974622, -0.03234451, -0.01968219, -0.04976925,  0.04979296,\n",
       "          0.04951995,  0.02168471, -0.04977903,  0.00170542, -0.04542714,\n",
       "          0.00738907, -0.049794  ,  0.01172816,  0.04978625, -0.03515161,\n",
       "         -0.0136699 , -0.04856919, -0.04770228, -0.01576583,  0.04451779,\n",
       "         -0.04783256, -0.03952964, -0.03444276, -0.0177742 , -0.01562179,\n",
       "          0.03596782, -0.04947602, -0.04101661, -0.04979194,  0.04280793,\n",
       "         -0.04956427,  0.00959389, -0.02237345, -0.04722083, -0.00517307,\n",
       "          0.04899135,  0.04979365,  0.01386703, -0.04308334,  0.04416853,\n",
       "          0.04977125,  0.0484073 , -0.01291931,  0.0482546 , -0.00509903,\n",
       "          0.04973972,  0.00891048,  0.049185  , -0.04867407, -0.04458094,\n",
       "          0.04426758, -0.04230008,  0.04934603, -0.02654761, -0.04423166,\n",
       "         -0.0022326 , -0.02710925,  0.01766046, -0.03435155,  0.02131011,\n",
       "          0.04288215,  0.03600668, -0.04003661,  0.04943301,  0.03035454,\n",
       "         -0.04929648,  0.02336942, -0.03540027, -0.03103617,  0.01373695,\n",
       "          0.04944873, -0.04580978,  0.04328997, -0.02822318,  0.02208998,\n",
       "          0.0497943 ,  0.04241423, -0.04975772,  0.04979391, -0.03378817,\n",
       "          0.02907955, -0.04565618, -0.03087938,  0.04971521, -0.03875145,\n",
       "          0.01062167,  0.04979316, -0.01997149, -0.04976828,  0.03126805,\n",
       "          0.0497833 ,  0.04928388,  0.03560081,  0.04972021, -0.04979366,\n",
       "          0.02916418,  0.04589792, -0.0445643 ,  0.03981417, -0.04122681,\n",
       "          0.04000589, -0.04971845,  0.01485428,  0.04979428,  0.03835174,\n",
       "          0.04979358, -0.00220441, -0.04907094,  0.04863104,  0.04821932,\n",
       "         -0.0497904 , -0.04979151,  0.04749329,  0.04975427,  0.04977019,\n",
       "         -0.03098856, -0.04979291, -0.0271126 , -0.01574485,  0.04633785,\n",
       "         -0.04924794, -0.03314345, -0.01778209, -0.01971244,  0.04925726,\n",
       "          0.01190411,  0.04464614, -0.04924034, -0.0497943 ,  0.03558321,\n",
       "         -0.03495647, -0.04588087,  0.01626891, -0.04979407,  0.0431533 ,\n",
       "         -0.00087169, -0.02462805, -0.01144133, -0.02935722,  0.01236412,\n",
       "         -0.04431689, -0.03737225,  0.03877841, -0.0313535 , -0.04909062,\n",
       "          0.03069956,  0.0460297 ,  0.04523678,  0.01166826, -0.02556123,\n",
       "         -0.00387815, -0.04727039,  0.00534086, -0.04977133,  0.03030376,\n",
       "         -0.04974059, -0.04571785,  0.00087983,  0.04978108,  0.00679932,\n",
       "         -0.01462543,  0.04801833, -0.0493874 , -0.01058216, -0.03815035,\n",
       "         -0.04378805, -0.02928468, -0.04861664, -0.04592235, -0.03866495,\n",
       "          0.03392034,  0.0497943 , -0.04791027, -0.00613005,  0.04361157,\n",
       "         -0.04494257, -0.04523405, -0.04978108, -0.04498083, -0.02228189,\n",
       "          0.04811632,  0.0374647 , -0.02319451,  0.04897144, -0.04979246,\n",
       "          0.01575031, -0.04962351, -0.01480925,  0.0478885 ,  0.04883246,\n",
       "          0.04921516, -0.049794  ,  0.0497943 , -0.02134964, -0.04976062,\n",
       "         -0.04978948, -0.03275776, -0.04964191, -0.00422184, -0.04979021,\n",
       "          0.01693605, -0.01242411], dtype=float32)},\n",
       " {'topic_idx': 37,\n",
       "  'topic_words': array(['correlation', 'correlations', 'coefficient', 'covariance',\n",
       "         'statistics', 'statistical', 'statistically', 'variance',\n",
       "         'coefficients', 'probabilistic', 'correlated', 'probability',\n",
       "         'statistic', 'variables', 'variances', 'correlate', 'correlates',\n",
       "         '변수', 'variability', 'relation', 'relations', 'regression', '통계',\n",
       "         'probabilities', '파라미터', 'estimator', 'variable', '통계청', 'ratio',\n",
       "         'proportional', '관계', 'relationship', '추정', 'parametric', 'stats',\n",
       "         '잠재변수', 'multivariate', 'predictive', 'approximation',\n",
       "         'nonparametric', 'estimated', 'relationships', 'relative',\n",
       "         'estimate', 'relevance', 'calculations', 'estimation', '비율',\n",
       "         'calculation', 'estimates'], dtype='<U15'),\n",
       "  'topic_vector': array([-6.56615645e-02, -1.56297889e-02, -2.98094307e-03, -3.02832015e-03,\n",
       "         -4.39345203e-02, -4.29608952e-03, -1.52324429e-02, -1.79588899e-03,\n",
       "          2.41383519e-02, -1.15333023e-02, -1.89307928e-02,  2.57783383e-02,\n",
       "          5.32352924e-02, -2.11405884e-02, -6.61478713e-02, -1.84344519e-02,\n",
       "         -4.29462641e-03, -1.67131666e-02,  4.61883210e-02,  4.53968868e-02,\n",
       "         -1.37089295e-02, -2.72174831e-02, -6.06740527e-02,  5.33733293e-02,\n",
       "         -6.48977011e-02, -4.81415428e-02,  2.19761431e-02,  5.08211926e-03,\n",
       "         -9.52967443e-03, -3.27921659e-02, -6.21634722e-02,  1.44318342e-02,\n",
       "          2.61218827e-02, -5.35793640e-02, -2.45769101e-04, -1.43683683e-02,\n",
       "         -5.39937802e-02,  4.61839959e-02,  7.91712664e-03,  2.24765427e-02,\n",
       "         -2.60353088e-04, -4.64111604e-02,  2.19468009e-02, -5.76173030e-02,\n",
       "         -2.49414910e-02, -4.32541929e-02,  5.51561303e-02, -3.34213972e-02,\n",
       "         -5.59100024e-02,  3.40076676e-03, -2.42774002e-02,  4.33722790e-03,\n",
       "          8.59740097e-03, -1.66737866e-02,  3.64566706e-02, -4.81681824e-02,\n",
       "          1.74524579e-02,  1.64774228e-02,  1.70977134e-02,  2.59316117e-02,\n",
       "          1.42625114e-02,  4.07140255e-02,  2.38390863e-02, -3.94067401e-03,\n",
       "         -1.80425644e-02,  3.75641021e-03, -1.46127315e-02,  2.47551687e-02,\n",
       "         -1.93645968e-03,  9.01007652e-03,  2.30513257e-03,  8.32167361e-03,\n",
       "          6.31633727e-03, -4.10123840e-02, -4.26532738e-02, -5.89115545e-02,\n",
       "          4.89841066e-02,  5.60679808e-02,  5.61081851e-03, -6.47693351e-02,\n",
       "         -6.57985061e-02, -3.92343178e-02, -1.09202219e-02,  3.15036252e-02,\n",
       "         -2.94221682e-03,  1.63760334e-02, -4.79584672e-02, -9.64645576e-03,\n",
       "         -3.36106159e-02, -4.70381379e-02, -3.20322365e-02, -2.37056874e-02,\n",
       "          3.86720374e-02, -4.55437340e-02,  4.39302884e-02,  5.60828187e-02,\n",
       "          3.98593172e-02,  2.34391838e-02,  3.42167839e-02,  1.41254896e-02,\n",
       "          5.43821342e-02,  1.15414932e-02,  5.45887128e-02, -1.05334893e-02,\n",
       "          4.86982092e-02, -5.96539639e-02, -2.35394966e-02, -2.88015790e-02,\n",
       "          2.17681099e-02,  3.00382841e-02,  5.59091493e-02, -2.12291870e-02,\n",
       "         -4.50800285e-02, -1.55795906e-02,  1.10256448e-02,  2.00499091e-02,\n",
       "          9.78661142e-03, -2.89248824e-02, -2.90890094e-02,  2.38913167e-02,\n",
       "         -3.08221672e-02,  4.10986952e-02,  2.61290632e-02,  3.26850750e-02,\n",
       "          4.17353697e-02, -1.14002982e-02, -5.07449545e-02,  2.78808512e-02,\n",
       "         -3.53635140e-02,  5.29541411e-02, -5.35645820e-02,  3.19592319e-02,\n",
       "          5.77153489e-02,  3.05633005e-02, -1.43698556e-02,  4.52475138e-02,\n",
       "          3.21384296e-02,  4.30197502e-03,  5.12442775e-02,  1.73096284e-02,\n",
       "         -3.95509787e-03, -1.26093384e-02,  1.76442303e-02, -4.14452776e-02,\n",
       "          5.58682866e-02, -2.74770614e-02, -4.21413481e-02,  8.89386423e-03,\n",
       "          2.12476347e-02,  2.93086469e-02,  4.19970118e-02,  3.38433054e-03,\n",
       "          1.80755667e-02, -2.99605038e-02,  4.07006070e-02, -2.15576943e-02,\n",
       "         -2.19841134e-02,  1.77734792e-02,  1.40868407e-02, -1.41267562e-02,\n",
       "         -3.39194550e-03, -2.13161912e-02,  1.26037644e-02, -4.86167893e-02,\n",
       "         -2.80431975e-02, -3.00205145e-02, -9.56545305e-03,  5.03003923e-03,\n",
       "         -2.93538459e-02,  5.05383536e-02,  1.24996314e-02, -1.23465555e-02,\n",
       "          1.98373292e-02, -1.73251610e-02, -2.42320746e-02,  8.78903456e-03,\n",
       "          3.31518687e-02,  2.44275127e-02, -2.74986662e-02,  1.31293070e-02,\n",
       "          3.42817828e-02,  2.78494647e-03, -1.35317463e-02,  4.05459963e-02,\n",
       "         -4.29274701e-02, -2.29948107e-02,  4.12567034e-02,  4.56710979e-02,\n",
       "         -4.31396440e-02, -6.48602396e-02, -9.27111693e-03, -1.32817132e-02,\n",
       "          3.59473042e-02, -4.12898250e-02,  1.14447521e-02,  1.71431638e-02,\n",
       "         -6.64506480e-02, -2.51089633e-02,  2.90915202e-02,  1.34047552e-03,\n",
       "          1.28429953e-03,  4.33031879e-02, -3.07743512e-02,  1.27246315e-02,\n",
       "         -2.39371192e-02, -3.77681032e-02, -4.75143194e-02,  1.10013143e-05,\n",
       "          7.95130711e-03,  5.19795977e-02, -3.58192883e-02,  1.23911100e-02,\n",
       "         -6.61592484e-02,  9.49700829e-03,  4.11000550e-02, -5.22142425e-02,\n",
       "         -3.48909013e-02, -2.77779233e-02,  4.34377007e-02, -2.14430522e-02,\n",
       "          1.01102935e-02,  4.09366563e-02,  4.68962751e-02,  3.15333232e-02,\n",
       "         -6.05498962e-02,  9.33012646e-03, -4.60558049e-02, -2.53348015e-02,\n",
       "         -8.77752900e-04, -3.65356682e-03, -3.56510766e-02,  5.08214496e-02,\n",
       "         -1.17979227e-02, -3.98471430e-02, -7.98566267e-03, -4.40308033e-03,\n",
       "         -2.06620507e-02, -5.72669145e-04, -3.79052088e-02, -1.85781512e-02,\n",
       "         -5.91292325e-03, -3.61068808e-02, -2.61739809e-02,  1.61195155e-02,\n",
       "          4.24638353e-02, -4.02850807e-02, -1.79710090e-02,  3.89457378e-03,\n",
       "          2.86106002e-02,  4.19382751e-02, -2.48044990e-02, -3.37937213e-02,\n",
       "          1.57300872e-03, -5.00488514e-03, -2.03472432e-02, -2.26402599e-02,\n",
       "         -3.19229402e-02,  5.93012897e-03, -3.81358229e-02,  2.09093858e-02,\n",
       "          1.51239615e-02, -1.22486532e-03, -3.39229479e-02, -2.52778865e-02,\n",
       "          4.80811335e-02, -5.47936521e-02, -2.11302079e-02, -1.48432236e-02,\n",
       "         -2.47784909e-02, -1.62696075e-02,  5.96659398e-03, -4.81771417e-02,\n",
       "         -4.90560196e-02, -3.79935391e-02,  6.25837455e-03,  4.10233922e-02,\n",
       "         -4.56866585e-02,  3.72595116e-02, -5.82084730e-02, -3.71976085e-02,\n",
       "         -5.43965735e-02, -7.30210496e-03,  3.96310873e-02, -1.27301514e-02,\n",
       "         -1.42162750e-02,  4.13085930e-02, -3.46381962e-02, -3.47819515e-02,\n",
       "         -1.92850661e-02,  3.74146439e-02,  2.97048073e-02,  4.80933562e-02,\n",
       "          2.28098463e-02,  3.25955898e-02, -1.66531503e-02,  2.21757311e-02,\n",
       "         -5.24894930e-02,  3.39777544e-02,  4.70348969e-02,  1.81849357e-02,\n",
       "         -5.77367544e-02,  3.89659181e-02, -5.08645140e-02, -4.96483259e-02,\n",
       "         -6.71859756e-02, -1.23133650e-02,  1.93476565e-02, -1.48578389e-02,\n",
       "         -4.14492153e-02, -1.78009626e-02, -2.05900241e-02, -1.31642716e-02,\n",
       "         -3.88834961e-02, -4.49780747e-02,  4.23781648e-02,  3.78055200e-02,\n",
       "          1.71873588e-02, -2.95961555e-02, -3.31803015e-03, -1.48623867e-03,\n",
       "         -1.35778254e-02,  3.68237123e-02, -8.77199881e-03,  2.93424781e-02,\n",
       "         -3.12401447e-02, -2.21576691e-02, -3.19586657e-02, -4.82021505e-03,\n",
       "          4.74627968e-03,  2.01414502e-03, -4.91361544e-02, -4.05579135e-02,\n",
       "          2.23679431e-02, -2.20726971e-02, -1.47920782e-02,  8.47501960e-03,\n",
       "         -2.95981765e-02, -1.98015478e-02, -5.13459183e-02, -4.56635281e-02,\n",
       "         -5.83687238e-02, -3.24820392e-02,  1.68149583e-02,  1.17550641e-02,\n",
       "         -4.32735384e-02,  4.35638353e-02,  5.24999574e-02,  1.67263299e-02,\n",
       "         -3.63632217e-02,  1.13078975e-03,  2.88363397e-02,  3.36406976e-02,\n",
       "         -2.24300753e-02,  3.22175696e-02,  2.27178335e-02,  2.36751568e-02,\n",
       "          2.70034908e-03,  2.70797666e-02, -4.79958914e-02, -2.50046588e-02,\n",
       "          4.16488573e-02, -3.41378860e-02,  2.26623286e-02,  1.30695319e-02,\n",
       "         -1.96196176e-02,  2.53045280e-02,  2.78841276e-02,  3.33816335e-02,\n",
       "         -3.11977267e-02,  5.68220317e-02,  5.20206057e-02,  2.77727861e-02,\n",
       "         -3.30938064e-02,  5.08265384e-02,  6.43498683e-03, -3.60911004e-02,\n",
       "          3.13585699e-02,  1.19449273e-02, -6.22863397e-02, -5.21211810e-02,\n",
       "          2.27374341e-02, -4.92475592e-02,  5.67887072e-03, -2.03665905e-03,\n",
       "         -5.09521039e-03,  6.01446964e-02,  4.75007556e-02, -3.57249938e-02,\n",
       "          4.94255088e-02,  1.98141895e-02, -2.02270206e-02,  3.65658626e-02,\n",
       "         -4.97654192e-02,  3.81666981e-02, -1.99652277e-02,  6.10795384e-03,\n",
       "          1.11142080e-02,  3.77981202e-03, -5.18178754e-02, -2.25214865e-02,\n",
       "          3.48765887e-02,  3.40044945e-02,  4.79241610e-02, -1.79406051e-02,\n",
       "         -4.83540632e-02,  3.91648747e-02,  3.41128074e-02, -3.31025720e-02,\n",
       "          1.66258160e-02,  3.16901552e-03,  2.38222201e-04,  4.34207497e-03,\n",
       "         -9.72899608e-03,  4.45029233e-03,  1.86253153e-02,  2.22397707e-02,\n",
       "          1.56812090e-02,  1.35865752e-02,  2.94001531e-02,  2.70336121e-02,\n",
       "         -4.90473174e-02, -6.50842637e-02, -3.11819594e-02,  4.95745800e-02,\n",
       "          5.19531555e-02,  1.19690492e-03, -3.46050635e-02, -2.53985506e-02,\n",
       "          3.69785093e-02, -4.13627736e-02, -3.44290659e-02,  1.09715117e-02,\n",
       "         -9.01592616e-03, -1.01348013e-02,  4.61314991e-02,  2.39023771e-02,\n",
       "          2.12213676e-02,  1.03274053e-02, -5.84016070e-02,  3.87865305e-02,\n",
       "         -1.97366439e-02, -2.57711112e-03, -3.41050103e-02, -6.30296692e-02,\n",
       "         -1.81251485e-02, -5.13997413e-02,  4.41955104e-02,  2.25686915e-02,\n",
       "         -2.35328060e-02, -1.23529823e-03, -3.11427675e-02, -1.08194668e-02,\n",
       "         -1.10776378e-02, -2.86621470e-02, -4.17714827e-02, -3.97974327e-02,\n",
       "          1.78958029e-02,  7.19719706e-03,  3.41701992e-02,  4.28303368e-02,\n",
       "         -1.34015959e-02, -2.09817700e-02,  3.01149823e-02, -5.84069490e-02,\n",
       "          4.31373790e-02, -3.88375930e-02,  4.46086004e-03, -3.41097526e-02,\n",
       "          6.19554184e-02, -2.78883759e-04,  3.08029000e-02, -1.19480388e-02,\n",
       "         -1.27448794e-02,  3.65257189e-02, -5.02424166e-02, -3.08488440e-02,\n",
       "          5.02230935e-02,  1.26430644e-02, -1.48324901e-02, -4.17327099e-02,\n",
       "          5.11657186e-02,  6.62716851e-02, -2.65282672e-02,  4.58456902e-03,\n",
       "          4.05962989e-02,  2.33812891e-02, -2.65181679e-02, -5.85639216e-02,\n",
       "          1.50378775e-02,  6.27171574e-03, -2.13430525e-04,  3.64171788e-02,\n",
       "         -3.10929921e-02,  9.13242158e-03, -1.92934088e-02, -3.14910039e-02,\n",
       "          3.73341353e-03, -3.04091275e-02,  2.25716252e-02, -1.93387773e-02,\n",
       "          1.87857114e-02, -4.47027646e-02,  6.56089708e-02, -6.77547278e-03,\n",
       "         -5.33861220e-02, -5.06703369e-02,  2.03158427e-02, -2.16137301e-02,\n",
       "          4.24155109e-02, -1.65042523e-02, -2.23405100e-02,  3.21303234e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 38,\n",
       "  'topic_words': array(['커널', 'linux', 'ubuntu', 'ssd', '부팅', 'partition', '명령어', 'bashrc',\n",
       "         '우분투', 'commands', '명령', '파티션', 'gb', 'sd', 'directory', 'command',\n",
       "         'kernel', 'stdout', 'canonical', 'sudo', 'cbind', 'unix', 'grep',\n",
       "         'cpu', 'xorg', 'config', '메모리', '노드', 'fpn', 'nodes', 'localhost',\n",
       "         'optimization', 'neuronal', 'node', 'system', 'subprocess',\n",
       "         'systematic', 'sys', 'wiki', 'defaults', 'script', 'neurosci',\n",
       "         'files', 'optimize', '리눅스', 'multiprocessing', 'default',\n",
       "         'synaptic', 'fpcn', 'systems'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.60728945e-02,  5.18946834e-02,  4.80024479e-02,  1.40608028e-02,\n",
       "          1.40332878e-02, -5.58480173e-02, -3.45677771e-02,  1.68144088e-02,\n",
       "          4.39985245e-02, -2.93203369e-02,  1.75404549e-02, -1.58294681e-02,\n",
       "          3.96648571e-02,  3.31443772e-02, -3.47947143e-03,  2.83109141e-03,\n",
       "         -4.64709848e-03, -8.40210728e-03,  2.69377884e-02,  5.57171591e-02,\n",
       "          1.76196713e-02,  3.20134349e-02,  4.86613484e-03,  1.74605325e-02,\n",
       "         -5.57118244e-02, -1.21685630e-02,  6.19716011e-03, -5.59167713e-02,\n",
       "          2.44030473e-03, -5.29119112e-02, -4.63722162e-02,  4.55743261e-02,\n",
       "          1.32405264e-02, -5.32355793e-02, -4.02273089e-02,  2.33659688e-02,\n",
       "          4.27384907e-03, -3.19053531e-02,  4.19916846e-02,  2.90524513e-02,\n",
       "          3.26500577e-03,  4.47543263e-02,  2.52934620e-02, -1.39891328e-02,\n",
       "          4.28067483e-02, -1.34197867e-03,  4.43143696e-02, -2.96632829e-03,\n",
       "         -3.74463797e-02, -1.35283992e-02, -3.55363488e-02, -3.51909432e-03,\n",
       "          2.32098382e-02, -1.53681254e-02, -4.58043674e-03, -5.58942594e-02,\n",
       "          2.54064351e-02,  4.84014489e-02,  4.34706062e-02,  5.49737215e-02,\n",
       "          1.54995294e-02,  5.44172712e-02,  1.06497714e-02, -5.27419038e-02,\n",
       "         -1.30296545e-02, -2.46635918e-02,  9.04036406e-03, -1.29603744e-02,\n",
       "          3.99124250e-02, -2.58088540e-02, -4.73712794e-02, -1.56277623e-02,\n",
       "         -7.34106079e-03,  4.67095757e-03, -3.82672995e-02,  1.49369007e-02,\n",
       "         -1.21220583e-02, -1.67705733e-02, -1.01237688e-02, -5.63268177e-02,\n",
       "         -5.63254505e-02,  2.08055135e-02, -1.07132392e-02, -1.37986066e-02,\n",
       "          2.01879311e-02,  3.12591530e-02, -2.75170058e-02, -1.78270675e-02,\n",
       "          1.18949013e-02, -5.51795103e-02, -2.56099775e-02, -5.53292781e-03,\n",
       "         -2.42731031e-02, -1.04964487e-02,  4.91101295e-02,  2.09777299e-02,\n",
       "         -5.49382716e-02, -1.37984790e-02,  3.02272793e-02,  2.53859293e-02,\n",
       "          4.72054444e-02,  2.87886318e-02,  1.96407791e-02,  4.06152718e-02,\n",
       "          4.53833975e-02, -3.02834678e-02, -5.18158125e-03, -2.76057478e-02,\n",
       "          4.31226790e-02,  3.64590026e-02,  1.98492091e-02, -5.51470704e-02,\n",
       "         -8.67454000e-05, -1.25366123e-02,  5.23428358e-02, -1.87062696e-02,\n",
       "         -1.07170073e-02,  1.86594427e-02,  2.84038279e-02,  4.33237338e-03,\n",
       "         -2.91476846e-02,  2.29928526e-03,  4.22734916e-02, -3.26447003e-02,\n",
       "          1.67190824e-02,  3.82580161e-02,  1.14278095e-02,  5.13283461e-02,\n",
       "         -1.52993752e-02,  9.40568093e-03, -5.34777157e-02, -3.49530950e-02,\n",
       "          5.62354736e-02, -1.02189844e-02,  1.88378990e-02,  5.26378751e-02,\n",
       "          3.90392803e-02, -2.57522017e-02,  5.40946312e-02,  7.50763342e-03,\n",
       "          2.30320394e-02, -2.20969450e-02,  9.58720688e-03,  3.53988931e-02,\n",
       "          6.70081330e-03, -2.62067169e-02,  3.99034582e-02,  4.80286069e-02,\n",
       "          4.16852087e-02,  2.08246578e-02, -9.78809432e-04,  1.00857103e-02,\n",
       "         -2.76342090e-02, -1.00027760e-02, -2.71862950e-02, -4.48489515e-03,\n",
       "          3.64017636e-02,  5.49244881e-02,  5.18151224e-02, -1.85239185e-02,\n",
       "          5.56206442e-02, -1.96050596e-03,  3.92583646e-02, -4.45994474e-02,\n",
       "          4.39335667e-02, -4.32922542e-02, -1.01892278e-03, -4.63118441e-02,\n",
       "          2.24939678e-02,  1.75625104e-02,  2.82052606e-02, -5.15132807e-02,\n",
       "         -3.24470475e-02, -1.60523076e-02,  2.57584658e-02,  3.91342305e-02,\n",
       "         -5.62228523e-02, -5.38665019e-02, -3.25384885e-02,  3.60030122e-02,\n",
       "          2.18718871e-02, -1.88665520e-02, -2.58443411e-02, -3.45564745e-02,\n",
       "         -2.71075051e-02, -9.65059083e-03, -3.36717628e-02,  5.43972552e-02,\n",
       "          3.24910544e-02,  4.28512953e-02,  1.30895304e-03, -4.84557636e-02,\n",
       "          5.35208732e-02, -2.99661178e-02, -4.12328504e-02, -9.64080449e-03,\n",
       "         -4.58660237e-02, -1.19546207e-03,  1.21181225e-02, -3.79794906e-03,\n",
       "          1.85735282e-02, -1.88674610e-02, -2.42299438e-02, -3.12210266e-02,\n",
       "         -1.24343365e-04, -1.66044999e-02,  1.35146277e-02, -7.31434999e-03,\n",
       "         -9.81305912e-03,  4.08638082e-02,  3.07691470e-02,  2.48355661e-02,\n",
       "          1.55972587e-02,  1.54957352e-02,  3.60820778e-02,  1.75209772e-02,\n",
       "         -2.06171256e-02, -2.10794061e-02, -5.19086085e-02, -9.70956963e-03,\n",
       "         -1.09438002e-02,  4.61538024e-02,  1.82541143e-02,  2.46202317e-03,\n",
       "         -5.62287085e-02, -2.45219227e-02, -5.14079183e-02,  4.65373136e-03,\n",
       "          1.70544442e-02, -3.08817122e-02, -8.06192402e-04,  5.55429868e-02,\n",
       "          1.86835974e-02,  5.04419357e-02, -4.82996367e-03,  4.02285755e-02,\n",
       "         -5.11395372e-02,  4.22902368e-02, -3.42381746e-02,  2.46064607e-02,\n",
       "          1.62145367e-03, -1.70858111e-02, -2.82389391e-02, -2.43607834e-02,\n",
       "          3.27919163e-02,  1.79084036e-02,  4.16526012e-02, -3.76652740e-02,\n",
       "          4.22794819e-02,  4.19397652e-02, -4.90186550e-02, -3.65742855e-02,\n",
       "         -5.62576205e-03,  2.85886228e-02, -2.83131283e-02, -1.35755613e-02,\n",
       "         -1.52769424e-02, -4.41851579e-02, -2.28602216e-02,  1.41684311e-02,\n",
       "          4.70730243e-03,  2.64553111e-02,  5.47680026e-03,  3.20142172e-02,\n",
       "          1.78249143e-02, -5.27682714e-02, -4.56206175e-03,  2.90212464e-02,\n",
       "          5.42530306e-02, -6.34506205e-03, -2.69141253e-02, -3.74544971e-02,\n",
       "         -1.34504065e-02,  4.73210849e-02, -1.93474125e-02, -2.91899573e-02,\n",
       "          4.77796085e-02,  9.14951146e-04, -3.60505134e-02,  6.89018890e-03,\n",
       "          1.43954130e-02,  2.63062846e-02,  7.60523183e-03, -2.33851839e-02,\n",
       "          3.43511663e-02,  3.74759473e-02, -5.58220558e-02,  3.51846893e-03,\n",
       "         -1.67397875e-02, -3.45179550e-02, -2.90787723e-02,  2.95374524e-02,\n",
       "         -2.22552065e-02,  9.00800992e-03, -5.63084781e-02, -3.21596744e-03,\n",
       "         -2.03320961e-02,  2.41936240e-02, -3.43319704e-03,  4.38898765e-02,\n",
       "         -2.03637090e-02, -1.94046181e-02, -3.51509042e-02, -4.43760268e-02,\n",
       "          2.56534200e-02,  1.92015786e-02, -2.77398825e-02,  1.73399150e-02,\n",
       "          4.31151800e-02, -2.33283732e-02,  5.00766523e-02, -6.81597739e-05,\n",
       "         -9.03066806e-03, -2.06616856e-02,  3.24105769e-02,  3.56203727e-02,\n",
       "         -3.12026660e-03, -1.69924721e-02, -7.93288753e-04, -3.21555845e-02,\n",
       "          1.98503751e-02,  2.99145821e-02,  2.43353248e-02,  5.84382238e-03,\n",
       "          1.22726485e-02, -4.22752500e-02, -3.93973403e-02, -2.36351565e-02,\n",
       "          5.49502559e-02,  5.91550162e-03, -6.50360249e-03, -4.33924841e-03,\n",
       "         -4.02692221e-02, -8.88255145e-03,  2.29420140e-02, -7.08664535e-03,\n",
       "          3.73426601e-02, -2.16220971e-02, -5.38670309e-02,  2.55944859e-02,\n",
       "         -2.73443218e-02,  7.17044948e-03, -9.59918369e-03, -4.16638069e-02,\n",
       "          5.39240241e-02,  1.09983413e-02,  3.08764484e-02,  8.03363882e-03,\n",
       "         -3.93871330e-02,  3.46623617e-03,  3.80941294e-02, -2.35451404e-02,\n",
       "          4.09766734e-02, -3.06538288e-02,  4.55850028e-02,  8.80527496e-03,\n",
       "          3.30391116e-02,  3.08452155e-02, -8.09922908e-03, -3.31421830e-02,\n",
       "         -3.72895636e-02,  3.48996781e-02,  4.99659367e-02,  1.11284852e-02,\n",
       "          2.65034358e-03, -2.04642005e-02,  2.28605885e-02,  5.32976203e-02,\n",
       "         -1.64691880e-02,  3.41655910e-02, -3.02195805e-03,  4.63051461e-02,\n",
       "         -3.71882543e-02,  1.82196423e-02, -3.77857983e-02, -2.78562661e-02,\n",
       "          1.78082362e-02,  1.92504693e-02,  3.27929892e-02,  1.04881013e-02,\n",
       "         -2.46509667e-02, -3.64473872e-02,  4.19987403e-02, -5.44418432e-02,\n",
       "          6.26592385e-03,  2.45100986e-02,  5.38997306e-03, -5.63088655e-02,\n",
       "          4.74928617e-02,  3.70450802e-02,  1.66250032e-03, -3.09874769e-02,\n",
       "          2.75338739e-02, -8.62413272e-03, -1.98143329e-02, -5.12963347e-03,\n",
       "          2.82855649e-02,  4.31259163e-02,  1.64682698e-02,  3.87266688e-02,\n",
       "          4.94498126e-02, -3.10948547e-02,  4.02623154e-02,  1.75567064e-02,\n",
       "         -8.45872145e-03, -2.92632431e-02,  1.24128163e-02, -4.05732580e-02,\n",
       "          4.59874310e-02,  2.24050190e-02, -2.13565547e-02,  6.16993569e-03,\n",
       "          1.87553111e-02,  4.20888513e-02,  1.79975219e-02,  1.48000522e-02,\n",
       "          1.98577549e-02,  4.29546423e-02, -3.34783047e-02,  3.33864205e-02,\n",
       "          4.38895375e-02,  1.60660073e-02,  5.02098687e-02,  4.09679376e-02,\n",
       "         -2.40420271e-02, -1.60013642e-05, -7.70805031e-03, -4.93721366e-02,\n",
       "         -3.60048190e-02, -1.51685877e-02,  3.00584454e-02, -1.85133498e-02,\n",
       "          4.44315709e-02,  5.33132404e-02,  4.19905782e-02, -7.85037503e-03,\n",
       "         -1.13586830e-02, -3.22573446e-02, -4.80230339e-02,  4.29885387e-02,\n",
       "         -4.06297296e-02, -2.39519943e-02,  2.13846844e-02, -5.19021638e-02,\n",
       "         -1.21150436e-02, -3.77012640e-02,  3.79282124e-02, -1.21769076e-02,\n",
       "          2.49621812e-02,  3.16384435e-02,  4.05413546e-02,  1.46066351e-02,\n",
       "         -5.15432470e-02, -2.58764476e-02, -1.17058130e-02,  2.17697322e-02,\n",
       "          5.14925411e-03, -3.87303941e-02,  3.46656404e-02,  3.65110077e-02,\n",
       "         -1.26496265e-02, -3.51525769e-02,  5.94897615e-03,  3.03660389e-02,\n",
       "          4.39038761e-02, -3.91236208e-02,  3.54892351e-02,  3.44286375e-02,\n",
       "          5.29515147e-02, -2.97217127e-02,  4.07461450e-02, -2.08305623e-02,\n",
       "         -3.62103246e-02,  9.39691160e-03, -3.49256806e-02,  1.47779733e-02,\n",
       "          2.50618979e-02, -2.94411257e-02,  7.18253339e-03,  4.48826794e-03,\n",
       "          2.06285808e-02,  5.57416379e-02, -6.48618443e-03,  1.68675128e-02,\n",
       "          1.81242041e-02, -1.27226831e-02,  1.09173059e-02, -5.50704896e-02,\n",
       "         -2.08600536e-02,  1.66545936e-03,  2.73439381e-02,  1.85023732e-02,\n",
       "         -1.92443710e-02, -2.24309396e-02, -2.03077625e-02, -4.33722921e-02,\n",
       "         -5.00259697e-02, -2.88206283e-02,  4.30879444e-02,  4.20071892e-02,\n",
       "          1.53867016e-02,  4.73910682e-02,  5.21460176e-02,  3.55865806e-02,\n",
       "         -2.43997872e-02, -5.62707968e-02,  3.45199672e-03,  1.37865357e-02,\n",
       "          9.63613298e-03, -2.24565137e-02, -3.42437439e-02, -3.23762442e-03],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 39,\n",
       "  'topic_words': array(['neurological', 'neuro', 'neurol', 'neurobiological', 'neuronal',\n",
       "         'neuroimaging', 'neurosciences', 'neurology', 'neurosci',\n",
       "         'neuroimage', 'neurogenesis', 'neuroscience', 'neurons', 'neuron',\n",
       "         'neuroethics', 'neuroscientific', 'neurobiology', 'neural',\n",
       "         'neuroscientists', 'neuroscientist', 'alzheimers', 'neurobiol',\n",
       "         'neurosurg', 'alzheimer', 'brainstem', '신경망', 'cerebrospinal',\n",
       "         'brain', 'brains', '신경', 'neurofeminist', 'cerebral',\n",
       "         'neurocultures', 'cognitive', 'midbrain', 'memory', 'forebrain',\n",
       "         'schizophrenia', 'neurofeminism', '메모리', 'cognitively',\n",
       "         'cerebellum', 'dementia', 'sensory', 'psychological', 'memories',\n",
       "         'mental', 'somatosensory', 'synapses', 'syndromes'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.06064594e-02, -9.06029076e-04, -2.20772829e-02,  1.58887729e-03,\n",
       "         -3.64679918e-02,  2.87541207e-02, -2.89897174e-02,  6.73936866e-03,\n",
       "          1.22622831e-03,  5.17465658e-02,  1.28418030e-02, -3.15951034e-02,\n",
       "          7.41803460e-03, -1.13951145e-02, -5.31660914e-02,  2.91763637e-02,\n",
       "          2.32553724e-02,  5.18682972e-03,  4.13793735e-02,  4.67266329e-02,\n",
       "         -2.80809179e-02, -4.98989373e-02,  1.55996680e-02,  4.19245176e-02,\n",
       "         -5.57278097e-02,  1.32821416e-02, -2.51412913e-02,  1.21689066e-02,\n",
       "          5.42816706e-02, -6.43700696e-05, -3.74406464e-02,  4.91801053e-02,\n",
       "          7.79055664e-03, -5.42647652e-02,  2.32643560e-02, -3.61217409e-02,\n",
       "         -4.56630290e-02,  8.57847452e-04,  1.46584911e-02, -5.45096099e-02,\n",
       "         -5.23937903e-02,  3.64717580e-02,  4.89450730e-02, -4.08582054e-02,\n",
       "         -4.39245813e-02,  2.26471405e-02,  5.25204986e-02,  3.36138462e-03,\n",
       "          2.65464578e-02, -3.64147127e-05,  3.67296413e-02, -4.85002762e-03,\n",
       "          1.68528799e-02,  2.40643788e-03,  3.85628198e-03, -3.37505862e-02,\n",
       "          3.43064144e-02,  1.95479486e-02,  2.15775277e-02,  3.94787677e-02,\n",
       "         -1.39942197e-02,  3.30359899e-02, -5.23324609e-02, -2.74764840e-02,\n",
       "          5.34822000e-03,  2.80696359e-02,  4.11116146e-02, -4.04424816e-02,\n",
       "         -1.88889652e-02, -3.74568515e-02,  1.14129856e-02,  1.18272379e-02,\n",
       "          3.04444935e-02, -1.49189467e-02, -2.52411980e-03, -1.33289676e-03,\n",
       "          5.28625734e-02,  3.25540714e-02, -1.68271381e-02, -5.50781526e-02,\n",
       "         -5.57340235e-02, -3.85308452e-02,  2.30808426e-02,  4.98855375e-02,\n",
       "         -1.84034500e-02, -2.95575964e-03, -4.33280952e-02,  3.68784629e-02,\n",
       "          1.62052680e-02,  1.84417162e-02, -5.06783836e-02, -4.64669429e-02,\n",
       "         -5.11672832e-02, -4.73484285e-02,  2.72509903e-02,  5.37577905e-02,\n",
       "          5.48080839e-02,  4.63089980e-02,  3.76134627e-02,  1.62467193e-02,\n",
       "          1.92293320e-02,  2.59029474e-02,  2.97138398e-03, -7.02157989e-03,\n",
       "         -1.69193968e-02,  4.46738787e-02, -4.59025092e-02, -5.76810958e-03,\n",
       "          2.50251591e-02,  4.91569899e-02,  5.17408140e-02, -5.55539429e-02,\n",
       "         -2.07254849e-03,  3.54442783e-02,  4.47516143e-03, -8.33544973e-03,\n",
       "          4.40203510e-02,  4.25819419e-02, -5.37110716e-02,  4.26037125e-02,\n",
       "         -3.53050195e-02,  5.27700521e-02,  3.74682918e-02, -3.00899576e-02,\n",
       "         -4.59866179e-03,  4.64501679e-02,  5.31516038e-02,  1.05300685e-02,\n",
       "         -4.20062989e-02,  5.10646589e-02, -3.80862057e-02,  1.51205184e-02,\n",
       "          3.02332770e-02,  5.21816202e-02, -1.94488540e-02,  5.03421687e-02,\n",
       "         -4.54912074e-02,  2.89590750e-02,  5.34577556e-02,  1.03968922e-02,\n",
       "          4.69018035e-02, -3.73774022e-03,  8.85393005e-03,  3.10646626e-03,\n",
       "          5.02309352e-02,  2.65282150e-02,  2.83039119e-02,  4.04012315e-02,\n",
       "         -8.21854547e-03,  5.24815284e-02,  4.69507873e-02,  4.30461466e-02,\n",
       "         -3.48581858e-02, -4.52421457e-02,  1.88799426e-02, -3.68257463e-02,\n",
       "         -1.77986976e-02, -2.49738544e-02,  1.60862710e-02, -5.16870432e-02,\n",
       "          4.31736372e-02, -3.22587937e-02, -4.29671220e-02,  2.45429203e-02,\n",
       "          3.85691710e-02, -2.01270487e-02,  2.35176086e-02, -1.76334509e-03,\n",
       "         -4.48611937e-02,  5.18178530e-02, -4.24706824e-02, -2.89092604e-02,\n",
       "          2.35200673e-02,  5.04989037e-03, -5.17140031e-02, -2.72985529e-02,\n",
       "          3.09602823e-02,  1.19359754e-02,  1.99495126e-02,  3.04912329e-02,\n",
       "          7.10759545e-03, -4.00776863e-02, -5.12318909e-02, -5.38246483e-02,\n",
       "          1.08634559e-02, -3.35361250e-02,  2.87419796e-04,  4.22211103e-02,\n",
       "          4.22217250e-02, -1.77522358e-02, -1.22968080e-02, -9.01239272e-03,\n",
       "          2.96864361e-02, -4.51594256e-02, -4.77412455e-02, -1.56451836e-02,\n",
       "         -2.00755559e-02,  3.28598469e-02,  5.38781583e-02,  2.30136956e-03,\n",
       "         -3.96455415e-02,  4.51633297e-02,  2.28805002e-02, -5.56084700e-02,\n",
       "          2.72921529e-02, -4.04384024e-02, -5.11209816e-02,  3.34405191e-02,\n",
       "          4.13482599e-02,  1.85540095e-02,  3.32826562e-02, -3.61489840e-02,\n",
       "          1.20383101e-02, -2.16142982e-02,  4.74573486e-02,  1.73267946e-02,\n",
       "          4.69040079e-03, -2.17235908e-02, -5.45176603e-02,  2.20773797e-02,\n",
       "         -1.30765317e-02,  4.16198038e-02,  4.35710102e-02,  3.24403159e-02,\n",
       "         -5.20631708e-02, -4.54431288e-02, -5.22997566e-02,  4.55003344e-02,\n",
       "         -7.02889031e-03, -1.02502713e-02,  9.92874894e-03,  5.54077886e-02,\n",
       "         -3.09257414e-02,  4.71788310e-02,  1.20020071e-02,  3.40509638e-02,\n",
       "          2.19179820e-02, -9.08551831e-03,  4.77910154e-02, -2.71619577e-02,\n",
       "         -6.10141968e-03,  3.81384641e-02, -3.43163386e-02, -3.29689831e-02,\n",
       "          4.20609452e-02,  7.51052564e-03,  4.66778167e-02,  3.72494683e-02,\n",
       "          2.16918532e-02,  4.43271138e-02, -3.70968245e-02, -4.94621433e-02,\n",
       "          5.53026609e-02, -7.44670397e-03,  2.66614184e-02,  1.69646461e-04,\n",
       "          4.39473689e-02,  4.90623564e-02, -2.76992396e-02,  4.94383462e-02,\n",
       "         -3.54623310e-02,  4.04048450e-02, -1.15439913e-03,  2.67577861e-02,\n",
       "          3.17799598e-02, -5.46794273e-02, -3.11401635e-02, -1.04272990e-02,\n",
       "         -1.48949074e-02,  2.73296759e-02,  3.32746957e-03, -3.19670476e-02,\n",
       "         -2.73828581e-02, -3.94856334e-02, -2.45935749e-02,  3.47062834e-02,\n",
       "         -4.02763449e-02,  4.20842506e-02, -5.23841716e-02, -1.94885060e-02,\n",
       "         -2.85798311e-02, -2.43957695e-02,  3.30381654e-02,  4.40487228e-02,\n",
       "         -2.20804196e-02,  2.48039421e-02, -4.86796647e-02, -5.12828231e-02,\n",
       "          2.24885643e-02, -3.68319862e-02,  4.47974391e-02, -1.30297616e-02,\n",
       "          4.01974320e-02, -1.10495165e-02, -3.40440124e-02, -4.81649749e-02,\n",
       "          3.93884145e-02,  2.49192882e-02,  4.18499000e-02,  5.42074926e-02,\n",
       "         -4.58371006e-02,  4.43929993e-03,  3.74791063e-02, -5.07773124e-02,\n",
       "         -5.19309826e-02, -4.38370816e-02, -3.15706022e-02,  2.94014812e-02,\n",
       "          1.50993196e-02,  4.75353114e-02, -3.89738865e-02, -4.42885421e-02,\n",
       "          1.92839429e-02, -5.42885475e-02,  4.82387841e-02,  4.55399901e-02,\n",
       "         -2.96381419e-03, -4.28984128e-02,  4.33410108e-02, -5.43684363e-02,\n",
       "          3.79210226e-02, -5.57415448e-02, -2.17580348e-02,  6.83275750e-03,\n",
       "         -5.27308844e-02, -3.86361890e-02,  1.40962070e-02, -1.95664521e-02,\n",
       "         -1.07873501e-02,  2.15331540e-02, -2.89773364e-02, -4.49515544e-02,\n",
       "         -4.51703668e-02, -1.42670674e-02, -1.82000324e-02,  1.54245952e-02,\n",
       "         -5.05375415e-02, -2.89960653e-02, -2.11311188e-02,  5.05717285e-02,\n",
       "         -4.24541347e-02, -2.43072417e-02, -7.51656992e-03, -5.36588766e-02,\n",
       "          5.38207255e-02,  5.24889119e-02,  4.46220078e-02, -4.75194715e-02,\n",
       "         -3.64093222e-02,  3.08220591e-02,  4.27343734e-02,  1.80992354e-02,\n",
       "         -1.49319023e-02,  5.36517166e-02, -1.19668590e-02,  4.52123694e-02,\n",
       "          3.51593718e-02,  3.47689353e-02, -3.65155078e-02, -5.22438735e-02,\n",
       "          3.51791829e-02, -1.48144551e-03,  4.98895831e-02, -2.77890470e-02,\n",
       "         -1.75259579e-02,  3.40325125e-02, -2.52063572e-02,  5.07609872e-03,\n",
       "         -2.63934080e-02,  2.04863064e-02,  4.74083275e-02,  1.73488911e-02,\n",
       "          1.98740866e-02,  1.04089938e-02,  3.77600379e-02, -5.10824770e-02,\n",
       "         -1.98721495e-02,  4.10791226e-02, -1.33725228e-02,  6.07913919e-03,\n",
       "          4.94968258e-02, -3.85093689e-02,  4.67754453e-02,  3.17416526e-02,\n",
       "          9.36948042e-03,  5.55531122e-02,  4.77391370e-02, -4.64224704e-02,\n",
       "          5.36206178e-02, -2.50401441e-02,  1.45282438e-02, -1.74775813e-02,\n",
       "         -6.60773227e-03,  4.98811454e-02, -5.24199456e-02,  1.49566680e-02,\n",
       "          5.08974232e-02, -1.40540870e-02, -3.68358083e-02,  3.97780351e-02,\n",
       "          3.52129675e-02,  4.05464135e-02,  1.62220467e-02,  1.38237299e-02,\n",
       "         -2.16934830e-02, -3.86075638e-02,  4.07989398e-02, -3.87243293e-02,\n",
       "          3.40146869e-02,  4.12652493e-02,  3.24511975e-02, -3.07454634e-02,\n",
       "          2.16126442e-02,  5.39768599e-02,  1.96513813e-02,  5.41827232e-02,\n",
       "         -3.18915903e-04, -4.12864462e-02,  3.01669594e-02,  5.18978536e-02,\n",
       "         -4.09377851e-02, -3.52337994e-02,  5.03652804e-02,  4.30530123e-02,\n",
       "          4.48147692e-02,  2.62523293e-02, -4.03011329e-02, -4.11470644e-02,\n",
       "         -4.54713963e-02,  6.82924502e-03, -4.43958044e-02,  2.46353894e-02,\n",
       "          3.60230845e-03, -2.85442080e-02,  4.61023115e-02,  4.22313623e-02,\n",
       "          1.34926466e-02, -5.10587990e-02, -5.50770424e-02,  5.37839234e-02,\n",
       "          1.92657392e-02, -7.09965499e-03,  9.28948913e-03, -5.24339490e-02,\n",
       "          3.45972665e-02, -1.75778735e-02, -3.69653590e-02,  4.93654497e-02,\n",
       "         -1.45285875e-02,  4.64595295e-02, -2.13977136e-03, -5.07945903e-02,\n",
       "          2.85015460e-02,  4.41478705e-03, -3.88702415e-02, -5.63485734e-03,\n",
       "          3.36331390e-02,  4.13798392e-02, -3.78152616e-02,  2.28479188e-02,\n",
       "         -3.65961753e-02, -5.42968996e-02, -3.79404128e-02, -4.73282933e-02,\n",
       "          4.42098193e-02, -5.30631132e-02, -1.03865368e-02, -2.83577223e-03,\n",
       "          4.20597941e-02, -3.70376781e-02, -4.78047365e-03,  5.53285182e-02,\n",
       "         -4.99982499e-02, -8.76992103e-03,  1.24142310e-02, -2.92747971e-02,\n",
       "          3.88856716e-02,  1.75679307e-02, -4.53337468e-02, -5.44281816e-03,\n",
       "          5.14302514e-02,  5.58478944e-02, -3.89115773e-02, -1.57495458e-02,\n",
       "          4.52040136e-02, -5.04449308e-02, -2.00257823e-02, -4.55557145e-02,\n",
       "         -4.88017648e-02, -4.12297547e-02,  3.35471779e-02,  4.68120910e-02,\n",
       "          1.58117861e-02,  3.03489715e-02, -2.69243028e-02, -4.75497991e-02,\n",
       "         -5.67249313e-04,  2.49187704e-02,  4.90261652e-02,  3.88163030e-02,\n",
       "          3.85674201e-02, -5.16121238e-02,  5.39221019e-02, -2.62213480e-02,\n",
       "         -3.28156240e-02, -4.85812314e-02,  2.15121894e-03,  4.22183936e-03,\n",
       "         -4.50453274e-02, -4.48287167e-02,  4.33181375e-02, -1.51554272e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 40,\n",
       "  'topic_words': array(['impulsivity', 'impulsive', 'compulsive', 'sensory',\n",
       "         'somatosensory', 'neuroethics', 'neuroimaging', 'psychological',\n",
       "         'neurosci', 'neuroscientific', 'neurosciences', 'neurological',\n",
       "         'neuronal', 'neuro', 'perceptual', 'cognitive', 'impulses',\n",
       "         'neuroscience', 'stimuli', 'neurol', 'stimulus', 'excitability',\n",
       "         'psychosis', 'behavioural', 'neuroimage', 'selective', 'neurosurg',\n",
       "         'psychology', 'neurogenesis', 'hyperactivity', 'cognitively',\n",
       "         'psychiatry', 'correlated', 'correlates', 'neuron',\n",
       "         'neuroscientists', 'correlation', 'neurology', 'sensitivity',\n",
       "         'neuroscientist', 'selectively', 'neurons', 'icds', 'correlate',\n",
       "         'psychol', 'dependence', 'neural', 'neurofeminism', '신경망',\n",
       "         'asymptotic'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.05833677,  0.01883828, -0.00295498, -0.00208096,  0.00396786,\n",
       "          0.05086537, -0.04797504, -0.02801841,  0.00570572,  0.03652681,\n",
       "          0.00577862, -0.00924905,  0.0239324 ,  0.00349421, -0.04289389,\n",
       "          0.04758208,  0.01637048, -0.02213251,  0.04645089,  0.0487134 ,\n",
       "          0.00190469, -0.04778121, -0.0367621 ,  0.05608099, -0.05709983,\n",
       "         -0.00389711, -0.03381597,  0.02729343,  0.02432399,  0.01517781,\n",
       "         -0.03744506,  0.03272277,  0.01861259, -0.05191296, -0.01291595,\n",
       "         -0.03284086, -0.01318251,  0.01067541, -0.03884592, -0.04823195,\n",
       "         -0.01599108, -0.01673495,  0.04754269, -0.00409042, -0.02815114,\n",
       "         -0.02309784,  0.05892692,  0.01437986,  0.00779443, -0.05394823,\n",
       "          0.05518695,  0.02714449,  0.02573196, -0.0550534 ,  0.00557759,\n",
       "          0.00201267,  0.01026263,  0.00606737,  0.03347832,  0.03439023,\n",
       "         -0.03857263,  0.05096809, -0.0251228 , -0.04861144, -0.04742309,\n",
       "          0.01868812,  0.00206734, -0.01350862, -0.04297554,  0.00769094,\n",
       "         -0.03302863,  0.04273718,  0.02132421, -0.0507919 , -0.01981011,\n",
       "         -0.02614586,  0.0407116 ,  0.0552711 , -0.02028878, -0.05878336,\n",
       "         -0.0578699 , -0.04732363,  0.01965126,  0.01268252, -0.0446312 ,\n",
       "         -0.00624358, -0.05180001, -0.02835956, -0.03619299, -0.02818267,\n",
       "         -0.05472791, -0.05209428, -0.03530028, -0.0277154 ,  0.04780049,\n",
       "          0.03808934,  0.05365605,  0.05817485,  0.02075083,  0.0274778 ,\n",
       "          0.03652817, -0.04124352,  0.04195329,  0.00695354,  0.03862422,\n",
       "          0.03271524, -0.05244338, -0.01273736, -0.04548467,  0.04615267,\n",
       "          0.05616613, -0.02971878, -0.0485143 ,  0.04727473,  0.05094849,\n",
       "          0.0412949 ,  0.04175996,  0.02756629, -0.00230267, -0.01077646,\n",
       "         -0.01979217,  0.039081  ,  0.04913989,  0.0406456 , -0.02896637,\n",
       "          0.02783541,  0.0525426 ,  0.04166313, -0.03745488,  0.05583634,\n",
       "         -0.03869215, -0.02805196,  0.0303479 ,  0.05751883, -0.01408415,\n",
       "          0.05900321, -0.02556469, -0.04322606,  0.0580672 ,  0.02038371,\n",
       "          0.05293579,  0.01686337,  0.04808591, -0.02495768,  0.03607599,\n",
       "          0.04182498, -0.0058674 ,  0.04400683,  0.04109213,  0.05054577,\n",
       "          0.04914926, -0.00308423,  0.00955867, -0.00302556, -0.0256802 ,\n",
       "         -0.02193448, -0.00208911, -0.04192159, -0.01551086, -0.04113207,\n",
       "          0.02325678, -0.0460284 , -0.03438402, -0.03661022,  0.01756907,\n",
       "         -0.04023111,  0.0419564 , -0.00970355, -0.01906666,  0.00814557,\n",
       "         -0.01780816, -0.04392205,  0.01560394,  0.0299619 , -0.03817513,\n",
       "          0.03405213,  0.03533475,  0.01544725,  0.01698866, -0.02100411,\n",
       "          0.00937039, -0.02021809, -0.01762432, -0.05065221, -0.03754312,\n",
       "          0.0142369 ,  0.03441361,  0.04958648,  0.04641262,  0.0111552 ,\n",
       "          0.01657115, -0.0351052 ,  0.02122725, -0.04730599, -0.03991414,\n",
       "         -0.03050266, -0.04736032,  0.04127515,  0.04998623,  0.03046085,\n",
       "         -0.02694946,  0.03039474, -0.02165425, -0.0470761 ,  0.03181792,\n",
       "         -0.0473844 , -0.05145893,  0.03289462,  0.03345897,  0.04652978,\n",
       "          0.00069657, -0.02098377,  0.0465385 , -0.02031872,  0.05629613,\n",
       "         -0.04183669,  0.02901998, -0.03072334,  0.01246685, -0.04716801,\n",
       "         -0.00538324,  0.02944474,  0.05222316,  0.020056  , -0.03802762,\n",
       "         -0.04099227, -0.05577749,  0.02063945, -0.03502378, -0.04365111,\n",
       "         -0.02592035,  0.0332606 , -0.03156272,  0.04400028, -0.00458733,\n",
       "         -0.04317064,  0.02901886,  0.04346299,  0.03289054,  0.01694281,\n",
       "          0.02283433,  0.01465736, -0.02002564,  0.04362212,  0.05527388,\n",
       "         -0.00152252,  0.05317926, -0.00480886, -0.0360073 ,  0.0491124 ,\n",
       "         -0.00343352, -0.05185202, -0.02501954, -0.05252927,  0.00310814,\n",
       "         -0.03091035,  0.01577906,  0.03409674, -0.02710823, -0.01225408,\n",
       "         -0.03037134,  0.05163749, -0.05195428,  0.04096564,  0.03754305,\n",
       "         -0.05757226, -0.02838162,  0.05664396,  0.01455794, -0.02233393,\n",
       "          0.04680898, -0.00821882,  0.00469932, -0.03310029,  0.04090004,\n",
       "          0.03155117, -0.01607148,  0.04572961, -0.05616917,  0.00248382,\n",
       "         -0.03846871, -0.01985127,  0.02418623,  0.04881475, -0.03487382,\n",
       "          0.02799558, -0.05438294, -0.0351009 , -0.01800768,  0.00502327,\n",
       "          0.05492409,  0.00944547,  0.04437286, -0.02482162, -0.03076344,\n",
       "         -0.04483708, -0.01534452,  0.03317688,  0.05726268,  0.04514608,\n",
       "         -0.05494116,  0.03175528, -0.03369268, -0.01908198, -0.02878544,\n",
       "          0.00019382, -0.02595488,  0.03611833, -0.02535915,  0.01213421,\n",
       "         -0.04278145, -0.03740941,  0.02473783, -0.05243894,  0.05810975,\n",
       "          0.05051784,  0.01641656, -0.02555358,  0.03397463, -0.04901869,\n",
       "          0.02408069, -0.03492345, -0.00171574,  0.02907107,  0.00719023,\n",
       "         -0.0446671 , -0.02758752, -0.01202089,  0.02482304,  0.01353623,\n",
       "          0.00137199, -0.02236496, -0.04118166, -0.01811584,  0.03374137,\n",
       "         -0.02635607, -0.05353318, -0.05265917, -0.0536471 ,  0.03768805,\n",
       "         -0.04126378, -0.02938183, -0.0023545 , -0.05697065,  0.02384578,\n",
       "          0.03725842,  0.04933485, -0.02512285, -0.04598558,  0.00956572,\n",
       "          0.0497876 ,  0.01989737,  0.01353038,  0.05800055,  0.05048893,\n",
       "          0.05740081,  0.03559761,  0.01918943, -0.05159925, -0.0313058 ,\n",
       "          0.01818647, -0.01750856,  0.04418844,  0.04018778, -0.02876685,\n",
       "          0.01906954, -0.04612102,  0.03632182, -0.02484762,  0.01359746,\n",
       "          0.00318318,  0.03951372, -0.00150953,  0.01085811,  0.00059374,\n",
       "         -0.05459203, -0.00621092,  0.02983171, -0.01048433, -0.03391383,\n",
       "          0.05673894,  0.01242338,  0.02053072,  0.02064719, -0.02543452,\n",
       "          0.05796945,  0.03863761, -0.02989899,  0.05404141, -0.02687966,\n",
       "         -0.0010252 ,  0.01861704, -0.0009942 ,  0.04158864, -0.03328042,\n",
       "          0.01821892,  0.05424329, -0.04715064, -0.02665677,  0.02232481,\n",
       "          0.04247031,  0.05213878,  0.03467389,  0.04726254, -0.03463181,\n",
       "          0.00732483,  0.02704617, -0.03924341,  0.04406253, -0.01829318,\n",
       "          0.01458949, -0.01672825, -0.02789476,  0.04194809, -0.02822885,\n",
       "          0.05496501, -0.01430365, -0.04200752,  0.02706417,  0.00665434,\n",
       "         -0.05175572, -0.0501506 ,  0.03453333,  0.04799929,  0.05551506,\n",
       "         -0.03618509, -0.03706954, -0.04062461, -0.01681589, -0.01107238,\n",
       "         -0.0446494 , -0.03966294, -0.01418064, -0.03641673,  0.02250086,\n",
       "         -0.02567147, -0.03411606, -0.04654584, -0.05922733,  0.04848694,\n",
       "          0.03243203, -0.0204051 ,  0.03069808, -0.05064023,  0.04368198,\n",
       "          0.02564833, -0.02749806,  0.04208612, -0.0374483 ,  0.00215791,\n",
       "         -0.00869987, -0.03421278, -0.02823032, -0.00813604, -0.03527257,\n",
       "         -0.01597838,  0.0073701 ,  0.02528266, -0.00241264,  0.01473313,\n",
       "         -0.04807059, -0.04288705, -0.00841425, -0.05160211,  0.05287407,\n",
       "         -0.05327862, -0.03770906, -0.03930344,  0.05573658,  0.04037283,\n",
       "          0.02962203,  0.04854117, -0.0222591 ,  0.03242034, -0.0210993 ,\n",
       "         -0.01159094,  0.01327094, -0.00951692, -0.02059271,  0.00515883,\n",
       "          0.00243178,  0.05940314, -0.04297742, -0.01574437,  0.03164131,\n",
       "         -0.05514741, -0.03105873, -0.04802448, -0.04294196, -0.03830232,\n",
       "          0.016408  ,  0.0263727 , -0.04548142,  0.00177229, -0.01957146,\n",
       "         -0.05251573, -0.02819275,  0.00663152,  0.03181442,  0.04381805,\n",
       "          0.04048058, -0.04663959,  0.05895953, -0.04482712, -0.04534594,\n",
       "         -0.05096965, -0.0056534 , -0.02812493, -0.01687153, -0.03771442,\n",
       "         -0.03451892,  0.01931738], dtype=float32)},\n",
       " {'topic_idx': 41,\n",
       "  'topic_words': array(['레시피', '라면', '요리', '소고기', 'soup', '고기', '소상', '스프', '야채', '반죽',\n",
       "         '국물', '마늘', '치즈', 'prepare', '토마토', 'preparation', '버터', '맛있',\n",
       "         'serving', '소스', 'foraging', 'protein', 'summarize', '설탕', 'raw',\n",
       "         'menu', '소금', 'answers', '음식', '과자', 'imperative', '곰탕',\n",
       "         'overview', '알아보', '재료', '성분', '준비', '전공', '메뉴', '바나나',\n",
       "         'indicative', '음식점', 'pizzagalli', '제곱', 'formulation', '건강',\n",
       "         'food', '대답', '의료', 'understanding'], dtype='<U15'),\n",
       "  'topic_vector': array([ 3.69504243e-02, -2.33737174e-02, -2.83340756e-02,  4.14248779e-02,\n",
       "          4.29498740e-02,  6.40317574e-02,  3.47698783e-03,  4.75737441e-04,\n",
       "          5.03170164e-03,  1.69301815e-02,  3.01297046e-02, -3.32850739e-02,\n",
       "          4.75187078e-02, -1.28237111e-02, -2.78646569e-03,  2.04013903e-02,\n",
       "         -3.24153677e-02, -9.51211248e-03,  2.65021026e-02,  4.84996028e-02,\n",
       "         -5.24005480e-02, -1.56484637e-02,  2.75676344e-02,  4.69696615e-03,\n",
       "         -6.53812960e-02, -5.60628250e-02, -2.10971050e-02,  3.10362019e-02,\n",
       "          1.96156297e-02, -3.46528329e-02, -5.46745248e-02, -1.73482876e-02,\n",
       "         -5.59929386e-03, -6.12032637e-02,  4.14667837e-03, -5.13321673e-03,\n",
       "          1.58749111e-02, -4.43624966e-02,  1.99821647e-02, -4.81011420e-02,\n",
       "          1.12744630e-03, -6.89948946e-02, -2.18290873e-02, -2.86119692e-02,\n",
       "          2.31680721e-02, -5.22370450e-02, -2.32972745e-02, -2.00394280e-02,\n",
       "         -7.11132213e-02,  2.25596782e-02, -1.29109621e-02,  1.94253586e-03,\n",
       "         -1.07232286e-02, -3.13157290e-02,  5.19745983e-03, -6.50566965e-02,\n",
       "          4.04268578e-02, -1.90998260e-02,  2.28361096e-02,  2.42662858e-02,\n",
       "          2.93772519e-02,  5.89093454e-02, -3.16633354e-03, -3.63316759e-02,\n",
       "          2.90107615e-02, -2.23489162e-02,  2.45832242e-02, -1.15440888e-02,\n",
       "         -3.33762579e-02, -1.85343530e-02, -2.40281411e-02,  4.12637591e-02,\n",
       "          3.30312625e-02, -1.59764830e-02, -2.17593464e-04, -2.73616016e-02,\n",
       "          1.64702199e-02,  8.07813369e-03, -3.76419839e-03, -7.09258467e-02,\n",
       "         -7.08834231e-02, -6.00977335e-03, -6.17128622e-04, -3.59772407e-02,\n",
       "         -3.13350968e-02, -2.97578331e-02, -3.47447060e-02, -4.62438352e-02,\n",
       "          5.15351817e-02, -7.79376552e-03,  7.98224472e-03, -2.21194513e-02,\n",
       "         -3.26961204e-02, -4.21145279e-03,  1.47481412e-02,  1.81099549e-02,\n",
       "         -3.88148837e-02,  3.75101343e-02, -4.68885005e-02,  5.01872879e-03,\n",
       "          3.39519233e-04,  1.63957309e-02, -4.19181306e-03,  5.17321937e-02,\n",
       "         -2.08738782e-02, -2.47586221e-02,  4.64896150e-02, -5.03001884e-02,\n",
       "         -2.07588007e-03, -1.15831448e-02, -1.21487621e-02, -1.52517296e-03,\n",
       "          4.85732816e-02,  3.40179987e-02,  5.44619095e-03,  9.50592104e-03,\n",
       "          7.00315367e-03, -1.03403050e-02,  7.02037066e-02, -4.80540507e-02,\n",
       "         -5.26895523e-02, -7.06470013e-02,  1.50957946e-02, -3.89331696e-03,\n",
       "         -4.82320040e-03, -6.04015477e-02,  2.89759482e-03,  5.05113304e-02,\n",
       "         -7.37570459e-03,  3.45738977e-03, -3.60878929e-03,  2.43259408e-02,\n",
       "         -5.72186187e-02,  3.23247835e-02, -7.11095631e-02,  4.94058020e-02,\n",
       "         -2.53602751e-02, -1.43124778e-02,  3.72430980e-02, -6.83293715e-02,\n",
       "          5.19927852e-02, -1.54590234e-03, -2.79086381e-02,  2.02118792e-02,\n",
       "         -4.48743552e-02,  1.86766835e-03,  5.18459082e-02, -3.64616737e-02,\n",
       "         -3.94274816e-02,  1.62705556e-02,  7.10366061e-03,  5.81264496e-02,\n",
       "         -6.21453002e-02, -1.33604538e-02,  1.63487680e-02, -5.70442341e-03,\n",
       "         -2.03926954e-02,  1.95856281e-02,  1.91598088e-02, -6.27799332e-02,\n",
       "         -1.29744709e-02, -3.08558047e-02,  1.45915691e-02,  2.68024136e-03,\n",
       "          3.42435017e-02,  3.66175361e-02, -2.39971783e-02,  2.16972493e-02,\n",
       "          1.59252435e-03,  4.71927933e-02,  2.74006166e-02,  1.21128066e-02,\n",
       "          2.56846379e-03,  1.41292261e-02, -5.69061050e-03,  3.83875370e-02,\n",
       "          2.35645659e-02, -2.98219807e-02,  2.64206734e-02,  3.58503237e-02,\n",
       "         -9.02075227e-03,  1.93221699e-02,  5.51220030e-03, -1.53140398e-02,\n",
       "         -3.86547036e-02,  1.73250437e-02,  2.73960624e-02,  5.89329377e-02,\n",
       "          1.48499385e-05,  7.07415119e-02,  2.40541846e-02,  2.46629473e-02,\n",
       "          4.27854387e-03, -2.28922516e-02, -5.41096507e-03,  7.37516582e-03,\n",
       "         -4.01263759e-02, -4.16815579e-02,  4.55303006e-02, -4.10491740e-03,\n",
       "         -3.77856418e-02, -3.42524983e-02,  3.94836590e-02, -2.78995372e-02,\n",
       "         -2.70264745e-02,  4.54843156e-02,  7.10962340e-02, -1.88889988e-02,\n",
       "         -1.00121452e-02,  1.39141055e-02,  6.92664552e-03, -3.20765823e-02,\n",
       "         -2.33161151e-02,  9.33590066e-03, -3.00663151e-02, -2.64444947e-02,\n",
       "          2.44720392e-02,  1.01664830e-02, -5.44739589e-02,  1.68194417e-02,\n",
       "          2.17503421e-02,  1.38854366e-02, -1.91338472e-02,  1.09898755e-02,\n",
       "          2.77353072e-04, -5.13036922e-02, -2.69598607e-02, -2.79192515e-02,\n",
       "         -1.76985450e-02,  1.86506901e-02,  2.69080289e-02, -3.96876521e-02,\n",
       "          1.62364449e-02, -8.61654244e-03,  5.27752214e-04,  3.06069143e-02,\n",
       "         -5.09316213e-02,  5.27293198e-02, -3.04499529e-02, -1.78898778e-02,\n",
       "         -1.87301300e-02,  1.74221047e-03,  4.87825237e-02,  5.96717757e-04,\n",
       "          1.35412710e-02, -2.00532470e-02,  4.72556651e-02,  3.38248238e-02,\n",
       "          4.76185419e-02, -8.05737264e-03,  5.88765629e-02,  7.79130030e-03,\n",
       "         -1.47906321e-04, -5.85489348e-02, -1.25000086e-02,  1.50471982e-02,\n",
       "         -2.09937114e-02,  4.21750247e-02, -1.36648091e-02,  5.49609885e-02,\n",
       "          3.98073122e-02,  3.73209789e-02, -2.45463848e-02, -7.09255561e-02,\n",
       "          1.29657460e-03, -6.67991340e-02,  1.50180105e-02,  6.21276870e-02,\n",
       "          1.16600655e-02,  2.32320670e-02, -2.39591654e-02, -1.63388886e-02,\n",
       "         -1.02436626e-02, -1.96696632e-02, -2.65875049e-02,  9.72790550e-03,\n",
       "         -2.08558282e-03, -3.44984755e-02, -5.12092486e-02, -3.87247130e-02,\n",
       "          2.38032006e-02, -4.26974073e-02,  1.62039511e-02, -3.61807831e-03,\n",
       "          2.68296488e-02,  1.22645730e-02, -5.53337745e-02, -3.74582484e-02,\n",
       "         -2.98531763e-02, -5.36781475e-02,  4.30583861e-03, -5.31064440e-03,\n",
       "          5.74573874e-03, -2.01237760e-02,  5.45799248e-02,  3.30801830e-02,\n",
       "          2.80849393e-02,  2.28862278e-02, -2.73384340e-02, -6.23215251e-02,\n",
       "         -3.65388617e-02,  3.25982608e-02, -3.34895849e-02, -8.70825257e-03,\n",
       "          4.56371978e-02, -1.85626075e-02,  3.62364240e-02,  1.02592623e-02,\n",
       "          4.00248878e-02,  2.59587970e-02,  4.17709872e-02, -5.78589663e-02,\n",
       "         -3.22264433e-02, -1.09794028e-02,  9.14268196e-04,  1.91189907e-02,\n",
       "         -4.69979271e-02, -1.93111133e-02,  4.07743976e-02,  1.31436344e-02,\n",
       "         -1.75236836e-02, -5.58971241e-02, -4.80620451e-02, -5.37146628e-03,\n",
       "          2.01018546e-02, -5.38904257e-02, -2.18146062e-03,  2.01068143e-03,\n",
       "          2.84603089e-02,  1.65299177e-02, -4.67460528e-02,  3.81053425e-03,\n",
       "         -6.27887715e-03,  6.23318087e-03,  3.70994285e-02, -5.14485165e-02,\n",
       "         -2.37147398e-02,  3.63978520e-02, -3.19202505e-02, -2.17551012e-02,\n",
       "         -3.87175754e-02, -3.25584933e-02, -3.08092646e-02,  5.27214259e-03,\n",
       "          6.73467666e-03,  3.40021364e-02, -3.07635721e-02,  1.44983428e-02,\n",
       "         -8.37861560e-04, -2.32259932e-04,  3.01808473e-02, -2.16593109e-02,\n",
       "         -9.69868433e-03, -3.58655863e-02,  8.61435942e-03,  1.45178717e-02,\n",
       "         -2.21537910e-02, -3.03168949e-02,  2.72115953e-02, -3.59898135e-02,\n",
       "         -5.01465052e-03,  2.14516763e-02,  4.87678573e-02, -4.87215891e-02,\n",
       "         -2.17273068e-02, -3.17843780e-02, -2.76563410e-02, -2.51583103e-02,\n",
       "          2.57528313e-02, -4.57129581e-03, -8.49370193e-03,  1.98013540e-02,\n",
       "          3.40705514e-02, -3.73072810e-02, -1.68113480e-03,  2.86061577e-02,\n",
       "         -4.29007644e-03, -7.50055164e-03,  5.83698526e-02,  1.62663199e-02,\n",
       "          2.45530065e-02,  5.34629123e-03,  2.32710503e-02,  4.95644920e-02,\n",
       "         -2.50240155e-02,  2.20460892e-02, -6.55690557e-04, -6.95704967e-02,\n",
       "          5.18681817e-02, -1.90274920e-02, -5.25417551e-03,  3.94351371e-02,\n",
       "         -7.55537068e-03,  9.95375123e-03,  5.69513142e-02,  2.08162945e-02,\n",
       "          1.83128158e-03, -1.53053831e-02,  7.75539270e-03,  1.09291859e-02,\n",
       "          2.96810567e-02,  2.22386345e-02,  3.47184464e-02,  6.61885738e-02,\n",
       "         -3.13023701e-02, -2.11163913e-03, -1.79809071e-02, -2.20061466e-02,\n",
       "          1.86187625e-02,  6.79304590e-03,  2.51800232e-02,  2.79677454e-02,\n",
       "          6.33169040e-02, -3.78186218e-02, -2.01587491e-02, -1.12576894e-02,\n",
       "          1.51774855e-02,  4.50910293e-02,  1.62023641e-02, -2.86290254e-02,\n",
       "          5.35587259e-02,  4.50136922e-02, -4.93803695e-02,  5.14759868e-03,\n",
       "          2.24647503e-02,  6.58396119e-03, -2.59373598e-02, -2.73241065e-02,\n",
       "         -4.84609492e-02, -7.28538400e-03, -2.61738859e-02,  8.00368749e-03,\n",
       "          4.99603823e-02,  3.21960859e-02,  5.21396026e-02, -6.05816999e-03,\n",
       "          2.58724894e-02,  5.51085267e-03, -6.88621551e-02,  5.06518856e-02,\n",
       "         -1.98334549e-02,  4.91822958e-02, -4.20661736e-03, -3.43200639e-02,\n",
       "         -6.21151272e-03, -6.05709758e-03,  5.78205101e-02,  2.97234841e-02,\n",
       "         -6.13237452e-03,  4.52833436e-02,  1.63729694e-02,  1.31302606e-02,\n",
       "         -3.30067128e-02,  4.77046240e-03,  1.05159003e-02,  1.56792887e-02,\n",
       "          5.87043935e-04,  3.35114375e-02,  2.19957139e-02,  3.82903218e-02,\n",
       "          3.04554850e-02,  1.79466454e-03,  3.56651835e-05, -6.33867807e-04,\n",
       "          1.81061064e-03, -4.59713005e-02, -1.34636164e-02, -7.01823980e-02,\n",
       "          6.76076561e-02,  2.26815306e-02,  1.15431640e-02, -3.12961750e-02,\n",
       "         -1.76332910e-02, -2.15419587e-02, -2.77063251e-02,  3.49032655e-02,\n",
       "          2.38158740e-02,  2.40729307e-03, -1.57372002e-02, -2.76613561e-03,\n",
       "         -2.29730718e-02,  4.18056697e-02, -9.76495794e-04,  2.45961528e-02,\n",
       "          5.95840439e-02,  4.55643721e-02,  1.60906315e-02, -6.68725520e-02,\n",
       "          2.02825340e-03,  1.57090332e-02,  1.25412615e-02,  4.51332852e-02,\n",
       "          3.17232125e-02, -4.85837311e-02, -2.21822467e-02, -4.86338772e-02,\n",
       "          5.81490248e-03, -6.22899737e-03,  2.33314149e-02,  5.34268888e-03,\n",
       "          6.48097396e-02,  2.87577137e-03,  6.45249411e-02,  2.47716140e-02,\n",
       "         -5.23486733e-02, -5.69848791e-02, -1.31533425e-02, -1.19044799e-02,\n",
       "         -9.51973815e-03, -5.75581081e-02,  2.87290327e-02, -1.32164033e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 42,\n",
       "  'topic_words': array(['robots', 'robot', 'scientists', '인공지능', '인공', 'scientist',\n",
       "         'artificial', 'neurosciences', 'exploratory', 'neurocultures',\n",
       "         'researchers', 'neuroscientists', 'neuroscientist', 'neuroscience',\n",
       "         'bot', 'evolutionary', 'researcher', 'technology', '과학자',\n",
       "         'discovery', 'neural', 'automated', 'humans', 'neurofeminism',\n",
       "         'neurofeminist', 'sensorimotor', 'woebot', 'stimuli', 'neurosci',\n",
       "         'exploration', 'neuroscientific', 'heuristics', 'darwin', '인류',\n",
       "         'stimulation', 'species', 'experts', 'selvars', 'stimulus',\n",
       "         'mechanisms', 'humanities', '지능', 'sensory', '연구비', 'machines',\n",
       "         'expert', 'neuroimaging', 'feminist', 'skill', 'exploring'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([ 4.12648171e-02,  3.34702544e-02,  3.13341357e-02, -3.67394648e-02,\n",
       "         -3.57924812e-02,  3.87220122e-02,  1.22008622e-02, -3.08901388e-02,\n",
       "          4.61343862e-02, -1.30426427e-02,  3.62357348e-02,  2.85264608e-02,\n",
       "          5.45024574e-02,  4.53117443e-03, -3.60250175e-02,  2.22539529e-03,\n",
       "          4.72481064e-02, -5.27024567e-02,  2.42606476e-02,  4.21208553e-02,\n",
       "         -3.84273045e-02, -5.49739562e-02,  5.52833378e-02,  1.24301789e-02,\n",
       "         -5.53940646e-02, -9.23094992e-03,  3.54867764e-02, -7.76472641e-03,\n",
       "          2.38225907e-02, -5.16594611e-02,  8.67124833e-03,  2.98264623e-02,\n",
       "          4.06211652e-02, -3.45543139e-02,  2.22092196e-02, -1.34284114e-02,\n",
       "          3.28327566e-02, -3.96004207e-02, -3.90188135e-02, -4.67207134e-02,\n",
       "         -3.63398306e-02,  2.00403631e-02,  5.31074107e-02, -4.02470818e-03,\n",
       "         -2.23038811e-02, -3.41646038e-02,  5.24299592e-02, -3.93788610e-03,\n",
       "          1.86454095e-02, -4.01475839e-02,  3.48902047e-02, -7.21798418e-03,\n",
       "         -2.19881092e-03,  2.87232664e-03, -3.57568339e-02, -5.52343428e-02,\n",
       "          5.20233959e-02, -1.89214777e-02,  2.63343807e-02, -1.84604581e-02,\n",
       "         -3.80894952e-02,  5.51633090e-02, -4.04188856e-02, -4.45081592e-02,\n",
       "          1.36092054e-02, -8.21295474e-03,  3.86815704e-02, -4.33078744e-02,\n",
       "         -1.23255337e-02,  1.25627862e-02, -1.73146464e-02,  6.96598785e-03,\n",
       "          2.99008414e-02, -3.04994509e-02,  1.02973171e-02, -5.42694703e-03,\n",
       "         -1.62246339e-02,  1.09168915e-02, -3.73949222e-02, -5.55691235e-02,\n",
       "         -5.55691905e-02, -5.20295911e-02,  3.54569554e-02,  3.09777856e-02,\n",
       "          1.09984353e-02, -2.25976259e-02, -3.70473824e-02, -4.43688743e-02,\n",
       "         -1.48444250e-02,  5.22686280e-02, -5.21827452e-02, -3.10446676e-02,\n",
       "         -2.68381089e-02,  1.59642696e-02,  2.03282889e-02,  6.04570424e-03,\n",
       "          4.48572636e-02,  4.18950617e-02, -6.89431792e-03, -2.35615787e-03,\n",
       "          4.38531935e-02,  1.42056150e-02, -4.03879248e-02, -3.32949236e-02,\n",
       "         -2.90518794e-02, -4.63126861e-02, -3.49454880e-02,  3.48377787e-02,\n",
       "         -2.65402328e-02,  1.06470091e-02,  3.55206467e-02, -4.07531299e-02,\n",
       "         -4.96869385e-02,  2.74199899e-02,  4.22222279e-02, -4.27030176e-02,\n",
       "          2.34144423e-02, -1.92693826e-02, -3.33413482e-02,  7.36548752e-03,\n",
       "          3.49637717e-02,  3.30824703e-02,  7.42726587e-03,  3.57178599e-02,\n",
       "          1.22101530e-02,  4.70176637e-02,  4.18333896e-02, -2.02940926e-02,\n",
       "         -3.36958058e-02, -9.84162092e-04, -3.02462429e-02, -3.28725092e-02,\n",
       "         -3.24051231e-02,  2.40894724e-02, -1.27792044e-03,  5.53497076e-02,\n",
       "         -3.67411263e-02, -2.65628546e-02,  5.24643473e-02,  1.32570500e-02,\n",
       "          5.23984842e-02,  2.57375240e-02,  4.50793989e-02,  2.64480915e-02,\n",
       "          4.80189957e-02,  1.43357730e-02,  5.09235002e-02, -3.17535736e-02,\n",
       "         -1.53961377e-02, -4.88411300e-02,  5.03841490e-02,  3.62792350e-02,\n",
       "         -9.62302368e-03, -3.35066505e-02,  5.66236908e-03,  3.22989412e-02,\n",
       "         -2.54305601e-02, -4.14241254e-02, -2.26041954e-02, -1.77656692e-02,\n",
       "          3.53289954e-02, -2.82308999e-02, -1.59530099e-02,  9.47338995e-03,\n",
       "         -3.37107480e-02,  8.10320396e-03,  2.77371556e-02, -1.17145749e-02,\n",
       "          1.89374518e-02,  2.65185279e-03, -2.29598489e-02,  1.17778629e-02,\n",
       "         -4.74413810e-03,  3.57990861e-02, -5.32287918e-02,  1.60588939e-02,\n",
       "         -3.91257703e-02,  4.90489639e-02, -3.02951783e-03,  1.56684685e-02,\n",
       "         -8.77690036e-03,  4.96123545e-02,  2.00138465e-02, -4.74388413e-02,\n",
       "          3.42018972e-03,  1.34126870e-02,  3.35827209e-02,  5.55433929e-02,\n",
       "          3.75310890e-02,  3.76898088e-02,  7.05838203e-04, -2.90740523e-02,\n",
       "          4.71298071e-03, -2.22167745e-02, -2.18972620e-02,  4.93541062e-02,\n",
       "         -4.36962806e-02, -1.79522913e-02,  3.17372791e-02, -7.36840954e-03,\n",
       "         -2.18544062e-02,  4.93654124e-02,  5.95627679e-03, -4.84369881e-02,\n",
       "          1.99890062e-02,  1.40086412e-02,  1.04911206e-02,  5.00175506e-02,\n",
       "          1.53636886e-02,  1.86110567e-02, -1.32756559e-02, -4.02772725e-02,\n",
       "          2.95055714e-02,  2.85086129e-02, -1.48549033e-02, -3.05482056e-02,\n",
       "          3.32935937e-02, -5.54717891e-02,  1.73221957e-02,  1.95682445e-03,\n",
       "         -3.47331800e-02,  3.04364786e-02,  8.65818281e-03,  2.69258227e-02,\n",
       "         -3.51823829e-02, -3.81396525e-02, -5.18498309e-02,  2.04389300e-02,\n",
       "         -5.38168140e-02, -2.67062932e-02, -1.49943249e-03,  1.65383443e-02,\n",
       "         -4.35854234e-02,  2.70407721e-02,  4.84038107e-02, -3.97407673e-02,\n",
       "          2.23212689e-02,  4.13726047e-02,  5.19172102e-02, -9.02256556e-03,\n",
       "         -7.47403130e-03,  3.78667526e-02,  5.08844517e-02, -7.16355490e-03,\n",
       "         -8.85065086e-03,  1.47129139e-02,  2.78909598e-02,  2.94172149e-02,\n",
       "         -4.62607993e-03,  3.90255116e-02,  2.07206961e-02, -3.64610851e-02,\n",
       "          5.47373109e-02, -2.35449430e-02,  2.71235183e-02, -2.23203693e-02,\n",
       "          4.12741117e-02, -5.94919780e-03, -4.07005660e-02,  3.45663317e-02,\n",
       "          2.77622510e-02,  2.98070610e-02,  1.79003533e-02, -6.83039427e-03,\n",
       "         -7.67441047e-03, -5.53295799e-02, -2.32501626e-02,  5.18373251e-02,\n",
       "         -3.40436250e-02, -3.72238569e-02, -7.94307888e-03, -2.05347370e-02,\n",
       "          1.77729800e-02, -1.99723858e-02,  1.84287149e-02,  3.29240412e-02,\n",
       "         -1.90873463e-02, -4.43913639e-02, -5.26142716e-02, -1.05754435e-02,\n",
       "         -4.80099209e-02, -3.14392745e-02,  1.62809882e-02, -2.74451021e-02,\n",
       "         -5.20317443e-02,  5.30275144e-02, -3.16450633e-02, -3.95980291e-02,\n",
       "          8.25533364e-03, -3.50331925e-02,  2.34413240e-02, -3.02083790e-03,\n",
       "         -2.92110327e-03,  3.97676378e-02,  1.09176768e-03,  3.39213312e-02,\n",
       "         -1.54090552e-02,  3.86860482e-02,  1.02413809e-02,  5.51279150e-02,\n",
       "         -3.03380769e-02,  3.06712911e-02,  3.33767235e-02, -3.19244228e-02,\n",
       "          2.71527320e-02, -6.07315078e-03, -5.40425032e-02,  4.55527417e-02,\n",
       "          4.29720106e-03, -1.84541438e-02, -9.91818216e-03, -1.39306812e-02,\n",
       "          4.58983146e-02,  1.98268071e-02,  4.87920940e-02,  2.54532080e-02,\n",
       "          2.30900515e-02,  1.23429494e-02,  3.25368829e-02, -1.46676200e-02,\n",
       "          1.34361573e-02, -3.62223573e-02, -3.49106602e-02, -1.76934246e-02,\n",
       "         -5.55609614e-02,  2.11363714e-02,  3.08315456e-02, -1.37932447e-03,\n",
       "          2.64202897e-02,  4.70054038e-02,  4.77100126e-02,  2.28722300e-02,\n",
       "         -3.99095602e-02, -2.55189110e-02,  2.05693394e-03,  2.77583655e-02,\n",
       "         -4.01027016e-02, -1.33820565e-03, -5.38657010e-02,  5.97666949e-05,\n",
       "         -3.90730985e-02,  4.29194272e-02, -1.67061482e-02, -3.49634402e-02,\n",
       "          7.00257951e-03,  1.99730210e-02,  4.89411503e-02, -2.43084077e-02,\n",
       "         -4.42814641e-03,  1.04818242e-02, -2.97720972e-02,  1.24048218e-02,\n",
       "          3.14268023e-02,  1.94303039e-02, -4.59905379e-02, -1.74249243e-02,\n",
       "         -1.76043641e-02,  9.80198570e-03, -2.99649294e-02,  3.11166793e-02,\n",
       "         -2.41382215e-02,  2.56356578e-02,  5.35150059e-02,  2.39836914e-03,\n",
       "          1.03568397e-02,  3.01346108e-02, -5.41165322e-02,  1.24260457e-02,\n",
       "          1.02829672e-02,  2.73850877e-02,  1.01239681e-02,  2.15838552e-02,\n",
       "         -3.00442148e-02,  2.37566773e-02,  8.59053526e-03,  2.28842106e-02,\n",
       "         -5.37136085e-02,  6.91372948e-03, -4.73725935e-03, -2.82352623e-02,\n",
       "          8.78334045e-04,  9.93872713e-03,  2.58726999e-03,  2.90403068e-02,\n",
       "         -4.28438224e-02,  5.54029830e-02, -5.19736065e-03, -5.50506711e-02,\n",
       "          5.38183786e-02,  2.31848601e-02,  4.58054477e-03, -3.29189003e-02,\n",
       "          2.85637248e-02,  1.63826197e-02, -3.87943052e-02,  3.84932831e-02,\n",
       "          7.77849741e-03, -9.72159579e-03, -4.00267802e-02,  1.39461989e-02,\n",
       "          1.01750791e-02,  4.58404757e-02, -5.32737523e-02,  1.45840691e-02,\n",
       "         -2.52280924e-02,  2.51262486e-02, -2.81185377e-02, -3.00726965e-02,\n",
       "          1.36483507e-02,  9.84525890e-04,  4.97806072e-02,  2.55713370e-02,\n",
       "          3.87858902e-03,  1.67381745e-02,  2.99938340e-02,  5.34184538e-02,\n",
       "          5.26241772e-02, -3.36387567e-02, -2.32130778e-03,  8.44625849e-03,\n",
       "          3.79722975e-02, -3.82153876e-02,  3.16540971e-02,  3.92009392e-02,\n",
       "          5.50951213e-02,  4.49834503e-02,  2.08024364e-02, -2.32638791e-02,\n",
       "         -5.26646562e-02, -3.03206891e-02,  9.49146599e-03, -4.96606715e-03,\n",
       "         -4.38855290e-02, -3.65977585e-02, -2.92132352e-03,  1.30190365e-02,\n",
       "          3.24883573e-02,  1.39066530e-02, -5.45989908e-02,  1.49959000e-02,\n",
       "          3.84279080e-02,  5.26100062e-02,  4.97193746e-02, -4.20015603e-02,\n",
       "          3.16417031e-02,  4.82577533e-02,  5.45338728e-02,  5.51600903e-02,\n",
       "          5.08487523e-02,  1.11057647e-02, -3.71022113e-02,  3.16544883e-02,\n",
       "          1.45047344e-03,  3.41703929e-02, -2.30198260e-02,  8.02916009e-03,\n",
       "          1.43175498e-02, -1.67918783e-02,  2.23696698e-02,  2.56174505e-02,\n",
       "         -3.04272473e-02, -2.49134675e-02, -4.08028848e-02, -3.30769308e-02,\n",
       "          9.93616879e-04, -5.23506589e-02, -5.38975112e-02,  2.61366442e-02,\n",
       "         -4.77164648e-02, -1.37888761e-02,  8.75783712e-03,  2.74429750e-02,\n",
       "         -1.91955138e-02,  4.26503085e-02,  3.45048830e-02,  2.75258422e-02,\n",
       "          1.45643402e-03,  3.94304879e-02,  7.11723743e-03, -1.24843167e-02,\n",
       "         -2.33813282e-02,  5.55659123e-02, -5.44631816e-02,  3.94950388e-03,\n",
       "         -5.24182022e-02, -5.33904918e-02,  3.08607463e-02, -5.54399453e-02,\n",
       "         -3.07521727e-02, -4.60693724e-02,  3.86782475e-02, -1.87155660e-02,\n",
       "          4.96287048e-02, -1.42400041e-02,  4.21552360e-02,  7.47148925e-03,\n",
       "         -5.37217706e-02, -4.06172462e-02, -3.92462127e-02, -1.73770636e-03,\n",
       "          1.27132265e-02, -3.05400509e-02,  4.84197773e-02, -3.76426429e-02,\n",
       "         -4.17292714e-02, -2.44591329e-02, -2.17760298e-02, -2.31477898e-02,\n",
       "          3.23944911e-03, -5.55394106e-02,  3.76566835e-02,  4.46803160e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 43,\n",
       "  'topic_words': array(['patients', 'datasets', '환자', 'preclinical', 'clinically',\n",
       "         'clinical', 'dataset', 'data', 'pathology', 'models', 'patient',\n",
       "         'orthopedic', 'dataframe', '의료', 'neurobiological',\n",
       "         'statistically', 'neurology', 'neurobiology', '모델', 'essentialist',\n",
       "         'modelling', 'statistical', 'hospital', '진단', '의학', '병원',\n",
       "         'neuroethics', 'statistics', 'anatomical', 'alzheimers',\n",
       "         'predictive', '데이터', 'modeled', 'neurosci', 'neurological',\n",
       "         'model', 'neurosciences', 'neural', 'neuro', 'alzheimer',\n",
       "         'predictor', 'neuronal', 'asymptotic', 'neurosurg', 'neurol',\n",
       "         'diagnosed', 'predicts', 'database', 'neuroscience', 'neurobiol'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-0.05553802,  0.02415447, -0.00358576,  0.00929969, -0.02401118,\n",
       "         -0.04413492,  0.03580455, -0.00851893,  0.02242437,  0.05418899,\n",
       "          0.04250617,  0.02336604,  0.03764523,  0.00686645, -0.01036168,\n",
       "          0.00314312,  0.02601641, -0.0198072 ,  0.03992152,  0.0266496 ,\n",
       "          0.00534989, -0.00929728, -0.04259906,  0.0404454 , -0.05617443,\n",
       "         -0.00596015, -0.01273499,  0.00086583,  0.00731648, -0.02342512,\n",
       "         -0.02191755, -0.00149211,  0.04481252, -0.05491921, -0.03463842,\n",
       "          0.02753925,  0.04376731,  0.03919064,  0.04803721, -0.0057967 ,\n",
       "         -0.03377717,  0.0256952 ,  0.0512856 , -0.02882474, -0.02596247,\n",
       "         -0.00239922,  0.05130794, -0.01837691, -0.01564949, -0.02829963,\n",
       "         -0.00616317, -0.02831843, -0.02511529, -0.01373892,  0.026644  ,\n",
       "         -0.05495333,  0.04495463,  0.02917557, -0.03157877,  0.04270855,\n",
       "          0.03459733,  0.05544097,  0.03105935, -0.04869962, -0.00517264,\n",
       "         -0.03042474,  0.04111527, -0.04858963, -0.03118945, -0.00897493,\n",
       "         -0.0311875 ,  0.03660225, -0.04103897, -0.01920951, -0.00913284,\n",
       "         -0.02998745,  0.01546927,  0.03478857,  0.00304477, -0.05620192,\n",
       "         -0.05620738, -0.03395038, -0.03578866,  0.03144136, -0.0340148 ,\n",
       "         -0.02878628, -0.05252037, -0.02481034,  0.01520535, -0.02010137,\n",
       "         -0.05135643, -0.04271365, -0.04228989, -0.04598121,  0.0228362 ,\n",
       "          0.04555599, -0.00968907,  0.03065132,  0.02866254, -0.00268008,\n",
       "          0.04815021, -0.00190545,  0.0207428 , -0.04661111,  0.00356814,\n",
       "          0.02959101, -0.05605029, -0.04672708,  0.03788204,  0.04956037,\n",
       "         -0.03243448, -0.04096677, -0.00190282, -0.01899032,  0.01178948,\n",
       "         -0.02557435, -0.024962  ,  0.02340752, -0.02770551, -0.01279905,\n",
       "         -0.01036579,  0.00147372,  0.0415042 ,  0.02922921,  0.05236349,\n",
       "         -0.00898682,  0.03112762, -0.01605518, -0.04715599,  0.00636033,\n",
       "         -0.05303748, -0.01750267,  0.01144503,  0.04427924,  0.04514796,\n",
       "          0.05606061, -0.01173511, -0.01593885,  0.05509808,  0.01677465,\n",
       "         -0.00703805, -0.04330952, -0.00133024,  0.01911492,  0.05510168,\n",
       "         -0.01292572, -0.03088221,  0.05509534,  0.02545192,  0.0423455 ,\n",
       "          0.03647967,  0.0402492 , -0.03615241, -0.01780477, -0.00410613,\n",
       "         -0.03365443, -0.02354848, -0.02644545,  0.00387674, -0.04870312,\n",
       "          0.05138124, -0.00717212, -0.01524821, -0.00839596, -0.02482155,\n",
       "         -0.01373952,  0.02027035, -0.04170061, -0.04756904,  0.05434992,\n",
       "         -0.02489781, -0.03550998,  0.02801612,  0.00711564, -0.00312989,\n",
       "          0.00359194, -0.02782147,  0.00051533, -0.02370681,  0.04053708,\n",
       "          0.04908685, -0.04090951, -0.04316255, -0.01307598, -0.03004267,\n",
       "         -0.03608336,  0.01663684,  0.04404565, -0.0277423 ,  0.03030018,\n",
       "          0.01001049, -0.01820951,  0.03341087, -0.03383139,  0.02689697,\n",
       "          0.029127  , -0.04634434, -0.02125343,  0.05454417,  0.02510677,\n",
       "         -0.04484975, -0.00678753, -0.05496939, -0.02447859, -0.00296927,\n",
       "          0.01468475, -0.03663101, -0.01690021,  0.02939626,  0.02098506,\n",
       "          0.03571564,  0.01038354, -0.05579404,  0.03285449,  0.04643931,\n",
       "          0.01160489, -0.02808896, -0.04699868, -0.00645557, -0.02083249,\n",
       "         -0.00592191,  0.03816773,  0.05308903,  0.00208172, -0.03292772,\n",
       "         -0.03213396, -0.05189773,  0.0136314 ,  0.01557976,  0.01113296,\n",
       "          0.00389875,  0.01004846, -0.0428031 ,  0.0533636 ,  0.0279252 ,\n",
       "          0.01026085, -0.04543336,  0.04980482,  0.05617528, -0.02515885,\n",
       "         -0.02222236,  0.01688942, -0.00880852,  0.00986376,  0.05324497,\n",
       "         -0.01089792,  0.03969269, -0.02774076,  0.03826402, -0.01079585,\n",
       "         -0.02333615, -0.04915421,  0.02716213, -0.015876  ,  0.03202146,\n",
       "         -0.04897689, -0.02125341,  0.02475226, -0.00346949,  0.01793282,\n",
       "          0.00227597,  0.05205009, -0.0393036 , -0.00416172, -0.02161983,\n",
       "         -0.05161958, -0.03164046,  0.01859481,  0.02879996,  0.01170135,\n",
       "         -0.01420895, -0.01633397, -0.00892037, -0.04083983,  0.00585255,\n",
       "          0.02952127, -0.0547627 ,  0.04607221, -0.05560337, -0.03336892,\n",
       "         -0.03586169,  0.02001489,  0.00985395,  0.04641689, -0.01475812,\n",
       "          0.042581  , -0.04541039, -0.00107698,  0.00925726,  0.02984531,\n",
       "          0.04187158,  0.00451125,  0.01118151,  0.02060025, -0.02394819,\n",
       "         -0.01165982,  0.00136275,  0.01104747,  0.01348946,  0.05598999,\n",
       "         -0.02995506,  0.03450323,  0.00745903, -0.05452678, -0.05172477,\n",
       "         -0.01461497, -0.03990401,  0.0461803 ,  0.01372017,  0.05544654,\n",
       "         -0.04557025, -0.02777381, -0.02517015, -0.05510962,  0.0511824 ,\n",
       "          0.02022282,  0.0117686 , -0.03927566,  0.03172571, -0.0213269 ,\n",
       "         -0.01455144, -0.03322474, -0.04668633,  0.00749995, -0.03335666,\n",
       "         -0.03925599,  0.0002286 , -0.04899328, -0.02073481, -0.02071986,\n",
       "         -0.04911694, -0.03554174, -0.00974569, -0.03944638,  0.02905425,\n",
       "          0.00945877, -0.04111273, -0.02915483, -0.04699226, -0.00531533,\n",
       "         -0.04756086, -0.01833786, -0.01060258, -0.03189337, -0.03131935,\n",
       "          0.01211929,  0.05184115,  0.04909617,  0.00609171,  0.01258554,\n",
       "         -0.00425338,  0.02149932, -0.00414256,  0.00662891, -0.03536197,\n",
       "         -0.01011593,  0.02646517,  0.02147254, -0.05003638, -0.02784779,\n",
       "          0.05505873, -0.03611159,  0.04525117, -0.03465514, -0.03199603,\n",
       "          0.03026904,  0.00183118,  0.03914612, -0.05433697, -0.01563507,\n",
       "          0.04830724,  0.04841726, -0.02219616,  0.02906497,  0.00020361,\n",
       "         -0.01372777, -0.00981838, -0.01947361, -0.03297422, -0.03736458,\n",
       "          0.01646006, -0.01487213,  0.01977234,  0.00633508, -0.00922289,\n",
       "          0.05400408,  0.04083299, -0.05541806,  0.05606302,  0.0016965 ,\n",
       "          0.01313745, -0.04945944, -0.00903231,  0.04852545, -0.03479847,\n",
       "         -0.03963583,  0.04344463,  0.01948798, -0.05405156,  0.01025868,\n",
       "          0.05135804,  0.03236125,  0.02862811,  0.01742875, -0.03157637,\n",
       "          0.02104965,  0.03875767, -0.02220137, -0.01064801, -0.00856153,\n",
       "          0.03322831, -0.0216737 ,  0.02367823,  0.04273202,  0.03463335,\n",
       "          0.04940967,  0.02339624, -0.02758525,  0.02428788, -0.01194937,\n",
       "          0.01003454, -0.04133774,  0.00890863,  0.05226804,  0.05433337,\n",
       "          0.00908201, -0.01237566, -0.05016591, -0.0197107 , -0.01434138,\n",
       "         -0.0431316 ,  0.01779349, -0.05198891, -0.03743375,  0.02692617,\n",
       "          0.01167575,  0.02852439, -0.00364199, -0.0443214 ,  0.03454515,\n",
       "         -0.02374453,  0.0314324 ,  0.02037097, -0.05563075,  0.01834708,\n",
       "         -0.03874136,  0.04089264,  0.00191501, -0.01216411, -0.0043453 ,\n",
       "         -0.00461357, -0.03502676,  0.05261254, -0.02168928, -0.02890718,\n",
       "         -0.0098983 ,  0.02925263,  0.03043164, -0.03262515,  0.0429585 ,\n",
       "         -0.00420179,  0.02503132, -0.00419677, -0.05087478,  0.00806787,\n",
       "         -0.05605236, -0.00723155, -0.04000585,  0.05399651, -0.04894918,\n",
       "          0.05134889,  0.04752276, -0.03323469,  0.02609707,  0.00080975,\n",
       "         -0.04707531,  0.03605777, -0.02365766, -0.02938773, -0.00872366,\n",
       "          0.05536764,  0.05620839, -0.05278958, -0.00885029,  0.04238196,\n",
       "          0.01822688, -0.03706592, -0.05569097, -0.04059728, -0.01830851,\n",
       "          0.03436873,  0.04572475,  0.02807178, -0.03378021, -0.02822994,\n",
       "         -0.04643548, -0.02782477,  0.02639941,  0.02730841, -0.0312369 ,\n",
       "          0.04445406, -0.05469376,  0.05059377, -0.01086469, -0.04974751,\n",
       "         -0.05024355, -0.02929991, -0.0511659 , -0.02079595, -0.05503664,\n",
       "          0.04023841,  0.01896527], dtype=float32)},\n",
       " {'topic_idx': 44,\n",
       "  'topic_words': array(['datasets', 'dataset', 'dataframe', 'matplotlib', 'lineplot',\n",
       "         'coordinates', 'tensorflow', 'vertices', 'vertexcount', 'ggplot',\n",
       "         'matlab', 'data', 'mxmatrix', 'scatterplot', 'algorithms',\n",
       "         'morphometry', 'vertex', 'surface', 'geom', 'genome',\n",
       "         'xticklabels', '데이터', 'algorithmic', 'parametric', 'information',\n",
       "         'algorithm', 'mxpath', 'clustering', 'neuronal', 'neurogenesis',\n",
       "         'tomography', 'mzdata', '알고리즘', 'interfaces', 'neurology', '선형',\n",
       "         'neurosurg', 'bmatrix', 'sklearn', 'orientations', 'neural',\n",
       "         'neurosciences', 'scaling', 'mathematics', 'neurons',\n",
       "         'dimensionality', 'neuroscience', 'baseline', 'neuron',\n",
       "         'neuroethics'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.43186180e-02, -1.09548001e-02, -3.57464887e-02, -3.76876853e-02,\n",
       "         -4.54604775e-02, -4.24602367e-02,  4.21059467e-02,  3.59686501e-02,\n",
       "          3.29729542e-02,  3.67185287e-03,  2.15035975e-02,  3.39819863e-03,\n",
       "          4.84354682e-02,  8.29641242e-03, -4.55241092e-02,  2.24439483e-02,\n",
       "          1.42981550e-02, -1.71375293e-02,  4.92779724e-02,  4.25884724e-02,\n",
       "          5.23245102e-03,  8.31693038e-03, -2.45579835e-02,  2.69134212e-02,\n",
       "         -4.67774086e-02, -2.71121063e-03,  4.37676497e-02, -3.14093865e-02,\n",
       "          2.56874412e-02, -5.55614829e-02, -4.70345318e-02,  3.11952978e-02,\n",
       "          2.70149056e-02, -5.49381264e-02, -2.34000012e-02, -1.63937639e-02,\n",
       "          3.13935168e-02,  5.93842706e-03,  4.22030725e-02, -8.35573673e-03,\n",
       "         -3.10523640e-02,  1.93568841e-02, -5.50459186e-03, -3.97554934e-02,\n",
       "         -4.01310548e-02, -2.34308224e-02,  3.37829329e-02,  4.29204898e-03,\n",
       "         -2.24575903e-02,  4.47696960e-03, -2.62632761e-02, -4.30586524e-02,\n",
       "         -2.10234243e-02,  2.23241840e-02,  3.27443257e-02, -5.60853630e-02,\n",
       "         -1.61425769e-02,  2.51941998e-02, -2.31003463e-02,  5.70012741e-02,\n",
       "          1.32745011e-02,  5.39925583e-02,  3.43820788e-02, -3.39824520e-02,\n",
       "          5.19486926e-02, -4.59237956e-02,  1.34192556e-02,  4.68761437e-02,\n",
       "          4.27348018e-02,  1.83838680e-02, -4.46895100e-02,  2.84766257e-02,\n",
       "          2.63303295e-02, -1.16929086e-02, -3.05582955e-03, -2.40452196e-02,\n",
       "          2.65963096e-02,  4.25282255e-04, -3.38981580e-03, -5.78870364e-02,\n",
       "         -5.19287474e-02, -3.01508699e-02, -9.32763051e-03,  1.54888863e-02,\n",
       "          2.65705753e-02, -4.51162122e-02, -4.72104736e-02, -2.57439893e-02,\n",
       "          7.64096156e-03, -1.90726351e-02,  3.81424017e-02,  2.11851504e-02,\n",
       "         -1.53940069e-02, -4.18324284e-02,  1.82190223e-03,  5.60113303e-02,\n",
       "          3.06342598e-02,  2.66110543e-02,  2.31920779e-02,  1.18883103e-02,\n",
       "          4.16193120e-02,  2.67349631e-02,  4.02849313e-04, -2.34677512e-02,\n",
       "          2.88158823e-02,  1.24839759e-02, -4.70898636e-02, -2.22752113e-02,\n",
       "          3.10730319e-02, -1.83993325e-04, -3.21155228e-02, -4.05809097e-02,\n",
       "         -3.77779268e-02, -7.22839311e-03,  4.87845801e-02,  5.04096597e-03,\n",
       "         -3.89229767e-02, -3.65202203e-02, -5.20067066e-02, -2.11774483e-02,\n",
       "          2.03079302e-02,  2.51665562e-02,  4.88841534e-02,  2.51075104e-02,\n",
       "          5.71478046e-02, -4.18518595e-02,  1.36522762e-02,  3.03233713e-02,\n",
       "          3.15485112e-02,  1.32395290e-02, -4.22939509e-02, -6.93816366e-03,\n",
       "          4.89522628e-02,  2.35986430e-02,  2.50453148e-02,  5.53905964e-02,\n",
       "         -1.71765573e-02, -8.08193945e-05,  2.72247940e-02,  4.65483628e-02,\n",
       "          1.74496940e-03, -2.57816240e-02,  3.43347597e-06, -3.56249586e-02,\n",
       "          4.88363057e-02, -4.07532565e-02, -2.57359985e-02,  4.10381965e-02,\n",
       "          4.60989177e-02,  3.61553393e-02,  4.32916842e-02,  5.57227619e-02,\n",
       "         -1.07425628e-02, -2.24428847e-02,  2.08240803e-02, -2.76871473e-02,\n",
       "          1.01509653e-02, -4.13292497e-02,  1.79641228e-02,  4.58084084e-02,\n",
       "          4.90127318e-02,  1.45880831e-02,  2.76242942e-02, -4.21873620e-03,\n",
       "         -3.96232354e-03, -2.04706714e-02,  3.67228989e-03, -3.68879847e-02,\n",
       "          1.94103923e-02,  5.14489599e-02,  2.71827560e-02, -3.07739973e-02,\n",
       "          2.44570454e-03,  2.44480614e-02, -2.35995892e-02,  5.08658923e-02,\n",
       "         -5.23552783e-02, -1.54275540e-03, -5.45291565e-02,  2.23732349e-02,\n",
       "          2.43513826e-02, -4.71287109e-02, -4.48767245e-02,  1.52334711e-02,\n",
       "         -5.09898216e-02, -1.91413667e-02,  1.74437445e-02,  3.07908505e-02,\n",
       "          1.16471155e-02, -7.27683073e-03,  3.02773565e-02, -4.02675085e-02,\n",
       "          4.86440817e-03,  2.20126268e-02,  1.08434185e-02,  7.05873920e-03,\n",
       "         -4.76825126e-02,  2.95239408e-02,  5.85334487e-02,  3.81868295e-02,\n",
       "         -4.37297262e-02,  5.01698069e-02,  2.02862229e-02, -3.17676105e-02,\n",
       "         -2.69872341e-02, -3.17755085e-03,  1.01500908e-02, -4.41241860e-02,\n",
       "         -2.16169152e-02,  2.21688803e-02,  1.60145888e-03, -2.52001286e-02,\n",
       "         -5.35407364e-02, -1.07620051e-02,  2.60912850e-02,  1.09526301e-02,\n",
       "         -1.57432798e-02, -5.16353846e-02,  3.17253359e-02, -3.05114836e-02,\n",
       "          2.85189301e-02,  3.57147306e-02, -2.71151718e-02,  2.62643471e-02,\n",
       "         -5.63217402e-02,  4.36756946e-02, -5.42958416e-02,  1.19123012e-02,\n",
       "          5.60867004e-02, -1.54763041e-03, -2.77096797e-02,  4.74362671e-02,\n",
       "         -1.36238588e-02,  3.97153152e-03,  1.60351582e-02,  1.69010030e-03,\n",
       "          1.16965398e-02,  2.06964053e-02,  3.70767377e-02, -2.71179583e-02,\n",
       "          1.28105953e-02,  1.60174388e-02, -3.11477240e-02,  1.84524357e-02,\n",
       "         -7.52318325e-03, -5.62266819e-02,  9.50584828e-04, -2.34701782e-02,\n",
       "          4.69159633e-02, -3.32934596e-02, -4.82252054e-02, -3.77625376e-02,\n",
       "          1.61650795e-02,  5.33872135e-02, -3.00664529e-02,  1.34384679e-02,\n",
       "          1.16257498e-03,  8.70289374e-03, -2.59322878e-02,  7.44905090e-03,\n",
       "         -3.49361151e-02,  3.37243490e-02, -3.64943407e-03, -7.39578949e-03,\n",
       "          2.30613928e-02, -3.70859355e-02, -9.68185998e-03,  1.07033625e-02,\n",
       "         -5.22633456e-03,  2.17329953e-02, -3.06366738e-02, -7.75812333e-03,\n",
       "         -4.66028154e-02, -2.12502647e-02, -7.29047321e-03,  1.14181153e-02,\n",
       "         -4.43369262e-02,  2.19233404e-03, -4.74589467e-02,  9.88174044e-03,\n",
       "         -2.16000024e-02,  1.92376580e-02,  3.68234776e-02,  4.34923060e-02,\n",
       "          4.68443148e-02,  4.83249687e-02, -4.90566604e-02, -2.88077500e-02,\n",
       "         -2.24356800e-02,  5.04658818e-02,  4.93842997e-02,  3.28596495e-02,\n",
       "          8.27790238e-03,  5.23196794e-02, -3.67796198e-02,  2.48536691e-02,\n",
       "         -7.65891746e-03, -1.46943899e-02, -1.78136863e-02,  3.99626456e-02,\n",
       "         -4.40330505e-02,  3.60426377e-03,  2.76239719e-02, -4.54549603e-02,\n",
       "         -5.01229204e-02, -4.80128825e-02, -4.36036289e-02,  5.96392481e-03,\n",
       "          1.42566748e-02,  1.40764741e-02, -3.73462476e-02, -2.28970945e-02,\n",
       "         -1.70997027e-02, -4.73724902e-02,  4.68429476e-02,  1.41207231e-02,\n",
       "          1.23430043e-02, -5.07863425e-02,  4.63918932e-02, -2.03624424e-02,\n",
       "         -1.99267697e-02, -1.62362587e-02, -1.16653480e-02, -1.13272443e-02,\n",
       "         -1.04460595e-02,  4.37304117e-02,  3.95903662e-02, -4.00960855e-02,\n",
       "         -5.36209829e-02,  1.30941467e-02, -2.61038635e-02, -1.73006579e-02,\n",
       "         -1.23927556e-02,  1.25110394e-03,  5.71915507e-03,  1.27910459e-02,\n",
       "         -2.73744594e-02,  1.28281638e-02, -5.61417304e-02, -2.49431911e-03,\n",
       "         -5.12177907e-02, -1.64296441e-02,  2.24154275e-02, -9.51398350e-03,\n",
       "          1.56405214e-02,  1.90937277e-02,  3.69114839e-02, -2.42946181e-03,\n",
       "          8.57822504e-03,  1.09019494e-02,  2.99841110e-02,  7.04281637e-03,\n",
       "          2.61424662e-04, -3.30172218e-02, -7.22863665e-03,  1.93816051e-03,\n",
       "          3.20769139e-02,  4.31074537e-02, -1.97628308e-02, -4.00334261e-02,\n",
       "         -2.45522503e-02, -3.88175622e-02, -8.89014162e-04, -5.36640175e-02,\n",
       "         -4.83886190e-02,  2.70652846e-02,  3.86284553e-02,  1.41927823e-02,\n",
       "         -4.15252075e-02,  1.93080977e-02,  1.34898005e-02,  3.02367639e-02,\n",
       "         -2.38152873e-02,  5.04689664e-02,  1.14860460e-02,  5.48578845e-03,\n",
       "         -9.15748440e-03, -1.60052460e-02, -2.11455207e-02, -1.87918469e-02,\n",
       "          4.14302722e-02, -2.90226042e-02, -1.15935057e-02,  2.55532633e-03,\n",
       "         -8.06829985e-03,  5.31617403e-02,  2.25160476e-02, -5.06109931e-02,\n",
       "          5.51074408e-02, -3.17725353e-04, -1.08017528e-03, -3.70730795e-02,\n",
       "         -2.31226813e-02, -1.81210581e-02,  1.67335868e-02,  4.20926604e-03,\n",
       "          1.14181293e-02, -1.98730398e-02, -5.17079532e-02,  8.13424494e-03,\n",
       "          5.51224947e-02, -4.19588238e-02,  4.01709266e-02, -1.85268838e-02,\n",
       "         -3.90076153e-02,  2.13945983e-03,  5.33356853e-02, -4.38950472e-02,\n",
       "         -3.05171683e-03,  3.05169616e-02,  9.20870434e-03,  3.13107893e-02,\n",
       "          4.56517376e-02,  8.83687846e-03,  4.25428338e-02,  4.34613414e-02,\n",
       "         -6.26262138e-03,  1.93932969e-02,  1.19256591e-02,  3.02408729e-02,\n",
       "          5.27700298e-02,  2.76268814e-02,  2.70295050e-02,  4.64395396e-02,\n",
       "          2.33183224e-02, -1.32977068e-02,  4.25168090e-02,  4.17539291e-02,\n",
       "         -2.07171440e-02, -3.05091986e-03, -3.49634998e-02, -1.58018209e-02,\n",
       "          2.82796975e-02,  3.18871327e-02, -1.00185238e-02,  3.70559692e-02,\n",
       "         -2.04660483e-02,  3.43833677e-02, -5.19951172e-02,  1.43657187e-02,\n",
       "         -3.19187455e-02,  4.42620665e-02, -1.70069467e-02, -5.41532598e-02,\n",
       "         -1.83637685e-03, -3.10276542e-02,  2.70620212e-02,  3.83781455e-02,\n",
       "          9.44856729e-04,  4.08124290e-02,  3.43069993e-02, -2.56459340e-02,\n",
       "         -2.89659575e-02, -8.46189726e-03, -3.09053510e-02, -3.14660035e-02,\n",
       "          1.12297097e-02,  4.83105071e-02, -8.52239411e-03,  3.73097323e-02,\n",
       "          1.00686625e-02, -4.67501767e-02,  3.14085223e-02, -9.90690850e-03,\n",
       "          3.50316428e-02, -4.34398316e-02, -3.34120691e-02, -2.29442939e-02,\n",
       "          5.46824001e-02, -2.52093319e-02,  3.03434283e-02,  3.49135771e-02,\n",
       "         -2.92003751e-02,  3.25537212e-02, -2.44470332e-02, -5.13615040e-03,\n",
       "          4.53417934e-02, -4.48797829e-02,  2.45800074e-02, -1.20365778e-02,\n",
       "          5.65070473e-02,  5.68261035e-02, -3.43276523e-02,  3.47964652e-02,\n",
       "          2.58745272e-02, -4.50530089e-02,  1.43416924e-02, -5.71987443e-02,\n",
       "         -2.25493982e-02, -1.69355851e-02,  2.38797907e-02,  2.41824370e-02,\n",
       "          2.14438234e-02,  4.91244067e-03, -1.37795545e-02, -1.34056611e-02,\n",
       "         -7.39205570e-04,  6.85280375e-03,  1.69284847e-02,  2.94346754e-02,\n",
       "          3.24210189e-02, -4.07992303e-02,  5.47887981e-02,  2.98768822e-02,\n",
       "         -4.58664708e-02, -5.09633310e-02, -2.28002388e-03, -2.35825684e-02,\n",
       "          8.60533398e-03, -4.22287434e-02,  3.29131004e-03,  2.05214019e-03],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 45,\n",
       "  'topic_words': array(['neuroscientific', 'neurobiology', 'neurosciences',\n",
       "         'neurobiological', 'neuroscience', 'neurogenesis', 'neuronal',\n",
       "         'neuroscientists', 'neurosci', 'neuro', 'neurobiol', 'neurol',\n",
       "         'neurocultures', 'neurons', 'neurological', 'neuroscientist',\n",
       "         'neuron', 'neural', 'biology', 'biochemical', 'neuroimaging',\n",
       "         'scientific', 'neuroethics', 'genome', 'stimulus', 'neuroimage',\n",
       "         'neurology', '뉴런', '신경망', 'neurosurg', 'biological', 'stimuli',\n",
       "         '신경', 'researchers', 'psychotherapy', '유전자', 'genetic', 'gene',\n",
       "         'cerebrospinal', '과학', 'toothgrowth', '작용', 'serotonin', '자극',\n",
       "         '연구', 'neurofeminism', 'biologically', 'genetics', 'dopaminergic',\n",
       "         'brainstem'], dtype='<U15'),\n",
       "  'topic_vector': array([-3.51144709e-02,  2.76039224e-02, -2.44732499e-02,  1.66083258e-02,\n",
       "         -3.42888720e-02,  5.05541191e-02, -1.62711311e-02,  2.14120056e-02,\n",
       "         -1.59284826e-02,  3.16633731e-02, -1.82904135e-02, -2.80795097e-02,\n",
       "         -1.96831822e-02, -5.43686422e-03, -3.80490460e-02,  1.60908401e-02,\n",
       "         -1.69409718e-02, -3.65071632e-02, -6.39947737e-03,  5.16334660e-02,\n",
       "          1.45449741e-02, -4.15238738e-02,  3.29876244e-02,  2.58955006e-02,\n",
       "         -5.74434586e-02,  5.92461182e-03,  3.69918277e-03, -2.28379797e-02,\n",
       "          5.08318208e-02, -3.95102166e-02, -1.95862222e-02,  3.48831899e-02,\n",
       "         -7.99443759e-03, -5.64692952e-02,  2.19965111e-02, -5.51280789e-02,\n",
       "          1.47232320e-02, -2.47519892e-02,  3.36124562e-04, -3.68702970e-02,\n",
       "         -9.26994625e-03,  2.99565755e-02,  5.70916235e-02,  3.43518592e-02,\n",
       "         -3.13068293e-02, -4.96952161e-02,  2.32692491e-02,  2.25704424e-02,\n",
       "          9.22194589e-03,  5.00271890e-05,  4.45802324e-02, -3.80067490e-02,\n",
       "          3.36857215e-02,  1.74862631e-02,  1.85213685e-02, -5.53289279e-02,\n",
       "          4.01859991e-02, -2.48551797e-02,  5.07806661e-03,  4.46222015e-02,\n",
       "         -5.36812805e-02,  5.56555651e-02, -4.71332408e-02, -3.32861580e-02,\n",
       "          1.13417273e-02, -2.73244246e-03, -2.07457761e-03, -2.91265156e-02,\n",
       "          8.91240686e-03, -9.28028114e-03,  8.38164520e-03,  3.84317967e-03,\n",
       "          2.95813531e-02, -3.18625793e-02, -3.72733288e-02, -1.39331007e-02,\n",
       "          2.25592405e-02,  5.22329807e-02, -3.58843617e-02, -5.73443472e-02,\n",
       "         -5.74834086e-02, -4.96698096e-02,  1.30726779e-02,  2.21336316e-02,\n",
       "          2.27466431e-02, -3.01865599e-04, -4.84100766e-02, -4.15033242e-03,\n",
       "          3.01920585e-02,  1.16229998e-02, -5.63591234e-02, -4.98577245e-02,\n",
       "         -1.14986552e-02, -4.08147201e-02,  2.24323920e-03,  5.48709072e-02,\n",
       "          4.84542772e-02,  5.72405048e-02,  2.77780462e-02,  1.81297772e-02,\n",
       "          1.30258715e-02,  3.45021822e-02, -1.95079260e-02,  1.17261242e-02,\n",
       "          1.17778662e-03,  5.45786731e-02, -5.44639826e-02, -8.57237075e-03,\n",
       "         -2.02794038e-02,  4.54625674e-02,  2.87579186e-02, -5.39681017e-02,\n",
       "          3.30320969e-02, -1.07938973e-02,  2.02937219e-02, -5.70472479e-02,\n",
       "          4.77482714e-02,  4.21453938e-02,  5.40561741e-03, -2.65385862e-02,\n",
       "         -3.98018770e-02,  2.32529547e-02,  3.75891253e-02, -2.69511901e-02,\n",
       "         -3.71863358e-02,  2.05099154e-02,  5.03823124e-02, -1.60509311e-02,\n",
       "         -2.84617227e-02,  5.43981381e-02, -4.78187539e-02, -3.27536687e-02,\n",
       "          5.52334264e-02,  2.73885597e-02, -2.61551123e-02,  5.71825430e-02,\n",
       "         -3.51694264e-02,  1.69581529e-02,  5.60640097e-02, -1.29413884e-02,\n",
       "          5.54411747e-02, -2.46245284e-02,  2.95072589e-02, -1.51161999e-02,\n",
       "          5.44539727e-02,  2.46846639e-02,  1.04569690e-02,  4.84591797e-02,\n",
       "          1.23367077e-02,  1.24927713e-02,  5.65749519e-02,  5.00011779e-02,\n",
       "         -2.08724383e-02, -1.99007057e-02, -3.50607671e-02,  2.09971927e-02,\n",
       "         -1.54750561e-02, -3.51076834e-02,  1.61762815e-02, -3.66850160e-02,\n",
       "          3.36376056e-02, -4.65259366e-02, -4.86808419e-02,  3.95784900e-02,\n",
       "          3.00255548e-02, -4.20855097e-02,  4.03237483e-03, -1.45025933e-02,\n",
       "         -5.60440309e-02,  5.44014154e-03, -1.66622568e-02, -1.58393979e-02,\n",
       "          2.88123395e-02, -3.18504544e-03,  8.56678642e-04, -3.43423001e-02,\n",
       "          1.75753627e-02,  2.97766328e-02, -5.65101020e-02,  4.50189635e-02,\n",
       "         -1.24831730e-02, -3.95676233e-02,  1.72647797e-02, -6.16001780e-04,\n",
       "         -1.10637664e-03, -1.12438397e-02,  2.64292192e-02,  5.40125966e-02,\n",
       "          1.59344710e-02,  3.06727756e-02,  3.53115238e-02, -1.83334854e-02,\n",
       "         -1.65558960e-02, -2.25917641e-02, -3.63403633e-02, -1.90782342e-02,\n",
       "          2.77862512e-02,  3.68421003e-02,  4.90482710e-02,  7.87243247e-03,\n",
       "         -3.10780872e-02,  2.49752458e-02,  5.16153276e-02, -3.24636437e-02,\n",
       "          2.41365214e-03, -2.14602035e-02,  7.57064903e-03, -9.28710622e-04,\n",
       "          4.96379025e-02,  5.14207743e-02, -9.51935130e-04,  7.58303038e-04,\n",
       "         -7.19371485e-03,  1.52963083e-04,  1.70168299e-02, -1.94353778e-02,\n",
       "          1.15974257e-02, -2.45591495e-02, -3.73881161e-02,  9.79799032e-03,\n",
       "         -1.64051112e-02,  2.85360552e-02,  5.68837635e-02,  1.98772810e-02,\n",
       "         -1.49680616e-03, -1.32398875e-02, -5.61051257e-02,  2.03326643e-02,\n",
       "          3.32745328e-03, -2.93422900e-02,  2.06722077e-02,  5.16016670e-02,\n",
       "         -2.18382068e-02,  4.49121520e-02,  2.67938487e-02,  1.57685596e-02,\n",
       "          2.03141123e-02,  3.42696952e-03,  5.26541695e-02, -7.50699965e-03,\n",
       "         -4.57359068e-02, -2.80458276e-04, -7.25711789e-03, -1.52970909e-03,\n",
       "          2.05821302e-02,  1.70135796e-02,  5.10187447e-02,  1.08817192e-02,\n",
       "         -1.75885740e-03,  3.18032550e-03,  2.05053631e-02, -3.73579189e-02,\n",
       "          5.51256724e-02, -2.63531897e-02,  1.73471496e-02, -2.71426607e-02,\n",
       "          2.06542108e-02,  3.79934870e-02, -4.55682874e-02,  4.27179411e-02,\n",
       "          2.74618715e-03,  4.85784486e-02, -5.01500778e-02, -1.94543954e-02,\n",
       "          5.04050888e-02, -5.57488538e-02, -5.32434024e-02,  2.94815693e-02,\n",
       "          2.62841452e-02,  2.96824630e-02,  1.87899321e-02, -3.53349671e-02,\n",
       "         -3.09544075e-02,  3.26683070e-03,  7.55157275e-03,  1.40885236e-02,\n",
       "         -5.30959554e-02,  1.11293737e-02, -5.68848848e-02, -4.54060845e-02,\n",
       "          1.07469326e-02,  1.45129673e-03, -9.55180367e-05,  6.70515047e-03,\n",
       "         -3.29525881e-02,  3.55989672e-02, -4.93256412e-02, -1.57401003e-02,\n",
       "         -1.72139183e-02, -1.06293021e-03,  5.17483428e-02, -2.82761659e-02,\n",
       "          1.46227395e-02, -9.85434372e-03,  2.07640938e-02,  8.83540791e-03,\n",
       "          3.98224294e-02,  2.56004073e-02,  2.26399992e-02,  4.41480614e-02,\n",
       "         -4.00799923e-02,  2.24576425e-02, -1.71169657e-02, -3.68061736e-02,\n",
       "          4.86565894e-03, -5.20792380e-02, -1.37019437e-02,  2.20673177e-02,\n",
       "          2.95741204e-02,  1.83902811e-02, -2.24631038e-02, -4.60641272e-02,\n",
       "          3.31268646e-02, -3.19120511e-02,  5.66986315e-02,  5.40890768e-02,\n",
       "         -1.91118065e-02,  1.01077082e-02,  5.13843931e-02, -3.79873551e-02,\n",
       "         -1.17006013e-02, -5.74819371e-02,  1.69218816e-02,  1.56452488e-02,\n",
       "         -5.63029945e-02,  1.00704366e-02,  4.58581261e-02,  1.53852850e-02,\n",
       "          3.14884409e-02,  3.06070540e-02, -3.78175564e-02, -4.10435796e-02,\n",
       "         -5.59065007e-02, -2.27992795e-02,  4.09323871e-02, -2.19594478e-03,\n",
       "         -4.22225185e-02, -1.96757149e-02, -4.08623321e-03,  1.93871080e-03,\n",
       "         -3.26035842e-02,  1.27635384e-02, -1.71128679e-02, -2.49528326e-02,\n",
       "          2.35291123e-02,  4.28804196e-02,  4.37395014e-02, -4.35368381e-02,\n",
       "         -7.38710118e-03,  3.51830423e-02,  2.52504312e-02,  1.72584075e-02,\n",
       "         -4.78535406e-02,  2.78472938e-02,  2.80444417e-02, -1.95824672e-02,\n",
       "         -3.38620506e-02,  1.25540877e-02, -9.02922824e-04, -4.84705903e-02,\n",
       "         -3.92878690e-04, -1.97255481e-02,  5.47933206e-02,  1.91664863e-02,\n",
       "          1.08806067e-03,  3.12555619e-02, -5.32519892e-02, -1.01671908e-02,\n",
       "         -2.07331479e-02,  3.73098254e-02,  2.54501905e-02,  7.54818926e-03,\n",
       "         -1.85565241e-02, -3.12760659e-02,  2.41118278e-02, -3.15491110e-02,\n",
       "         -1.11015039e-02,  1.75836459e-02,  4.88876067e-02, -3.84708866e-02,\n",
       "          4.97429855e-02, -4.27643843e-02,  4.86935265e-02,  3.23947109e-02,\n",
       "         -1.07524907e-02,  5.73604293e-02,  3.55989970e-02, -5.69454059e-02,\n",
       "          5.68834543e-02,  4.25888188e-02, -7.07061542e-03, -1.03877289e-02,\n",
       "          2.86231786e-02,  4.42154631e-02, -3.97035778e-02,  2.28871312e-02,\n",
       "          4.73753475e-02, -1.87873282e-02,  2.86973622e-02,  4.64531705e-02,\n",
       "          5.24211600e-02,  5.72239086e-02,  4.28202786e-02, -1.51076764e-02,\n",
       "         -1.39314001e-02,  2.48163678e-02, -3.50670181e-02,  1.87449101e-02,\n",
       "          3.62136029e-02, -6.56459806e-03,  5.51344827e-02,  9.51013900e-03,\n",
       "         -6.78034546e-03,  5.00466600e-02, -1.71029884e-02,  5.72935157e-02,\n",
       "         -9.71931033e-03, -2.29555070e-02,  5.41733205e-02,  3.46166901e-02,\n",
       "         -3.64298560e-02,  2.75511295e-04,  4.69556190e-02,  1.92008354e-02,\n",
       "          5.38901351e-02,  8.91784951e-03, -4.67009619e-02, -4.22292352e-02,\n",
       "         -4.74877842e-02,  3.86303919e-03, -3.83756496e-02,  1.46238329e-02,\n",
       "         -3.55188176e-02, -1.76814366e-02,  4.99930605e-02, -1.09787984e-02,\n",
       "          3.53588685e-02, -4.07311209e-02, -5.74783348e-02,  3.07343770e-02,\n",
       "          3.00445594e-02,  3.83551791e-02,  1.11737652e-02, -5.46068288e-02,\n",
       "          2.19483916e-02, -1.84236970e-02, -2.88162064e-02,  4.00173031e-02,\n",
       "          1.35712270e-02,  3.02821510e-02, -2.59356089e-02,  2.92382631e-02,\n",
       "          1.02643427e-02,  1.39444286e-03, -4.56112325e-02,  7.89699145e-03,\n",
       "          1.54138124e-02,  1.47553468e-02, -3.97391729e-02,  1.59246866e-02,\n",
       "         -5.39339660e-03, -5.67223653e-02, -3.93581167e-02, -5.11871511e-03,\n",
       "          8.94974824e-03, -3.80305871e-02, -3.09276246e-02, -1.11959623e-02,\n",
       "          4.83510420e-02, -1.94575191e-02, -9.58763715e-03,  5.12506673e-03,\n",
       "         -5.53551838e-02, -2.27631126e-02, -4.41107294e-03, -3.46243046e-02,\n",
       "         -2.52786614e-02,  2.71658879e-02, -2.73050964e-02, -1.90474391e-02,\n",
       "          3.51696648e-02,  5.74842207e-02, -3.83575633e-02, -5.48339961e-03,\n",
       "          2.59387847e-02, -2.69698855e-02, -4.23707776e-02, -5.72390966e-02,\n",
       "         -1.15684206e-02, -3.58577482e-02,  2.42037866e-02,  8.95164721e-03,\n",
       "          3.38670127e-02,  2.17711907e-02, -2.32968796e-02, -2.61697266e-02,\n",
       "         -5.08033670e-02, -2.09327918e-02,  2.59826742e-02,  2.34615039e-02,\n",
       "          2.12145448e-02, -4.49856929e-02,  5.67823537e-02,  7.17208209e-03,\n",
       "         -3.94745506e-02, -5.71255088e-02,  3.10628233e-03, -2.53050011e-02,\n",
       "         -3.17459553e-02, -5.71770780e-02,  2.76367310e-02,  3.96807753e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 46,\n",
       "  'topic_words': array(['tensorflow', 'matplotlib', 'nvidia', 'github', 'ubuntu', 'xorg',\n",
       "         '우분투', 'gedit', 'gcc', 'linux', 'bashrc', 'glm', 'vtk', 'gpu',\n",
       "         'anaconda', 'numpy', 'argv', '커널', 'kernel', 'tensor', 'cython',\n",
       "         'gaussian', 'gtx', '컴파일러', 'matlab', 'lineplot', 'sklearn',\n",
       "         'compile', 'stdout', 'installed', 'sudo', 'python', 'kwargs',\n",
       "         'subprocess', '컴파일', 'vertexcount', 'compiler', 'cm', 'scipy',\n",
       "         'sgacc', 'svms', 'cuda', 'gpi', 'rjava', 'stable', 'nipype',\n",
       "         'mxmatrix', 'install', 'ggplot', 'cpu'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.57507165e-02, -4.00316454e-02, -4.97310907e-02,  1.80700514e-02,\n",
       "         -2.53555346e-02, -5.65198213e-02,  3.76545377e-02,  4.03733328e-02,\n",
       "          4.59578969e-02, -3.80498283e-02,  3.11827790e-02, -1.80849750e-02,\n",
       "          5.48818260e-02, -2.74752267e-03, -1.50099276e-02, -4.38589090e-03,\n",
       "          1.05495928e-02,  4.36738990e-02,  3.61218788e-02,  4.51412052e-02,\n",
       "          4.49988097e-02,  3.29484977e-02,  3.17117609e-02,  4.80334163e-02,\n",
       "         -5.50666749e-02, -4.97575104e-02,  3.31084579e-02,  2.57638539e-03,\n",
       "          3.20191421e-02, -5.50707281e-02, -4.45225574e-02,  1.73377674e-02,\n",
       "         -1.01696020e-02, -5.46130538e-02, -2.07631420e-02,  1.14496080e-02,\n",
       "         -2.33440418e-02, -2.35916693e-02,  4.54742499e-02, -4.39550243e-02,\n",
       "         -3.95370275e-02,  1.65305790e-02,  4.08045053e-02,  2.40643676e-02,\n",
       "          1.58611201e-02, -8.34804308e-03,  4.55576889e-02, -1.07638361e-02,\n",
       "         -5.57898320e-02, -1.33261941e-02, -3.87811027e-02, -2.29193028e-02,\n",
       "          3.89962532e-02, -1.56811327e-02,  2.71216575e-02, -5.53925447e-02,\n",
       "         -4.25599702e-02,  5.31323403e-02,  1.45055093e-02,  5.05829304e-02,\n",
       "          4.02532555e-02,  4.22369428e-02,  2.47563254e-02, -5.58370203e-02,\n",
       "          1.32323876e-02, -3.28449681e-02, -1.69538017e-02, -2.28525624e-02,\n",
       "          5.63553758e-02,  4.69842851e-02, -2.41316035e-02,  2.21187789e-02,\n",
       "          3.53927985e-02, -2.36269385e-02, -5.41719981e-02, -2.78464537e-02,\n",
       "         -1.35820461e-02, -3.49082462e-02, -1.79551262e-02, -5.64863980e-02,\n",
       "         -5.65384813e-02,  4.24993746e-02, -4.72111665e-02, -4.35676165e-02,\n",
       "          4.04577591e-02,  1.94260292e-02,  7.56763294e-03, -4.82201688e-02,\n",
       "          4.29310910e-02, -2.21319553e-02,  1.35518610e-03, -3.42678577e-02,\n",
       "          4.07729857e-02, -1.09334886e-02,  5.53464293e-02,  6.53157197e-03,\n",
       "         -5.14503121e-02,  4.39027101e-02,  5.02883233e-02, -2.41475385e-02,\n",
       "         -2.91223172e-02,  2.52840598e-03, -4.38518636e-02,  4.21850085e-02,\n",
       "          3.69924381e-02,  9.22583323e-03, -4.81665730e-02, -1.48166940e-02,\n",
       "          3.47921290e-02,  2.65423637e-02,  2.10199114e-02, -5.15150875e-02,\n",
       "         -1.79280788e-02, -5.53333759e-02,  4.11440581e-02,  2.83161905e-02,\n",
       "         -3.15196514e-02, -3.82251181e-02, -5.49117662e-02,  4.79246788e-02,\n",
       "          3.08805536e-02, -2.08462626e-02, -3.82322334e-02,  3.84837203e-02,\n",
       "         -1.64650809e-02,  4.97665256e-02, -3.10675353e-02, -2.12803911e-02,\n",
       "          3.96757051e-02, -2.00838875e-02, -3.14986371e-02,  3.70691228e-03,\n",
       "          5.65480255e-02,  5.25001390e-03, -8.85696989e-03, -5.99130802e-03,\n",
       "          4.65330593e-02,  8.67315102e-03,  3.99321914e-02,  1.65724696e-03,\n",
       "         -1.41583076e-02, -9.63430852e-03,  3.75561528e-02,  3.21660079e-02,\n",
       "         -4.39642519e-02, -4.80467938e-02, -2.89305765e-02,  5.06181233e-02,\n",
       "          6.55101193e-03,  2.18928084e-02,  3.22016031e-02, -3.74872237e-02,\n",
       "         -2.45572552e-02, -4.41066176e-02, -9.35930107e-03, -1.09719299e-03,\n",
       "         -3.95863913e-02,  3.36488001e-02,  1.53929496e-03, -4.76510711e-02,\n",
       "          2.90955957e-02,  4.07185778e-02,  5.61457090e-02, -8.92209914e-03,\n",
       "          4.57502641e-02, -2.81334314e-02, -1.65982246e-02,  1.02764927e-02,\n",
       "          2.24596262e-02,  1.67437587e-02,  4.56292890e-02, -2.20173802e-02,\n",
       "         -2.94887330e-02, -6.77399710e-03, -9.58658103e-03,  4.28360663e-02,\n",
       "         -5.59154898e-02, -2.81314179e-02, -5.53857647e-02,  5.49252667e-02,\n",
       "         -3.80646251e-02,  2.49741450e-02, -4.61280681e-02, -2.88838949e-02,\n",
       "         -4.47702259e-02, -3.39044221e-02,  4.52322625e-02,  5.28371930e-02,\n",
       "          1.97855979e-02,  5.45806251e-02,  4.42105383e-02, -5.12916483e-02,\n",
       "          3.47321369e-02,  3.64034250e-03, -1.38749704e-02,  5.60782813e-02,\n",
       "         -3.20607238e-02, -1.52501538e-02,  3.72279733e-02, -5.83212217e-03,\n",
       "         -4.60751690e-02, -2.43937057e-02, -1.52014894e-02,  2.21494734e-02,\n",
       "         -3.00804377e-02,  5.94717264e-03, -9.05717548e-04,  3.14567462e-02,\n",
       "          4.24349792e-02,  1.83273572e-02, -3.72139290e-02,  2.36014780e-02,\n",
       "          5.60741238e-02, -4.84747402e-02, -5.53362817e-03,  2.33373512e-02,\n",
       "          1.18232779e-02,  2.77220905e-02,  3.91462483e-02,  9.74145066e-03,\n",
       "         -3.32845934e-03,  2.64451280e-02, -1.04915695e-02, -2.91083287e-02,\n",
       "         -5.63066863e-02,  3.21159023e-03, -2.06456836e-02, -5.09893382e-03,\n",
       "          4.23513018e-02, -2.81053912e-02, -2.77176853e-02,  4.94036935e-02,\n",
       "          4.51639630e-02,  1.55799417e-02,  3.12591381e-02,  5.15721925e-02,\n",
       "         -1.14466595e-02, -2.32510399e-02,  4.79305387e-02, -4.35065031e-02,\n",
       "          3.54908109e-02,  8.70731380e-03,  1.74507964e-02,  2.12993175e-02,\n",
       "         -4.26580049e-02, -5.05542792e-02, -2.53982544e-02, -3.42427976e-02,\n",
       "          4.09866869e-02, -4.01196666e-02, -3.59302461e-02,  1.03769973e-02,\n",
       "         -8.06962419e-03,  4.25233841e-02,  2.73133684e-02, -2.73794886e-02,\n",
       "          2.20172554e-02, -3.39052416e-02, -3.53952944e-02, -2.55302694e-02,\n",
       "          3.83515917e-02,  4.54233773e-02, -4.98058908e-02, -2.43717059e-02,\n",
       "          3.02083362e-02, -4.08112369e-02,  7.82979745e-03, -4.87815738e-02,\n",
       "          2.43241843e-02,  8.44001304e-03, -2.08723340e-02, -2.23003533e-02,\n",
       "         -2.31688265e-02,  5.02372272e-02,  2.37251315e-02, -3.11497655e-02,\n",
       "         -4.63738702e-02,  2.49469042e-04, -2.29334608e-02,  3.92163470e-02,\n",
       "          3.84292416e-02,  4.45857309e-02, -1.16895661e-02, -2.57089455e-02,\n",
       "         -9.77639481e-03,  3.12882173e-03, -4.78214733e-02, -2.09943745e-02,\n",
       "          3.45099680e-02, -1.89229771e-02,  2.32625008e-02,  5.83504280e-03,\n",
       "         -1.03986608e-02,  5.14249951e-02, -5.65046184e-02, -2.84621473e-02,\n",
       "         -1.78349670e-02,  1.35620786e-02,  2.70763040e-02,  4.95051257e-02,\n",
       "         -3.42589952e-02,  3.64140533e-02, -2.68785879e-02, -2.89903115e-02,\n",
       "         -3.81337553e-02,  2.09848080e-02, -3.61138321e-02, -3.80368046e-02,\n",
       "          2.65352032e-03,  4.81517129e-02,  2.57425010e-02,  3.72688174e-02,\n",
       "         -4.50884439e-02,  3.98969688e-02, -3.71230990e-02, -4.72472981e-03,\n",
       "          5.64652123e-02, -5.53978644e-02,  3.32212187e-02, -1.74802560e-02,\n",
       "         -1.53493965e-02, -3.49048562e-02, -2.69619431e-02,  1.26028089e-02,\n",
       "          2.78774593e-02,  5.30429296e-02, -4.03828360e-02, -2.18024235e-02,\n",
       "          2.19186936e-02, -2.69309934e-02, -2.14520786e-02, -2.86246333e-02,\n",
       "         -4.49698865e-02, -5.87260984e-05, -2.48006415e-02,  4.81158495e-02,\n",
       "          4.25313693e-03,  1.78332645e-02, -5.60986511e-02, -2.55732443e-02,\n",
       "         -2.20891442e-02,  5.63804545e-02,  1.70644950e-02,  3.28806904e-03,\n",
       "         -1.09891864e-02, -3.08914930e-02, -9.99079272e-03,  5.87211596e-03,\n",
       "         -3.26468460e-02,  1.09439986e-02,  3.45419757e-02, -4.39096205e-02,\n",
       "         -9.38629266e-03, -5.60133867e-02,  7.92801380e-04, -1.99499484e-02,\n",
       "         -4.29536812e-02,  3.03756744e-02,  2.41062567e-02, -4.52314876e-02,\n",
       "         -1.58851426e-02, -2.54483502e-02,  4.16487716e-02, -3.38714123e-02,\n",
       "          4.37238663e-02, -3.69290076e-02,  2.82056779e-02,  3.14215459e-02,\n",
       "         -5.31968139e-02,  4.50681448e-02,  1.53590664e-02,  5.31895161e-02,\n",
       "          4.51296605e-02, -1.68434102e-02,  2.47904584e-02, -5.22933900e-02,\n",
       "          6.19421713e-03,  2.09219549e-02,  5.58701456e-02, -3.99393179e-02,\n",
       "         -5.15172072e-02, -5.54846637e-02,  1.45371677e-03, -5.65632470e-02,\n",
       "         -2.66104285e-02,  3.72122712e-02,  1.76581144e-02, -5.62936775e-02,\n",
       "         -5.02676554e-02,  3.65948002e-03, -3.65390778e-02, -3.48711982e-02,\n",
       "          1.23761892e-02, -2.84422487e-02, -3.27502899e-02,  3.26595716e-02,\n",
       "          2.67822351e-02,  4.99364324e-02,  3.99771407e-02,  3.40398289e-02,\n",
       "          3.11549064e-02, -3.56859863e-02,  5.55846840e-02, -9.79095697e-03,\n",
       "          4.02723365e-02,  1.38881663e-02,  4.36241888e-02, -3.76850031e-02,\n",
       "          3.65227945e-02,  1.36662452e-02,  2.24887505e-02,  4.14133072e-02,\n",
       "          1.94069091e-02, -2.55894139e-02,  1.75670150e-03, -3.17392163e-02,\n",
       "          3.78266908e-02,  3.87379676e-02, -5.00736118e-04, -4.15534154e-02,\n",
       "          4.54079062e-02,  4.15970059e-03,  5.47177307e-02,  2.27200682e-03,\n",
       "         -3.88304219e-02,  3.01685482e-02,  3.94360535e-02, -2.85227764e-02,\n",
       "          4.70573716e-02, -9.85528715e-03,  4.06594649e-02,  2.02700347e-02,\n",
       "         -1.51235722e-02,  2.47719530e-02, -2.27041766e-02, -8.04969389e-03,\n",
       "         -2.02357527e-02,  3.98248136e-02, -4.56245355e-02, -2.58642295e-03,\n",
       "         -5.37298210e-02,  3.34295188e-03,  2.07357015e-02, -4.47373986e-02,\n",
       "         -2.81956047e-02,  3.07762157e-02,  5.41362055e-02,  3.15619968e-02,\n",
       "          5.24255224e-02,  3.98562662e-02,  9.68687050e-03,  5.55507839e-02,\n",
       "         -5.35529703e-02, -7.85623584e-03, -5.39471917e-02, -5.01152277e-02,\n",
       "          5.29835522e-02,  2.75448784e-02, -3.62167996e-03,  5.09463809e-02,\n",
       "          4.12521362e-02, -1.46003580e-02,  5.28231598e-02,  7.04017049e-03,\n",
       "          3.35226022e-02, -5.26968986e-02, -1.12191774e-03,  4.10987921e-02,\n",
       "          4.49292995e-02, -4.76330966e-02,  4.94109541e-02, -5.36376536e-02,\n",
       "          1.09740868e-02, -1.69434939e-02, -5.03513925e-02, -1.11196302e-02,\n",
       "         -1.90606043e-02,  1.23290522e-02, -2.85445359e-02, -1.02910390e-02,\n",
       "          2.45937034e-02, -3.28256818e-03, -4.35610004e-02,  8.58145021e-03,\n",
       "          1.72547419e-02,  3.48370858e-02, -6.57163328e-03, -5.34614585e-02,\n",
       "          2.74099484e-02, -3.61873247e-02, -7.13850884e-03, -2.07156502e-03,\n",
       "          1.58424154e-02, -2.93751974e-02,  3.23853903e-02, -6.81846216e-03,\n",
       "         -4.83281426e-02, -4.32866029e-02,  5.25453947e-02,  2.84578595e-02,\n",
       "         -3.24125886e-02,  5.64021282e-02,  3.21159549e-02, -3.57104801e-02,\n",
       "          1.09168785e-02, -5.65423816e-02,  2.01457199e-02,  3.81665044e-02,\n",
       "          1.67243220e-02,  8.95732827e-03, -2.64533777e-02,  3.73178646e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 47,\n",
       "  'topic_words': array(['urllib', 'url', 'redirect', 'redirected', 'request', 'requests',\n",
       "         '요청', 'page', '페이지', 'pages', 'localhost', 'createpage',\n",
       "         'response', 'query', '홈페이지', 'demands', 'queries', 'crawler',\n",
       "         'regression', 'utf', 'json', 'address', 'retrieval', 'regex',\n",
       "         'xpath', 'responsivity', 'recursive', '파이썬', 'addresses',\n",
       "         'pathological', 'responses', 'regressor', 'javascript', 'html',\n",
       "         'webdriver', 'application', 'khtml', 'demand', '파라미터', 'pathway',\n",
       "         'rewrite', 'website', 'google', 'mxpath', 'pathophysiology',\n",
       "         'replication', 'python', 'path', 'proxy', 'parameters'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-4.76216003e-02, -9.57930810e-04, -1.44454567e-02,  2.74825506e-02,\n",
       "         -3.41213532e-02, -3.78938615e-02,  1.75926611e-02,  2.08690912e-02,\n",
       "          4.75910380e-02,  7.31031690e-03,  3.54394093e-02,  3.76707390e-02,\n",
       "          2.98517887e-02,  4.13598791e-02,  2.75364928e-02, -1.49040641e-02,\n",
       "          1.64991356e-02, -5.18422574e-03,  1.78435780e-02,  5.07054552e-02,\n",
       "         -1.06970267e-02,  2.03834381e-02,  3.71402204e-02,  2.58435495e-02,\n",
       "         -3.70891839e-02,  1.84863769e-02,  8.83118343e-03, -4.11277600e-02,\n",
       "         -6.42841011e-02, -5.54967225e-02, -3.57615910e-02,  5.19439466e-02,\n",
       "         -4.17690799e-02, -3.67637910e-02, -3.78547609e-02, -4.31704335e-02,\n",
       "          3.80071774e-02,  4.22868207e-02,  2.39902698e-02,  3.31618218e-03,\n",
       "         -3.18555348e-02, -1.24064612e-03,  1.32241603e-02, -7.77393859e-03,\n",
       "          1.08677894e-04, -1.22192251e-02,  2.79691257e-02, -1.89022757e-02,\n",
       "          2.79966537e-02,  1.84386820e-02, -2.87322104e-02, -7.56242778e-03,\n",
       "         -5.54733984e-02, -4.26798984e-02,  1.61409788e-02, -4.03182320e-02,\n",
       "          2.83528604e-02,  3.10595222e-02,  3.96146141e-02, -4.24050875e-02,\n",
       "         -3.89678031e-03,  4.53627259e-02,  3.05989273e-02, -2.89513208e-02,\n",
       "         -3.33882123e-02,  2.11316291e-02,  2.89553348e-02, -3.69971991e-02,\n",
       "          3.60244922e-02, -2.47963052e-02, -6.71782251e-03,  8.98722652e-03,\n",
       "          5.86210564e-03, -4.89089116e-02, -4.61285338e-02, -2.15282775e-02,\n",
       "          2.39047483e-02,  2.29399782e-02,  5.28353639e-02, -4.88248765e-02,\n",
       "         -5.52703552e-02, -4.36680131e-02,  1.44898519e-03, -5.80070242e-02,\n",
       "          1.74547099e-02,  1.47099118e-03, -2.82288902e-02, -3.11023891e-02,\n",
       "          2.06903229e-03,  2.35910397e-02,  3.13616581e-02, -3.45982686e-02,\n",
       "          4.34758849e-02, -4.62299306e-03,  5.55853955e-02, -4.62434180e-02,\n",
       "         -4.62887883e-02, -4.25664708e-02,  2.17960924e-02, -1.85941365e-02,\n",
       "          3.33551392e-02,  6.19449615e-02,  9.68690496e-03,  1.15879802e-02,\n",
       "          3.14305052e-02, -1.52622554e-02, -2.87793782e-02, -3.18938084e-02,\n",
       "         -1.63716357e-02,  2.52249576e-02,  4.79548275e-02, -2.13786159e-02,\n",
       "          2.58412696e-02, -4.07435186e-02,  3.33125517e-02, -3.51664871e-02,\n",
       "          1.93170048e-02,  1.35892658e-02, -4.04918604e-02,  1.65001862e-02,\n",
       "         -3.42492238e-02,  6.46794587e-03, -3.26056639e-03,  5.31957373e-02,\n",
       "          1.54400347e-02,  3.37493457e-02,  8.16954859e-03, -1.12807136e-02,\n",
       "         -1.18359756e-02, -2.42280774e-02, -4.11443971e-02,  1.90650653e-02,\n",
       "          5.63398972e-02, -6.61794981e-03, -3.21383998e-02, -8.91953520e-03,\n",
       "         -4.09588106e-02,  1.22765172e-02,  4.82362807e-02,  1.63376387e-02,\n",
       "          4.51007783e-02,  1.58957578e-02, -2.63219029e-02,  2.92614456e-02,\n",
       "          2.87725143e-02,  3.47397104e-02, -4.19080891e-02, -3.08772270e-02,\n",
       "          2.46654786e-02,  3.55360024e-02, -5.64349303e-03, -9.83222574e-03,\n",
       "         -3.43624577e-02, -4.92207743e-02, -6.24647364e-03, -1.22598624e-02,\n",
       "         -4.62254956e-02,  3.18303034e-02,  9.71555430e-03,  4.47028223e-03,\n",
       "          3.86036634e-02, -3.33668962e-02,  1.56092076e-02, -6.30308827e-03,\n",
       "          4.84193116e-02, -3.27209383e-02,  2.45331321e-02,  1.17416186e-02,\n",
       "         -1.62406196e-03,  2.61280537e-02,  4.88329642e-02,  8.70639458e-03,\n",
       "         -2.61133257e-02,  2.77681798e-02,  2.24141013e-02,  1.95521545e-02,\n",
       "         -2.84885131e-02,  2.65516099e-02, -4.41693626e-02,  2.85029672e-02,\n",
       "          5.15917726e-02,  1.64442565e-02,  4.34095673e-02,  1.59909185e-02,\n",
       "         -1.41374376e-02,  2.46286802e-02,  5.93365589e-03,  5.77688441e-02,\n",
       "          3.53217870e-02, -4.13184166e-02,  3.50494049e-02, -3.12014222e-02,\n",
       "          5.53050563e-02,  1.02713434e-02, -1.21889450e-02, -1.99066456e-02,\n",
       "          6.24405742e-02, -4.82446477e-02,  4.09487262e-03,  1.70831736e-02,\n",
       "          3.57757621e-02, -8.14265478e-03,  3.86291742e-02, -1.91847943e-02,\n",
       "          2.59193629e-02, -6.09454997e-02,  1.24448584e-02, -2.01220084e-02,\n",
       "          1.98310651e-02,  2.89112963e-02,  9.38696321e-03,  2.12286618e-02,\n",
       "          2.11893264e-02,  2.37590168e-02,  5.23886755e-02,  4.55575669e-03,\n",
       "         -1.59925967e-02,  9.65079106e-03, -7.95727409e-03,  3.23284008e-02,\n",
       "          2.39298455e-02,  1.92286093e-02,  3.09675522e-02,  4.17548046e-02,\n",
       "         -5.40833063e-02, -2.13409699e-02, -2.56646667e-02, -7.29187578e-03,\n",
       "         -4.60718349e-02,  2.67514233e-02, -3.23755406e-02,  4.04254235e-02,\n",
       "          1.02604181e-02, -1.62783358e-02, -3.88859175e-02, -2.56794761e-03,\n",
       "          1.31763294e-02, -3.20989266e-02,  1.17438065e-03, -3.69815715e-03,\n",
       "          1.70631800e-02, -6.31026924e-05,  4.72844718e-03,  4.22385074e-02,\n",
       "          2.53902338e-02, -3.21507491e-02,  1.79389305e-02,  2.77172215e-02,\n",
       "         -3.61120924e-02,  4.34591025e-02,  3.10179535e-02,  2.17940323e-02,\n",
       "         -2.81556733e-02, -4.14052904e-02,  3.38868611e-02, -1.98221598e-02,\n",
       "         -2.03020331e-02,  6.35659844e-02, -4.18403707e-02,  3.35856825e-02,\n",
       "          2.42333151e-02,  4.85551953e-02, -4.70346734e-02, -4.78155054e-02,\n",
       "         -2.63951831e-02, -5.19127250e-02, -1.95951685e-02, -4.36232202e-02,\n",
       "         -7.71043357e-03,  2.96271890e-02, -5.35232909e-02, -3.35747823e-02,\n",
       "         -2.03340091e-02,  5.19689098e-02,  4.89742532e-02, -4.20792475e-02,\n",
       "         -9.37865116e-03,  9.45215952e-03, -3.83635424e-02, -5.41015044e-02,\n",
       "         -1.82447098e-02, -2.39825230e-02,  2.89633423e-02, -6.01293743e-02,\n",
       "          2.18459480e-02, -1.66520588e-02, -4.98299934e-02, -3.61558869e-02,\n",
       "         -1.76803283e-02, -2.95274202e-02,  6.25287741e-03,  5.29065961e-03,\n",
       "         -2.44679814e-03,  5.44531830e-02, -4.89908308e-02, -2.00978816e-02,\n",
       "         -5.65085895e-02,  4.26003113e-02, -7.85440765e-03,  4.65506800e-02,\n",
       "          6.54316042e-03,  1.36765987e-02, -2.15396173e-02,  1.64071806e-02,\n",
       "         -8.53603613e-03,  4.00880352e-02,  3.56799886e-02, -1.53004797e-02,\n",
       "         -4.48689982e-02, -1.06447563e-02,  5.12750261e-02, -1.77057274e-02,\n",
       "          3.09382975e-02, -4.41733338e-02, -3.07930764e-02,  2.77706627e-02,\n",
       "         -2.06040964e-03,  7.43317604e-03,  2.82315016e-02, -3.39038447e-02,\n",
       "          2.73880251e-02, -2.64403373e-02,  1.55593427e-02, -2.76594460e-02,\n",
       "         -4.53664288e-02, -4.05235328e-02,  3.95184942e-02, -4.14833874e-02,\n",
       "          3.65840644e-02, -5.23157716e-02, -5.35957925e-02, -5.23665920e-03,\n",
       "         -3.41571644e-02, -1.21581806e-02,  3.80093642e-02,  3.32391262e-02,\n",
       "          2.76767872e-02,  4.03590202e-02, -4.84968051e-02, -3.19539346e-02,\n",
       "          3.39642465e-02,  4.96908203e-02, -2.20835004e-02, -3.22235748e-02,\n",
       "         -3.91750522e-02,  4.21129689e-02,  3.19765918e-02, -8.78747524e-05,\n",
       "         -1.81356333e-02,  5.06227724e-02, -5.08586057e-02,  3.56524177e-02,\n",
       "          2.07690075e-02, -2.88428669e-03, -1.60359428e-03, -1.07796462e-02,\n",
       "         -2.16975696e-02, -9.54632182e-03, -4.49876040e-02, -4.62893173e-02,\n",
       "         -6.28605485e-04,  9.21148993e-03, -2.27502491e-02, -2.61186771e-02,\n",
       "          2.10124999e-02, -3.41806328e-03,  1.41795604e-02,  4.22019474e-02,\n",
       "         -4.82500866e-02, -6.74606627e-03, -2.39389800e-02, -7.02641439e-03,\n",
       "          1.98969990e-02, -2.22102217e-02,  7.06330035e-03, -5.05193248e-02,\n",
       "         -3.41760293e-02, -2.76898444e-02, -3.94872837e-02, -1.79542247e-02,\n",
       "         -4.70089726e-02, -5.05592003e-02, -4.54935357e-02,  4.10541296e-02,\n",
       "          2.57535279e-02,  3.23613100e-02,  2.97370907e-02, -5.63939326e-02,\n",
       "         -1.87864769e-02,  3.02289128e-02,  1.32647576e-02, -5.28348982e-02,\n",
       "          3.24596278e-02,  2.53204945e-02,  1.26828998e-02, -4.85561490e-02,\n",
       "          2.92887744e-02,  3.69766504e-02,  2.76007131e-03,  1.74925867e-02,\n",
       "          2.87317149e-02, -5.22722956e-03,  5.13662472e-02, -2.34232540e-03,\n",
       "         -1.34371743e-02, -2.12881230e-02, -1.99771076e-02,  2.26709638e-02,\n",
       "          3.56839672e-02,  2.26497743e-02, -4.07551900e-02, -3.66306007e-02,\n",
       "          3.53969410e-02, -1.40984673e-02,  1.12048294e-02, -1.66558288e-02,\n",
       "          2.93910764e-02, -6.14882037e-02,  2.15658061e-02, -1.47389267e-02,\n",
       "          2.38031242e-02,  3.16280946e-02, -2.04614494e-02,  6.09850278e-03,\n",
       "         -3.08414456e-02,  1.76415406e-02,  5.56036122e-02,  9.94840451e-03,\n",
       "          4.62082438e-02, -2.75328942e-02,  2.92962678e-02, -3.33690234e-02,\n",
       "          5.37331700e-02,  2.15570070e-02,  4.11627367e-02,  6.04892075e-02,\n",
       "         -3.57878134e-02, -3.12146600e-02, -5.14559820e-02, -1.63635146e-02,\n",
       "         -1.60984695e-02, -1.69591233e-02, -2.38510827e-03, -4.08889949e-02,\n",
       "         -8.84024892e-03, -2.80003697e-02,  4.36361022e-02, -5.21774292e-02,\n",
       "         -5.02285128e-03, -9.24448110e-03,  2.12458037e-02,  4.53095324e-02,\n",
       "         -5.22298627e-02,  8.86314362e-03, -1.12648029e-02, -3.79124768e-02,\n",
       "         -1.83204301e-02, -3.93153913e-02, -1.26473084e-02,  1.51021453e-02,\n",
       "         -2.12413184e-02,  7.75260944e-03, -4.02277336e-02, -8.37855041e-03,\n",
       "         -5.54783619e-04, -1.13052288e-02, -2.36487370e-02, -1.50882695e-02,\n",
       "          5.65833859e-02,  3.31561193e-02,  3.34145911e-02, -3.85079868e-02,\n",
       "          3.32944170e-02,  2.08908524e-02, -1.94758065e-02, -2.22988129e-02,\n",
       "          2.98819095e-02,  5.56583889e-02, -3.73938382e-02,  2.69477554e-02,\n",
       "          2.17508078e-02,  1.38066465e-03, -2.72373259e-02, -1.48771480e-02,\n",
       "         -1.44261690e-02,  4.53855246e-02, -3.80456038e-02, -5.31199798e-02,\n",
       "          4.09862623e-02,  3.40096876e-02,  1.35613857e-02,  7.41168344e-03,\n",
       "          2.50958167e-02,  1.24376146e-02,  8.87038279e-03, -2.26776721e-03,\n",
       "         -3.30097638e-02, -3.53387184e-02,  5.19151762e-02,  4.89744954e-02,\n",
       "         -8.09674151e-03, -4.73307595e-02,  4.57393155e-02,  3.10549699e-02,\n",
       "         -3.97165678e-02, -4.24814820e-02, -5.14777191e-02,  2.31526159e-02,\n",
       "          6.52502244e-03,  1.85114406e-02,  4.65651564e-02,  3.02893221e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 48,\n",
       "  'topic_words': array(['피해자', 'deaths', 'facts', '사망', '전염병', 'injuries', 'fatalities',\n",
       "         '정부', 'epidemic', 'drugs', 'plausible', 'causal', 'evidence', '증상',\n",
       "         'psychiatric', 'suffering', '감염병', 'mediation', '사건', '의학', '뉴스',\n",
       "         '손상', 'diseases', 'opioid', '언론', 'deviation', 'prevalence', '증명',\n",
       "         'disorders', 'injury', 'feminist', 'drug', '사례', '의료', 'death',\n",
       "         '감염자', 'cases', '인한', 'news', 'medical', 'affected', 'pain', '면역',\n",
       "         '정치', 'media', '증권사', '실제', 'fraud', '백신', '틀린'], dtype='<U15'),\n",
       "  'topic_vector': array([ 0.01847832,  0.02322637,  0.00848463, -0.0324012 ,  0.04632065,\n",
       "          0.02724947,  0.0543223 ,  0.00721063,  0.00389995,  0.03023821,\n",
       "          0.00273247,  0.00397951,  0.0199733 , -0.00134323,  0.01352225,\n",
       "          0.00438958, -0.01852564, -0.05273222, -0.02632531,  0.05813131,\n",
       "          0.02488423, -0.0544567 ,  0.04203602, -0.01235232, -0.06081677,\n",
       "         -0.00447718, -0.00928569, -0.00089627,  0.03024669, -0.05777676,\n",
       "          0.0131978 , -0.01656135,  0.00160216, -0.01266951,  0.00237968,\n",
       "         -0.0517966 ,  0.0174619 , -0.03546517, -0.02974659, -0.01035687,\n",
       "         -0.01003182,  0.03366344,  0.05061415,  0.00420743,  0.02507849,\n",
       "         -0.05911753, -0.02456946, -0.02973465, -0.03088317,  0.01168853,\n",
       "         -0.01803947, -0.03169559,  0.00055603,  0.01063062, -0.00628087,\n",
       "         -0.06086832,  0.03468756,  0.01156742, -0.02367427,  0.01163522,\n",
       "          0.01875929,  0.05644088,  0.02938854, -0.04807044,  0.01520681,\n",
       "         -0.01149928,  0.03548287, -0.01534449, -0.00334369,  0.02031435,\n",
       "          0.02949063,  0.04664498,  0.05565792, -0.02558631,  0.00932619,\n",
       "          0.02280531,  0.00694266,  0.03412994, -0.00197812, -0.06107515,\n",
       "         -0.06110272, -0.00667497, -0.00557986,  0.05446523, -0.0270778 ,\n",
       "          0.00948513, -0.05665305, -0.01581901, -0.01145629, -0.00679725,\n",
       "         -0.05323032, -0.01467091, -0.01143338,  0.02070461,  0.00406189,\n",
       "          0.02285572,  0.05752053,  0.03753052,  0.02255137,  0.00882603,\n",
       "          0.0058418 ,  0.00392287, -0.01489952,  0.02004957,  0.01501157,\n",
       "          0.03308887, -0.01878516, -0.02876018,  0.00403062, -0.00698935,\n",
       "         -0.015215  ,  0.01130457,  0.00613447,  0.00825594,  0.02080181,\n",
       "          0.03907706, -0.01483369, -0.02996668,  0.00556063, -0.02310886,\n",
       "          0.00391864,  0.04104713,  0.01715673, -0.01044385, -0.00753111,\n",
       "          0.05590064,  0.00186675, -0.01425218, -0.00406324,  0.00717523,\n",
       "         -0.0488029 , -0.02261244, -0.00893948, -0.04023827,  0.00751448,\n",
       "          0.06071056,  0.01603335, -0.03262404,  0.04890503,  0.00046645,\n",
       "          0.02761915,  0.04773017,  0.04256289, -0.00268778,  0.02467026,\n",
       "         -0.05438359,  0.05732993,  0.01220657,  0.05119701,  0.04118314,\n",
       "          0.04136016,  0.03475367, -0.02282776,  0.00199465,  0.01232226,\n",
       "         -0.04116474, -0.01505124, -0.03409441, -0.0043356 , -0.01286723,\n",
       "          0.04271644, -0.0353551 ,  0.03580519,  0.02443592, -0.03913986,\n",
       "         -0.04001765, -0.00452039, -0.00077095, -0.02878054, -0.038331  ,\n",
       "         -0.01299188,  0.02598026, -0.00819761,  0.0027362 , -0.00641035,\n",
       "          0.05589058, -0.0286341 , -0.00672144, -0.04482945,  0.03659866,\n",
       "          0.03704296, -0.01094106,  0.01626131, -0.01765052, -0.00942123,\n",
       "          0.02483274,  0.04103643,  0.06078215, -0.01870298,  0.03131958,\n",
       "         -0.02127958, -0.01060448,  0.02922126,  0.02098259, -0.02365599,\n",
       "          0.03389131,  0.00315057, -0.01117139,  0.04675522,  0.0181092 ,\n",
       "         -0.03077543,  0.00475512,  0.02212973, -0.05087734, -0.01985054,\n",
       "         -0.03785526,  0.03296011, -0.02520077,  0.01576518,  0.03471655,\n",
       "         -0.02884455, -0.02208069, -0.05161338, -0.0229327 , -0.03495167,\n",
       "         -0.02060092, -0.01301529, -0.0247739 ,  0.02486893,  0.01890799,\n",
       "         -0.04407879,  0.01531815,  0.02286182,  0.01827166,  0.04451953,\n",
       "         -0.05053611, -0.00449656,  0.00681901, -0.01995258,  0.00521187,\n",
       "          0.02144423, -0.05466814, -0.03288499,  0.05340133,  0.00343682,\n",
       "         -0.03890232,  0.01456269, -0.0013712 ,  0.04886998,  0.00300278,\n",
       "         -0.0051907 , -0.01563128,  0.02144965,  0.04016361,  0.01439759,\n",
       "          0.02491105,  0.05123496, -0.023203  ,  0.02480489, -0.0114514 ,\n",
       "         -0.04331328, -0.03516062, -0.0128629 , -0.03210551,  0.00445851,\n",
       "         -0.03710378, -0.05164866,  0.04502219, -0.03103874,  0.0561949 ,\n",
       "          0.02567424,  0.05486573, -0.02164858, -0.01045325,  0.03671507,\n",
       "         -0.05135409, -0.01543573,  0.03818625, -0.03504606,  0.02900644,\n",
       "         -0.01395876, -0.02609287,  0.00638763, -0.01882942, -0.01788297,\n",
       "          0.01136639,  0.05083853, -0.03291364, -0.05476223, -0.03905734,\n",
       "          0.00225633, -0.00778913,  0.00924207,  0.0004601 , -0.01732464,\n",
       "         -0.01962708, -0.05560974,  0.02620289, -0.02137572,  0.00247641,\n",
       "         -0.01392166,  0.03195836, -0.04394562,  0.0384089 ,  0.03274133,\n",
       "          0.05442048,  0.02035421,  0.01592291,  0.00709247,  0.04620568,\n",
       "          0.00799013,  0.04868167, -0.03117777, -0.01693126,  0.01733175,\n",
       "         -0.0146772 , -0.00600094,  0.03809469,  0.05041025,  0.02518446,\n",
       "         -0.01190199,  0.01455479, -0.03444183,  0.04116208,  0.05599152,\n",
       "          0.05813674, -0.0547256 , -0.0148079 ,  0.05832009, -0.02230222,\n",
       "          0.01103893, -0.04025274, -0.00066616,  0.02548889, -0.02543283,\n",
       "         -0.03079979, -0.02336766,  0.00229028,  0.03332577,  0.03651955,\n",
       "         -0.04940661,  0.00815315, -0.02853154,  0.01691528,  0.03146655,\n",
       "         -0.03037415,  0.00062811,  0.04335254, -0.0575433 , -0.02291151,\n",
       "         -0.03689341, -0.00340052, -0.04086572, -0.01340045,  0.02302639,\n",
       "          0.02174014,  0.0381704 , -0.02886643,  0.04901298,  0.03070868,\n",
       "          0.01817165,  0.01019475,  0.01758377,  0.03200759, -0.01667848,\n",
       "          0.02320195, -0.00670802,  0.02828332, -0.00959911, -0.01330077,\n",
       "          0.03412882,  0.034748  ,  0.05150581,  0.06078284, -0.02319426,\n",
       "         -0.03880596, -0.04346012, -0.01831905, -0.00910758,  0.04237106,\n",
       "         -0.00423867,  0.01503283,  0.01741535,  0.00070336, -0.00627249,\n",
       "          0.03689324, -0.05349903, -0.04010628,  0.01458906, -0.00432846,\n",
       "          0.01649505, -0.01256378,  0.01135485,  0.03508137, -0.0232687 ,\n",
       "          0.06080084,  0.01512245, -0.0593223 ,  0.0596926 ,  0.02989571,\n",
       "         -0.00258036, -0.0302818 ,  0.0229572 ,  0.05545326,  0.03988828,\n",
       "         -0.02710022, -0.0104535 ,  0.02731729,  0.01258828, -0.00670738,\n",
       "          0.03798164,  0.04197929,  0.04491314, -0.00494968,  0.02237778,\n",
       "          0.03887264,  0.02854694,  0.0006238 ,  0.04474925,  0.05145535,\n",
       "          0.0450225 , -0.02093095, -0.00330999,  0.05693189,  0.03921725,\n",
       "          0.05022028,  0.02306046,  0.04589052, -0.03163632, -0.0095826 ,\n",
       "         -0.00750506,  0.05277332, -0.00703657,  0.04882057,  0.05955512,\n",
       "         -0.03443732, -0.00947474,  0.00026231, -0.01454162,  0.02310297,\n",
       "         -0.02593781, -0.00123706,  0.02957961, -0.01425113,  0.03234484,\n",
       "         -0.02910432,  0.0037763 ,  0.00152603, -0.05311574,  0.05087186,\n",
       "          0.01067046, -0.00044152, -0.0463266 , -0.05590246,  0.00077462,\n",
       "          0.05420398,  0.05945967, -0.05073281, -0.01121128,  0.00552579,\n",
       "          0.00206064,  0.04379895,  0.05816231, -0.01847198, -0.02694899,\n",
       "         -0.03290104,  0.0313447 , -0.02687143, -0.00322206, -0.03440019,\n",
       "          0.00320573, -0.01208386, -0.03105811, -0.0404654 , -0.02867453,\n",
       "         -0.05835481, -0.05860154,  0.03968322, -0.04325517,  0.03199707,\n",
       "          0.03035275,  0.01627506, -0.03538572,  0.02468005, -0.01779383,\n",
       "         -0.03570311,  0.02597212, -0.04317203, -0.02131262,  0.00397614,\n",
       "          0.05526726,  0.06071038, -0.05604327,  0.0426174 , -0.05911671,\n",
       "          0.00121414, -0.02851225, -0.06010333, -0.0156321 ,  0.01367002,\n",
       "          0.03460234,  0.02555972,  0.02439851,  0.03196749,  0.01330321,\n",
       "          0.01662263, -0.01684241, -0.00466542, -0.01387089,  0.01902977,\n",
       "          0.03708876, -0.04137876,  0.03697712, -0.01382266, -0.06073865,\n",
       "         -0.02532352, -0.01045423, -0.01682303, -0.03176846, -0.05182874,\n",
       "          0.00524487,  0.00935374], dtype=float32)},\n",
       " {'topic_idx': 49,\n",
       "  'topic_words': array(['email', 'mail', 'spam', 'postaladdress', 'addresses',\n",
       "         'neuroscience', 'neurosciences', 'scientists', 'sender', 'address',\n",
       "         '전자', 'neuroscientific', 'scientist', 'scientific', 'science',\n",
       "         'neurosci', 'electronic', '과학', 'interest', 'none', 'sends', '과학자',\n",
       "         'neuroscientists', 'neuroscientist', 'sciences', 'neurobiol',\n",
       "         'neurons', '보내', 'neuron', 'spatial', 'ignore', 'neuronal',\n",
       "         'neurology', 'genome', 'isotropic', 'nobody', 'radiation', '메시지',\n",
       "         'neurocultures', 'paramagnetic', 'stimulus', 'psychotherapy',\n",
       "         'purposes', 'spatially', 'send', 'interests', 'nothing', 'sensory',\n",
       "         'letters', 'avoid'], dtype='<U15'),\n",
       "  'topic_vector': array([ 3.36785503e-02,  2.77602114e-04, -7.13065863e-02, -1.20600709e-03,\n",
       "          5.93860745e-02,  2.70675700e-02,  6.31367601e-03, -4.02062088e-02,\n",
       "          2.48029605e-02,  6.30551875e-02,  4.37931046e-02,  1.04377791e-02,\n",
       "          8.60693585e-03,  1.96985565e-02, -6.26107976e-02, -3.82587966e-03,\n",
       "          1.91244297e-02, -7.69882426e-02,  5.39914407e-02, -9.54826027e-02,\n",
       "          8.51467438e-03,  4.22487482e-02,  1.78514421e-02, -8.16023722e-03,\n",
       "         -5.59450313e-02,  6.24477640e-02, -2.16520578e-03, -1.98766682e-02,\n",
       "         -5.34850433e-02,  8.55240598e-03, -1.79363750e-02,  3.66483144e-02,\n",
       "         -5.52072823e-02, -2.87567899e-02, -3.79234329e-02, -2.30339635e-02,\n",
       "          5.23921773e-02,  2.89265644e-02, -3.06872763e-02,  1.91618986e-02,\n",
       "         -8.60355049e-03, -3.86832058e-02,  8.94507840e-02,  7.55478535e-03,\n",
       "         -2.88461596e-02, -2.45247390e-02, -5.75878732e-02, -1.77332442e-02,\n",
       "          5.06410450e-02,  3.52647565e-02, -7.97859356e-02, -3.72304618e-02,\n",
       "          3.06344479e-02,  5.96685372e-02, -2.17981264e-02, -7.56008625e-02,\n",
       "          7.54463375e-02, -3.76205184e-02, -5.69710955e-02,  5.77388592e-02,\n",
       "          2.78025046e-02,  5.39526977e-02, -3.07320338e-03, -6.07619472e-02,\n",
       "          5.99273145e-02,  7.68866092e-02,  1.43967941e-02, -3.32426578e-02,\n",
       "         -3.80776376e-02, -4.17338684e-02, -4.68323231e-02, -4.05166969e-02,\n",
       "          2.62060389e-02, -5.39234513e-03, -6.04452826e-02,  4.27143984e-02,\n",
       "          5.17388387e-03,  1.11846756e-02, -1.55165438e-02, -8.99476260e-02,\n",
       "         -9.48108733e-02, -7.00347722e-02, -6.34399243e-03, -2.71741264e-02,\n",
       "          1.12701384e-02, -3.69815566e-02,  5.32901671e-04, -2.55487673e-02,\n",
       "          4.05301787e-02,  2.58074645e-02,  8.86284113e-02,  1.20805707e-02,\n",
       "         -7.04052392e-03, -6.56003952e-02, -1.83205400e-02, -2.46036146e-03,\n",
       "          9.74778086e-05, -3.61859463e-02, -4.12639529e-02,  3.09368409e-03,\n",
       "          2.94169448e-02, -3.61779965e-02,  5.17026410e-02, -2.78373025e-02,\n",
       "          4.00324874e-02,  3.63065973e-02, -5.65806851e-02,  6.69533163e-02,\n",
       "         -2.04682201e-02,  3.56536433e-02, -5.04563749e-02, -7.20389709e-02,\n",
       "         -1.91468615e-02,  4.85341325e-02,  1.00718327e-02, -3.55832279e-02,\n",
       "         -2.72904634e-02,  3.30764684e-03, -5.79416379e-03,  3.38886678e-02,\n",
       "          9.23090652e-02,  2.69657485e-02,  5.67728281e-03,  5.36826029e-02,\n",
       "         -9.19257570e-03,  1.28774280e-02, -7.75637329e-02, -2.97041014e-02,\n",
       "          1.28988307e-02, -3.97063941e-02, -4.17356193e-02,  1.32069122e-02,\n",
       "          1.20127201e-02, -1.75472703e-02,  3.20503861e-02,  4.25869003e-02,\n",
       "         -3.63657922e-02, -5.07779345e-02, -2.33127587e-02,  4.00125720e-02,\n",
       "          2.85477899e-02,  7.77724059e-03,  2.35443134e-02, -4.96741086e-02,\n",
       "         -8.24326053e-02,  1.44553406e-03,  6.44634515e-02,  2.46501528e-04,\n",
       "          1.86287798e-02,  3.11141871e-02,  6.19131364e-02, -1.21332780e-02,\n",
       "         -1.73373520e-02, -9.77354124e-02, -4.89384048e-02, -4.77341302e-02,\n",
       "          1.33566093e-02, -3.43770757e-02,  1.93271730e-02, -2.88097318e-02,\n",
       "          2.37869471e-02, -4.53084633e-02, -5.36708459e-02, -1.07178893e-02,\n",
       "         -1.10837668e-02, -2.75514126e-02,  2.77288891e-02, -3.09475288e-02,\n",
       "          8.37141648e-03,  4.14188728e-02, -1.08477995e-02,  1.74515229e-02,\n",
       "          8.46337061e-03,  2.43835617e-02, -2.01903041e-02,  5.45634739e-02,\n",
       "         -1.09694907e-02,  5.47788199e-03, -6.93121925e-03,  3.83037142e-02,\n",
       "          4.63735834e-02, -2.48278398e-02, -1.27140842e-02, -9.57434066e-03,\n",
       "         -4.97006178e-02, -1.33112175e-02,  5.93842939e-02,  6.86068907e-02,\n",
       "          3.89647968e-02,  3.87194082e-02,  3.91327813e-02, -5.87233715e-02,\n",
       "         -8.07223259e-04, -3.60873900e-02, -5.08842357e-02, -6.50390759e-02,\n",
       "          8.21193606e-02, -4.40394841e-02,  3.61938849e-02,  9.20258015e-02,\n",
       "          1.27089713e-02, -2.65007839e-02,  2.58064214e-02, -6.97313398e-02,\n",
       "          2.36863755e-02, -6.14629919e-03,  1.70466863e-03,  4.11630757e-02,\n",
       "          2.89135519e-03,  7.19477236e-02, -4.93909009e-02,  1.82816964e-02,\n",
       "         -1.39338719e-02,  5.66087849e-02, -1.93710979e-02,  1.79571286e-02,\n",
       "          4.93141413e-02, -3.29355970e-02,  4.85571995e-02,  2.71870457e-02,\n",
       "          2.66984990e-03, -1.71416719e-02, -2.86611319e-02,  8.26800391e-02,\n",
       "          1.61180720e-02, -1.02333613e-02,  1.85056888e-02,  2.73856893e-02,\n",
       "          4.69190851e-02,  2.26170123e-02,  1.23381615e-05,  1.04597211e-03,\n",
       "         -1.34342872e-02,  5.20249568e-02,  4.17792946e-02,  6.99010938e-02,\n",
       "         -8.89738440e-04,  3.60479131e-02,  6.69489056e-02,  1.80036537e-02,\n",
       "         -2.51028128e-02,  1.87895559e-02, -1.04500009e-02,  4.19195630e-02,\n",
       "          4.49140444e-02,  3.69346850e-02,  4.29245904e-02,  1.07581969e-02,\n",
       "         -4.78404313e-02, -3.33788618e-02,  5.68903163e-02, -7.38422498e-02,\n",
       "          4.36451398e-02, -3.56204212e-02,  4.33507562e-02, -4.53359485e-02,\n",
       "          8.58855247e-03,  2.05628667e-02, -5.73224835e-02,  2.30753869e-02,\n",
       "         -8.71981867e-03,  3.64775956e-02,  3.59491706e-02, -7.49251097e-02,\n",
       "          3.76277268e-02, -3.41352867e-03, -5.09613976e-02,  1.47328358e-02,\n",
       "          3.26367617e-02,  4.55993041e-03,  8.75798315e-02,  4.21167351e-04,\n",
       "          3.89747545e-02,  3.37425992e-03,  4.51428592e-02,  4.44860309e-02,\n",
       "         -3.49539220e-02,  4.45579439e-02, -4.40431535e-02, -5.79423942e-02,\n",
       "         -1.07859010e-02, -3.07986960e-02, -3.08047980e-02,  1.08820908e-02,\n",
       "         -3.11854947e-02,  3.93056776e-03,  2.86345603e-04, -7.89324101e-03,\n",
       "         -2.76745390e-02, -7.04949498e-02,  5.66857010e-02,  3.78569141e-02,\n",
       "         -9.33286175e-03,  9.61204991e-02, -5.29425126e-03, -3.44672203e-02,\n",
       "         -5.89251295e-02, -2.29304302e-02, -1.35626178e-02, -1.26512861e-02,\n",
       "         -1.64002962e-02,  3.89227942e-02, -2.30994727e-03,  2.38454919e-02,\n",
       "          7.31603876e-02, -1.83232687e-02, -1.43620186e-04,  4.03558314e-02,\n",
       "          4.85741943e-02,  5.43994503e-03,  2.38014087e-02, -2.74609774e-02,\n",
       "          3.25287357e-02,  1.47195754e-03,  5.40048257e-02,  4.26114388e-02,\n",
       "         -6.96370527e-02, -2.10854709e-02, -3.18683730e-03, -2.04570927e-02,\n",
       "          3.74166295e-02, -3.51178870e-02,  3.55362110e-02, -1.87287219e-02,\n",
       "         -4.61312905e-02, -2.26457082e-02,  7.23079890e-02,  2.21123807e-02,\n",
       "          2.84707770e-02, -3.57194133e-02, -2.81878263e-02,  5.15532196e-02,\n",
       "          1.49881113e-02, -7.03880005e-03,  3.31628844e-02, -1.82648767e-02,\n",
       "          3.61754894e-02,  1.53617999e-02, -6.46994635e-02, -2.89246254e-02,\n",
       "          9.62859839e-02,  9.45493858e-03, -3.24833654e-02, -2.43148804e-02,\n",
       "          7.14388266e-02,  5.29059656e-02,  5.07597327e-02,  1.25122815e-02,\n",
       "         -4.39187102e-02, -8.24666768e-02, -5.60950898e-02, -4.55596335e-02,\n",
       "         -4.04527783e-03,  2.38770097e-02, -6.17577843e-02, -8.28600377e-02,\n",
       "          9.03986860e-03, -2.31457185e-02,  1.07792281e-02, -4.23234049e-03,\n",
       "          4.66834716e-02, -4.29074503e-02, -2.28786636e-02,  3.57664227e-02,\n",
       "         -5.40358797e-02,  4.08198908e-02,  4.33075987e-03, -1.98620539e-02,\n",
       "         -5.40446192e-02, -3.42699662e-02,  3.05540115e-02,  4.94076423e-02,\n",
       "         -3.43339182e-02,  4.79379818e-02, -6.60322011e-02,  3.59753817e-02,\n",
       "          1.68408416e-02, -1.59154516e-02,  9.34357289e-04, -1.57725625e-02,\n",
       "         -3.22570652e-02, -1.50991157e-02, -3.61097381e-02,  4.51751091e-02,\n",
       "         -6.84019849e-02,  6.02198020e-02,  4.72819582e-02, -1.99786946e-02,\n",
       "          1.21417847e-02,  4.44093496e-02,  2.88803242e-02,  3.58321592e-02,\n",
       "         -1.14776660e-03, -6.29852246e-03, -2.95285159e-03, -3.95555981e-02,\n",
       "          3.85390036e-02,  1.61360987e-02,  1.85082760e-02, -2.43636407e-02,\n",
       "          2.46738782e-04,  7.35689849e-02,  3.25594023e-02, -3.75253968e-02,\n",
       "         -6.56959508e-03,  3.18465382e-02, -2.54257713e-02, -3.93234193e-02,\n",
       "         -9.41270869e-03, -3.58011797e-02,  7.84512684e-02, -1.28926355e-02,\n",
       "          1.59657467e-02,  1.83709227e-02,  3.24556381e-02,  6.57667499e-03,\n",
       "         -2.82284580e-02,  1.06044114e-02,  1.12672606e-02,  3.20238620e-02,\n",
       "         -5.77314058e-03,  3.83976549e-02,  3.58735435e-02,  6.02406971e-02,\n",
       "          6.37287349e-02, -1.44988550e-02, -3.05686444e-02,  5.14383055e-02,\n",
       "          1.48060611e-02,  3.20253777e-03,  2.18010247e-02,  1.58109535e-02,\n",
       "         -1.01624290e-04,  4.33729067e-02,  6.65204078e-02,  2.30414351e-03,\n",
       "         -2.18131188e-02,  3.46833542e-02, -4.69665378e-02, -1.74735747e-02,\n",
       "         -3.22265662e-02,  6.23477772e-02,  8.05262625e-02, -4.37832624e-02,\n",
       "          4.01857197e-02,  1.90647226e-02,  9.06915367e-02,  6.21640775e-03,\n",
       "          2.46177968e-02,  2.86696944e-02,  3.30115343e-03, -4.97168154e-02,\n",
       "         -3.41735482e-02,  8.33924264e-02, -3.45548168e-02, -3.37456465e-02,\n",
       "         -1.48245767e-02, -1.92276444e-02, -2.83556599e-02, -3.64283100e-02,\n",
       "          1.33218765e-02, -6.48017675e-02, -2.52564512e-02,  4.06978130e-02,\n",
       "         -9.73111913e-02, -3.10635474e-02,  3.69692454e-03, -2.46619936e-02,\n",
       "          8.09517950e-02, -1.39750959e-02,  5.57530560e-02,  2.45739333e-02,\n",
       "         -7.75444806e-02,  4.42928076e-02, -9.46094561e-03,  6.54586628e-02,\n",
       "          1.88408531e-02,  5.00913188e-02,  1.75247639e-02,  9.13656875e-03,\n",
       "          4.11358252e-02, -2.21512862e-03, -2.49134302e-02, -5.88652566e-02,\n",
       "         -7.97110610e-03, -4.08065319e-02,  2.58992426e-02, -7.63501450e-02,\n",
       "          5.93704451e-03, -1.89822540e-03, -8.58544745e-03, -1.14905061e-02,\n",
       "          7.47619867e-02, -9.53953248e-03,  7.26797879e-02,  1.27580715e-02,\n",
       "         -3.33742052e-02, -1.80157297e-03,  1.75052173e-02,  7.08362386e-02,\n",
       "          4.68392596e-02, -7.31230900e-02,  2.64688265e-02,  1.73766743e-02,\n",
       "         -6.58391863e-02, -5.62119484e-03, -5.97945750e-02, -1.46017373e-02,\n",
       "         -3.23139019e-02,  2.83530783e-02, -1.25945788e-02,  8.01020265e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 50,\n",
       "  'topic_words': array(['neuroscientific', 'neurosciences', 'neuroscience', 'neuro',\n",
       "         'neurobiological', 'neuronal', 'neurosci', 'neurobiology',\n",
       "         'neurological', 'neurol', 'neuroimaging', 'neural',\n",
       "         'neuroscientists', 'neuroethics', 'neurogenesis', 'neurons',\n",
       "         'neuron', 'neuroscientist', 'neurosurg', 'neurology', 'neurobiol',\n",
       "         'neuroimage', 'adhd', 'selection', 'correlations', 'correlation',\n",
       "         'cognitive', 'sensory', 'attribute', 'selective', 'neurocultures',\n",
       "         'correlated', 'correlates', 'brainstem', 'correlate',\n",
       "         'impulsivity', 'selectively', 'cerebral', '신경망', 'cognitively',\n",
       "         'psychology', 'somatosensory', 'brains', 'categories', 'selecting',\n",
       "         'distributed', 'stimuli', 'developmental', '신경', 'forebrain'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-0.0539675 ,  0.03121009, -0.01835198,  0.04023115, -0.03563082,\n",
       "          0.05085425, -0.03099629, -0.00614853,  0.01110249,  0.04866922,\n",
       "         -0.00402696, -0.02352988,  0.04073556,  0.00732324, -0.03837343,\n",
       "          0.03045927,  0.01335397, -0.01706034,  0.03191631,  0.05292801,\n",
       "          0.00229929, -0.04056546, -0.05096085,  0.03930397, -0.05538161,\n",
       "         -0.02782355,  0.00475251,  0.04281034,  0.00383091,  0.0085747 ,\n",
       "         -0.02512342,  0.04375387,  0.04972668, -0.05473636, -0.01427605,\n",
       "         -0.03764969, -0.02484522,  0.02726198, -0.01684173, -0.04281423,\n",
       "         -0.05089873,  0.03076464,  0.05407468, -0.01427024, -0.04185828,\n",
       "          0.00847318,  0.05479375,  0.02404543,  0.00532659, -0.02436335,\n",
       "          0.04387474,  0.02318158,  0.03236981, -0.04060211,  0.02842492,\n",
       "         -0.02769742,  0.02913812,  0.03205032,  0.00607889,  0.04705858,\n",
       "         -0.02576648,  0.05223841, -0.05152154, -0.04728813, -0.00352423,\n",
       "         -0.02037517,  0.04835375, -0.00561606, -0.03731143, -0.04795058,\n",
       "         -0.02482555,  0.00494816,  0.01912251, -0.04330147, -0.04036946,\n",
       "         -0.03061857,  0.03051859, -0.00562335, -0.03754207, -0.05398972,\n",
       "         -0.05522861, -0.03833837,  0.01723054,  0.00708233, -0.05257813,\n",
       "         -0.03686877, -0.00504249,  0.01087683, -0.01212588, -0.03016677,\n",
       "         -0.04610959, -0.03138012, -0.00497348, -0.05387159, -0.00622675,\n",
       "          0.05411983,  0.05261955,  0.04539236,  0.04521926,  0.00507337,\n",
       "          0.04915315, -0.04162136,  0.03639149,  0.02216062,  0.05132684,\n",
       "          0.02613639, -0.05471981, -0.03148573,  0.01687516,  0.05184259,\n",
       "          0.03475961, -0.05538589, -0.04780082,  0.03290419,  0.04570312,\n",
       "         -0.03623016,  0.04310945,  0.03261524, -0.01191251, -0.01572597,\n",
       "         -0.01288393,  0.04184222,  0.03791346, -0.01751487,  0.01168431,\n",
       "          0.02094172,  0.0544881 ,  0.00796597, -0.05279387,  0.03965183,\n",
       "         -0.04664919,  0.00646632,  0.02005554,  0.04166254, -0.02149324,\n",
       "          0.05350129, -0.05390605, -0.04658607,  0.05246851,  0.02455285,\n",
       "          0.05501512, -0.01057925,  0.0214371 , -0.00518725,  0.03470434,\n",
       "          0.03912142, -0.04369434,  0.05253456,  0.03543032,  0.05524913,\n",
       "          0.05220598,  0.0119642 ,  0.02498941, -0.05392412, -0.01251936,\n",
       "         -0.01882516, -0.01334337,  0.01731288,  0.01406113, -0.0218938 ,\n",
       "          0.02445448, -0.02821814, -0.05123789, -0.05389792,  0.00682567,\n",
       "         -0.03416973,  0.03224529, -0.02045481, -0.05272338,  0.05121428,\n",
       "         -0.01824458, -0.02232782,  0.01898328, -0.00514917, -0.03179913,\n",
       "          0.00906609,  0.02191205,  0.03760902, -0.02234389,  0.029918  ,\n",
       "          0.00899812, -0.01815614, -0.00204902, -0.02308205, -0.04946689,\n",
       "         -0.01477104,  0.02189742,  0.05159535,  0.03954861,  0.04319728,\n",
       "         -0.03370021, -0.0086349 ,  0.00022824, -0.01118855, -0.05233929,\n",
       "         -0.04634092, -0.05209305,  0.04824805,  0.05487323,  0.02938123,\n",
       "         -0.03348436,  0.01840036, -0.03101108, -0.03457557,  0.02810237,\n",
       "         -0.05475092, -0.05449026,  0.01043711,  0.02744514,  0.04772552,\n",
       "          0.02823661, -0.02034668, -0.0008242 ,  0.00066266,  0.05171042,\n",
       "         -0.00199399,  0.01686857, -0.04340865,  0.04263854, -0.03009319,\n",
       "          0.0136831 ,  0.0214166 ,  0.05499501, -0.01034578, -0.05417589,\n",
       "         -0.0176488 , -0.05536864,  0.03514579, -0.00907775, -0.01522269,\n",
       "         -0.03289845,  0.05410849, -0.05023174,  0.02681391,  0.04326538,\n",
       "         -0.04119373, -0.02903784,  0.05424106,  0.05338698, -0.0154371 ,\n",
       "          0.01011971,  0.0263042 , -0.01733117,  0.01016861,  0.03667246,\n",
       "         -0.00649265,  0.0452567 , -0.03490075,  0.00621839,  0.01799548,\n",
       "          0.02041577, -0.02875713,  0.0360318 , -0.02581306, -0.0091981 ,\n",
       "         -0.02758347,  0.0380478 ,  0.04363253, -0.03888414, -0.00812039,\n",
       "         -0.00066511,  0.04874912, -0.02163946,  0.00626246,  0.03612111,\n",
       "         -0.05491338, -0.01550428,  0.01722002,  0.01726647,  0.02582254,\n",
       "          0.04434755,  0.02648091, -0.01244521, -0.05260363,  0.01743635,\n",
       "          0.00678031, -0.04826298,  0.02793561, -0.05453186, -0.00743345,\n",
       "         -0.01654006, -0.02076825,  0.02022514,  0.04267919, -0.05028305,\n",
       "          0.04882519, -0.05075421, -0.04295867, -0.00551985,  0.04791123,\n",
       "          0.04964712,  0.00799114,  0.02089873, -0.04386292, -0.03468776,\n",
       "         -0.04083981,  0.01048634,  0.00796617,  0.02546813,  0.04625283,\n",
       "         -0.04924047,  0.03318506, -0.00531912, -0.02473927, -0.04359203,\n",
       "         -0.05083286, -0.03374498,  0.05034692,  0.00464863,  0.02674589,\n",
       "         -0.03863917, -0.02406995, -0.03002315, -0.04094323,  0.05025399,\n",
       "          0.04050315, -0.0110839 , -0.01123115,  0.03049782, -0.05425121,\n",
       "          0.0428249 , -0.0553815 , -0.02414482,  0.03546634, -0.0521128 ,\n",
       "         -0.03947791, -0.04161318,  0.0180994 ,  0.05059947,  0.02185549,\n",
       "         -0.04639303, -0.05343257, -0.04801024, -0.02299419, -0.02285984,\n",
       "          0.00039873, -0.0494812 , -0.05333142, -0.05347291,  0.01820753,\n",
       "         -0.0272244 , -0.00061101, -0.00119068, -0.05246412,  0.01901865,\n",
       "          0.05044276,  0.0551497 , -0.03691417, -0.04485818,  0.00776194,\n",
       "          0.03293858,  0.04771576, -0.0229854 ,  0.04484109,  0.0390128 ,\n",
       "          0.03006818,  0.03834148,  0.00989698, -0.03605438, -0.03440689,\n",
       "          0.02764582, -0.00365774,  0.03295175, -0.01274004, -0.0450257 ,\n",
       "         -0.00364719, -0.04150537,  0.0422218 , -0.05376645,  0.02425124,\n",
       "          0.03209051,  0.03167606, -0.02097165,  0.01693219,  0.01825321,\n",
       "         -0.05397827, -0.0351789 ,  0.02363347, -0.04028703, -0.04493492,\n",
       "          0.05503264, -0.02262644,  0.04060832,  0.01357568, -0.04567537,\n",
       "          0.05531615,  0.03742268, -0.05013891,  0.05507402, -0.04985467,\n",
       "          0.03637025, -0.00867175,  0.01840287,  0.03342583, -0.05203492,\n",
       "          0.0316734 ,  0.0548951 , -0.03767648, -0.02379214,  0.02004475,\n",
       "          0.0263921 ,  0.04211927,  0.03986417,  0.05476153, -0.03423894,\n",
       "          0.00244356,  0.02344554, -0.04898234,  0.03717735, -0.00467127,\n",
       "          0.02788836, -0.01064944, -0.01187205,  0.02791456, -0.02934851,\n",
       "          0.0550255 ,  0.00492635, -0.05457404,  0.04817292,  0.01439864,\n",
       "         -0.03431599, -0.05412526,  0.03602181,  0.05066611,  0.05248553,\n",
       "         -0.00742208, -0.05464122, -0.03891164, -0.04669148,  0.03415456,\n",
       "         -0.0544715 , -0.02897124, -0.02684125, -0.04390538,  0.02760785,\n",
       "          0.01593064,  0.01180836, -0.04340999, -0.0553799 ,  0.01300469,\n",
       "          0.02221545, -0.02222884,  0.05194158, -0.04016479,  0.04946111,\n",
       "         -0.02009306, -0.02791595,  0.04645114,  0.0020711 ,  0.0034791 ,\n",
       "         -0.05316436, -0.0320478 ,  0.01435922, -0.00884546, -0.03388259,\n",
       "          0.00021795,  0.04623491,  0.02195315, -0.00169562,  0.01237268,\n",
       "         -0.01648521, -0.05410421, -0.05010584, -0.05323941,  0.04636968,\n",
       "         -0.05498125, -0.01699074, -0.04014864,  0.05460773, -0.03331187,\n",
       "         -0.00593423,  0.05014031, -0.03006034,  0.0008696 , -0.0037046 ,\n",
       "         -0.02127565, -0.00248675,  0.01600346, -0.03543742,  0.02327211,\n",
       "          0.02664821,  0.05539397, -0.05013718, -0.02818422,  0.02569178,\n",
       "         -0.04959489, -0.02036689, -0.04383238, -0.03790935, -0.00681263,\n",
       "          0.03029811,  0.0279844 , -0.01496817,  0.02708664, -0.03006248,\n",
       "         -0.03015045, -0.01700693, -0.00081669,  0.02936388,  0.00023663,\n",
       "          0.00701912, -0.05257169,  0.05528888,  0.00734923, -0.0518449 ,\n",
       "         -0.05183244,  0.02414383, -0.04433429, -0.05241093, -0.0511481 ,\n",
       "         -0.03745433, -0.00333025], dtype=float32)},\n",
       " {'topic_idx': 51,\n",
       "  'topic_words': array(['마태오', '복원', '문화재', '미술관', '천사', 'culture', 'artifacts', '마미코',\n",
       "         'mahjong', 'cultural', 'destruction', '신종', 'art', 'amyotrophic',\n",
       "         '카카오', '회복', 'glutamatergic', '영수증', '전통', 'validity', '증명서',\n",
       "         'techniques', '기존', 'recovery', 'monkey', 'original',\n",
       "         'neurocultures', 'japanese', '원래', '치료', '손상', 'initiation', '조치',\n",
       "         'conventional', '마늘', 'priming', '증명', 'mask', 'treatment', '반복',\n",
       "         'recovered', 'essentialist', 'valid', 'prophet', 'technique',\n",
       "         'degeneration', 'practices', 'reuptake', 'recursive',\n",
       "         'decomposition'], dtype='<U15'),\n",
       "  'topic_vector': array([ 0.05465956,  0.03539738,  0.05202358,  0.02029871, -0.0421163 ,\n",
       "          0.05243789, -0.04753854, -0.02350167,  0.05489637,  0.01774096,\n",
       "          0.02922762,  0.00262832,  0.01394487,  0.04309291, -0.03027746,\n",
       "          0.0013887 , -0.004608  , -0.04433095, -0.01094582,  0.05402038,\n",
       "         -0.0097676 , -0.05520149,  0.05455332, -0.02312494, -0.05528963,\n",
       "         -0.00410045,  0.00505595,  0.0322777 ,  0.04953517, -0.0547787 ,\n",
       "          0.00278671,  0.01267996,  0.01563158, -0.00082916, -0.03519709,\n",
       "         -0.00237603, -0.00393752, -0.04082311, -0.0134668 , -0.03604102,\n",
       "          0.02298606,  0.05359575, -0.00581229, -0.02187064, -0.02021924,\n",
       "          0.01851109, -0.05392746, -0.05264103,  0.05215569,  0.04568135,\n",
       "         -0.02725386, -0.05339143, -0.00235992, -0.02031207,  0.04967319,\n",
       "         -0.05528456,  0.02514669, -0.04372925, -0.05276266,  0.02859831,\n",
       "         -0.00988299,  0.0551891 , -0.03398597, -0.04612808,  0.04807576,\n",
       "          0.05083211,  0.03809488, -0.04701392, -0.04411856, -0.03732745,\n",
       "          0.04767659,  0.05408651,  0.02663116, -0.00473312,  0.02258933,\n",
       "         -0.01066114, -0.01902809,  0.02192978, -0.04323595, -0.05528416,\n",
       "         -0.0552901 , -0.04054744,  0.05447954,  0.04981272, -0.01944211,\n",
       "         -0.05427716, -0.05528693,  0.00660813,  0.00330675,  0.02226139,\n",
       "         -0.03125744, -0.01757525, -0.02224134,  0.00438895,  0.02088843,\n",
       "         -0.00071161,  0.05527681,  0.05502927, -0.00574589,  0.05415364,\n",
       "         -0.0218867 ,  0.05456381, -0.0538001 ,  0.02489488,  0.00025051,\n",
       "         -0.00845181,  0.01564214, -0.0375969 ,  0.01776534, -0.03484426,\n",
       "          0.03926978,  0.00847277,  0.05472076, -0.01294907, -0.02428543,\n",
       "          0.02530462, -0.00977472, -0.00915249,  0.0116666 , -0.03556624,\n",
       "         -0.00668828,  0.04383167,  0.04046533,  0.04845018,  0.01024605,\n",
       "          0.01247998,  0.04106681,  0.02885406,  0.00543992,  0.05333886,\n",
       "         -0.02599257, -0.04280934, -0.01636998, -0.02559368,  0.00855775,\n",
       "          0.05528977,  0.02016394,  0.05025015,  0.04778738,  0.03660709,\n",
       "          0.05374685,  0.00940995, -0.02844306,  0.01002951,  0.03693366,\n",
       "         -0.04017347,  0.05509895, -0.03112725,  0.02557879, -0.0526077 ,\n",
       "          0.05381602,  0.01684226, -0.03545307,  0.0022215 ,  0.01975575,\n",
       "         -0.02623567, -0.01390097, -0.03362143, -0.00110333,  0.04841273,\n",
       "         -0.01565873, -0.05527448,  0.00168426,  0.03901849,  0.03299694,\n",
       "         -0.05384576,  0.05353898, -0.03491956, -0.02229976, -0.04499901,\n",
       "         -0.02388253,  0.05001649, -0.05522631,  0.01115504, -0.01538788,\n",
       "          0.02399543,  0.04964591,  0.02181525,  0.01491238,  0.05526039,\n",
       "          0.03525111, -0.05348848,  0.01423119,  0.01337485, -0.05344698,\n",
       "          0.02879751,  0.02115059,  0.05231485, -0.04432039,  0.04025624,\n",
       "         -0.00425565, -0.00319007,  0.0215082 ,  0.0110931 , -0.02939035,\n",
       "          0.03988532,  0.04039566,  0.01893672, -0.01189829, -0.03320822,\n",
       "         -0.03803594,  0.01757517, -0.00599279, -0.04645477,  0.02331065,\n",
       "          0.01168001, -0.02420706,  0.04989068,  0.00703841, -0.01056898,\n",
       "         -0.00463188,  0.01589775, -0.04306446,  0.04846636,  0.04849531,\n",
       "         -0.02792069,  0.03000175,  0.03171953, -0.01626087,  0.04143004,\n",
       "          0.00132982, -0.02923248,  0.01809216, -0.01533349,  0.01790345,\n",
       "         -0.02356532, -0.0475865 , -0.05424979, -0.0476866 , -0.00357038,\n",
       "         -0.00414026, -0.0485121 , -0.00163096,  0.031442  ,  0.02350306,\n",
       "          0.04678289, -0.04874987,  0.02630389,  0.0473094 , -0.02008547,\n",
       "          0.01702243, -0.0414065 ,  0.04764903, -0.00910984,  0.01781641,\n",
       "         -0.04529844,  0.05492492,  0.00652959,  0.00816885, -0.02770831,\n",
       "         -0.02714321, -0.04215517,  0.05119957,  0.0320098 , -0.01815361,\n",
       "         -0.0005049 , -0.03777361,  0.03382177,  0.02521474,  0.05523471,\n",
       "          0.02317254,  0.05522765, -0.01865458,  0.02776994,  0.01232469,\n",
       "         -0.03844263, -0.02321875,  0.04890047,  0.00266775, -0.05290375,\n",
       "          0.01939817, -0.02880442, -0.01823969, -0.05432058,  0.04996802,\n",
       "          0.03875269,  0.05038689, -0.02359496, -0.05500762, -0.04385924,\n",
       "         -0.05105012, -0.00208324, -0.00956644,  0.03086283,  0.02852168,\n",
       "          0.00069432, -0.05381756,  0.01212273, -0.04948651,  0.01942655,\n",
       "         -0.05468254, -0.05208139, -0.01485993,  0.05481349,  0.05290414,\n",
       "          0.05522373, -0.00162349, -0.03094603, -0.02620845,  0.01996089,\n",
       "          0.03894831, -0.02273506,  0.01664271, -0.05307923,  0.03680484,\n",
       "         -0.02751279,  0.00326599,  0.04594188,  0.0107655 , -0.01047473,\n",
       "          0.01456745, -0.0530782 ,  0.00231867,  0.03215637,  0.04854643,\n",
       "          0.04991311,  0.00946346, -0.04109934,  0.00042416,  0.00821968,\n",
       "          0.00539019, -0.01251237,  0.01125524, -0.0406272 , -0.05526129,\n",
       "          0.0103718 ,  0.00395947,  0.01886151,  0.00917778,  0.03358549,\n",
       "         -0.02522333,  0.01976003, -0.02190163, -0.05467291,  0.04474915,\n",
       "         -0.0483862 , -0.00975834,  0.03776635, -0.04423901, -0.03123707,\n",
       "         -0.04737617,  0.05341934, -0.051191  , -0.01614041, -0.05286638,\n",
       "         -0.01736308,  0.05461271, -0.00742073,  0.04047555,  0.03728613,\n",
       "          0.00663335,  0.04546571, -0.01715728, -0.024955  ,  0.0391556 ,\n",
       "          0.01461729,  0.0306611 ,  0.01579046,  0.00479921, -0.0440446 ,\n",
       "          0.01169202,  0.01427003,  0.03790804,  0.03741172,  0.01460915,\n",
       "         -0.01636072, -0.05194065, -0.00620499,  0.02659123,  0.05062246,\n",
       "         -0.0167008 ,  0.02041065,  0.00567516, -0.0290541 , -0.00772494,\n",
       "          0.04679175, -0.01452461, -0.00481558,  0.04976403, -0.01736423,\n",
       "          0.0290991 , -0.01561696,  0.00907638,  0.05525367,  0.00102466,\n",
       "          0.05522743,  0.02255259, -0.05403209,  0.05383666,  0.05420005,\n",
       "         -0.03463454,  0.01100318,  0.00140189,  0.01080653,  0.04848657,\n",
       "         -0.05093182, -0.02521007, -0.03453344,  0.04630145, -0.03255395,\n",
       "         -0.0296709 ,  0.03118439, -0.05324987, -0.02965992, -0.00208492,\n",
       "          0.04543467, -0.04983759,  0.01094109, -0.01978798, -0.0140048 ,\n",
       "          0.05238003, -0.02618326, -0.00319106,  0.05386617,  0.01102253,\n",
       "          0.05456285,  0.04142413,  0.02215888, -0.01186139, -0.05473949,\n",
       "          0.05115409,  0.04175073, -0.05406559,  0.00206137,  0.05438614,\n",
       "          0.01849576,  0.05255054, -0.01497456, -0.05331461, -0.05280596,\n",
       "          0.05377923,  0.01383772,  0.0346887 , -0.02863027,  0.05503489,\n",
       "         -0.0455045 ,  0.04907276,  0.03712261, -0.05528675,  0.01083715,\n",
       "         -0.03611904,  0.05445966, -0.03909306, -0.05241867, -0.00824374,\n",
       "         -0.0146776 ,  0.05508679,  0.05263231,  0.02463337,  0.00772603,\n",
       "          0.01324451,  0.05216745,  0.04576887, -0.01841364, -0.0552639 ,\n",
       "         -0.00187255,  0.02656648, -0.0184533 ,  0.00577527,  0.05236389,\n",
       "         -0.00790882,  0.017405  , -0.03330791,  0.04587801,  0.03649396,\n",
       "         -0.05522323,  0.02050925,  0.04042976, -0.05278774,  0.00230098,\n",
       "         -0.01954195, -0.04898762, -0.02400756, -0.02283674, -0.02509363,\n",
       "         -0.0512224 ,  0.05485085, -0.02385282,  0.03361909, -0.04308661,\n",
       "          0.04951132,  0.05529051, -0.04770251,  0.03088586, -0.02002801,\n",
       "         -0.02885697, -0.01252315, -0.05528118, -0.05058334,  0.00345943,\n",
       "          0.05419586,  0.05156958,  0.0445583 , -0.01611906, -0.00105085,\n",
       "         -0.01908796,  0.01159978, -0.00464636,  0.00917879,  0.02158693,\n",
       "          0.03506708,  0.05175777,  0.05022831,  0.02769896, -0.05521752,\n",
       "          0.01962124, -0.01095968,  0.01878036,  0.00067394, -0.05119947,\n",
       "         -0.03483405,  0.01004141], dtype=float32)},\n",
       " {'topic_idx': 52,\n",
       "  'topic_words': array(['depression', 'adhd', 'statistically', 'statistical', 'depressive',\n",
       "         'diagnosed', 'diagnoses', 'statistics', 'syndromes',\n",
       "         'schizophrenia', 'syndrome', 'symptom', 'asymptotic', 'depressed',\n",
       "         'clinically', 'ptsd', 'correlation', 'diagnosis', 'psychological',\n",
       "         'alzheimers', 'statistic', 'demographic', '우울증', 'clinical',\n",
       "         'stats', 'stat', 'disorders', '진단', 'correlations', 'dementia',\n",
       "         'distinctiveness', 'prevalence', 'symptoms', 'disorder',\n",
       "         'alzheimer', 'dissociation', 'percentile', 'discriminant',\n",
       "         'epilepsy', 'coefficient', 'percentage', '통계청', 'correlated',\n",
       "         'mental', 'diagnostic', 'psychiatric', 'psychiatry',\n",
       "         'coefficients', 'variability', 'psychology'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.35629801e-02, -3.01780906e-02,  3.74647863e-02, -3.50277498e-02,\n",
       "          4.86368919e-03,  3.09946127e-02, -4.57902737e-02,  2.93187685e-02,\n",
       "         -4.86939065e-02, -1.11453491e-03,  2.06218697e-02, -2.92402357e-02,\n",
       "          3.42793539e-02, -5.07055931e-02, -1.01145599e-02,  2.70314701e-02,\n",
       "         -4.91290204e-02,  2.52167648e-03,  4.88122143e-02,  3.09261978e-02,\n",
       "          1.79886557e-02, -3.67693119e-02, -4.84472923e-02,  5.23277149e-02,\n",
       "         -5.37600294e-02,  1.58869736e-02, -1.42441364e-02,  7.00287492e-05,\n",
       "         -1.29929129e-02,  4.20501567e-02, -5.28288074e-02,  3.43767740e-03,\n",
       "         -6.84300065e-03, -5.19816279e-02,  4.71939072e-02, -5.06272726e-02,\n",
       "         -3.59585648e-03,  4.06224243e-02, -2.62045045e-03, -5.11929393e-02,\n",
       "         -6.01914385e-03, -1.76408924e-02,  5.39391860e-02, -3.26593891e-02,\n",
       "         -2.96000596e-02,  5.19367820e-03,  5.39466627e-02,  4.14863899e-02,\n",
       "         -2.60953419e-02, -5.23841754e-02,  4.49295379e-02,  4.04434502e-02,\n",
       "          5.08193485e-02, -3.61971669e-02,  4.17555533e-02, -9.25197732e-03,\n",
       "          2.86071710e-02,  2.41245478e-02, -3.74306515e-02,  4.93998826e-02,\n",
       "         -3.05690207e-02,  4.96294945e-02,  1.18177468e-02,  1.19005619e-02,\n",
       "         -5.37834540e-02,  2.90468000e-02,  2.80593522e-02,  1.93359666e-02,\n",
       "          1.07181808e-02, -3.86170410e-02,  2.75596287e-02, -1.38304504e-02,\n",
       "         -3.30961607e-02, -4.89459559e-02,  1.51743200e-02, -5.39435912e-03,\n",
       "          5.28220534e-02,  2.76749581e-02, -4.62154374e-02, -5.25921881e-02,\n",
       "         -5.38479276e-02, -4.29660678e-02,  4.66013141e-03,  4.50068042e-02,\n",
       "         -4.74610999e-02,  2.77859922e-02, -4.49739583e-02, -3.38898525e-02,\n",
       "         -4.81750518e-02, -4.97300737e-02, -1.79315172e-02, -5.32784350e-02,\n",
       "         -1.31115522e-02, -3.64481397e-02,  1.11170150e-02,  5.35323247e-02,\n",
       "          5.26663847e-02,  5.36666736e-02, -1.82561739e-03,  4.68075201e-02,\n",
       "         -3.01100127e-03, -2.39576809e-02,  2.17703730e-03,  1.28282532e-02,\n",
       "         -3.07363570e-02,  5.40205948e-02, -4.92839888e-02,  1.58577021e-02,\n",
       "         -3.06681059e-02,  5.19598126e-02,  2.99674571e-02, -4.84419763e-02,\n",
       "         -4.66559343e-02,  2.23996062e-02,  3.01474128e-02, -4.88917902e-02,\n",
       "         -5.48530137e-03,  2.04811804e-02, -2.28988342e-02, -7.11201224e-03,\n",
       "         -4.17366326e-02,  4.46039066e-02,  1.83673743e-02,  4.22589183e-02,\n",
       "         -2.44938694e-02,  5.14284596e-02,  5.40201254e-02,  2.86351182e-02,\n",
       "         -4.72980142e-02,  5.36477566e-02, -4.60327379e-02, -3.99797782e-02,\n",
       "          4.88067754e-02,  2.92678270e-02,  3.11645512e-02,  5.38053587e-02,\n",
       "         -3.08503713e-02, -3.38019095e-02,  5.34376875e-02,  2.50551607e-02,\n",
       "          4.57522310e-02, -2.64187548e-02,  3.16759534e-02, -2.83886082e-02,\n",
       "          3.36908698e-02,  4.69800122e-02, -4.27783243e-02,  4.52248454e-02,\n",
       "          3.83443013e-02,  3.73631492e-02,  4.60752361e-02, -1.01481285e-02,\n",
       "         -4.03292365e-02,  4.02713269e-02, -4.98751514e-02,  2.42565206e-04,\n",
       "          3.34905274e-02, -1.35225113e-02,  2.13328656e-02, -3.11674364e-02,\n",
       "          3.08396220e-02, -5.27341552e-02, -4.82770838e-02,  4.29968257e-03,\n",
       "         -2.82277120e-03, -2.47872286e-02,  3.20365839e-02,  7.52654299e-03,\n",
       "         -3.27903107e-02,  3.94665003e-02, -4.44049016e-02, -5.16921878e-02,\n",
       "         -7.92569481e-03,  1.26093980e-02, -3.07609793e-02,  5.23897894e-02,\n",
       "          3.24249864e-02, -2.89718295e-03, -8.35973583e-03,  1.40601397e-02,\n",
       "          1.68835167e-02, -4.38037142e-02, -1.41056851e-02,  2.55409144e-02,\n",
       "         -1.32983159e-02, -3.51105146e-02,  3.04320753e-02,  5.26170060e-02,\n",
       "          5.35287745e-02,  2.60606296e-02, -1.86076649e-02,  1.68069615e-03,\n",
       "          3.49509791e-02, -3.14856544e-02, -5.19508421e-02, -2.39085518e-02,\n",
       "         -1.77894440e-02,  3.28022018e-02,  4.94952314e-02, -2.28522532e-02,\n",
       "         -2.16019750e-02,  4.08664439e-03,  2.97421776e-02, -5.54819545e-03,\n",
       "         -2.04293542e-02, -5.36597371e-02, -5.35444021e-02,  4.87195961e-02,\n",
       "          1.20013291e-02,  5.22201061e-02,  2.05428265e-02, -3.77129056e-02,\n",
       "          2.81148795e-02,  4.31912057e-02,  3.88060845e-02,  2.93678455e-02,\n",
       "          4.31773253e-02, -4.77519594e-02, -2.53625698e-02, -2.86088083e-02,\n",
       "          4.67803143e-03,  4.98501249e-02,  5.38909249e-02,  2.63799969e-02,\n",
       "         -5.06034978e-02, -4.14743237e-02, -5.33125810e-02,  3.09319291e-02,\n",
       "         -2.30146982e-02, -4.50036749e-02, -1.00155454e-02,  2.98252944e-02,\n",
       "         -1.18425759e-02,  4.99351807e-02,  1.18993828e-02, -3.83108072e-02,\n",
       "          7.49102980e-03, -2.08486617e-03,  5.34757078e-02,  3.73911336e-02,\n",
       "         -3.95131037e-02,  1.04687447e-02, -2.36788485e-02,  4.36905995e-02,\n",
       "          5.19417413e-02, -3.60747352e-02,  4.35306057e-02,  1.99750029e-02,\n",
       "          4.89136167e-02,  4.34909128e-02, -4.84557897e-02, -4.66496050e-02,\n",
       "         -3.86364423e-02, -3.76324505e-02,  1.72235188e-03, -3.51026729e-02,\n",
       "         -3.55770849e-02, -1.41058210e-02,  1.01651195e-02,  3.79792973e-02,\n",
       "         -7.75027415e-03,  4.67199311e-02, -5.37996888e-02,  4.66269627e-02,\n",
       "          4.90002967e-02, -5.36796153e-02, -4.69641909e-02,  3.77747752e-02,\n",
       "          1.14873121e-03,  2.01973505e-02,  1.59650669e-02,  2.38484479e-02,\n",
       "         -1.02037508e-02, -5.13959527e-02,  5.01218252e-02,  4.88449931e-02,\n",
       "         -4.96290997e-02,  2.87518259e-02, -5.34191020e-02, -1.18975695e-02,\n",
       "         -5.25620058e-02,  3.98331210e-02,  5.34991845e-02,  5.13743088e-02,\n",
       "         -3.75244394e-02, -8.38312041e-03, -4.98353131e-02, -2.18626074e-02,\n",
       "         -4.20852080e-02,  4.07214202e-02,  5.34218177e-02,  3.29436883e-02,\n",
       "          1.77047588e-02, -5.72684780e-03, -4.07644324e-02, -4.30399403e-02,\n",
       "          4.65910919e-02,  4.07198146e-02,  3.66018303e-02,  5.04292250e-02,\n",
       "         -5.31464927e-02,  4.48453613e-02, -4.63821068e-02,  7.32602552e-03,\n",
       "         -5.34723289e-02, -7.25837518e-03,  2.39152312e-02,  1.18072508e-02,\n",
       "         -1.04492577e-02,  4.31474075e-02, -5.35977259e-02, -5.04530296e-02,\n",
       "          1.99783687e-02, -1.15962671e-02,  4.89507541e-02,  5.07097133e-02,\n",
       "          3.99359688e-02, -2.96980999e-02, -4.92511131e-03, -5.37153594e-02,\n",
       "         -3.84047627e-02, -5.40205836e-02, -4.28125225e-02,  4.41217646e-02,\n",
       "         -1.42702311e-02, -8.83106422e-03, -5.25192507e-02, -2.27235686e-02,\n",
       "         -4.18746695e-02,  8.24575219e-03,  2.48134439e-03, -5.11194356e-02,\n",
       "         -5.34914620e-02, -2.74712201e-02,  3.23383440e-03,  3.65843251e-02,\n",
       "         -5.24038598e-02, -2.54257675e-02, -3.48936878e-02, -6.19634008e-03,\n",
       "         -5.16012497e-02, -3.85255888e-02,  3.16051915e-02, -5.02054580e-02,\n",
       "         -2.95654181e-02,  5.23008592e-02,  5.39800599e-02, -2.62093209e-02,\n",
       "         -4.95899320e-02,  5.24536557e-02,  3.53245363e-02,  2.67110206e-02,\n",
       "          1.10580865e-02,  3.55207697e-02,  5.29483855e-02,  7.86363706e-03,\n",
       "         -5.70950005e-03,  4.88738418e-02, -4.20316607e-02, -4.57384177e-02,\n",
       "          2.29435563e-02, -4.95607182e-02,  5.31359203e-02,  3.57768610e-02,\n",
       "         -2.88755186e-02,  5.25005944e-02, -8.47965200e-03,  7.04249600e-03,\n",
       "         -4.44595292e-02,  1.08599486e-02,  3.86029594e-02,  4.35391739e-02,\n",
       "          4.42674682e-02,  4.72652093e-02, -9.80279408e-03, -3.36171985e-02,\n",
       "          3.63154300e-02, -2.45032385e-02,  4.06658128e-02, -5.21859713e-02,\n",
       "          5.11144586e-02, -4.91851419e-02,  4.13220637e-02,  4.62397821e-02,\n",
       "         -1.02006644e-02,  5.39910682e-02,  5.30620031e-02, -5.36090508e-02,\n",
       "          5.33207133e-02, -3.62461130e-03,  3.21731083e-02,  4.58384454e-02,\n",
       "         -5.31953585e-04,  5.40154986e-02, -3.79292294e-02,  4.66287918e-02,\n",
       "          5.30051403e-02, -1.76688097e-02,  2.90874131e-02,  2.43272372e-02,\n",
       "          2.12806948e-02,  5.38492277e-02,  3.77888754e-02,  4.14303020e-02,\n",
       "         -4.90503870e-02, -2.03061961e-02,  3.90575789e-02, -4.58936319e-02,\n",
       "          5.23971915e-02, -2.26548761e-02,  2.95529123e-02, -1.54185127e-02,\n",
       "          7.21882004e-03,  5.40191941e-02,  2.38578580e-02,  5.39576784e-02,\n",
       "          2.61839926e-02, -4.75000814e-02,  4.27986607e-02, -1.97237469e-02,\n",
       "         -5.34446761e-02, -5.36457710e-02,  1.97716597e-02,  4.22968529e-02,\n",
       "          5.25377095e-02, -5.06934226e-02, -4.51868102e-02, -5.31213731e-03,\n",
       "          4.45929309e-03,  1.87411197e-02, -4.16720994e-02,  1.45762563e-02,\n",
       "         -5.05682640e-03, -4.63756807e-02,  2.97252480e-02, -2.75198333e-02,\n",
       "          2.97896322e-02, -5.22107370e-02, -5.39179221e-02,  5.21120057e-02,\n",
       "          2.22385973e-02, -3.35434191e-02,  2.04405194e-04, -5.00405915e-02,\n",
       "         -1.83982775e-03,  2.06404533e-02, -5.14814779e-02,  2.72934474e-02,\n",
       "          7.60863069e-03, -4.52351607e-02,  1.37968762e-02,  3.29180881e-02,\n",
       "          1.36798574e-02,  2.18675211e-02, -3.65757346e-02,  2.83958800e-02,\n",
       "         -3.71299172e-03,  8.35031364e-03,  1.70423242e-03,  6.62166998e-03,\n",
       "         -5.05801328e-02,  3.43039148e-02, -4.25532367e-03, -4.89780642e-02,\n",
       "          3.15154716e-02, -5.19561060e-02,  1.27104763e-02, -5.02703302e-02,\n",
       "          4.87034693e-02,  4.29032743e-02, -5.09150792e-03,  5.36333248e-02,\n",
       "         -4.80717234e-02,  1.51417106e-02, -3.53269354e-02, -4.17884737e-02,\n",
       "         -3.09554674e-02, -5.20206392e-02, -7.29896128e-04,  2.07887925e-02,\n",
       "          5.39530404e-02,  5.40204756e-02, -1.10839661e-02, -1.52638378e-02,\n",
       "          5.35004623e-02,  2.52266414e-02, -1.96231306e-02, -4.79468442e-02,\n",
       "         -1.68431196e-02, -4.04646657e-02,  3.01889293e-02,  2.55358219e-03,\n",
       "         -3.54091674e-02, -2.97714956e-02, -5.24680987e-02, -3.81310061e-02,\n",
       "         -2.32908595e-02,  5.26272543e-02,  3.71877737e-02, -3.90669554e-02,\n",
       "          2.02656873e-02, -5.01178093e-02,  5.33343144e-02, -4.97947261e-02,\n",
       "         -4.90384586e-02, -4.97242734e-02,  4.83726785e-02, -4.69600856e-02,\n",
       "         -4.77769971e-02, -5.18491641e-02,  3.39722894e-02,  2.48853918e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 53,\n",
       "  'topic_words': array(['correlation', 'statistically', 'correlations', 'correlated',\n",
       "         'statistical', 'correlates', 'correlate', 'genotype',\n",
       "         'significance', 'probability', 'genetically', 'genetic',\n",
       "         'relevance', 'genotypes', 'demographic', 'probabilistic', 'gene',\n",
       "         'genes', 'distinctiveness', 'significantly', 'genetics',\n",
       "         'variance', 'statistic', 'statistics', 'ggplot', 'datasets',\n",
       "         'multivariate', 'significant', 'rare', 'variances', '확률',\n",
       "         'percentage', 'adhd', '유전자', 'prevalence', 'probabilities',\n",
       "         'genome', 'parcellation', 'familial', 'distributed', 'scatterplot',\n",
       "         'alzheimers', 'covariance', 'percentile', 'distribution',\n",
       "         'relative', 'considerable', 'variability', 'valuable',\n",
       "         'qualitative'], dtype='<U15'),\n",
       "  'topic_vector': array([-4.4665169e-02, -4.1882906e-02, -1.8707253e-02, -3.9499890e-02,\n",
       "         -2.3278277e-02,  5.4464862e-02,  2.3893237e-02,  3.4819134e-03,\n",
       "         -5.0563518e-02,  3.1858362e-02,  1.1221488e-02, -8.3025452e-04,\n",
       "          3.9037868e-02, -1.7453916e-02, -3.2210767e-02, -6.1583696e-03,\n",
       "         -4.2522814e-02,  2.4756063e-03,  5.3784255e-02, -3.7813215e-03,\n",
       "         -7.0581543e-03, -3.3213317e-02, -4.6446159e-02,  5.4349821e-02,\n",
       "         -4.2003162e-02,  5.1318510e-03,  1.7833045e-02,  4.6615474e-02,\n",
       "         -3.0202093e-03,  3.1547442e-02, -1.3376685e-02,  6.1313584e-03,\n",
       "          4.7591045e-02, -2.7446568e-02,  2.7384147e-02, -4.5524478e-02,\n",
       "         -2.8143596e-02,  1.3448867e-02,  2.8614711e-02,  1.4870790e-02,\n",
       "          1.7554546e-03, -1.3152352e-03,  3.2321434e-02, -4.6492457e-02,\n",
       "         -1.9786149e-02, -2.0280901e-02,  5.3941041e-02,  3.8931072e-03,\n",
       "         -7.8096194e-03, -1.6941905e-02,  2.8390892e-02,  2.0856811e-03,\n",
       "          1.7553315e-02, -1.9246735e-02,  4.1489908e-03,  7.9770880e-03,\n",
       "          1.4005394e-02,  1.4403914e-02, -2.2893196e-02,  2.7635332e-02,\n",
       "          5.0044890e-02,  5.1984344e-02, -6.0575856e-03, -4.6007693e-02,\n",
       "         -5.6676254e-02,  1.9840352e-02,  4.2327810e-02,  3.3383194e-02,\n",
       "         -7.7340920e-03, -2.2816818e-02,  1.2103514e-02, -1.8708337e-02,\n",
       "         -2.4515282e-02, -5.4274224e-02, -4.0405929e-02, -4.8223913e-02,\n",
       "          5.3308733e-02, -2.8644949e-02, -2.3215700e-02, -4.5770183e-02,\n",
       "         -5.6461744e-02, -3.1745911e-02,  5.1684733e-02,  3.5884760e-02,\n",
       "         -4.7495108e-02,  1.2209860e-02, -4.8363078e-02, -3.4344222e-02,\n",
       "         -2.7756926e-02, -3.7808344e-02,  3.2501193e-03, -3.5305075e-02,\n",
       "         -1.0294748e-02, -2.9866789e-02,  3.0946974e-02,  3.6536820e-02,\n",
       "          5.0359603e-02,  2.5582934e-02,  1.2089809e-02,  3.4490041e-02,\n",
       "          4.2200640e-02, -2.0291228e-02,  9.0570683e-03, -4.7451273e-02,\n",
       "         -1.0342685e-02,  3.5094395e-02, -5.6698695e-02, -1.5507918e-02,\n",
       "          2.9382670e-02,  5.1254410e-02,  5.4127529e-02, -4.6749156e-02,\n",
       "         -4.4470262e-03, -1.7225064e-02,  2.1363009e-02, -1.3789436e-02,\n",
       "          4.8881415e-02, -5.0370514e-02, -2.8411556e-02,  9.0737566e-03,\n",
       "         -5.3272054e-02,  2.9506428e-02,  3.6437653e-02,  1.1590953e-02,\n",
       "         -2.5556240e-02,  2.1700639e-02,  4.8101619e-02, -1.5041442e-02,\n",
       "         -3.9162450e-02,  2.9032446e-02, -4.3953180e-02, -3.6150318e-02,\n",
       "          1.1525319e-02,  2.9767398e-04, -4.0507127e-02,  5.5854600e-02,\n",
       "         -4.0323464e-03,  1.8260293e-02,  4.8997059e-02, -1.7146887e-02,\n",
       "          3.4330688e-02, -5.1073421e-02,  1.0795848e-02, -5.3301737e-02,\n",
       "          3.1895336e-02,  2.8787358e-02, -4.9524371e-02,  2.7782807e-02,\n",
       "          4.8224173e-02, -2.5972344e-02,  3.2313216e-02,  2.7722385e-02,\n",
       "          1.1829712e-02, -1.9137796e-02, -3.6074221e-02,  4.7297701e-02,\n",
       "          3.0084219e-02, -9.4675738e-04,  1.8288478e-02,  4.2088404e-03,\n",
       "          1.6660087e-02, -2.2508409e-02, -4.7473941e-02, -1.0337951e-02,\n",
       "         -2.0663461e-03, -4.2340685e-02, -2.6457911e-02,  2.7099723e-02,\n",
       "         -3.5962947e-02,  1.8114883e-02, -4.6509113e-02, -3.6795415e-02,\n",
       "         -2.8028060e-03,  2.3338325e-02, -2.7082367e-02,  4.2524170e-02,\n",
       "          4.0715918e-02, -4.3157591e-03,  1.2441324e-03,  3.1051477e-02,\n",
       "          2.1213869e-02, -5.5946928e-02,  1.9085512e-02,  5.2140489e-02,\n",
       "         -2.2220230e-03, -5.2214492e-02,  1.9348580e-02,  5.5092786e-02,\n",
       "          3.5996996e-02,  3.0110557e-02, -4.8180982e-02,  1.2909023e-02,\n",
       "          6.6157645e-03, -2.9338799e-02, -5.5769082e-02, -4.4671278e-02,\n",
       "         -7.9571921e-03,  3.8184438e-02,  4.4337947e-02, -4.0473443e-02,\n",
       "          2.1582454e-02,  1.8628426e-02,  1.2533868e-02,  5.2497540e-02,\n",
       "         -2.9058211e-02, -4.4422403e-02, -5.7477247e-02,  4.0736105e-02,\n",
       "          5.0434776e-02,  3.4612015e-02,  8.0036633e-03,  6.3423775e-03,\n",
       "         -3.6956809e-02,  4.3244150e-02,  4.9387764e-02, -1.2471136e-02,\n",
       "         -2.6159316e-02, -2.8754691e-02,  1.7702902e-02, -3.2129318e-02,\n",
       "          3.4329161e-02,  4.4012994e-02,  4.4508979e-02,  3.1112950e-02,\n",
       "         -4.5320418e-02,  2.0414405e-04, -5.6222722e-02, -3.5456666e-03,\n",
       "         -3.6980724e-03, -2.7289920e-02, -2.3996936e-02,  3.1121014e-02,\n",
       "         -3.5140086e-02,  3.8381092e-02,  1.5574819e-02, -9.2786644e-04,\n",
       "          4.3928489e-02,  1.4119936e-02,  3.4394417e-02,  3.7703305e-02,\n",
       "          3.2079767e-02, -1.1697955e-02, -2.0244716e-02,  5.0197557e-02,\n",
       "          4.1568335e-02, -3.0895246e-02,  4.8142277e-02, -2.4708502e-02,\n",
       "         -4.2578876e-02,  3.4499083e-02, -3.0920725e-02, -2.8883280e-02,\n",
       "          2.4161221e-02, -1.1056588e-02, -4.3849228e-04, -4.2752769e-02,\n",
       "         -2.0167263e-02,  2.8113432e-02, -5.4263910e-03,  3.6754970e-02,\n",
       "          5.6881616e-03,  1.5985722e-02, -3.0726636e-02,  5.3170837e-02,\n",
       "          2.8951105e-02, -5.4731973e-02, -3.9576415e-02,  3.7096035e-02,\n",
       "         -1.3781320e-02,  3.0325282e-02,  3.2227382e-02, -4.4190161e-02,\n",
       "         -5.3409703e-02, -4.4123001e-02, -2.5257971e-02,  1.7923769e-04,\n",
       "         -3.6393180e-02, -1.6889071e-02, -5.6619003e-02, -3.0051302e-02,\n",
       "         -3.8887672e-02,  4.1337363e-02,  5.1576514e-02,  3.9897870e-02,\n",
       "         -4.1312678e-03,  2.0483963e-02, -4.9974546e-02, -1.0771830e-02,\n",
       "         -3.3344354e-02,  4.6165694e-02,  4.5330539e-02,  3.2345355e-02,\n",
       "          1.7921038e-02, -2.2215789e-02, -2.1889061e-02, -2.6380409e-02,\n",
       "          3.7166528e-02, -4.8356741e-03,  4.5407850e-02,  2.6336875e-02,\n",
       "         -4.4136617e-02,  4.4543862e-02, -3.4735389e-02, -1.4936537e-03,\n",
       "         -5.7468954e-02, -2.0295223e-03,  6.1125839e-03,  2.2114435e-02,\n",
       "         -2.2303559e-02,  1.3867350e-02, -5.7043154e-02, -3.0996539e-02,\n",
       "         -1.0343890e-02, -2.6641704e-02,  5.0593495e-02,  2.9458549e-02,\n",
       "          4.9171291e-02, -1.6467106e-02,  9.3044648e-03, -1.9158047e-02,\n",
       "          1.7056817e-02, -4.9997289e-02, -8.7173246e-03,  4.3945577e-02,\n",
       "         -5.1095068e-02,  1.5016316e-02, -1.8232957e-02,  1.5718129e-02,\n",
       "         -4.8383418e-02,  1.0022652e-02,  1.9778879e-03, -2.4916038e-02,\n",
       "         -3.7776969e-02, -4.9873192e-02, -4.7112830e-02,  1.4770643e-02,\n",
       "         -3.9220817e-02, -4.0730659e-02, -5.4015189e-02, -4.2289685e-02,\n",
       "         -2.9401120e-02,  1.7589008e-02, -2.4757575e-02, -2.6455969e-02,\n",
       "         -3.7306625e-02,  2.7605321e-02,  5.7324313e-02, -1.5767561e-02,\n",
       "         -5.3585000e-02,  4.3079864e-02,  8.6489944e-03,  4.5530699e-02,\n",
       "          6.3839182e-04,  1.6384404e-02,  5.2715428e-02, -2.4059787e-05,\n",
       "         -4.7080159e-02,  4.0516041e-02, -3.3313520e-02, -1.8524177e-02,\n",
       "          1.0540210e-02, -5.6509968e-02,  2.8273288e-02,  3.8040753e-02,\n",
       "         -4.5359131e-02,  5.6401554e-02, -1.2209081e-02,  2.0029461e-02,\n",
       "          9.1162045e-04,  2.3761053e-02,  2.1110758e-02,  4.2290185e-02,\n",
       "         -2.9886670e-02,  5.2530516e-02,  7.9736086e-03, -4.0450417e-02,\n",
       "          5.8535803e-03, -2.7545698e-02,  8.7763229e-03, -4.3942701e-02,\n",
       "          4.4281159e-02, -1.7725252e-02, -1.8771458e-02, -1.7235491e-02,\n",
       "         -4.8145000e-03,  5.7256930e-02,  5.1723227e-02, -5.2746885e-02,\n",
       "          5.3910315e-02, -2.3719229e-02, -4.4311620e-03,  2.5330976e-02,\n",
       "         -1.4421934e-02,  3.2846734e-02, -3.7465062e-02,  2.2438141e-02,\n",
       "          4.0871620e-02, -2.2750050e-02, -2.0323375e-02, -1.3962610e-02,\n",
       "          4.6688583e-02,  5.5742394e-02,  1.7223943e-02, -3.0014291e-03,\n",
       "         -5.4891333e-02, -6.7917304e-04,  4.4715904e-02, -2.4804201e-02,\n",
       "          2.6211973e-02, -2.8698174e-02,  3.7796982e-03, -3.2009773e-02,\n",
       "          1.1927184e-02,  5.0100632e-02, -2.9015057e-02,  5.7065092e-02,\n",
       "          2.5898797e-02, -4.2425897e-02,  4.9041774e-02, -1.3783538e-02,\n",
       "         -5.5849627e-02, -4.8014097e-02,  2.0149946e-02,  5.4094560e-02,\n",
       "          5.6199886e-02, -2.0786460e-02, -5.2206054e-02,  1.9516563e-03,\n",
       "          6.4049261e-03, -1.5207576e-03, -3.2159559e-02, -3.9334632e-03,\n",
       "         -1.7173765e-02, -2.1012895e-02,  2.0536579e-02,  2.8449802e-02,\n",
       "          2.4739726e-02, -5.1589154e-02, -5.7274129e-02,  5.3275093e-02,\n",
       "          3.6196034e-02, -9.3228444e-03,  3.9758001e-02, -5.6962635e-02,\n",
       "          9.7231250e-03,  2.4763659e-02, -5.4765180e-02,  3.2758262e-02,\n",
       "         -5.4729469e-02,  1.0290006e-03,  2.4532592e-03,  2.8317980e-03,\n",
       "          2.9320763e-02, -5.4046689e-03, -2.2626987e-02,  4.1015837e-03,\n",
       "          3.8879393e-03,  1.7525870e-02, -3.3845995e-02,  2.4373960e-02,\n",
       "         -5.1344771e-02, -3.3266645e-02, -2.8917398e-03, -5.2085426e-02,\n",
       "          4.5949362e-02, -4.3836076e-02,  7.1171857e-03, -3.9570414e-02,\n",
       "          5.0425127e-02,  2.4231128e-02, -1.3587285e-02,  1.3856986e-02,\n",
       "         -8.1360992e-03,  1.7460287e-03, -4.2186387e-02, -3.4791276e-02,\n",
       "         -4.6458706e-02, -2.5553510e-02,  6.8769623e-03,  2.1747250e-02,\n",
       "          5.3675123e-02,  5.7508238e-02, -3.3905677e-02,  1.3175600e-02,\n",
       "          1.6967513e-02, -2.0474564e-02, -9.4871614e-03, -3.2097615e-02,\n",
       "         -1.5953077e-02, -2.2154747e-02,  4.4905420e-02,  3.9657000e-02,\n",
       "         -2.3844827e-02,  1.2263043e-02, -5.6748800e-02,  2.0127868e-02,\n",
       "         -2.4909552e-02,  8.9233369e-03,  3.4342855e-02, -2.8161284e-02,\n",
       "          5.2796803e-02, -5.5861291e-02,  5.6319866e-02, -1.9704200e-02,\n",
       "         -4.0998518e-02, -5.6365877e-02, -9.1178278e-03, -4.5011185e-02,\n",
       "         -1.5007257e-02, -5.6130584e-02,  9.4528440e-03,  2.3138922e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 54,\n",
       "  'topic_words': array(['한국어', 'korean', '평양', '한국', 'seoul', '일본', 'japanese', '한글',\n",
       "         'korea', '라면', '동관', '서울대', '서울', '맛있', '마태오', '음식점', 'mahjong',\n",
       "         '음식', 'menu', '동시', '소고기', 'chiang', '제곱', '메뉴', '서민', 'chang',\n",
       "         '수많', '조선', '서울시', '대구', 'wang', '용어', '고기', '요리', '다진', '국물',\n",
       "         'food', '훨씬', 'ㅋㅋ', '깔끔', '괜찮', '뚜껑', 'terminology', '식당', '나누',\n",
       "         'traditional', '각종', '언어', '다양', '유의'], dtype='<U15'),\n",
       "  'topic_vector': array([ 6.07210621e-02,  2.94599831e-02,  9.03919246e-03, -1.40819345e-02,\n",
       "          3.18915993e-02,  6.05899245e-02,  2.22438537e-02,  4.54992317e-02,\n",
       "          9.21605434e-03,  6.02999926e-02, -3.27710025e-02,  3.10476273e-02,\n",
       "          5.56840785e-02, -3.89801227e-02, -3.54854763e-02, -9.64847207e-03,\n",
       "          2.61202622e-02, -5.76207973e-03,  4.90463674e-02,  4.54204157e-02,\n",
       "         -1.75655261e-02, -5.33228889e-02,  2.75041461e-02,  1.42909065e-02,\n",
       "         -6.07296303e-02, -5.14055379e-02, -1.19242938e-02,  2.01102737e-02,\n",
       "          4.97221947e-02, -5.85351996e-02, -5.07628433e-02,  1.48078986e-02,\n",
       "         -4.30848636e-03, -4.55475375e-02,  2.82480419e-02, -5.09806946e-02,\n",
       "         -5.66829462e-03, -5.51459081e-02,  7.65238050e-03, -3.19787562e-02,\n",
       "         -1.92640517e-02, -6.06118739e-02, -1.56490766e-02, -5.89288101e-02,\n",
       "         -8.59044120e-03, -4.32723090e-02, -6.05454892e-02,  2.17659045e-02,\n",
       "         -6.09536618e-02,  4.63664010e-02, -1.51960813e-02, -4.59365733e-02,\n",
       "          2.16595270e-03, -2.37522647e-04,  3.72785814e-02, -6.09357767e-02,\n",
       "          4.77192104e-02, -6.07336685e-02,  1.44013353e-02, -1.06076868e-02,\n",
       "         -2.37122849e-02,  6.00539893e-02,  2.27262825e-03, -1.42206531e-02,\n",
       "          3.51896770e-02,  2.70655341e-02,  2.50586402e-02, -5.28376326e-02,\n",
       "         -2.09503248e-02, -7.73699675e-03, -3.56766097e-02,  5.79884946e-02,\n",
       "          2.01762859e-02, -8.49808194e-03,  8.64837412e-03,  7.76020810e-03,\n",
       "         -3.97257246e-02,  4.25122678e-04,  2.43380480e-02, -6.09626174e-02,\n",
       "         -6.09631389e-02,  1.75468903e-02,  5.23260385e-02,  5.74466623e-02,\n",
       "          1.43386610e-02, -5.42571619e-02, -5.89970425e-02, -2.11549457e-02,\n",
       "          5.06090373e-03,  3.88961062e-02,  6.34014327e-03, -1.81146804e-02,\n",
       "         -4.81519699e-02, -4.14810330e-02, -1.23243686e-02,  5.67907952e-02,\n",
       "          1.04691200e-02,  5.98047860e-02, -4.47841473e-02,  5.64478189e-02,\n",
       "         -2.62879059e-02,  3.35603915e-02, -3.39369252e-02,  2.89402343e-02,\n",
       "          3.60697620e-02, -5.53015769e-02,  5.42901345e-02, -4.09063548e-02,\n",
       "         -3.94548327e-02, -2.45407801e-02,  5.11764511e-02, -1.26674073e-02,\n",
       "          5.95630743e-02,  3.28486897e-02,  8.90392996e-03, -2.31378116e-02,\n",
       "          1.94410980e-02, -1.55061809e-03,  3.10544446e-02, -5.49819618e-02,\n",
       "         -5.38640060e-02, -5.65344617e-02,  3.18315551e-02,  1.89085267e-02,\n",
       "         -4.16129157e-02, -4.75671217e-02,  4.41461951e-02,  5.44167310e-02,\n",
       "         -4.07440849e-02,  5.84477037e-02, -5.36781922e-02, -2.97140032e-02,\n",
       "          2.48333309e-02,  1.47047509e-02, -6.09482899e-02,  6.06021360e-02,\n",
       "         -3.15425619e-02,  3.16326693e-02,  3.14860120e-02, -5.14974818e-02,\n",
       "          5.81921339e-02, -4.98304851e-02, -3.98476943e-02,  4.63864729e-02,\n",
       "         -2.24746615e-02,  2.66028792e-02,  5.98416887e-02, -5.39061949e-02,\n",
       "          2.38471478e-03,  5.48382476e-03, -7.75188766e-03,  6.62571844e-03,\n",
       "         -3.10101584e-02, -4.20749560e-02, -1.01868687e-02, -3.83033119e-02,\n",
       "         -3.87297161e-02, -3.73737514e-02, -1.68846361e-02, -2.89283600e-02,\n",
       "         -5.57457805e-02, -6.08894527e-02,  2.51673553e-02,  2.58526877e-02,\n",
       "          5.90974744e-03, -4.99916971e-02, -1.62572023e-02, -8.15533753e-03,\n",
       "         -5.66861331e-02, -1.13448203e-02, -3.42532694e-02,  5.20916283e-02,\n",
       "         -3.87114361e-02,  2.93079745e-02,  3.82336639e-02,  6.03547320e-02,\n",
       "          2.35936418e-02, -4.13222890e-03,  3.53486687e-02,  6.07134700e-02,\n",
       "         -2.83712130e-02,  3.36948223e-02,  3.24348547e-03,  5.43148182e-02,\n",
       "         -5.31380661e-02,  1.73025541e-02,  4.89042252e-02,  6.07901849e-02,\n",
       "          1.87244490e-02,  5.97790144e-02,  2.01321114e-03, -7.74469227e-03,\n",
       "          3.87666002e-02, -4.15077806e-02, -3.62012275e-02, -2.31304877e-02,\n",
       "          4.22709212e-02, -3.72292511e-02,  3.88498344e-02, -1.87729895e-02,\n",
       "         -5.71665242e-02,  2.31520869e-02, -1.69685576e-02, -5.56553109e-03,\n",
       "         -3.22790183e-02, -3.94892618e-02,  6.07469156e-02,  1.96392890e-02,\n",
       "         -2.02404987e-03,  5.21405675e-02, -3.91236432e-02,  2.89794933e-02,\n",
       "         -5.18651791e-02, -1.74421165e-02, -6.81657996e-03, -3.16309854e-02,\n",
       "          2.33800001e-02,  1.39375012e-02, -2.56877821e-02,  5.32364696e-02,\n",
       "          2.07200740e-03, -2.84697954e-03,  5.44630438e-02,  1.46916294e-02,\n",
       "          5.74572012e-02,  1.49378460e-02, -5.23380600e-02, -3.41561064e-03,\n",
       "         -5.32049686e-04, -2.60656010e-02, -1.11796958e-02, -6.08402789e-02,\n",
       "          5.55566177e-02,  4.90374714e-02,  4.00939658e-02,  3.72921824e-02,\n",
       "         -5.73532581e-02,  3.90809029e-03, -6.92719873e-03, -1.06122447e-02,\n",
       "          3.40927579e-03, -4.85303253e-02,  4.81662862e-02, -6.54966570e-04,\n",
       "          1.91383511e-02,  4.31466661e-02,  6.01166934e-02,  3.87213565e-02,\n",
       "          3.79032940e-02, -3.09539344e-02,  6.14399649e-03,  1.12744989e-02,\n",
       "         -4.20806520e-02,  5.98744527e-02,  2.41656527e-02,  5.87488450e-02,\n",
       "          2.74946690e-02,  3.36111076e-02, -2.27729306e-02,  6.04504794e-02,\n",
       "          5.72719462e-02,  5.98763973e-02, -9.17340629e-03, -6.08072057e-02,\n",
       "          1.40029024e-02, -5.99879958e-02, -1.49590969e-02,  6.04392551e-02,\n",
       "          3.58208641e-02, -6.36841264e-03, -3.79644781e-02, -4.18302827e-02,\n",
       "          5.55474386e-02, -1.67092085e-02,  3.92876305e-02, -1.06165819e-02,\n",
       "          2.22981330e-02, -5.95072098e-02, -5.86707518e-02, -5.93908653e-02,\n",
       "          5.76029420e-02, -3.21506429e-03,  5.58534190e-02,  1.07483193e-02,\n",
       "          5.83535582e-02,  2.29554214e-02, -3.00555639e-02,  5.31034917e-02,\n",
       "         -2.15831213e-02,  4.90180543e-03, -5.23771308e-02,  1.58273838e-02,\n",
       "          1.41575169e-02, -2.47081406e-02,  5.40782586e-02,  6.02453202e-02,\n",
       "          9.69921052e-03,  2.58605927e-02, -3.14468034e-02, -1.49471797e-02,\n",
       "          3.60735040e-03, -1.89131685e-02,  5.11320643e-02, -8.73676408e-03,\n",
       "          5.27296066e-02, -3.53736952e-02,  5.42799868e-02,  5.47116771e-02,\n",
       "         -2.60574669e-02,  5.68931922e-02,  1.34485923e-02, -5.42117059e-02,\n",
       "         -4.48998362e-02, -2.41156444e-02, -2.35057101e-02,  5.38774393e-02,\n",
       "         -3.38362008e-02, -2.78624110e-02,  5.95770292e-02, -5.31844981e-03,\n",
       "         -2.96818372e-02, -4.65541929e-02,  2.45226659e-02, -1.69307366e-03,\n",
       "         -2.44577453e-02, -4.38666940e-02,  1.52378632e-02, -2.87264213e-02,\n",
       "          4.32135910e-02,  1.61412302e-02, -7.73127284e-03, -5.01683839e-02,\n",
       "         -4.67915833e-02,  3.80207337e-02, -2.15952341e-02, -5.38337938e-02,\n",
       "         -2.30720602e-02,  5.56200668e-02, -3.33257951e-02, -5.25858812e-02,\n",
       "         -5.44160753e-02, -2.92751100e-03, -2.14586593e-02,  1.14708915e-02,\n",
       "         -1.57319251e-02,  4.01679799e-02, -1.54616032e-02,  4.75263447e-02,\n",
       "         -7.95987435e-04, -1.83274411e-02,  2.19222941e-02,  1.53698577e-02,\n",
       "          5.61565161e-02, -2.89374888e-02,  4.64959145e-02,  4.20255437e-02,\n",
       "         -3.40223610e-02, -4.17506471e-02,  5.76936826e-03,  2.65397411e-02,\n",
       "         -3.24663334e-03,  1.27522573e-02,  4.33620512e-02, -5.01549430e-02,\n",
       "         -9.17616952e-03, -3.80179137e-02, -5.98728135e-02, -5.86625859e-02,\n",
       "          4.60865311e-02, -2.66504027e-02,  1.52564440e-02,  4.95354012e-02,\n",
       "          3.97753604e-02, -3.48779634e-02,  2.35788766e-02,  5.64132910e-03,\n",
       "         -2.07178518e-02, -4.47785221e-02,  5.61410859e-02, -3.17393504e-02,\n",
       "          3.07731219e-02,  3.47293690e-02,  3.33454236e-02,  4.89019118e-02,\n",
       "          2.82486789e-02,  5.91485500e-02, -2.72372141e-02, -6.08103313e-02,\n",
       "          5.83451428e-02,  6.07813410e-02,  4.87780385e-03,  3.27455141e-02,\n",
       "         -5.54256607e-04,  1.80524997e-02,  5.67346700e-02, -4.31437753e-02,\n",
       "         -5.67232892e-02, -3.31277922e-02, -3.68670039e-02,  3.80123816e-02,\n",
       "          9.28583741e-03, -8.20484664e-03,  3.43803614e-02,  5.02594188e-02,\n",
       "          3.83687392e-03, -6.54641818e-03, -5.14275394e-02, -9.04558226e-03,\n",
       "         -2.58724345e-03, -3.70102264e-02,  5.90391457e-02,  5.72870951e-03,\n",
       "          5.89827672e-02,  3.01806256e-04, -4.33924757e-02,  5.58914430e-02,\n",
       "          4.68560681e-03,  3.51711214e-02,  1.21267056e-02, -5.94178960e-02,\n",
       "          4.10343595e-02,  4.67911251e-02, -5.54712266e-02,  3.18348259e-02,\n",
       "          4.09982689e-02,  5.59029286e-04,  3.43165547e-02,  3.64041440e-02,\n",
       "         -6.01577610e-02, -5.65523095e-02, -3.35765965e-02,  2.87795588e-02,\n",
       "          3.35248858e-02,  5.40041253e-02,  6.05459176e-02, -4.60684113e-02,\n",
       "          2.24330314e-02,  5.31294681e-02, -6.09510764e-02,  4.75948378e-02,\n",
       "          3.79469581e-02,  5.96464649e-02, -1.55406836e-02, -4.80891429e-02,\n",
       "          1.01932278e-03, -4.04492393e-02,  6.07981086e-02,  5.65849990e-02,\n",
       "          1.65827526e-03,  4.61023152e-02,  1.09167267e-02,  3.28935757e-02,\n",
       "         -1.05916047e-02,  1.79839842e-02, -6.09451681e-02,  5.68246543e-02,\n",
       "          2.37011686e-02, -3.67480926e-02,  4.07658108e-02,  6.07700460e-02,\n",
       "          2.65443828e-02,  5.71121462e-04,  2.70386301e-02, -1.67824794e-02,\n",
       "         -1.95906721e-02, -6.08971938e-02, -2.28387155e-02, -3.08069363e-02,\n",
       "          2.57482678e-02,  4.52206545e-02,  9.86864325e-05,  1.61206480e-02,\n",
       "         -4.88926470e-03,  1.07219778e-02, -2.59787217e-02, -3.12322415e-02,\n",
       "          5.43608516e-02,  2.61742510e-02, -7.92774488e-04,  1.13248834e-02,\n",
       "         -3.71445306e-02,  6.09629899e-02, -6.39181305e-03,  3.54226772e-03,\n",
       "          5.09276204e-02,  4.25068811e-02,  4.67111841e-02, -6.09490797e-02,\n",
       "         -4.23218720e-02, -4.85287122e-02,  3.85990106e-02,  4.97748330e-02,\n",
       "          4.37490158e-02,  8.35485756e-04, -8.64817202e-03, -3.30617018e-02,\n",
       "         -5.69866858e-02, -5.02386391e-02,  5.01965173e-03,  6.92842714e-03,\n",
       "          6.96316268e-03,  3.07855010e-02,  5.98798841e-02,  5.94907850e-02,\n",
       "         -6.07521608e-02, -3.72845083e-02,  1.49134193e-02, -5.34164347e-02,\n",
       "          1.90072786e-03, -5.37133999e-02,  2.97417468e-03,  2.02818811e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 55,\n",
       "  'topic_words': array(['createpage', 'plugins', 'templates', 'github', 'graphql',\n",
       "         'bootstrap', 'gatsby', '함수', 'powerpoint', 'matplotlib', 'css',\n",
       "         'pages', 'functional', 'createpages', 'html', '홈페이지', 'template',\n",
       "         'lineplot', 'urllib', 'javascript', 'functions', 'tensorflow',\n",
       "         'khtml', 'baseline', 'dataframe', 'function', 'conductance',\n",
       "         'mxpath', 'graphs', 'functionally', 'vertexcount', '태그',\n",
       "         'varlambda', 'ggplot', 'integrate', 'graph', 'integration',\n",
       "         'infrastructure', 'linking', 'queries', '페이지', 'webgl',\n",
       "         'integrating', 'url', 'dependency', '기능', 'query', 'allostatic',\n",
       "         'integrative', '파라미터'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.75981922e-02,  2.51256917e-02, -1.10688973e-02,  5.64128067e-03,\n",
       "         -3.79642583e-02, -5.85591868e-02, -5.83478343e-03,  2.60566082e-02,\n",
       "          5.64627647e-02,  5.01393564e-02,  3.31950337e-02,  4.77594621e-02,\n",
       "          5.33360243e-02,  2.01099832e-02,  4.53432426e-02, -3.95370685e-02,\n",
       "         -3.72710004e-02, -5.59700746e-03,  5.15182242e-02,  4.58716750e-02,\n",
       "          1.71074811e-02,  3.71517614e-02,  4.12470512e-02,  5.05095124e-02,\n",
       "         -5.85589223e-02, -2.41594929e-02,  2.81819608e-02, -1.69328339e-02,\n",
       "         -5.27341180e-02, -5.20322435e-02, -5.36661521e-02, -2.81938370e-02,\n",
       "         -3.05773411e-02, -5.56824207e-02, -3.21570076e-02, -4.72201817e-02,\n",
       "          5.40117733e-02, -1.42598078e-02,  2.93239560e-02, -4.67156097e-02,\n",
       "         -4.05715816e-02, -2.43472159e-02, -1.56439766e-02, -1.34631265e-02,\n",
       "          1.48065912e-03, -1.51167829e-02,  5.64194210e-02, -1.24659538e-02,\n",
       "          4.21279147e-02,  3.52931814e-03, -5.11441454e-02,  9.35487263e-03,\n",
       "         -5.04380874e-02, -3.11246756e-02, -1.46431047e-02, -5.60612269e-02,\n",
       "         -2.82516517e-02,  2.90823635e-02, -1.54346349e-02,  3.48707028e-02,\n",
       "          3.36815007e-02,  5.78503311e-02, -4.34790850e-02, -1.75711960e-02,\n",
       "         -3.46750729e-02, -1.09695988e-02,  3.27228867e-02, -6.99012494e-03,\n",
       "          3.43054906e-02, -1.61715802e-02, -4.91812900e-02,  1.75351780e-02,\n",
       "         -6.05829339e-03, -4.59845029e-02,  3.22070047e-02,  1.79585721e-02,\n",
       "          1.58754345e-02,  5.35755977e-02,  1.42896567e-02, -5.85615635e-02,\n",
       "         -5.85639589e-02,  3.43985818e-02, -4.46037129e-02, -4.12287936e-02,\n",
       "          3.80635634e-02,  1.47243049e-02, -4.81747314e-02, -3.67686972e-02,\n",
       "          2.26866268e-02, -4.68413532e-03, -2.28158827e-03, -1.78454556e-02,\n",
       "         -7.24493712e-03,  4.95667709e-03,  5.57890758e-02,  5.60157225e-02,\n",
       "         -3.03648058e-02, -1.87024176e-02,  5.39546795e-02, -7.86004495e-03,\n",
       "          2.21412294e-02,  5.15596569e-02,  8.06227513e-03,  2.60646529e-02,\n",
       "          5.29131703e-02,  4.97102961e-02, -5.57947941e-02, -3.43591385e-02,\n",
       "          4.80092950e-02,  1.23087186e-02,  5.44458702e-02, -3.45264114e-02,\n",
       "          3.09061948e-02, -4.00770046e-02,  4.69167419e-02,  1.64780580e-02,\n",
       "         -5.47562316e-02,  1.67188607e-02,  3.52487117e-02,  5.71269449e-03,\n",
       "          1.60710756e-02, -5.32233939e-02, -6.19730074e-03,  5.79550937e-02,\n",
       "          4.12769243e-02, -2.22762171e-02, -2.99732890e-02,  4.68603000e-02,\n",
       "          5.67704812e-02,  1.46310034e-04, -3.77806611e-02, -4.40623565e-03,\n",
       "          5.84282354e-02,  1.98402293e-02,  6.52427133e-03,  4.82690744e-02,\n",
       "          4.92720976e-02,  2.32623029e-03,  4.72716466e-02,  5.76364212e-02,\n",
       "         -4.58876975e-02,  2.10980158e-02, -8.51279404e-03, -2.32147407e-02,\n",
       "          4.24452983e-02,  1.65646840e-02, -2.98684500e-02,  5.60709462e-02,\n",
       "          4.04477045e-02, -9.24536609e-04,  5.78636006e-02, -1.05901975e-02,\n",
       "          1.64483711e-02,  1.84347108e-03, -1.72123052e-02,  1.89885683e-02,\n",
       "          1.91269834e-02, -3.83930691e-02,  3.00635509e-02,  3.16973105e-02,\n",
       "          4.32320461e-02, -4.72310884e-03,  5.15224449e-02, -4.17974219e-02,\n",
       "          2.69746277e-02, -5.15720844e-02, -3.83331031e-02,  1.72906257e-02,\n",
       "          4.90538627e-02,  3.99086773e-02,  4.65544946e-02, -5.51459193e-02,\n",
       "         -3.81347761e-02,  3.05168089e-02,  3.04166563e-02,  4.39594276e-02,\n",
       "         -5.78591935e-02, -2.12964974e-02, -5.73551431e-02,  4.61955629e-02,\n",
       "          1.11422297e-02, -4.79413336e-03, -2.83163544e-02, -1.21264299e-02,\n",
       "         -2.91352123e-02, -5.06442860e-02,  4.66409624e-02,  5.54211512e-02,\n",
       "          2.28220616e-02, -1.75053570e-02,  1.83285214e-02, -5.36423810e-02,\n",
       "          5.64367697e-02,  4.80972938e-02, -1.52816353e-02,  1.94225386e-02,\n",
       "         -5.43513149e-03,  1.57007668e-02, -1.46714819e-03,  2.11684499e-02,\n",
       "         -6.17835484e-03, -2.99036736e-03, -2.19249781e-02, -4.64461707e-02,\n",
       "         -3.89767401e-02, -1.71661526e-02,  2.91455928e-02, -3.20169255e-02,\n",
       "         -3.71987894e-02,  2.53577232e-02, -3.97704951e-02,  2.26936359e-02,\n",
       "         -3.31492573e-02, -6.87780697e-03,  5.31341843e-02, -5.85200731e-03,\n",
       "         -3.49643193e-02, -3.94857973e-02, -8.33055284e-03, -3.49998096e-04,\n",
       "         -2.48606652e-02,  3.20883282e-02,  5.36080226e-02,  4.76905815e-02,\n",
       "         -5.81039675e-02, -3.37295718e-02, -2.50820406e-02, -5.66518260e-03,\n",
       "          4.82928241e-03,  2.73707602e-02, -5.22905961e-04,  5.52824065e-02,\n",
       "          3.75014916e-02,  1.31551623e-02, -2.24434957e-02,  4.55262810e-02,\n",
       "          1.60987638e-02,  2.39960123e-02,  5.34808561e-02,  1.96139570e-02,\n",
       "         -3.56301680e-05,  2.52507925e-02, -1.27136586e-02, -5.11990394e-03,\n",
       "          3.64254937e-02, -5.06997481e-02,  3.53328474e-02,  2.59707472e-03,\n",
       "          3.07663679e-02, -1.29157156e-02, -1.92351323e-02, -5.21631539e-02,\n",
       "          2.07581948e-02,  1.16865095e-02,  1.74128227e-02, -1.71690937e-02,\n",
       "          2.11272426e-02,  3.71674523e-02, -2.06692610e-04,  2.15506107e-02,\n",
       "         -4.08981144e-02,  4.68934104e-02, -4.48227525e-02, -4.05156910e-02,\n",
       "         -3.71615291e-02, -5.79715259e-02, -1.33210095e-02, -2.71219611e-02,\n",
       "          5.22351563e-02,  1.51896076e-02, -4.96382192e-02, -3.92183810e-02,\n",
       "         -4.89326939e-02,  2.33733444e-03, -2.23517604e-02,  1.24179330e-02,\n",
       "         -4.92485687e-02,  4.08500433e-03, -4.66685779e-02, -3.66872326e-02,\n",
       "         -1.45540480e-02,  3.81635353e-02,  1.03839347e-02, -1.28210885e-02,\n",
       "          4.97309826e-02,  5.37624061e-02, -5.54949343e-02,  4.53030597e-03,\n",
       "         -1.94877014e-03,  2.97652073e-02, -3.20447162e-02,  8.07737093e-03,\n",
       "          3.48033980e-02,  5.76399863e-02, -5.85287809e-02, -2.65427376e-03,\n",
       "         -5.67770302e-02,  6.65402552e-03,  3.84473726e-02,  5.44412360e-02,\n",
       "         -3.88435274e-02,  2.90105641e-02, -2.21846420e-02, -5.29495366e-02,\n",
       "         -8.28549545e-03, -3.90431508e-02,  5.13364607e-03,  1.15485885e-03,\n",
       "         -2.87177116e-02,  4.41580974e-02,  1.49746286e-02, -1.33669283e-02,\n",
       "         -4.14365716e-02, -2.15864927e-02, -1.15859509e-03,  5.28014414e-02,\n",
       "          4.70550992e-02, -2.61550434e-02,  1.34762553e-02,  3.48975584e-02,\n",
       "          1.57663669e-03,  2.40858737e-02,  6.48239534e-03, -5.14693037e-02,\n",
       "         -2.51732878e-02, -4.39909212e-02,  8.82985257e-03, -3.38165835e-02,\n",
       "         -5.63006215e-02, -1.42685845e-02, -4.76492345e-02,  1.51273143e-03,\n",
       "         -4.10306826e-02, -3.90866175e-02,  5.43982163e-02,  1.12969559e-02,\n",
       "         -2.74167918e-02,  1.52407063e-03, -5.72607890e-02,  4.71469834e-02,\n",
       "         -3.12790871e-02, -3.85103635e-02,  1.47833135e-02, -3.31563838e-02,\n",
       "         -8.15968029e-03, -4.68757097e-03,  5.30049279e-02,  2.48720441e-02,\n",
       "          2.57540550e-02, -5.19040413e-02, -4.81037870e-02,  8.11753445e-04,\n",
       "          3.35378945e-02, -5.61143979e-02,  4.51793782e-02,  3.89290452e-02,\n",
       "          2.71159448e-02,  1.74687319e-02,  8.86489265e-03, -5.45896403e-02,\n",
       "         -2.61960980e-02, -2.80732121e-02,  2.35545449e-02, -4.68661040e-02,\n",
       "          4.56476882e-02,  3.91647927e-02, -5.31651359e-03,  5.36417849e-02,\n",
       "         -4.87260297e-02,  1.73178408e-02, -3.05556618e-02, -4.32517985e-03,\n",
       "         -3.01542971e-02,  2.16553304e-02,  9.18332674e-03, -5.01547642e-02,\n",
       "         -3.38060930e-02,  2.64798515e-02, -2.87585966e-02, -4.57181744e-02,\n",
       "         -4.59406637e-02,  2.69018412e-02,  1.93634667e-02, -2.30678488e-02,\n",
       "         -1.92271862e-02,  1.01891011e-02,  1.69826373e-02, -5.85571900e-02,\n",
       "          3.20429578e-02,  2.85193622e-02,  3.99489561e-03, -1.99329145e-02,\n",
       "         -4.38448302e-02,  3.60892480e-03,  9.95125342e-03, -3.90603207e-02,\n",
       "          4.06588092e-02,  9.17485741e-04,  1.08729000e-03, -2.35773325e-02,\n",
       "          4.66124453e-02,  2.99444702e-02,  5.51309064e-02, -4.59883399e-02,\n",
       "          3.22225466e-02, -1.82183906e-02, -4.43775579e-02,  2.18981747e-02,\n",
       "         -3.49979810e-02,  2.57441103e-02, -6.80553401e-03,  6.66603958e-03,\n",
       "          1.06457649e-02, -1.22950720e-02,  1.34533988e-02,  1.63605269e-02,\n",
       "          4.32525724e-02, -2.48338021e-02, -6.24646340e-03, -3.26654762e-02,\n",
       "          4.45121117e-02,  5.76525740e-02,  1.33406650e-02,  5.34267072e-03,\n",
       "         -2.13733204e-02,  1.44067854e-02,  4.53801826e-02, -2.76116189e-02,\n",
       "         -3.05965915e-03, -4.12061401e-02,  4.24869247e-02,  1.83242168e-02,\n",
       "          1.92204863e-02,  3.63852642e-02,  2.19250005e-02,  3.97156999e-02,\n",
       "         -4.36967984e-02,  7.70735135e-03, -5.79140186e-02,  2.84893811e-02,\n",
       "         -2.69470848e-02, -7.24119553e-03,  1.09411497e-02, -5.03122211e-02,\n",
       "         -4.30755280e-02, -5.67451827e-02,  4.08849195e-02,  1.70242433e-02,\n",
       "         -8.58542416e-03,  4.42039855e-02,  5.95891615e-03,  6.24185055e-03,\n",
       "         -5.75290993e-02, -2.51059085e-02, -4.23735287e-03, -1.12120640e-02,\n",
       "          3.13006714e-02,  2.24381890e-02,  1.83131304e-02,  4.87998351e-02,\n",
       "         -3.13837640e-02, -4.26935181e-02,  2.81374145e-04, -7.60635268e-03,\n",
       "          2.67189890e-02, -3.50000262e-02,  1.28672989e-02, -4.61846739e-02,\n",
       "          5.25086597e-02,  1.18940966e-02,  4.86276485e-02, -8.17576982e-03,\n",
       "          4.30972688e-02,  1.12929307e-02, -4.67993356e-02, -3.06118038e-02,\n",
       "          2.76970174e-02, -5.04619488e-03,  1.68108065e-02, -2.03464506e-03,\n",
       "          3.69422771e-02,  4.76830490e-02, -1.63440779e-03, -2.60495134e-02,\n",
       "         -1.44739496e-02, -7.24120438e-03, -3.14274020e-02, -5.85089102e-02,\n",
       "         -8.51808209e-03, -3.18445042e-02, -2.58972496e-02,  4.49770689e-02,\n",
       "          4.49669547e-02,  3.44592109e-02, -1.11677079e-02, -4.52082753e-02,\n",
       "          1.93260387e-02, -2.96290517e-02,  3.17096822e-02, -3.17199901e-03,\n",
       "         -3.42841595e-02,  6.74087694e-03,  5.70832379e-02,  1.59741230e-02,\n",
       "         -4.83620688e-02, -5.68684265e-02, -3.03830802e-02, -2.33795103e-02,\n",
       "          3.48925218e-02, -1.12895090e-02,  1.28103001e-02,  4.04921472e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 56,\n",
       "  'topic_words': array(['probabilistic', 'computational', 'computation', 'simulations',\n",
       "         '통계청', 'computationally', 'simulation', 'simulated', 'physics',\n",
       "         'theoretical', 'computing', 'practical', '통계', 'functional',\n",
       "         'statistical', 'statistically', 'statistics', 'infrastructure',\n",
       "         'stats', 'empirical', 'computed', 'functioning', 'functionally',\n",
       "         'calculation', 'calculations', '실제', 'analysis', 'mathematics',\n",
       "         'fundamental', 'statistic', 'undergraduate', 'intrinsic',\n",
       "         'quantify', 'analytics', 'conditional', 'algorithmic',\n",
       "         'randomized', 'capability', 'calculating', 'functions',\n",
       "         'physically', 'probability', 'numerical', 'situations', 'physical',\n",
       "         'quantitative', 'analytical', 'stat', 'parametric', 'algorithms'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-0.03930356,  0.06063564, -0.00502092,  0.01887185,  0.00073008,\n",
       "         -0.02865326, -0.00452304, -0.00331694,  0.05834146,  0.03425735,\n",
       "          0.03446152,  0.05080082, -0.00059386,  0.03202277, -0.06446861,\n",
       "         -0.01642206,  0.04317344, -0.01591028,  0.03440332,  0.0515336 ,\n",
       "         -0.02071569,  0.02989188, -0.01459109,  0.05187722, -0.06565592,\n",
       "         -0.04701674,  0.00477541, -0.02665598, -0.05690826, -0.03441051,\n",
       "         -0.00723295,  0.00689799,  0.03147646, -0.05376102, -0.05066174,\n",
       "          0.03173839,  0.05155363,  0.03844536,  0.0268036 ,  0.02783684,\n",
       "         -0.01765524,  0.02998228,  0.02885088, -0.01236143,  0.0025308 ,\n",
       "          0.01061098, -0.0148663 ,  0.0461261 , -0.0285879 , -0.04092906,\n",
       "         -0.04590305, -0.04855157, -0.04138928,  0.01351771,  0.04486202,\n",
       "         -0.06404447, -0.04873389,  0.00126426, -0.00356977,  0.03551508,\n",
       "         -0.02418835,  0.06324705,  0.02897285, -0.05394128,  0.01215528,\n",
       "          0.02154053,  0.05667966, -0.01704481, -0.03133707, -0.02264498,\n",
       "         -0.00095234,  0.01871047, -0.04213225,  0.01931257,  0.01304872,\n",
       "          0.0125378 ,  0.01982233,  0.05681521,  0.03152138, -0.06672946,\n",
       "         -0.06659367, -0.02836532, -0.05541629,  0.05637525,  0.00884084,\n",
       "         -0.00772885, -0.05655942,  0.0223341 , -0.00642178, -0.01295002,\n",
       "         -0.0563492 ,  0.00327055, -0.02732597, -0.05050704,  0.0409723 ,\n",
       "          0.06334408, -0.04087901,  0.02658077, -0.02261009,  0.03361977,\n",
       "          0.05136059,  0.0431193 ,  0.06213146, -0.03185188,  0.01847754,\n",
       "         -0.03589923, -0.06531382, -0.0169479 ,  0.04319205,  0.04312855,\n",
       "          0.04895014, -0.05002572, -0.00052702, -0.02363899,  0.02118793,\n",
       "         -0.0648117 ,  0.00476925,  0.05062059,  0.01873743,  0.02750125,\n",
       "         -0.05558636,  0.02944069,  0.04073936,  0.03378819,  0.02892699,\n",
       "         -0.02708999, -0.05418956,  0.00814332,  0.01973392,  0.048185  ,\n",
       "         -0.05646283, -0.04464578,  0.04165205,  0.05116948,  0.03126258,\n",
       "          0.06100402,  0.01393684, -0.02660324,  0.0614561 ,  0.0072941 ,\n",
       "          0.00200265, -0.0133896 ,  0.03478577,  0.02917629,  0.05745023,\n",
       "         -0.02798927, -0.00426004,  0.05186412,  0.01676923,  0.01902759,\n",
       "          0.05308865,  0.00994674, -0.03674401, -0.03080101,  0.01618016,\n",
       "         -0.0092064 ,  0.00091238, -0.04215063, -0.0447603 , -0.0497777 ,\n",
       "          0.04689867, -0.02781197,  0.0086516 , -0.01225498, -0.04715482,\n",
       "          0.01060075,  0.00592393, -0.00040315, -0.01741704,  0.05023284,\n",
       "          0.00891801, -0.01687093, -0.022057  ,  0.04033865,  0.03976641,\n",
       "          0.00287353, -0.04121394,  0.01781384, -0.05621409,  0.05465674,\n",
       "          0.01154366, -0.04374674, -0.00852873, -0.01261683, -0.06259503,\n",
       "         -0.0258191 ,  0.03953172,  0.04790125, -0.03297119, -0.00370641,\n",
       "          0.04168737, -0.04384517,  0.0614498 ,  0.01985827, -0.02259789,\n",
       "          0.06149064, -0.02283271, -0.02745036,  0.04819359,  0.01652703,\n",
       "         -0.04276963, -0.01226281, -0.03378559, -0.06353951, -0.0405737 ,\n",
       "          0.00919944,  0.02899641, -0.05424334, -0.00346623,  0.00608216,\n",
       "          0.00865974, -0.03659617, -0.05885614,  0.00853222,  0.04718401,\n",
       "         -0.03962902,  0.02093906,  0.00344689, -0.02327924, -0.01285302,\n",
       "         -0.04946944,  0.05426559,  0.04217925,  0.01107093, -0.03322193,\n",
       "         -0.03962754, -0.06106949, -0.00337189,  0.0092764 ,  0.03972924,\n",
       "         -0.0097225 ,  0.0506254 ,  0.04877606,  0.00727712,  0.02116637,\n",
       "          0.02224863, -0.01795437,  0.00794739,  0.06567445,  0.00247958,\n",
       "         -0.0270778 , -0.04680656,  0.00265689, -0.00631819,  0.04342449,\n",
       "          0.00029687,  0.05436413, -0.02034109,  0.02042926, -0.04743546,\n",
       "         -0.01780822, -0.00934596,  0.01720721, -0.04927253, -0.00777986,\n",
       "         -0.03053679, -0.04682662,  0.01745679, -0.0033997 ,  0.02327911,\n",
       "         -0.00989915,  0.04098551, -0.03285538, -0.03730123,  0.02093086,\n",
       "         -0.02486108, -0.0128604 ,  0.03187752,  0.04466943,  0.0138182 ,\n",
       "          0.0092691 , -0.0190748 , -0.00157277,  0.0024058 , -0.00187431,\n",
       "          0.01797518, -0.04163672,  0.05172596, -0.04898851, -0.01485175,\n",
       "         -0.01463505, -0.02656706, -0.03128977,  0.01562636, -0.00966988,\n",
       "          0.01006752, -0.05607314,  0.00739562, -0.03800406,  0.0421172 ,\n",
       "         -0.01627629,  0.02715194,  0.0106528 ,  0.03988534, -0.02091545,\n",
       "         -0.01602902, -0.03902472,  0.03667285,  0.02637456,  0.05652471,\n",
       "         -0.00280209,  0.02341059, -0.02384058, -0.02148245, -0.05853271,\n",
       "         -0.02349057,  0.04859787,  0.02204053,  0.03226371, -0.0126178 ,\n",
       "         -0.01217006,  0.00944758, -0.05368124, -0.03832006,  0.05394624,\n",
       "          0.05612056, -0.0277499 , -0.01668847,  0.03786467, -0.05039519,\n",
       "          0.03472779,  0.05125896, -0.01324233,  0.00054641,  0.01505711,\n",
       "         -0.05830723,  0.00177073, -0.05084811,  0.04946635, -0.03650598,\n",
       "         -0.05453165, -0.043464  , -0.01012153, -0.04701471, -0.01497671,\n",
       "         -0.02858203, -0.00085973, -0.00758339, -0.03009566, -0.02852769,\n",
       "         -0.05755775,  0.05227471, -0.01877962, -0.0465031 , -0.01942908,\n",
       "          0.04110971,  0.03583274,  0.03951008, -0.01152339,  0.01043588,\n",
       "         -0.02744093, -0.00664774,  0.0082897 , -0.01432215, -0.05732545,\n",
       "          0.02750851, -0.04680708,  0.03704831, -0.02342771, -0.05750363,\n",
       "          0.04393423, -0.00188002,  0.05235405, -0.03555278,  0.023632  ,\n",
       "          0.03829144, -0.01382972,  0.04358466, -0.03283983, -0.05585328,\n",
       "          0.02972206,  0.0337067 , -0.01200474,  0.03856822, -0.0089333 ,\n",
       "         -0.03531092,  0.01762002, -0.01726173, -0.03017628, -0.03516099,\n",
       "         -0.02500425, -0.019248  ,  0.02752572,  0.03071713, -0.02165758,\n",
       "          0.05946798,  0.01737388, -0.03457514,  0.03245828,  0.05057816,\n",
       "         -0.00177629, -0.03265083, -0.03463732,  0.06085069, -0.03530774,\n",
       "         -0.04020912,  0.03021948,  0.03135419, -0.05059903, -0.01242663,\n",
       "          0.04777442,  0.06400365,  0.06250996,  0.0138329 ,  0.02132691,\n",
       "          0.00806439, -0.02775421,  0.00800402, -0.00540149,  0.00043778,\n",
       "         -0.01494399,  0.02185597,  0.03337147, -0.05161846,  0.05131565,\n",
       "          0.0528499 ,  0.00453718, -0.01261226, -0.04745366, -0.02509542,\n",
       "          0.00160111, -0.05571058,  0.03672979,  0.03888338,  0.05523338,\n",
       "          0.03681712, -0.01838442, -0.02680239, -0.0249719 , -0.05766964,\n",
       "         -0.00614498,  0.03280342, -0.04284666, -0.0099118 ,  0.05606161,\n",
       "          0.01833647,  0.00022279, -0.04087624, -0.05085823, -0.02484565,\n",
       "         -0.05315156,  0.03644165,  0.01032925, -0.06322281, -0.02455984,\n",
       "         -0.05929081,  0.05879936, -0.00575354,  0.04313602,  0.00665052,\n",
       "         -0.00718452, -0.00472078, -0.00834951, -0.00181526, -0.02698267,\n",
       "          0.03890118,  0.05689817, -0.03241946, -0.03759236,  0.0517199 ,\n",
       "         -0.02224767, -0.02490144, -0.00104789, -0.05938494,  0.01161595,\n",
       "         -0.04309534, -0.03411834, -0.0061954 ,  0.06273048, -0.0563433 ,\n",
       "          0.05897241,  0.05292996,  0.01994352, -0.01773932, -0.02044304,\n",
       "         -0.05462968,  0.04219455, -0.02148336, -0.0020141 , -0.02050523,\n",
       "          0.0585003 ,  0.06422108, -0.05050422,  0.04783418,  0.05724813,\n",
       "          0.0163139 , -0.05860008, -0.06115656, -0.0204696 ,  0.00958767,\n",
       "          0.02881392, -0.0009982 ,  0.03102052, -0.00544163,  0.01649875,\n",
       "         -0.05682017, -0.01165144, -0.04827398,  0.03256294,  0.0150835 ,\n",
       "         -0.01104279, -0.06489629,  0.06200608, -0.01874544, -0.05274921,\n",
       "         -0.04410262, -0.01787467, -0.05240551, -0.01672174, -0.03042204,\n",
       "          0.02818432,  0.05299523], dtype=float32)},\n",
       " {'topic_idx': 57,\n",
       "  'topic_words': array(['전염병', 'epidemic', '감염자', '백신', '감염병', 'diseases', '전염',\n",
       "         'infected', '감염', 'populations', 'prevalence', 'disease', '면역',\n",
       "         'population', '감염증', '인구', 'statistical', 'illness',\n",
       "         'statistically', 'syndromes', 'deaths', '바이러스', 'statistics',\n",
       "         'statistic', 'lesions', 'fatalities', 'expectancy', '사망',\n",
       "         'patients', '신종', 'syndrome', '통계청', 'pathology', '환자', 'epilepsy',\n",
       "         'patient', 'predictive', 'predictor', '박사', '예측', 'predicts',\n",
       "         'transcranial', 'lesion', 'immune', 'pathological', 'projections',\n",
       "         'neuroethics', 'predicting', 'diagnosed', 'prefrontal'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-4.30358341e-03,  3.12220063e-02, -2.68727541e-04, -2.51741651e-02,\n",
       "          3.33432183e-02,  2.09224615e-02,  1.02414833e-02,  5.67223120e-04,\n",
       "         -2.22530216e-02,  4.84383292e-02,  1.43337715e-02, -2.79463418e-02,\n",
       "         -1.65205337e-02,  1.77414827e-02, -1.88992023e-02, -3.01403888e-02,\n",
       "         -4.32276502e-02, -5.98018169e-02, -5.11153452e-02,  5.59385940e-02,\n",
       "         -4.08930257e-02, -4.14042398e-02,  5.52274752e-03, -5.81000140e-03,\n",
       "         -5.93707263e-02,  1.59134883e-02,  1.00341039e-02,  1.65788885e-02,\n",
       "          2.39467178e-03, -3.83419394e-02, -2.14728452e-02, -4.46425285e-04,\n",
       "          4.81252233e-03, -3.74314897e-02, -2.56632511e-02, -4.63557877e-02,\n",
       "          2.30103452e-02,  1.07778832e-02, -1.05300425e-02, -4.93166335e-02,\n",
       "          2.33342350e-02,  5.48091717e-02,  3.00818440e-02, -3.66989076e-02,\n",
       "         -1.97734237e-02, -5.75741306e-02,  1.69692598e-02, -1.48099242e-02,\n",
       "         -2.13647932e-02, -6.14367006e-03, -2.23341733e-02, -4.96323481e-02,\n",
       "          2.56795287e-02, -1.91517547e-02,  1.12853833e-02, -6.25812858e-02,\n",
       "          2.08831318e-02,  4.36746664e-02, -2.10460462e-02,  2.43286733e-02,\n",
       "          7.15586171e-03,  6.04648106e-02, -2.03316547e-02, -3.31734829e-02,\n",
       "         -4.40527909e-02, -4.13997546e-02,  4.46226075e-02, -5.69482557e-02,\n",
       "         -2.91714482e-02,  6.15830533e-02, -8.85934383e-03,  1.36840697e-02,\n",
       "          1.29575413e-02, -1.71994157e-02, -1.28588360e-02, -9.78894439e-03,\n",
       "          4.79917452e-02,  1.91910826e-02,  2.67377310e-02, -6.24969974e-02,\n",
       "         -6.38305396e-02, -4.22877260e-02,  3.21389623e-02,  9.25187953e-03,\n",
       "         -4.93444726e-02, -4.59942818e-02, -5.45458198e-02,  6.43367926e-03,\n",
       "         -3.51577997e-02,  3.82220931e-03, -3.72843742e-02, -3.49259302e-02,\n",
       "         -1.23731093e-02, -4.62311991e-02,  1.43047841e-02,  3.17084715e-02,\n",
       "          3.64527479e-02,  4.92967702e-02, -8.93130898e-03, -5.19871935e-02,\n",
       "         -1.19584249e-02,  1.85625814e-02,  1.58328712e-02, -1.12007614e-02,\n",
       "         -1.55315455e-02,  6.23283759e-02, -3.78286615e-02, -1.62532926e-03,\n",
       "         -2.33736821e-02, -2.98267305e-02,  2.09495761e-02, -5.36208823e-02,\n",
       "          3.06883659e-02,  1.64929666e-02,  2.08730288e-02, -1.67812146e-02,\n",
       "         -2.96929218e-02,  4.27049361e-02, -4.91539761e-02,  1.12191122e-02,\n",
       "          3.87045145e-02,  3.17944288e-02,  3.11991032e-02, -2.32567657e-02,\n",
       "         -4.03944366e-02,  4.86181676e-02,  3.96295041e-02, -2.60994583e-03,\n",
       "         -3.94973829e-02,  1.58373709e-03, -5.96397519e-02, -2.56435983e-02,\n",
       "          3.55647132e-02, -1.74821001e-02,  5.16660092e-03,  6.18571118e-02,\n",
       "          3.29790115e-02, -1.76799688e-02,  5.85077778e-02,  2.94688083e-02,\n",
       "          3.81810479e-02, -2.88571473e-02,  2.26318487e-03,  4.36199605e-02,\n",
       "          1.21209575e-02, -3.76412049e-02,  3.63736115e-02,  1.49874892e-02,\n",
       "          4.24238779e-02,  2.91648749e-02,  5.42322583e-02,  2.31318008e-02,\n",
       "         -4.13020402e-02, -4.45460854e-03, -2.80718096e-02,  3.81233878e-02,\n",
       "         -3.43978032e-02, -5.40076979e-02,  5.18790111e-02, -2.58925892e-02,\n",
       "          4.71342728e-02, -2.36752667e-02, -3.10572479e-02, -1.04023544e-02,\n",
       "         -3.20132310e-03, -1.57163292e-02,  1.58724282e-02,  8.13592412e-03,\n",
       "         -5.43668866e-02, -1.62153691e-02,  1.34930834e-02,  2.83574350e-02,\n",
       "          5.05312206e-03,  3.98241356e-02, -1.29005089e-02,  2.44815741e-02,\n",
       "         -4.00892599e-03,  1.69266500e-02, -5.67011125e-02,  5.17417900e-02,\n",
       "          4.47594523e-02, -4.88581918e-02,  4.75668386e-02,  2.30621640e-02,\n",
       "          2.47534961e-02,  1.34376287e-02, -3.36181815e-03,  6.01514950e-02,\n",
       "         -3.32446322e-02,  2.98849860e-04,  5.16168599e-04, -1.72696803e-02,\n",
       "          2.99761444e-03, -4.06516418e-02, -1.52805373e-02,  3.61409560e-02,\n",
       "          1.98472664e-02, -8.33261013e-03,  4.78333980e-02, -5.92975551e-03,\n",
       "         -3.83710191e-02,  1.23765860e-02, -9.02692962e-04,  6.95904624e-03,\n",
       "         -4.35142443e-02, -4.84817699e-02, -8.35208688e-03,  2.33621653e-02,\n",
       "         -1.36257410e-02,  2.91253682e-02, -2.22984347e-02,  1.28139462e-02,\n",
       "         -4.22944650e-02,  2.31190911e-03,  3.09176240e-02,  2.21313648e-02,\n",
       "         -3.01063359e-02, -2.70463265e-02, -6.16910942e-02, -7.30560441e-03,\n",
       "         -1.60779320e-02,  9.30150598e-03,  4.80124243e-02,  2.58610994e-02,\n",
       "          6.87842304e-03, -5.86933978e-02, -3.89287993e-02,  2.88363937e-02,\n",
       "         -3.08784787e-02, -3.27181295e-02,  2.00971104e-02, -5.10043800e-02,\n",
       "         -5.44496588e-02,  4.22191992e-02,  2.06985939e-02, -4.39082086e-03,\n",
       "         -1.47707565e-02,  1.71421021e-02,  4.91315611e-02, -2.34595388e-02,\n",
       "         -4.56311088e-03, -2.83733122e-02, -1.79980882e-02,  5.92576936e-02,\n",
       "          3.43608372e-02, -3.24944966e-02,  4.57546785e-02, -1.39566362e-02,\n",
       "         -6.15881896e-03, -3.77302617e-02, -2.66051684e-02, -4.70648743e-02,\n",
       "          3.06305140e-02,  3.12450137e-02, -1.25358924e-02, -2.13049501e-02,\n",
       "         -2.69366801e-02,  4.44384404e-02, -2.95277685e-02,  4.93511334e-02,\n",
       "          5.77164674e-03,  5.75706959e-02, -3.86559553e-02, -5.26770130e-02,\n",
       "          3.17192376e-02, -5.38075492e-02, -3.53558213e-02,  4.89742383e-02,\n",
       "         -1.00374371e-02, -7.61879375e-03, -3.90358269e-02,  1.71183292e-02,\n",
       "         -1.96223557e-02, -2.71119028e-02,  5.00863697e-03,  4.00924608e-02,\n",
       "          1.65656898e-02, -4.83052097e-02, -3.81272435e-02, -7.46236462e-03,\n",
       "         -7.86476769e-03, -3.76465097e-02,  3.80740352e-02, -1.22025944e-02,\n",
       "         -2.93614753e-02, -5.93651086e-03, -5.37864976e-02,  1.99844129e-02,\n",
       "         -8.42770655e-03, -4.44309181e-03, -1.01199131e-02, -2.77944207e-02,\n",
       "         -5.91303781e-03, -2.37309840e-02,  1.73960812e-02,  1.14892181e-02,\n",
       "          3.45523772e-03, -3.02849021e-02,  4.83796969e-02,  6.26787320e-02,\n",
       "         -4.46154643e-03,  4.69244681e-02, -4.89937216e-02, -4.51543033e-02,\n",
       "         -2.90870760e-02,  7.50242034e-03,  3.34145054e-02,  3.63119729e-02,\n",
       "          2.77324133e-02,  1.09093916e-02, -1.67119242e-02,  1.70723237e-02,\n",
       "         -3.52713689e-02,  1.31075205e-02,  5.99009022e-02,  3.83099988e-02,\n",
       "         -1.25138732e-02, -3.41627598e-02,  5.15543148e-02, -3.95930409e-02,\n",
       "          5.66074974e-04, -5.51985279e-02, -3.53523009e-02,  5.15106693e-02,\n",
       "         -4.38105613e-02,  2.16322113e-02,  4.53076847e-02, -2.69247591e-02,\n",
       "          1.80063210e-02,  1.32639827e-02, -3.92971598e-02,  2.41345111e-02,\n",
       "         -4.39642072e-02,  2.23570503e-02,  5.20254602e-04, -1.85600407e-02,\n",
       "         -1.03717921e-02, -4.17127460e-03, -5.09332940e-02, -1.96069181e-02,\n",
       "          9.22260433e-03, -2.52575278e-02, -3.34576890e-02, -3.84804346e-02,\n",
       "         -2.77120923e-03, -1.63058285e-03,  4.63750074e-03, -3.84558961e-02,\n",
       "         -3.16328593e-02,  1.11779701e-02, -2.66992347e-03, -8.73286277e-03,\n",
       "         -1.23623954e-02,  2.28746738e-02,  4.65984717e-02,  2.60525141e-02,\n",
       "          2.00816919e-03,  3.07510309e-02, -4.57889959e-02, -2.97172312e-02,\n",
       "          4.66343984e-02, -4.20152321e-02,  6.12661839e-02,  5.69322631e-02,\n",
       "         -4.73077409e-02,  5.57144657e-02, -5.62942810e-02, -8.32387991e-03,\n",
       "          2.59143710e-02,  5.32339737e-02, -2.77200378e-02,  4.03945968e-02,\n",
       "         -9.30272136e-03,  3.93740200e-02,  7.86100142e-03,  1.80881303e-02,\n",
       "          1.26431976e-02, -6.93203043e-03,  4.50567901e-02, -4.54873033e-02,\n",
       "          3.17743532e-02, -3.11502758e-02,  1.00864898e-02, -1.11214118e-02,\n",
       "         -3.63078229e-02,  5.97111285e-02,  4.20068242e-02, -3.33966017e-02,\n",
       "          5.28825633e-02,  1.87187251e-02, -4.93371896e-02, -2.19965517e-03,\n",
       "         -2.94557512e-02,  6.36243969e-02, -3.68177891e-04, -5.82983950e-03,\n",
       "         -1.78138874e-02,  1.72540285e-02, -4.53383625e-02,  4.40151356e-02,\n",
       "          4.39110920e-02,  5.48851080e-02,  5.77246733e-02, -1.58066899e-02,\n",
       "         -4.64915521e-02,  4.39152345e-02,  8.17181729e-03, -1.15657561e-02,\n",
       "          2.77400278e-02, -1.21573452e-02,  8.56904779e-03, -2.13000141e-02,\n",
       "         -8.23687576e-03,  6.29238635e-02,  4.09721285e-02,  5.23078367e-02,\n",
       "          3.42138554e-03,  1.19228680e-02,  4.32145968e-03, -1.11801941e-02,\n",
       "         -3.43329385e-02,  1.49030834e-02, -3.19961607e-02,  3.84834185e-02,\n",
       "          5.67245595e-02,  2.40119472e-02, -1.69868988e-03, -5.07788658e-02,\n",
       "         -1.15237962e-02, -1.42733511e-02, -3.09861600e-02, -2.31742002e-02,\n",
       "         -1.04483906e-02,  2.70455470e-03,  2.63084117e-02,  2.72482820e-02,\n",
       "          3.09404768e-02,  4.73995367e-03, -5.43322973e-02,  5.84437959e-02,\n",
       "         -1.50893750e-02, -2.81209941e-03, -4.68137190e-02, -5.31458631e-02,\n",
       "          6.08402165e-03,  2.65985765e-02,  2.93888450e-02, -2.99502574e-02,\n",
       "         -4.91805747e-02,  5.40159158e-02, -9.88376793e-03,  2.39555724e-02,\n",
       "          1.60733648e-02,  3.26289162e-02, -4.26198095e-02, -4.68682759e-02,\n",
       "          1.98989064e-02,  9.43958480e-03, -4.85694632e-02,  6.01534359e-03,\n",
       "          8.09296209e-04,  3.40011641e-02, -5.49990535e-02, -2.42782645e-02,\n",
       "          7.08450889e-03, -6.19160309e-02, -4.21527401e-02,  3.88983376e-02,\n",
       "          2.69861165e-02, -3.29540707e-02,  3.65138426e-02,  1.19372625e-02,\n",
       "         -4.08241414e-02,  4.15028259e-02, -1.08832121e-02, -4.28432040e-02,\n",
       "          3.15816887e-02, -6.34333026e-03, -5.91951720e-02, -2.11582072e-02,\n",
       "          5.47434911e-02,  6.39793500e-02, -1.20695699e-02, -2.30517257e-02,\n",
       "         -1.95559151e-02, -4.71741986e-03,  9.44933854e-03, -5.93474582e-02,\n",
       "         -2.42510494e-02,  4.25454602e-02,  3.89067791e-02,  2.47003306e-02,\n",
       "          2.11406350e-02, -7.94798107e-05,  2.34832312e-03, -2.55483389e-02,\n",
       "         -3.52771133e-02,  8.86865985e-03,  3.42219472e-02, -5.40050678e-04,\n",
       "          3.12668085e-02, -2.15594638e-02,  5.31776734e-02, -2.13308558e-02,\n",
       "         -4.84287627e-02, -4.26538661e-02, -3.40376273e-02, -2.87851356e-02,\n",
       "         -2.71238144e-02, -3.46888006e-02,  1.04357991e-02,  2.52845548e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 58,\n",
       "  'topic_words': array(['participants', 'cohort', 'somatosensory', 'assessed',\n",
       "         'correlation', 'measured', 'correlations', 'individual',\n",
       "         'individuals', 'evaluated', 'correlated', 'quantify',\n",
       "         'measurements', 'frequencies', 'clustering', 'numerical',\n",
       "         'correlate', 'measurement', 'total', 'metrics', 'predictors',\n",
       "         'coefficient', 'numeric', 'correlates', 'estimators', 'perceptual',\n",
       "         'scores', 'quantified', 'coefficients', 'statistical', 'groups',\n",
       "         'quantitative', 'cumulative', '측정', 'scored', 'computationally',\n",
       "         'individually', 'ratings', 'statistically', 'psychology',\n",
       "         'interaction', 'measuring', 'multivariate', 'statistic', '그룹',\n",
       "         'statistics', 'neuronal', 'metric', 'evaluation', 'alzheimers'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-0.05240946,  0.04901297,  0.01849182, -0.0053667 , -0.01314838,\n",
       "          0.04129874, -0.04221033,  0.03023016,  0.03914761,  0.05204671,\n",
       "         -0.00700273, -0.0221971 ,  0.01565237, -0.02483878, -0.05163693,\n",
       "          0.0152506 ,  0.00200236, -0.06062396,  0.00879489,  0.02376915,\n",
       "          0.01179251, -0.04656553, -0.01684673,  0.00473811, -0.06450359,\n",
       "         -0.027815  ,  0.03043095,  0.00091176, -0.04196109, -0.02180624,\n",
       "         -0.00182042, -0.00393188,  0.03135364, -0.03656979,  0.03660204,\n",
       "         -0.03808721, -0.02051017, -0.00969356, -0.01134931, -0.0406982 ,\n",
       "         -0.02010607,  0.00653207,  0.05400066, -0.02463344, -0.03642972,\n",
       "          0.02685272,  0.02850391,  0.03536027, -0.01328403, -0.0171693 ,\n",
       "          0.03934291, -0.04929248,  0.03026507, -0.03136653,  0.04988296,\n",
       "         -0.05965536, -0.00348848,  0.00954753,  0.02552404,  0.05889042,\n",
       "         -0.00989847,  0.06346492, -0.02453836, -0.045862  , -0.0026007 ,\n",
       "         -0.00481658,  0.01848776, -0.02053139, -0.04308613, -0.00739426,\n",
       "         -0.03466135,  0.01085726, -0.0214971 , -0.04505613,  0.01586293,\n",
       "         -0.02374656,  0.03588462,  0.04908974, -0.01713417, -0.06059401,\n",
       "         -0.06556258, -0.04141166,  0.03065762,  0.02108655, -0.04581875,\n",
       "          0.02900067, -0.03354213,  0.01641378,  0.00331691, -0.01028426,\n",
       "         -0.03903685, -0.04410829, -0.04257319, -0.00703131, -0.03709339,\n",
       "          0.01210154,  0.03004125,  0.04525119, -0.06055219, -0.00340301,\n",
       "          0.01192058, -0.03948884,  0.05723636, -0.03074503,  0.01144286,\n",
       "          0.02094734, -0.05506705, -0.01535529, -0.01946362,  0.01585801,\n",
       "          0.05190896, -0.05155322, -0.05235273, -0.02060782,  0.01768133,\n",
       "         -0.04578139,  0.02910953,  0.03954674, -0.01595685,  0.03566051,\n",
       "         -0.04556031,  0.04785529,  0.01351579,  0.02937466, -0.01849606,\n",
       "          0.00982627,  0.02813838,  0.0179709 , -0.03409618,  0.02827001,\n",
       "         -0.05063493, -0.03083149, -0.00818217,  0.0243846 ,  0.01488352,\n",
       "          0.06291451, -0.02235594, -0.03394852,  0.05669433,  0.03131705,\n",
       "          0.02161696, -0.0038493 , -0.00243894, -0.00323129,  0.03130649,\n",
       "          0.02311585, -0.01067123,  0.02081574,  0.05300231,  0.03673009,\n",
       "          0.05909921, -0.00942447, -0.01009638, -0.03162185, -0.04755343,\n",
       "         -0.00391149,  0.05413336, -0.00276049, -0.04723615, -0.02224768,\n",
       "          0.02765069, -0.03914923, -0.05925617,  0.00312568, -0.00181566,\n",
       "         -0.05059023,  0.0489261 ,  0.0438209 , -0.04681911,  0.0409746 ,\n",
       "         -0.03363398,  0.00130151,  0.03321889, -0.00638798, -0.01239812,\n",
       "          0.04458414,  0.01817418,  0.02554251, -0.00566782,  0.04545952,\n",
       "          0.02471722, -0.00729761,  0.00541382, -0.00646325, -0.0410988 ,\n",
       "         -0.01204369,  0.05153438,  0.05646445,  0.02385862,  0.05523219,\n",
       "         -0.01960153, -0.03972317,  0.00687017,  0.01276329, -0.01440863,\n",
       "          0.06027642, -0.0052601 , -0.01143159,  0.04128434,  0.04356714,\n",
       "         -0.03434084,  0.02514752, -0.05288847, -0.03657912, -0.02401574,\n",
       "         -0.04529177, -0.04076546,  0.05159636,  0.00270245,  0.04582115,\n",
       "          0.02116567, -0.02511257,  0.01040863, -0.00578144,  0.0400811 ,\n",
       "         -0.04159639,  0.02197791, -0.04035878, -0.03430309, -0.03381369,\n",
       "          0.00560534,  0.02942159,  0.0520831 ,  0.04044703, -0.02687712,\n",
       "         -0.02884654, -0.06072789,  0.01488508, -0.01676136, -0.05534226,\n",
       "          0.01894092,  0.04648881, -0.04064761,  0.04057171,  0.02941442,\n",
       "         -0.04158011, -0.01349705,  0.03198604,  0.06077846, -0.05567169,\n",
       "          0.00222055,  0.03227968, -0.02988631,  0.0227693 ,  0.04375176,\n",
       "         -0.03960182,  0.04926832,  0.03163597, -0.01144552, -0.00071924,\n",
       "         -0.05684379, -0.06074342,  0.02009098, -0.06171196,  0.0450725 ,\n",
       "         -0.01029617, -0.02064221, -0.00206722,  0.01705303,  0.02834573,\n",
       "         -0.02420725,  0.04617064, -0.02605573,  0.01292319,  0.0237258 ,\n",
       "         -0.04097071, -0.0376554 ,  0.03348851,  0.04480661,  0.02198846,\n",
       "         -0.00549744,  0.03846052, -0.02182965, -0.02861208,  0.03412442,\n",
       "          0.01122168, -0.05007531,  0.05985602, -0.04704118,  0.03867825,\n",
       "         -0.04306028, -0.03555761,  0.00884819,  0.01487832, -0.04044546,\n",
       "          0.03849518, -0.05175774, -0.02124725, -0.04631685,  0.0184768 ,\n",
       "          0.0448376 ,  0.05310853,  0.02857832, -0.02224299, -0.02048115,\n",
       "         -0.02416431,  0.01821843,  0.02955386,  0.04581206,  0.02960847,\n",
       "         -0.03862896,  0.03605272, -0.04313438,  0.01913472, -0.02456035,\n",
       "         -0.01615178, -0.01562681,  0.04960737, -0.0165863 ,  0.03078425,\n",
       "         -0.02267063, -0.02742551, -0.00257239, -0.05758474,  0.06332184,\n",
       "          0.04592273,  0.00579302, -0.0458348 ,  0.00691871, -0.01488555,\n",
       "         -0.00893874, -0.02579228, -0.03939497,  0.05681591,  0.01521082,\n",
       "         -0.02787007, -0.0215469 , -0.01258067, -0.00869674, -0.00490776,\n",
       "          0.00062133, -0.04285863, -0.03743652, -0.03456324,  0.03247077,\n",
       "         -0.03255587, -0.01466883, -0.00219196, -0.03467973, -0.01329137,\n",
       "         -0.04959871, -0.03424026,  0.02596493, -0.05929109, -0.02302309,\n",
       "          0.03489973,  0.05738521,  0.00242928, -0.0318095 ,  0.04179373,\n",
       "          0.0230325 ,  0.01853478,  0.02136276,  0.05106968, -0.03412763,\n",
       "          0.05842324, -0.0016642 ,  0.02366675, -0.01695379, -0.03899938,\n",
       "          0.00161805, -0.05408692,  0.05405854,  0.00041576, -0.01530023,\n",
       "          0.01058423, -0.0040327 ,  0.02688361, -0.03223693,  0.00167897,\n",
       "          0.00123156,  0.05270636, -0.03125588, -0.01333148,  0.00026135,\n",
       "         -0.00853283, -0.0019894 , -0.02012247,  0.04095265,  0.00316839,\n",
       "          0.04097703, -0.01637675,  0.0438339 ,  0.02380641, -0.03496068,\n",
       "          0.06593747,  0.00852195, -0.03867693,  0.05758737,  0.0143119 ,\n",
       "          0.04551847,  0.00868507, -0.00651232,  0.03020176, -0.00552772,\n",
       "          0.04334173,  0.06020478,  0.00770606, -0.0453794 ,  0.03305053,\n",
       "          0.03203785,  0.03602844,  0.04701682,  0.04773584, -0.04124578,\n",
       "          0.05246412,  0.0343289 , -0.02704808,  0.01813659,  0.00359899,\n",
       "          0.01049882, -0.03292982, -0.01395018,  0.03631679,  0.00803084,\n",
       "          0.04459246,  0.02793303, -0.01297639, -0.02033516,  0.02603938,\n",
       "         -0.06058913, -0.05876651,  0.03984527,  0.05007064,  0.05913663,\n",
       "          0.02250611, -0.06119256, -0.01170581,  0.02330523,  0.01984716,\n",
       "         -0.04524148,  0.00114782, -0.04514859, -0.02208279, -0.00203555,\n",
       "         -0.03054287,  0.04472493, -0.02025561, -0.06215882,  0.036814  ,\n",
       "         -0.06091507,  0.00945197,  0.02114404, -0.04423378,  0.00050325,\n",
       "          0.01986386,  0.01937894,  0.0238068 ,  0.04420206,  0.0136747 ,\n",
       "         -0.03274097, -0.00325243, -0.00144929,  0.01270696, -0.02338897,\n",
       "          0.01069762,  0.02515963, -0.00174539,  0.01768307, -0.00903585,\n",
       "         -0.02254242, -0.04400327, -0.02591927, -0.04842685, -0.03293349,\n",
       "         -0.06216402, -0.05913897, -0.03437927,  0.03428014,  0.02151549,\n",
       "          0.04246073,  0.03012709, -0.00174358,  0.01851888, -0.02117181,\n",
       "          0.00490661,  0.03024944, -0.02222514, -0.01813003, -0.03851181,\n",
       "         -0.00877334,  0.06596882, -0.04657002,  0.02051217,  0.02820026,\n",
       "          0.00302594, -0.04392924, -0.05437414, -0.02355529,  0.00071251,\n",
       "         -0.03057122, -0.00422696,  0.008226  , -0.00232136, -0.03206639,\n",
       "         -0.0272538 , -0.06041124, -0.04319236,  0.05157357,  0.01905695,\n",
       "          0.03413549, -0.0562246 ,  0.06099096, -0.01994747, -0.0388582 ,\n",
       "         -0.05458616,  0.0316742 ,  0.00032705, -0.05456118, -0.02808664,\n",
       "          0.0253196 ,  0.0408872 ], dtype=float32)},\n",
       " {'topic_idx': 59,\n",
       "  'topic_words': array(['ubuntu', 'gedit', 'linux', '우분투', 'xorg', 'kakaotalk', 'sudo',\n",
       "         'bashrc', '커널', 'unicode', 'kernel', 'stdout', '명령', 'commands',\n",
       "         'github', 'install', 'compile', 'installer', 'installation',\n",
       "         'canonical', '명령어', 'command', 'installing', 'kakao', '컴파일',\n",
       "         'normalization', 'localhost', '컴파일러', 'bootstrap', 'installed',\n",
       "         'config', 'argv', 'standardized', 'translate', 'norms', 'gencode',\n",
       "         'firefox', '설치', '윈도우', 'regularization', 'matplotlib',\n",
       "         'glutamate', 'normalize', 'utf', 'openmx', 'compiler', '부팅',\n",
       "         'normalized', 'mathbb', 'countries'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.21469414e-02, -3.32204886e-02, -1.28382156e-02,  5.21424673e-02,\n",
       "          5.01329601e-02, -5.22023253e-02,  4.28618165e-03,  4.86352742e-02,\n",
       "          3.30931656e-02, -2.25113556e-02,  4.84528206e-02, -4.84655797e-02,\n",
       "          5.21977246e-02,  1.46419266e-02,  5.49980998e-03,  2.32255757e-02,\n",
       "          1.61556974e-02,  3.37340795e-02,  5.19329011e-02,  5.16431071e-02,\n",
       "          3.91917787e-02,  5.15075289e-02,  4.51340377e-02,  5.15143126e-02,\n",
       "         -5.22022881e-02, -5.10857701e-02,  5.45050763e-03,  1.15218190e-02,\n",
       "          4.72868867e-02, -5.21126986e-02, -5.01129329e-02,  2.07163971e-02,\n",
       "         -2.59043965e-02, -5.21853082e-02, -3.25087947e-03,  3.83163802e-02,\n",
       "          5.08143753e-02, -4.96927388e-02,  5.19847423e-02, -4.60812263e-02,\n",
       "          4.79310751e-02,  4.36945073e-03, -6.95189601e-03,  9.04482149e-04,\n",
       "          2.20632806e-04, -3.55006158e-02,  5.22013456e-02, -5.13297357e-02,\n",
       "         -5.22023253e-02,  2.85533387e-02, -5.21809049e-02, -4.44008596e-02,\n",
       "          5.21770567e-02, -5.07880701e-03,  3.85930091e-02, -5.21911345e-02,\n",
       "         -4.59758788e-02,  5.06194644e-02, -1.90135073e-02,  2.17974726e-02,\n",
       "          2.95696650e-02,  5.18692918e-02,  1.69656705e-02, -5.20676970e-02,\n",
       "         -4.56246324e-02,  1.82766430e-02, -5.19041084e-02, -6.84227562e-03,\n",
       "          5.21985032e-02,  2.89851297e-02, -1.76793244e-02,  5.17213158e-02,\n",
       "          3.79917063e-02, -5.42304653e-04, -5.21840714e-02,  1.45285269e-02,\n",
       "         -4.74137962e-02, -5.08445613e-02, -5.20220809e-02, -5.22023253e-02,\n",
       "         -5.22023253e-02, -1.15729636e-02, -5.21689802e-02, -5.19944578e-02,\n",
       "          4.36002426e-02,  1.33331120e-02, -3.52211669e-02, -2.79200543e-02,\n",
       "          4.98981588e-02,  1.16590001e-02, -4.08544727e-02,  3.17850453e-03,\n",
       "         -1.19067654e-02,  3.05906683e-02,  5.21509461e-02,  9.99883842e-03,\n",
       "         -5.21339923e-02,  1.57708395e-02,  5.07056974e-02, -2.57275049e-02,\n",
       "          3.98435555e-02, -2.24992353e-02, -2.46567111e-02,  2.30209026e-02,\n",
       "          3.94422673e-02,  9.85839870e-03, -4.95854057e-02, -4.01729047e-02,\n",
       "          1.61189269e-02, -6.00047549e-03,  1.59819815e-02, -5.21717556e-02,\n",
       "          2.10400745e-02, -5.21958284e-02,  4.74015763e-03,  4.07900065e-02,\n",
       "         -1.10391714e-02,  2.82116476e-02,  9.64817684e-03,  5.16998805e-02,\n",
       "          2.10813973e-02,  5.17341634e-03, -2.23559397e-03,  1.69067848e-02,\n",
       "         -3.86575609e-02,  4.58296724e-02, -4.13405187e-02,  5.19629084e-02,\n",
       "         -9.24184918e-04, -1.89956762e-02, -2.50342917e-02,  2.38011107e-02,\n",
       "          5.22023030e-02,  3.11838910e-02,  4.24807891e-03,  2.42823716e-02,\n",
       "          4.97385375e-02, -1.08833788e-02,  5.21990173e-02,  1.01206666e-02,\n",
       "          3.27418931e-02, -1.79053117e-02, -2.13684142e-02,  3.93634476e-02,\n",
       "         -4.54251505e-02, -2.91470196e-02,  4.77110632e-02,  5.00216298e-02,\n",
       "          4.79397811e-02, -6.48375973e-03,  2.51174811e-02,  1.24723502e-02,\n",
       "         -4.63104509e-02, -5.15999943e-02, -1.58474466e-03,  3.97877134e-02,\n",
       "         -4.47738059e-02,  5.22001199e-02,  1.78787075e-02, -5.21744937e-02,\n",
       "          3.80795971e-02,  1.23403035e-02,  5.21955974e-02,  2.84412131e-03,\n",
       "          1.81059372e-02, -5.03774770e-02,  1.32464489e-03, -1.76741201e-02,\n",
       "          2.29977965e-02, -5.26905060e-03,  5.10324873e-02, -4.08658199e-02,\n",
       "         -5.19996323e-02, -4.22048522e-03, -3.93828563e-02,  5.19246906e-02,\n",
       "         -5.22023253e-02, -4.58802097e-02, -5.08808307e-02,  5.21975048e-02,\n",
       "         -1.63112786e-02,  4.99741137e-02, -3.29191387e-02, -2.34264019e-03,\n",
       "         -5.21476865e-02,  3.42236198e-02,  5.22010922e-02,  5.21644466e-02,\n",
       "         -2.07356941e-02,  5.22021763e-02,  1.24609061e-02, -5.21278493e-02,\n",
       "          5.05840369e-02,  4.86568250e-02, -4.72031385e-02,  5.21657653e-02,\n",
       "         -6.60934485e-03, -3.51018682e-02,  4.47172904e-03, -4.37262654e-02,\n",
       "         -4.58661579e-02,  1.59048324e-03, -3.38285528e-02, -3.83898728e-02,\n",
       "         -1.60252601e-02, -1.16748651e-02,  5.21024354e-02,  2.41787713e-02,\n",
       "         -3.21859382e-02,  5.05619794e-02, -2.88634282e-02,  2.02362780e-02,\n",
       "          5.13475090e-02, -4.89357822e-02, -2.56581753e-02, -1.60985887e-02,\n",
       "         -1.19642420e-02, -3.86231653e-02, -1.33974254e-02,  2.29754355e-02,\n",
       "          1.47475572e-02,  1.08989552e-02,  4.85750623e-02,  4.77591120e-02,\n",
       "         -5.22022210e-02, -2.04622354e-02, -3.99135984e-02,  5.04423724e-03,\n",
       "         -1.07495822e-02, -3.98363993e-02, -5.22010773e-02,  5.03401868e-02,\n",
       "          4.63115089e-02, -4.09547798e-02,  4.91165780e-02,  5.19886315e-02,\n",
       "         -5.08663356e-02,  5.19238748e-02,  3.15467380e-02, -2.58268882e-03,\n",
       "          1.72057841e-02,  2.17303392e-02,  1.31057231e-02,  2.52623949e-02,\n",
       "          1.92023329e-02, -1.89803299e-02,  2.34869923e-02,  2.24995869e-03,\n",
       "          5.11977375e-02, -1.70286354e-02, -5.09952791e-02, -2.38674525e-02,\n",
       "         -4.73733731e-02,  4.97601628e-02,  2.10112259e-02, -4.36150581e-02,\n",
       "         -5.18795103e-02,  3.22596845e-03, -2.56939828e-02, -1.86099689e-02,\n",
       "         -3.07023209e-02,  5.20465970e-02, -4.53889966e-02,  3.77844274e-03,\n",
       "          5.02223484e-02, -5.21349944e-02, -1.12414621e-02,  2.25403011e-02,\n",
       "         -1.73700042e-02,  1.60086621e-02,  5.20321429e-02, -1.67600960e-02,\n",
       "         -2.38886476e-02,  4.14081849e-02,  5.18724769e-02,  1.00487247e-02,\n",
       "          4.85767014e-02, -5.05393408e-02, -3.72908525e-02,  5.05835116e-02,\n",
       "          5.20998724e-02,  5.05948924e-02, -1.04224822e-02, -1.45054432e-02,\n",
       "         -3.08795068e-02,  8.49203765e-03, -5.21791764e-02,  3.66454944e-02,\n",
       "          2.82343458e-02,  1.19226621e-02, -2.36020852e-02,  1.99188013e-02,\n",
       "         -2.64082127e-03,  4.10703681e-02, -5.22023179e-02, -4.18880172e-02,\n",
       "         -2.94513796e-02,  4.67808396e-02,  8.18731729e-03,  8.99648760e-03,\n",
       "          1.13778217e-02, -1.44251073e-02,  7.37366593e-03, -5.17297052e-02,\n",
       "          1.35558052e-02, -2.06493288e-02, -1.61731411e-02, -8.81256908e-03,\n",
       "          4.37792800e-02,  6.47720741e-03,  1.41890720e-02, -5.31475386e-03,\n",
       "         -1.51526928e-02,  2.90085003e-02,  1.29670352e-02,  4.46732156e-02,\n",
       "          5.13203777e-02, -4.78112847e-02,  2.46039350e-02, -4.56712246e-02,\n",
       "         -2.09490955e-02,  4.55831885e-02,  6.17449032e-03,  4.19342853e-02,\n",
       "          5.09078056e-02,  5.18616028e-02, -5.22002988e-02, -5.06488942e-02,\n",
       "         -2.30890512e-02, -3.88607085e-02, -5.14555275e-02, -4.62299474e-02,\n",
       "         -5.19500226e-02,  4.76258360e-02,  1.42929060e-02,  4.94105630e-02,\n",
       "          1.80301834e-02, -1.24619445e-02, -5.21989055e-02, -4.90361117e-02,\n",
       "         -1.71796959e-02,  3.30314450e-02,  1.66289862e-02, -3.86035293e-02,\n",
       "          2.84807980e-02, -1.56354047e-02, -9.80218034e-03, -3.76557596e-02,\n",
       "         -4.55861874e-02,  5.19780349e-03,  4.35178876e-02,  7.05128023e-03,\n",
       "          2.59130988e-02, -5.21995761e-02,  5.16467206e-02, -9.86214820e-03,\n",
       "         -2.19974685e-02,  4.54127192e-02,  9.54120699e-03, -4.21058349e-02,\n",
       "         -1.36740161e-02,  9.51921009e-03,  5.19969650e-02, -1.83907226e-02,\n",
       "          5.18035777e-02, -4.92971539e-02,  4.97762896e-02, -6.22092187e-03,\n",
       "         -5.21528982e-02,  4.56447862e-02, -3.86178531e-02, -3.40588833e-03,\n",
       "          4.73480225e-02, -4.45625447e-02,  2.41187513e-02, -2.18168814e-02,\n",
       "         -5.18147051e-02,  7.46581377e-03,  5.22010624e-02, -5.17031886e-02,\n",
       "         -4.24448065e-02, -5.20830303e-02, -3.34952283e-03, -5.22022955e-02,\n",
       "          4.58705761e-02,  5.16505651e-02,  2.12893616e-02, -5.22022359e-02,\n",
       "         -1.73429046e-02,  2.97690555e-02, -4.67171073e-02, -3.43116559e-02,\n",
       "          4.94044274e-02, -4.63774391e-02, -3.34770195e-02,  1.18315639e-02,\n",
       "          6.35042554e-03,  3.33488062e-02,  5.22009693e-02, -1.63609963e-02,\n",
       "          4.68096137e-02, -4.84073944e-02,  5.21966033e-02,  1.79696046e-02,\n",
       "         -4.26343568e-02,  4.07289006e-02,  1.10962763e-02, -4.79192548e-02,\n",
       "          1.22400587e-02,  2.14052852e-02, -2.51749028e-02,  5.16027510e-02,\n",
       "          8.93585384e-05,  2.78593469e-02,  3.26749682e-02, -2.71774456e-02,\n",
       "          3.71123366e-02,  3.18354703e-02, -3.95547338e-02, -4.58748527e-02,\n",
       "          5.14539778e-02, -7.81132886e-03,  4.83295918e-02, -5.95899066e-03,\n",
       "         -3.15569639e-02,  5.20106591e-02,  4.99115102e-02, -5.10145575e-02,\n",
       "         -7.56372884e-03, -5.06023020e-02,  2.34164787e-03,  4.54004668e-02,\n",
       "         -3.70513313e-02,  3.15534025e-02,  1.40409358e-02,  3.26402523e-02,\n",
       "         -1.96406487e-02,  4.94541526e-02, -4.98026647e-02, -1.29843019e-02,\n",
       "         -5.20651974e-02, -8.77334923e-03, -1.81525350e-02, -2.20495854e-02,\n",
       "         -4.22901325e-02, -1.11914473e-02,  5.06035350e-02,  3.64246219e-02,\n",
       "          5.09235561e-02, -1.39630241e-02,  5.15481532e-02,  5.21698743e-02,\n",
       "         -5.22010885e-02,  1.57335494e-02, -5.20527661e-02,  1.65937264e-02,\n",
       "          5.21981269e-02, -1.32462652e-02,  1.91695560e-02,  4.20468040e-02,\n",
       "          4.17791121e-02, -3.85756157e-02,  5.00036664e-02,  4.37681414e-02,\n",
       "         -1.77037772e-02, -5.21207564e-02,  5.08732311e-02,  5.19256294e-02,\n",
       "          5.14499657e-02, -4.84020710e-02,  5.07846661e-02, -5.21776713e-02,\n",
       "          7.43309036e-03,  3.04287095e-02, -5.19894809e-02,  2.55527403e-02,\n",
       "         -2.73559242e-02, -1.45880701e-02,  1.35442913e-02,  4.46392857e-02,\n",
       "         -2.34598550e-03,  3.97238657e-02, -3.04674823e-02, -1.33814430e-02,\n",
       "          1.73723400e-02, -3.09796724e-02,  1.40988966e-02, -5.22022694e-02,\n",
       "         -1.92479324e-02, -4.93903346e-02,  4.17310335e-02,  4.00582217e-02,\n",
       "         -8.92374839e-04,  1.43881142e-02,  3.17934267e-02, -3.86729054e-02,\n",
       "         -5.21980934e-02, -2.23664418e-02,  3.50446701e-02,  3.82993780e-02,\n",
       "          1.29294498e-02,  5.22023253e-02,  4.23142165e-02,  1.70280896e-02,\n",
       "         -2.05373708e-02, -5.22023253e-02, -2.45132204e-02,  8.37174535e-04,\n",
       "          1.02863675e-02, -1.58275124e-02, -2.03828979e-02,  4.01752554e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 60,\n",
       "  'topic_words': array(['epidemic', '인구', '통계청', 'statistically', 'statistical',\n",
       "         'population', '서울', 'trend', '한국', 'statistic', '서울대',\n",
       "         'statistics', '데이터', 'seoul', 'populations', '통계', 'trends',\n",
       "         'prevalence', 'tendency', 'outcomes', 'data', 'korea',\n",
       "         'correlation', '서울시', 'correlations', 'affected', 'deaths', '떨어지',\n",
       "         '손상', '사망', 'injuries', 'decreasing', 'incidence', 'correlates',\n",
       "         'std', 'outcome', 'stats', 'correlated', 'demographic', '확률',\n",
       "         'deviations', 'correlate', 'korean', '피해자', 'causal', 'news',\n",
       "         'regression', 'deviation', 'scaling', 'severity'], dtype='<U15'),\n",
       "  'topic_vector': array([ 1.96141507e-02, -2.16166116e-02, -3.29726096e-03, -1.46355061e-02,\n",
       "          1.30760185e-02,  1.02614798e-02,  1.55214230e-02,  4.08420414e-02,\n",
       "         -4.89295125e-02,  4.15787064e-02, -1.12234475e-03,  2.68322658e-02,\n",
       "         -4.31178249e-02, -2.01888918e-03, -7.75660481e-03,  1.30247567e-02,\n",
       "         -8.59066006e-03, -1.86049882e-02, -3.12338714e-02,  4.65697981e-02,\n",
       "          1.11338906e-02, -3.43111306e-02, -3.07890177e-02,  2.16227584e-02,\n",
       "         -6.03112504e-02,  1.96521934e-02,  4.17826697e-02,  1.07534230e-02,\n",
       "          6.30130693e-02, -5.40406592e-02, -5.58225103e-02, -6.29471242e-02,\n",
       "          2.56362092e-03, -1.90644199e-03,  8.60086922e-03, -4.60045338e-02,\n",
       "         -1.57523975e-02, -8.19836929e-03, -1.31521290e-02, -4.11333181e-02,\n",
       "          3.21406536e-02, -2.25705281e-02,  2.76054647e-02, -5.39187938e-02,\n",
       "          7.74894794e-03, -6.18928559e-02,  2.18029208e-02, -2.81404592e-02,\n",
       "         -4.20497917e-02, -4.40110564e-02, -3.38511262e-03, -5.14722392e-02,\n",
       "          2.87929587e-02, -2.20679305e-03,  5.39605431e-02, -6.36645332e-02,\n",
       "          5.72418161e-02,  3.02536972e-03,  1.09275058e-03,  5.62083498e-02,\n",
       "         -5.36224153e-03,  6.22095540e-02, -4.38137911e-03, -1.73687320e-02,\n",
       "         -3.63715403e-02,  4.98012379e-02,  4.13935445e-02, -6.48876131e-02,\n",
       "          1.19292941e-02,  6.07895628e-02,  2.01849863e-02,  5.66686094e-02,\n",
       "          3.29708569e-02, -5.45572788e-02, -7.38590816e-03,  1.34671973e-02,\n",
       "          6.43359423e-02,  1.64612290e-03, -2.71600820e-02, -4.07011360e-02,\n",
       "         -6.79809526e-02, -6.50532246e-02,  6.03267737e-02,  3.15993614e-02,\n",
       "         -6.18943274e-02, -1.26846191e-02, -6.64291307e-02, -4.03022803e-02,\n",
       "          3.08375955e-02, -3.63658853e-02,  1.92520209e-04, -6.31221337e-03,\n",
       "         -1.31738903e-02,  1.48704927e-02, -4.31546383e-03, -3.40156257e-05,\n",
       "          2.79216412e-02,  6.14980534e-02, -2.98162643e-03, -1.05648888e-02,\n",
       "          2.95651071e-02,  1.23834107e-02, -9.90233384e-03,  3.42942774e-02,\n",
       "         -1.92833561e-02,  5.98534495e-02, -5.12784645e-02, -2.70888824e-02,\n",
       "          1.13071958e-02, -9.83484089e-03,  5.48543558e-02,  4.57554404e-03,\n",
       "          1.52624426e-02,  3.67458835e-02,  4.39891545e-03,  1.54696032e-03,\n",
       "         -5.29055484e-03,  2.66935304e-02, -4.46017943e-02, -4.16103937e-03,\n",
       "          1.07591841e-02,  4.67460863e-02,  5.27790375e-02, -4.15434800e-02,\n",
       "          1.97240282e-02,  6.20014891e-02,  2.11144574e-02,  5.02693560e-03,\n",
       "         -4.37108129e-02,  5.31560630e-02, -1.36929248e-02, -4.36604172e-02,\n",
       "          2.74349749e-02,  8.53080954e-03, -1.53947249e-03,  6.67226985e-02,\n",
       "          1.73790865e-02,  2.85532139e-02,  6.46823868e-02,  3.51112187e-02,\n",
       "          3.14250588e-02, -4.24860679e-02,  4.95494306e-02,  2.87633874e-02,\n",
       "          5.34697250e-02, -3.77830490e-02,  4.62060608e-02, -1.77014060e-02,\n",
       "          5.08771762e-02,  3.62871066e-02,  5.95322177e-02,  1.30280815e-02,\n",
       "         -3.38433385e-02,  5.19008823e-02, -1.98948812e-02,  9.31059942e-04,\n",
       "         -2.30139121e-02, -2.30067549e-03,  5.01369573e-02, -5.29345274e-02,\n",
       "         -4.38068770e-02, -6.96585476e-02, -3.01058218e-02,  1.44133642e-02,\n",
       "         -2.70948038e-02, -5.07463664e-02,  4.16010879e-02,  5.67685300e-03,\n",
       "         -2.53389366e-02, -3.96976657e-02,  2.22670976e-02,  3.81502248e-02,\n",
       "         -3.58491987e-02,  6.59568189e-03,  5.65112866e-02,  1.76202543e-02,\n",
       "          1.80005580e-02,  2.96265166e-03, -5.50701208e-02,  6.34207353e-02,\n",
       "          4.87929955e-02, -5.73803484e-02,  7.20982626e-03,  5.10386378e-02,\n",
       "          3.67134325e-02,  1.10537056e-02,  3.91411632e-02,  6.27400503e-02,\n",
       "         -6.24095425e-02, -1.74533557e-02, -1.36009837e-02,  7.71130249e-03,\n",
       "         -3.38061303e-02, -2.00896934e-02, -3.34270522e-02,  1.16223488e-02,\n",
       "          8.86139832e-03, -3.17323394e-03,  2.26757154e-02,  4.02677581e-02,\n",
       "         -4.77249324e-02, -7.78028928e-03,  4.36370783e-02, -4.73964140e-02,\n",
       "         -5.90169765e-02, -5.44828437e-02,  1.24403704e-02,  2.34389789e-02,\n",
       "          2.24385746e-02,  6.03517778e-02, -5.95099889e-02,  4.51991260e-02,\n",
       "         -5.45529611e-02, -3.20094675e-02, -1.83892567e-02,  3.51404622e-02,\n",
       "         -3.04033849e-02, -2.89933290e-04, -6.77726269e-02,  3.89181525e-02,\n",
       "         -4.60206345e-02,  5.03033996e-02,  3.32984217e-02,  5.22923172e-02,\n",
       "          3.62711735e-02,  1.29516423e-02, -5.11657260e-02,  5.46247466e-03,\n",
       "          2.08429024e-02, -3.82243022e-02,  2.15327255e-02, -6.07387349e-02,\n",
       "         -5.39411344e-02,  3.65190990e-02,  3.53629552e-02, -5.32682389e-02,\n",
       "         -1.20585030e-02, -2.48442590e-02,  2.78039984e-02, -3.55241969e-02,\n",
       "          2.99815889e-02, -4.78915647e-02,  3.18524241e-03,  4.99641225e-02,\n",
       "          1.23070246e-02, -3.57788913e-02,  4.87783812e-02,  5.15938364e-03,\n",
       "          1.55476481e-02, -2.91773267e-02, -5.87415621e-02, -4.36475724e-02,\n",
       "         -3.06504965e-03,  6.26379326e-02, -1.04599856e-02, -4.31384295e-02,\n",
       "         -4.85001057e-02,  4.19067703e-02, -4.63103093e-02,  6.45552352e-02,\n",
       "          4.41492237e-02,  2.52463743e-02, -3.16562951e-02, -1.12475771e-02,\n",
       "          4.05411571e-02, -4.82390970e-02, -3.76142114e-02,  4.71303761e-02,\n",
       "          4.79357131e-02,  2.88249981e-02, -4.79082055e-02, -9.14875790e-03,\n",
       "         -3.24550318e-03, -7.48438295e-03, -2.91646342e-03,  2.38637626e-03,\n",
       "          1.92786101e-03, -3.59331742e-02, -5.88199422e-02, -5.60819358e-02,\n",
       "         -3.43371369e-02, -3.40078883e-02,  6.00259751e-02, -4.71761376e-02,\n",
       "         -9.34778713e-03, -2.14609355e-02, -2.15838701e-02,  1.74943525e-02,\n",
       "         -4.35975008e-02,  5.24453539e-03,  1.53575046e-02,  2.88122185e-02,\n",
       "          5.94600616e-03,  2.12934148e-02, -4.14274745e-02,  6.51673414e-03,\n",
       "         -8.97849910e-03, -2.42087748e-02,  6.11754805e-02,  2.14375369e-02,\n",
       "         -2.34236009e-04,  6.36979938e-02, -2.45401487e-02, -4.05011475e-02,\n",
       "         -3.78639065e-02, -3.62932831e-02,  5.68045042e-02,  1.94596667e-02,\n",
       "         -6.15808833e-03, -1.13080190e-02, -5.93392104e-02, -1.60989109e-02,\n",
       "         -3.97724323e-02,  2.74363793e-02,  4.29232568e-02,  3.21322531e-02,\n",
       "         -1.88213214e-02, -3.41238491e-02,  8.72567669e-03, -4.07991000e-02,\n",
       "          3.37959900e-02, -6.52053654e-02,  3.31021920e-02,  4.89132069e-02,\n",
       "         -6.43145889e-02,  3.63300927e-02,  3.01179476e-02,  1.72434188e-02,\n",
       "         -3.74934822e-03,  1.10263042e-02, -3.35579813e-02,  2.29659565e-02,\n",
       "         -6.55706003e-02,  3.92126702e-02, -5.24050780e-02, -1.08881313e-02,\n",
       "         -1.61029398e-02,  2.40817666e-02, -3.48728597e-02, -2.47040819e-02,\n",
       "         -5.24679460e-02,  1.39456429e-02, -4.36010137e-02, -2.68651340e-02,\n",
       "         -5.74897490e-02,  3.05241346e-02,  2.13174913e-02, -2.52113771e-02,\n",
       "         -3.48167755e-02,  4.01913039e-02,  6.36363123e-03,  4.19010594e-02,\n",
       "          5.50965667e-02,  3.22829559e-02,  5.04098684e-02,  3.61742638e-02,\n",
       "         -2.90033445e-02,  4.60591726e-02, -5.73354475e-02, -6.31396621e-02,\n",
       "          4.78023291e-02, -1.66251771e-02,  6.74521700e-02,  5.28168008e-02,\n",
       "         -1.73146129e-02, -1.75356679e-02, -5.09301797e-02, -4.93376181e-02,\n",
       "          3.00036166e-02,  6.13590777e-02,  9.16406326e-03,  4.54796739e-02,\n",
       "         -3.32425050e-02, -5.90180978e-03,  4.74621430e-02, -1.26213767e-03,\n",
       "          4.33701649e-02, -1.54475290e-02,  2.90911030e-02, -3.16765904e-02,\n",
       "          2.36502010e-02, -3.36077511e-02, -4.81872074e-02,  5.61878532e-02,\n",
       "          1.97921656e-02,  6.34557530e-02,  9.33385268e-03, -4.83135246e-02,\n",
       "          5.23285568e-02, -9.95346345e-04, -2.28843000e-02, -1.26695093e-02,\n",
       "          1.17775677e-02,  6.43322021e-02,  6.14154786e-02, -2.26084776e-02,\n",
       "         -5.57070822e-02,  5.08322082e-02, -1.01918913e-02,  3.53452154e-02,\n",
       "          3.08572985e-02,  6.53501749e-02,  6.41128421e-02,  1.63778700e-02,\n",
       "         -5.51464558e-02,  4.46362421e-02,  9.35915858e-04, -2.08051153e-03,\n",
       "          3.85676958e-02,  8.39797780e-03,  2.64710151e-02, -3.85797583e-02,\n",
       "         -9.63605940e-03,  2.87099816e-02,  2.00007409e-02,  6.15839399e-02,\n",
       "          2.72676013e-02,  2.26150174e-02, -1.26506593e-02, -2.28581131e-02,\n",
       "         -5.76575696e-02, -2.45623142e-02, -2.58367397e-02,  6.35605678e-02,\n",
       "          4.83325534e-02,  1.33266021e-02, -1.59982103e-03, -4.81518358e-02,\n",
       "          3.47408950e-02,  2.93419696e-02, -6.33253306e-02, -4.19714209e-03,\n",
       "          1.00855902e-03, -1.39451642e-02,  2.61611156e-02, -4.12265845e-02,\n",
       "          3.79531346e-02, -2.70410720e-03, -5.79657257e-02,  4.80403937e-02,\n",
       "         -2.20534578e-02, -1.94593742e-02, -7.97640719e-03, -4.39879522e-02,\n",
       "         -2.19606748e-03,  3.56356353e-02,  4.14470397e-02,  5.97525015e-03,\n",
       "         -4.52709347e-02,  3.51838022e-02, -2.46789381e-02,  3.87472883e-02,\n",
       "          4.70789671e-02,  1.20634884e-02, -6.98330104e-02, -2.38774344e-02,\n",
       "          1.81881152e-02, -1.74648613e-02, -2.19158605e-02, -3.43290418e-02,\n",
       "          1.13545759e-02, -4.99061458e-02,  4.37330641e-03, -4.41924594e-02,\n",
       "          1.31323170e-02, -6.09811246e-02, -3.14460099e-02,  5.23725562e-02,\n",
       "          1.90436449e-02,  4.39828541e-03,  3.57901789e-02,  4.28011045e-02,\n",
       "         -3.51219848e-02,  1.40321907e-03, -4.24937047e-02, -4.96331193e-02,\n",
       "          5.47387227e-02, -1.93771087e-02, -5.16179428e-02, -5.50323129e-02,\n",
       "          6.19578585e-02,  7.05222785e-02,  3.82802915e-03, -5.56061231e-02,\n",
       "         -1.05134863e-02,  3.99901345e-02, -5.48814097e-03, -6.47057593e-02,\n",
       "         -3.81768234e-02,  2.68245433e-02,  2.69223563e-02, -4.56468575e-02,\n",
       "          1.67510398e-02, -1.39145227e-02, -4.81046960e-02,  5.06633148e-03,\n",
       "         -3.48990075e-02,  4.15609106e-02,  4.06516194e-02,  1.52429454e-02,\n",
       "          1.21996747e-02, -5.11626676e-02,  6.12922125e-02, -2.75916569e-02,\n",
       "         -5.94195910e-02, -5.95513508e-02, -9.58448276e-03, -3.13718691e-02,\n",
       "         -1.10396072e-02, -5.83653301e-02, -2.40805745e-03, -3.10903993e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 61,\n",
       "  'topic_words': array(['tensorflow', 'python', 'numpy', 'matplotlib', 'cython', 'sklearn',\n",
       "         '파이썬', 'scipy', 'nipype', 'subprocess', 'multiprocessing',\n",
       "         'github', 'stdout', 'tutorial', 'fov', 'workflow', 'graphics',\n",
       "         'ggplot', 'graphical', 'dataframe', 'interfaces', 'visualizations',\n",
       "         '소개', 'dict', 'introduction', 'graphs', 'gaussian', '그래픽',\n",
       "         'ubuntu', 'lineplot', 'presentations', 'scatterplot',\n",
       "         'exponential', 'synaptic', 'pip', 'visualization', 'neural',\n",
       "         'preprocessing', 'bootstrap', 'plugins', 'interface',\n",
       "         'documentation', 'hippocampus', '그래프', 'neurobiology', '우분투', '모델',\n",
       "         '뉴턴', 'overview', 'boxplot'], dtype='<U15'),\n",
       "  'topic_vector': array([-6.72461689e-02, -9.33003705e-03, -1.55963907e-02, -2.27428898e-02,\n",
       "          6.70529529e-03, -6.49494454e-02,  2.24374700e-03,  1.71283949e-02,\n",
       "          5.99351786e-02,  2.02597547e-02,  1.69473067e-02,  3.75724398e-04,\n",
       "          4.64719534e-02,  4.06414084e-02, -4.01783697e-02, -9.66414809e-03,\n",
       "          5.20411544e-02,  2.06682067e-02,  5.89714162e-02,  4.16031070e-02,\n",
       "          3.60845514e-02,  3.21317352e-02, -1.57151988e-03,  6.57879561e-02,\n",
       "         -6.74191043e-02, -4.48338799e-02,  3.45782697e-04,  1.24476282e-02,\n",
       "          4.83540557e-02, -6.24758564e-02, -3.33985835e-02,  1.44304847e-02,\n",
       "          2.19919290e-02, -6.57209158e-02,  9.67596378e-03,  5.73258661e-02,\n",
       "         -2.47540441e-03, -2.69077718e-02,  1.63129997e-02,  2.35347357e-02,\n",
       "          1.54271116e-02,  4.73439582e-02, -2.50798091e-02,  3.22317034e-02,\n",
       "         -6.33192202e-03,  5.52920662e-02,  3.28350775e-02,  3.11142970e-02,\n",
       "         -5.24025708e-02, -3.02150492e-02, -3.47230956e-02, -5.42748980e-02,\n",
       "         -2.96844095e-02, -2.78007463e-02,  5.61274700e-02, -6.79256096e-02,\n",
       "          1.04678273e-02,  6.32160082e-02,  2.69851070e-02,  4.58509736e-02,\n",
       "         -1.31338723e-02,  3.58850919e-02,  1.95724908e-02, -4.68928255e-02,\n",
       "         -2.09939972e-04,  5.19067049e-03, -7.25082727e-03, -3.23120616e-02,\n",
       "          4.22393233e-02, -3.72695588e-02, -4.89061177e-02, -1.32885324e-02,\n",
       "          2.62226420e-03, -5.88796276e-04,  2.48424243e-02, -3.47377397e-02,\n",
       "         -4.02280241e-02,  1.65330134e-02,  2.92852651e-02, -6.93405271e-02,\n",
       "         -6.96263388e-02, -9.32286028e-03, -2.11359411e-02,  3.93414535e-02,\n",
       "          5.65477051e-02, -5.78533811e-03, -1.72766056e-02, -5.70235355e-03,\n",
       "          2.90713236e-02,  3.22615579e-02, -7.84542132e-03, -7.59674236e-03,\n",
       "          5.72842471e-02, -4.34954055e-02,  2.01258082e-02,  5.69193214e-02,\n",
       "         -3.62063013e-02,  4.20801342e-02,  6.08935719e-03,  4.44960454e-03,\n",
       "          5.08299144e-03, -6.01442531e-03, -1.68984812e-02,  2.86543388e-02,\n",
       "          4.70525958e-02, -1.04870172e-02, -5.55264615e-02,  1.85515974e-02,\n",
       "          3.57947052e-02,  4.33311276e-02,  2.51965169e-02, -4.31235246e-02,\n",
       "         -2.76446175e-02, -2.21918318e-02,  4.10400927e-02,  2.59322170e-02,\n",
       "         -5.27897440e-02, -2.20695268e-02,  2.61953715e-02,  1.06027192e-02,\n",
       "         -1.06595391e-02, -3.66393737e-02, -3.30633856e-03,  5.56472056e-02,\n",
       "          4.67444919e-02, -4.92443852e-02, -3.65766324e-02,  1.45148521e-03,\n",
       "          3.07388306e-02, -4.36186194e-02, -5.40485084e-02,  2.60896590e-02,\n",
       "          6.44797906e-02,  5.69724552e-02, -1.46977529e-02,  5.32801636e-02,\n",
       "          2.11479943e-02, -4.20034379e-02,  3.11703477e-02,  4.39442880e-02,\n",
       "         -5.79058714e-02, -1.94138009e-02,  6.95611164e-03,  6.07472397e-02,\n",
       "         -4.45817746e-02, -2.23727673e-02, -5.27907796e-02,  6.32713959e-02,\n",
       "          8.99349432e-03, -2.59125978e-02,  4.61062603e-02,  3.18543278e-02,\n",
       "          3.54347005e-03, -5.83420799e-04, -2.60329619e-02, -2.56661070e-03,\n",
       "         -4.45950441e-02, -5.42759299e-02, -2.53486242e-02,  2.81898733e-02,\n",
       "          4.33725007e-02,  4.65412764e-03,  4.19293828e-02,  5.13127260e-02,\n",
       "          1.66992079e-02,  7.27496902e-03, -2.84561720e-02,  2.32421309e-02,\n",
       "         -1.36424899e-02,  3.09337918e-02,  4.69445288e-02, -1.31996619e-02,\n",
       "          2.32388917e-02,  2.10709348e-02, -1.51403071e-02,  1.98300723e-02,\n",
       "         -6.55821115e-02,  3.16054486e-02, -6.74592331e-02,  4.26438861e-02,\n",
       "         -1.43321082e-02,  2.08386928e-02, -2.17658910e-03, -4.64399904e-02,\n",
       "         -5.64729013e-02, -2.76107788e-02,  6.06936924e-02,  1.99893415e-02,\n",
       "         -3.61880548e-02,  2.42097396e-02, -4.35590511e-03, -3.62508968e-02,\n",
       "          3.91843431e-02,  4.11644839e-02, -4.87192115e-03,  3.64402495e-02,\n",
       "         -5.29560447e-02, -4.55529056e-02,  6.30107597e-02,  4.97080386e-02,\n",
       "         -2.42177565e-02,  5.27328737e-02, -4.20960784e-02, -5.80698550e-02,\n",
       "         -3.58936600e-02,  4.48740013e-02, -1.10680787e-02,  4.39979276e-03,\n",
       "          1.39736757e-02,  2.23497543e-02, -1.60911884e-02, -2.28722245e-02,\n",
       "         -1.86164558e-04, -3.06886807e-02,  2.90983897e-02,  3.22079897e-04,\n",
       "          4.35940921e-04, -3.13870199e-02,  7.35675776e-03, -1.15810335e-03,\n",
       "         -1.23776905e-02, -2.99434308e-02, -8.25062394e-04, -1.71765387e-02,\n",
       "         -6.82205111e-02,  3.66211385e-02, -5.58331013e-02,  2.34306548e-02,\n",
       "          4.99947183e-02,  3.84057127e-02,  3.10456124e-03,  6.52322695e-02,\n",
       "          3.07532679e-02,  2.13661790e-02,  3.60966101e-03,  3.06386352e-02,\n",
       "         -3.49817127e-02,  5.64024225e-03,  6.22437149e-02,  1.52039006e-02,\n",
       "         -2.04970259e-02,  1.46058062e-02,  8.20872653e-03,  1.81818623e-02,\n",
       "          1.77289471e-02, -6.66918308e-02, -4.19354206e-03, -3.98014784e-02,\n",
       "          1.52334049e-02, -4.97885160e-02, -1.99586395e-02, -3.85224335e-02,\n",
       "          3.03833429e-02, -2.64852047e-02,  3.43961418e-02,  1.39568839e-03,\n",
       "          2.48223022e-02, -2.69401800e-02,  1.72061939e-02, -2.16481904e-03,\n",
       "          2.50366330e-02,  2.24137679e-02, -1.98900308e-02, -5.91647811e-02,\n",
       "          3.00158206e-02, -5.46023659e-02,  4.01296951e-02,  3.16415019e-02,\n",
       "          4.33253944e-02,  1.21195763e-02, -9.54014715e-03, -4.50681746e-02,\n",
       "         -2.27415506e-02,  1.18486760e-02,  1.20028155e-02,  3.27990279e-02,\n",
       "          1.03819678e-02, -8.76446441e-03, -4.86333370e-02,  2.97839846e-02,\n",
       "         -1.63930971e-02,  9.22109932e-04, -1.43004274e-02, -2.02500541e-02,\n",
       "          1.56211676e-02,  2.17579454e-02, -9.68649518e-03, -4.21237350e-02,\n",
       "          2.29072180e-02,  4.31924164e-02,  3.68752405e-02,  2.70280316e-02,\n",
       "          3.76232788e-02,  6.27766177e-02, -6.83297813e-02, -1.24075590e-03,\n",
       "         -4.28823084e-02,  5.28325327e-02,  2.82845776e-05,  6.82166442e-02,\n",
       "          1.22234039e-02,  4.44601364e-02,  1.13144936e-02, -4.85577136e-02,\n",
       "          3.43838074e-05, -4.24218923e-02, -4.43567596e-02,  2.77312044e-02,\n",
       "          2.97519397e-02,  3.21158171e-02, -3.39483768e-02,  4.37292969e-03,\n",
       "         -4.42849100e-02,  8.04058649e-03, -1.14124874e-02,  2.73770597e-02,\n",
       "          6.11129552e-02, -1.35938525e-02,  4.08186257e-04, -1.68967135e-02,\n",
       "          4.62948494e-02, -2.69709583e-02, -2.87493337e-02, -1.91398954e-03,\n",
       "          5.02533168e-02, -2.34045386e-02, -5.43825217e-02, -4.16085124e-02,\n",
       "         -3.31693739e-02, -1.93380024e-02,  1.60418786e-02, -2.23134365e-02,\n",
       "         -4.25658263e-02, -1.88949574e-02, -4.93535437e-02,  1.13644330e-02,\n",
       "         -2.02111434e-02,  2.16651764e-02, -6.95347935e-02, -3.25935297e-02,\n",
       "         -3.73709872e-02,  5.04695065e-02, -1.29682897e-02, -2.48085037e-02,\n",
       "          9.11505055e-03, -2.46567558e-02,  3.61259803e-02,  2.56787222e-02,\n",
       "          1.16027258e-02, -5.87321492e-03, -3.61227989e-03, -4.19196934e-02,\n",
       "          4.03932519e-02, -6.18916340e-02, -2.55007520e-02,  1.13496734e-02,\n",
       "          4.35207374e-02,  2.65013073e-02, -3.79838087e-02, -2.02713944e-02,\n",
       "          1.87626909e-02,  9.66590736e-03,  1.98454019e-02, -6.12132512e-02,\n",
       "         -1.40910847e-02, -4.50157262e-02,  1.19870650e-02,  2.11312678e-02,\n",
       "         -5.31868124e-03, -1.95554048e-02,  3.52386758e-03,  3.01061813e-02,\n",
       "         -3.49346548e-02, -4.35265899e-03, -9.32318810e-03, -5.57990782e-02,\n",
       "          1.78011525e-02,  2.24810038e-02, -7.91425293e-04, -6.23048842e-02,\n",
       "         -6.11007176e-02, -3.19978967e-02,  3.32437083e-03, -5.44581600e-02,\n",
       "         -9.03675891e-03,  3.22767645e-02,  3.22369598e-02, -4.91008162e-02,\n",
       "          1.14285378e-02,  5.46061434e-02,  5.06035276e-02, -4.90673184e-02,\n",
       "         -4.10701819e-02,  1.28251417e-02, -1.00083053e-02, -3.03787794e-02,\n",
       "          2.68051680e-02,  1.77272817e-03, -2.65774578e-02,  8.87241680e-03,\n",
       "          3.44385058e-02, -5.99502260e-03,  6.23019934e-02, -4.87290509e-02,\n",
       "          5.81624210e-02,  4.42846715e-02,  2.26737950e-02, -6.22847080e-02,\n",
       "          2.09431276e-02,  2.06493232e-02,  9.88061819e-03,  4.52603884e-02,\n",
       "          3.49178500e-02, -4.25753891e-02,  2.48842742e-02, -7.98410643e-03,\n",
       "          3.11783329e-02,  4.08593006e-02, -3.11786979e-02, -3.49561987e-03,\n",
       "          5.52369542e-02, -1.32833347e-02,  5.29252999e-02,  5.95167279e-02,\n",
       "         -1.55449174e-02,  1.53014548e-02, -2.47021746e-02, -2.59151589e-02,\n",
       "         -4.86643873e-02, -3.17638405e-02, -2.42183451e-02,  4.24106419e-02,\n",
       "         -1.02091453e-03, -3.28558795e-02,  7.64968945e-03,  2.72020344e-02,\n",
       "         -2.02410463e-02,  6.82445839e-02, -5.54831289e-02,  3.29585522e-02,\n",
       "         -4.83005531e-02,  4.35426645e-02,  2.07002368e-02, -6.21290095e-02,\n",
       "          1.63388420e-02, -2.82198582e-02,  6.65642917e-02,  3.81076075e-02,\n",
       "         -3.00536375e-03,  2.68827975e-02,  3.16296443e-02, -5.79454750e-03,\n",
       "         -6.02058917e-02, -4.44914848e-02, -4.33592685e-02, -1.56066343e-02,\n",
       "          5.88263124e-02,  4.65115421e-02, -1.00348704e-02,  4.85913865e-02,\n",
       "         -2.12628096e-02, -8.85033887e-03, -7.11158523e-03, -3.16617377e-02,\n",
       "          3.19726914e-02, -6.43201545e-02, -1.38851553e-02, -2.33474206e-02,\n",
       "          5.92818558e-02, -1.44051081e-02,  5.73897548e-02,  5.63536398e-02,\n",
       "          4.45395559e-02, -1.33554162e-02, -2.76206788e-02,  7.90865067e-03,\n",
       "          1.09062390e-02, -4.96655256e-02, -1.59892580e-03, -1.53547870e-02,\n",
       "          5.14638387e-02,  1.70912240e-02, -3.19449194e-02,  1.08112833e-02,\n",
       "         -3.76502685e-02,  2.15262547e-02,  4.09418643e-02, -6.71250746e-02,\n",
       "         -2.09282860e-02, -5.28163910e-02, -1.80718824e-02,  2.72467732e-02,\n",
       "         -1.74645882e-03, -3.49566042e-02,  1.41830025e-02, -1.67993810e-02,\n",
       "          1.71359926e-02, -1.79255828e-02,  4.51397896e-02,  6.21371157e-02,\n",
       "         -5.93043864e-03,  7.28921324e-04,  5.54448627e-02, -7.93959945e-04,\n",
       "         -1.27111338e-02, -6.92983642e-02, -1.49865299e-02, -9.90913901e-03,\n",
       "         -1.76772848e-03, -5.41446954e-02, -3.50095308e-03,  1.52355442e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 62,\n",
       "  'topic_words': array(['channels', 'neurobiological', 'neurobiology', 'neuroethics',\n",
       "         'interactions', 'neuronal', 'neurosciences', '세포', 'frequencies',\n",
       "         'interaction', 'neuroscience', 'impulsivity', 'cells', 'dynamic',\n",
       "         'excitability', 'variability', 'neurogenesis', 'clinical',\n",
       "         'interactive', 'neurobiol', 'frequency', 'membrane', 'activations',\n",
       "         'dynamics', 'interconnected', 'extracellular', 'currents',\n",
       "         'intrinsic', 'clinically', 'neurocultures', 'neuroscientific',\n",
       "         'neuroscientists', 'correlations', 'stimuli', 'linearity',\n",
       "         'neuroimaging', 'cell', 'hemodynamic', 'channel', 'classification',\n",
       "         'neurons', 'paramagnetic', 'correlation', 'networks',\n",
       "         'neuroscientist', 'activation', 'allodynamic', 'neurosci',\n",
       "         'correlated', 'interacting'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.05367592e-02,  2.32962910e-02, -4.96034771e-02,  4.86117452e-02,\n",
       "         -8.85634217e-03,  5.13149947e-02,  3.94012071e-02, -5.14224432e-02,\n",
       "          2.34115757e-02,  3.27054709e-02, -1.03885997e-02, -4.45993654e-02,\n",
       "          4.40157093e-02,  1.63355879e-02, -5.14355972e-02,  4.29611914e-02,\n",
       "         -3.54331508e-02,  1.04648862e-02,  5.07718325e-02, -1.35654304e-03,\n",
       "          3.72418202e-03, -3.98771428e-02, -4.91991565e-02,  5.12799770e-02,\n",
       "         -5.14660925e-02, -1.51648857e-02,  1.93440281e-02,  2.90340185e-02,\n",
       "          3.68074514e-02,  1.16291698e-02, -4.76086661e-02, -1.02522699e-02,\n",
       "         -4.74655479e-02, -5.09915911e-02, -4.21136916e-02, -4.65276763e-02,\n",
       "         -1.43016689e-04,  1.11233015e-02, -5.79829887e-03,  1.04909204e-02,\n",
       "         -3.42462473e-02,  4.76940125e-02,  3.21888924e-02, -6.43830700e-03,\n",
       "         -3.25748809e-02, -4.22638953e-02,  5.14622927e-02, -3.35603617e-02,\n",
       "          5.12340665e-02, -2.57837866e-03, -9.50394012e-03,  2.94424538e-02,\n",
       "          4.36579362e-02,  2.90846229e-02,  2.61209570e-02, -4.07296903e-02,\n",
       "          4.74741869e-02,  6.89638779e-03, -1.11214202e-02,  3.51537652e-02,\n",
       "         -5.49335359e-03,  5.09245098e-02, -4.45025973e-02, -3.03688645e-02,\n",
       "         -1.68103464e-02,  5.87884337e-04, -2.52958536e-02,  1.95472371e-02,\n",
       "         -8.25909153e-03, -3.99764674e-03, -1.59684438e-02, -8.95065442e-03,\n",
       "         -1.50019061e-02, -5.11585660e-02, -5.00917509e-02, -2.59905197e-02,\n",
       "          2.51372010e-02,  2.27778722e-02, -1.70275867e-02, -5.13548926e-02,\n",
       "         -5.14668152e-02,  1.78415757e-02,  5.14165461e-02,  4.83906716e-02,\n",
       "         -5.08672036e-02, -1.76736210e-02, -5.03039062e-02, -1.15739461e-03,\n",
       "         -2.09907442e-03, -3.82902734e-02, -2.38456614e-02, -5.14050648e-02,\n",
       "         -1.10113882e-02, -4.97047752e-02,  3.95045578e-02,  4.40779179e-02,\n",
       "          5.14583588e-02,  4.61224839e-02,  4.66057397e-02,  3.81008945e-02,\n",
       "          3.97249609e-02,  1.64866224e-02,  2.91345697e-02, -1.64090209e-02,\n",
       "          2.09102910e-02, -1.13102589e-02, -4.78182659e-02, -4.66598608e-02,\n",
       "         -2.14164853e-02,  3.75307798e-02,  5.14106825e-02, -1.87294409e-02,\n",
       "         -5.13265207e-02, -2.61805952e-02,  2.51929630e-02,  3.16758528e-02,\n",
       "          5.02128303e-02,  1.94139015e-02, -5.12115583e-02,  1.19330920e-03,\n",
       "         -4.85904068e-02,  4.58234735e-02,  2.61699893e-02, -2.39308216e-02,\n",
       "          1.00832544e-02, -1.53825022e-02,  4.95202765e-02,  9.86370072e-03,\n",
       "         -2.60874219e-02,  5.08707240e-02, -5.08886501e-02,  1.16427206e-02,\n",
       "          4.96448018e-02,  4.88421693e-02,  1.47602856e-02,  5.14477715e-02,\n",
       "         -2.19660439e-02, -2.83181444e-02,  4.92114648e-02,  2.99945381e-02,\n",
       "         -2.67467294e-02, -3.35011631e-02,  5.14075756e-02, -3.78928669e-02,\n",
       "          5.10970280e-02,  4.98311594e-04, -4.99857478e-02,  4.69314530e-02,\n",
       "         -1.99840162e-02,  2.27331184e-02,  5.10740839e-02,  5.10401465e-02,\n",
       "         -3.33397426e-02, -2.96085477e-02,  3.70955095e-02, -5.67872729e-03,\n",
       "         -2.63399025e-03, -1.59750059e-02,  5.13760783e-02, -2.90106200e-02,\n",
       "          5.12008741e-02, -4.08376157e-02, -4.25484031e-02, -5.01607582e-02,\n",
       "          2.20931899e-02, -3.45729105e-02,  1.81890465e-02, -1.68929435e-02,\n",
       "         -4.61755320e-02,  6.21899636e-03, -1.55575071e-02, -4.98635210e-02,\n",
       "          5.12169078e-02,  1.45815834e-02,  1.68988062e-03,  1.16465781e-02,\n",
       "          5.12434691e-02,  4.86092493e-02,  9.92873404e-03,  5.05497083e-02,\n",
       "          1.90752223e-02, -5.12082800e-02, -3.02569009e-02, -2.58663800e-02,\n",
       "         -9.00474191e-03, -4.88150418e-02,  9.76147130e-04,  5.13207093e-02,\n",
       "         -2.34174915e-02, -4.91669551e-02,  1.60325635e-02, -3.20723765e-02,\n",
       "         -4.88038640e-03,  1.72136463e-02, -5.06852455e-02,  1.10921040e-02,\n",
       "         -3.06247827e-02,  4.58579734e-02,  5.05823418e-02, -3.47556453e-03,\n",
       "         -4.74902354e-02, -5.16756112e-03, -2.28795540e-02, -5.07712178e-02,\n",
       "          1.63117331e-02, -2.40484141e-02, -4.04587388e-02,  2.99225580e-02,\n",
       "          5.09525165e-02,  5.13219535e-02,  6.04130328e-05,  4.19663489e-02,\n",
       "         -5.12389615e-02,  1.71544962e-02,  4.66075502e-02,  6.12044521e-03,\n",
       "         -2.19471660e-03, -5.07087111e-02,  2.06144601e-02, -4.58100773e-02,\n",
       "         -8.93255603e-03,  4.92007583e-02,  5.12052290e-02,  3.68366539e-02,\n",
       "         -4.81794961e-02,  3.37760299e-02, -5.14656603e-02, -2.44461931e-02,\n",
       "         -1.24068018e-02,  2.86875665e-03, -1.65585931e-02,  3.43500227e-02,\n",
       "         -5.10957651e-02,  4.13675457e-02, -1.01190768e-02,  1.87901314e-02,\n",
       "         -2.40603350e-02,  4.29190136e-02,  4.89873551e-02, -5.09191602e-02,\n",
       "         -4.49579582e-02, -4.41760756e-04,  1.94190443e-03,  3.34703624e-02,\n",
       "          5.11451438e-02, -1.65498797e-02,  5.08708283e-02,  1.52046215e-02,\n",
       "         -4.81897183e-02,  2.24879645e-02,  1.62337720e-03, -5.06141856e-02,\n",
       "          3.03965416e-02,  4.69975546e-02, -5.11749089e-02,  4.65535559e-02,\n",
       "          4.65634391e-02,  3.09353545e-02, -4.80096377e-02, -2.52562389e-02,\n",
       "         -5.05377799e-02,  4.79089022e-02, -5.14620990e-02,  6.54609874e-04,\n",
       "         -2.27753073e-02, -5.14603704e-02, -1.15322880e-03,  2.75856256e-02,\n",
       "          4.79465201e-02,  2.13212017e-02, -1.35831023e-03, -4.79289293e-02,\n",
       "         -5.12796417e-02, -1.42831691e-02, -4.96433526e-02,  5.10815941e-02,\n",
       "         -3.26332636e-02,  3.89288925e-02, -5.14086634e-02, -1.22474013e-02,\n",
       "         -2.21591331e-02, -5.45939989e-03,  2.10204218e-02, -7.85292126e-04,\n",
       "         -9.96894389e-03,  1.87518578e-02, -4.41469811e-02,  2.38637757e-02,\n",
       "          3.47782001e-02, -2.70815212e-02,  5.12057245e-02,  4.10738550e-02,\n",
       "          3.22489366e-02, -4.95527759e-02, -4.35101911e-02,  5.34261996e-03,\n",
       "         -4.62960489e-02,  2.61764936e-02,  1.63753442e-02,  4.09197062e-02,\n",
       "         -1.35438526e-02,  2.06443761e-02,  2.56020818e-02, -3.81468162e-02,\n",
       "         -2.42129304e-02, -4.21886295e-02, -1.59520172e-02, -9.89104994e-03,\n",
       "         -3.30564044e-02, -2.70861946e-02, -5.12082204e-02,  8.81538726e-04,\n",
       "          3.18555981e-02, -3.71474512e-02,  5.14621586e-02,  4.92028594e-02,\n",
       "          2.22345460e-02, -4.64174040e-02, -9.63567197e-03, -5.37347607e-03,\n",
       "         -1.12843169e-02, -3.98230702e-02, -1.93900336e-02,  4.96132970e-02,\n",
       "         -1.83884650e-02,  1.51506690e-02,  7.46128149e-03, -3.05175222e-02,\n",
       "         -2.50892900e-02,  3.97949219e-02, -4.25403826e-02, -4.82695848e-02,\n",
       "         -1.61726326e-02,  2.77170502e-02,  5.10519929e-02, -2.08253674e-02,\n",
       "         -3.93629670e-02, -4.30863462e-02, -4.96881194e-02,  4.10803035e-02,\n",
       "         -4.19005156e-02,  4.26652730e-02, -4.63261418e-02, -2.55459957e-02,\n",
       "          2.90007181e-02,  5.14522716e-02,  5.08365631e-02, -2.84950007e-02,\n",
       "          1.55815147e-02,  4.86751013e-02,  4.39391620e-02,  2.77737882e-02,\n",
       "          4.70493920e-04,  4.99839708e-02,  2.79849023e-02,  2.50808205e-02,\n",
       "         -5.14666140e-02,  3.46660018e-02, -1.14194211e-03, -3.42179947e-02,\n",
       "          3.46478112e-02, -5.00295013e-02,  5.13298064e-02, -6.66244421e-03,\n",
       "         -4.98128757e-02,  3.90274115e-02, -2.26770900e-02,  2.21550819e-02,\n",
       "         -3.51347439e-02,  5.09097986e-02,  4.85954508e-02,  4.50208522e-02,\n",
       "         -3.98967974e-02,  1.66705921e-02,  2.01705210e-02, -3.37987728e-02,\n",
       "         -2.61164829e-02,  8.89899954e-03, -8.80271662e-03, -2.72517949e-02,\n",
       "          3.74251418e-02, -1.88747384e-02,  1.06708482e-02, -2.69534364e-02,\n",
       "         -2.06373557e-02,  5.05562872e-02,  2.86350660e-02, -5.14662638e-02,\n",
       "          5.13677672e-02, -3.10282223e-04, -2.55966391e-02,  1.55928284e-02,\n",
       "         -4.21681255e-03,  7.00453995e-03, -1.03532532e-02, -4.96533401e-02,\n",
       "          5.14551774e-02, -1.23046851e-02, -5.05614430e-02,  1.66282505e-02,\n",
       "          2.80672591e-02,  4.82719168e-02,  1.68093350e-02, -3.81349325e-02,\n",
       "         -2.57804543e-02,  2.78433096e-02, -3.08609288e-02, -3.19526419e-02,\n",
       "         -1.91968791e-02, -2.24772878e-02,  3.69248427e-02, -4.62063998e-02,\n",
       "          5.01084067e-02,  5.03326729e-02, -3.94509267e-03,  4.73329276e-02,\n",
       "         -4.14541960e-02,  1.79595873e-03,  5.07043935e-02,  8.93181097e-03,\n",
       "         -3.17999944e-02, -2.44591814e-02, -1.92190893e-03,  4.42338847e-02,\n",
       "          5.13875484e-02, -4.89904322e-02, -2.73750741e-02, -4.72019687e-02,\n",
       "         -3.44984122e-02,  2.02641711e-02, -5.09358458e-02, -2.66724024e-02,\n",
       "         -4.88007814e-02, -5.00212051e-02,  5.01592048e-02,  4.21607234e-02,\n",
       "         -8.04753974e-04, -1.66833233e-02, -5.14667109e-02, -5.05864695e-02,\n",
       "         -1.06016900e-02, -6.45660888e-03, -4.42774184e-02, -5.08175939e-02,\n",
       "         -1.03975590e-02, -5.14568947e-02, -3.43089625e-02, -5.50856814e-04,\n",
       "          2.47427970e-02,  2.57350691e-02,  9.94150899e-03, -1.12321135e-02,\n",
       "          7.84102082e-03,  2.64274143e-03, -5.13896570e-02,  1.43010318e-02,\n",
       "          1.22328801e-02,  2.21913494e-02, -4.12731431e-02,  4.01738100e-02,\n",
       "         -4.14867885e-04, -5.12141883e-02,  4.78422754e-02, -2.23581158e-02,\n",
       "          6.63269311e-05, -4.53518331e-02, -1.31325983e-03, -4.54318672e-02,\n",
       "          5.12850806e-02,  2.36258637e-02, -2.52878573e-03,  4.25938796e-03,\n",
       "         -5.09066992e-02,  4.56539169e-02, -3.66012417e-02,  3.97179499e-02,\n",
       "         -5.01871966e-02, -2.47320868e-02, -2.19796058e-02, -4.85097431e-03,\n",
       "          3.58241284e-03,  5.14668152e-02, -3.99352834e-02,  4.90074940e-02,\n",
       "          4.16012257e-02, -4.90795933e-02, -3.99438106e-02, -5.14238253e-02,\n",
       "         -5.10548875e-02, -1.19304610e-02,  1.26896696e-02,  9.91717353e-03,\n",
       "          2.64365505e-03,  4.55462895e-02, -5.06989956e-02,  1.84276570e-02,\n",
       "         -3.24426219e-02, -1.53426975e-02,  4.24653627e-02,  5.03967404e-02,\n",
       "          3.50079723e-02, -3.96380424e-02,  5.14665544e-02,  3.34576424e-03,\n",
       "         -4.54133041e-02, -4.49760333e-02,  1.26317544e-02, -2.80613899e-02,\n",
       "         -2.84545794e-02, -5.14337718e-02, -3.16637978e-02, -7.11535802e-03],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 63,\n",
       "  'topic_words': array(['asymptotic', 'computational', '함수', 'exponential', 'graphs',\n",
       "         'graph', 'computationally', 'computation', 'mathbb',\n",
       "         'maximization', 'graphql', 'displaystyle', 'computed',\n",
       "         'coefficient', 'calculation', 'regression', 'functions',\n",
       "         'gaussian', 'algorithmic', 'characterize', 'approximation',\n",
       "         'calculations', 'matlab', 'coefficients', 'maximize', '알고리즘',\n",
       "         '그래프', 'function', 'tensorflow', '방정식', 'xticklabels', 'algorithm',\n",
       "         'paradigm', 'maximizing', 'characterized', 'probabilistic',\n",
       "         'dysfunctional', 'behavioral', 'equations', '프로그래밍', 'diagram',\n",
       "         'paradigms', 'histogram', 'define', 'equation', 'simulation',\n",
       "         'algorithms', 'chart', 'functional', 'behaviors'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.24011590e-02, -1.63621381e-02, -8.93685315e-03,  4.74675782e-02,\n",
       "         -2.13864297e-02, -4.01507281e-02, -3.20100188e-02, -4.98722270e-02,\n",
       "          5.23584187e-02,  4.06599045e-02, -3.72017026e-02,  3.21225589e-03,\n",
       "          4.96007614e-02, -4.50136513e-03, -5.23985066e-02, -3.53254527e-02,\n",
       "          2.42154635e-02,  1.30097438e-02,  5.22035845e-02,  5.21788150e-02,\n",
       "         -3.58411632e-02,  2.50278935e-02, -3.28695029e-02,  4.77918498e-02,\n",
       "         -5.23954965e-02, -5.16361296e-02,  4.53641340e-02,  2.65594833e-02,\n",
       "          4.47860062e-02, -4.80658710e-02, -5.23516908e-02, -1.44816656e-03,\n",
       "          1.32248197e-02, -5.10508232e-02, -5.02896346e-02,  2.02126186e-02,\n",
       "          3.52055393e-02, -4.38653165e-03,  4.45157848e-02,  3.93260047e-02,\n",
       "         -6.00532396e-03,  2.32590921e-02,  5.10438830e-02, -3.64392847e-02,\n",
       "          2.65397094e-02, -4.41744365e-02,  5.23970574e-02, -5.16591668e-02,\n",
       "         -4.22023498e-02, -1.17692566e-02,  1.89152770e-02,  1.52856233e-02,\n",
       "          2.68146247e-02, -1.63222477e-03,  5.16520292e-02, -5.23827896e-02,\n",
       "          3.10415160e-02,  2.15907544e-02, -2.19121426e-02,  4.95100059e-02,\n",
       "          1.12597160e-02,  5.16225770e-02,  6.34414610e-03, -3.40925828e-02,\n",
       "          3.04164775e-02, -2.02082433e-02, -2.62413993e-02, -2.87574232e-02,\n",
       "          4.35285792e-02,  1.24577936e-02, -4.25144359e-02, -1.11463666e-03,\n",
       "         -2.95271054e-02, -2.98034661e-02, -5.05441613e-02, -3.14202625e-03,\n",
       "         -3.21859606e-02, -9.18868277e-03,  1.92901194e-02, -5.24005890e-02,\n",
       "         -5.24012484e-02, -4.16876450e-02,  3.65648381e-02,  1.89193841e-02,\n",
       "          5.23533896e-02, -9.92767047e-03, -5.13032675e-02, -1.16305035e-02,\n",
       "         -2.87050810e-02, -3.03596370e-02, -1.83462575e-02,  1.98981520e-02,\n",
       "         -4.36370000e-02, -5.21154329e-02,  5.23779280e-02,  5.23616746e-02,\n",
       "          5.08923903e-02,  2.23685615e-03,  4.92982231e-02, -2.10479274e-03,\n",
       "          3.40178460e-02, -2.02690735e-02, -1.15831979e-02, -5.14229909e-02,\n",
       "          5.12341969e-02, -3.23689207e-02, -1.69682093e-02, -4.76484746e-02,\n",
       "          4.32656929e-02,  5.04164472e-02,  4.45733406e-02, -3.56983021e-02,\n",
       "         -5.22417910e-02, -9.97561961e-03,  5.15718050e-02,  2.11211052e-02,\n",
       "         -1.40085211e-02,  3.70154902e-02, -2.47751065e-02,  4.24859151e-02,\n",
       "         -1.02703273e-02,  3.90954427e-02, -3.53315622e-02, -1.78932920e-02,\n",
       "          1.47932731e-02, -5.23115043e-03, -5.19857742e-02,  3.52426842e-02,\n",
       "         -4.52400977e-03,  1.66921914e-02, -5.18597290e-02,  5.23526222e-02,\n",
       "          5.23101687e-02,  3.53122428e-02,  4.75566462e-02,  5.23469560e-02,\n",
       "          4.06722166e-03, -5.76445973e-03,  4.51057330e-02,  4.41525206e-02,\n",
       "          3.91236767e-02,  1.85125899e-02,  5.21470793e-02, -4.38597463e-02,\n",
       "          5.18481284e-02, -1.49224810e-02, -4.58137505e-02,  3.11300177e-02,\n",
       "          1.01992497e-02,  3.30321491e-02,  4.86789234e-02,  4.44134232e-03,\n",
       "         -1.40339974e-03, -3.35206650e-02,  3.32664996e-02, -1.77555643e-02,\n",
       "          6.18576165e-03,  2.85583586e-02, -9.90863889e-03,  4.75758640e-03,\n",
       "          5.23022264e-02,  3.35457698e-02, -3.71045247e-02,  4.00903150e-02,\n",
       "         -2.43497379e-02, -3.00895497e-02,  1.43039171e-02, -4.90558036e-02,\n",
       "          1.80656426e-02,  5.23444191e-02,  2.28340160e-02, -2.63989791e-02,\n",
       "          1.20639130e-02,  1.14914756e-02, -1.34818833e-02,  4.07955274e-02,\n",
       "         -1.62523501e-02,  1.44750671e-02, -2.39680447e-02,  3.61667052e-02,\n",
       "          8.96543637e-03, -4.04218063e-02,  1.84265077e-02, -2.35447846e-02,\n",
       "         -5.23933657e-02, -4.77271155e-02,  3.43133658e-02,  5.21798581e-02,\n",
       "         -3.65718454e-02, -5.22057042e-02,  2.12544482e-03,  7.50086084e-03,\n",
       "          3.62678170e-02,  1.34798158e-02, -2.76801307e-02, -5.88540919e-04,\n",
       "         -5.24011366e-02,  1.22496737e-02,  5.22067584e-02,  3.59750427e-02,\n",
       "          8.61046650e-03,  1.88117735e-02, -5.12854606e-02, -3.01235467e-02,\n",
       "          1.05911037e-02,  1.39717665e-02, -3.34591977e-02,  3.82714905e-02,\n",
       "         -4.97130118e-02,  5.21304943e-02,  2.77402438e-02, -1.13976263e-02,\n",
       "         -5.23266308e-02, -2.43618824e-02,  5.22109270e-02, -5.01560681e-02,\n",
       "         -1.94556322e-02, -8.02835450e-03, -8.96506384e-03, -5.08813411e-02,\n",
       "          8.98103975e-03,  5.19939549e-02,  5.20257354e-02,  2.51794308e-02,\n",
       "         -5.23901135e-02, -1.23404320e-02, -5.21651991e-02, -2.16353126e-02,\n",
       "         -2.02508811e-02, -4.36116420e-02, -4.77678403e-02,  5.21425642e-02,\n",
       "         -3.35776918e-02,  9.76746622e-03,  1.69195794e-02,  2.86389403e-02,\n",
       "         -4.71206941e-02,  5.12108505e-02, -5.06733805e-02,  1.82840750e-02,\n",
       "          4.92757447e-02,  1.83724146e-02,  2.01854436e-03, -4.71185297e-02,\n",
       "          5.06879427e-02, -2.62662116e-02,  4.84850705e-02, -5.20782433e-02,\n",
       "          2.17060912e-02,  8.43218993e-03, -3.52188461e-02, -5.20134903e-02,\n",
       "         -1.26836104e-02,  1.51567962e-02,  9.22097731e-03,  2.90216748e-02,\n",
       "         -3.40755768e-02,  1.45974047e-02, -1.78593285e-02, -5.03951982e-02,\n",
       "         -3.84693742e-02,  1.93975475e-02,  3.48641723e-02, -3.25159170e-02,\n",
       "          1.79280732e-02, -5.23841754e-02,  4.24169004e-03,  4.53103893e-02,\n",
       "          1.97961852e-02,  9.70811583e-04,  8.29684269e-03, -5.07037193e-02,\n",
       "          7.93223642e-03, -3.69581953e-02,  5.12814149e-02,  4.84688841e-02,\n",
       "         -5.22537269e-02,  3.17623056e-02, -5.23603633e-02,  3.33920717e-02,\n",
       "         -4.92077842e-02,  3.31224836e-02, -1.54388128e-02,  5.14364652e-02,\n",
       "         -5.16311862e-02,  8.11955612e-03, -5.19089475e-02, -1.61063876e-02,\n",
       "          1.97992437e-02,  2.94780778e-03,  1.46753993e-02, -7.23758480e-03,\n",
       "          4.22331020e-02,  1.66255832e-02, -5.09316362e-02, -3.64464289e-03,\n",
       "         -5.01533747e-02,  3.99764907e-03,  3.58690955e-02,  5.23861460e-02,\n",
       "         -4.73898370e-03, -4.99281548e-02,  3.84631567e-02, -5.23931049e-02,\n",
       "         -5.23523577e-02, -6.39003888e-03, -5.15782349e-02,  1.75843537e-02,\n",
       "         -4.00269032e-02, -2.33548693e-02, -4.45296392e-02,  4.19600122e-02,\n",
       "         -4.67131212e-02, -4.19610888e-02,  5.09524867e-02,  4.75623719e-02,\n",
       "          2.47316808e-02, -5.12115099e-02,  3.11504863e-02, -1.51126040e-02,\n",
       "         -4.18408103e-02,  5.19144498e-02,  5.95390238e-03, -5.13721555e-02,\n",
       "          2.01266557e-02, -4.48281132e-02, -2.47689784e-02, -2.68378258e-02,\n",
       "         -5.23950681e-02, -3.21343541e-02, -3.13447937e-02, -3.37073840e-02,\n",
       "          4.78992574e-02, -5.12980893e-02,  5.22104353e-02,  4.17004637e-02,\n",
       "         -2.10829787e-02, -1.15340725e-02, -5.23876473e-02, -3.09023298e-02,\n",
       "         -4.80099060e-02, -4.67386730e-02,  6.48188498e-03, -2.54685003e-02,\n",
       "          4.81037647e-02,  4.86871190e-02,  5.22058532e-02, -1.03377905e-02,\n",
       "         -2.21972987e-02,  2.06397176e-02,  4.75310609e-02,  4.21048403e-02,\n",
       "          1.42900068e-02,  5.09531274e-02, -3.44197731e-04,  4.96339537e-02,\n",
       "          1.57142933e-02,  3.52927782e-02, -5.18808961e-02, -2.25172490e-02,\n",
       "         -3.80624533e-02, -3.66617143e-02,  5.05479462e-02, -4.74912859e-02,\n",
       "         -5.22731580e-02,  4.55018543e-02,  3.80403697e-02,  4.88670692e-02,\n",
       "         -4.98306975e-02,  5.21212183e-02, -2.56860582e-03,  5.02500311e-02,\n",
       "          1.17381215e-02,  3.21022570e-02, -3.58637460e-02, -5.14150821e-02,\n",
       "         -4.58154827e-05,  4.13025916e-02, -5.24010807e-02, -4.91873771e-02,\n",
       "          4.55154702e-02, -3.55565101e-02,  3.28052882e-03,  5.19648083e-02,\n",
       "         -1.42343557e-02,  5.22547066e-02,  3.17843184e-02, -5.12215234e-02,\n",
       "          5.02118245e-02,  1.20791467e-02, -1.62087120e-02,  4.88604009e-02,\n",
       "          8.94122757e-04,  4.90888730e-02, -5.16479909e-02,  3.31577398e-02,\n",
       "         -3.54838707e-02,  2.40698420e-02, -5.19958064e-02,  4.53853682e-02,\n",
       "          3.35969627e-02,  4.55512367e-02,  5.08565679e-02, -1.43918982e-02,\n",
       "         -2.01875120e-02,  3.98918241e-02, -1.76912770e-02, -4.30191271e-02,\n",
       "          4.21970226e-02,  3.97294164e-02, -1.17761781e-02, -2.80801672e-02,\n",
       "          4.47602272e-02, -4.11956310e-02,  3.65824848e-02,  5.98202506e-03,\n",
       "         -1.15086734e-02,  3.94457057e-02,  3.56082432e-02,  4.15257253e-02,\n",
       "          4.99035493e-02, -4.89615910e-02,  3.29459459e-03,  4.86209206e-02,\n",
       "          5.06558456e-02,  5.17679192e-02,  2.19532847e-02, -5.12632281e-02,\n",
       "         -3.47200781e-02, -5.18292822e-02, -3.27242203e-02,  5.60816284e-03,\n",
       "          1.48788504e-02,  3.12399641e-02,  3.50279771e-02,  4.52814847e-02,\n",
       "         -2.03219876e-02,  5.23724295e-02, -5.23957126e-02,  3.49086896e-02,\n",
       "         -4.51003853e-03, -3.39462887e-03, -4.13818769e-02, -5.20962030e-02,\n",
       "          5.10749817e-02, -4.90433499e-02,  4.06222455e-02,  3.20000872e-02,\n",
       "          4.35567014e-02,  2.70702876e-02,  3.62429433e-02, -1.20977759e-02,\n",
       "         -2.41910480e-03, -3.72725613e-02, -5.15569411e-02, -2.47222707e-02,\n",
       "         -1.35277044e-02,  5.11098243e-02, -1.75604336e-02,  4.84306067e-02,\n",
       "         -4.93863337e-02, -4.53477390e-02,  2.69073695e-02, -2.96086296e-02,\n",
       "          5.23331650e-02, -5.23920134e-02, -7.54780183e-03, -3.09644118e-02,\n",
       "          4.86517847e-02, -4.33491170e-03,  4.83892299e-02,  2.72515863e-02,\n",
       "         -5.17436191e-02,  4.74163964e-02, -4.55775708e-02,  3.70651893e-02,\n",
       "          2.69233622e-02,  1.52051505e-02,  1.30020604e-02,  2.49922182e-02,\n",
       "         -3.38629633e-02,  5.24012484e-02, -3.59532908e-02,  4.49679904e-02,\n",
       "          4.79832292e-02, -4.28702943e-02, -1.11022219e-03, -5.21895252e-02,\n",
       "         -4.17122338e-03,  3.70330922e-03,  2.35216711e-02,  3.37429903e-02,\n",
       "          3.07856947e-02,  4.85011041e-02, -4.99033965e-02, -5.20147607e-02,\n",
       "          2.25088745e-03,  1.18835643e-02, -1.86220221e-02, -4.62157875e-02,\n",
       "          4.45320457e-02, -3.03592850e-02,  5.24008423e-02,  4.55217622e-02,\n",
       "         -5.00772744e-02, -5.23863286e-02,  2.24076193e-02, -4.53084055e-03,\n",
       "          1.28914565e-02, -4.93194722e-02, -4.48984355e-02,  9.66805592e-03],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 64,\n",
       "  'topic_words': array(['github', 'directory', 'git', 'bashrc', 'foldername', 'filename',\n",
       "         'gedit', 'folder', 'renaming', 'svms', 'grep', 'gcc', '커널', '우분투',\n",
       "         'svm', 'commands', '명령어', 'unix', 'files', 'commit', 'mv', '폴더',\n",
       "         'ubuntu', '명령', 'kernel', '스크립트', 'tensorflow', 'rewrite', 'rm',\n",
       "         'command', 'modify', 'regex', 'editor', 'ctrl', '파일', 'scripting',\n",
       "         'filenametype', 'scripts', 'script', 'localhost', 'ssh',\n",
       "         'repository', 'sudo', 'textrm', 'pathophysiology', 'mxpath',\n",
       "         'gencode', 'doc', 'tcp', 'default'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.70164844e-02,  1.75572764e-02, -1.97647624e-02,  3.46537083e-02,\n",
       "         -8.55830871e-03, -5.77266403e-02, -2.69502029e-02,  3.40290368e-04,\n",
       "          5.29013276e-02,  5.45810126e-02, -1.55001990e-02,  2.04081833e-02,\n",
       "          5.24647608e-02,  4.63393331e-02, -1.68995950e-02, -2.87435222e-02,\n",
       "         -4.00754847e-02, -1.04794437e-02,  8.98567308e-03,  1.40553806e-02,\n",
       "          1.09959114e-02,  1.11815752e-02,  9.67191625e-03,  3.74581739e-02,\n",
       "         -5.77725135e-02,  5.95815852e-03, -5.39217889e-03,  2.19479240e-02,\n",
       "          2.46068556e-02, -5.71691617e-02,  1.12765497e-02,  5.27988337e-02,\n",
       "          9.09915660e-03, -5.73893562e-02, -4.77139466e-02, -2.78054662e-02,\n",
       "          2.15023533e-02, -4.23654243e-02, -1.55966515e-02, -4.19714451e-02,\n",
       "         -1.22977290e-02, -3.17119583e-02,  2.25483999e-03, -3.27661857e-02,\n",
       "         -1.71192735e-02,  3.60977799e-02,  5.45964427e-02, -5.65964133e-02,\n",
       "         -5.81090059e-03,  2.24575307e-03, -5.76984249e-02, -3.44569609e-02,\n",
       "         -6.17669616e-03, -2.41066869e-02,  9.72033478e-03, -4.98726740e-02,\n",
       "          3.82737294e-02,  5.26359603e-02,  4.18200977e-02,  1.88929327e-02,\n",
       "          4.72181961e-02,  3.92265804e-02, -2.04166118e-03, -4.27816212e-02,\n",
       "         -3.63148004e-02, -7.88273290e-03,  4.02914034e-03,  2.06878390e-02,\n",
       "          5.25397807e-02,  4.59234603e-03, -2.36431845e-02, -5.31635284e-02,\n",
       "          1.74874160e-02, -3.46940383e-02, -2.79200971e-02,  1.96301676e-02,\n",
       "         -4.41719890e-02, -4.77700830e-02, -2.71875411e-04, -5.78944646e-02,\n",
       "         -5.78998886e-02,  3.68823558e-02, -3.43751535e-03, -4.33559120e-02,\n",
       "          1.59202684e-02,  1.38030294e-03, -3.00309304e-02,  3.19025293e-02,\n",
       "          2.71463823e-02,  2.10270584e-02,  1.53521262e-02,  2.89663933e-02,\n",
       "         -2.75605265e-02, -5.59005216e-02,  2.61888318e-02,  4.56537791e-02,\n",
       "         -5.76003343e-02,  3.58139649e-02,  5.45359328e-02, -1.82147250e-02,\n",
       "          2.79051401e-02, -1.64647717e-02, -3.94852012e-02,  5.52399978e-02,\n",
       "          3.56822163e-02,  4.50529493e-02, -4.72414494e-02, -3.00768595e-02,\n",
       "         -2.79260334e-02,  3.11026908e-02,  5.64582981e-02, -5.16436063e-02,\n",
       "          1.20418379e-02, -5.75596616e-02,  2.04513855e-02, -4.93342318e-02,\n",
       "         -1.74034405e-02,  4.68884315e-03, -4.65159398e-03, -5.04803564e-03,\n",
       "         -3.81549187e-02, -6.02639746e-03,  4.71802056e-03,  3.45388800e-02,\n",
       "         -2.21403912e-02,  1.79068707e-02,  1.39703667e-02,  3.65562290e-02,\n",
       "          2.17752066e-03,  3.18167731e-03, -3.03616710e-02,  3.28083243e-03,\n",
       "          5.78791015e-02,  1.95317566e-02, -1.08618969e-02,  2.07999796e-02,\n",
       "          5.45720756e-02,  4.00924757e-02,  3.97297256e-02,  2.92168520e-02,\n",
       "          7.68751372e-03,  3.06821894e-03,  1.59187838e-02,  4.42311242e-02,\n",
       "         -4.60975096e-02,  2.65001599e-03, -2.68248878e-02,  4.39775512e-02,\n",
       "          4.63745147e-02,  3.69052291e-02,  1.46678183e-02, -1.73977427e-02,\n",
       "         -1.30829923e-02, -1.90448165e-02, -1.94450039e-02,  2.56911535e-02,\n",
       "          2.17019897e-02,  3.90632562e-02, -2.56712195e-02,  3.77173536e-03,\n",
       "         -4.79909452e-03,  5.30563891e-02,  5.65223992e-02, -3.16338465e-02,\n",
       "          5.50365858e-02,  1.92127824e-02,  6.86066132e-03,  2.49413047e-02,\n",
       "          8.48905277e-03, -3.74534242e-02,  2.44906265e-02, -9.08616371e-03,\n",
       "          5.15670422e-03,  3.18683609e-02, -1.11926207e-02,  4.27638702e-02,\n",
       "         -5.78451268e-02,  5.66261820e-03, -5.64934425e-02,  5.24529256e-02,\n",
       "         -9.86293796e-03,  5.61515838e-02, -1.43995509e-04,  1.16947964e-02,\n",
       "          4.81381677e-02,  8.48943926e-03,  1.38836708e-02,  5.15550077e-02,\n",
       "         -5.64387105e-02,  5.51109724e-02,  1.25391139e-02, -2.16868166e-02,\n",
       "          4.41502854e-02,  3.26155052e-02, -3.09699513e-02,  3.97100076e-02,\n",
       "          1.42185576e-02,  2.03996301e-02, -5.17766364e-02, -1.26727764e-02,\n",
       "          4.73169945e-02,  2.96997726e-02,  2.21757814e-02,  2.66322922e-02,\n",
       "          2.53763683e-02, -9.64940339e-03, -2.86522321e-03, -1.52905062e-02,\n",
       "         -3.40075605e-02,  5.73695116e-02, -1.23021565e-02,  3.75145674e-02,\n",
       "          2.84174178e-02,  2.73669232e-03,  9.42427479e-03, -3.57921459e-02,\n",
       "         -4.72061336e-02, -3.61664668e-02, -2.92058494e-02, -8.79338663e-03,\n",
       "          1.40797924e-02, -3.24039161e-02,  2.30144281e-02,  4.50723106e-03,\n",
       "         -5.78670986e-02,  7.54399225e-05,  1.79403014e-02,  3.86189371e-02,\n",
       "          3.95705178e-02, -1.69313811e-02,  1.22745428e-03,  5.72932847e-02,\n",
       "         -3.19805369e-02, -3.50712705e-03,  3.98187749e-02,  1.72870904e-02,\n",
       "          4.43281941e-02,  2.85652578e-02, -4.75639198e-03, -4.72219437e-02,\n",
       "          8.43134709e-03, -1.53689226e-02, -2.03708541e-02,  1.22060757e-02,\n",
       "          3.36738601e-02, -3.33076380e-02,  1.23058083e-02,  2.61653997e-02,\n",
       "          4.30011600e-02,  3.00045833e-02, -4.13055159e-02, -3.10928673e-02,\n",
       "          1.88022666e-03,  2.77796183e-02,  2.91619338e-02, -4.06024158e-02,\n",
       "         -4.73988056e-02, -5.39730415e-02, -2.24610101e-02, -2.89017372e-02,\n",
       "         -4.96589877e-02,  1.94203202e-02,  1.79074015e-02,  4.58291769e-02,\n",
       "          4.29611430e-02, -5.37553839e-02, -3.78235653e-02,  2.71101482e-02,\n",
       "          5.42314686e-02, -3.42801353e-03,  4.43428308e-02, -2.89634429e-02,\n",
       "         -8.08598474e-03,  4.08114791e-02, -2.09354125e-02, -4.79584709e-02,\n",
       "          5.50560132e-02, -1.88875683e-02, -1.88364442e-02, -2.47975904e-02,\n",
       "          4.90224399e-02,  2.16120183e-02, -2.90749455e-03, -1.82518810e-02,\n",
       "         -1.84897371e-02,  1.96213052e-02, -5.12374528e-02,  2.92900745e-02,\n",
       "          2.12588869e-02, -8.16682354e-04,  2.06575394e-02,  3.77677195e-02,\n",
       "          2.57854499e-02,  5.71531020e-02, -5.79025932e-02,  3.31303254e-02,\n",
       "         -4.83159572e-02,  1.74577795e-02,  4.15908992e-02,  3.89677063e-02,\n",
       "          3.77635732e-02,  7.56392721e-03,  1.98027166e-03, -2.65104920e-02,\n",
       "          5.02158254e-02, -1.17218122e-04, -6.52417354e-03, -2.75946595e-02,\n",
       "         -4.60179783e-02, -2.29987316e-04,  5.15270084e-02, -2.53687613e-02,\n",
       "         -3.75146233e-02,  9.07187536e-03, -1.80630870e-02,  1.13864429e-04,\n",
       "          1.52391279e-02,  1.69103667e-02,  2.13431101e-03,  8.46348703e-05,\n",
       "         -3.62789407e-02,  4.85428870e-02, -2.70565134e-03, -5.93394972e-03,\n",
       "         -1.01657845e-02,  2.92244703e-02, -2.55091283e-02,  9.19245882e-04,\n",
       "          5.05708605e-02, -1.10197328e-02, -8.33869074e-03,  6.50512055e-03,\n",
       "          2.32694559e-02, -2.84589715e-02,  3.30377184e-02,  2.77383476e-02,\n",
       "          1.01838280e-02, -2.79807337e-02, -5.78413866e-02, -5.56237213e-02,\n",
       "         -2.63591707e-02,  2.46356539e-02, -2.95346603e-02, -6.93718111e-03,\n",
       "          1.51976971e-02, -2.65493263e-02, -8.42757337e-03,  2.25509033e-02,\n",
       "          5.63611500e-02, -2.80900486e-02,  5.35786264e-02, -2.23442204e-02,\n",
       "         -1.48998518e-02, -2.65065953e-02, -5.71209565e-03,  2.02824678e-02,\n",
       "          1.34977708e-02, -1.72804296e-02,  1.00321127e-02, -4.71499823e-02,\n",
       "         -5.73147982e-02, -2.10878532e-03,  2.01721191e-02,  3.24434116e-02,\n",
       "          9.56582185e-03, -5.65253869e-02,  1.36973904e-02,  4.82523479e-02,\n",
       "         -4.50137779e-02,  5.04432395e-02,  4.52458151e-02, -8.88503715e-03,\n",
       "         -3.95958647e-02,  5.10730669e-02, -2.04353593e-03, -2.68652476e-02,\n",
       "         -1.92387756e-02,  5.76045662e-02,  5.15046343e-02, -2.91856267e-02,\n",
       "         -5.61351702e-02, -5.74607588e-02, -3.94459404e-02, -5.78731149e-02,\n",
       "         -2.57163290e-02,  1.48947285e-02, -3.59832682e-02, -5.77632375e-02,\n",
       "          1.69226713e-02,  3.49170081e-02, -1.69247463e-02, -1.19979437e-02,\n",
       "         -4.31499854e-02, -4.88645285e-02, -2.20190845e-02, -3.93586271e-02,\n",
       "          4.71534953e-02, -3.02027948e-02, -5.30515686e-02, -1.07479393e-02,\n",
       "          1.74538977e-02,  2.54508629e-02,  5.30343503e-02,  2.59214323e-02,\n",
       "          2.41851639e-02, -4.48035523e-02,  5.59957698e-05, -4.01774272e-02,\n",
       "         -2.36999523e-02,  3.96049097e-02,  3.26513499e-02,  7.56128691e-03,\n",
       "          1.73110440e-02, -6.86697988e-03, -1.14154378e-02, -1.67269632e-02,\n",
       "          5.05456589e-02,  3.72561663e-02,  3.03371809e-02, -2.61946879e-02,\n",
       "          4.75174859e-02,  2.97872499e-02,  5.71168661e-02, -1.65759195e-02,\n",
       "         -2.69995891e-02, -4.17354982e-03, -2.05703899e-02, -4.68766838e-02,\n",
       "         -2.24325340e-03, -8.10849015e-03,  4.32783253e-02,  9.93674621e-03,\n",
       "          2.00350974e-02,  4.62155007e-02,  2.08979025e-02,  5.06020617e-03,\n",
       "          1.61980428e-02, -4.94775511e-02, -4.88706231e-02,  3.48924771e-02,\n",
       "         -4.87189442e-02, -5.57108223e-03,  4.05980982e-02, -4.80919927e-02,\n",
       "          1.06440568e-02, -2.97267139e-02,  5.76495938e-02, -2.51150709e-02,\n",
       "          5.30292019e-02,  1.61784850e-02, -2.31298357e-02, -1.50524518e-02,\n",
       "         -5.77178374e-02, -4.11044955e-02, -1.05699170e-02,  1.79502778e-02,\n",
       "          3.98749821e-02,  1.35186445e-02,  5.25705342e-04,  4.75840531e-02,\n",
       "         -8.46990384e-03,  2.64158081e-02, -4.03703749e-02, -1.84380133e-02,\n",
       "         -3.41549814e-02, -3.27646323e-02,  2.74114683e-02,  4.72210161e-02,\n",
       "          5.58663756e-02, -3.47022340e-03,  5.67432642e-02,  2.58855429e-03,\n",
       "          2.56127678e-04, -3.94280031e-02, -5.33432104e-02, -1.11061484e-02,\n",
       "         -5.30766062e-02,  4.18278202e-03,  1.21573117e-02, -1.75919868e-02,\n",
       "          2.22500134e-02, -2.94070728e-02,  2.25261115e-02,  4.65051271e-02,\n",
       "          3.89273912e-02, -1.62364189e-02, -3.27569284e-02, -5.47739528e-02,\n",
       "         -3.73344049e-02, -5.90623356e-03, -3.08087189e-03,  3.89528275e-02,\n",
       "          4.05948907e-02,  5.62182330e-02,  2.45735124e-02,  9.02169384e-03,\n",
       "          1.35786626e-02, -5.73807582e-02,  4.50116470e-02, -6.80273212e-03,\n",
       "          3.88517138e-03,  1.15162116e-02,  4.98482063e-02, -2.73539275e-02,\n",
       "         -2.41619721e-02, -5.79041950e-02,  2.78502908e-02, -4.35883291e-02,\n",
       "         -9.85313207e-04, -2.02647299e-02, -4.57662418e-02,  1.46004278e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 65,\n",
       "  'topic_words': array(['access', '접근', 'accessible', '옵션', 'options', 'option', 'genetic',\n",
       "         '유전자', '권한', 'genotype', 'frontal', '장애', 'genetics',\n",
       "         'genetically', 'genes', 'lateral', 'gene', '진단', 'pdf', '기술',\n",
       "         'diagnosed', 'articles', '측면', '여기', 'pathological', 'front',\n",
       "         'socio', 'pathology', 'available', 'side', '의료', 'article', '자식',\n",
       "         'pharmacological', 'genome', 'diagnoses', 'disease', 'genotypes',\n",
       "         '복지', 'syndrome', 'diagnostic', 'cohort', 'technology',\n",
       "         'diagnosis', 'perspective', 'illness', 'perspectives', 'anterior',\n",
       "         'psychology', 'optional'], dtype='<U15'),\n",
       "  'topic_vector': array([-7.34944567e-02,  7.20550818e-03,  3.35228592e-02,  1.35223502e-02,\n",
       "         -2.83084232e-02, -2.21149605e-02,  5.80692030e-02,  4.06035595e-02,\n",
       "          4.20356877e-02, -3.12147494e-02, -5.48881181e-02, -5.35653979e-02,\n",
       "          2.18753666e-02, -2.57345047e-02, -1.63662564e-02,  5.76983728e-02,\n",
       "          4.11178544e-02, -1.63705628e-02,  5.43871112e-02,  7.35905692e-02,\n",
       "          4.04424518e-02,  4.87295687e-02, -7.11138546e-02, -1.38844608e-03,\n",
       "         -2.78647523e-02, -3.27959023e-02, -4.40011211e-02, -4.25062068e-02,\n",
       "          4.08526622e-02, -5.34980483e-02,  1.59571189e-02, -2.79959682e-02,\n",
       "          8.03727191e-03, -4.95795570e-02, -1.82432886e-02, -7.38393292e-02,\n",
       "          5.95960729e-02,  2.34146044e-02,  3.78767811e-02, -6.58949688e-02,\n",
       "         -8.62425007e-03,  3.13973725e-02, -3.57897021e-02,  5.55345602e-02,\n",
       "         -7.23250657e-02,  8.99554696e-03, -6.14882000e-02,  1.89027395e-02,\n",
       "          8.12812336e-03, -3.00629195e-02, -1.33522926e-02, -1.26577159e-02,\n",
       "          1.62738543e-02, -5.79153039e-02,  6.10789955e-02, -6.92946166e-02,\n",
       "          6.36032745e-02, -1.97643097e-02, -8.56785569e-03,  6.94749653e-02,\n",
       "         -3.29619832e-02,  5.51492870e-02,  1.48794083e-02, -1.97822358e-02,\n",
       "          2.57966910e-02,  7.63202161e-02,  6.30097166e-02, -1.19968252e-02,\n",
       "          4.97137429e-03,  4.36598947e-03, -8.56562257e-02,  6.29557157e-03,\n",
       "         -1.53158335e-02, -6.05989695e-02, -3.11330776e-03,  2.36416701e-02,\n",
       "          3.37333977e-02,  4.84072752e-02, -3.56723070e-02, -7.36337677e-02,\n",
       "         -5.93327396e-02,  5.37399985e-02,  6.07717643e-03, -1.20571405e-02,\n",
       "          1.95356712e-04, -5.53610139e-02,  2.56986525e-02,  3.79829742e-02,\n",
       "          4.92253900e-02,  3.96030815e-03, -1.35970889e-02, -2.26989333e-02,\n",
       "         -4.54115123e-02, -4.95442189e-02,  1.43756690e-02,  3.06369681e-02,\n",
       "          2.40583047e-02,  6.47205114e-02, -6.47661909e-02, -5.53314900e-03,\n",
       "          3.30355056e-02,  5.84376119e-02, -4.51648496e-02, -6.29792362e-02,\n",
       "          1.69495437e-02,  5.12879938e-02, -6.15337379e-02, -1.66256225e-03,\n",
       "          7.48057887e-02,  4.02915999e-02, -4.01124321e-02, -7.33539984e-02,\n",
       "          6.94640959e-03,  7.29886740e-02,  5.35485474e-03, -3.71485949e-04,\n",
       "         -2.83085462e-02,  6.65657520e-02,  1.64263900e-02,  1.73582789e-02,\n",
       "          3.91239487e-02,  7.17062876e-03, -3.51151265e-02,  5.61860912e-02,\n",
       "          1.69164443e-03,  2.59137396e-02,  4.54593599e-02,  4.44711506e-04,\n",
       "         -1.69843975e-02, -6.65811971e-02, -3.29812467e-02,  2.06533242e-02,\n",
       "          3.92292207e-03, -1.29810609e-02,  5.10281734e-02,  7.43083730e-02,\n",
       "          5.23739345e-02, -3.50975096e-02,  4.53661680e-02, -3.42821516e-02,\n",
       "          4.46837060e-02, -3.07403803e-02,  2.88606584e-02,  5.76193072e-02,\n",
       "          2.50141304e-02,  5.25701456e-02,  4.61408161e-02, -1.85209755e-02,\n",
       "          2.21297015e-02,  3.20337266e-02,  5.37871569e-02,  5.69851696e-03,\n",
       "         -5.88615276e-02,  5.65751158e-02,  2.10545156e-02,  3.80941667e-02,\n",
       "         -2.49276478e-02, -4.41374369e-02,  2.22595576e-02, -1.32274313e-03,\n",
       "          6.57074377e-02,  3.43460068e-02,  6.40268251e-02, -5.45414584e-03,\n",
       "          5.21047227e-02, -2.62549948e-02, -2.33267844e-02, -8.93566664e-03,\n",
       "         -6.69222139e-03,  7.42605096e-03, -2.69823540e-02, -3.10970354e-03,\n",
       "         -2.30940431e-02, -3.28027755e-02,  3.80552150e-02,  3.17939855e-02,\n",
       "         -2.57566553e-02, -4.99400310e-02, -5.33285178e-02,  2.36506034e-02,\n",
       "          6.08832873e-02, -1.96310855e-03, -4.28279154e-02,  5.37931658e-02,\n",
       "         -5.31385727e-02, -2.89579779e-02,  6.28448129e-02, -5.55101642e-03,\n",
       "          4.87095229e-02,  1.42034413e-02,  2.41325144e-02, -9.98356045e-05,\n",
       "          1.66282281e-02, -1.36347814e-02, -5.68653410e-03, -2.24930495e-02,\n",
       "         -2.45717540e-03, -6.50140420e-02,  7.69351050e-02,  7.45870965e-03,\n",
       "         -8.60064700e-02,  6.87546432e-02, -3.24279629e-02,  1.88431144e-02,\n",
       "          2.60047410e-02, -2.94042099e-02, -7.06669316e-02, -3.87754850e-02,\n",
       "         -2.81279702e-02,  4.60144744e-04,  1.02407429e-02, -3.16153467e-02,\n",
       "         -2.44767219e-02,  5.05244732e-02,  5.05280197e-02, -1.86241567e-02,\n",
       "         -7.69639015e-03, -2.43797451e-02,  3.85882221e-02, -8.57108366e-03,\n",
       "         -3.36729437e-02,  2.57173013e-02,  1.51177822e-02, -1.89709477e-02,\n",
       "         -5.21300733e-02, -7.67815039e-02, -5.57493456e-02,  1.67334974e-02,\n",
       "          3.40826400e-02, -6.64906278e-02,  5.40489145e-02,  1.65665653e-02,\n",
       "         -4.06268053e-02,  3.32565643e-02,  8.95832945e-03,  1.83296169e-03,\n",
       "         -1.66600365e-02,  3.77691053e-02,  4.83945012e-02, -3.91793884e-02,\n",
       "          4.11987165e-03, -3.34572606e-02,  8.17210004e-02,  2.53729373e-02,\n",
       "          2.20804121e-02,  1.25350235e-02, -4.23342921e-02, -4.60119806e-02,\n",
       "         -1.21019688e-03, -2.58894563e-02,  4.94120717e-02, -1.22601092e-02,\n",
       "          2.68221442e-02,  1.59101412e-02,  6.01683259e-02,  5.31142801e-02,\n",
       "          4.58844267e-02,  2.98795309e-02, -1.39490133e-02, -7.02950880e-02,\n",
       "          4.06263657e-02, -1.99024472e-02, -3.88253070e-02,  9.77772847e-03,\n",
       "          9.49482899e-03,  5.36282249e-02,  6.72818453e-04, -2.39744391e-02,\n",
       "          6.45609573e-03,  1.22669488e-02,  5.64675368e-02,  3.32036652e-02,\n",
       "         -3.18721384e-02,  4.00822051e-03,  4.52602394e-02, -4.41591814e-03,\n",
       "          9.69781447e-03,  8.22617486e-02,  5.87297417e-02,  7.36266151e-02,\n",
       "          1.05028702e-02,  2.01947894e-02,  4.52671060e-03,  6.35363907e-02,\n",
       "          2.96386704e-02,  2.03318037e-02,  6.10474544e-03, -5.83177991e-02,\n",
       "         -5.40715270e-02,  5.78865074e-02,  8.17433279e-03,  4.81602438e-02,\n",
       "         -2.47722063e-02,  5.47645427e-02, -7.70381838e-03,  7.54449293e-02,\n",
       "          5.94194680e-02,  7.24788308e-02, -3.80226932e-02,  1.88736618e-02,\n",
       "         -3.31980363e-02, -1.80855710e-02, -5.48030920e-02,  3.93421017e-02,\n",
       "          2.49332581e-02, -5.45614399e-03, -4.27190922e-02, -1.27416356e-02,\n",
       "          7.11625442e-02,  3.35103758e-02,  4.93348651e-02,  1.75818373e-02,\n",
       "         -6.17948584e-02,  2.00969800e-02,  4.74065356e-02, -1.88171677e-03,\n",
       "          2.71110926e-02, -2.80699152e-02,  2.99006496e-02, -2.12829188e-03,\n",
       "         -3.95262130e-02, -7.00873658e-02,  1.17492294e-02, -1.06804492e-02,\n",
       "          2.94700707e-03,  5.16694784e-02,  3.00094653e-02,  2.05254927e-02,\n",
       "         -2.23516743e-03, -2.88733002e-02, -4.47897315e-02,  3.45651060e-02,\n",
       "          1.17496327e-02, -5.21141775e-02, -9.58930049e-03, -9.82947648e-03,\n",
       "         -1.64384730e-02,  6.25566617e-02, -7.09879175e-02, -3.45591269e-02,\n",
       "         -2.09147651e-02, -2.97615454e-02, -1.25521524e-02, -1.31838098e-02,\n",
       "         -1.76883135e-02, -4.06755544e-02,  5.20331748e-02, -5.07226996e-02,\n",
       "         -9.52662528e-03,  6.88776420e-03, -2.70917341e-02,  6.50540367e-02,\n",
       "          3.88515554e-02, -1.22238882e-03, -4.04316001e-02, -3.97895910e-02,\n",
       "          1.77766848e-03,  9.92095750e-03,  4.10607196e-02,  1.00610533e-03,\n",
       "          1.34574389e-02,  2.17815936e-02,  5.09269051e-02, -5.04779024e-03,\n",
       "          3.51865105e-02,  2.47054938e-02, -1.97586026e-02,  6.81038247e-03,\n",
       "         -7.62478933e-02, -3.92875867e-03, -6.55168369e-02,  4.77157347e-02,\n",
       "         -1.94237996e-02, -5.31341732e-02,  6.83512911e-02, -2.77163386e-02,\n",
       "          2.35732738e-02, -4.61505949e-02,  3.28990184e-02, -5.40613122e-02,\n",
       "          3.27224098e-02,  3.86379622e-02,  5.39731421e-02,  7.05333352e-02,\n",
       "         -4.27216031e-02,  3.78355347e-02,  5.04216820e-04,  3.90099809e-02,\n",
       "          3.88809741e-02, -3.67974006e-02, -4.54849051e-03, -5.28579764e-02,\n",
       "          2.30678041e-02,  1.64224580e-02, -6.81312904e-02, -4.21282612e-02,\n",
       "          7.24850297e-02,  5.94003610e-02, -3.12071387e-02, -5.62576158e-03,\n",
       "          1.92541406e-02,  4.70660217e-02,  5.67903556e-02, -2.03414205e-02,\n",
       "         -2.30854750e-02,  7.00594783e-02,  5.35228141e-02,  2.08853371e-03,\n",
       "          6.66501150e-02,  3.24590690e-02, -5.06294668e-02, -5.60148209e-02,\n",
       "          4.94187884e-02,  6.96526468e-02,  3.60497274e-02,  2.67028939e-02,\n",
       "         -1.75938883e-03,  1.72694272e-03, -2.44586286e-03, -3.02731078e-02,\n",
       "         -5.48732877e-02, -2.88044903e-02, -5.87557442e-02,  4.53794487e-02,\n",
       "          4.16014306e-02, -7.33838156e-02, -3.81382369e-02,  7.41698034e-03,\n",
       "          4.84791286e-02, -4.59951572e-02, -3.82288732e-02, -1.48842223e-02,\n",
       "         -1.84577703e-02, -8.14192928e-03,  3.91542651e-02, -4.00489941e-02,\n",
       "          1.20229656e-02,  5.99616170e-02, -3.46458331e-02,  5.60582578e-02,\n",
       "          1.04308443e-03,  1.33729456e-02,  1.76045131e-02,  3.94825637e-02,\n",
       "          2.80877426e-02,  2.56034527e-02, -1.67861953e-03, -1.42111990e-03,\n",
       "         -5.83317578e-02,  8.17603692e-02,  4.26083244e-02, -3.47940512e-02,\n",
       "         -4.42616502e-03, -6.69903532e-02, -1.85672718e-03,  1.18350908e-02,\n",
       "         -5.26361950e-02, -5.93905449e-02, -3.60484421e-02,  3.60224512e-03,\n",
       "         -2.17996072e-02,  6.32699803e-02, -2.09759772e-02, -8.33911076e-02,\n",
       "          1.33889476e-02, -3.51735204e-02,  1.45293830e-03, -1.72507130e-02,\n",
       "          6.63916692e-02,  5.31789213e-02,  2.27696095e-02,  2.57746819e-02,\n",
       "         -1.60418767e-02,  2.70053316e-02,  1.82206947e-02, -3.90064582e-04,\n",
       "         -9.15064383e-03, -5.60337603e-02,  7.02514022e-04,  2.80097183e-02,\n",
       "          8.24145600e-02,  5.81338815e-02, -9.67478380e-03,  3.52844261e-02,\n",
       "         -3.82691529e-03, -4.07924242e-02, -1.97114404e-02, -7.51006380e-02,\n",
       "          6.11223578e-02, -6.47556260e-02, -1.90193001e-02,  3.11480537e-02,\n",
       "          5.43478131e-02, -6.62374571e-02, -7.96275362e-02,  1.90033242e-02,\n",
       "         -6.66593835e-02,  7.30007216e-02, -2.51613054e-02, -4.92133051e-02,\n",
       "          1.33860512e-02, -1.39397355e-02,  9.61243000e-04,  2.15356257e-02,\n",
       "          5.36376191e-03, -3.06033622e-02,  4.20123674e-02, -6.74581602e-02,\n",
       "         -5.53355999e-02, -2.26293057e-02, -3.94356512e-02, -1.71869081e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 66,\n",
       "  'topic_words': array(['sklearn', 'learner', '학습', 'learning', 'courses', 'teach',\n",
       "         'learns', 'tutorial', 'learn', '전공', '과정', 'classes', 'taught',\n",
       "         'neural', 'teaching', 'neurosciences', 'neuroscience', 'neurosci',\n",
       "         'programming', '교육', 'faculty', 'training', '클래스', 'education',\n",
       "         'learned', 'undergraduate', '강좌', 'formation', 'computing',\n",
       "         'computational', 'neurol', '수업', '공부', '배울', 'student',\n",
       "         'textbooks', 'study', 'computation', 'institute', '훈련', 'studying',\n",
       "         '연습', 'neuro', 'college', 'academic', '교수', 'neurocultures', '지식',\n",
       "         'class', 'trained'], dtype='<U15'),\n",
       "  'topic_vector': array([-4.25019227e-02,  5.36231846e-02, -2.81324182e-02, -7.69830449e-03,\n",
       "          2.41463240e-02, -2.80175451e-02,  4.49077077e-02, -1.77210737e-02,\n",
       "          1.19608259e-02,  2.38933619e-02,  3.97705548e-02, -5.96767524e-03,\n",
       "          5.30016385e-02, -6.04245672e-03, -6.43061325e-02, -2.10426524e-02,\n",
       "          4.85370904e-02, -3.70884724e-02,  4.79057664e-03,  4.47524339e-02,\n",
       "         -1.27185909e-02, -2.98401173e-02,  5.07310443e-02,  3.45052034e-02,\n",
       "         -6.40052781e-02, -5.35650440e-02,  1.15355784e-02,  1.66740939e-02,\n",
       "         -4.63091992e-02, -2.15429291e-02, -5.14974296e-02,  3.77164148e-02,\n",
       "          3.43899168e-02, -5.56188375e-02, -3.98930773e-04,  7.20293634e-03,\n",
       "         -1.16560878e-02,  4.78258589e-03, -5.95780052e-02,  2.74786577e-02,\n",
       "         -2.09247787e-02,  3.82031240e-02,  3.47532667e-02, -3.69658172e-02,\n",
       "         -5.90170808e-02,  6.17149025e-02,  6.28518686e-02,  2.37573031e-02,\n",
       "         -4.77578342e-02, -3.31215598e-02,  3.30781713e-02, -7.95982126e-03,\n",
       "         -9.57474113e-05,  4.17649299e-02, -2.30972711e-02, -6.41041324e-02,\n",
       "          5.89707755e-02, -2.14405488e-02,  3.36909853e-02,  3.96715589e-02,\n",
       "         -3.29717807e-02,  6.39322698e-02,  5.35540888e-03, -4.51999307e-02,\n",
       "         -3.48443777e-04, -1.38287013e-02,  4.81736250e-02, -4.37755026e-02,\n",
       "         -3.93299349e-02, -6.60258904e-03, -2.71973405e-02,  2.63931081e-02,\n",
       "          5.43265529e-02, -1.69971343e-02,  3.29901017e-02, -1.35219350e-04,\n",
       "          2.58134902e-02,  6.33504102e-03,  4.18083370e-02, -6.43763244e-02,\n",
       "         -6.43785298e-02, -5.52641116e-02, -5.08286543e-02,  2.65505612e-02,\n",
       "          3.60303372e-02, -9.30260494e-03,  2.67196968e-02, -2.65480932e-02,\n",
       "          6.14566319e-02, -1.95046572e-03, -6.18740767e-02,  2.35312898e-02,\n",
       "         -2.06378065e-02, -3.48043628e-02,  6.13539256e-02,  5.07116430e-02,\n",
       "         -3.05899624e-02,  3.73231731e-02, -2.49145180e-02,  1.35491760e-02,\n",
       "         -5.82937011e-03,  4.88840602e-02, -1.08739911e-02, -5.85384027e-04,\n",
       "          2.91466713e-05,  2.10019201e-02, -6.42663613e-02,  2.10776925e-02,\n",
       "         -3.87901515e-02,  1.68737751e-02, -2.82609537e-02, -2.89206263e-02,\n",
       "          2.50133574e-02,  4.06380780e-02,  4.60091867e-02, -6.43460974e-02,\n",
       "         -3.91637683e-02,  5.70532866e-02, -3.61481011e-02, -1.67048704e-02,\n",
       "         -4.14412431e-02,  5.23255505e-02,  2.72373855e-02, -2.21121460e-02,\n",
       "          2.19740719e-02, -7.13930279e-03, -5.01238592e-02, -9.56419110e-03,\n",
       "         -1.54075408e-02, -5.38495183e-02, -1.56461727e-02, -1.77202728e-02,\n",
       "          3.33806463e-02,  4.75191288e-02, -5.33966860e-03,  6.11084402e-02,\n",
       "          7.38026947e-03, -2.12137606e-02,  6.02966249e-02,  2.83989254e-02,\n",
       "         -5.69146127e-04,  2.65568290e-02,  5.33859432e-02,  4.63620685e-02,\n",
       "         -2.20713019e-02, -7.46742869e-03,  5.21135367e-02,  1.11395521e-02,\n",
       "          3.47814639e-03,  1.33403661e-02,  6.04665093e-02,  4.80969436e-02,\n",
       "         -2.70602200e-02, -4.50828709e-02, -8.96442775e-03, -3.74853127e-02,\n",
       "         -4.21006680e-02, -1.57758165e-02, -6.14749789e-02, -5.99044375e-02,\n",
       "          4.84160334e-02, -5.86576341e-03, -4.51785028e-02,  3.20627838e-02,\n",
       "          1.76761150e-02,  7.65524665e-03, -5.05200215e-02, -4.16379534e-02,\n",
       "         -2.67907903e-02,  2.73390338e-02, -4.21313941e-03, -3.18627693e-02,\n",
       "          6.28684042e-03,  1.94815081e-02, -3.11576519e-02, -4.29491997e-02,\n",
       "         -5.91723882e-02, -5.44815743e-03, -6.12048954e-02,  5.92406131e-02,\n",
       "         -9.77938902e-03,  1.00088930e-02,  1.62337143e-02, -5.76399900e-02,\n",
       "         -2.68444177e-02,  5.45147769e-02,  3.83014642e-02,  6.37040809e-02,\n",
       "          2.08664257e-02, -3.60620767e-02,  3.15251388e-02, -2.96825692e-02,\n",
       "          5.81354238e-02, -1.03021236e-02, -1.90784875e-02,  3.65263037e-02,\n",
       "         -3.33718993e-02,  2.75192857e-02,  3.21642719e-02,  2.52941940e-02,\n",
       "         -1.88267585e-02, -2.06358242e-03, -3.47224511e-02, -4.31441702e-02,\n",
       "         -2.96096131e-02,  2.93144360e-02,  5.07937558e-02, -2.78262272e-02,\n",
       "          2.73606237e-02, -2.99393642e-03,  1.94976181e-02, -1.73318817e-03,\n",
       "         -5.30053116e-02, -4.77481494e-03,  3.39032896e-02, -4.97596003e-02,\n",
       "          1.92896854e-02, -5.19451909e-02, -2.09023952e-02,  1.08927935e-02,\n",
       "         -1.30176023e-02,  3.17296982e-02,  3.19399722e-02, -1.06827430e-02,\n",
       "         -3.76251340e-02,  9.84475296e-03, -4.82094102e-02,  4.23845612e-02,\n",
       "          8.54589790e-03,  2.08174866e-02,  1.95262693e-02, -2.53525581e-02,\n",
       "          1.06506497e-02,  1.08479811e-02,  4.62772436e-02,  3.67308892e-02,\n",
       "          3.74106355e-02,  4.67416830e-02,  6.40943944e-02, -3.85931730e-02,\n",
       "         -4.73963916e-02, -5.77499205e-03, -1.47507153e-03, -4.60725315e-02,\n",
       "         -9.89434961e-03, -5.43636680e-02, -1.39024633e-03, -2.34607290e-02,\n",
       "          3.81232202e-02, -4.83875833e-02, -3.36056463e-02, -6.09059632e-02,\n",
       "          5.23853563e-02,  7.51567120e-03,  5.03515117e-02, -3.05745471e-02,\n",
       "          2.55202372e-02, -9.48054437e-03, -3.04308236e-02,  3.62672471e-02,\n",
       "          2.89402027e-02,  7.74109876e-03,  2.84252819e-02, -4.00032513e-02,\n",
       "          3.99073176e-02, -5.25500774e-02, -2.64565945e-02,  4.83591743e-02,\n",
       "          2.88292710e-02,  3.73637378e-02, -1.76348779e-02, -3.42543386e-02,\n",
       "         -2.93156933e-02, -3.59869492e-03,  3.75297293e-02,  4.26307730e-02,\n",
       "         -4.68080938e-02,  3.94723676e-02, -5.41238487e-02, -4.08187844e-02,\n",
       "         -1.72215011e-02, -5.13104796e-02,  3.77769358e-02,  1.78863592e-02,\n",
       "         -4.90434133e-02, -9.19106510e-03, -3.66420485e-02, -1.92836877e-02,\n",
       "         -2.96113524e-03, -7.88408052e-03,  3.76719870e-02,  5.64586334e-02,\n",
       "         -1.33154159e-02,  2.82749832e-02, -6.22599088e-02,  3.64960022e-02,\n",
       "         -6.06394745e-02,  4.79278751e-02,  2.31252536e-02,  6.21323148e-03,\n",
       "         -3.73499878e-02, -3.42008211e-02,  4.68548127e-02, -5.67278117e-02,\n",
       "          2.64439378e-02,  2.71872263e-02, -5.21487892e-02,  4.29923534e-02,\n",
       "          3.97630371e-02,  3.90799679e-02,  1.42499367e-02, -3.19950767e-02,\n",
       "         -4.71179076e-02, -1.60795767e-02,  2.90591568e-02,  1.03259021e-02,\n",
       "         -5.55461533e-02,  2.77126338e-02,  6.19053431e-02, -1.90859307e-02,\n",
       "          3.81137282e-02,  2.43825167e-02, -4.02286351e-02, -2.02148277e-02,\n",
       "         -1.93723086e-02,  4.74190973e-02,  9.33582801e-03, -3.07583828e-02,\n",
       "          1.80148680e-04,  5.58686443e-03, -1.76157115e-03, -5.99115677e-02,\n",
       "         -5.96811511e-02, -6.41338006e-02, -2.75763050e-02,  3.18884477e-02,\n",
       "         -3.34999561e-02,  5.36451489e-03, -6.06815703e-02,  1.23566017e-03,\n",
       "         -4.20483202e-02,  1.77038293e-02, -3.41575481e-02, -3.11467797e-02,\n",
       "         -3.91291864e-02,  4.85396199e-02,  4.09771092e-02,  1.96491107e-02,\n",
       "          8.35871976e-03, -2.82507297e-02, -1.75181348e-02, -1.57690626e-02,\n",
       "         -6.34277379e-03,  2.55464879e-03, -6.07195459e-02, -5.69208106e-03,\n",
       "          3.55452597e-02,  5.19134700e-02,  5.43807214e-03, -3.50342877e-02,\n",
       "          1.81367937e-02,  3.82959214e-03,  5.81398793e-02, -6.38556555e-02,\n",
       "          7.05092167e-03,  3.59141417e-02, -3.57999913e-02,  2.06284467e-02,\n",
       "         -2.43424121e-02, -2.09113583e-03,  3.68313454e-02,  1.18841371e-02,\n",
       "         -2.74999943e-02,  2.79848482e-02,  8.11153185e-03,  2.73232907e-03,\n",
       "         -3.00795492e-02, -1.33650342e-03, -1.17477179e-02, -1.54766487e-02,\n",
       "         -5.14916563e-03,  1.85561012e-02,  8.43673851e-03,  2.55699325e-02,\n",
       "         -3.81560693e-03,  6.14700131e-02, -4.79992889e-02, -5.28592877e-02,\n",
       "          6.33352250e-02,  5.28796948e-02, -2.38376739e-03, -5.70224561e-02,\n",
       "         -4.46628816e-02,  3.78271863e-02, -1.58285461e-02,  3.57494387e-03,\n",
       "          5.60235083e-02,  3.38198766e-02, -6.08950071e-02,  2.24291999e-02,\n",
       "          4.41724770e-02,  5.55471629e-02,  6.10107966e-02, -2.87578106e-02,\n",
       "         -4.06463109e-02, -1.30981505e-02, -1.84617192e-03, -3.74693912e-03,\n",
       "          2.30964776e-02,  9.97462403e-03,  2.95008402e-02,  6.29734108e-03,\n",
       "          4.67629582e-02, -5.72577827e-02,  5.11772335e-02,  5.43947816e-02,\n",
       "          2.96678636e-02,  2.08692160e-02, -4.49911617e-02,  2.89811138e-02,\n",
       "         -2.15089563e-02,  7.70996930e-03,  4.80824746e-02,  3.12052369e-02,\n",
       "          4.57046330e-02,  2.84433272e-02, -8.29185918e-03, -3.86206917e-02,\n",
       "         -2.06750743e-02, -4.26376164e-02, -4.51794406e-03,  1.74864326e-02,\n",
       "          1.66296903e-02, -4.26663347e-02,  2.60267463e-02,  5.38843572e-02,\n",
       "          3.41644920e-02,  1.34465024e-02, -5.65251224e-02,  2.66330806e-03,\n",
       "         -4.18686308e-02,  5.20888120e-02,  1.29875215e-02, -6.19509183e-02,\n",
       "          1.81011558e-02,  2.23861039e-02,  6.42964840e-02,  3.31715159e-02,\n",
       "          6.43771589e-02, -2.19394397e-02, -8.90038535e-03,  2.40834299e-02,\n",
       "         -4.30798298e-03,  6.03295900e-02, -4.47456539e-02, -3.93868098e-03,\n",
       "          2.51642670e-02, -2.37550735e-02, -2.97124088e-02, -4.55938578e-02,\n",
       "          1.15121156e-03, -1.37925968e-02,  5.13371229e-02,  2.90425178e-02,\n",
       "         -3.01113371e-02, -6.14088587e-02, -6.01667874e-02,  3.14866714e-02,\n",
       "          6.39101267e-02, -5.97437322e-02,  7.69595755e-03,  6.38616756e-02,\n",
       "         -3.96026038e-02, -2.78050546e-02, -3.94301936e-02, -5.10039218e-02,\n",
       "          7.97249842e-03,  4.02508713e-02, -3.76477689e-02, -5.10214381e-02,\n",
       "          1.27331140e-02,  5.38971014e-02, -4.14014347e-02,  1.76229887e-02,\n",
       "          5.51363714e-02,  5.84805198e-02,  2.96281856e-02, -6.42869547e-02,\n",
       "         -5.91883063e-02, -1.56921148e-02,  2.89889723e-02, -3.33821662e-02,\n",
       "          3.18751745e-02, -2.43223626e-02, -1.26281409e-02,  4.25523333e-02,\n",
       "          1.94565803e-02, -7.23496312e-03,  7.80560821e-03,  3.11259795e-02,\n",
       "          3.94562595e-02, -6.24396615e-02,  7.46622821e-03, -4.87593748e-02,\n",
       "         -5.80168255e-02, -6.14877343e-02, -5.28253280e-02,  4.22860533e-02,\n",
       "         -2.70597916e-02, -6.28443435e-02,  4.92311902e-02,  1.54534904e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 67,\n",
       "  'topic_words': array(['히어로', 'heroes', '캐릭터', '아이언맨', 'hero', 'character', 'abilities',\n",
       "         'creatures', 'characters', 'weapon', 'kruskal', 'episodic',\n",
       "         'monster', 'ability', 'fiction', 'spearman', 'tishby', '인간',\n",
       "         'human', '능력', 'bandersnatch', 'fantasy', 'destruction', 'damage',\n",
       "         '인류', 'warden', 'humans', 'kasper', 'animal', 'deviance',\n",
       "         'substantia', '문자', 'sporns', 'name', 'selvars', 'crawler',\n",
       "         'names', 'scholar', 'blacklist', 'legend', 'mask', 'skills',\n",
       "         'spider', 'skill', '공격', 'spike', '사이보그', 'masks', 'aversive',\n",
       "         'ashburner'], dtype='<U15'),\n",
       "  'topic_vector': array([ 0.041763  , -0.01308853,  0.0082689 ,  0.01162295,  0.00554183,\n",
       "          0.05078851, -0.0068712 , -0.01552673,  0.05490237, -0.00654878,\n",
       "          0.02228628, -0.01743145,  0.02376212, -0.05175202, -0.04839996,\n",
       "         -0.00419785,  0.00528489, -0.03983982, -0.01451103,  0.05130759,\n",
       "         -0.00639854, -0.03462349,  0.05064808,  0.02691712, -0.0489154 ,\n",
       "         -0.01401099,  0.02836351,  0.00706907,  0.03672098, -0.05965523,\n",
       "         -0.02502346,  0.0232529 ,  0.03213025, -0.03950137,  0.00063492,\n",
       "         -0.00803907, -0.00497629, -0.02053215, -0.00073161, -0.05000959,\n",
       "         -0.04071498,  0.03736185, -0.00473807,  0.00568474, -0.01182288,\n",
       "         -0.01783593, -0.02356817, -0.05969581,  0.02003929, -0.00948844,\n",
       "         -0.00692947, -0.01277671, -0.01425028, -0.00865638, -0.00091799,\n",
       "         -0.05539265,  0.03797995,  0.04673042,  0.02613369,  0.01385809,\n",
       "          0.00356643,  0.05879015,  0.02521936, -0.01105962,  0.00372405,\n",
       "         -0.01060397,  0.04212856, -0.0494045 , -0.04322713, -0.0107978 ,\n",
       "          0.0384944 , -0.04643503,  0.05433603,  0.0106794 ,  0.00302602,\n",
       "          0.02905256, -0.04033668,  0.03674196,  0.01053065, -0.06010541,\n",
       "         -0.0600796 , -0.01941839,  0.0360878 ,  0.04145633,  0.00572895,\n",
       "         -0.02049352, -0.01657492, -0.02982977, -0.03449904, -0.01216272,\n",
       "         -0.0051929 , -0.01658865, -0.05860806,  0.0457724 ,  0.05042371,\n",
       "         -0.00418313,  0.00718831,  0.04485483,  0.0149275 , -0.00620474,\n",
       "          0.00296727,  0.00175171,  0.00427931, -0.03025289,  0.04070314,\n",
       "         -0.01587063,  0.05092011, -0.04585786, -0.04668704,  0.03617996,\n",
       "          0.00106225, -0.01873318,  0.00013318, -0.01163581,  0.00936611,\n",
       "          0.00490472, -0.00535556, -0.00970998, -0.00463118, -0.01098805,\n",
       "         -0.0010496 ,  0.01519391,  0.04044307,  0.04136154,  0.02139703,\n",
       "         -0.01064929,  0.02205111, -0.02347639,  0.0137855 , -0.02456402,\n",
       "         -0.04084946, -0.03746171, -0.00853058,  0.01195163, -0.04785426,\n",
       "          0.05072904, -0.00793354,  0.00873645,  0.03761975, -0.02479608,\n",
       "         -0.01764492, -0.01212671,  0.03439635,  0.03824599,  0.02410692,\n",
       "         -0.02355664,  0.04836878, -0.02899157, -0.01586459, -0.01696912,\n",
       "          0.03989343,  0.01017166, -0.00384922,  0.0328049 ,  0.03483323,\n",
       "          0.01859069, -0.01888778, -0.03608119, -0.04765137, -0.04041645,\n",
       "          0.050092  , -0.02793337,  0.00224769, -0.00398263, -0.03470201,\n",
       "         -0.04599678, -0.04381562, -0.0339971 , -0.00027869,  0.0047921 ,\n",
       "          0.01722026,  0.03906468,  0.0110503 , -0.0028131 ,  0.02230736,\n",
       "          0.01887347, -0.02647668,  0.0148798 ,  0.03338061,  0.05061055,\n",
       "          0.01139993, -0.00968427, -0.0014253 , -0.01492503, -0.03938738,\n",
       "          0.03777738,  0.02282666,  0.05326942, -0.01113767,  0.00257194,\n",
       "          0.03284422,  0.00013315,  0.04151807,  0.02539702, -0.01282393,\n",
       "          0.03111244, -0.0265062 , -0.03575494,  0.04441654,  0.0450746 ,\n",
       "         -0.01593072,  0.0409851 ,  0.01119557, -0.048846  , -0.02905529,\n",
       "          0.01814484,  0.00729921, -0.01875173, -0.01365386,  0.02343361,\n",
       "         -0.02563287,  0.04316147, -0.01471322,  0.03128212,  0.03708017,\n",
       "         -0.01911099,  0.00366162, -0.03258049,  0.01929251,  0.0503293 ,\n",
       "         -0.01477195, -0.0240682 ,  0.01949228,  0.03121843, -0.00516093,\n",
       "         -0.0252344 , -0.03521303,  0.00656545, -0.05638941, -0.03518823,\n",
       "          0.02715692,  0.01780579, -0.00099075,  0.05912874, -0.01141529,\n",
       "          0.04173351, -0.02733168, -0.02223711, -0.0242596 ,  0.02552151,\n",
       "          0.0075392 , -0.0138338 ,  0.025223  , -0.0294087 , -0.00708698,\n",
       "          0.03529324,  0.03981408, -0.01547205,  0.02386449,  0.02496462,\n",
       "         -0.018387  ,  0.02127989, -0.00389298, -0.03410453,  0.02274424,\n",
       "          0.01314211,  0.0072125 , -0.02615686, -0.04696338,  0.05041867,\n",
       "         -0.00071261,  0.0370491 , -0.03742583, -0.01893687,  0.03411965,\n",
       "         -0.01862191, -0.00641757,  0.01703233, -0.01544396,  0.01764883,\n",
       "         -0.0472147 , -0.03368853,  0.01042387, -0.02222264,  0.0499141 ,\n",
       "         -0.00819305, -0.01200693,  0.00199893, -0.05639372,  0.01644053,\n",
       "         -0.03329853, -0.0036386 ,  0.03040576, -0.00928247,  0.02713173,\n",
       "          0.01310197, -0.05486907, -0.03549816, -0.0326313 ,  0.01797498,\n",
       "         -0.01350057, -0.03869356,  0.00190633,  0.05258209, -0.01507017,\n",
       "          0.0558694 ,  0.0112913 ,  0.02029544,  0.03332865,  0.03054606,\n",
       "          0.00468426,  0.00101711, -0.00258099, -0.04107609, -0.00159417,\n",
       "          0.02331496, -0.0483731 ,  0.04526563,  0.0359589 , -0.0054369 ,\n",
       "          0.00344812,  0.01169547, -0.01712189,  0.0079299 ,  0.04465723,\n",
       "          0.0366617 ,  0.03735702,  0.02306787, -0.05749631,  0.02972001,\n",
       "          0.03063547, -0.02061636, -0.02733893,  0.02949782, -0.05839515,\n",
       "          0.01805306,  0.02109748,  0.00303239,  0.04200982, -0.00383541,\n",
       "         -0.01612183,  0.01899169, -0.02064375,  0.02498964,  0.00020981,\n",
       "         -0.00809342, -0.05709675,  0.01671626, -0.03637005, -0.00439786,\n",
       "         -0.01331767,  0.03033787, -0.04360718, -0.01846882,  0.01800284,\n",
       "         -0.01535889,  0.03403364,  0.02670007,  0.01537444, -0.00094722,\n",
       "         -0.00311304,  0.01548925,  0.03605079,  0.0211296 , -0.04154374,\n",
       "         -0.0251933 ,  0.02784293,  0.0460199 ,  0.00367213, -0.05446226,\n",
       "          0.04694597,  0.00417696,  0.03006942,  0.05884159,  0.0058012 ,\n",
       "         -0.02758923,  0.01080791,  0.03878953,  0.00432316,  0.00987783,\n",
       "         -0.00736387, -0.01543838,  0.02318178,  0.02729658,  0.03507093,\n",
       "          0.05802127, -0.02438271, -0.0167092 ,  0.00306483, -0.00809252,\n",
       "         -0.00555747, -0.0103644 ,  0.04215411,  0.03338679, -0.00207155,\n",
       "         -0.00511659, -0.02029578, -0.06012982,  0.05322884, -0.02910541,\n",
       "          0.00907182, -0.00200614,  0.01538105, -0.02278506, -0.00926813,\n",
       "         -0.04006879,  0.00848478,  0.00299261, -0.02465813,  0.04412717,\n",
       "          0.05568301,  0.04911654, -0.06017678, -0.02490373, -0.02176626,\n",
       "          0.00160257,  0.0271988 , -0.04540602,  0.04341013,  0.00753943,\n",
       "         -0.00564822, -0.01271484,  0.05395522,  0.02937362, -0.01391994,\n",
       "          0.02452819,  0.03294144,  0.01740247, -0.00544345, -0.00151806,\n",
       "          0.01336263,  0.02022655,  0.05232321,  0.03715439,  0.04796328,\n",
       "          0.05212267,  0.03466168,  0.01932704, -0.04317299, -0.0311711 ,\n",
       "          0.00389037, -0.03947455, -0.03891153, -0.05398171,  0.0551551 ,\n",
       "          0.02953858,  0.03638009,  0.01206186, -0.03588624,  0.05112081,\n",
       "         -0.0442899 ,  0.03995368, -0.00745253, -0.04845951, -0.03166898,\n",
       "          0.03822743,  0.05884523,  0.03276975,  0.00408796,  0.02662376,\n",
       "          0.04237919,  0.05023117, -0.01598353, -0.00736452, -0.00067575,\n",
       "          0.04748879, -0.0083693 ,  0.01738782, -0.01262436,  0.03325085,\n",
       "          0.04041065,  0.02061575,  0.00704897, -0.02721479, -0.0146171 ,\n",
       "         -0.03731817, -0.05239892,  0.04878704, -0.03217478, -0.02290083,\n",
       "         -0.04072491, -0.03780572,  0.05262423,  0.00119835,  0.01252435,\n",
       "          0.03585114, -0.02899434, -0.00875333, -0.03400374, -0.02956138,\n",
       "         -0.05547302,  0.02457616, -0.05411424,  0.01971671, -0.06016606,\n",
       "          0.00115667,  0.011524  , -0.05870539, -0.01418014, -0.04834274,\n",
       "         -0.04744284, -0.04232833,  0.04363076,  0.02228413,  0.02628994,\n",
       "         -0.00726382, -0.05493843,  0.00943534, -0.03333986,  0.00250977,\n",
       "          0.0111428 , -0.0096265 ,  0.02326353,  0.05072729, -0.04549809,\n",
       "          0.02747004,  0.01205877,  0.01149597,  0.00215406, -0.00110572,\n",
       "         -0.0009212 , -0.02306223], dtype=float32)},\n",
       " {'topic_idx': 68,\n",
       "  'topic_words': array(['adhd', 'children', 'syndromes', 'diagnosed', 'developmental',\n",
       "         'syndrome', 'child', 'neurology', 'diagnoses', 'neuroscientific',\n",
       "         'disorders', 'neurological', 'disorder', '아이', 'hyperactivity',\n",
       "         'diagnosis', 'sensory', 'hd', 'kid', 'adolescents', 'childhood',\n",
       "         'symptom', 'somatosensory', 'sensitivity', 'icds', 'ptsd',\n",
       "         'neurosci', 'demographic', 'neurol', 'symptoms', 'neurogenesis',\n",
       "         'neuroimaging', 'neuro', 'chronic', 'neuroethics', 'perceptual',\n",
       "         'neurosciences', '장애', 'epilepsy', 'schizophrenia', 'neuroscience',\n",
       "         'impulsive', 'diagnostic', 'impulsivity', 'impaired', 'icd', 'eds',\n",
       "         'numeric', 'compulsive', '증상'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.04852875,  0.0213696 ,  0.05132091, -0.03666273,  0.0122194 ,\n",
       "          0.0317848 , -0.04632974,  0.02968426, -0.00712613,  0.02075875,\n",
       "          0.04436487, -0.05668308,  0.035979  , -0.03989473, -0.0175741 ,\n",
       "          0.01835109, -0.01406981,  0.017801  ,  0.02126026,  0.05457262,\n",
       "         -0.01597726, -0.04001569, -0.00735325,  0.0485881 , -0.05700117,\n",
       "          0.02579967, -0.05661393, -0.01099387,  0.01600613, -0.02005995,\n",
       "         -0.03905183,  0.00762072,  0.03134685, -0.05289974,  0.0336129 ,\n",
       "         -0.01111245,  0.01015166, -0.00126622, -0.04606377, -0.05617074,\n",
       "         -0.02557488, -0.05218564,  0.05709052, -0.04974657, -0.00280421,\n",
       "          0.05714768,  0.05705475,  0.02157368,  0.01940695, -0.05462893,\n",
       "          0.0559523 ,  0.02944461,  0.00390097, -0.02530723, -0.00369628,\n",
       "         -0.01832258, -0.00406667,  0.02467058, -0.05318475,  0.05669974,\n",
       "          0.04852033,  0.05620973, -0.02918338, -0.01493007, -0.03355955,\n",
       "          0.03246926,  0.00586477,  0.02839274, -0.03931158,  0.00114364,\n",
       "          0.04426286, -0.04849424,  0.01655679, -0.05714391, -0.05696515,\n",
       "          0.01808509,  0.05674161, -0.0118383 , -0.02938455, -0.05534822,\n",
       "         -0.05703137, -0.03423351, -0.04452093,  0.04550135, -0.04182404,\n",
       "          0.01977591,  0.01899573,  0.03622376,  0.04973839, -0.05558298,\n",
       "         -0.03743181, -0.03294575, -0.01741614, -0.05495661, -0.01189846,\n",
       "          0.04658836,  0.04262789,  0.05528812,  0.0071109 ,  0.03911738,\n",
       "          0.01627948, -0.02186718,  0.00785409,  0.00660643,  0.01081949,\n",
       "          0.05675864, -0.04955867,  0.05196632, -0.01796862, -0.00507861,\n",
       "         -0.00280315, -0.05675813, -0.03388801,  0.05709979,  0.05593662,\n",
       "         -0.05482647,  0.00334673, -0.00089021,  0.00130993, -0.05509484,\n",
       "         -0.01566245,  0.05052622,  0.03638262, -0.02036423, -0.04330655,\n",
       "          0.05425047,  0.05672476, -0.03566634, -0.04019303,  0.04937248,\n",
       "         -0.0029908 , -0.0538224 , -0.00066723, -0.05014582,  0.04550445,\n",
       "          0.05677551, -0.04532276, -0.04223035,  0.05594367,  0.04921119,\n",
       "          0.05107212,  0.0099569 ,  0.05008839, -0.0250569 ,  0.04564868,\n",
       "          0.03299481,  0.00356545,  0.03363473, -0.01557168,  0.03773482,\n",
       "          0.03475923,  0.04577191, -0.00878081,  0.00043597, -0.05553484,\n",
       "          0.04199328, -0.02660243, -0.02693618,  0.0466884 , -0.02622983,\n",
       "          0.02927715, -0.04470076, -0.05693724, -0.02550188,  0.04703156,\n",
       "         -0.05085308,  0.01286279, -0.02777641, -0.05628274,  0.02896301,\n",
       "         -0.05027504, -0.05641927,  0.03793954,  0.02967888, -0.03767727,\n",
       "          0.03174935, -0.0569291 , -0.00941468,  0.00818107, -0.0133139 ,\n",
       "          0.01155874, -0.0259109 ,  0.05155553,  0.01558773, -0.01175152,\n",
       "          0.01342465,  0.01453908,  0.05159552,  0.04793834,  0.04301411,\n",
       "         -0.04721468, -0.01586536, -0.00094829,  0.02906386, -0.05714662,\n",
       "         -0.02971288,  0.00582219,  0.04499516, -0.00937354,  0.00905001,\n",
       "         -0.05504203,  0.01858103, -0.00275381, -0.0203244 ,  0.05190611,\n",
       "         -0.05522366, -0.00801746,  0.05422276,  0.0473848 ,  0.02680411,\n",
       "          0.02266641, -0.04704458,  0.05236888, -0.01768026,  0.04342701,\n",
       "          0.04962519,  0.0260585 , -0.05446623,  0.00481428, -0.00125342,\n",
       "          0.03675661,  0.03264789,  0.05633374,  0.03656046, -0.05671279,\n",
       "         -0.0326596 , -0.05629389,  0.02448281,  0.02802104, -0.00754973,\n",
       "         -0.0193807 ,  0.01985745,  0.02769005,  0.05040462,  0.03462713,\n",
       "         -0.05298804, -0.00239238, -0.03295592,  0.02811965,  0.0302835 ,\n",
       "         -0.03080029,  0.03347961, -0.01114062,  0.05032169,  0.01800983,\n",
       "         -0.03902491,  0.01418677, -0.05143537,  0.05620103,  0.04610939,\n",
       "         -0.03106182, -0.0429953 , -0.0068468 , -0.01990663, -0.02667026,\n",
       "         -0.05285291, -0.00145871, -0.02601865, -0.04438539, -0.01346033,\n",
       "          0.02915169,  0.03959499, -0.02451134,  0.05124609,  0.05098941,\n",
       "         -0.05660379, -0.02933711,  0.05462427,  0.00972623,  0.05013525,\n",
       "          0.01677827, -0.00479247,  0.04740232, -0.0468076 ,  0.04116789,\n",
       "          0.03210221, -0.04460771, -0.01763226, -0.0553796 , -0.00244929,\n",
       "         -0.05307159,  0.02294588, -0.03339725,  0.02150195, -0.05558702,\n",
       "          0.02985443, -0.03877772, -0.01045261, -0.03444183, -0.02408833,\n",
       "          0.05635875, -0.00829653, -0.00688105,  0.01845568, -0.02116815,\n",
       "         -0.05349684,  0.05025129,  0.0373189 ,  0.00757247,  0.05558171,\n",
       "         -0.03253942, -0.01399038,  0.01062378, -0.03578372, -0.0274049 ,\n",
       "         -0.01836099, -0.02142654,  0.0264424 ,  0.04147938,  0.04638202,\n",
       "         -0.04608585, -0.05566141,  0.00569409, -0.05502119,  0.02746485,\n",
       "          0.05284439,  0.02346116, -0.01704736,  0.05299962, -0.0349055 ,\n",
       "          0.01453879, -0.05713813, -0.01677901,  0.05466785,  0.02513301,\n",
       "         -0.03639004, -0.03278759,  0.03249363,  0.00857623,  0.0263657 ,\n",
       "         -0.00223593, -0.03826873, -0.05545415, -0.0571481 , -0.00640714,\n",
       "          0.0347813 , -0.05459101, -0.02883416, -0.0120894 , -0.00335446,\n",
       "         -0.03690759, -0.01549079,  0.05281642, -0.0376947 , -0.01571525,\n",
       "          0.04645574,  0.05683257, -0.04818107, -0.04225719, -0.00460632,\n",
       "         -0.00603548,  0.01296704, -0.03994412,  0.04575896,  0.05175956,\n",
       "          0.03639318,  0.04216808,  0.05563858, -0.05156855, -0.04314123,\n",
       "         -0.03957104, -0.01107649,  0.04663981,  0.01771111, -0.04928828,\n",
       "          0.05426971, -0.02928814,  0.02123004, -0.04533393, -0.02111274,\n",
       "          0.05655501,  0.0481237 ,  0.05113645, -0.00342189, -0.04664141,\n",
       "         -0.02527951,  0.02564513,  0.02341237,  0.04603978, -0.0231465 ,\n",
       "          0.04265123, -0.00636227,  0.00840864,  0.02727037, -0.00065526,\n",
       "          0.05710246,  0.04167515, -0.05686285,  0.05695438, -0.04348956,\n",
       "          0.05274165, -0.02064301,  0.02038156,  0.05627572, -0.0199547 ,\n",
       "          0.05552636,  0.05617311, -0.02624013,  0.0562834 , -0.01179149,\n",
       "          0.00336995,  0.05631879,  0.02645582,  0.04620695,  0.03809429,\n",
       "          0.0311832 ,  0.02342617, -0.04728531,  0.03476105,  0.02723478,\n",
       "          0.04269395, -0.00045642,  0.01503289,  0.05695866, -0.02928483,\n",
       "          0.05635912,  0.0391342 , -0.05300325,  0.03070604, -0.04593803,\n",
       "         -0.0441754 , -0.02428197,  0.03452025,  0.0049674 ,  0.04408548,\n",
       "         -0.05714786, -0.02897529, -0.04792069, -0.01677443, -0.03920121,\n",
       "         -0.0547782 , -0.01338244, -0.04988686, -0.04819288, -0.02674718,\n",
       "          0.03016523, -0.03496337, -0.05486952, -0.0570229 ,  0.05118725,\n",
       "          0.0130815 , -0.03176355,  0.00436055, -0.05283305,  0.02405422,\n",
       "         -0.01615013, -0.00574176,  0.01611756,  0.03032096, -0.00759702,\n",
       "         -0.055424  ,  0.02479846, -0.01572817,  0.00620058, -0.01727462,\n",
       "          0.04998527,  0.0321035 ,  0.02196368,  0.00360559, -0.04804983,\n",
       "         -0.05627649,  0.00098314, -0.01153487, -0.03377982, -0.01577408,\n",
       "         -0.0558739 , -0.02302127, -0.03631264,  0.05299006,  0.05207397,\n",
       "         -0.03735647,  0.05703433, -0.03901296,  0.00705992, -0.00134268,\n",
       "         -0.04193381,  0.03158132, -0.04666783, -0.05306605,  0.01469775,\n",
       "          0.05305289,  0.05714732, -0.01516524, -0.01467582,  0.04674671,\n",
       "         -0.04656832, -0.00693606, -0.03477812,  0.01992725, -0.04864565,\n",
       "          0.03015991,  0.03457727, -0.01001179,  0.04736629, -0.04097459,\n",
       "         -0.05284855, -0.01788147,  0.04952176, -0.00905662, -0.01567202,\n",
       "         -0.0538244 , -0.0166164 ,  0.04391922, -0.04172521, -0.04659569,\n",
       "         -0.03788868, -0.00595548, -0.02837885, -0.03504784, -0.05653746,\n",
       "          0.05071634,  0.03785625], dtype=float32)},\n",
       " {'topic_idx': 69,\n",
       "  'topic_words': array(['clustering', 'clusters', 'matplotlib', 'cluster', 'dataset',\n",
       "         'dataframe', 'datasets', 'sklearn', 'numpy', 'data', 'matlab',\n",
       "         'tensorflow', 'statistics', 'cython', 'statistic', 'statistically',\n",
       "         'computationally', '데이터', 'python', 'ggplot', 'statistical',\n",
       "         'vertexcount', '통계청', 'correlations', '통계', 'computing',\n",
       "         'computational', 'computation', 'scatterplot', 'populations',\n",
       "         'github', 'computed', 'correlate', 'correlation', 'algorithms',\n",
       "         'correlated', 'correlates', 'graphs', 'sampling', 'stats',\n",
       "         'synapses', 'calculations', 'lineplot', 'twindata', 'urllib',\n",
       "         'median', 'scaling', '커널', 'cumulative', 'cohort'], dtype='<U15'),\n",
       "  'topic_vector': array([-6.36906624e-02,  3.16027342e-03,  3.39945167e-04,  3.39215249e-03,\n",
       "         -1.20445071e-02, -7.18976930e-02,  3.31166461e-02,  2.07003057e-02,\n",
       "          5.61396927e-02, -7.98362494e-03, -5.07168844e-03,  8.38566292e-03,\n",
       "          1.31200207e-02,  3.53280678e-02, -5.08911200e-02, -8.19571689e-03,\n",
       "          9.41323489e-03, -1.82837446e-03,  4.26159501e-02,  2.76006218e-02,\n",
       "          5.33547811e-03,  4.16563451e-03, -1.48905488e-02, -1.03861485e-02,\n",
       "         -5.97370975e-02, -3.17623429e-02,  4.64917459e-02,  3.01097706e-02,\n",
       "          1.56566687e-02, -4.98525910e-02, -6.66332468e-02,  3.62280942e-02,\n",
       "         -1.87906418e-02, -6.22648858e-02, -1.81494525e-03,  4.07448299e-02,\n",
       "         -3.54214199e-02,  1.19519734e-03, -6.81952201e-03,  5.81724802e-03,\n",
       "         -2.89485157e-02,  3.09065785e-02, -5.88525496e-02, -3.54247796e-03,\n",
       "         -4.59717810e-02,  3.61319375e-03,  1.36694154e-02,  4.79639433e-02,\n",
       "         -4.42646928e-02, -2.58464161e-02, -5.31961629e-03, -2.70108450e-02,\n",
       "          3.09629436e-03, -3.55401970e-02,  4.22004797e-02, -5.48024140e-02,\n",
       "          2.04649400e-02,  5.09111285e-02,  4.86632772e-02, -1.46928185e-03,\n",
       "          2.96327355e-03,  3.51621658e-02,  2.47919355e-02, -3.43917012e-02,\n",
       "          3.00342739e-02, -6.30797446e-03,  1.51741123e-02, -3.80251594e-02,\n",
       "          3.26324217e-02,  2.79791728e-02, -4.97317314e-02,  8.54693633e-03,\n",
       "         -8.40004440e-03,  4.41052020e-04,  2.79951561e-02, -3.75565477e-02,\n",
       "          4.55741286e-02,  3.03780288e-03,  6.89049996e-03, -6.88748360e-02,\n",
       "         -7.16103315e-02, -2.66552120e-02, -2.82609481e-02,  8.27249605e-03,\n",
       "          2.48981137e-02, -3.06521952e-02, -2.37364639e-02, -4.11022343e-02,\n",
       "          8.63368716e-03,  3.56508531e-02,  6.58983970e-03, -1.58667956e-02,\n",
       "          1.73815172e-02, -4.51045968e-02, -9.15663957e-04,  4.71171439e-02,\n",
       "         -3.78970876e-02,  2.05462407e-02, -3.86805199e-02, -1.40566602e-02,\n",
       "          9.60414589e-04,  1.87300537e-02,  8.09719507e-03, -1.36797307e-02,\n",
       "          5.89700043e-02, -1.45536326e-02, -3.90160270e-02, -2.04401347e-03,\n",
       "          3.15538421e-02,  6.22525625e-02,  4.07117419e-02, -5.74881583e-02,\n",
       "          1.18459724e-02, -2.69345939e-02,  1.68063808e-02, -1.06347129e-02,\n",
       "         -1.63595993e-02, -4.30573113e-02, -1.62885413e-02,  4.27921414e-02,\n",
       "          4.34698276e-02,  2.01280043e-03,  2.91293841e-02,  1.05531896e-02,\n",
       "          6.97658360e-02, -4.41240221e-02, -1.48718664e-02, -2.68944893e-02,\n",
       "          3.87559161e-02,  3.38409133e-02, -2.54162755e-02,  9.81039833e-03,\n",
       "          6.90939352e-02,  1.94268581e-02, -3.05229258e-02,  5.05340695e-02,\n",
       "          1.43810958e-02, -3.44772153e-02, -6.47542402e-05,  1.19969435e-02,\n",
       "         -9.62514803e-03, -1.45117342e-02,  2.38969922e-02,  2.90612876e-02,\n",
       "          1.13014765e-02, -5.24203070e-02, -5.72518520e-02,  3.45395692e-02,\n",
       "         -8.77669267e-03, -4.85553145e-02,  1.72986910e-02,  3.01969741e-02,\n",
       "          1.01375990e-02, -9.26806033e-03, -1.64652150e-03, -2.34090518e-02,\n",
       "          3.50903161e-02,  1.94842496e-03, -1.31990267e-02, -9.64959059e-03,\n",
       "          5.66099435e-02, -5.12936525e-02,  6.23409860e-02, -6.06867671e-02,\n",
       "          2.78588873e-03, -2.49405205e-02, -3.59473638e-02, -1.88331716e-02,\n",
       "         -1.87754799e-02,  5.05666025e-02,  6.15706034e-02, -5.19355573e-02,\n",
       "         -1.51920756e-02,  3.65539156e-02,  4.15541679e-02,  1.07228756e-04,\n",
       "         -5.92894740e-02, -1.61244869e-02, -6.98513091e-02,  4.08177190e-02,\n",
       "          1.96802430e-03, -4.00160551e-02, -5.65689197e-03, -1.27847837e-02,\n",
       "         -4.82591428e-02, -6.13515312e-03,  4.15719151e-02,  2.51700524e-02,\n",
       "          2.03141645e-02,  1.34430686e-02, -2.71092057e-02,  1.34688662e-02,\n",
       "          6.81838533e-03,  1.85780656e-02,  1.22796437e-05, -8.10540456e-04,\n",
       "         -3.58101726e-02, -2.49720109e-03,  5.63423075e-02,  3.96698005e-02,\n",
       "          7.79367983e-03, -2.69628596e-02, -4.70398972e-03, -3.02585904e-02,\n",
       "         -6.02573017e-03, -3.89474742e-02,  1.53527409e-03, -2.75274664e-02,\n",
       "          1.39279629e-03,  8.92791525e-03, -5.46953455e-03,  2.73603946e-02,\n",
       "         -4.31783609e-02,  3.39822918e-02, -1.47668831e-03,  3.81092355e-03,\n",
       "         -3.42282876e-02, -6.87292293e-02, -3.43805775e-02, -1.34011293e-02,\n",
       "         -1.11148385e-02,  3.12627666e-02, -2.55421456e-02, -3.08822989e-02,\n",
       "         -4.43348773e-02,  3.68698798e-02, -6.02279492e-02,  3.33872437e-02,\n",
       "          2.19769571e-02, -2.20147464e-02,  2.39000935e-02,  4.27807756e-02,\n",
       "          2.70955656e-02,  1.59444623e-02,  9.83220618e-03,  2.81525925e-02,\n",
       "         -2.28316411e-02,  1.87490415e-02,  5.96404374e-02, -1.43571375e-02,\n",
       "         -2.26141680e-02, -2.70528421e-02,  6.36980915e-03,  3.26823234e-03,\n",
       "         -3.70011367e-02, -6.94709718e-02,  3.10493936e-03, -1.05455667e-02,\n",
       "          1.76154543e-03,  2.26544845e-03, -1.72203239e-02, -6.77713454e-02,\n",
       "          1.22112781e-03, -1.45463208e-02,  1.55689633e-02, -4.01510969e-02,\n",
       "         -4.20996780e-03, -3.14491801e-02,  1.28042875e-02, -1.74891669e-02,\n",
       "          2.26700138e-02, -1.05616162e-02, -2.47727837e-02, -1.08119445e-02,\n",
       "         -3.83330393e-03, -1.49929337e-02, -8.48533772e-03, -8.55403300e-03,\n",
       "         -2.28967387e-02,  1.56872068e-02, -2.27617398e-02,  1.95900607e-03,\n",
       "         -6.36683404e-02,  3.05784848e-02,  1.35688819e-02,  1.88425686e-02,\n",
       "         -5.68814576e-02,  4.73760366e-02, -3.17325965e-02,  8.06237664e-03,\n",
       "         -5.98159395e-02,  3.60200740e-02,  4.11567651e-02,  2.41233762e-02,\n",
       "         -6.89698709e-03, -1.49735333e-02, -3.48086804e-02, -5.75367995e-02,\n",
       "         -1.59895848e-02,  9.17121861e-03,  2.99081374e-02,  6.03251942e-02,\n",
       "         -3.51210274e-02,  3.86539474e-02, -5.15999980e-02,  1.83254350e-02,\n",
       "         -3.54191065e-02,  3.47624458e-02,  2.60949135e-03,  6.49109334e-02,\n",
       "         -1.97542105e-02,  5.73486201e-02,  5.41488221e-03,  1.04003272e-03,\n",
       "         -6.59227371e-02,  4.88689542e-03,  5.86778112e-03, -2.23178025e-02,\n",
       "          3.19104455e-02,  5.84474690e-02, -1.12011507e-02, -2.65013520e-02,\n",
       "          4.81233839e-03, -3.67771350e-02, -1.84894130e-02,  8.34846229e-04,\n",
       "          3.77357118e-02,  4.53253463e-03,  2.31893901e-02,  2.22986136e-02,\n",
       "          5.57589531e-03, -3.94971110e-02,  4.57146903e-03, -3.11377700e-02,\n",
       "         -4.26893942e-02, -2.93253660e-02, -2.23297831e-02, -5.82020395e-02,\n",
       "          3.31478417e-02,  3.92109947e-03,  3.68756126e-03, -4.03703516e-03,\n",
       "         -5.21240085e-02, -2.44289115e-02, -2.65985597e-02,  1.09732896e-02,\n",
       "         -1.31279454e-02, -5.77989593e-03, -6.61375448e-02, -1.03964228e-02,\n",
       "         -3.73632871e-02,  1.98903996e-02,  6.67115077e-02, -4.08352679e-03,\n",
       "         -4.54369783e-02,  1.46574127e-02,  1.03784259e-02,  3.67615260e-02,\n",
       "         -1.09151995e-03, -4.12934646e-02,  1.67220850e-02,  2.06687115e-02,\n",
       "          4.60628979e-02, -6.01751395e-02, -4.44918387e-02, -1.35412777e-03,\n",
       "          8.31713621e-03,  1.68878417e-02,  2.18564719e-02, -5.23360185e-02,\n",
       "          2.04537362e-02, -3.95677648e-02,  3.67831178e-02, -4.46775518e-02,\n",
       "         -7.73323094e-03, -1.53330704e-02,  3.41547988e-02,  2.53253505e-02,\n",
       "         -3.04913018e-02, -5.67631237e-02,  1.14341015e-02,  6.66135475e-02,\n",
       "         -9.17801913e-03,  2.16269325e-02, -1.47213629e-02, -5.82640879e-02,\n",
       "         -7.22335419e-03,  5.61529398e-03,  1.41113438e-02, -2.44761314e-02,\n",
       "          2.16330569e-02, -3.85927595e-02,  2.80349161e-02, -2.54730489e-02,\n",
       "         -6.43393444e-03, -2.30258089e-02,  9.74445790e-03, -4.41362374e-02,\n",
       "          3.93706076e-02, -3.49922478e-03,  2.00953018e-02, -5.47797270e-02,\n",
       "          2.81815813e-03,  2.10922305e-02,  1.02399774e-02,  2.28507165e-02,\n",
       "          4.76562381e-02,  3.78674194e-02, -6.45798305e-03, -8.06489307e-03,\n",
       "          9.90315154e-03,  5.17002642e-02,  6.99128583e-02, -4.57605869e-02,\n",
       "         -2.07301285e-02,  2.74445936e-02,  3.51623259e-02, -5.19169159e-02,\n",
       "          4.72572148e-02, -6.42466592e-03, -2.11615171e-02,  1.63652701e-03,\n",
       "         -3.89425643e-03, -4.15904708e-02,  1.73822548e-02,  1.21065984e-02,\n",
       "          4.49746251e-02,  3.68244499e-02, -1.03405779e-02, -2.95719635e-02,\n",
       "          3.33064608e-02, -3.79879288e-02,  2.18438748e-02,  3.71614248e-02,\n",
       "          9.06432699e-03,  4.38034981e-02,  3.60243730e-02, -4.14459072e-02,\n",
       "          2.61723567e-02, -2.36630980e-02,  7.85016920e-03,  1.89290959e-02,\n",
       "         -3.02890334e-02, -4.46676183e-03,  1.91740692e-02,  2.27680523e-02,\n",
       "         -1.22103840e-02, -2.85794288e-02, -3.22814807e-02,  2.36171465e-02,\n",
       "         -3.56269404e-02,  4.19950932e-02,  2.67015398e-02, -4.44430560e-02,\n",
       "         -4.19913121e-02, -1.57274902e-02,  3.64077874e-02,  1.59686934e-02,\n",
       "          1.55424764e-02,  1.18210157e-02,  9.25431401e-03, -9.91390739e-03,\n",
       "         -1.05864331e-02, -4.95115034e-02, -1.72782559e-02, -1.01253064e-02,\n",
       "          2.81971414e-02,  7.59113254e-03, -3.08002830e-02,  5.54734133e-02,\n",
       "          1.45478779e-02, -2.47280393e-02, -1.26726935e-02, -7.01152384e-02,\n",
       "          6.42630830e-02, -3.27371322e-02, -1.66509394e-02, -3.34928520e-02,\n",
       "          5.96234761e-02, -4.95447107e-02,  4.05285098e-02,  5.99792041e-02,\n",
       "          4.63967165e-03, -3.62257170e-03, -2.70669106e-02, -5.33462167e-02,\n",
       "         -9.37471632e-03, -2.42993031e-02, -8.17018468e-03, -4.76625748e-02,\n",
       "          5.79106696e-02,  2.59146597e-02, -5.12673939e-03, -4.25116420e-02,\n",
       "          1.60133671e-02,  2.48691887e-02,  4.50965352e-02, -5.60542829e-02,\n",
       "          2.84719672e-02, -1.30973915e-02,  2.41735224e-02, -4.48051728e-02,\n",
       "         -2.73137111e-02, -3.40225436e-02,  2.61138659e-02, -9.35714319e-03,\n",
       "         -4.23094025e-03, -4.85531650e-02,  4.11645323e-02,  2.87720319e-02,\n",
       "         -2.04134900e-02, -5.65631390e-02,  5.41760512e-02, -3.81366722e-02,\n",
       "          1.97476987e-02, -7.02022612e-02,  5.73914684e-03, -5.28074913e-02,\n",
       "         -5.62949590e-02,  1.19719105e-02,  1.55760599e-02, -2.87240446e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 70,\n",
       "  'topic_words': array(['ssh', 'github', 'stdout', 'localhost', 'linux', '커널', 'port',\n",
       "         'bashrc', '우분투', 'ubuntu', 'remote', '터미널', 'usb', 'python',\n",
       "         'terminal', 'virtual', 'interface', 'computing', 'bootstrap',\n",
       "         'host', 'database', 'connectome', 'matplotlib', 'implement',\n",
       "         'implementing', 'interfaces', 'peripheral', 'xorg', 'cython',\n",
       "         'connectivity', 'lightdm', 'input', 'computational', 'ide',\n",
       "         'connect', 'subprocess', 'hub', 'implementation', 'convnet',\n",
       "         'kernel', 'lineplot', 'configure', 'output', 'javascript',\n",
       "         'inputs', 'computer', 'urllib', '파이썬', 'implements', 'toolbox'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-5.51056899e-02, -1.89799275e-02, -9.38602351e-03,  3.39238681e-02,\n",
       "         -7.42275221e-03, -6.51961491e-02,  2.58914530e-02, -4.28719781e-02,\n",
       "          5.92760593e-02, -4.15708385e-02, -8.60224944e-03, -4.65748906e-02,\n",
       "          3.85313965e-02, -1.11394702e-02, -2.84418408e-02, -1.89437978e-02,\n",
       "          2.03792434e-02, -3.22091877e-02,  1.92491356e-02,  4.79761176e-02,\n",
       "          1.80841684e-02,  1.56683719e-03,  1.16169462e-02,  3.91173884e-02,\n",
       "         -6.39774725e-02, -1.26085675e-03,  2.06494052e-02,  3.06383967e-02,\n",
       "         -2.74809208e-02, -5.21683730e-02,  5.04370546e-03, -3.49096507e-02,\n",
       "          2.43322309e-02, -6.36282414e-02,  3.61834951e-02,  2.38621365e-02,\n",
       "         -1.86428800e-02, -2.57529113e-02,  3.97290150e-03,  5.86055815e-02,\n",
       "          4.10909718e-03,  2.90653259e-02, -1.73420850e-02, -3.52515019e-02,\n",
       "         -5.19259041e-03,  1.62459705e-02,  3.97756584e-02,  3.56663428e-02,\n",
       "         -6.17088675e-02, -5.26662432e-02,  2.03764904e-02,  1.77858153e-03,\n",
       "          3.07505298e-02,  2.02528518e-02, -4.48165834e-03, -6.15394823e-02,\n",
       "          1.20286392e-02,  5.62448502e-02,  5.52984774e-02,  5.64728305e-03,\n",
       "         -1.66842788e-02,  2.84765065e-02,  6.01306418e-03, -4.39313762e-02,\n",
       "         -2.26254072e-02,  5.55217974e-02,  5.79958893e-02, -5.84995151e-02,\n",
       "          4.57748771e-02, -3.53969373e-02, -4.40017693e-02, -3.58215794e-02,\n",
       "          2.52465904e-02,  1.65314991e-02, -2.88375560e-02,  5.13677560e-02,\n",
       "         -6.12438172e-02, -1.56862084e-02,  3.46289203e-02, -6.54804409e-02,\n",
       "         -6.54958859e-02, -5.54576553e-02, -5.49965799e-02, -3.54663804e-02,\n",
       "          1.46775981e-02, -6.83065504e-03, -7.07825879e-03, -2.58137584e-02,\n",
       "          3.41205448e-02, -3.16177346e-02, -1.35109099e-02, -1.33656198e-02,\n",
       "          1.72356684e-02, -2.78468039e-02,  5.24215214e-02,  4.20214096e-03,\n",
       "         -3.26283686e-02,  5.70407957e-02,  1.36580886e-02,  6.65179640e-03,\n",
       "          4.45276266e-03,  3.02219149e-02, -1.09303659e-02, -3.74719650e-02,\n",
       "          5.84175289e-02,  7.35670328e-05, -3.36995535e-02,  7.23991543e-03,\n",
       "          1.05623649e-02,  5.07038124e-02,  3.34234647e-02, -6.14783876e-02,\n",
       "          9.76661500e-03,  2.11467538e-02,  5.04522771e-02, -2.25735102e-02,\n",
       "         -3.84278707e-02,  1.52479419e-02, -6.03373386e-02, -5.01285978e-02,\n",
       "         -4.99097304e-03,  1.43967019e-02, -2.62908936e-02,  2.51934920e-02,\n",
       "          3.64846624e-02, -1.98384784e-02,  2.30412725e-02,  2.97545791e-02,\n",
       "         -7.64843030e-03, -3.25577823e-03, -3.37419324e-02, -8.07480246e-04,\n",
       "          2.38230582e-02,  7.50832120e-03,  4.34867442e-02, -5.80414757e-03,\n",
       "          2.65745018e-02, -1.53420621e-03,  1.96364913e-02,  3.25571522e-02,\n",
       "          2.05396507e-02, -2.27396712e-02,  6.29172400e-02,  3.85070406e-02,\n",
       "          1.56336522e-03, -2.66621783e-02,  1.86252892e-02,  5.02915569e-02,\n",
       "          2.26472411e-02, -1.14441635e-02, -2.36328561e-02,  1.50024416e-02,\n",
       "         -4.22276966e-02, -3.82054783e-02,  1.07334433e-02,  1.09219002e-02,\n",
       "         -1.06188254e-02,  3.00999377e-02,  1.75009239e-02, -6.43803775e-02,\n",
       "         -1.16486428e-02, -3.45889367e-02,  2.82131005e-02,  4.19153087e-02,\n",
       "         -1.14701102e-02, -1.23281330e-02,  1.37994392e-02, -3.54097486e-02,\n",
       "         -5.47336228e-02,  8.05255678e-03,  2.16971580e-02,  9.00260464e-04,\n",
       "         -1.10767558e-02,  4.04079668e-02, -1.75502505e-02,  4.60438766e-02,\n",
       "         -6.48553446e-02, -3.45471613e-02, -3.15872692e-02,  4.13924195e-02,\n",
       "         -7.38165528e-03,  2.21688822e-02,  3.92609835e-02, -4.44291495e-02,\n",
       "         -1.33426292e-02,  5.88363111e-02,  4.01702151e-03,  5.55930138e-02,\n",
       "          3.09809763e-02,  6.14612401e-02, -6.64429180e-03, -2.77950913e-02,\n",
       "          5.06990263e-03,  1.04517862e-03, -3.35325114e-02, -3.74359451e-02,\n",
       "          3.19817173e-03, -1.18585182e-02, -2.57067811e-02,  5.06879054e-02,\n",
       "         -3.99096347e-02, -1.27495835e-02,  1.39325717e-02, -2.71568913e-02,\n",
       "         -1.43535407e-02, -6.44478127e-02,  4.56542782e-02,  1.85581576e-02,\n",
       "         -2.89103780e-02,  3.34596448e-02,  1.08154006e-02,  6.36132136e-02,\n",
       "          4.82066758e-02,  4.92996983e-02, -2.74213571e-02,  4.03694995e-02,\n",
       "          4.03608866e-02,  2.10022032e-02,  2.31776703e-02,  2.16514412e-02,\n",
       "         -5.27724028e-02,  4.68634255e-02, -2.70718932e-02, -2.56216582e-02,\n",
       "         -6.35931715e-02,  2.00335421e-02,  4.45186235e-02,  4.22678180e-02,\n",
       "         -4.24008816e-03, -4.54989672e-02,  7.94066116e-03,  3.60994413e-02,\n",
       "          3.73040028e-02,  8.84471182e-03,  1.98563542e-02,  5.23883998e-02,\n",
       "          1.69745013e-02,  1.94096211e-02,  4.84645665e-02, -3.24024819e-02,\n",
       "         -4.08780947e-03,  2.59152260e-02,  5.43495901e-02,  4.07955796e-02,\n",
       "          4.74864431e-03, -5.97468950e-02,  2.14927015e-03,  1.76630151e-02,\n",
       "          4.81858887e-02,  5.44582345e-02, -1.92183387e-02, -1.17429169e-02,\n",
       "          8.96523613e-03, -1.08770123e-02, -3.72131616e-02, -3.16835977e-02,\n",
       "          1.49415359e-02, -2.92764064e-02, -1.45865465e-02, -2.40181163e-02,\n",
       "         -2.66143624e-02, -8.10678862e-03,  1.72914434e-02,  1.56231904e-02,\n",
       "          5.14265783e-02, -5.02605103e-02,  1.76775772e-02,  2.20551472e-02,\n",
       "         -4.70811278e-02,  2.63327193e-02, -3.03921402e-02,  3.69836204e-03,\n",
       "          3.80497682e-03,  5.02813347e-02, -2.50258688e-02, -1.80041250e-02,\n",
       "         -1.07891858e-03, -4.77369241e-02, -3.21904682e-02, -1.06536681e-02,\n",
       "          2.28880420e-02,  5.21306507e-03, -5.40776551e-03,  1.46066761e-02,\n",
       "         -1.64528433e-02,  5.42222708e-02, -5.36780357e-02,  1.52321002e-02,\n",
       "         -1.66924223e-02, -2.93271360e-03,  1.82853192e-02,  4.38974947e-02,\n",
       "         -5.75827658e-02, -7.47696636e-03, -6.54387772e-02,  3.76049280e-02,\n",
       "         -3.95536758e-02,  2.49527171e-02, -2.26412956e-02, -1.94550212e-02,\n",
       "          2.04572957e-02,  2.40607653e-02, -9.09177400e-03, -3.82399969e-02,\n",
       "          2.03599501e-02,  4.61852215e-02,  2.41243970e-02, -1.60854999e-02,\n",
       "         -9.87130869e-03, -4.46866788e-02, -6.69186295e-04,  1.03337308e-02,\n",
       "          2.83283945e-02,  7.72629073e-03, -4.73333299e-02, -8.33202899e-03,\n",
       "          4.73812930e-02,  2.12211907e-02, -1.05609223e-02, -4.47888486e-02,\n",
       "          3.63716967e-02, -1.83608942e-02,  1.19670928e-02,  3.73328552e-02,\n",
       "          1.64274331e-02, -3.52002643e-02, -4.26701866e-02,  2.93403175e-02,\n",
       "         -7.37765164e-04,  1.64179190e-03, -2.02504490e-02, -3.59575413e-02,\n",
       "         -2.38102451e-02,  3.23792286e-02,  3.68317366e-02,  3.44140418e-02,\n",
       "          3.77827398e-02,  4.04093973e-02, -6.51551783e-02,  1.79945026e-02,\n",
       "         -1.00857532e-02,  5.79004176e-02, -3.62350605e-03, -5.98795852e-03,\n",
       "         -7.80300656e-03, -2.60275006e-02,  2.65296921e-03, -1.32891675e-02,\n",
       "         -4.88976799e-02, -1.95782501e-02, -1.13184573e-02, -8.28435936e-04,\n",
       "         -7.18900526e-04, -3.63112949e-02, -2.12324653e-02, -5.71447648e-02,\n",
       "         -1.17265955e-02, -6.93032006e-03, -1.92458313e-02, -4.64648865e-02,\n",
       "         -2.35921815e-02,  1.57130193e-02,  5.26979379e-02,  2.61126459e-03,\n",
       "          8.68742634e-03, -2.73823459e-02, -3.42741422e-02, -1.98865812e-02,\n",
       "          1.51578560e-02, -6.28480613e-02,  1.95544753e-02, -3.53054740e-02,\n",
       "         -3.61646079e-02, -9.40292701e-03,  1.45502938e-02,  4.54692431e-02,\n",
       "         -3.77210192e-02,  3.45690511e-02,  5.97723015e-02,  5.09228855e-02,\n",
       "          5.21318009e-03, -4.90064658e-02, -2.20985319e-02, -3.26442756e-02,\n",
       "          6.50264090e-03,  2.95924935e-02,  1.22135384e-02, -5.15712090e-02,\n",
       "          6.30023191e-03,  3.73603962e-03, -2.06387285e-05, -2.27264166e-02,\n",
       "         -2.73990748e-03,  2.08744407e-02, -7.28280237e-03, -2.99004484e-02,\n",
       "          5.20143211e-02,  5.49950562e-02, -9.31535568e-03,  1.60662550e-02,\n",
       "         -1.15786679e-02, -3.74545045e-02,  5.96605651e-02, -1.87405255e-02,\n",
       "          6.14133477e-02,  5.73837617e-03, -3.17813642e-02, -3.19428928e-02,\n",
       "         -9.68089048e-03,  4.43070568e-02, -7.57441064e-03,  3.71103734e-03,\n",
       "         -1.97603833e-02, -4.31147777e-02,  6.80792704e-03, -3.04548591e-02,\n",
       "          1.98107287e-02,  3.49913351e-02, -2.13562814e-03, -1.53930904e-03,\n",
       "          5.29065877e-02, -1.20350234e-02,  3.83383222e-02,  1.41320704e-02,\n",
       "         -1.55390298e-03,  3.32746133e-02,  3.87773998e-02,  1.94624607e-02,\n",
       "         -9.80710145e-03,  7.37083436e-04,  3.98291834e-02, -6.54187202e-02,\n",
       "         -1.91070009e-02,  6.35702955e-03,  1.64383799e-02,  2.95346528e-02,\n",
       "          1.02227852e-02,  1.80394892e-02, -4.70617302e-02,  5.65369241e-02,\n",
       "          1.06603755e-02,  4.79129814e-02, -2.48371363e-02, -6.21639378e-02,\n",
       "          7.90723041e-03, -2.09836531e-02,  6.36173710e-02, -5.45525439e-02,\n",
       "          2.93515939e-02, -5.38101159e-02,  5.46724387e-02,  3.44544128e-02,\n",
       "         -2.56893579e-02, -3.84371728e-02, -4.51757386e-03, -6.13904111e-02,\n",
       "          3.38241011e-02, -3.72566395e-02,  4.57557710e-03,  3.72966081e-02,\n",
       "         -1.53270876e-02,  2.60308590e-02,  4.00651656e-02, -5.35673881e-03,\n",
       "          4.94662970e-02, -2.25878209e-02, -2.57208999e-02, -8.17560218e-03,\n",
       "          5.95150739e-02, -4.64788340e-02,  3.37998122e-02, -2.01238338e-02,\n",
       "         -5.11855669e-02,  7.62926927e-03, -5.30677028e-02,  2.09472999e-02,\n",
       "         -3.08833029e-02, -1.49226040e-02, -1.99030340e-03, -1.79120079e-02,\n",
       "          4.44410034e-02, -4.04948704e-02, -5.13282930e-03, -2.85551492e-02,\n",
       "         -5.24333864e-02,  1.00047626e-02,  2.86733988e-03, -5.61849773e-02,\n",
       "         -1.65413693e-02, -5.32524101e-02,  2.64648590e-02,  2.73448601e-02,\n",
       "         -2.64558792e-02, -4.47653346e-02,  1.27150901e-02,  1.59369037e-02,\n",
       "         -5.49702905e-02, -8.55162274e-03, -1.14792334e-02,  1.84434354e-02,\n",
       "          2.03732960e-02,  3.59535404e-02,  2.12335140e-02, -6.35303557e-03,\n",
       "         -9.81491152e-03, -6.53381348e-02, -5.91976754e-02, -3.85115705e-02,\n",
       "         -2.29111165e-02, -8.40072241e-03,  6.42212713e-03, -1.53995724e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 71,\n",
       "  'topic_words': array(['apk', '컴파일', '컴파일러', 'compile', 'java', 'compiler', 'rjava', '자바',\n",
       "         'android', '우분투', 'exe', '파일', '컴포넌트', 'javascript', 'jar',\n",
       "         'repository', 'app', 'png', 'github', 'coc', 'file', 'files',\n",
       "         'filename', 'leak', '코딩', 'urllib', 'root', '코드', 'shared', 'apps',\n",
       "         'toolkit', 'dependencies', '압축', 'gcc', 'argv', 'zip', 'localhost',\n",
       "         'filenametype', '커널', 'covariate', 'component', 'lib', 'covid',\n",
       "         'ubuntu', 'covariates', 'dependency', 'native', 'vtk', 'divided',\n",
       "         'coded'], dtype='<U15'),\n",
       "  'topic_vector': array([-9.08122119e-03,  2.36996785e-02,  7.63151282e-03,  3.75137515e-02,\n",
       "         -1.98688474e-03, -6.31963983e-02, -1.28379269e-02,  1.73478443e-02,\n",
       "          6.40612617e-02,  3.55824195e-02,  5.76348267e-02, -1.26803601e-02,\n",
       "         -6.41661510e-03, -6.08739741e-02, -6.61378494e-03,  2.75826752e-02,\n",
       "         -2.26174369e-02, -9.26627684e-03,  3.84184555e-03,  5.63829131e-02,\n",
       "          2.64246333e-02,  2.50568036e-02,  4.13628556e-02,  3.37609053e-02,\n",
       "         -3.21094282e-02, -3.36875729e-02,  1.94353350e-02, -3.03791333e-02,\n",
       "          2.01993827e-02, -2.08310653e-02, -5.96750677e-02, -3.20147909e-02,\n",
       "          5.80373146e-02, -5.53659759e-02,  1.18585331e-02,  1.46201523e-02,\n",
       "         -1.89699400e-02,  4.17055488e-02,  5.29916920e-02, -5.33441342e-02,\n",
       "          3.47309299e-02,  1.66220646e-02,  3.12051014e-03,  9.42226313e-03,\n",
       "          1.28360279e-02,  4.53101285e-02,  3.98407131e-02,  2.81510199e-03,\n",
       "          2.20513139e-02, -2.38410067e-02, -5.30626737e-02,  1.15749361e-02,\n",
       "          8.13783612e-03,  8.32026917e-03,  1.95506271e-02, -1.50676267e-02,\n",
       "          4.50667925e-02, -1.45874256e-02, -2.46585142e-02,  1.19584715e-02,\n",
       "         -4.18728553e-02,  5.19544072e-02,  5.13173901e-02, -5.83681650e-03,\n",
       "         -4.41321321e-02,  7.43982941e-03, -1.08835159e-03,  2.89768223e-02,\n",
       "         -1.72597673e-02,  3.87922078e-02,  1.15327761e-02, -5.55806840e-03,\n",
       "          6.22479133e-02, -5.11018513e-03, -8.70312273e-04,  5.24770319e-02,\n",
       "         -5.66732511e-03,  1.37337379e-03,  6.18403740e-02, -5.20512722e-02,\n",
       "         -6.59348890e-02,  5.85413687e-02, -5.28216325e-02,  2.24022046e-02,\n",
       "          2.67631579e-02, -1.00716045e-02,  6.74574450e-03,  2.69080158e-02,\n",
       "          3.11299246e-02,  3.80204171e-02, -1.41409831e-02, -1.40792103e-02,\n",
       "          2.23901924e-02,  5.83327226e-02,  5.29275723e-02, -2.39002015e-02,\n",
       "         -5.67675047e-02, -2.45084818e-02, -5.01377694e-02, -3.96810360e-02,\n",
       "          1.89732965e-02, -5.21878786e-02, -1.65477600e-02,  3.09112319e-03,\n",
       "          3.56118865e-02, -2.39521116e-02, -3.63143422e-02, -7.43596256e-03,\n",
       "          2.45252643e-02,  7.95464870e-03,  5.57513302e-03,  7.12258816e-02,\n",
       "          2.95716673e-02, -5.27915359e-02,  4.39232402e-02, -6.22323155e-03,\n",
       "          5.87466098e-02,  2.74472032e-02,  1.28345611e-02, -3.27950157e-02,\n",
       "          4.88188304e-03,  2.58618500e-02,  3.92363733e-03,  2.87301391e-02,\n",
       "         -4.15956490e-02, -1.93636620e-03,  2.45225313e-03, -2.46378426e-02,\n",
       "          2.68801320e-02, -5.89260645e-02, -3.41179483e-02, -2.32419893e-02,\n",
       "          6.70174286e-02,  3.46086882e-02,  5.97474584e-03,  6.21228851e-02,\n",
       "          5.95258772e-02,  1.43050477e-02,  1.52060045e-02,  3.90983820e-02,\n",
       "          2.66058240e-02,  4.71923985e-02, -3.36285718e-02,  2.83120759e-03,\n",
       "          7.91647192e-03, -3.57756317e-02, -1.86383836e-02, -1.85366105e-02,\n",
       "          5.21394471e-03,  2.42524687e-02,  1.20274164e-02,  4.87103164e-02,\n",
       "          1.15649169e-02, -1.48134055e-02,  7.22891465e-03,  2.20781565e-02,\n",
       "         -4.03607823e-02,  4.25178371e-02, -3.05129793e-02, -2.81879529e-02,\n",
       "          3.90676372e-02, -2.50322130e-02,  6.37216866e-03,  9.90771339e-04,\n",
       "         -4.48095659e-03, -4.58696969e-02,  3.78246121e-02,  2.74009723e-02,\n",
       "          4.52232957e-02, -4.73476797e-02,  6.44555911e-02, -4.64450307e-02,\n",
       "         -2.33801920e-02, -5.42605408e-02,  9.42424405e-03,  4.26800782e-03,\n",
       "         -5.66530712e-02,  3.84055190e-02, -6.92245737e-02,  4.43364382e-02,\n",
       "         -4.09976803e-02,  5.86313605e-02, -2.83179227e-02,  1.01439410e-03,\n",
       "         -5.02909580e-03,  5.12562506e-02,  5.87583892e-02,  4.86759506e-02,\n",
       "         -2.92966906e-02,  6.54897168e-02, -2.80605201e-02, -3.47500630e-02,\n",
       "          3.26892138e-02,  2.63831671e-02, -1.06683252e-02,  6.52252361e-02,\n",
       "          5.31440862e-02, -4.71129417e-02,  2.17308346e-02, -4.75531183e-02,\n",
       "         -1.00740120e-02, -1.16405031e-02,  3.85405379e-03, -2.17159931e-02,\n",
       "          1.67801157e-02,  4.43689665e-03,  5.58966063e-02,  9.16143227e-03,\n",
       "          6.71439692e-02, -7.31596863e-03, -4.76646386e-02,  5.27003221e-02,\n",
       "          7.26141268e-03, -6.40463307e-02,  4.27798033e-02, -1.58396978e-02,\n",
       "         -4.72790487e-02,  3.07575557e-02,  5.51669300e-03,  5.39902858e-02,\n",
       "         -5.43976538e-02, -1.72831509e-02, -6.77370504e-02, -3.34590413e-02,\n",
       "         -5.98879196e-02, -1.07600568e-02, -1.75266806e-02, -5.68391792e-02,\n",
       "          1.07677383e-02,  5.73579669e-02,  3.86858382e-03,  3.83685455e-02,\n",
       "          5.07724993e-02,  2.36803982e-02,  2.47185174e-02,  3.98033820e-02,\n",
       "         -2.33913753e-02,  4.93461750e-02,  5.23709841e-02,  4.99913730e-02,\n",
       "         -4.78492789e-02, -3.02636381e-02, -1.27346553e-02, -3.79551854e-03,\n",
       "         -3.71479578e-02, -5.57737947e-02,  4.20880504e-02, -1.91099346e-02,\n",
       "         -3.00862506e-04,  2.89283763e-03, -4.15319353e-02,  3.57213989e-02,\n",
       "         -5.92692047e-02, -1.34660108e-02, -3.61808129e-02, -4.64172550e-02,\n",
       "          4.77312505e-02, -3.03260777e-02, -2.41512135e-02,  2.14659031e-02,\n",
       "          2.86306161e-02,  3.09324879e-02, -2.54962742e-02, -5.36541156e-02,\n",
       "          6.43759295e-02, -2.33808514e-02,  1.19975498e-02,  7.56495679e-03,\n",
       "          3.16220708e-02, -3.83151206e-03,  1.98048409e-02,  1.74004007e-02,\n",
       "         -3.12621146e-02,  6.83660328e-04,  5.98504804e-02,  2.32254248e-02,\n",
       "          1.99841638e-03, -1.43269019e-03, -3.60032059e-02, -3.55697535e-02,\n",
       "         -2.93628052e-02,  5.58316708e-02, -3.80132496e-02,  2.20693070e-02,\n",
       "          4.24665697e-02, -5.62996976e-02,  6.64349645e-03, -5.59450723e-02,\n",
       "         -2.97019035e-02, -9.13239364e-03, -1.05021633e-02,  5.34313917e-02,\n",
       "         -3.05971000e-02,  4.55485992e-02, -6.56403452e-02,  3.46751958e-02,\n",
       "          2.94639338e-02,  1.97849926e-02,  3.49446908e-02,  2.55640503e-02,\n",
       "          1.77688319e-02, -2.53046006e-02, -6.58765733e-02, -4.02635373e-02,\n",
       "          3.77633385e-02, -4.27349098e-02,  1.92201603e-02, -2.89835110e-02,\n",
       "         -1.73400212e-02,  5.27972169e-02,  1.30337747e-02,  1.27840117e-02,\n",
       "         -5.63125173e-03,  4.76725511e-02,  1.17085902e-02,  4.78665940e-02,\n",
       "         -5.50688012e-04, -2.68921554e-02, -2.65035499e-02,  2.01999713e-02,\n",
       "         -1.99335236e-02, -2.74219550e-03, -3.31982970e-03,  1.76647361e-02,\n",
       "          4.35848683e-02,  3.69778089e-03, -6.36990974e-03, -1.01811038e-02,\n",
       "          3.17860730e-02, -5.24084037e-03, -2.49697100e-02, -1.83564853e-02,\n",
       "         -4.16361960e-03, -1.48620568e-02,  1.74622387e-02,  1.41892927e-02,\n",
       "          9.76297911e-03, -2.45485976e-02, -6.66639209e-02, -3.64765786e-02,\n",
       "         -3.25897522e-03,  3.35573331e-02, -5.15333898e-02,  4.96299863e-02,\n",
       "         -5.32814674e-02, -1.73600316e-02,  4.91922116e-03, -6.88581988e-02,\n",
       "         -2.11887863e-02, -1.22565208e-02,  2.11607143e-02, -1.55686832e-03,\n",
       "         -1.91020444e-02, -5.82548231e-02,  1.17518893e-02,  4.81213443e-02,\n",
       "          5.18172570e-02,  7.83283450e-03, -7.00329319e-02, -5.81078976e-02,\n",
       "          1.44083546e-02,  1.09337419e-02,  1.78193282e-02,  4.63141315e-02,\n",
       "          3.89978811e-02, -1.08280405e-03,  1.12137794e-02, -1.61986575e-02,\n",
       "         -3.53876464e-02,  8.09474941e-03, -4.84347753e-02, -3.37975509e-02,\n",
       "         -2.77368277e-02,  3.99745367e-02, -3.12195662e-02,  1.48507738e-02,\n",
       "         -9.11779795e-03,  1.39526566e-02,  8.77525937e-03, -4.74834144e-02,\n",
       "          8.07713717e-03, -5.60576431e-02, -2.55305525e-02, -4.75101657e-02,\n",
       "          2.32646894e-02,  3.78506035e-02, -6.00849986e-02, -3.54797952e-02,\n",
       "          1.82563495e-02,  4.15050201e-02, -4.87468578e-02,  4.36003618e-02,\n",
       "          2.65339892e-02,  1.91438815e-03,  9.23603494e-03, -5.86953647e-02,\n",
       "         -1.35420104e-02,  5.46847135e-02,  4.31448258e-02, -2.31784787e-02,\n",
       "          9.30386875e-03, -1.20282173e-02,  5.52179180e-02,  2.62725800e-02,\n",
       "          4.43753088e-03, -1.45348385e-02, -3.16685475e-02,  6.10520691e-02,\n",
       "          1.31622190e-02, -3.34015079e-02, -2.22752094e-02,  1.77288614e-02,\n",
       "         -3.38341743e-02,  2.46230587e-02, -7.76494807e-03,  2.43739393e-02,\n",
       "          1.76058244e-02,  3.87769975e-02, -4.24312837e-02, -5.92330694e-02,\n",
       "          5.62162884e-02, -2.26746444e-02,  3.55254598e-02,  5.12482077e-02,\n",
       "          3.29668336e-02,  4.01232503e-02,  2.74481792e-02,  1.45915411e-02,\n",
       "          2.99713705e-02, -8.77442863e-03, -4.33172621e-02,  5.12286536e-02,\n",
       "         -1.13122119e-02, -3.32504846e-02,  5.15579581e-02,  4.98507768e-02,\n",
       "         -2.09805861e-04,  2.59504374e-02, -5.57825975e-02,  1.27656488e-02,\n",
       "         -5.63224256e-02, -2.55169254e-02, -6.31348416e-02, -2.87377238e-02,\n",
       "         -4.92535122e-02,  5.12005994e-03,  1.05036749e-02, -5.05948476e-02,\n",
       "          5.07814577e-03, -1.12441285e-02,  1.25647113e-02,  5.49136810e-02,\n",
       "         -5.85285127e-02,  2.28326600e-02, -4.37720269e-02,  4.79198210e-02,\n",
       "         -1.82276014e-02, -1.95870642e-02,  5.14828563e-02,  5.03345430e-02,\n",
       "          9.23809930e-05,  1.84885245e-02,  1.80716496e-02,  8.90426245e-03,\n",
       "          3.37672941e-02, -5.63407429e-02,  3.12894098e-02,  4.91404496e-02,\n",
       "          4.58265208e-02, -2.72613857e-02,  3.01325396e-02, -9.48394928e-03,\n",
       "          6.70396164e-02,  4.52770032e-02, -4.39411551e-02, -1.24469874e-02,\n",
       "         -9.86183342e-03,  3.98797169e-02,  5.46948910e-02,  3.10350452e-02,\n",
       "          4.71150829e-03,  1.72674879e-02,  3.97546729e-03,  2.62247045e-02,\n",
       "          5.59831038e-04,  4.68589477e-02, -2.48274580e-02, -4.41695862e-02,\n",
       "          2.70678569e-02, -1.56521592e-02,  1.25630843e-02, -4.15320359e-02,\n",
       "         -1.85136609e-02,  2.74232477e-02, -3.34389471e-02, -3.27003337e-02,\n",
       "         -1.05061932e-02, -2.30998106e-04,  4.04894091e-02,  4.68831919e-02,\n",
       "         -1.25517128e-02,  3.63461263e-02,  4.27688984e-03,  2.81641185e-02,\n",
       "         -1.87546555e-02, -6.57299981e-02,  1.74820032e-02, -2.02198606e-02,\n",
       "          2.08929628e-02, -1.51803670e-02, -3.16970944e-02, -1.46971578e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 72,\n",
       "  'topic_words': array(['statistical', 'statistically', 'statistics', 'datasets',\n",
       "         'dataset', 'data', 'statistic', '통계', '통계청', '회귀분석', '데이터',\n",
       "         'regression', 'correlations', 'dataframe', 'correlation', 'stats',\n",
       "         'coefficient', 'probabilistic', 'randomized', 'coefficients',\n",
       "         'computationally', 'correlates', 'correlated', 'multiprocessing',\n",
       "         'multivariate', 'quantitative', 'predictive', 'computational',\n",
       "         'correlate', 'predictor', 'predictors', 'variance', 'matplotlib',\n",
       "         'variables', 'normalization', 'ggplot', 'computation', 'variances',\n",
       "         '파라미터', 'stat', '변수', 'parameters', 'percentage', 'predicts',\n",
       "         'parametric', 'covariance', 'scatterplot', 'estimators',\n",
       "         'quantitatively', 'graphql'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.06242323,  0.03635243, -0.02661472, -0.00047105, -0.02710816,\n",
       "         -0.05732298,  0.04242039, -0.03651445,  0.0403488 ,  0.03888407,\n",
       "          0.02645307,  0.02955043,  0.04062207,  0.01940111, -0.0435857 ,\n",
       "          0.01366396, -0.04628009,  0.03253815,  0.05506405,  0.00859972,\n",
       "          0.0123562 , -0.01702922, -0.04485349,  0.05747086, -0.06251839,\n",
       "         -0.05858286,  0.00554136,  0.02420648,  0.00776653,  0.00366642,\n",
       "         -0.0182298 ,  0.01655605,  0.02969959, -0.06093538, -0.04273557,\n",
       "          0.00824087, -0.01503692,  0.03062537,  0.01464621,  0.02955057,\n",
       "         -0.01795418,  0.00562666,  0.03485877, -0.05578823, -0.01085677,\n",
       "         -0.03189798,  0.05100106,  0.01991077, -0.05138313, -0.01846221,\n",
       "         -0.01025326, -0.04123875, -0.01385493, -0.04163775,  0.04885156,\n",
       "         -0.04494762,  0.04558192,  0.01362411,  0.05708386,  0.04815896,\n",
       "          0.0327878 ,  0.05314494, -0.01086982, -0.05403112, -0.02709621,\n",
       "          0.02439495,  0.02793706, -0.03117908,  0.02412694, -0.01996125,\n",
       "         -0.01190173, -0.00298447,  0.00129412, -0.0481424 , -0.05362414,\n",
       "         -0.00343391,  0.05113854,  0.05184396, -0.00710472, -0.06136376,\n",
       "         -0.06229595, -0.05632892,  0.02260268, -0.02737928, -0.0096142 ,\n",
       "          0.03037835, -0.05586429,  0.01400228, -0.04823173, -0.04806617,\n",
       "         -0.05348607, -0.03445814,  0.00808091, -0.06030143,  0.02826447,\n",
       "          0.05902302, -0.05065688,  0.02931437,  0.01183121,  0.04052876,\n",
       "          0.05866368, -0.01857898,  0.0603587 , -0.04031079, -0.01424127,\n",
       "         -0.05643174, -0.05244088, -0.0118928 ,  0.02739768,  0.05865692,\n",
       "          0.06058947, -0.05637182, -0.04922464, -0.0429436 ,  0.05665934,\n",
       "         -0.0165024 ,  0.02207699,  0.00513216, -0.01667312,  0.02267621,\n",
       "         -0.04948691,  0.02344152,  0.05629152,  0.01678709,  0.0606543 ,\n",
       "         -0.0031076 ,  0.03537796,  0.05675164, -0.04953565,  0.06062411,\n",
       "         -0.06030363, -0.04097809,  0.06120466,  0.02221205, -0.02197446,\n",
       "          0.06188041, -0.01372042, -0.01622324,  0.06078733,  0.02528974,\n",
       "         -0.0124678 , -0.02833263,  0.03508502, -0.03039981,  0.04928889,\n",
       "         -0.00618505, -0.06207982,  0.05581858,  0.05484393,  0.02206405,\n",
       "          0.03673354,  0.00837088, -0.05786081, -0.01893884,  0.04928884,\n",
       "         -0.03041938, -0.02019165, -0.02828467,  0.0411178 , -0.00913774,\n",
       "          0.04432243, -0.05256424, -0.02311952, -0.05978292, -0.04139717,\n",
       "          0.02004842,  0.00467939, -0.00113695, -0.04323485,  0.06007747,\n",
       "         -0.04433508,  0.00425399,  0.03892239, -0.0204206 ,  0.02217548,\n",
       "          0.01466478,  0.02210023,  0.00826726, -0.00309607,  0.03430816,\n",
       "          0.03465332, -0.04682103, -0.00717678, -0.04260284, -0.04632721,\n",
       "          0.01130163,  0.03880683,  0.02572975, -0.00869743, -0.05383612,\n",
       "          0.01629804,  0.00566036,  0.04982531, -0.044788  ,  0.03681538,\n",
       "         -0.0033259 , -0.05907908, -0.0052403 ,  0.05473748,  0.01743885,\n",
       "         -0.02833735,  0.01013035, -0.03655054,  0.00245749, -0.04891759,\n",
       "          0.01605707, -0.0432982 , -0.01792545, -0.00086977,  0.02352057,\n",
       "          0.00560198,  0.00779473, -0.05888347,  0.0412288 ,  0.04648221,\n",
       "         -0.00317173,  0.00625797, -0.05072409, -0.04653223, -0.03960845,\n",
       "          0.03744897,  0.0468618 ,  0.02613078, -0.0278727 ,  0.0022813 ,\n",
       "          0.02244654, -0.05413928, -0.04491651, -0.0118201 ,  0.05330416,\n",
       "         -0.03955979, -0.00900396, -0.0173049 , -0.0307517 ,  0.01432637,\n",
       "         -0.0075487 , -0.01404843,  0.0466877 ,  0.06198697,  0.00619131,\n",
       "          0.0553025 ,  0.04767654, -0.04184832,  0.03245963,  0.05724595,\n",
       "         -0.06220701,  0.03098516,  0.03015049, -0.00617872,  0.01298725,\n",
       "         -0.0541413 , -0.05113762, -0.01236608, -0.05315588, -0.01203591,\n",
       "         -0.03059965, -0.04484507, -0.01145457,  0.00312472, -0.03660962,\n",
       "         -0.03067185,  0.00873264, -0.04611935, -0.03723666, -0.01212167,\n",
       "         -0.06155239, -0.00473102,  0.02337659, -0.00158728,  0.04612362,\n",
       "         -0.0126689 , -0.04700284,  0.01976598, -0.0361759 ,  0.00976589,\n",
       "          0.0219759 , -0.06018853,  0.04613787, -0.06122071, -0.05012126,\n",
       "         -0.05932936, -0.02798928,  0.03679295,  0.02310506, -0.04624554,\n",
       "          0.03676365, -0.04523438, -0.03893512,  0.00532151,  0.05720836,\n",
       "          0.04940789,  0.00659595,  0.05465089, -0.02889888, -0.05827575,\n",
       "         -0.04363734, -0.00693081,  0.03709151,  0.03752508,  0.05391954,\n",
       "         -0.04871779,  0.04300316, -0.05538898, -0.05870265, -0.06232023,\n",
       "         -0.04501854, -0.03784162,  0.02687618, -0.05386879, -0.00231588,\n",
       "         -0.03967525, -0.01836397, -0.05431895, -0.04926592,  0.01811985,\n",
       "          0.00964289,  0.00426383, -0.0341073 ,  0.01594224, -0.0558115 ,\n",
       "          0.00872   , -0.01152971, -0.0599435 , -0.01908166, -0.02949252,\n",
       "         -0.01776741, -0.03108699, -0.05350534, -0.00296578, -0.03350748,\n",
       "         -0.01242932, -0.05577738,  0.01222904, -0.04047942, -0.02254129,\n",
       "         -0.03586663, -0.03077049, -0.0456573 , -0.06176912, -0.04738488,\n",
       "         -0.04745824,  0.00554309,  0.05524838, -0.05667011,  0.00458764,\n",
       "          0.02282116,  0.05362289,  0.04094172, -0.04629083,  0.04691757,\n",
       "          0.04906532,  0.03806771, -0.00229116,  0.00520343, -0.033648  ,\n",
       "          0.01031244,  0.00604188,  0.0186512 , -0.00456363, -0.0518964 ,\n",
       "          0.04977237, -0.05773355,  0.03952097, -0.02376098, -0.04656501,\n",
       "          0.01124097,  0.03591235,  0.05254423, -0.02071035,  0.00974977,\n",
       "          0.01359467,  0.05827294, -0.0268091 ,  0.06044697,  0.02930841,\n",
       "         -0.04439464, -0.04192025, -0.00825514, -0.0473167 , -0.03321113,\n",
       "          0.03783986, -0.03227425,  0.00540514,  0.04086026, -0.01812239,\n",
       "          0.05430949,  0.00647087, -0.039117  ,  0.05505213, -0.02462941,\n",
       "          0.01298946,  0.00729451, -0.05309646,  0.04485012, -0.03479642,\n",
       "         -0.01667934,  0.04951759,  0.0473433 , -0.06072092,  0.00649663,\n",
       "          0.05255808,  0.05146109,  0.05725257,  0.04791437, -0.05718047,\n",
       "          0.02791326, -0.00750743, -0.03305424,  0.0362508 , -0.03373669,\n",
       "         -0.01734171, -0.01841255,  0.02076329,  0.00175235,  0.0033786 ,\n",
       "          0.04880543, -0.00240294,  0.0201345 ,  0.02765931, -0.00549561,\n",
       "         -0.00432723, -0.06240784,  0.02073892,  0.0385232 ,  0.04992629,\n",
       "          0.03905181, -0.03234938, -0.05617313, -0.00862246,  0.03255782,\n",
       "         -0.02739777,  0.00131768, -0.04122273, -0.03188421,  0.03937166,\n",
       "          0.01732822,  0.02442777, -0.0229896 , -0.06228036,  0.00824396,\n",
       "         -0.00286127,  0.00272591, -0.00544255, -0.06152719, -0.01507399,\n",
       "         -0.00643105,  0.02011668,  0.02228037,  0.0001513 ,  0.01897355,\n",
       "         -0.02245193, -0.03953864, -0.0255008 ,  0.02631231, -0.04404862,\n",
       "         -0.04311831,  0.04926751,  0.04131839,  0.0080333 ,  0.04917969,\n",
       "         -0.03717937, -0.0306654 , -0.00214797, -0.06141485,  0.0576155 ,\n",
       "         -0.06212835,  0.01229615, -0.05781121,  0.06124257, -0.03105093,\n",
       "          0.02276565,  0.05673222,  0.02774756,  0.00690712, -0.0347653 ,\n",
       "         -0.03120779,  0.04846264,  0.03006321, -0.00821389, -0.04429212,\n",
       "          0.06202735,  0.06258997, -0.03991649,  0.00616092,  0.02720511,\n",
       "         -0.01796324, -0.01618548, -0.05498477, -0.04435085, -0.04549052,\n",
       "          0.02375819,  0.01634272,  0.00209362, -0.0484025 , -0.01569904,\n",
       "         -0.05264492,  0.00417262, -0.04096713,  0.03242815,  0.00623378,\n",
       "          0.05166128, -0.0621103 ,  0.06211422, -0.05263967, -0.05054869,\n",
       "         -0.06214765,  0.0449689 ,  0.01590972,  0.00806277, -0.03631612,\n",
       "         -0.03755377,  0.01262765], dtype=float32)}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tm_model.get_topics_info_as_dict_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tm_model.reduce_topic(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic_idxes': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       " 'topics_words': array([['sklearn', 'teach', 'learning', 'learner', '학습', 'taught',\n",
       "         'learns', '전공', 'neurosciences', 'neuroscience', 'neural',\n",
       "         'undergraduate', 'faculty', 'neurosci', 'scholarship',\n",
       "         'academic', 'scholar', 'learn', 'resource', 'teaching',\n",
       "         'funding', 'courses', 'tutorial', 'funded', '강좌', 'classes',\n",
       "         'education', 'bootstrap', 'studying', 'contribute', 'grant',\n",
       "         'study', '학문', 'student', 'students', 'university', 'sciences',\n",
       "         'beneficial', 'volunteer', 'professor', 'resources', '자원',\n",
       "         'textbooks', 'training', 'contributes', '교수', 'fund', 'arxiv',\n",
       "         'formation', 'promote'],\n",
       "        ['neuronal', 'neurosciences', 'neurobiological',\n",
       "         'neuroscientific', 'neuroscience', 'neurosci', 'neurogenesis',\n",
       "         'neurobiology', 'neurons', 'neuro', 'neuron', 'neural',\n",
       "         'neurological', 'neuroimaging', 'neuroethics', 'neurol',\n",
       "         'neuroscientists', 'neuroimage', 'neuroscientist', 'neurology',\n",
       "         'neurobiol', 'neurosurg', 'neurocultures', 'alzheimers',\n",
       "         'brainstem', 'correlated', 'correlations', 'correlation',\n",
       "         'correlates', 'correlate', '신경망', 'cerebrospinal', 'brains',\n",
       "         'brain', 'alzheimer', 'somatosensory', 'genome', 'cerebral',\n",
       "         'clustering', '신경', 'neurofeminist', 'developmental', 'synapses',\n",
       "         'cognitive', 'biology', 'neurofeminism', 'intrinsic',\n",
       "         'forebrain', 'midbrain', 'psychology'],\n",
       "        ['probabilistic', 'statistical', 'statistically', 'probability',\n",
       "         'covariance', 'statistics', 'variance', 'coefficient',\n",
       "         'statistic', 'variances', 'coefficients', 'regression',\n",
       "         'correlation', 'predictive', 'correlations', '통계청',\n",
       "         'probabilities', 'predictor', 'multivariate', '통계', 'predictors',\n",
       "         'predicts', 'randomized', 'normalization', 'approximation',\n",
       "         'calculations', 'computationally', 'scatterplot', 'predict',\n",
       "         'gaussian', 'calculation', '확률', 'computation', 'asymptotic',\n",
       "         'computed', 'quantitative', 'matplotlib', 'predicting',\n",
       "         'nonparametric', 'exponential', 'variability', 'computational',\n",
       "         'populations', 'parametric', 'correlated', '분포', 'clustering',\n",
       "         'proportional', 'correlates', '회귀분석'],\n",
       "        ['matplotlib', 'ggplot', 'lineplot', 'dataframe', 'scatterplot',\n",
       "         'dataset', 'datasets', 'matlab', 'tensorflow', 'numpy',\n",
       "         'multiprocessing', 'algorithms', 'xticklabels', 'sklearn',\n",
       "         'data', 'subprocess', 'boxplot', 'graphql', 'graphs',\n",
       "         'computationally', 'algorithmic', 'parametric', 'vertexcount',\n",
       "         'computational', 'computation', 'algorithm', 'github', '파라미터',\n",
       "         'mxmatrix', '데이터', 'graph', 'calculations', 'correlations',\n",
       "         'subplots', 'correlation', 'scipy', '알고리즘', 'gaussian',\n",
       "         'clustering', 'plotting', 'calculation', 'computed', 'bmatrix',\n",
       "         'statistics', 'interfaces', 'quantitative', 'genome', '통계청',\n",
       "         'scaling', 'optimize'],\n",
       "        ['서울대', '서울시', '서울', 'seoul', '평양', 'korean', '한국', '신청', '한국어',\n",
       "         'korea', 'uniformity', 'regularization', '전공', '경제',\n",
       "         'application', 'simplest', '대중', '한글', '신용', '급여', 'population',\n",
       "         'normalized', '서민', 'fundamental', 'basic', 'asymptotic',\n",
       "         'accounting', 'imperative', '일반', 'applications', 'general',\n",
       "         '정리', 'percentage', 'simplified', 'differentiated', 'widespread',\n",
       "         '수많', 'soup', '지하철', 'populations', 'procedures',\n",
       "         'normalization', 'saliency', '공공', 'economic', 'diversity',\n",
       "         'economics', 'commonly', 'common', 'cities'],\n",
       "        ['urllib', 'github', 'javascript', 'browser', 'url', 'chrome',\n",
       "         '브라우저', 'khtml', 'firefox', 'html', 'createpage', 'dependencies',\n",
       "         'mozilla', 'dependency', 'cython', 'dataframe', 'bootstrap',\n",
       "         '구글', 'linewidth', 'sklearn', '홈페이지', 'plugins', 'regex',\n",
       "         'webdriver', 'localhost', 'multiprocessing', 'matplotlib',\n",
       "         'pages', 'sites', 'google', 'tensorflow', 'python', 'webgl',\n",
       "         '변수', 'css', 'crawler', '파라미터', 'websites', 'xpath', 'dataset',\n",
       "         'bandwidth', 'links', 'queries', 'page', 'toolkit', 'selenium',\n",
       "         'correlations', 'dependence', 'parametric', '크롬'],\n",
       "        ['ubuntu', 'xorg', '커널', 'linux', '우분투', 'nvidia', 'kernel',\n",
       "         'sudo', 'bashrc', 'gedit', 'stdout', 'gpu', '부팅', 'tensorflow',\n",
       "         'github', 'config', 'matplotlib', 'gnome', 'unix', 'cpu', 'glm',\n",
       "         'subprocess', 'localhost', 'canonical', 'gtx', 'synaptic',\n",
       "         'lightdm', 'terminal', 'grep', 'partition', 'boot', 'grub',\n",
       "         'command', 'openmx', 'install', 'bash', 'gcc', 'firefox', '명령',\n",
       "         'ssd', 'commands', 'plugins', 'installed', 'sli', 'vertexcount',\n",
       "         'cbind', '윈도우', 'bootstrap', 'vtk', 'compile'],\n",
       "        ['python', 'cython', '파이썬', 'subprocess', 'multiprocessing',\n",
       "         'matplotlib', 'numpy', 'stdout', '함수', 'tensorflow', '컴파일러',\n",
       "         'github', 'compiler', '컴파일', 'kwargs', '프로그래밍', 'compile',\n",
       "         'function', 'varlambda', '변수', 'scipy', 'gcc', '코딩', 'functions',\n",
       "         'args', 'regex', 'bashrc', 'sklearn', 'filename', 'dataframe',\n",
       "         '잠재변수', '스크립트', 'dict', 'syntax', 'programming', 'integer',\n",
       "         'lineplot', 'encoding', 'urllib', 'preprocessing', 'unicode',\n",
       "         'coded', '파라미터', 'tuple', 'algorithmic', 'commands',\n",
       "         'filenametype', 'javascript', 'integers', 'ubuntu'],\n",
       "        ['dataframe', 'dataset', 'covariance', 'statistical', 'variance',\n",
       "         'statistics', 'statistically', 'datasets', 'matplotlib',\n",
       "         'variances', 'correlation', 'statistic', 'correlations',\n",
       "         'regression', 'multivariate', 'numpy', 'scatterplot',\n",
       "         'coefficient', 'coefficients', 'variables', 'ggplot', '통계청',\n",
       "         'variability', 'probabilistic', '통계', 'data', '변수',\n",
       "         'multiprocessing', 'tensorflow', 'matlab', 'correlated',\n",
       "         'sklearn', 'lineplot', 'stats', 'graphql', '잠재변수', 'correlate',\n",
       "         'correlates', 'bivariate', 'quantitative', 'nonparametric',\n",
       "         'probability', 'xticklabels', 'computed', 'calculations',\n",
       "         'computation', 'computationally', 'twindata', 'populations',\n",
       "         'computational'],\n",
       "        ['scientist', 'scientists', '과학자', 'fiction', 'neuroscientist',\n",
       "         'deviance', 'neuroscientists', 'neurosciences', 'scholar',\n",
       "         'feminist', 'scholars', 'heuristics', 'darwin', '소설',\n",
       "         'neuroscience', 'neurosci', 'writer', 'robots', 'intellectual',\n",
       "         'psychosis', 'heuristic', '과학', 'scientific', 'psychological',\n",
       "         'kruskal', 'neurocultures', 'psychiatric', 'literature',\n",
       "         'authors', 'zimbardo', 'plausible', 'neuroscientific', 'science',\n",
       "         'novel', 'sensory', 'robot', 'professor', 'neural', '일종',\n",
       "         'abilities', 'selvars', 'prisoners', '작가', 'fantasy',\n",
       "         'parkinsonism', 'repetitive', 'schmitz', '학문', 'psychiatry',\n",
       "         'psychology'],\n",
       "        ['adhd', 'neuroscientific', 'neurological', 'neuroimaging',\n",
       "         'correlation', 'neuro', 'neurology', 'neuroethics', 'neurol',\n",
       "         'neurosci', 'hyperactivity', 'correlations', 'neurosciences',\n",
       "         'psychological', 'neurogenesis', 'syndromes', 'somatosensory',\n",
       "         'neuronal', 'correlated', 'sensory', 'serotonin',\n",
       "         'schizophrenia', 'cognitive', 'neuroscience', 'correlates',\n",
       "         'neuroimage', 'psychosis', 'disorders', 'correlate', 'syndrome',\n",
       "         'perceptual', 'impulsive', 'psychiatry', 'depression',\n",
       "         'impulsivity', 'alzheimers', 'psychology', 'ptsd', 'asymptotic',\n",
       "         'dopamine', 'cognitively', 'dissociation', 'hyperactive',\n",
       "         'neurobiological', 'neurosurg', 'affective', 'disorder',\n",
       "         'compulsive', 'distinctiveness', 'neuroscientists'],\n",
       "        ['psychology', 'psychological', 'neurosciences', 'neuroscience',\n",
       "         '학문', 'neurofeminism', 'neurosci', 'feminist', 'neuroscientific',\n",
       "         'neurofeminist', 'psychosis', 'psychiatry', '심리', 'psychiatric',\n",
       "         'scientists', 'intellectual', 'neuroscientist', 'scientist',\n",
       "         'psychotherapy', 'academic', 'neuroscientists', 'brainstem',\n",
       "         'scholar', 'neurons', 'neuronal', 'neuron', 'scientific',\n",
       "         'mental', 'psychol', 'scholars', 'neurology', 'alzheimers',\n",
       "         'alzheimer', 'brains', 'researchers', 'neurological',\n",
       "         'depressive', 'brain', 'neuro', 'studies', 'cognitive',\n",
       "         'neuroethics', 'intelligent', 'neurol', 'neurobiology',\n",
       "         'neurobiological', 'intelligence', 'researcher', 'depression',\n",
       "         'forebrain'],\n",
       "        ['neural', 'neurobiology', 'neuronal', 'neurosciences',\n",
       "         'neurobiological', 'neurons', 'neuron', 'neuroscience',\n",
       "         'neurosci', 'neuro', 'neurol', 'neuroscientists', 'neurobiol',\n",
       "         'neurogenesis', 'neuroscientist', 'neuroethics', 'neurological',\n",
       "         'computational', 'neuroscientific', 'neuroimaging', 'networks',\n",
       "         '알고리즘', 'computing', 'algorithms', 'neuroimage', 'computation',\n",
       "         'neurology', 'neurosurg', 'neurocultures', 'computationally',\n",
       "         'network', 'algorithmic', '네트워크', '신경망', 'brainstem',\n",
       "         'algorithm', 'cerebrospinal', 'sklearn', 'forebrain', 'computed',\n",
       "         '신경', 'probabilistic', 'genome', 'brains', 'clustering',\n",
       "         'computers', 'brain', 'intelligence', 'cerebral',\n",
       "         'neurofeminist'],\n",
       "        ['statistics', 'statistical', 'statistically', '통계청', 'datasets',\n",
       "         '통계', 'dataset', 'statistic', 'probabilistic', 'regression',\n",
       "         'stats', 'data', 'predictive', '파라미터', 'dataframe',\n",
       "         'correlations', 'predictor', 'parametric', 'correlation',\n",
       "         'predicts', '데이터', 'nonparametric', 'multivariate', 'models',\n",
       "         'parameters', 'predictors', 'predict', 'correlates', 'stat',\n",
       "         'correlate', 'analytics', 'predicting', 'variability',\n",
       "         'correlated', '예측', 'coefficient', 'asymptotic',\n",
       "         'neurobiological', 'paradigms', '모델', 'pathology',\n",
       "         'neurobiology', 'variance', 'patients', 'undergraduate',\n",
       "         'predictions', 'paradigm', 'modelling', 'percentage',\n",
       "         'quantitative'],\n",
       "        ['epidemic', '전염병', '감염자', '백신', '면역', 'prevalence', 'deaths',\n",
       "         '감염병', '사망', '전염', 'diseases', 'fatalities', '피해자', 'disease',\n",
       "         'population', '감염증', '감염', 'populations', 'infected', 'injuries',\n",
       "         '병원', 'illness', '손상', 'disorders', 'seoul', '신종', 'lesions',\n",
       "         '증상', 'affected', '통계청', 'immune', 'suffering', '인구', '서울', '회복',\n",
       "         '한국', 'death', 'deviation', 'psychosis', 'psychiatric', 'lesion',\n",
       "         'abnormalities', 'causal', 'widespread', 'transcranial',\n",
       "         'neuroimage', 'severity', 'neuroscientist', '서울대', 'statistics']],\n",
       "       dtype='<U15'),\n",
       " 'topic_vectors': array([[-0.01677523,  0.01721246, -0.00994472, ..., -0.02922866,\n",
       "         -0.00470831,  0.01085729],\n",
       "        [-0.04367518,  0.01686145, -0.02994338, ..., -0.05216362,\n",
       "          0.01830443,  0.01066946],\n",
       "        [-0.05674189, -0.01836246, -0.02711796, ..., -0.03834207,\n",
       "         -0.02994371,  0.02922855],\n",
       "        ...,\n",
       "        [-0.05019362,  0.05498513, -0.01933749, ..., -0.05621022,\n",
       "          0.01175264,  0.01132722],\n",
       "        [-0.05565861,  0.03091411, -0.00837341, ..., -0.03695475,\n",
       "          0.01025532,  0.02235715],\n",
       "        [ 0.01356217,  0.01784475,  0.0186967 , ..., -0.04718057,\n",
       "         -0.00655186, -0.00617672]], dtype=float32)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tm_model.get_topics_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_tm_model.get_topics_info()['topics_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'topic_idx': 0,\n",
       "  'topic_words': array(['sklearn', 'teach', 'learning', 'learner', '학습', 'taught',\n",
       "         'learns', '전공', 'neurosciences', 'neuroscience', 'neural',\n",
       "         'undergraduate', 'faculty', 'neurosci', 'scholarship', 'academic',\n",
       "         'scholar', 'learn', 'resource', 'teaching', 'funding', 'courses',\n",
       "         'tutorial', 'funded', '강좌', 'classes', 'education', 'bootstrap',\n",
       "         'studying', 'contribute', 'grant', 'study', '학문', 'student',\n",
       "         'students', 'university', 'sciences', 'beneficial', 'volunteer',\n",
       "         'professor', 'resources', '자원', 'textbooks', 'training',\n",
       "         'contributes', '교수', 'fund', 'arxiv', 'formation', 'promote'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-1.67752337e-02,  1.72124635e-02, -9.94471926e-03,  1.06960768e-02,\n",
       "          2.38307398e-02, -1.53593952e-03,  1.09070716e-02,  3.94930458e-03,\n",
       "          1.72648896e-02,  3.28083592e-03,  1.36826104e-02, -5.05149085e-03,\n",
       "          4.47546458e-03, -8.05605296e-03, -4.81562093e-02,  4.17164154e-03,\n",
       "          1.08522512e-02, -5.33715785e-02,  2.84409039e-02,  1.92022640e-02,\n",
       "         -9.97889414e-03,  1.24694193e-02,  2.62345038e-02,  1.99135505e-02,\n",
       "         -2.27128845e-02,  3.97751434e-03,  1.14480813e-03, -6.31506834e-03,\n",
       "         -2.75599845e-02, -3.05607170e-02, -3.50048877e-02,  1.92436352e-02,\n",
       "         -6.19095890e-03, -3.94763052e-02,  5.11142379e-03,  2.60101561e-03,\n",
       "          2.08872110e-02,  1.28358521e-03, -1.58572846e-04, -9.64115839e-03,\n",
       "          2.26781223e-04,  2.29633171e-02,  3.11621139e-03, -2.56705261e-03,\n",
       "         -4.16373424e-02,  2.16708649e-02, -1.44524416e-02, -9.95464344e-03,\n",
       "         -8.48364644e-03,  1.17479917e-02, -1.44336773e-02, -1.40655283e-02,\n",
       "          1.10121919e-02,  7.17504369e-03, -1.33237243e-03, -3.90586890e-02,\n",
       "          2.65142471e-02,  5.45098586e-03, -2.09412668e-02, -2.50222394e-03,\n",
       "         -5.82473632e-03,  4.21100780e-02,  1.56139983e-02, -3.72542813e-02,\n",
       "          2.75207404e-03,  2.58713349e-04,  3.87767255e-02, -1.45064713e-02,\n",
       "          3.92942410e-03, -4.91738087e-03,  1.77543552e-03,  7.47256959e-03,\n",
       "          1.80984009e-02,  6.94195228e-03,  1.94230247e-02,  2.98349943e-04,\n",
       "         -5.83523419e-03,  3.67602217e-04,  8.32271110e-03, -5.95592521e-02,\n",
       "         -7.01662675e-02, -2.41367649e-02, -3.26741524e-02, -6.91582775e-03,\n",
       "          1.27989249e-02, -2.84332708e-02, -1.50223142e-02,  1.14907767e-03,\n",
       "          3.41305509e-02,  2.26686732e-03,  9.01306048e-04,  3.67302028e-03,\n",
       "         -5.38285356e-03, -2.11807508e-02,  2.83398591e-02,  1.94408223e-02,\n",
       "         -8.06224719e-03,  1.14664072e-02, -6.60913857e-03,  5.76059846e-03,\n",
       "          2.21848357e-02,  8.19492713e-03,  2.06692889e-02, -2.49586087e-02,\n",
       "          1.33754294e-02,  9.76512395e-03, -5.20207919e-02,  1.54315969e-02,\n",
       "          7.14676455e-03,  1.46582676e-02, -5.24832588e-03, -1.51815498e-02,\n",
       "          3.13515514e-02,  1.05789881e-02,  9.80954990e-03, -3.68245393e-02,\n",
       "         -2.84326840e-02,  2.24208441e-02,  2.80376663e-03,  4.73800348e-03,\n",
       "         -5.33209974e-03,  1.80265959e-02,  1.33424774e-02,  6.65658014e-03,\n",
       "         -1.00706797e-02, -2.26577856e-02, -2.84352303e-02, -1.43553736e-02,\n",
       "         -8.73809122e-03, -2.31092591e-02, -1.53321261e-02, -2.82280240e-02,\n",
       "          3.61203738e-02,  2.08385848e-02,  3.19199357e-03,  6.52456358e-02,\n",
       "         -7.18936743e-03, -1.76283568e-02,  2.72234455e-02,  5.62550081e-03,\n",
       "          1.85112152e-02,  2.57043466e-02,  1.16970623e-02,  2.17251275e-02,\n",
       "         -1.05809486e-02, -5.71560441e-03,  2.37680655e-02,  1.36648063e-02,\n",
       "         -1.55500770e-02,  1.52983712e-02,  4.32201847e-02,  2.44552316e-03,\n",
       "         -1.13079688e-02, -2.21480168e-02, -7.26040592e-03, -1.64670814e-02,\n",
       "         -1.56143808e-03, -1.22870980e-02, -1.42790256e-02, -4.23594704e-03,\n",
       "          3.61526422e-02, -1.56652294e-02, -6.12294907e-03,  1.18709332e-03,\n",
       "          1.26899092e-03, -7.26666767e-03, -5.75510459e-03, -1.41079621e-02,\n",
       "         -3.40915308e-03,  6.28062990e-03, -9.81275924e-03, -7.55111640e-03,\n",
       "         -1.95348617e-02,  9.16482881e-03, -1.99959427e-02, -1.67775247e-02,\n",
       "         -3.80271748e-02,  3.79759865e-03, -3.99940722e-02,  3.81953642e-02,\n",
       "         -6.05405681e-03, -3.65787465e-03, -1.34203676e-02,  2.35947268e-03,\n",
       "         -3.56633738e-02,  4.71752556e-03,  1.94694642e-02,  4.18639220e-02,\n",
       "         -6.79129642e-03,  1.21399397e-02,  2.49568392e-02,  1.65563799e-03,\n",
       "          2.62649730e-02,  7.39581184e-03, -1.45408651e-02,  1.18916854e-02,\n",
       "          8.09856225e-03, -5.38859225e-04,  2.23374628e-02,  3.81446443e-02,\n",
       "         -1.29260507e-05, -2.89838626e-05, -2.28978880e-02, -2.32040025e-02,\n",
       "          1.52273860e-03,  7.32014747e-03,  1.85750611e-02, -8.94600619e-03,\n",
       "          9.49170068e-03,  8.58986471e-03,  2.28537503e-03, -7.46536488e-03,\n",
       "         -2.49190833e-02,  1.27490526e-02,  9.22492892e-03,  2.21726857e-03,\n",
       "          8.53138138e-03, -1.49638131e-02, -5.13079530e-03,  4.51094331e-03,\n",
       "         -1.48074348e-02,  2.26277001e-02,  2.01700479e-02,  6.87572453e-03,\n",
       "         -1.61882918e-02, -2.43804809e-02, -1.52673367e-02,  1.75713897e-02,\n",
       "         -2.73850234e-03, -1.15568575e-04, -1.61429183e-04, -1.29108946e-03,\n",
       "         -1.77445658e-03,  2.76465192e-02,  2.04723272e-02,  4.51796949e-02,\n",
       "         -1.00743994e-02,  1.71035994e-02,  4.68410030e-02, -9.93393268e-03,\n",
       "         -2.67669521e-02, -1.18923271e-02,  1.06390119e-02, -3.30305682e-03,\n",
       "          1.46601303e-02,  2.39493878e-04,  9.48880333e-03, -2.23181285e-02,\n",
       "          5.50230965e-03, -3.78428139e-02,  2.20651254e-02, -2.65908968e-02,\n",
       "          2.47954577e-02, -6.58203475e-03,  1.07026082e-02, -3.40373628e-03,\n",
       "          2.30083782e-02,  3.66552803e-03, -2.24533938e-02,  2.42717136e-02,\n",
       "          1.70376874e-03,  1.25994571e-02, -6.95519987e-03, -1.32836951e-02,\n",
       "          1.51982820e-02,  4.07850044e-03, -2.89511285e-03,  1.23000396e-02,\n",
       "          4.56344336e-03,  2.17188732e-03,  1.06212413e-02, -1.95350088e-02,\n",
       "         -6.24068128e-03, -7.36759789e-03,  2.36658938e-02,  1.85070466e-02,\n",
       "         -1.01517895e-02,  8.45299195e-03, -3.96526046e-02, -2.28118431e-02,\n",
       "         -1.38476901e-02,  2.42976402e-03, -7.61477370e-03,  1.92602689e-04,\n",
       "          1.67990674e-03,  2.00461410e-02, -3.88587974e-02,  3.25902412e-03,\n",
       "         -3.60527635e-02, -1.49907768e-02,  2.36570816e-02,  2.04897765e-02,\n",
       "         -8.86448100e-03,  2.54768468e-02, -3.34817395e-02,  1.06162252e-02,\n",
       "         -2.79615279e-02,  5.81245078e-03,  4.64799628e-03,  1.48560684e-02,\n",
       "         -6.63522677e-03, -4.34386916e-03, -1.23349493e-02, -2.97183748e-02,\n",
       "          2.59042718e-03, -1.05171520e-02,  3.44367418e-03,  5.84363705e-04,\n",
       "          3.02328356e-02,  1.27324872e-02,  1.61124133e-02, -8.38897191e-03,\n",
       "          1.71946976e-05, -1.67321675e-02,  4.38358709e-02,  1.81939099e-02,\n",
       "         -2.25788802e-02,  5.08990977e-03,  1.92632992e-02, -1.73145737e-02,\n",
       "          2.77586803e-02,  6.82122028e-03, -1.73112806e-02, -3.91061045e-03,\n",
       "         -1.55626219e-02,  1.00590596e-02,  2.31067389e-02, -2.04534773e-02,\n",
       "          2.04784498e-02, -2.18501990e-03, -2.43958272e-02,  4.11281548e-03,\n",
       "         -2.17137504e-02, -2.68410686e-02,  6.46599289e-03,  6.58228016e-03,\n",
       "          9.12803505e-03,  5.20146498e-03, -4.50483821e-02, -1.72079436e-03,\n",
       "         -1.75914087e-03,  2.15000622e-02, -2.17022765e-02, -4.20266250e-03,\n",
       "         -1.20446971e-02,  2.89167780e-02, -7.41017936e-03,  1.62634086e-02,\n",
       "          6.75228052e-03, -1.18230991e-02, -2.26870368e-04,  3.42175527e-03,\n",
       "          2.57437467e-03, -3.73710296e-03, -1.83559097e-02, -5.60806773e-04,\n",
       "          6.12025149e-03,  1.12373335e-02,  2.70868535e-04, -4.01812233e-02,\n",
       "          1.30157350e-02, -2.05365028e-02,  2.38567740e-02, -1.86143536e-02,\n",
       "         -1.34507660e-02,  2.88633425e-02, -1.12509979e-02, -5.63140586e-03,\n",
       "         -3.61013673e-02,  7.36668007e-03, -5.87789528e-03,  2.02697162e-02,\n",
       "         -3.53316404e-02,  2.39868499e-02,  2.17084493e-03,  9.16652195e-03,\n",
       "          2.24819159e-04, -2.68788971e-02,  4.43079975e-03, -3.26586887e-02,\n",
       "         -1.15170740e-02,  8.52619763e-03, -4.46459046e-03, -1.24544569e-03,\n",
       "         -1.86966676e-02,  3.01232729e-02,  3.19851656e-03, -2.73419935e-02,\n",
       "          2.84398813e-02,  2.52189189e-02, -4.43857349e-03, -1.89106930e-02,\n",
       "         -6.38487656e-03,  1.01333009e-02, -5.48420195e-03, -1.85191147e-02,\n",
       "          1.23024266e-02,  2.55506951e-03, -4.59236000e-03,  1.71517283e-02,\n",
       "          3.00622620e-02,  4.75961976e-02,  3.43514644e-02, -1.58718787e-02,\n",
       "         -1.83383022e-02,  1.53777786e-02, -1.37237068e-02, -5.24799107e-03,\n",
       "          2.66780378e-03, -9.48439259e-03,  2.95761582e-02,  1.46645270e-02,\n",
       "          3.07096243e-02, -1.11015728e-02,  1.18355267e-02,  3.48245017e-02,\n",
       "          7.44854705e-03,  6.72985287e-03, -2.62070633e-03,  6.93891314e-04,\n",
       "          1.64043922e-02,  2.66989321e-02,  3.35972733e-03,  1.63122304e-02,\n",
       "          4.01548781e-02,  8.21878575e-03,  1.55829741e-02, -1.51372803e-02,\n",
       "          2.27306038e-03, -2.85641532e-02,  8.39883275e-03,  2.62170509e-02,\n",
       "         -4.82805399e-03,  9.05833673e-03,  2.64797546e-02,  8.08649231e-03,\n",
       "          1.91042968e-03,  2.07353868e-02, -3.38003077e-02, -1.32047525e-02,\n",
       "         -2.45783683e-02,  3.61630730e-02,  1.92971732e-02, -4.37503830e-02,\n",
       "          1.07338587e-02,  1.54876513e-02,  4.41237651e-02,  3.55869206e-03,\n",
       "          3.33139263e-02,  2.23307386e-02, -4.78328671e-03,  1.08603593e-02,\n",
       "          5.09065576e-03,  2.31822580e-02, -4.17443365e-02, -1.01819178e-02,\n",
       "          1.26939723e-02, -1.19842188e-02, -2.21223310e-02, -1.48934918e-02,\n",
       "          1.95252039e-02, -6.72351383e-03, -1.21818564e-03,  2.35919934e-03,\n",
       "         -3.46679464e-02, -4.27807122e-02, -2.03486457e-02,  2.78465189e-02,\n",
       "          4.68616672e-02, -3.51899825e-02,  2.90541425e-02,  3.12551893e-02,\n",
       "         -1.06413616e-02, -1.32858045e-02, -8.81031062e-03, -1.21898185e-02,\n",
       "          5.11715142e-03,  8.04901402e-03, -5.36272209e-03, -9.79010854e-03,\n",
       "          2.06209570e-02,  3.23104300e-02, -2.33008247e-02, -3.09852115e-03,\n",
       "          2.58358791e-02,  1.92441065e-02,  9.93879884e-03, -6.00547716e-02,\n",
       "         -1.65730454e-02, -9.65574011e-03,  4.97992616e-03, -1.29342619e-02,\n",
       "          2.15870179e-02, -4.04798659e-03,  1.38336364e-02, -1.42187870e-03,\n",
       "          3.14620178e-04, -4.04206570e-03, -5.17639192e-03,  1.50695378e-02,\n",
       "          1.31570455e-02, -2.72551943e-02,  2.43388042e-02,  7.28285965e-03,\n",
       "         -3.02054528e-02, -2.27787383e-02, -2.42522117e-02, -8.12316500e-03,\n",
       "         -2.72309463e-02, -2.92286556e-02, -4.70830686e-03,  1.08572897e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 1,\n",
       "  'topic_words': array(['neuronal', 'neurosciences', 'neurobiological', 'neuroscientific',\n",
       "         'neuroscience', 'neurosci', 'neurogenesis', 'neurobiology',\n",
       "         'neurons', 'neuro', 'neuron', 'neural', 'neurological',\n",
       "         'neuroimaging', 'neuroethics', 'neurol', 'neuroscientists',\n",
       "         'neuroimage', 'neuroscientist', 'neurology', 'neurobiol',\n",
       "         'neurosurg', 'neurocultures', 'alzheimers', 'brainstem',\n",
       "         'correlated', 'correlations', 'correlation', 'correlates',\n",
       "         'correlate', '신경망', 'cerebrospinal', 'brains', 'brain',\n",
       "         'alzheimer', 'somatosensory', 'genome', 'cerebral', 'clustering',\n",
       "         '신경', 'neurofeminist', 'developmental', 'synapses', 'cognitive',\n",
       "         'biology', 'neurofeminism', 'intrinsic', 'forebrain', 'midbrain',\n",
       "         'psychology'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.04367518,  0.01686145, -0.02994338,  0.01506373, -0.03379631,\n",
       "          0.03674919, -0.00512181,  0.0029315 ,  0.00916626,  0.04206098,\n",
       "         -0.00290107, -0.02670439,  0.03041011, -0.00027404, -0.0446522 ,\n",
       "          0.0280352 ,  0.00151996, -0.02284001,  0.02679244,  0.035854  ,\n",
       "         -0.0006723 , -0.04558334, -0.00937535,  0.0393282 , -0.05503694,\n",
       "         -0.01318311,  0.01895068,  0.02046972,  0.02476652, -0.01863768,\n",
       "         -0.02356493,  0.0203791 ,  0.01210491, -0.05329704,  0.0096463 ,\n",
       "         -0.04226772, -0.02594542,  0.00230336,  0.00985433, -0.03262977,\n",
       "         -0.01824366,  0.02266762,  0.0462942 , -0.00601977, -0.02958086,\n",
       "         -0.01392155,  0.0491178 ,  0.01936375,  0.00927467, -0.01351319,\n",
       "          0.02229652, -0.01706505,  0.02268017,  0.00919669,  0.02496274,\n",
       "         -0.04210418,  0.02616915,  0.0175142 ,  0.00725165,  0.03844475,\n",
       "         -0.02202031,  0.05070961, -0.03782725, -0.0373765 , -0.00657396,\n",
       "         -0.00770737,  0.02742177, -0.02382976, -0.01802637, -0.01534095,\n",
       "         -0.01699361,  0.00590978,  0.00276684, -0.03930719, -0.02975221,\n",
       "         -0.02403345,  0.02538616,  0.0274257 , -0.03316228, -0.05394921,\n",
       "         -0.05527056, -0.03958102,  0.03156691,  0.03730585, -0.02881381,\n",
       "         -0.00867225, -0.03539513,  0.00855405,  0.00272166, -0.00374764,\n",
       "         -0.03969256, -0.04366674, -0.02864994, -0.04729284,  0.01092841,\n",
       "          0.048574  ,  0.0493216 ,  0.04999441,  0.02621179,  0.01743196,\n",
       "          0.03118943,  0.0085144 ,  0.00872727,  0.00171466,  0.01430472,\n",
       "          0.02535829, -0.05228993, -0.02141299,  0.00910956,  0.04347055,\n",
       "          0.03246597, -0.04487378, -0.02742841,  0.00447675,  0.03070762,\n",
       "         -0.02143859,  0.03358933,  0.02465578, -0.03995398,  0.01386507,\n",
       "         -0.03313145,  0.04246123,  0.03840224, -0.01177705, -0.00580839,\n",
       "          0.0219296 ,  0.04484618,  0.01736808, -0.03917789,  0.04260278,\n",
       "         -0.0443374 , -0.01122423,  0.02513258,  0.03811098, -0.02405019,\n",
       "          0.05407375, -0.0392507 , -0.00289018,  0.05193836,  0.01875994,\n",
       "          0.04107468, -0.01455553,  0.03522309, -0.01301002,  0.04755178,\n",
       "          0.01436917, -0.0230171 ,  0.04341669,  0.01504795,  0.03211005,\n",
       "          0.05060944,  0.03766438, -0.02082516, -0.03980476, -0.00327645,\n",
       "         -0.0013288 ,  0.00351554, -0.0221072 ,  0.00875478, -0.03572517,\n",
       "          0.03833216, -0.04103218, -0.04614701, -0.00745596,  0.00351838,\n",
       "         -0.03338518,  0.00475434,  0.00179997, -0.05107734,  0.03711022,\n",
       "         -0.02351219, -0.01689138,  0.02249052, -0.00256438, -0.02630889,\n",
       "          0.01273441,  0.02790106,  0.02896115, -0.01969984,  0.03356776,\n",
       "          0.01841356, -0.02945202, -0.02055879, -0.01575023, -0.01044478,\n",
       "         -0.01714223,  0.01087005,  0.04964394,  0.00958295,  0.01335898,\n",
       "         -0.00870419, -0.02171331, -0.00565315, -0.02140603, -0.03860134,\n",
       "          0.00884855, -0.02876176,  0.02780806,  0.0527278 ,  0.01670467,\n",
       "         -0.02654625,  0.0302259 ,  0.00497924, -0.02595935,  0.00855451,\n",
       "         -0.03834236, -0.03975045,  0.01331518,  0.03204438,  0.03099653,\n",
       "          0.01139621, -0.00045844, -0.02685524,  0.00061112,  0.0396037 ,\n",
       "         -0.0119441 ,  0.00714334, -0.04111867, -0.00981781, -0.01212483,\n",
       "         -0.00394866,  0.03664572,  0.05074043,  0.02870039, -0.0442765 ,\n",
       "         -0.0179744 , -0.05410258,  0.01790511,  0.00686508, -0.02359976,\n",
       "         -0.00929668,  0.04355088, -0.03709888,  0.03989651,  0.01887528,\n",
       "         -0.00594696,  0.01128268,  0.024341  ,  0.05115946, -0.03180512,\n",
       "         -0.0140244 ,  0.01739326, -0.01665177,  0.01289139,  0.03844503,\n",
       "         -0.01849806,  0.04071147,  0.00183073, -0.00608301,  0.01833495,\n",
       "         -0.01965757, -0.04252742,  0.04043483,  0.00327411,  0.00121581,\n",
       "          0.00173388,  0.01635313,  0.0231207 , -0.03488753,  0.02076802,\n",
       "         -0.0067723 ,  0.04233641, -0.02471983,  0.0158625 ,  0.01940705,\n",
       "         -0.05475484, -0.03656023,  0.02482884,  0.00810955,  0.03222125,\n",
       "          0.01173989, -0.0198044 , -0.03495175, -0.02398855, -0.01524822,\n",
       "          0.01317059, -0.04621404,  0.03248918, -0.05386025, -0.01179461,\n",
       "         -0.02582301, -0.01617306,  0.01981568,  0.02592513, -0.02056194,\n",
       "          0.03668734, -0.04291524, -0.03347733,  0.00040797,  0.00037011,\n",
       "          0.03869662,  0.01419003,  0.0304085 , -0.02507893, -0.02362423,\n",
       "         -0.02009956,  0.01780688,  0.02773866,  0.03506201,  0.04351198,\n",
       "         -0.03563012,  0.0180894 , -0.00042859, -0.03146839, -0.03066122,\n",
       "         -0.03604575, -0.02786619,  0.02473381, -0.00574029,  0.02395636,\n",
       "         -0.04126928, -0.03251405,  0.00647583, -0.04076242,  0.05050423,\n",
       "          0.04376379,  0.00293234, -0.02736709,  0.02260359, -0.03354885,\n",
       "          0.0173254 , -0.05140055, -0.01304484,  0.03229363, -0.04451171,\n",
       "         -0.01304217,  0.00931252, -0.0045379 , -0.00403752,  0.03339138,\n",
       "         -0.02948519, -0.03821682, -0.03923346, -0.0184079 , -0.00148282,\n",
       "         -0.00020787, -0.04403921, -0.03831228, -0.04227413,  0.01831682,\n",
       "         -0.03255083,  0.0098798 , -0.01070691, -0.03915166,  0.01377993,\n",
       "          0.0411686 ,  0.0505132 , -0.02279141, -0.02146848,  0.03512256,\n",
       "          0.03808033,  0.02030234, -0.01602954,  0.03753117,  0.00114708,\n",
       "          0.0230075 , -0.00605308,  0.02474353, -0.02600204, -0.04339965,\n",
       "          0.02214743, -0.02940167,  0.04555161, -0.01245483, -0.03406787,\n",
       "          0.01796086, -0.03771634,  0.01933512, -0.03147872,  0.02062486,\n",
       "          0.0331905 ,  0.03101877, -0.02887328,  0.01085745,  0.0162957 ,\n",
       "         -0.03883665, -0.01393551,  0.01027323,  0.00294032, -0.01765128,\n",
       "          0.04038138, -0.02559653,  0.02664617,  0.00771252, -0.01082379,\n",
       "          0.05298683,  0.03452092, -0.05126473,  0.05424928, -0.0078458 ,\n",
       "          0.01911833, -0.0204525 ,  0.00736203,  0.04074794, -0.03357213,\n",
       "          0.00617764,  0.05115133, -0.01361383, -0.03555113,  0.03140098,\n",
       "          0.03795837,  0.04247459,  0.03308681,  0.01411651, -0.02225152,\n",
       "          0.01534963,  0.00943989, -0.0293193 ,  0.02458881, -0.00126915,\n",
       "          0.03792429, -0.02945129,  0.00424217,  0.04681706,  0.00820104,\n",
       "          0.05358   ,  0.01050463, -0.03333087,  0.03991432,  0.02511731,\n",
       "         -0.03455042, -0.03366011,  0.04137356,  0.0396408 ,  0.05096189,\n",
       "          0.00174517, -0.03398529, -0.03735418, -0.03674561,  0.01452827,\n",
       "         -0.0466085 , -0.00321343, -0.02657554, -0.02744061,  0.02556246,\n",
       "          0.02189675,  0.02591218, -0.03003898, -0.05441553,  0.02862027,\n",
       "         -0.00343277,  0.00520687,  0.0163804 , -0.05091538,  0.0247917 ,\n",
       "         -0.02023119, -0.01488012,  0.03053614,  0.01300895,  0.01951594,\n",
       "         -0.02080943, -0.02146939,  0.01560364, -0.00944644, -0.03751572,\n",
       "         -0.00118809,  0.02897956,  0.02988048, -0.02420709,  0.02026902,\n",
       "         -0.01456784, -0.04611421, -0.0125809 , -0.03904467,  0.02257635,\n",
       "         -0.04674836, -0.03022909, -0.01355181,  0.04529988, -0.01089648,\n",
       "         -0.00478311,  0.03240103, -0.03625342, -0.00018443, -0.00478997,\n",
       "         -0.00429109, -0.00490564, -0.00574247, -0.02774997, -0.00470579,\n",
       "          0.03566192,  0.05541495, -0.03948031,  0.00199465,  0.03088816,\n",
       "         -0.032722  , -0.00712149, -0.0517244 , -0.03795279, -0.02344164,\n",
       "          0.03227079,  0.02786365,  0.00866615,  0.02604413, -0.03585395,\n",
       "         -0.00916813, -0.03187057, -0.01237938,  0.02897415,  0.02873498,\n",
       "          0.02690047, -0.04698817,  0.0541223 , -0.01217115, -0.04258887,\n",
       "         -0.05111927, -0.0052727 , -0.02455609, -0.03530919, -0.05216362,\n",
       "          0.01830443,  0.01066946], dtype=float32)},\n",
       " {'topic_idx': 2,\n",
       "  'topic_words': array(['probabilistic', 'statistical', 'statistically', 'probability',\n",
       "         'covariance', 'statistics', 'variance', 'coefficient', 'statistic',\n",
       "         'variances', 'coefficients', 'regression', 'correlation',\n",
       "         'predictive', 'correlations', '통계청', 'probabilities', 'predictor',\n",
       "         'multivariate', '통계', 'predictors', 'predicts', 'randomized',\n",
       "         'normalization', 'approximation', 'calculations',\n",
       "         'computationally', 'scatterplot', 'predict', 'gaussian',\n",
       "         'calculation', '확률', 'computation', 'asymptotic', 'computed',\n",
       "         'quantitative', 'matplotlib', 'predicting', 'nonparametric',\n",
       "         'exponential', 'variability', 'computational', 'populations',\n",
       "         'parametric', 'correlated', '분포', 'clustering', 'proportional',\n",
       "         'correlates', '회귀분석'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.05674189, -0.01836246, -0.02711796,  0.00228184, -0.02876088,\n",
       "         -0.00268592,  0.00381448, -0.01283583,  0.03781418,  0.01357194,\n",
       "         -0.01124443,  0.01578229,  0.0457148 ,  0.00490527, -0.05714738,\n",
       "         -0.02520745, -0.00505332, -0.02117536,  0.03465667,  0.03375893,\n",
       "         -0.02116574, -0.02688133, -0.03880353,  0.04453956, -0.05402751,\n",
       "         -0.03192605,  0.02612562,  0.0040244 , -0.00350764, -0.03579196,\n",
       "         -0.04791128,  0.01308465,  0.01988186, -0.05328369, -0.01055333,\n",
       "         -0.00490264, -0.03472671, -0.00194999,  0.02016961,  0.02240145,\n",
       "          0.01118838, -0.02163623,  0.03841518, -0.04079871, -0.01770023,\n",
       "         -0.03347784,  0.0491412 , -0.0141225 , -0.04376671, -0.00836622,\n",
       "         -0.0085368 , -0.02115975,  0.02686212, -0.00985785,  0.04850907,\n",
       "         -0.05117734,  0.01801024,  0.02813556, -0.01651638,  0.03899813,\n",
       "          0.002932  ,  0.04241859,  0.0247953 , -0.02688386,  0.00496692,\n",
       "         -0.00178228,  0.00508861,  0.00725908,  0.01784444,  0.0153723 ,\n",
       "         -0.02481679,  0.00306383, -0.01369519, -0.03826739, -0.04695293,\n",
       "         -0.04256943,  0.030046  ,  0.02155774,  0.00057519, -0.0562336 ,\n",
       "         -0.05669488, -0.0354631 ,  0.0016606 ,  0.01193879, -0.00017736,\n",
       "         -0.01540534, -0.04623836, -0.02575952, -0.02833738, -0.03574469,\n",
       "         -0.03480115, -0.0235149 ,  0.00780336, -0.05134982,  0.04359274,\n",
       "          0.05285816,  0.03486285,  0.02616552,  0.02645916,  0.01794708,\n",
       "          0.05002911, -0.00772408,  0.03868602, -0.02358099,  0.01873596,\n",
       "         -0.0490079 , -0.02964387, -0.0332825 ,  0.01868314,  0.04553348,\n",
       "          0.04268358, -0.03805349, -0.04009278,  0.00716642,  0.03054302,\n",
       "          0.01823505,  0.01786975,  0.00646953, -0.03878409,  0.02073767,\n",
       "         -0.01495752,  0.03789959,  0.01536991,  0.01200493,  0.02526801,\n",
       "          0.00481395, -0.03767608,  0.03610389, -0.03066333,  0.03636319,\n",
       "         -0.053989  ,  0.02701512,  0.05085326,  0.02409257, -0.00631416,\n",
       "          0.04217355, -0.00537576,  0.00098364,  0.04768407,  0.00045693,\n",
       "          0.01598706, -0.02588046,  0.03285054, -0.04062629,  0.04226204,\n",
       "         -0.00259536, -0.04318257,  0.02604238,  0.02652272,  0.03469909,\n",
       "          0.03923396, -0.00400132, -0.01490951, -0.03904889,  0.02989999,\n",
       "         -0.02079621,  0.00855134,  0.00564278,  0.00979079,  0.00648038,\n",
       "          0.02480058, -0.01191506,  0.00265656, -0.03060059, -0.02701709,\n",
       "         -0.01786243,  0.0061296 , -0.01709123, -0.0132516 ,  0.04852591,\n",
       "         -0.01456705, -0.00137188,  0.02796901, -0.00255653, -0.01013885,\n",
       "          0.03421774,  0.02886314,  0.02553363, -0.04037936,  0.02670052,\n",
       "          0.03080159, -0.01786137, -0.01440592,  0.00902228, -0.04686372,\n",
       "         -0.03657641,  0.03705302,  0.05108478, -0.02009756, -0.05083047,\n",
       "         -0.00438172,  0.00665139,  0.03866598, -0.02108135, -0.00207727,\n",
       "          0.0217637 , -0.05600924, -0.02189251,  0.04809392,  0.01805667,\n",
       "         -0.00799606,  0.01717332, -0.03904596,  0.00167148, -0.01975986,\n",
       "         -0.03113158, -0.03739906,  0.012646  , -0.01827083,  0.03638666,\n",
       "         -0.00423311,  0.00905185, -0.05737738,  0.00712272,  0.03636742,\n",
       "         -0.03646113, -0.01468514, -0.03636935,  0.00902669, -0.02550887,\n",
       "          0.01007952,  0.02193988,  0.03432482, -0.00555806, -0.05427438,\n",
       "          0.00932245, -0.050651  , -0.00351811,  0.0021387 ,  0.00958084,\n",
       "         -0.01678034,  0.04994731, -0.02285367, -0.01354779, -0.01037391,\n",
       "         -0.00021563, -0.01441228,  0.03339276, -0.01054295,  0.00332038,\n",
       "          0.00839309, -0.00591794, -0.00969561,  0.00907753,  0.04260062,\n",
       "         -0.0383121 ,  0.01393218, -0.01426214,  0.00259434,  0.01152944,\n",
       "         -0.02138543, -0.03331407,  0.0029903 , -0.00062051, -0.02822769,\n",
       "         -0.0076918 , -0.02064179, -0.0005477 , -0.02351236, -0.01378181,\n",
       "         -0.00124644,  0.02164873, -0.02609644, -0.02173999,  0.03409852,\n",
       "         -0.05188446, -0.01050691,  0.0026369 , -0.0072886 ,  0.01134115,\n",
       "          0.00793953, -0.0222318 , -0.03351304, -0.04599377,  0.00063343,\n",
       "          0.02267525, -0.04001107,  0.03491218, -0.05316183, -0.00179336,\n",
       "         -0.04819025,  0.01661002,  0.02960243,  0.02659845, -0.01968588,\n",
       "          0.03857201, -0.03710024, -0.03213687, -0.0125133 ,  0.03010849,\n",
       "          0.02396199,  0.03664349,  0.03641737,  0.00724466, -0.03806318,\n",
       "          0.01524341, -0.03010866,  0.01884972,  0.04511865,  0.04491555,\n",
       "         -0.04611046,  0.03098283, -0.02889922, -0.05014502, -0.0551821 ,\n",
       "         -0.00414334, -0.00382017, -0.00743025, -0.02511782,  0.00450576,\n",
       "         -0.03390649, -0.01739564, -0.04233836, -0.03325522,  0.034739  ,\n",
       "          0.03460963,  0.0272159 , -0.0386629 ,  0.01943194, -0.02018438,\n",
       "         -0.00026646,  0.00968921, -0.02820136,  0.00555388, -0.02580835,\n",
       "          0.00329538, -0.03049878, -0.01401725,  0.0021836 , -0.00506415,\n",
       "         -0.03071637, -0.03573455,  0.01738283, -0.02601629, -0.00181332,\n",
       "          0.01182189, -0.02990688, -0.01872371, -0.0514477 , -0.04032104,\n",
       "         -0.03839025, -0.01370385,  0.02444811, -0.01148476, -0.00952072,\n",
       "          0.03979756,  0.04573189,  0.00704471, -0.02169105,  0.01561821,\n",
       "          0.0346357 ,  0.01843646, -0.0132094 ,  0.01330357,  0.01942532,\n",
       "          0.01631967, -0.01456889,  0.03197712, -0.04217931, -0.02694525,\n",
       "          0.02892439, -0.04630799,  0.02774894, -0.00922439, -0.0424476 ,\n",
       "          0.02721762, -0.00108653,  0.03759902, -0.02481176,  0.04298672,\n",
       "          0.03193058,  0.03796836, -0.02074563,  0.03990936, -0.00565336,\n",
       "         -0.03729788,  0.00663081,  0.0033004 , -0.04562364, -0.04763626,\n",
       "          0.02516292, -0.04529477,  0.01697838,  0.00363866, -0.02191994,\n",
       "          0.05465393,  0.02872109, -0.04499872,  0.04582987, -0.00371215,\n",
       "          0.00138499,  0.00969198, -0.01570131,  0.04033743, -0.03099131,\n",
       "          0.00266741,  0.01247074,  0.00654766, -0.04470304,  0.0142965 ,\n",
       "          0.0288901 ,  0.0422838 ,  0.04764082,  0.00269253, -0.04136291,\n",
       "          0.01982359,  0.01255717, -0.03507571,  0.00968035, -0.00802513,\n",
       "         -0.00376167, -0.01121559,  0.00342639, -0.00476956,  0.02566044,\n",
       "          0.03298284,  0.00953228,  0.0202812 ,  0.03872095,  0.00807204,\n",
       "         -0.01301291, -0.05317989, -0.01572022,  0.05134274,  0.04852962,\n",
       "          0.0175071 , -0.00877651, -0.03064233,  0.0184076 , -0.01010174,\n",
       "         -0.02965301,  0.01428131, -0.01568376, -0.02022089,  0.04081668,\n",
       "          0.03669655,  0.02076581,  0.02362875, -0.05547957,  0.02263637,\n",
       "         -0.02946224, -0.00979587, -0.02896555, -0.05554799,  0.02512141,\n",
       "         -0.03538503,  0.03008227,  0.01940415,  0.00094429,  0.02059196,\n",
       "         -0.01548677, -0.01242847,  0.01242422, -0.03294672, -0.0448379 ,\n",
       "         -0.0357419 , -0.01082057,  0.03107941,  0.00966446,  0.04973494,\n",
       "         -0.0077477 , -0.03646525,  0.01600648, -0.04904209,  0.04346331,\n",
       "         -0.04545091, -0.00303333, -0.04526966,  0.05556855, -0.00256606,\n",
       "          0.02884913,  0.01401008, -0.02678741,  0.02542995, -0.04712059,\n",
       "         -0.00540793,  0.03029297, -0.02288182, -0.00271146, -0.01254524,\n",
       "          0.03088014,  0.05612688, -0.03063104,  0.00317211,  0.03877   ,\n",
       "          0.01711423, -0.00240526, -0.05436594, -0.01143838,  0.00690216,\n",
       "          0.02318685,  0.01957124,  0.00087483,  0.00527702, -0.01960666,\n",
       "         -0.0258529 ,  0.00434649, -0.0217643 ,  0.02435092, -0.00329353,\n",
       "          0.02021834, -0.04461898,  0.0569244 , -0.00072418, -0.03435876,\n",
       "         -0.05010167,  0.02095992, -0.03776017,  0.00147677, -0.03834207,\n",
       "         -0.02994371,  0.02922855], dtype=float32)},\n",
       " {'topic_idx': 3,\n",
       "  'topic_words': array(['matplotlib', 'ggplot', 'lineplot', 'dataframe', 'scatterplot',\n",
       "         'dataset', 'datasets', 'matlab', 'tensorflow', 'numpy',\n",
       "         'multiprocessing', 'algorithms', 'xticklabels', 'sklearn', 'data',\n",
       "         'subprocess', 'boxplot', 'graphql', 'graphs', 'computationally',\n",
       "         'algorithmic', 'parametric', 'vertexcount', 'computational',\n",
       "         'computation', 'algorithm', 'github', '파라미터', 'mxmatrix', '데이터',\n",
       "         'graph', 'calculations', 'correlations', 'subplots', 'correlation',\n",
       "         'scipy', '알고리즘', 'gaussian', 'clustering', 'plotting',\n",
       "         'calculation', 'computed', 'bmatrix', 'statistics', 'interfaces',\n",
       "         'quantitative', 'genome', '통계청', 'scaling', 'optimize'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-5.58773875e-02, -2.00029835e-02, -2.77153477e-02, -6.90346817e-03,\n",
       "         -3.60428765e-02, -5.54426163e-02,  2.38467678e-02,  1.82054136e-02,\n",
       "          4.80942763e-02,  1.70558039e-02,  2.80481614e-02, -9.36929253e-04,\n",
       "          4.71897572e-02,  8.04844871e-03, -3.65331508e-02,  1.26907378e-02,\n",
       "          8.15359317e-03,  1.11589702e-02,  4.23914827e-02,  3.99013162e-02,\n",
       "          8.94397870e-03,  2.27860082e-03, -4.19932371e-03,  3.56886983e-02,\n",
       "         -5.13919257e-02, -4.01518941e-02,  3.60544771e-02, -1.14445575e-02,\n",
       "          2.96162255e-02, -5.29825613e-02, -4.41913977e-02,  1.25599345e-02,\n",
       "          1.13699760e-03, -5.64722195e-02,  1.70530868e-03,  8.24654754e-03,\n",
       "          4.33046184e-03, -1.57017261e-02,  6.45513786e-03, -4.00732271e-03,\n",
       "         -1.70058161e-02,  1.00823231e-02, -1.46107106e-02, -2.35584546e-02,\n",
       "         -1.25450911e-02, -2.52369419e-02,  3.89619470e-02, -5.83550753e-03,\n",
       "         -3.34458500e-02, -4.72181535e-04, -3.32055837e-02, -2.39776522e-02,\n",
       "         -1.17931543e-02, -1.42949643e-02,  3.30690779e-02, -5.38935214e-02,\n",
       "         -1.32915955e-02,  2.66799238e-02,  9.77283902e-03,  4.64629047e-02,\n",
       "          2.40989495e-03,  5.08234575e-02,  8.82546697e-03, -3.26479524e-02,\n",
       "          1.47152590e-02, -2.30292846e-02,  2.39821104e-03,  1.72445159e-02,\n",
       "          4.63197269e-02,  1.46334898e-02, -3.58285047e-02,  2.30304454e-03,\n",
       "          8.34136084e-03, -1.98777691e-02, -2.07328238e-02, -2.32276432e-02,\n",
       "          1.09939603e-02,  1.91730857e-02, -1.01395389e-02, -5.92657477e-02,\n",
       "         -5.87226078e-02, -7.35284714e-03, -2.74710916e-02, -4.08435706e-03,\n",
       "          3.17411497e-02, -3.36785503e-02, -3.49722914e-02, -2.22065318e-02,\n",
       "          7.08087813e-04, -1.90797001e-02,  1.14058880e-02,  6.25138916e-03,\n",
       "         -1.52727785e-02, -3.66943292e-02,  2.32451260e-02,  4.63221818e-02,\n",
       "          5.79506531e-03,  2.10223459e-02,  2.95103528e-02, -7.32900007e-05,\n",
       "          3.83950025e-02,  2.23063137e-02,  1.25767486e-02, -1.28022218e-02,\n",
       "          3.84533890e-02,  1.10973846e-02, -4.30280156e-02, -2.90861446e-02,\n",
       "          2.72083171e-02,  3.29808295e-02,  9.87802353e-03, -4.58046123e-02,\n",
       "         -9.47060809e-03, -3.83840129e-02,  3.32338102e-02,  5.54730976e-03,\n",
       "         -2.95912288e-02, -1.33561697e-02, -2.15296280e-02,  1.00721465e-02,\n",
       "          1.23102695e-03,  1.42160440e-02,  1.14991311e-02,  4.22072746e-02,\n",
       "          4.57587689e-02, -2.48607807e-02, -4.65029571e-03,  5.85537031e-03,\n",
       "          1.17794359e-02,  2.17356700e-02, -4.28968370e-02,  1.26355579e-02,\n",
       "          5.72345778e-02,  1.37778912e-02,  7.94240367e-03,  4.38667573e-02,\n",
       "         -6.90084929e-03, -1.10314861e-02,  3.71299535e-02,  4.78124693e-02,\n",
       "         -1.08588915e-02, -2.73688827e-02,  1.67385042e-02,  3.71445995e-03,\n",
       "          1.94557011e-02, -3.21975872e-02, -3.12534757e-02,  4.51759845e-02,\n",
       "          2.80697048e-02, -4.58633713e-03,  4.32884246e-02,  4.29149792e-02,\n",
       "         -8.75557680e-03, -3.20274904e-02,  9.39377770e-03, -2.63287406e-02,\n",
       "         -7.84681528e-04, -1.76308770e-02,  9.12785437e-03,  1.35290958e-02,\n",
       "          4.34451960e-02, -2.97260727e-03,  4.26658913e-02, -8.24038684e-03,\n",
       "         -7.69561669e-03, -1.79466568e-02, -1.71544850e-02, -1.58386771e-02,\n",
       "         -2.70253792e-03,  4.10582162e-02,  1.83389802e-02, -3.88736799e-02,\n",
       "          2.94203241e-03,  1.87630653e-02,  1.21770613e-02,  4.63597216e-02,\n",
       "         -5.37010096e-02,  1.11794434e-02, -4.71940637e-02,  3.86751927e-02,\n",
       "          2.06895694e-02, -1.91610083e-02, -7.84789957e-03, -2.00228082e-04,\n",
       "         -4.63458635e-02, -3.27322856e-02,  4.38560732e-02,  4.29890975e-02,\n",
       "          5.32683358e-03, -9.35600325e-03,  7.77925970e-03, -2.80544236e-02,\n",
       "          3.98008451e-02,  2.37073284e-02, -2.87405611e-03,  5.14396746e-03,\n",
       "         -4.77124453e-02, -1.92344841e-03,  4.46562208e-02,  2.59609390e-02,\n",
       "         -1.66916028e-02,  1.62755586e-02, -1.30370900e-04, -3.64812538e-02,\n",
       "         -2.35361792e-02, -1.66189373e-02,  1.27912508e-02, -5.35921613e-03,\n",
       "         -2.30580606e-02,  2.41474342e-02, -9.42511391e-03,  1.02367997e-03,\n",
       "         -4.11879420e-02,  3.33361281e-03,  3.67229618e-02, -1.25664705e-02,\n",
       "         -1.43622365e-02, -5.07974811e-02,  1.89000070e-02, -2.71344651e-02,\n",
       "         -4.28021606e-03,  3.43471430e-02, -1.13477046e-03, -1.92873855e-03,\n",
       "         -5.45108393e-02,  2.40465365e-02, -4.18035015e-02, -5.48585085e-03,\n",
       "          3.09514105e-02,  1.25615047e-02, -2.20717601e-02,  5.23183569e-02,\n",
       "         -7.44614098e-03,  4.30164626e-03,  1.03676701e-02,  2.54098382e-02,\n",
       "         -1.66918207e-02,  2.38426011e-02,  2.65256669e-02, -3.02413274e-02,\n",
       "          3.29781161e-03,  2.68763453e-02, -9.17290524e-03,  1.77993905e-02,\n",
       "         -1.07496064e-02, -5.72273433e-02,  4.42524091e-04, -2.09800564e-02,\n",
       "          2.07432415e-02, -2.84298304e-02, -3.08585856e-02, -4.03900743e-02,\n",
       "          2.75797886e-03,  2.78378036e-02,  7.85149110e-04, -2.51170597e-03,\n",
       "         -2.46894057e-03, -1.24852266e-02, -9.27887484e-03, -9.38518718e-03,\n",
       "         -1.48023572e-02,  1.34774167e-02, -2.01200414e-02, -3.15266065e-02,\n",
       "          8.13741330e-03, -4.42489572e-02, -9.33930743e-03,  5.49791427e-03,\n",
       "          1.59868971e-02,  1.86145771e-02, -2.78728269e-02, -3.46373431e-02,\n",
       "         -4.17329445e-02, -9.35271266e-04, -5.84945315e-03,  1.02476347e-02,\n",
       "         -4.06064577e-02,  1.82424411e-02, -4.25941721e-02,  5.27997501e-03,\n",
       "         -2.96304524e-02,  2.08124612e-02,  3.09340339e-02,  2.30658744e-02,\n",
       "         -3.68696195e-03,  3.08045205e-02, -4.61536460e-02, -4.02994864e-02,\n",
       "         -2.58095772e-03,  3.22819762e-02,  3.79827432e-02,  3.57973129e-02,\n",
       "          1.91383343e-02,  4.56165597e-02, -5.41138873e-02,  5.03838481e-03,\n",
       "         -3.67086157e-02,  1.06625948e-02, -1.87889137e-03,  5.07342815e-02,\n",
       "         -1.22624692e-02,  1.93627048e-02, -5.32425754e-03, -4.45536934e-02,\n",
       "         -4.65311557e-02, -3.27945948e-02, -2.66810395e-02, -2.40966328e-03,\n",
       "          1.49589265e-02,  1.92706790e-02, -2.20074132e-02, -7.73510570e-03,\n",
       "         -4.73911129e-03, -9.61855520e-03,  1.63169522e-02,  2.14645229e-02,\n",
       "          1.79262105e-02, -2.13967934e-02,  1.03434874e-02, -1.37188565e-02,\n",
       "          7.82896485e-03, -1.49684995e-02, -1.14208097e-02, -1.68223940e-02,\n",
       "         -9.50725004e-03,  6.33245800e-03, -1.56554021e-02, -3.74868996e-02,\n",
       "         -3.16564701e-02,  1.80590048e-03, -3.42374966e-02, -2.03490835e-02,\n",
       "         -2.58674454e-02, -1.96744744e-02, -1.34908529e-02,  2.38749888e-02,\n",
       "          4.59375279e-03,  6.04934758e-04, -5.70700280e-02,  2.51650624e-03,\n",
       "         -4.19194922e-02, -6.05270127e-03,  3.55711803e-02, -1.79640893e-02,\n",
       "         -4.96757496e-03,  2.30862275e-02,  4.29500043e-02,  1.02312947e-02,\n",
       "         -8.16644356e-03, -1.04479967e-02,  2.51812730e-02,  1.40844695e-02,\n",
       "          1.95560697e-02, -4.63057086e-02, -1.27294920e-02, -7.61296973e-03,\n",
       "          3.04377489e-02,  3.85801978e-02, -2.15371214e-02, -4.37568054e-02,\n",
       "         -2.18647462e-03, -3.19406651e-02,  3.26324217e-02, -3.77191044e-02,\n",
       "         -2.64314301e-02,  5.23554813e-03,  3.29215117e-02,  3.47579494e-02,\n",
       "         -1.71761140e-02,  1.53561179e-02, -5.14780823e-03,  4.52550910e-02,\n",
       "         -2.60716826e-02,  3.86209935e-02,  1.44869266e-02, -3.58527415e-02,\n",
       "         -1.79252103e-02, -1.28610544e-02, -3.76273207e-02, -3.13272402e-02,\n",
       "          6.85939449e-04, -3.59438844e-02,  1.04258554e-02, -1.73043739e-02,\n",
       "         -2.94764508e-02,  3.86695266e-02,  3.61724198e-02, -5.34939244e-02,\n",
       "          3.62493470e-02, -3.73365940e-03, -7.59516982e-03, -1.74840037e-02,\n",
       "         -3.26986909e-02,  3.77857033e-03, -9.80179291e-03,  8.90046172e-03,\n",
       "          1.78923570e-02,  6.42231619e-03, -2.26950198e-02,  5.29103633e-03,\n",
       "          4.30656075e-02,  1.23939430e-02,  4.44914065e-02, -1.83336306e-02,\n",
       "         -3.21167074e-02, -3.33289336e-03,  1.51731661e-02, -4.40043695e-02,\n",
       "          3.14937532e-02,  8.08654912e-03,  2.86788028e-03,  2.45403145e-02,\n",
       "          3.46045084e-02, -2.13320684e-02,  3.55997682e-02, -1.11257844e-03,\n",
       "          2.95895170e-02,  3.86726074e-02,  6.76938659e-03,  2.77811978e-02,\n",
       "          4.81144264e-02, -5.30381403e-05,  3.70961241e-02,  3.48039493e-02,\n",
       "          1.97946671e-02,  1.88976917e-02,  4.03060168e-02, -1.58556588e-02,\n",
       "         -8.53096228e-03, -5.33989491e-03, -1.35076856e-02, -1.18408184e-02,\n",
       "          5.18969353e-03,  1.35730887e-02, -2.18585436e-03,  6.79247687e-03,\n",
       "         -8.58096126e-03,  1.57258566e-02, -5.24569601e-02,  1.93570293e-02,\n",
       "         -3.96763049e-02,  2.25898325e-02,  8.89486820e-03, -5.25443666e-02,\n",
       "         -1.42447818e-02, -3.98649015e-02,  4.15741615e-02,  1.45849437e-02,\n",
       "         -7.13268295e-03,  2.15376224e-02,  2.05010120e-02, -1.13506597e-02,\n",
       "         -3.22767124e-02, -1.43886497e-02, -3.44221368e-02, -3.13549414e-02,\n",
       "          3.32431719e-02,  4.39397953e-02,  5.39851328e-03,  4.50044572e-02,\n",
       "         -3.90286534e-03, -3.33911777e-02, -2.36597704e-03, -3.33649144e-02,\n",
       "          3.20127718e-02, -4.23810408e-02, -2.13690605e-02, -3.77988368e-02,\n",
       "          5.45931458e-02, -2.24073417e-02,  4.00296897e-02,  2.37148833e-02,\n",
       "          7.19748763e-03,  7.12514715e-03, -3.81424464e-02, -1.38411596e-02,\n",
       "          1.14692710e-02, -2.41548289e-02,  1.36097185e-02, -1.51616000e-02,\n",
       "          4.82547842e-02,  4.27796170e-02, -2.37116832e-02,  9.56127979e-03,\n",
       "         -5.23645943e-03, -2.20293291e-02,  3.40491091e-03, -5.47454283e-02,\n",
       "          8.25665519e-03, -5.91146201e-03,  1.24960458e-02,  9.72924009e-03,\n",
       "          4.54312794e-06, -2.53352075e-04, -4.03690571e-03, -2.52412651e-02,\n",
       "          2.59935437e-03, -3.27564701e-02,  3.36532481e-02,  2.94991992e-02,\n",
       "          1.04620820e-02, -3.23243327e-02,  4.82093766e-02,  4.40667942e-03,\n",
       "         -2.75778417e-02, -5.79889044e-02, -9.78064816e-03, -1.07146166e-02,\n",
       "         -2.05968972e-03, -3.93435322e-02, -1.00163685e-03,  2.20900495e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 4,\n",
       "  'topic_words': array(['서울대', '서울시', '서울', 'seoul', '평양', 'korean', '한국', '신청', '한국어',\n",
       "         'korea', 'uniformity', 'regularization', '전공', '경제', 'application',\n",
       "         'simplest', '대중', '한글', '신용', '급여', 'population', 'normalized',\n",
       "         '서민', 'fundamental', 'basic', 'asymptotic', 'accounting',\n",
       "         'imperative', '일반', 'applications', 'general', '정리', 'percentage',\n",
       "         'simplified', 'differentiated', 'widespread', '수많', 'soup', '지하철',\n",
       "         'populations', 'procedures', 'normalization', 'saliency', '공공',\n",
       "         'economic', 'diversity', 'economics', 'commonly', 'common',\n",
       "         'cities'], dtype='<U15'),\n",
       "  'topic_vector': array([ 4.39929822e-03,  6.36617607e-03, -1.31736072e-02,  9.94292460e-03,\n",
       "          3.38204727e-02,  4.42830361e-02, -4.86310804e-03,  5.56128938e-03,\n",
       "          9.69492178e-03,  2.80366056e-02, -1.72288083e-02,  1.29671578e-04,\n",
       "          2.29024384e-02, -6.43459102e-03, -1.66915695e-03,  2.06855107e-02,\n",
       "          1.03901466e-02, -2.40892954e-02,  3.26655060e-02,  4.82572019e-02,\n",
       "          1.61670183e-03, -1.96932424e-02,  5.24051907e-03,  9.67655703e-03,\n",
       "         -5.67088909e-02, -1.90918874e-02, -9.13585816e-03,  6.60264492e-03,\n",
       "          2.83990018e-02, -4.18604389e-02, -2.82943510e-02,  2.42600078e-03,\n",
       "          1.30445035e-02, -3.58218215e-02,  2.03825496e-02, -1.18738962e-02,\n",
       "          1.35435816e-02, -4.46389541e-02,  5.86397480e-03, -1.67744607e-02,\n",
       "         -1.22280968e-02, -1.84477214e-02,  3.73635930e-03, -1.56536959e-02,\n",
       "          2.61140685e-03, -4.40605804e-02, -2.40553748e-02, -2.35215891e-02,\n",
       "         -1.46684097e-02,  1.18651148e-02, -6.35578344e-03, -1.31381843e-02,\n",
       "          8.22441373e-03, -1.70373488e-02,  3.57590914e-02, -5.81526756e-02,\n",
       "          2.34362222e-02, -3.30560729e-02, -1.47557082e-02,  2.76568090e-03,\n",
       "          1.08181285e-02,  5.60401268e-02,  6.08153502e-03, -2.56313737e-02,\n",
       "          9.54435236e-05,  9.71819554e-03,  2.63615437e-02, -1.62691809e-02,\n",
       "         -2.09736265e-02, -2.46357769e-02,  2.37846817e-03,  3.59339453e-02,\n",
       "          1.38785709e-02,  2.42100214e-03, -3.68638034e-03,  1.56754255e-02,\n",
       "         -2.81612645e-03,  7.66780879e-03,  5.65495947e-03, -6.14167824e-02,\n",
       "         -6.35971576e-02, -1.11056520e-02,  2.01245602e-02,  1.60450973e-02,\n",
       "          1.50293665e-04, -2.94645727e-02, -4.74483892e-02, -2.27561034e-02,\n",
       "          2.16405634e-02, -4.76085348e-03, -1.31257866e-02,  5.11956355e-03,\n",
       "         -1.26720341e-02, -1.10942870e-02,  1.04925605e-02,  1.30053256e-02,\n",
       "          2.88073614e-04,  4.06483896e-02, -1.44654214e-02,  1.71099268e-02,\n",
       "         -7.73195084e-03,  2.20066458e-02, -3.27700982e-03,  1.35386679e-02,\n",
       "         -5.35466895e-03, -1.88953169e-02, -1.52955083e-02, -1.90905407e-02,\n",
       "          1.10027455e-02, -5.06716734e-03,  2.04569586e-02,  3.71379638e-03,\n",
       "          4.23341207e-02,  1.80721283e-02,  2.36295108e-02,  8.14318471e-03,\n",
       "          2.12981515e-02, -3.12485895e-03, -7.70522375e-03, -3.08043659e-02,\n",
       "         -2.52670012e-02, -3.19917575e-02,  1.68866925e-02, -9.23640467e-03,\n",
       "          1.34542631e-02, -1.97481643e-02, -4.58216667e-03,  3.80657874e-02,\n",
       "         -3.08988150e-02,  2.22575627e-02, -4.08850163e-02, -1.41282026e-02,\n",
       "          1.57768372e-02,  1.66438483e-02, -2.50825696e-02,  5.97081855e-02,\n",
       "         -5.96785452e-03, -1.40134841e-02,  4.87052463e-02, -3.15434709e-02,\n",
       "          3.75909880e-02, -1.89664471e-03, -1.64491460e-02,  1.05592571e-02,\n",
       "          1.23441275e-02, -1.32023841e-02,  4.27561738e-02, -1.17861591e-02,\n",
       "          1.67549904e-02,  1.49674043e-02,  1.86553709e-02,  2.14987732e-02,\n",
       "         -3.50319706e-02, -3.39485938e-03,  2.32975800e-02, -1.44304857e-02,\n",
       "         -1.50664030e-02, -7.52390455e-03,  5.52354800e-03, -3.27651501e-02,\n",
       "          1.63942762e-02, -4.61559519e-02,  1.79745387e-02,  1.42937619e-02,\n",
       "          8.75408202e-03, -2.58646812e-02,  2.17285752e-02, -9.98466741e-03,\n",
       "         -1.80371962e-02, -1.84741803e-02,  1.50869545e-02,  4.19685524e-03,\n",
       "         -1.55422166e-02,  9.16897226e-03,  2.66624652e-02,  3.96057516e-02,\n",
       "          7.45428354e-03, -1.78519692e-02, -3.32818250e-03,  4.53098007e-02,\n",
       "          1.47392806e-02, -1.48994923e-02,  2.18296563e-03,  8.14984366e-03,\n",
       "         -3.01583149e-02,  5.55281818e-04,  2.75131725e-02,  5.26402667e-02,\n",
       "          7.48200458e-04,  2.65616132e-03, -5.12428675e-03,  1.25382869e-02,\n",
       "          1.81965828e-02, -2.31078360e-02, -2.40490176e-02,  1.53713822e-02,\n",
       "          5.57611790e-03,  1.28581582e-04,  1.29393293e-02,  8.91187973e-03,\n",
       "         -3.60848382e-02, -1.37300212e-02, -2.89375428e-04, -3.52149233e-02,\n",
       "         -1.69561263e-02, -1.20804424e-03,  3.43021266e-02,  1.62384310e-03,\n",
       "         -4.73412359e-03,  4.13777605e-02, -8.31961259e-03,  6.62985304e-03,\n",
       "         -4.01839465e-02, -1.33232418e-02, -1.41857490e-02, -8.05053301e-03,\n",
       "          2.62124185e-02,  4.04615042e-04, -4.07987572e-02,  3.14725563e-02,\n",
       "         -2.05791518e-02, -8.06485955e-03,  1.01740658e-02,  4.96719498e-03,\n",
       "         -2.14821706e-03, -2.10113190e-02, -2.15427764e-02,  2.41542608e-03,\n",
       "         -2.38328357e-03,  1.54903554e-03,  1.42567698e-02, -4.90788445e-02,\n",
       "          1.76774152e-02,  4.80189128e-03,  1.80760119e-02,  9.71549656e-03,\n",
       "         -2.09735446e-02,  1.98913626e-02,  5.00962045e-03,  1.05088223e-02,\n",
       "         -1.04972310e-02, -2.59411093e-02,  3.45629156e-02, -1.14264516e-02,\n",
       "          3.69625464e-02,  2.50588115e-02,  4.49154116e-02,  2.15444081e-02,\n",
       "          1.64507963e-02, -2.10608467e-02, -2.35510051e-05, -2.94364034e-03,\n",
       "         -2.12642420e-02,  1.68662034e-02,  9.61671118e-03,  1.95493945e-03,\n",
       "         -9.74734139e-04,  1.48084862e-02, -1.97164249e-02,  5.64434528e-02,\n",
       "          2.25421619e-02,  2.90924851e-02, -2.33362075e-02, -6.77358219e-03,\n",
       "          1.18916724e-02, -5.12850173e-02,  8.86494177e-04,  4.13491540e-02,\n",
       "          2.18661278e-02,  7.70785194e-03,  1.91766606e-03, -1.82873867e-02,\n",
       "          2.12089848e-02, -1.50882807e-02,  1.70948021e-02,  1.69972219e-02,\n",
       "          1.32476445e-02, -2.65341140e-02, -5.20650335e-02, -3.65712456e-02,\n",
       "         -1.38125103e-03, -1.91311203e-02,  1.04409512e-02, -1.71632245e-02,\n",
       "          1.75678097e-02, -2.43959366e-03, -4.61083762e-02,  2.01194640e-02,\n",
       "         -3.59690264e-02, -2.26718467e-02, -2.08729748e-02,  1.17053743e-02,\n",
       "          6.33377675e-03, -1.08525744e-02,  2.09604092e-02,  2.49865856e-02,\n",
       "          1.78920222e-03, -6.92189485e-03, -1.93511136e-02, -1.73571371e-02,\n",
       "          1.98280439e-04,  7.08766747e-03, -8.75654537e-03, -1.84057094e-02,\n",
       "          3.14956233e-02, -2.61142161e-02,  3.11416741e-02,  1.37653844e-02,\n",
       "          2.44116485e-02, -7.00649898e-03,  2.73125824e-02, -1.90152396e-02,\n",
       "         -1.63419582e-02,  1.17365224e-02,  2.97153294e-02,  3.99958454e-02,\n",
       "         -2.49914285e-02, -1.83686800e-02,  1.55441854e-02,  1.79923214e-02,\n",
       "         -6.40243664e-03,  3.42671946e-03, -1.38360467e-02,  5.61759202e-03,\n",
       "          9.90218576e-03, -1.04162274e-02,  6.21502567e-03, -4.26209392e-03,\n",
       "          2.11051162e-02,  1.95323816e-03, -2.61273384e-02, -2.91032884e-02,\n",
       "         -2.12813355e-02, -3.21420725e-03,  1.10793738e-02, -3.97723392e-02,\n",
       "         -1.43612921e-02,  3.08918003e-02, -3.50265466e-02, -2.81689912e-02,\n",
       "         -2.60930024e-02, -5.24082780e-03, -2.13218220e-02, -6.57509733e-03,\n",
       "         -1.70543976e-02,  1.91308130e-02, -1.50345089e-02,  7.60549773e-03,\n",
       "          1.76531579e-02,  1.48159582e-02,  2.55596973e-02, -1.23660974e-02,\n",
       "          2.40771826e-02,  4.55829408e-03, -6.29950222e-03,  2.64228694e-02,\n",
       "         -3.27042304e-02,  7.71835167e-03, -1.83747225e-02, -3.07220332e-02,\n",
       "          2.37476490e-02, -1.21273252e-03,  4.17493619e-02, -1.75456721e-02,\n",
       "          5.84870297e-03, -4.57579829e-03, -2.51985304e-02, -1.18991099e-02,\n",
       "          1.68974865e-02,  5.99913485e-03, -2.00336846e-03,  2.75647826e-02,\n",
       "         -7.58790458e-03, -2.57397257e-03,  1.43305240e-02,  9.09277052e-03,\n",
       "          1.72312988e-03, -1.84848942e-02,  4.01921719e-02,  4.00957186e-03,\n",
       "          8.76896270e-03,  2.61137076e-02,  1.66166183e-02,  3.73451151e-02,\n",
       "          5.98783279e-03,  3.68708335e-02, -7.01634074e-03, -5.50770275e-02,\n",
       "          4.80909161e-02,  3.59548703e-02, -8.20999313e-03,  2.42026001e-02,\n",
       "          6.53049094e-04,  2.19643228e-02,  2.56933514e-02, -9.49321128e-03,\n",
       "         -7.40213180e-03,  4.56307316e-03,  9.33376886e-03,  2.10460965e-02,\n",
       "          1.41030941e-02,  1.80966109e-02,  4.16430160e-02,  1.43345054e-02,\n",
       "         -2.66388804e-03, -6.29000459e-03, -2.40108222e-02, -6.65545449e-05,\n",
       "          6.88910577e-03,  3.58321890e-03,  1.94180142e-02,  8.11792538e-03,\n",
       "          2.47333962e-02, -6.28202548e-03, -3.78831988e-03,  3.30405533e-02,\n",
       "          1.04032885e-02,  3.18681225e-02, -1.25928072e-03, -2.56154276e-02,\n",
       "          1.72779188e-02,  3.57828960e-02, -1.01989163e-02,  3.58623490e-02,\n",
       "          1.99346580e-02, -4.13328322e-04,  2.81431768e-02, -2.02789549e-02,\n",
       "         -2.35829819e-02, -3.51255871e-02,  1.91644114e-03,  1.32681783e-02,\n",
       "          2.52763331e-02, -2.99882190e-03,  4.37510088e-02, -1.07630370e-02,\n",
       "          2.81303730e-02,  2.93032043e-02, -5.85609004e-02,  2.31504999e-02,\n",
       "          2.27774400e-02,  4.11619730e-02, -7.67081324e-03, -4.35528979e-02,\n",
       "          2.89769284e-03,  1.27245309e-02,  4.94018048e-02, -1.30051989e-02,\n",
       "          1.17767556e-02,  4.17793766e-02,  1.68325640e-02,  3.53050232e-02,\n",
       "          2.69093513e-02,  6.66273152e-03, -3.86118293e-02,  1.74349826e-02,\n",
       "          6.19395543e-03, -8.84239934e-03,  1.38317104e-02,  1.29301948e-02,\n",
       "          2.83011608e-02, -6.78458298e-03, -7.71293556e-03, -5.71700651e-03,\n",
       "          9.21724923e-03, -5.10954075e-02, -4.14921762e-03, -1.21016968e-02,\n",
       "          3.08009125e-02,  4.39359760e-03,  2.52236519e-02, -1.11864209e-02,\n",
       "         -1.56025989e-02, -6.59188488e-03, -3.34155113e-02, -2.18964461e-02,\n",
       "          1.36746941e-02, -2.98427278e-03, -1.73525326e-02, -7.19213253e-03,\n",
       "          1.82004310e-02,  5.39000258e-02, -6.30118465e-03, -1.95315643e-03,\n",
       "          3.25281806e-02,  1.27884168e-02,  3.14298682e-02, -5.79845384e-02,\n",
       "         -2.11404301e-02, -1.39474021e-02,  1.61389448e-02,  2.67342068e-02,\n",
       "          2.14358103e-02, -1.20287603e-02, -1.82254240e-03, -2.88362615e-02,\n",
       "         -2.36641131e-02, -7.30478391e-03,  1.83923170e-02,  2.47733835e-02,\n",
       "          1.87999848e-02,  4.48116288e-03,  4.89696190e-02,  2.62031015e-02,\n",
       "         -5.51578626e-02, -3.96720804e-02,  1.55633641e-02, -4.60732635e-03,\n",
       "         -5.00139128e-03, -4.28036079e-02,  4.15929407e-03, -4.01844596e-03],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 5,\n",
       "  'topic_words': array(['urllib', 'github', 'javascript', 'browser', 'url', 'chrome',\n",
       "         '브라우저', 'khtml', 'firefox', 'html', 'createpage', 'dependencies',\n",
       "         'mozilla', 'dependency', 'cython', 'dataframe', 'bootstrap', '구글',\n",
       "         'linewidth', 'sklearn', '홈페이지', 'plugins', 'regex', 'webdriver',\n",
       "         'localhost', 'multiprocessing', 'matplotlib', 'pages', 'sites',\n",
       "         'google', 'tensorflow', 'python', 'webgl', '변수', 'css', 'crawler',\n",
       "         '파라미터', 'websites', 'xpath', 'dataset', 'bandwidth', 'links',\n",
       "         'queries', 'page', 'toolkit', 'selenium', 'correlations',\n",
       "         'dependence', 'parametric', '크롬'], dtype='<U15'),\n",
       "  'topic_vector': array([-4.35199700e-02,  1.85753815e-02, -1.45756761e-02,  9.52558499e-03,\n",
       "          1.63346354e-04, -5.64646088e-02,  2.12453734e-02, -4.58989013e-03,\n",
       "          5.15724942e-02,  2.85414141e-02,  2.21731719e-02,  2.57578325e-02,\n",
       "          3.58321071e-02,  1.23756249e-02,  7.85344746e-03,  9.66207124e-03,\n",
       "          5.07081719e-03, -3.05584003e-03,  2.36635283e-02,  4.35477681e-02,\n",
       "          2.26831008e-02,  3.18168737e-02,  7.89120980e-03,  3.82919796e-02,\n",
       "         -5.69321215e-02, -2.08658725e-02,  4.10167780e-03, -1.00208670e-02,\n",
       "         -5.90393990e-02, -4.73596975e-02, -3.02275773e-02,  9.53670591e-03,\n",
       "         -1.91610900e-03, -5.19614890e-02, -1.81802157e-02, -6.00415189e-03,\n",
       "          3.62674966e-02,  7.36966403e-03,  2.43091900e-02, -1.00929001e-02,\n",
       "         -2.35649999e-02, -1.12520810e-02, -1.71281472e-02, -2.40485985e-02,\n",
       "         -3.59229511e-03, -4.82558599e-03,  7.64076272e-03,  4.52760467e-03,\n",
       "         -5.77958534e-03, -7.07467273e-03, -2.43328568e-02,  6.01132913e-03,\n",
       "         -1.76098291e-02, -1.15543697e-02,  4.32507321e-03, -5.50454147e-02,\n",
       "          2.50228513e-02,  2.80266758e-02, -5.13970153e-04, -1.69759635e-02,\n",
       "          9.16900020e-03,  4.84573282e-02,  2.70337705e-02, -3.97726633e-02,\n",
       "         -1.83831528e-02,  1.93600859e-02,  1.39406351e-02, -2.82814000e-02,\n",
       "          2.21308302e-02, -1.74515173e-02, -3.26550566e-02, -2.17500934e-03,\n",
       "          8.72960873e-03, -3.08196358e-02, -1.92696031e-03,  1.86188810e-03,\n",
       "          1.84403434e-02,  3.11317258e-02,  2.86955144e-02, -5.98050170e-02,\n",
       "         -6.57198504e-02, -4.00822051e-02, -3.38202566e-02, -2.13327166e-02,\n",
       "          1.03848604e-02,  1.27567202e-02, -1.91063043e-02, -2.05929633e-02,\n",
       "         -2.80521694e-03,  5.09008253e-03, -3.51072056e-03, -6.68231025e-03,\n",
       "          2.29436792e-02, -1.32203000e-04,  2.98070032e-02,  6.65349886e-03,\n",
       "         -3.64057161e-02, -1.20276026e-02,  4.81564086e-03, -1.90792847e-02,\n",
       "          3.74360383e-02,  3.39713655e-02, -1.31941040e-03,  1.92317870e-02,\n",
       "          3.14234793e-02, -9.62395687e-03, -4.66895588e-02, -6.69137249e-03,\n",
       "          1.20559176e-02,  3.21730115e-02,  2.31898073e-02, -2.81904247e-02,\n",
       "          2.71341708e-02, -3.51137407e-02,  3.57051566e-02, -2.71783695e-02,\n",
       "         -5.69959357e-03, -1.39637515e-02,  1.39126834e-03,  7.56146107e-03,\n",
       "         -3.62356310e-03, -1.29146082e-02, -8.64217523e-03,  1.18712476e-02,\n",
       "          2.63339635e-02,  1.24755576e-02, -2.24739853e-02, -9.22939368e-03,\n",
       "          6.96905516e-03, -5.35366870e-03, -4.03097160e-02,  6.18495652e-03,\n",
       "          6.15332313e-02, -5.16142696e-03, -2.23486871e-02,  3.90241854e-02,\n",
       "          5.39728347e-03, -1.00332983e-02,  3.56000364e-02,  2.23925356e-02,\n",
       "          6.86218543e-03,  2.39527598e-02, -3.09356228e-02,  2.35321391e-02,\n",
       "          1.36630610e-02, -6.69508227e-05, -1.80236828e-02,  2.16952972e-02,\n",
       "          1.47736846e-02,  1.52223436e-02,  1.37334391e-02,  1.92766022e-02,\n",
       "         -3.41356779e-03, -3.53431329e-02,  1.09051596e-02, -8.98707192e-03,\n",
       "         -1.45102069e-02,  9.33670253e-03,  5.80877671e-03, -1.19892962e-03,\n",
       "          4.48880345e-02, -2.44763941e-02,  4.29611877e-02,  6.90681554e-05,\n",
       "          3.51876318e-02, -2.69867368e-02,  1.71887279e-02,  1.15395831e-02,\n",
       "         -3.40201752e-03,  2.65142135e-03,  2.35320926e-02, -1.82863399e-02,\n",
       "         -1.17770908e-02,  5.30393980e-03, -9.99556202e-03,  2.75358967e-02,\n",
       "         -5.03614917e-02,  5.39434899e-04, -4.49719131e-02,  4.64267135e-02,\n",
       "          2.56224512e-03,  1.43547812e-02, -1.57933426e-03,  4.67408635e-03,\n",
       "         -2.27108952e-02,  7.55658653e-03,  2.84446236e-02,  4.43112552e-02,\n",
       "          4.58684843e-03,  1.03072030e-02,  1.21933250e-02, -3.18658650e-02,\n",
       "          3.92755754e-02,  2.27310578e-03, -2.34931428e-02,  3.55851534e-03,\n",
       "          5.09829186e-02, -2.14250125e-02,  1.93954427e-02,  9.97783709e-03,\n",
       "          1.85329858e-02, -1.03840129e-02,  3.37429112e-03, -2.89341770e-02,\n",
       "         -6.70939079e-03, -3.14883478e-02,  3.95161696e-02, -1.58997625e-02,\n",
       "          1.01775397e-03,  1.87629927e-02, -2.15558037e-02,  1.43111078e-02,\n",
       "          1.02196932e-02,  8.88485834e-03,  3.23049463e-02, -8.98960605e-03,\n",
       "         -2.22849008e-02, -2.36082859e-02, -1.05095468e-02,  1.30933793e-02,\n",
       "         -1.60990804e-02,  1.08674844e-03,  2.89628506e-02, -6.67276746e-03,\n",
       "         -5.57123162e-02, -1.34558864e-02, -2.59913858e-02, -2.42734817e-03,\n",
       "          1.71852764e-02, -6.43032650e-03, -3.06075625e-02,  4.27649245e-02,\n",
       "          2.71710884e-02, -3.50551866e-03,  1.45538058e-03,  2.85090674e-02,\n",
       "          1.85825285e-02, -2.27291649e-03,  4.40034308e-02, -2.57424582e-02,\n",
       "         -2.27530356e-02,  3.13842483e-03,  3.01748514e-03,  1.53089743e-02,\n",
       "         -3.92101705e-04, -5.42563684e-02,  2.20137518e-02,  4.41834331e-03,\n",
       "         -2.25803368e-02,  1.88573916e-02, -1.98089164e-02, -2.74221245e-02,\n",
       "         -2.39541586e-02, -3.34290564e-02,  3.48933600e-02, -3.50559466e-02,\n",
       "          1.30624825e-03,  5.12346774e-02, -1.04860198e-02,  1.71409585e-02,\n",
       "         -1.07702222e-02,  3.23210992e-02, -2.85216793e-02, -4.66225259e-02,\n",
       "         -4.04913351e-03, -2.42776610e-02, -3.51594202e-02,  4.58774669e-03,\n",
       "         -6.92430465e-03,  3.29917371e-02, -1.35150915e-02, -1.61550306e-02,\n",
       "         -2.86363903e-02,  3.43649052e-02,  3.37031297e-02, -7.73559837e-03,\n",
       "          4.58213082e-03,  9.61522479e-03, -3.44691724e-02, -1.96735747e-02,\n",
       "         -9.15307552e-03,  2.13187877e-02,  1.82897598e-02, -2.53667142e-02,\n",
       "          4.75646048e-05, -2.53219306e-02, -3.86087596e-02, -1.31439222e-02,\n",
       "         -1.68705285e-02,  6.91689318e-03,  2.51650228e-04,  2.33090036e-02,\n",
       "         -1.56631246e-02,  5.28142452e-02, -6.08318597e-02,  9.52090975e-03,\n",
       "         -5.20266183e-02,  5.00105545e-02, -2.42988952e-03,  4.32239845e-02,\n",
       "          3.67754302e-03,  1.12542892e-02, -1.46703897e-02, -1.12625575e-02,\n",
       "         -7.48356571e-03,  5.12000453e-03,  1.95702352e-02,  1.89293769e-06,\n",
       "         -4.20536473e-03,  2.33379696e-02,  4.63705882e-02, -1.80078857e-02,\n",
       "         -1.47137670e-02, -3.14329029e-03, -1.21472515e-02,  3.42413262e-02,\n",
       "          1.60522815e-02,  3.69202928e-03,  1.53535306e-02,  9.79243778e-03,\n",
       "          2.28229910e-02, -6.07967377e-03, -1.37504656e-02, -7.96071533e-03,\n",
       "         -9.81737580e-03, -2.42686737e-02,  3.71415867e-03, -2.84851473e-02,\n",
       "          2.10962240e-02, -2.56099626e-02, -2.37820316e-02, -2.33465638e-02,\n",
       "         -1.03471186e-02, -1.83845405e-02,  3.56858559e-02,  1.35661019e-02,\n",
       "          1.72079504e-02,  7.95652717e-03, -5.73651344e-02, -2.67059840e-02,\n",
       "          6.02497207e-03,  1.99739970e-02, -1.80919692e-02, -2.25629583e-02,\n",
       "         -1.84071083e-02,  2.05382854e-02,  1.53812859e-02,  1.16344811e-02,\n",
       "         -7.74052972e-03, -5.08976588e-03, -3.53926718e-02,  6.16106857e-03,\n",
       "          1.63039658e-03, -5.43266675e-03, -2.00304408e-02, -7.82519113e-03,\n",
       "         -2.81298030e-02,  1.44704171e-02, -4.40879376e-04, -3.32927443e-02,\n",
       "         -4.35818359e-03, -2.81044934e-02,  1.71387047e-02, -2.63576545e-02,\n",
       "          1.71149317e-02, -1.54849915e-02,  8.24890006e-03,  1.07565168e-02,\n",
       "         -3.93863358e-02, -1.61004849e-02, -1.25355832e-02,  3.05857020e-03,\n",
       "         -1.27551910e-02,  4.94920043e-03,  9.28238500e-03, -3.90846431e-02,\n",
       "         -1.52463885e-02, -7.97111262e-03, -8.54678173e-03, -1.57004949e-02,\n",
       "         -2.83173565e-02, -1.75768398e-02, -6.86223246e-03,  2.13036630e-02,\n",
       "          4.16478002e-03,  3.13023031e-02,  2.36145277e-02, -5.22744097e-02,\n",
       "          1.31537179e-02,  2.13329066e-02,  2.32587401e-02, -2.74184104e-02,\n",
       "         -1.87111069e-02,  1.11924587e-02,  1.67781133e-02, -3.97863016e-02,\n",
       "          2.37989780e-02,  1.71830263e-02,  1.01851579e-02,  5.57950279e-03,\n",
       "          2.07995772e-02,  1.06370160e-02,  5.67267686e-02, -1.28954006e-02,\n",
       "          1.23107983e-02, -1.04051745e-02, -9.57480352e-03,  3.29402764e-03,\n",
       "          1.49320131e-02, -1.94331538e-02, -1.70940142e-02,  2.90490733e-03,\n",
       "          2.25101318e-02,  5.06259094e-04, -1.68090768e-03,  1.15657761e-03,\n",
       "          3.54092941e-02, -3.79577763e-02, -7.96001591e-03, -3.44103798e-02,\n",
       "          2.25623604e-02,  1.24284215e-02,  5.23842033e-03,  2.05366556e-02,\n",
       "         -1.14462091e-04,  2.37436146e-02,  1.86204165e-02, -4.19432996e-04,\n",
       "          7.58053735e-03, -4.81928661e-02,  1.06562451e-02,  1.87273752e-02,\n",
       "          1.88840963e-02,  1.91520005e-02,  1.93824414e-02,  4.49600555e-02,\n",
       "         -2.24754717e-02, -1.59970913e-02, -4.02346738e-02,  8.21442250e-03,\n",
       "         -1.88069884e-02,  6.68240525e-03,  9.00235027e-04, -5.02877645e-02,\n",
       "         -1.52248256e-02, -1.98740941e-02,  5.50809279e-02, -2.71019582e-02,\n",
       "          6.78675435e-03,  2.63267439e-02,  2.47798339e-02,  2.79650632e-02,\n",
       "         -5.94771840e-02, -9.64868814e-03, -1.60568487e-02, -1.46258147e-02,\n",
       "          2.30128821e-02, -3.64697762e-02, -3.95027595e-03,  4.04122546e-02,\n",
       "         -5.60150202e-03, -3.48303111e-05, -1.43205803e-02, -3.09780277e-02,\n",
       "          2.79993310e-05, -3.28027010e-02, -1.91119115e-03, -1.92941178e-03,\n",
       "          5.73479310e-02,  3.97705007e-03,  4.49231640e-02, -5.40855853e-03,\n",
       "          3.70289572e-02,  1.59757340e-03, -2.45996229e-02, -3.18895541e-02,\n",
       "          2.29057353e-02,  2.23686155e-02, -1.06151411e-02,  1.71306133e-02,\n",
       "          3.76957096e-02,  3.42499763e-02, -1.59796607e-02,  7.56264292e-03,\n",
       "         -4.92117414e-03,  1.84056181e-02, -1.89239401e-02, -5.86249940e-02,\n",
       "          2.59382501e-02,  1.90183835e-03, -1.75122567e-03,  1.85161065e-02,\n",
       "          2.42986232e-02, -4.17169603e-03,  4.55639325e-03, -1.83479711e-02,\n",
       "         -4.68880520e-04, -3.33248377e-02,  3.00934687e-02,  1.53846005e-02,\n",
       "         -7.49607058e-03, -7.19790487e-03,  3.48292924e-02,  2.20261477e-02,\n",
       "         -3.18588205e-02, -5.06438091e-02, -2.90042758e-02, -1.90727529e-03,\n",
       "         -2.58920360e-02,  4.22401493e-03,  3.08315288e-02,  2.10642647e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 6,\n",
       "  'topic_words': array(['ubuntu', 'xorg', '커널', 'linux', '우분투', 'nvidia', 'kernel', 'sudo',\n",
       "         'bashrc', 'gedit', 'stdout', 'gpu', '부팅', 'tensorflow', 'github',\n",
       "         'config', 'matplotlib', 'gnome', 'unix', 'cpu', 'glm',\n",
       "         'subprocess', 'localhost', 'canonical', 'gtx', 'synaptic',\n",
       "         'lightdm', 'terminal', 'grep', 'partition', 'boot', 'grub',\n",
       "         'command', 'openmx', 'install', 'bash', 'gcc', 'firefox', '명령',\n",
       "         'ssd', 'commands', 'plugins', 'installed', 'sli', 'vertexcount',\n",
       "         'cbind', '윈도우', 'bootstrap', 'vtk', 'compile'], dtype='<U15'),\n",
       "  'topic_vector': array([-4.94654700e-02,  2.21844739e-03, -4.77534859e-03,  2.80643199e-02,\n",
       "         -3.73940635e-03, -5.92458993e-02,  1.35451946e-02,  1.96297523e-02,\n",
       "          3.92349474e-02, -2.98627261e-02,  1.81507412e-02, -2.44773291e-02,\n",
       "          4.28460166e-02,  7.48153403e-03, -3.21433181e-03, -3.73758073e-03,\n",
       "          2.22136988e-03,  5.80502488e-03,  3.07712741e-02,  4.94051874e-02,\n",
       "          3.06507200e-02,  3.21164802e-02,  7.05434475e-03,  3.74128520e-02,\n",
       "         -5.24455868e-02, -3.47141325e-02,  2.38683615e-02, -1.94344148e-02,\n",
       "          3.08752600e-02, -5.19228280e-02, -1.14240302e-02,  1.83440465e-02,\n",
       "         -1.03429034e-02, -5.47538996e-02, -2.26497520e-02,  1.45172412e-02,\n",
       "          1.94248743e-02, -1.74652692e-02,  4.84615192e-02,  1.60323922e-02,\n",
       "         -1.44726383e-02,  3.69261354e-02,  2.10803654e-02, -1.10813358e-03,\n",
       "          2.67880838e-02, -1.91165376e-02,  4.60558496e-02, -2.12252084e-02,\n",
       "         -5.12735732e-02, -1.40903704e-02, -1.61029771e-02, -1.28247067e-02,\n",
       "          4.52896543e-02, -1.61427502e-02,  1.31105352e-02, -5.02928570e-02,\n",
       "         -1.28303478e-02,  4.72816117e-02, -2.53670383e-03,  2.78312210e-02,\n",
       "          2.27997098e-02,  5.00562899e-02,  2.75185294e-02, -4.88913320e-02,\n",
       "         -1.27788102e-02, -1.71145052e-02,  6.24374952e-03, -2.67651044e-02,\n",
       "          4.91243973e-02,  4.61652409e-03, -2.06021965e-02,  2.11644899e-02,\n",
       "          2.59456858e-02,  9.18513257e-03, -4.49441262e-02,  1.98685583e-02,\n",
       "         -3.26033011e-02, -3.60863395e-02, -2.60524619e-02, -5.71280234e-02,\n",
       "         -5.91849014e-02, -6.30435999e-04, -3.57857198e-02, -3.85851935e-02,\n",
       "          2.01101284e-02,  1.69151910e-02, -5.02270972e-03, -2.55423374e-02,\n",
       "          3.29566486e-02, -1.80259328e-02, -1.87680672e-03, -1.11834472e-02,\n",
       "          5.40499296e-03,  9.23094433e-03,  5.31256273e-02, -9.45400819e-03,\n",
       "         -5.16895391e-02,  1.80025585e-02,  2.94164922e-02,  2.96961959e-03,\n",
       "          2.51083523e-02, -5.97148435e-03, -3.95985320e-03,  1.95682701e-02,\n",
       "          1.46863693e-02, -1.15234535e-02, -3.42326611e-02, -2.78554149e-02,\n",
       "          3.24107073e-02,  2.22647637e-02, -5.73033700e-03, -4.79259677e-02,\n",
       "          1.11159170e-03, -1.29987132e-02,  3.34237032e-02,  2.28034123e-03,\n",
       "          3.93307069e-03,  1.51241450e-02, -2.18323618e-02,  1.86692979e-02,\n",
       "         -1.29225580e-02, -5.51346922e-03, -9.55084246e-03, -1.45173899e-03,\n",
       "         -1.52806817e-02,  3.60578410e-02, -2.26903316e-02,  3.06774192e-02,\n",
       "          2.27984339e-02, -1.85521785e-02, -3.17342468e-02,  6.48333132e-03,\n",
       "          5.35713732e-02,  1.65695492e-02,  1.67048350e-02,  2.52753552e-02,\n",
       "          4.62032072e-02,  3.09891882e-03,  4.46637049e-02,  1.17052319e-02,\n",
       "          2.52742302e-02, -1.33007327e-02,  1.83800217e-02,  3.83661687e-02,\n",
       "         -1.02906059e-02, -2.39152499e-02,  1.76537316e-02,  3.96841541e-02,\n",
       "          2.35890988e-02, -6.38967686e-05,  2.55002659e-02, -7.92855490e-03,\n",
       "         -3.22416984e-02, -2.47582458e-02,  3.58772511e-03,  8.43276363e-03,\n",
       "         -7.96794146e-03,  3.83473225e-02,  1.66828763e-02, -4.83136624e-02,\n",
       "          3.64602394e-02,  1.67194176e-02,  4.48490866e-02, -1.59352422e-02,\n",
       "         -3.16984457e-04, -2.71180402e-02, -2.40966026e-02, -1.92381442e-02,\n",
       "          2.35530268e-02,  1.16969720e-02,  2.22553033e-02, -2.68388521e-02,\n",
       "         -3.87680046e-02, -1.02290669e-02, -1.00789440e-03,  4.21233065e-02,\n",
       "         -5.26273400e-02, -4.12388146e-02, -3.57440189e-02,  4.34337072e-02,\n",
       "          5.71947545e-03,  2.45778002e-02, -1.97407100e-02, -2.19089221e-02,\n",
       "         -4.09552157e-02, -2.80963909e-03,  2.07560118e-02,  5.32016456e-02,\n",
       "          2.00263076e-02,  5.59226386e-02,  4.54933848e-03, -3.82540338e-02,\n",
       "          3.22117992e-02, -9.34176240e-03, -3.97969708e-02,  2.74727494e-02,\n",
       "         -3.17419879e-02, -5.12318080e-03,  4.56999103e-03, -1.20106172e-02,\n",
       "         -1.13222422e-02, -2.37283148e-02, -8.51577427e-03, -1.08319297e-02,\n",
       "         -1.16977450e-02, -9.68800392e-03,  2.72982270e-02,  2.40278561e-02,\n",
       "         -1.14474474e-02,  2.83761434e-02,  3.77298729e-03,  3.34522761e-02,\n",
       "          4.04953547e-02,  1.46538907e-04,  5.62421372e-03,  1.00586619e-02,\n",
       "          8.16267543e-03,  6.14028424e-04, -1.70003939e-02,  2.46650018e-02,\n",
       "         -1.12420693e-02,  2.80959550e-02,  6.95569208e-03,  1.68513390e-03,\n",
       "         -5.75070009e-02, -3.16275563e-03, -3.20209265e-02,  8.40664376e-03,\n",
       "          1.35548599e-02, -2.99865846e-02, -2.73665842e-02,  5.02475165e-02,\n",
       "          2.85692178e-02,  3.32789943e-02,  1.52693922e-02,  5.16464002e-02,\n",
       "         -3.75125036e-02,  2.29555257e-02,  3.04827187e-03, -2.12092139e-03,\n",
       "          5.99977095e-03, -2.44101835e-03,  1.93067398e-02,  2.08703000e-02,\n",
       "          9.72805172e-03, -6.29917625e-03,  1.27080455e-02, -2.71487590e-02,\n",
       "          4.16426174e-02,  2.23283675e-02, -2.87894476e-02,  2.75519444e-03,\n",
       "         -1.93919870e-03,  1.37007628e-02,  4.76090529e-04, -2.50023436e-02,\n",
       "         -4.07011621e-03, -4.31597009e-02, -1.60129387e-02, -8.54319427e-03,\n",
       "          2.02819128e-02,  3.42879966e-02, -1.67463049e-02,  1.81525908e-02,\n",
       "          3.29173394e-02, -4.48181070e-02,  1.03956535e-02,  4.61852783e-03,\n",
       "          8.25791899e-03,  1.11227864e-02,  4.60632751e-03, -1.21113453e-02,\n",
       "         -1.30717363e-02,  3.40517908e-02,  7.30107166e-03, -2.81913318e-02,\n",
       "          1.62706207e-02, -1.65210031e-02, -3.20252962e-02,  2.99138147e-02,\n",
       "          2.18018945e-02,  2.66217459e-02, -1.67091805e-02, -1.54845593e-02,\n",
       "         -4.99144290e-03,  2.87583191e-02, -4.92596850e-02,  2.90753483e-03,\n",
       "         -2.72359978e-03, -2.54127383e-02, -7.17469782e-04,  8.57866555e-03,\n",
       "         -1.21435048e-02,  1.68556515e-02, -5.88537455e-02,  1.37378294e-02,\n",
       "         -3.63923162e-02,  8.45179614e-03, -1.03460927e-03, -4.19948436e-03,\n",
       "          8.82743672e-03, -9.47596505e-03, -2.27997247e-02, -2.76087299e-02,\n",
       "          8.39850120e-03,  1.64816007e-02, -2.45142821e-02, -2.19920035e-02,\n",
       "          2.16816105e-02,  1.42985703e-02,  2.11358275e-02, -5.89391077e-03,\n",
       "         -2.52285693e-02,  1.86380222e-02, -6.39407802e-03,  2.86417101e-02,\n",
       "          3.79842892e-02, -2.90392395e-02, -6.84514816e-04, -2.07138956e-02,\n",
       "         -1.19101733e-03,  2.05106847e-02,  1.72855472e-03,  2.46246755e-02,\n",
       "          3.21171209e-02,  1.95980184e-02, -4.19739187e-02, -2.95447297e-02,\n",
       "          5.36294794e-03, -1.55432476e-02, -2.91801281e-02, -3.42197791e-02,\n",
       "         -3.57562676e-02,  1.20934164e-02, -8.35120853e-04,  2.94161290e-02,\n",
       "          2.71865316e-02,  4.32208093e-04, -5.55387102e-02, -7.16827484e-03,\n",
       "         -1.31289456e-02,  4.46054451e-02, -4.29437449e-03, -2.13174503e-02,\n",
       "          2.53767148e-02, -1.83535216e-03, -4.84049233e-04,  1.36783672e-02,\n",
       "         -2.43243519e-02,  1.66954251e-03,  2.27806661e-02, -5.41006215e-03,\n",
       "          5.14191249e-03, -4.79219258e-02,  3.42296101e-02, -8.45542829e-03,\n",
       "         -1.64972115e-02,  2.64075361e-02, -8.24397150e-03, -4.06798199e-02,\n",
       "         -4.82531218e-03,  2.10000556e-02,  4.17247377e-02,  7.88234267e-03,\n",
       "          2.82132495e-02, -3.36099528e-02, -4.97899204e-03,  1.32050700e-02,\n",
       "         -3.83913405e-02,  2.50867903e-02,  3.75073589e-03,  3.28248069e-02,\n",
       "          1.34322317e-02, -1.35198440e-02,  9.21601430e-04, -2.60625668e-02,\n",
       "         -1.08380672e-02,  3.04952171e-02,  4.99917343e-02, -6.20278344e-03,\n",
       "         -1.89990979e-02, -4.60907407e-02, -3.04936984e-04, -5.35351411e-02,\n",
       "          6.20110380e-03,  3.93019691e-02, -1.55762164e-02, -5.45894355e-02,\n",
       "         -8.32311530e-03,  9.49797407e-03, -2.44643912e-02, -2.74912305e-02,\n",
       "          2.91602705e-02, -8.12955201e-04, -2.94602234e-02,  5.15122246e-03,\n",
       "          1.05910040e-02,  3.43413763e-02,  3.04155108e-02,  2.50541642e-02,\n",
       "          3.15602571e-02, -1.34166777e-02,  4.79016006e-02,  1.51258335e-02,\n",
       "          1.03325834e-02,  8.18571635e-03,  8.64101201e-03, -3.23188268e-02,\n",
       "          2.99618971e-02,  3.15276347e-02, -1.97968911e-02,  2.87946686e-02,\n",
       "          1.69344270e-03,  1.20276744e-02,  1.53076625e-03,  5.11228293e-03,\n",
       "          1.82612520e-02,  4.42562401e-02, -1.67664979e-02, -2.04093028e-02,\n",
       "          4.33149487e-02,  4.42323182e-03,  4.44619358e-02,  2.24911422e-02,\n",
       "         -8.88189580e-03,  2.10914649e-02,  3.08322813e-02, -3.12403794e-02,\n",
       "          1.68364272e-02, -1.44559462e-02,  3.38191204e-02,  1.89502537e-02,\n",
       "          1.76735278e-02,  2.55130026e-02,  1.34257255e-02, -1.05158472e-03,\n",
       "         -5.16822154e-04,  2.54191458e-02, -4.79288809e-02,  2.15825960e-02,\n",
       "         -4.74494547e-02, -6.91206427e-03, -7.95794837e-03, -3.62103693e-02,\n",
       "         -1.85377039e-02,  3.90867097e-03,  4.63306233e-02,  1.77667923e-02,\n",
       "          4.63035703e-02,  1.24536827e-02,  3.41727026e-02,  4.46837358e-02,\n",
       "         -5.10443784e-02, -1.66753586e-02, -2.53407527e-02, -2.25699972e-02,\n",
       "          4.14712131e-02, -1.65822788e-03,  1.69924516e-02,  4.43637818e-02,\n",
       "          1.13636488e-02, -1.69866940e-03,  3.63427885e-02,  3.64982188e-02,\n",
       "          2.25272980e-02, -4.87449057e-02,  1.59069691e-02,  4.56571616e-02,\n",
       "          4.76904847e-02, -3.63313593e-02,  4.41257060e-02, -4.53463085e-02,\n",
       "          1.97049943e-04,  1.10987609e-03, -4.13209163e-02,  3.28066712e-03,\n",
       "         -5.62510965e-03, -2.13934574e-02,  4.65908786e-03,  3.05977650e-03,\n",
       "         -4.49175341e-03,  1.10986717e-02, -1.63640846e-02,  3.72078473e-04,\n",
       "          5.23715792e-03,  4.64108726e-03,  1.58421416e-02, -5.55882081e-02,\n",
       "         -8.46027571e-04, -3.19508873e-02,  2.29909178e-02,  2.59887539e-02,\n",
       "         -1.97778083e-03, -1.69863924e-02,  1.20620327e-02, -1.76450498e-02,\n",
       "         -4.57618088e-02, -2.26856209e-03,  8.40749312e-03,  3.16198021e-02,\n",
       "          2.57815584e-03,  5.33840582e-02,  3.21315043e-02,  1.39814038e-02,\n",
       "         -1.11858184e-02, -5.64208664e-02, -1.05277002e-02,  1.30534945e-02,\n",
       "          1.40670491e-02, -3.33615426e-05, -8.93091131e-03,  2.34235711e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 7,\n",
       "  'topic_words': array(['python', 'cython', '파이썬', 'subprocess', 'multiprocessing',\n",
       "         'matplotlib', 'numpy', 'stdout', '함수', 'tensorflow', '컴파일러',\n",
       "         'github', 'compiler', '컴파일', 'kwargs', '프로그래밍', 'compile',\n",
       "         'function', 'varlambda', '변수', 'scipy', 'gcc', '코딩', 'functions',\n",
       "         'args', 'regex', 'bashrc', 'sklearn', 'filename', 'dataframe',\n",
       "         '잠재변수', '스크립트', 'dict', 'syntax', 'programming', 'integer',\n",
       "         'lineplot', 'encoding', 'urllib', 'preprocessing', 'unicode',\n",
       "         'coded', '파라미터', 'tuple', 'algorithmic', 'commands',\n",
       "         'filenametype', 'javascript', 'integers', 'ubuntu'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.76564185e-02, -1.00130187e-02, -2.85153612e-02,  6.31983997e-03,\n",
       "          3.17115709e-03, -6.03179410e-02, -1.27726449e-02,  2.00501513e-02,\n",
       "          5.72545491e-02, -1.74956471e-02,  1.09853595e-02,  2.76652146e-02,\n",
       "          4.73821051e-02,  1.62524004e-02, -4.52046059e-02, -9.57503729e-03,\n",
       "          2.51631048e-02, -4.59019653e-03,  3.27884406e-02,  3.46023254e-02,\n",
       "          2.75255665e-02, -1.86236633e-04,  6.86376495e-03,  4.33323272e-02,\n",
       "         -5.82883954e-02, -4.07716259e-02, -3.54241556e-03, -1.31678872e-03,\n",
       "          3.86712700e-02, -4.41077463e-02, -1.39634358e-02,  3.33581865e-02,\n",
       "          4.10902692e-04, -5.76355122e-02, -1.71141617e-03, -7.37638838e-05,\n",
       "         -2.45030504e-02, -8.53510294e-03,  1.51279289e-02, -7.35251419e-03,\n",
       "         -1.08265541e-02, -2.49375887e-02,  7.87088182e-03,  9.73743759e-03,\n",
       "         -1.82726942e-02,  2.20612786e-03,  4.79007103e-02, -1.39859244e-02,\n",
       "         -2.38132086e-02,  1.69228408e-02, -1.60427336e-02, -2.86565255e-02,\n",
       "         -2.94034537e-02, -1.55117130e-02,  1.50142433e-02, -5.00951819e-02,\n",
       "          9.46567301e-03,  4.83987555e-02,  4.87181023e-02,  1.93425943e-03,\n",
       "          7.42917461e-03,  2.90031321e-02, -8.81038047e-03, -3.56200598e-02,\n",
       "         -1.23164523e-02, -5.69561543e-03, -3.06285219e-03, -1.75147243e-02,\n",
       "          4.11402099e-02, -2.66013034e-02, -3.80705371e-02,  7.56244687e-03,\n",
       "         -8.80195294e-03, -2.96678431e-02, -1.42298089e-02, -2.75520459e-02,\n",
       "         -1.72816124e-02, -1.23898755e-03,  4.32406217e-02, -6.03070855e-02,\n",
       "         -6.06637374e-02,  6.22597570e-03, -4.37185541e-03, -5.14381006e-03,\n",
       "          2.94794776e-02,  3.26624699e-03,  6.93278154e-03, -1.49661945e-02,\n",
       "          1.25560481e-02,  1.93936564e-02, -1.22471973e-02, -2.02506743e-02,\n",
       "          1.51411342e-02, -7.57295173e-03,  3.78135853e-02,  2.49376446e-02,\n",
       "         -5.38276210e-02,  3.97699773e-02,  3.76098901e-02, -5.36916731e-03,\n",
       "          1.47066992e-02,  8.32911115e-03, -2.01735571e-02,  1.16453143e-02,\n",
       "          3.70282121e-02,  1.91184804e-02, -1.35264015e-02, -2.09120717e-02,\n",
       "          1.54656195e-03,  2.76543815e-02,  1.56603195e-02, -3.55320349e-02,\n",
       "          1.16432952e-02, -3.97117510e-02,  3.46476510e-02, -1.54645592e-02,\n",
       "         -3.45849954e-02, -1.86791029e-02, -7.62725528e-03,  1.94171816e-02,\n",
       "         -3.95904966e-02,  7.44076353e-03, -4.12427541e-03,  3.25128473e-02,\n",
       "          3.29516195e-02,  4.49534878e-03, -1.84406452e-02,  2.46939994e-02,\n",
       "         -5.88225527e-03,  1.21218795e-02, -3.56765650e-02,  1.85652804e-02,\n",
       "          5.84752150e-02,  2.25753114e-02, -3.71778160e-02,  2.18620002e-02,\n",
       "          1.46121699e-02,  4.44382383e-03,  3.10184192e-02,  2.70266104e-02,\n",
       "          6.78989757e-03,  2.74102017e-03,  1.47336628e-02,  2.24333405e-02,\n",
       "          1.16177443e-02,  2.54802452e-03, -3.63717079e-02,  4.32378985e-02,\n",
       "          1.90326646e-02, -5.29927108e-03,  3.44639532e-02,  2.72428356e-02,\n",
       "         -2.47476250e-02, -1.55710923e-02, -2.47718338e-02, -1.74972266e-02,\n",
       "         -2.15034187e-02,  9.83540434e-03, -2.06327066e-02, -4.42564487e-06,\n",
       "          2.27811635e-02,  1.31829781e-02,  4.21046987e-02,  2.63243401e-03,\n",
       "          1.68824233e-02, -6.01687119e-04,  4.87489020e-03,  1.14060929e-02,\n",
       "         -3.49135743e-03,  2.19083168e-02,  3.45900431e-02, -1.48733452e-04,\n",
       "          1.69113949e-02,  2.48562768e-02, -1.61419213e-02,  3.54057364e-02,\n",
       "         -3.97903398e-02, -1.10566965e-03, -5.25251627e-02,  4.26480547e-02,\n",
       "          1.76231435e-03,  4.27515917e-02,  6.11323863e-03, -6.67617517e-03,\n",
       "         -2.59163044e-02,  4.19754302e-03,  9.69265960e-03,  4.63580303e-02,\n",
       "          2.95920926e-03, -2.00166577e-03,  5.42860571e-03, -2.35048104e-02,\n",
       "          4.31879871e-02,  2.69966549e-03, -3.05341668e-02,  1.85654461e-02,\n",
       "         -1.61378179e-02, -1.56237576e-02,  1.70786530e-02, -1.33397523e-03,\n",
       "          2.73089614e-02,  2.09968705e-02, -1.86148584e-02, -3.19842505e-03,\n",
       "         -1.73833575e-02,  5.77753410e-03,  3.78659852e-02, -3.71474139e-02,\n",
       "          1.58742294e-02,  2.01872084e-02, -1.71008147e-02,  4.10136804e-02,\n",
       "          1.00092553e-02, -2.07947940e-02,  2.29190681e-02, -7.37035694e-03,\n",
       "         -1.28226094e-02, -2.55707875e-02,  4.80986666e-04, -6.61125919e-03,\n",
       "         -5.54250367e-03,  3.28255421e-03,  2.37881877e-02,  4.55141308e-05,\n",
       "         -5.88770173e-02, -1.85715277e-02, -6.08640350e-03,  1.24921957e-02,\n",
       "          8.79591389e-04,  1.46052390e-02,  4.81624901e-03,  5.79472221e-02,\n",
       "          1.95295457e-02, -1.63993761e-02,  5.99633763e-03,  4.45365673e-03,\n",
       "         -3.61605693e-04,  1.41457533e-02, -3.80865997e-03, -1.76371895e-02,\n",
       "          1.31391501e-02,  1.49116730e-02, -3.51243606e-03,  1.25730997e-02,\n",
       "          9.88634583e-03, -5.76113388e-02,  4.34884848e-03,  1.48602882e-02,\n",
       "          4.99191275e-03, -5.62582072e-03, -2.67570000e-02, -2.90784631e-02,\n",
       "         -1.34216622e-02,  8.89778603e-03,  4.10348177e-02, -1.48357330e-02,\n",
       "          1.37661416e-02, -4.01765630e-02,  2.02811090e-03, -1.75883379e-02,\n",
       "          2.28960626e-02,  2.69422513e-02, -2.61957329e-02, -2.78441645e-02,\n",
       "          2.89884787e-02, -5.11543639e-02, -2.56766193e-02,  1.24273514e-02,\n",
       "          2.94529572e-02,  2.69577261e-02,  1.45649267e-02, -4.19554822e-02,\n",
       "         -1.02074938e-02,  2.02964228e-02,  7.59382872e-03,  3.70185310e-03,\n",
       "         -1.13512306e-02, -2.70795599e-02, -3.48051339e-02, -9.32175573e-03,\n",
       "          1.34545437e-03,  1.87417474e-02, -6.92537799e-03,  4.64291405e-03,\n",
       "         -3.26464698e-02,  1.74367763e-02, -3.44539061e-02, -4.07434488e-03,\n",
       "          1.99929532e-02,  1.59278959e-02, -1.28367904e-03,  2.91629788e-02,\n",
       "          1.40297739e-02,  4.66137007e-02, -6.07961528e-02,  2.45655365e-02,\n",
       "         -2.21608914e-02,  3.87132689e-02, -2.01745727e-03,  4.35716100e-02,\n",
       "          9.60267964e-04, -2.31752768e-02, -3.00709158e-02, -4.22905646e-02,\n",
       "          1.21594323e-02, -1.52191345e-03, -2.49515940e-02, -1.20046716e-02,\n",
       "         -3.14279534e-02,  1.39934784e-02,  3.69626656e-02,  2.45667733e-02,\n",
       "         -7.78277451e-03,  3.31371161e-03, -1.88996084e-02,  1.10764215e-02,\n",
       "          1.60065349e-02, -9.66277812e-03,  8.68942589e-03, -1.59847122e-02,\n",
       "         -2.32969318e-02,  2.46904884e-03,  5.73068950e-03, -6.97273016e-03,\n",
       "         -1.79130547e-02, -3.98114603e-03, -4.22731861e-02, -3.07623185e-02,\n",
       "          3.95709090e-02, -1.14180101e-02, -2.28862297e-02, -3.27124111e-02,\n",
       "         -4.60243486e-02, -9.96093359e-03,  3.94736184e-03,  2.73948722e-02,\n",
       "          4.67124191e-04, -2.62591094e-02, -5.81341200e-02, -3.48349065e-02,\n",
       "         -2.03806907e-04,  1.01802768e-02,  6.61741616e-03, -2.11896040e-02,\n",
       "          8.81538261e-04, -3.92764993e-03,  1.02665462e-02,  2.76462454e-02,\n",
       "          3.27036418e-02,  1.43116042e-02,  5.56269661e-03,  4.21167165e-03,\n",
       "          8.20477400e-03, -2.64885128e-02, -4.55413526e-03,  1.22341514e-02,\n",
       "          9.09041427e-03,  1.13084791e-02,  2.01822515e-03, -3.72984298e-02,\n",
       "         -1.47779444e-02,  1.86882983e-03,  7.64396973e-03, -1.48079479e-02,\n",
       "          1.68081895e-02, -2.53483560e-02,  2.91937459e-02,  3.00867967e-02,\n",
       "         -7.95400236e-03,  2.60434765e-02, -9.11345985e-03, -7.41944788e-03,\n",
       "         -3.35434377e-02, -7.00901216e-03,  1.75185557e-02, -3.39163281e-02,\n",
       "         -2.54674908e-02,  2.23253239e-02, -2.68211868e-02, -4.01633605e-02,\n",
       "         -4.09882143e-02, -5.13121970e-02, -4.46692295e-03, -4.12734710e-02,\n",
       "         -2.34647579e-02,  1.89739261e-02,  2.76551917e-02, -5.49316779e-02,\n",
       "          2.15910710e-02,  4.25052904e-02,  1.46689173e-02, -4.61585587e-03,\n",
       "         -2.27104872e-02, -6.02422981e-03, -2.37803943e-02, -2.17177086e-02,\n",
       "          1.14876628e-02,  8.82274006e-03, -2.72496808e-02,  1.99370179e-02,\n",
       "          2.65977122e-02, -3.26217222e-03,  5.67171313e-02, -2.55484432e-02,\n",
       "          2.98024323e-02,  5.40973432e-03,  3.71377100e-03, -3.68660539e-02,\n",
       "          1.51535869e-02, -2.03718152e-02, -5.47597883e-03,  8.75500496e-03,\n",
       "          3.08928955e-02, -1.90920979e-02,  2.30010673e-02, -3.34240012e-02,\n",
       "          4.66949604e-02,  4.01924588e-02, -1.90765336e-02,  2.71843597e-02,\n",
       "          3.30324061e-02,  1.85168814e-02,  4.33781743e-02,  3.68545130e-02,\n",
       "         -2.63542458e-02,  3.03945728e-02,  1.34125678e-02, -1.40922368e-02,\n",
       "         -3.46031040e-04,  1.40764825e-02,  1.79729462e-02,  1.76902656e-02,\n",
       "          2.12553293e-02,  1.02177113e-02,  1.76873561e-02,  1.43412603e-02,\n",
       "          1.60017461e-02, -1.11745000e-02, -4.83558327e-02,  4.27503185e-03,\n",
       "         -4.34761494e-02,  1.61047727e-02,  1.25116678e-02, -4.88187708e-02,\n",
       "         -1.24464873e-02, -3.33021916e-02,  5.48292063e-02, -1.14090061e-02,\n",
       "          2.66135037e-02, -2.15668883e-03,  1.00644920e-02,  3.20256432e-03,\n",
       "         -5.35992570e-02, -5.20521961e-03,  2.80796811e-02, -2.37850044e-02,\n",
       "          3.97176482e-02, -1.43318577e-02,  8.04962649e-04,  4.72638272e-02,\n",
       "         -1.07135260e-02, -8.30425601e-03, -6.62482576e-04, -3.81515771e-02,\n",
       "         -6.65629655e-03, -2.95485705e-02, -1.93940173e-03, -2.34313961e-02,\n",
       "          5.60577586e-02, -3.54920551e-02,  2.98564918e-02, -1.15977796e-02,\n",
       "          4.22647037e-03, -2.17956621e-02, -5.07863574e-02, -1.99169703e-02,\n",
       "         -1.73579045e-02, -1.97202107e-03,  1.81895948e-03,  3.77622014e-03,\n",
       "          1.32422009e-02, -7.17883045e-03, -3.01426463e-03,  1.63226016e-02,\n",
       "         -2.19843276e-02,  3.24902944e-02, -4.59792232e-03, -5.13499044e-02,\n",
       "          1.22985076e-02, -3.09464782e-02, -8.42918828e-03,  2.84729004e-02,\n",
       "         -3.75526436e-02,  7.50704342e-03,  1.92121435e-02, -8.01561959e-03,\n",
       "         -3.14097553e-02, -5.04476763e-02,  4.99940515e-02,  4.22521308e-02,\n",
       "         -3.09329573e-02,  1.20619936e-02,  4.12822105e-02, -2.45631710e-02,\n",
       "         -2.33118590e-02, -6.09080270e-02,  2.37884093e-02, -1.87605806e-02,\n",
       "         -1.70130730e-02, -2.82685757e-02,  5.03494963e-03,  6.64425257e-04],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 8,\n",
       "  'topic_words': array(['dataframe', 'dataset', 'covariance', 'statistical', 'variance',\n",
       "         'statistics', 'statistically', 'datasets', 'matplotlib',\n",
       "         'variances', 'correlation', 'statistic', 'correlations',\n",
       "         'regression', 'multivariate', 'numpy', 'scatterplot',\n",
       "         'coefficient', 'coefficients', 'variables', 'ggplot', '통계청',\n",
       "         'variability', 'probabilistic', '통계', 'data', '변수',\n",
       "         'multiprocessing', 'tensorflow', 'matlab', 'correlated', 'sklearn',\n",
       "         'lineplot', 'stats', 'graphql', '잠재변수', 'correlate', 'correlates',\n",
       "         'bivariate', 'quantitative', 'nonparametric', 'probability',\n",
       "         'xticklabels', 'computed', 'calculations', 'computation',\n",
       "         'computationally', 'twindata', 'populations', 'computational'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-0.05961818, -0.02416701, -0.00680025,  0.01161483, -0.04081945,\n",
       "         -0.03865511,  0.00782279, -0.02475436,  0.05018535,  0.02025942,\n",
       "          0.02282742,  0.02749583,  0.05155105, -0.01312988, -0.05665712,\n",
       "         -0.00406636,  0.01311828, -0.01237329,  0.02925505,  0.03809209,\n",
       "         -0.00476208, -0.03456568, -0.02730034,  0.04043739, -0.04865455,\n",
       "         -0.04867312,  0.01593861, -0.00842788,  0.02131197, -0.04915681,\n",
       "         -0.05135158,  0.01819059,  0.00825817, -0.05625247,  0.01021216,\n",
       "          0.00499841, -0.02876754,  0.01379128, -0.0200224 ,  0.03231881,\n",
       "         -0.00855864, -0.00083931,  0.01524618, -0.04897317, -0.0180166 ,\n",
       "         -0.04549404,  0.04442077,  0.00250351, -0.0255777 , -0.01844206,\n",
       "         -0.00960106, -0.01048755,  0.0061902 , -0.01548155,  0.02520921,\n",
       "         -0.05154411,  0.00735798,  0.03396583,  0.00103427,  0.043623  ,\n",
       "          0.01942492,  0.04730693,  0.02297206, -0.03023316,  0.01527579,\n",
       "         -0.00887887,  0.00463612, -0.00215735,  0.02975803,  0.01647312,\n",
       "         -0.0339192 , -0.0137089 , -0.02170665, -0.03841182, -0.04168558,\n",
       "         -0.04978673,  0.01946607,  0.03439916, -0.01344825, -0.06103797,\n",
       "         -0.06070923, -0.03300391, -0.03239968, -0.0001983 ,  0.00995368,\n",
       "         -0.01865865, -0.04135893, -0.02815859,  0.00278363, -0.02500914,\n",
       "          0.00035923, -0.01725693,  0.01794735, -0.04372533,  0.02015893,\n",
       "          0.05140497, -0.00777318,  0.01823296,  0.01809086,  0.02258669,\n",
       "          0.04213011, -0.00435498,  0.04002996, -0.00352507,  0.02961721,\n",
       "         -0.02152251, -0.04008974, -0.01199914,  0.01219976,  0.04456381,\n",
       "          0.02737016, -0.02633027, -0.02101587, -0.01392427,  0.02176913,\n",
       "          0.00799451,  0.00058516, -0.02293898, -0.00663139, -0.01010238,\n",
       "         -0.00672879,  0.01906693,  0.00892689,  0.03461248,  0.04033659,\n",
       "          0.00438414, -0.02698671,  0.02816251, -0.04333938,  0.02138499,\n",
       "         -0.05168135,  0.02798872,  0.05485892,  0.01375631, -0.01014371,\n",
       "          0.02840032,  0.00446171, -0.02474639,  0.04519398,  0.04097797,\n",
       "         -0.02073023, -0.02124024,  0.02059836, -0.01931169,  0.02626497,\n",
       "          0.00938905, -0.03239446,  0.0342707 ,  0.01194362, -0.00052845,\n",
       "          0.04679512,  0.01622161,  0.01512196, -0.03699639,  0.03002834,\n",
       "         -0.01404047, -0.00426948, -0.01337862,  0.00895879, -0.00866686,\n",
       "          0.02783466,  0.00742365,  0.01083232, -0.02433754, -0.03881441,\n",
       "         -0.02337697, -0.02287266,  0.00767131, -0.01990986,  0.04326193,\n",
       "         -0.02673117, -0.00575802,  0.02037742,  0.0008511 ,  0.00845091,\n",
       "          0.04475778, -0.02704819,  0.03194885, -0.04817722,  0.03729483,\n",
       "          0.02445151, -0.01451136,  0.01270802, -0.009861  , -0.05113093,\n",
       "         -0.03137643,  0.04373139,  0.05036178, -0.00907709, -0.04356123,\n",
       "         -0.01331992, -0.00852706,  0.04788341, -0.00874693, -0.00814927,\n",
       "          0.01994154, -0.05381379, -0.02262462,  0.04424158,  0.02249152,\n",
       "         -0.01062852,  0.00334136, -0.0375415 , -0.00588486, -0.01651286,\n",
       "         -0.02779627, -0.01996811,  0.00756775, -0.03029179,  0.03572749,\n",
       "         -0.02498858,  0.02078065, -0.05279065,  0.00352434,  0.03682371,\n",
       "         -0.02062068, -0.00921101, -0.05599597,  0.02612055, -0.01551497,\n",
       "          0.00288597, -0.00041819,  0.02145784, -0.02894379, -0.05686043,\n",
       "          0.00459153, -0.03698181, -0.03212648,  0.01648006, -0.01044822,\n",
       "         -0.01030468,  0.05050904, -0.00733704, -0.01843875,  0.03559981,\n",
       "          0.01658003, -0.0144601 ,  0.02933604,  0.01006345, -0.0165389 ,\n",
       "         -0.0096174 ,  0.0294662 ,  0.00353992,  0.02213201, -0.00838246,\n",
       "         -0.05581331, -0.02483629,  0.00123377,  0.01202178, -0.00640848,\n",
       "         -0.02223804, -0.03845734, -0.02115515, -0.02689459, -0.013122  ,\n",
       "         -0.01553077, -0.00783819, -0.02043485, -0.01235586, -0.01761782,\n",
       "          0.00230056,  0.01115472, -0.02287777, -0.02549024,  0.02514449,\n",
       "         -0.0421623 , -0.02555203, -0.01594034, -0.00572017, -0.00166299,\n",
       "         -0.02672032, -0.04503308, -0.02404929, -0.02978535, -0.004677  ,\n",
       "          0.00104554, -0.04478562,  0.03587315, -0.03959045,  0.00375854,\n",
       "         -0.04776919,  0.01486692,  0.02715086, -0.00212768, -0.0283881 ,\n",
       "          0.03486492, -0.03223709, -0.03949083, -0.0229254 ,  0.0422409 ,\n",
       "          0.03777787,  0.05500439,  0.04232654,  0.01226846, -0.05492124,\n",
       "          0.0278308 , -0.02900579,  0.0180932 ,  0.03513698,  0.03717238,\n",
       "         -0.03986558,  0.03795394, -0.02545977, -0.05151769, -0.05671739,\n",
       "         -0.00741854, -0.01881272,  0.01281487, -0.01063407,  0.03838503,\n",
       "         -0.0077442 , -0.01050893, -0.04441637, -0.00348145,  0.01395019,\n",
       "          0.03671851,  0.03198232, -0.02137417,  0.01483808, -0.00223647,\n",
       "          0.00563667, -0.01006945, -0.03096456,  0.01349101, -0.03148139,\n",
       "         -0.00718949, -0.02255172, -0.02825161, -0.00151435, -0.00057377,\n",
       "         -0.02700356, -0.03728547, -0.01424241, -0.0519815 , -0.02822279,\n",
       "          0.03232284, -0.00676343, -0.02706443, -0.05824356, -0.0271658 ,\n",
       "         -0.03577974, -0.02296998,  0.04210226, -0.00498868, -0.02855528,\n",
       "          0.03915001,  0.04781014,  0.02316954, -0.03442334, -0.0135977 ,\n",
       "          0.02326   ,  0.01585734,  0.02137354, -0.00552528,  0.00224774,\n",
       "          0.01762972,  0.01294915,  0.04164201, -0.04029796, -0.04261057,\n",
       "          0.00789595, -0.03099338,  0.03186664, -0.00627511, -0.04089421,\n",
       "          0.01254505,  0.02303371,  0.02976053, -0.01038449,  0.05484418,\n",
       "          0.02373423,  0.03514278, -0.01748447,  0.02874814, -0.02011584,\n",
       "         -0.0491511 ,  0.01613044, -0.02643885, -0.04399761, -0.04478917,\n",
       "          0.02093409, -0.0499516 ,  0.00131403, -0.01819834, -0.0423708 ,\n",
       "          0.05265493,  0.00566454, -0.04693148,  0.03621456, -0.01430217,\n",
       "          0.02469273, -0.03167824, -0.04867234,  0.04939915, -0.04400589,\n",
       "          0.01940259,  0.03732002, -0.00561076, -0.03660706,  0.01149884,\n",
       "          0.0233188 ,  0.05208376,  0.03987169, -0.02196839, -0.03579891,\n",
       "          0.01774771, -0.0039527 , -0.03330974,  0.037548  , -0.01421352,\n",
       "         -0.01229204,  0.01331228,  0.0216837 , -0.01823885,  0.03166282,\n",
       "          0.01898282,  0.03074327,  0.02116991,  0.03827765,  0.00778633,\n",
       "          0.00217845, -0.03338151,  0.01725821,  0.04606529,  0.04214991,\n",
       "          0.02229604, -0.00446469, -0.02419668,  0.00529749, -0.01895169,\n",
       "         -0.02821176,  0.00027414,  0.00535222, -0.01329882,  0.00360771,\n",
       "          0.03163279,  0.03884128,  0.0006366 , -0.05247241,  0.02439278,\n",
       "         -0.01958439,  0.00452997, -0.01102088, -0.05313271,  0.01094377,\n",
       "         -0.01138901,  0.04945102, -0.00193671,  0.00999716,  0.01824889,\n",
       "          0.00292912, -0.00323335, -0.03032318, -0.01321277, -0.04545707,\n",
       "         -0.02358623,  0.02290015,  0.02339801,  0.04010297,  0.03033747,\n",
       "         -0.0084939 , -0.02009711, -0.01013427, -0.0396791 ,  0.04089109,\n",
       "         -0.03209367,  0.00128998, -0.05025794,  0.0578627 , -0.01051527,\n",
       "          0.03419449,  0.01169088,  0.00659906,  0.01570723, -0.04721891,\n",
       "         -0.02854022,  0.02822165, -0.01365578, -0.02351516, -0.01489943,\n",
       "          0.04779593,  0.03270524, -0.03663215,  0.0050587 ,  0.02104176,\n",
       "          0.0045078 , -0.01946016, -0.05515314, -0.01186982, -0.02314751,\n",
       "          0.02350689, -0.01045351, -0.00566296, -0.01468539, -0.00014777,\n",
       "         -0.02770695,  0.00176856, -0.04181633,  0.02738282,  0.00891445,\n",
       "          0.00141261, -0.04404669,  0.04703233,  0.00734666, -0.02073859,\n",
       "         -0.05600915, -0.00496663, -0.02057279, -0.00417993, -0.04381529,\n",
       "         -0.01745184,  0.03378233], dtype=float32)},\n",
       " {'topic_idx': 9,\n",
       "  'topic_words': array(['scientist', 'scientists', '과학자', 'fiction', 'neuroscientist',\n",
       "         'deviance', 'neuroscientists', 'neurosciences', 'scholar',\n",
       "         'feminist', 'scholars', 'heuristics', 'darwin', '소설',\n",
       "         'neuroscience', 'neurosci', 'writer', 'robots', 'intellectual',\n",
       "         'psychosis', 'heuristic', '과학', 'scientific', 'psychological',\n",
       "         'kruskal', 'neurocultures', 'psychiatric', 'literature', 'authors',\n",
       "         'zimbardo', 'plausible', 'neuroscientific', 'science', 'novel',\n",
       "         'sensory', 'robot', 'professor', 'neural', '일종', 'abilities',\n",
       "         'selvars', 'prisoners', '작가', 'fantasy', 'parkinsonism',\n",
       "         'repetitive', 'schmitz', '학문', 'psychiatry', 'psychology'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([ 3.16010416e-02,  1.64976083e-02,  1.21413665e-02, -1.53006334e-02,\n",
       "         -1.52382050e-02,  4.85865660e-02, -1.46706530e-03, -6.53630681e-03,\n",
       "          3.83803025e-02,  8.10727291e-03,  6.28585112e-04,  9.03972331e-03,\n",
       "          4.45141159e-02, -6.04194961e-03, -4.19153646e-02, -1.42831001e-02,\n",
       "          9.27991699e-03, -5.05509377e-02,  5.16961794e-03,  3.57979275e-02,\n",
       "         -2.97165085e-02, -4.52879407e-02,  4.44524027e-02,  1.17666451e-02,\n",
       "         -5.30738160e-02,  1.07737258e-02,  2.67816838e-02, -5.92430402e-03,\n",
       "          1.49519928e-02, -4.88975458e-02,  1.17652901e-02,  2.49446239e-02,\n",
       "          2.84754559e-02, -3.46682817e-02,  1.63365044e-02, -1.88653506e-02,\n",
       "          1.10291233e-02, -1.84616856e-02, -1.86219532e-02, -3.82387787e-02,\n",
       "         -2.16383804e-02,  1.57095268e-02,  4.26234566e-02,  3.46361240e-03,\n",
       "         -1.54595170e-02, -6.74374821e-03,  1.82919037e-02, -2.78406069e-02,\n",
       "          1.25495847e-02, -2.04421394e-02, -2.40981200e-04, -1.45845581e-02,\n",
       "          3.78550077e-03,  8.09887331e-03,  2.05963803e-03, -5.31798229e-02,\n",
       "          4.07922380e-02, -4.14554868e-03,  2.05353834e-02, -2.77090439e-04,\n",
       "         -1.19060744e-02,  5.29508479e-02, -3.39182792e-03, -3.75876836e-02,\n",
       "         -6.00309623e-03, -1.25340382e-02,  2.18746662e-02, -2.87398100e-02,\n",
       "         -1.36329941e-02,  1.73015948e-02, -4.97124332e-04,  2.64101173e-03,\n",
       "          2.37448215e-02, -1.50949946e-02, -2.74778600e-03,  6.05297182e-03,\n",
       "         -2.48324610e-02,  4.48954804e-03, -1.80663040e-03, -5.57020567e-02,\n",
       "         -6.07566014e-02, -2.39655655e-02, -5.25544165e-03,  3.23812142e-02,\n",
       "          3.91409812e-05, -1.48760267e-02, -1.78147331e-02, -2.82175746e-02,\n",
       "         -1.13806026e-02,  2.61925440e-02, -3.45335267e-02, -2.64302809e-02,\n",
       "         -4.35612127e-02, -2.52519478e-03,  2.58275643e-02, -2.43081339e-03,\n",
       "          3.80266197e-02,  3.59850787e-02,  4.56017209e-03,  1.50512485e-02,\n",
       "          1.52983060e-02,  1.25772813e-02, -1.67368557e-02,  2.88322126e-03,\n",
       "         -1.12495746e-03, -3.23824920e-02, -2.31061000e-02,  7.76632829e-03,\n",
       "         -1.54300164e-02,  1.39837107e-02,  2.67907996e-02, -2.71430835e-02,\n",
       "         -2.15659980e-02,  2.33260524e-02,  3.15771252e-02, -2.51074973e-02,\n",
       "          4.97287198e-04, -1.25109609e-02, -2.09738743e-02,  2.00474113e-02,\n",
       "          1.43171381e-02,  3.45542841e-02,  2.09890231e-02,  2.22688653e-02,\n",
       "         -1.40044268e-03,  3.42916064e-02,  1.22267101e-02, -1.30252903e-02,\n",
       "         -3.17798741e-03,  2.62944750e-03, -3.76657806e-02, -2.30196901e-02,\n",
       "         -1.18716955e-02,  1.30087836e-02, -1.11459270e-02,  5.30050360e-02,\n",
       "         -9.49359220e-03, -9.47297737e-03,  4.63148728e-02,  2.27683783e-03,\n",
       "          1.65506192e-02,  1.44708557e-02,  2.18013842e-02,  2.82248314e-02,\n",
       "          2.41891500e-02, -2.60900066e-04,  4.24714051e-02, -2.12882683e-02,\n",
       "          9.29214619e-03, -2.84435377e-02,  3.46771628e-02, -4.20978665e-03,\n",
       "         -6.01324718e-03, -7.83398934e-03,  4.65431670e-03,  1.25543280e-02,\n",
       "         -6.19868515e-03, -1.75916515e-02, -3.18729654e-02, -4.91644163e-03,\n",
       "          3.86352651e-02, -3.14958133e-02, -6.28898246e-03,  1.08696218e-03,\n",
       "         -2.14523990e-02, -8.34495481e-03,  1.20716365e-02, -4.24215710e-03,\n",
       "         -8.35942943e-03, -1.67721231e-03, -2.31802650e-02,  2.51407400e-02,\n",
       "          1.58879370e-03,  1.14247091e-02, -2.44080480e-02,  2.20450778e-02,\n",
       "         -3.03930249e-02,  2.60062702e-02,  9.72838886e-03,  2.80329566e-02,\n",
       "          3.99925793e-03,  1.86428558e-02,  1.10131316e-02, -3.09020821e-02,\n",
       "         -1.56563632e-02,  8.21141154e-03,  1.75056383e-02,  5.53247556e-02,\n",
       "          2.92910784e-02,  1.80201977e-02,  1.55456515e-03, -3.07962708e-02,\n",
       "          2.45129410e-02, -7.82668963e-03, -8.46965797e-03,  3.49887758e-02,\n",
       "         -2.55596843e-02, -8.36622808e-03,  7.52936676e-03,  1.27216270e-02,\n",
       "         -7.40785571e-03,  2.34294143e-02, -3.66144650e-06, -4.72002998e-02,\n",
       "          1.38367843e-02,  9.55693237e-03,  1.44055095e-02,  2.83481069e-02,\n",
       "          4.03446332e-03,  2.66189892e-02, -1.04976576e-02, -2.22453084e-02,\n",
       "          2.00392418e-02,  6.79447828e-03,  1.16424318e-02, -9.47015360e-03,\n",
       "          1.41023677e-02, -3.61426100e-02,  1.83008742e-02,  2.21731439e-02,\n",
       "         -2.51679290e-02,  6.60550268e-03,  2.69682035e-02,  2.35698298e-02,\n",
       "         -6.08064281e-03, -3.20548154e-02, -2.62877978e-02, -2.42184103e-03,\n",
       "         -4.02321778e-02, -2.53903996e-02,  4.17694869e-03,  8.18911754e-03,\n",
       "         -1.42148724e-02,  1.52414804e-02,  2.36718133e-02, -7.37568783e-03,\n",
       "         -1.65536092e-03,  1.04040941e-02,  3.09173204e-02, -8.02007224e-03,\n",
       "          9.91218630e-03,  2.54211063e-03,  3.17182951e-02,  1.56079128e-04,\n",
       "          1.42751969e-02,  2.55799964e-02,  4.19127792e-02,  8.53065494e-03,\n",
       "          1.42783811e-02,  1.70345828e-02,  3.96979181e-03, -2.27474980e-02,\n",
       "          1.85636021e-02, -2.57669464e-02,  1.23627102e-02, -1.37643772e-03,\n",
       "          9.71372705e-03,  2.64811562e-03, -2.72581317e-02,  4.44966480e-02,\n",
       "          9.55061894e-03,  3.64809334e-02, -9.44033323e-04, -1.09833973e-02,\n",
       "          9.42529365e-03, -5.26147522e-02, -2.21061818e-02,  2.61922907e-02,\n",
       "         -5.65557834e-03, -2.05186773e-02, -4.72975615e-03, -1.57616884e-02,\n",
       "         -5.73799899e-03, -2.92716008e-02,  3.45144309e-02,  1.22878989e-02,\n",
       "         -1.48455705e-02, -2.68329936e-03, -4.86747436e-02, -1.92965660e-02,\n",
       "         -2.92235203e-02, -1.27742002e-02,  2.05799751e-02, -1.07404273e-02,\n",
       "         -4.86487849e-03,  2.97195427e-02, -3.89303826e-02, -1.92544460e-02,\n",
       "          1.39780215e-03, -7.24650640e-03, -2.56321765e-03,  2.23597437e-02,\n",
       "          6.21472159e-03,  3.18628550e-02,  2.39918977e-02,  3.52626517e-02,\n",
       "          1.46441087e-02,  7.56102894e-03, -3.78470213e-05,  3.52850370e-02,\n",
       "          6.13532588e-03,  1.84824057e-02,  6.18887367e-04, -3.48494053e-02,\n",
       "          7.85815436e-03, -6.23996090e-03, -3.32588628e-02,  4.43986617e-02,\n",
       "          1.73667800e-02, -1.14273131e-02, -1.17399695e-03, -6.68427069e-03,\n",
       "          2.76196562e-03, -9.67218913e-03,  4.10185121e-02,  3.35076302e-02,\n",
       "          1.94255039e-02,  5.96461026e-03,  2.30512535e-03, -2.05495209e-02,\n",
       "          9.22977179e-03, -1.39416233e-02, -1.62160732e-02,  2.27938946e-02,\n",
       "         -3.97076271e-02,  5.63830556e-03,  9.25392844e-03, -9.74030700e-03,\n",
       "          3.74511369e-02,  2.18265783e-02, -1.09518983e-03,  1.10862274e-02,\n",
       "         -1.18054273e-02, -1.56128528e-02, -1.50296706e-04,  6.47684094e-03,\n",
       "         -2.43355297e-02, -6.46225968e-03, -5.13996556e-02, -1.59611590e-02,\n",
       "         -2.29221564e-02,  2.44794115e-02, -2.77471598e-02, -2.66689919e-02,\n",
       "         -4.80459584e-03,  1.00938855e-02,  4.49666865e-02, -1.20678609e-02,\n",
       "         -1.07376473e-02, -5.95367979e-03,  9.51633602e-03,  6.47439575e-03,\n",
       "          1.37351956e-02,  1.00405645e-02, -2.29907222e-02, -9.52127564e-04,\n",
       "         -1.35062141e-02,  2.47515514e-02, -1.25226481e-02,  6.62521925e-03,\n",
       "         -6.12861756e-03,  1.21075027e-02,  4.34625447e-02,  3.02675981e-02,\n",
       "          1.67654343e-02, -1.43654866e-03, -1.29887592e-02,  8.81920848e-03,\n",
       "         -5.39449416e-03,  2.28756648e-02, -9.91477817e-03,  1.79761648e-02,\n",
       "          2.59059062e-03,  1.37198167e-02,  1.58673637e-02,  3.98723930e-02,\n",
       "         -3.56631167e-02,  9.81477182e-03,  2.57473032e-04, -2.22054645e-02,\n",
       "         -9.37579479e-03,  2.48940545e-03,  4.69263410e-03,  2.08105687e-02,\n",
       "         -9.84865334e-03,  4.59258929e-02, -9.36959218e-03, -5.71191870e-02,\n",
       "          5.55081256e-02,  2.44459771e-02,  4.16469388e-03, -3.33568044e-02,\n",
       "          2.41448153e-02, -4.16450249e-03,  4.35296865e-03,  1.18353041e-02,\n",
       "          1.38028273e-02, -2.82638543e-03, -5.06302854e-03, -5.31839021e-03,\n",
       "          1.17980372e-02,  3.38653624e-02, -2.60840524e-02,  8.82726256e-03,\n",
       "         -1.15882838e-03,  1.21865142e-03, -1.47929993e-02, -1.20329503e-02,\n",
       "         -8.34138482e-04,  2.53849961e-02,  3.91816199e-02,  8.78494047e-03,\n",
       "          3.03980950e-02,  2.58274376e-05,  1.46657862e-02,  4.00859341e-02,\n",
       "          2.94224601e-02,  1.25697134e-02, -1.58296283e-02, -5.88165363e-03,\n",
       "          2.31999829e-02,  1.19899306e-03,  6.08498580e-04,  2.80413050e-02,\n",
       "          5.45519032e-02,  2.59279292e-02,  8.44388735e-03,  6.90799847e-04,\n",
       "         -4.91226427e-02, -1.03055052e-02,  2.79929973e-02, -9.81954392e-03,\n",
       "         -2.39045899e-02, -2.42625270e-02,  1.54451868e-02, -1.22918729e-02,\n",
       "          1.60280187e-02,  7.17306684e-04, -5.37122637e-02,  2.53857747e-02,\n",
       "         -1.29749691e-02,  4.23542783e-02,  1.60191599e-02, -4.89788949e-02,\n",
       "          1.98942218e-02,  2.34975498e-02,  5.53922802e-02,  2.82226410e-02,\n",
       "          3.02633438e-02,  4.53056395e-03, -2.28267541e-04,  3.59798409e-02,\n",
       "         -1.06965366e-03,  1.51120322e-02, -1.70818102e-02,  1.14937369e-02,\n",
       "          6.60480512e-03,  1.09891396e-03,  2.34003197e-02,  7.68804224e-03,\n",
       "          7.08339689e-03, -7.82770757e-03, -1.78380054e-03, -1.62196141e-02,\n",
       "         -3.23068649e-02, -5.40005416e-02, -4.43226136e-02,  3.62365544e-02,\n",
       "         -3.35312746e-02,  2.44549382e-03, -1.45428861e-02,  2.25506611e-02,\n",
       "         -8.86457227e-03,  1.62591618e-02,  3.38242389e-03,  1.60876699e-02,\n",
       "          1.67368967e-02,  2.11761310e-03, -3.05054919e-03, -4.25540237e-03,\n",
       "         -1.00320699e-02,  4.78079990e-02, -3.61450873e-02,  2.64307763e-03,\n",
       "         -3.30481753e-02, -1.42753087e-02, -9.32544377e-03, -5.67638725e-02,\n",
       "         -2.17763148e-02, -2.91436724e-02,  1.56420544e-02, -3.06590088e-03,\n",
       "          3.94621454e-02, -7.29627721e-03,  2.08054148e-02,  1.43550374e-02,\n",
       "         -2.55715046e-02, -4.86740982e-03, -3.19963247e-02, -7.90299731e-04,\n",
       "         -4.99866018e-03, -2.33173650e-02,  4.18104976e-02, -1.36848232e-02,\n",
       "         -4.05473486e-02, -1.67214149e-03,  1.44337275e-04,  1.37703971e-03,\n",
       "         -2.18000896e-02, -4.73609380e-02,  3.33435908e-02,  3.51837240e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 10,\n",
       "  'topic_words': array(['adhd', 'neuroscientific', 'neurological', 'neuroimaging',\n",
       "         'correlation', 'neuro', 'neurology', 'neuroethics', 'neurol',\n",
       "         'neurosci', 'hyperactivity', 'correlations', 'neurosciences',\n",
       "         'psychological', 'neurogenesis', 'syndromes', 'somatosensory',\n",
       "         'neuronal', 'correlated', 'sensory', 'serotonin', 'schizophrenia',\n",
       "         'cognitive', 'neuroscience', 'correlates', 'neuroimage',\n",
       "         'psychosis', 'disorders', 'correlate', 'syndrome', 'perceptual',\n",
       "         'impulsive', 'psychiatry', 'depression', 'impulsivity',\n",
       "         'alzheimers', 'psychology', 'ptsd', 'asymptotic', 'dopamine',\n",
       "         'cognitively', 'dissociation', 'hyperactive', 'neurobiological',\n",
       "         'neurosurg', 'affective', 'disorder', 'compulsive',\n",
       "         'distinctiveness', 'neuroscientists'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.05043835,  0.008684  ,  0.00173165, -0.01587967, -0.00353499,\n",
       "          0.04286073, -0.04357293, -0.00193489, -0.01461548,  0.02382311,\n",
       "          0.00840075, -0.03187568,  0.02471044, -0.02077834, -0.03761426,\n",
       "          0.02988723, -0.01317691, -0.00500636,  0.04076405,  0.03919613,\n",
       "         -0.00505317, -0.04273592, -0.02415785,  0.05088607, -0.051806  ,\n",
       "          0.00046587, -0.02433275,  0.01949608,  0.01235768,  0.02054273,\n",
       "         -0.03646105,  0.02366001,  0.00083599, -0.04786891,  0.0245177 ,\n",
       "         -0.0409893 , -0.01963687,  0.01276514, -0.01217989, -0.04505576,\n",
       "         -0.02183231, -0.00244461,  0.0505723 , -0.01410818, -0.03099279,\n",
       "         -0.00364066,  0.05096626,  0.02077923,  0.01455475, -0.03740638,\n",
       "          0.05059111,  0.01455308,  0.03210141, -0.03864462,  0.01692252,\n",
       "         -0.01618315,  0.02270655,  0.00798983,  0.00780072,  0.03456764,\n",
       "         -0.01114388,  0.05119602, -0.0238751 , -0.02937907, -0.04502621,\n",
       "          0.02115051,  0.01729389, -0.00204829, -0.02371212, -0.01722567,\n",
       "          0.00153657,  0.00843065,  0.00598779, -0.0457258 , -0.02147291,\n",
       "         -0.00641976,  0.04416367,  0.02949699, -0.03000888, -0.05378129,\n",
       "         -0.05433447, -0.03479672,  0.01560022,  0.03018836, -0.03512157,\n",
       "          0.01324403, -0.03493845, -0.02033655, -0.01689479, -0.03377771,\n",
       "         -0.03836498, -0.04732069, -0.02401213, -0.03931887,  0.02341663,\n",
       "          0.04561368,  0.04995013,  0.05007423,  0.02168904,  0.03261329,\n",
       "          0.01299955, -0.02497995,  0.0066466 , -0.00295659,  0.01310954,\n",
       "          0.04608339, -0.05129931, -0.00116589, -0.02890662,  0.04422049,\n",
       "          0.04008219, -0.04770649, -0.03312982,  0.02932927,  0.04293253,\n",
       "         -0.00820517,  0.03215993,  0.02651156, -0.00466421, -0.01620226,\n",
       "         -0.03536454,  0.04141074,  0.03895744,  0.02340615, -0.02538545,\n",
       "          0.03916454,  0.05179638,  0.01533743, -0.03634074,  0.04779002,\n",
       "         -0.0366017 , -0.03537596,  0.03372599,  0.03033222, -0.00482446,\n",
       "          0.05433975, -0.02906154, -0.02579133,  0.05350822,  0.02874224,\n",
       "          0.04706576, -0.01078106,  0.03821071, -0.01875839,  0.04221882,\n",
       "          0.0392758 , -0.01921305,  0.04258391,  0.03156003,  0.03866082,\n",
       "          0.04438254,  0.01472856, -0.01513718, -0.00435588, -0.04238578,\n",
       "         -0.00831347,  0.01735504, -0.02746601,  0.01519735, -0.0313918 ,\n",
       "          0.03248549, -0.04199562, -0.04334696, -0.01262245,  0.01576572,\n",
       "         -0.04162709,  0.02330628, -0.00338292, -0.03816108,  0.02309436,\n",
       "         -0.04326871, -0.05090565,  0.02161681,  0.01978006, -0.03736769,\n",
       "          0.02525482,  0.02797859,  0.01514286, -0.00184822,  0.00684518,\n",
       "          0.00366089, -0.03822418,  0.00103276, -0.01875261, -0.00484089,\n",
       "         -0.01099635,  0.03925846,  0.05131882,  0.04863211,  0.01826133,\n",
       "         -0.01658522, -0.01656052,  0.01353302, -0.02147156, -0.04592492,\n",
       "         -0.03029784, -0.01226001,  0.03841832,  0.04203431, -0.00482862,\n",
       "         -0.02696354,  0.01961844,  0.01459095, -0.0293628 ,  0.01637247,\n",
       "         -0.04969659, -0.04152473,  0.04513511,  0.03332097,  0.04126314,\n",
       "          0.01238927, -0.03535125,  0.03743041,  0.00759072,  0.04661397,\n",
       "          0.0147389 ,  0.02752182, -0.03520663, -0.00089541, -0.02028893,\n",
       "          0.00278847,  0.04312943,  0.05168534,  0.03044575, -0.04444297,\n",
       "         -0.02500315, -0.05312051,  0.02515034, -0.02569142, -0.03288899,\n",
       "          0.00050407,  0.03809774, -0.02787093,  0.04050505,  0.01104551,\n",
       "         -0.03267876,  0.01563575,  0.0193373 ,  0.04123652,  0.03083435,\n",
       "         -0.00506975,  0.01629471, -0.01920301,  0.03557946,  0.04616257,\n",
       "         -0.00868154,  0.04418472, -0.01319546,  0.00011449,  0.04027394,\n",
       "         -0.00940393, -0.04925491, -0.01018769, -0.03781539,  0.00729122,\n",
       "         -0.03550195,  0.01282574,  0.00939402, -0.01962198,  0.0148173 ,\n",
       "         -0.00546359,  0.04199336, -0.04152234,  0.03867616,  0.0400368 ,\n",
       "         -0.05374833, -0.03673036,  0.04681246,  0.01037515,  0.02123969,\n",
       "          0.03176684, -0.00371613, -0.01523157, -0.03883434,  0.03065669,\n",
       "          0.02652023, -0.03892921,  0.02231526, -0.0536527 , -0.01919096,\n",
       "         -0.03793272,  0.00801384,  0.02375681,  0.04351648, -0.03575617,\n",
       "          0.02778849, -0.04982778, -0.0315659 , -0.02629744,  0.00232223,\n",
       "          0.05173727,  0.01102718,  0.02831282, -0.0168664 , -0.03342501,\n",
       "         -0.04586467,  0.01805438,  0.0299297 ,  0.03816966,  0.04012744,\n",
       "         -0.04735176,  0.02373023, -0.01805241, -0.01451305, -0.03473745,\n",
       "         -0.01997438, -0.01361783,  0.02773918, -0.00310528,  0.03210945,\n",
       "         -0.0438516 , -0.04322904,  0.02488355, -0.03862981,  0.04903993,\n",
       "          0.04881252,  0.01966095, -0.02749985,  0.02034974, -0.04429885,\n",
       "          0.00103316, -0.04883862, -0.0013641 ,  0.03892334, -0.00619378,\n",
       "         -0.03400479, -0.02620971, -0.00905902, -0.00042539,  0.01523547,\n",
       "         -0.01605317, -0.04062373, -0.04856604, -0.01803803,  0.01129866,\n",
       "          0.00192153, -0.0507689 , -0.03357401, -0.03370201,  0.01529152,\n",
       "         -0.03753554, -0.02751662,  0.01749581, -0.04691019,  0.0050826 ,\n",
       "          0.046424  ,  0.0521483 , -0.0329042 , -0.0468909 ,  0.02619707,\n",
       "          0.03227093,  0.01954332, -0.0122036 ,  0.04390834,  0.04627303,\n",
       "          0.03565777,  0.01836772,  0.03761759, -0.04586213, -0.03525621,\n",
       "          0.02032909, -0.01593453,  0.04563292,  0.02432921, -0.03472047,\n",
       "          0.03831657, -0.02196821,  0.00840648, -0.02728168,  0.01548064,\n",
       "          0.02615401,  0.04000942,  0.01598826,  0.0194086 , -0.00063357,\n",
       "         -0.04169441,  0.00539318,  0.01304058,  0.01921129, -0.03390074,\n",
       "          0.04875698, -0.01384526,  0.02448678,  0.0310866 , -0.0140578 ,\n",
       "          0.0543973 ,  0.04738814, -0.04440245,  0.05336134, -0.01961998,\n",
       "          0.01302078,  0.02195835,  0.01179305,  0.04648451, -0.03857156,\n",
       "          0.02661233,  0.05226324, -0.03548584,  0.00701553,  0.0240527 ,\n",
       "          0.02999302,  0.05307297,  0.03294035,  0.03371565, -0.0271383 ,\n",
       "          0.00442012,  0.02153154, -0.03479341,  0.02894218,  0.00010282,\n",
       "          0.0246592 , -0.00669789,  0.00011055,  0.05016939, -0.01969835,\n",
       "          0.05370673,  0.0071112 , -0.04605642,  0.03951535,  0.00828446,\n",
       "         -0.04868384, -0.03714522,  0.03372923,  0.03346018,  0.05104893,\n",
       "         -0.02750349, -0.04256392, -0.03067059, -0.01965243,  0.00243582,\n",
       "         -0.04349795, -0.01007777, -0.01554543, -0.039464  ,  0.02756627,\n",
       "         -0.0064051 , -0.01327755, -0.05046298, -0.05462501,  0.04440312,\n",
       "          0.02296854, -0.02539766,  0.02130597, -0.05099209,  0.02380737,\n",
       "         -0.00324458, -0.02626079,  0.03778584, -0.01098932, -0.0008519 ,\n",
       "         -0.02342609, -0.00465567, -0.01159158,  0.01261726, -0.03424149,\n",
       "         -0.00354505,  0.01588192,  0.02296144, -0.01596378, -0.00287953,\n",
       "         -0.0392074 , -0.02433467, -0.0147147 , -0.04072024,  0.03549261,\n",
       "         -0.05095399, -0.01835825, -0.03750594,  0.05156434,  0.02206046,\n",
       "          0.01142366,  0.04894566, -0.03933914,  0.00813236, -0.01734634,\n",
       "         -0.02959416, -0.01222941, -0.02378285, -0.02719714, -0.00093962,\n",
       "          0.0411819 ,  0.0547029 , -0.02934614, -0.01057111,  0.04173538,\n",
       "         -0.02937594, -0.0262252 , -0.04432775, -0.02599166, -0.0360724 ,\n",
       "          0.03345489,  0.02268288, -0.03240811,  0.01412219, -0.0362075 ,\n",
       "         -0.03428616, -0.03076817,  0.02648338,  0.02292563,  0.00914156,\n",
       "          0.02396917, -0.04517949,  0.05277852, -0.04365031, -0.04667049,\n",
       "         -0.04992462,  0.01783235, -0.03692688, -0.03610446, -0.04989708,\n",
       "         -0.00321654,  0.02267261], dtype=float32)},\n",
       " {'topic_idx': 11,\n",
       "  'topic_words': array(['psychology', 'psychological', 'neurosciences', 'neuroscience',\n",
       "         '학문', 'neurofeminism', 'neurosci', 'feminist', 'neuroscientific',\n",
       "         'neurofeminist', 'psychosis', 'psychiatry', '심리', 'psychiatric',\n",
       "         'scientists', 'intellectual', 'neuroscientist', 'scientist',\n",
       "         'psychotherapy', 'academic', 'neuroscientists', 'brainstem',\n",
       "         'scholar', 'neurons', 'neuronal', 'neuron', 'scientific', 'mental',\n",
       "         'psychol', 'scholars', 'neurology', 'alzheimers', 'alzheimer',\n",
       "         'brains', 'researchers', 'neurological', 'depressive', 'brain',\n",
       "         'neuro', 'studies', 'cognitive', 'neuroethics', 'intelligent',\n",
       "         'neurol', 'neurobiology', 'neurobiological', 'intelligence',\n",
       "         'researcher', 'depression', 'forebrain'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.0243097 ,  0.03375202,  0.01070361, -0.03400807, -0.00685072,\n",
       "          0.05036619, -0.02271513,  0.01300895,  0.04043701,  0.02673846,\n",
       "         -0.01100898,  0.00498717,  0.01844998, -0.01621702, -0.04162728,\n",
       "          0.02503659, -0.00851936, -0.05301292,  0.0118473 ,  0.05057374,\n",
       "         -0.01972387, -0.04306589,  0.0093381 ,  0.02073275, -0.05552742,\n",
       "          0.00089352,  0.01992013, -0.00521985,  0.00320712, -0.04428077,\n",
       "          0.01128924,  0.00386826, -0.00627279, -0.04190019,  0.02182141,\n",
       "         -0.02473008,  0.03378272, -0.0073282 , -0.02854134, -0.02687289,\n",
       "         -0.00672368,  0.00661443,  0.04841306,  0.01208014, -0.04156024,\n",
       "          0.00540709,  0.01600523, -0.00240875, -0.00055798, -0.00642566,\n",
       "          0.03962894, -0.01103199,  0.01464136, -0.01617442, -0.00360861,\n",
       "         -0.05316872,  0.02974911,  0.00165777,  0.01252821,  0.03918037,\n",
       "         -0.03306262,  0.05641204, -0.00354062, -0.04668073, -0.00287545,\n",
       "          0.01309189,  0.02764904, -0.03052723, -0.01820919, -0.00535116,\n",
       "          0.01001963,  0.01188898,  0.01915688, -0.04942851,  0.01113786,\n",
       "         -0.03013485,  0.02882762,  0.03953315, -0.02885583, -0.06138965,\n",
       "         -0.06259014, -0.03528045, -0.02317443,  0.03960126, -0.02266688,\n",
       "         -0.00290606, -0.02476938, -0.00435866,  0.00347256,  0.03173621,\n",
       "         -0.04224597, -0.01395313, -0.03696286, -0.02765779,  0.00298278,\n",
       "          0.00729405,  0.05620674,  0.04824803, -0.00484352,  0.01662273,\n",
       "          0.00100805, -0.00758829, -0.00549508,  0.0023875 ,  0.01718147,\n",
       "          0.00287192, -0.05233103, -0.00101995, -0.02217905,  0.03170376,\n",
       "          0.0075625 , -0.0376714 , -0.01763957,  0.00747679,  0.02668632,\n",
       "         -0.04196377,  0.01958652,  0.01597565, -0.02285086,  0.02464816,\n",
       "         -0.00436881,  0.04181092,  0.03087479,  0.02039509, -0.00881928,\n",
       "          0.03281068,  0.01690566,  0.01013367, -0.03092241,  0.0254397 ,\n",
       "         -0.03357444,  0.00165432,  0.02329812,  0.03466747,  0.01469985,\n",
       "          0.05966099, -0.00835157, -0.02461806,  0.0549079 ,  0.0102751 ,\n",
       "          0.0294723 ,  0.0209878 ,  0.00823199,  0.01925051,  0.03138418,\n",
       "          0.00393412,  0.04032877,  0.00151709,  0.00898315, -0.00621838,\n",
       "          0.05307643,  0.00718329,  0.00892689, -0.00861597, -0.03519619,\n",
       "         -0.00017115,  0.00460598, -0.01612792, -0.03659549, -0.0278868 ,\n",
       "          0.0341036 , -0.0472156 , -0.0157341 , -0.00468735, -0.0244637 ,\n",
       "         -0.03940254,  0.02038278, -0.010436  , -0.00444886,  0.00695125,\n",
       "         -0.02797079,  0.00552079, -0.00316111, -0.01590863, -0.01590254,\n",
       "          0.01622572, -0.01800261,  0.02952606, -0.04456666,  0.02697834,\n",
       "          0.0379037 ,  0.0286521 ,  0.00262722, -0.01871341, -0.01261697,\n",
       "          0.00702474,  0.01719102,  0.05738795,  0.03221743,  0.01469361,\n",
       "          0.01716055, -0.03129179,  0.02210318, -0.00763856, -0.01185228,\n",
       "          0.02286014, -0.015148  ,  0.01090136,  0.03119987,  0.01437744,\n",
       "         -0.02893924,  0.02492163,  0.00068974, -0.0290306 ,  0.02422849,\n",
       "         -0.03897793, -0.00558168,  0.02986824,  0.01962583,  0.03801197,\n",
       "          0.00515028, -0.03576968,  0.00880433, -0.00174228, -0.00433771,\n",
       "         -0.00596922, -0.00421319, -0.02665512,  0.00047489,  0.0252455 ,\n",
       "         -0.03695917,  0.04249984,  0.04223626,  0.01928376, -0.02251163,\n",
       "         -0.04177495, -0.04036105, -0.00241755, -0.04041989, -0.04394463,\n",
       "          0.0209752 , -0.01677481, -0.01434922,  0.03756178,  0.0339986 ,\n",
       "         -0.01475819, -0.00150892, -0.00465346,  0.05755317, -0.03063434,\n",
       "         -0.04043099, -0.00776022,  0.01666846,  0.02755723,  0.04062338,\n",
       "          0.01812606,  0.03581574,  0.01312847,  0.02662217, -0.01910956,\n",
       "         -0.0057831 , -0.02028622,  0.02439501, -0.03448098,  0.02446559,\n",
       "         -0.01719033, -0.00538096,  0.02028615, -0.0234428 ,  0.02691158,\n",
       "         -0.01763368,  0.02883337, -0.01983586,  0.02404872,  0.03522946,\n",
       "         -0.03870892, -0.02606579,  0.03441732, -0.00730069,  0.01304688,\n",
       "          0.02666728,  0.0038876 ,  0.01933186, -0.04447575,  0.04110255,\n",
       "          0.00560515, -0.03317725,  0.02993184, -0.05259449, -0.03227098,\n",
       "         -0.02790419, -0.00022396,  0.01634144,  0.0156265 , -0.02621982,\n",
       "          0.02197623, -0.03656571, -0.01726555, -0.02451211, -0.02124396,\n",
       "          0.01967535,  0.01398496,  0.01881584,  0.01904573,  0.04288313,\n",
       "          0.02198483, -0.00082708,  0.03267551,  0.02430348,  0.0346838 ,\n",
       "         -0.00154865,  0.02101795, -0.02658843, -0.04345846,  0.00640927,\n",
       "         -0.01378456, -0.02010082,  0.03848901,  0.02634178, -0.00469203,\n",
       "          0.00112814, -0.01769329,  0.00398537,  0.001254  ,  0.03967182,\n",
       "          0.03180812, -0.00221062, -0.00992519,  0.04531373, -0.02481619,\n",
       "         -0.02457934, -0.03970139, -0.01202787,  0.01647175, -0.01759485,\n",
       "         -0.01281888,  0.00390287, -0.01601625,  0.03485426,  0.02190861,\n",
       "         -0.00331934,  0.00315606, -0.0432646 , -0.04179256, -0.01480108,\n",
       "          0.00945797, -0.02337705, -0.02495179, -0.04389884, -0.00063064,\n",
       "         -0.04283638, -0.0140138 , -0.00574634, -0.03370302,  0.00182282,\n",
       "          0.02086026,  0.04471896, -0.01381675, -0.01746139, -0.00854573,\n",
       "          0.01110864, -0.01175901,  0.01622785,  0.04134926, -0.02028337,\n",
       "          0.03288531, -0.01310889,  0.03529964, -0.02401268, -0.02838335,\n",
       "         -0.00967614,  0.00710547,  0.04574275,  0.02295824,  0.00298734,\n",
       "          0.02232462, -0.03195285,  0.01929002, -0.02743396,  0.00228212,\n",
       "          0.00397826,  0.03332148,  0.01234418,  0.00486616,  0.02722218,\n",
       "          0.02162262, -0.00277472,  0.0111149 ,  0.01903716, -0.01068579,\n",
       "          0.00458995, -0.03050024,  0.02687844,  0.00619635, -0.01135294,\n",
       "          0.06147017,  0.02284286, -0.05581046,  0.05323876,  0.02677975,\n",
       "          0.00061301, -0.01916688,  0.03213945,  0.0514472 , -0.00184057,\n",
       "          0.0321573 ,  0.02523564, -0.01700413,  0.01681514,  0.01610643,\n",
       "          0.02949154,  0.04514711,  0.01466281,  0.00943039, -0.01380803,\n",
       "          0.00152088,  0.01334886, -0.02151216,  0.01413295,  0.01653396,\n",
       "          0.03861286, -0.00049577,  0.01021048,  0.00306707,  0.00234085,\n",
       "          0.05419075,  0.01703073, -0.02005885,  0.00917123, -0.01298603,\n",
       "         -0.00960745, -0.0227129 ,  0.01173973,  0.02280369,  0.04900493,\n",
       "         -0.00864672, -0.00677285, -0.00960083, -0.04472168, -0.01184289,\n",
       "         -0.00343511,  0.01085081, -0.01959818, -0.03798512,  0.00514082,\n",
       "         -0.03831154,  0.01201316, -0.02278364, -0.04898058,  0.02452075,\n",
       "         -0.00554843,  0.00134418,  0.01411446, -0.04585456,  0.01930311,\n",
       "          0.04196119,  0.03257865,  0.02778301,  0.04576403,  0.0238083 ,\n",
       "         -0.02057343,  0.0239289 ,  0.00214596,  0.01087225, -0.01532841,\n",
       "         -0.00634285, -0.00184954,  0.01376022,  0.03947552, -0.02551231,\n",
       "         -0.00993208, -0.03255296, -0.0287601 , -0.03724757, -0.03888183,\n",
       "         -0.05756763, -0.05022049,  0.02001023, -0.01526449,  0.01299849,\n",
       "          0.00216759,  0.04531367, -0.04211495,  0.00859302, -0.00607897,\n",
       "          0.00339873,  0.01609517,  0.0030354 , -0.02036855,  0.00594305,\n",
       "          0.02377253,  0.06122317, -0.03493308,  0.00671713, -0.00091423,\n",
       "         -0.0003144 , -0.03436369, -0.05810338, -0.0028588 , -0.03204131,\n",
       "          0.00990691, -0.00229941,  0.02232662, -0.01399088,  0.00062737,\n",
       "         -0.01223074, -0.03756443,  0.01565267,  0.03074179,  0.00572388,\n",
       "          0.02032265, -0.03692459,  0.04096838, -0.02198222, -0.04116685,\n",
       "         -0.01358214,  0.00920608,  0.00784411, -0.02822861, -0.0434928 ,\n",
       "          0.00379474,  0.02732721], dtype=float32)},\n",
       " {'topic_idx': 12,\n",
       "  'topic_words': array(['neural', 'neurobiology', 'neuronal', 'neurosciences',\n",
       "         'neurobiological', 'neurons', 'neuron', 'neuroscience', 'neurosci',\n",
       "         'neuro', 'neurol', 'neuroscientists', 'neurobiol', 'neurogenesis',\n",
       "         'neuroscientist', 'neuroethics', 'neurological', 'computational',\n",
       "         'neuroscientific', 'neuroimaging', 'networks', '알고리즘', 'computing',\n",
       "         'algorithms', 'neuroimage', 'computation', 'neurology',\n",
       "         'neurosurg', 'neurocultures', 'computationally', 'network',\n",
       "         'algorithmic', '네트워크', '신경망', 'brainstem', 'algorithm',\n",
       "         'cerebrospinal', 'sklearn', 'forebrain', 'computed', '신경',\n",
       "         'probabilistic', 'genome', 'brains', 'clustering', 'computers',\n",
       "         'brain', 'intelligence', 'cerebral', 'neurofeminist'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.01936227e-02,  5.49851283e-02, -1.93374921e-02,  2.06883699e-02,\n",
       "         -1.99053623e-02, -2.32264586e-02,  1.33874444e-02, -1.95260271e-02,\n",
       "          4.14541140e-02,  3.83038744e-02, -7.02644652e-03,  1.70651842e-02,\n",
       "          3.24571431e-02,  1.74451414e-02, -5.31142652e-02,  2.87786350e-02,\n",
       "          1.35354530e-02, -4.06724587e-02,  2.07232591e-02,  4.56147566e-02,\n",
       "         -1.23368260e-02, -4.39679138e-02,  9.37049845e-05,  4.34852391e-02,\n",
       "         -5.58582321e-02, -2.01008637e-02,  4.42429818e-02,  2.78550908e-02,\n",
       "         -2.20201630e-02, -1.19471597e-02, -1.07516535e-02,  3.85745056e-02,\n",
       "          1.47924982e-02, -5.25517762e-02, -3.12565044e-02, -2.27595549e-02,\n",
       "         -2.37403736e-02, -3.73073108e-02, -1.63991395e-02, -1.80883519e-02,\n",
       "         -4.29710373e-03,  3.72632518e-02,  3.92071642e-02,  3.56504857e-03,\n",
       "         -4.64726724e-02,  2.61332132e-02,  4.43759859e-02,  8.19431990e-03,\n",
       "         -3.05846818e-02, -7.70836486e-04,  2.08345316e-02, -3.28388251e-02,\n",
       "         -7.48561090e-03,  2.37980653e-02,  7.69058010e-03, -4.45750207e-02,\n",
       "          1.39479209e-02,  5.04290452e-03,  2.13626605e-02,  2.77902894e-02,\n",
       "         -2.40117460e-02,  5.05306944e-02, -2.26295665e-02, -4.76960614e-02,\n",
       "         -2.71686818e-02, -8.58027861e-03,  3.74184735e-02, -3.67919244e-02,\n",
       "         -5.31666260e-03, -8.85821786e-03, -2.22046059e-02,  1.10586695e-02,\n",
       "         -3.29582393e-03, -7.46941334e-03,  6.37689931e-03,  2.95778504e-04,\n",
       "          2.56226938e-02, -4.81964042e-03,  2.55944990e-02, -5.67915738e-02,\n",
       "         -6.03500307e-02, -5.08796461e-02,  1.88367944e-02,  2.70092916e-02,\n",
       "         -2.69228825e-04, -3.69287818e-03, -2.57871090e-03,  5.61764231e-03,\n",
       "          3.66824977e-02,  1.50810853e-02, -3.18420976e-02, -2.36108229e-02,\n",
       "         -3.29563245e-02, -5.63583486e-02,  2.09391881e-02,  4.92585003e-02,\n",
       "          3.16925496e-02,  3.02968025e-02,  2.19403990e-02,  5.17229724e-04,\n",
       "          4.15461361e-02,  5.05130142e-02,  7.05542602e-03, -4.69347276e-02,\n",
       "          3.14723291e-02, -1.88574679e-02, -5.67850210e-02, -8.75746924e-03,\n",
       "          2.64013577e-02,  3.53239886e-02,  5.94045827e-03, -5.14343232e-02,\n",
       "         -3.09188813e-02, -6.29588822e-03,  4.01186235e-02, -3.99462469e-02,\n",
       "         -2.52441317e-03,  2.48361640e-02, -4.06436548e-02,  2.63312012e-02,\n",
       "         -1.31369065e-02,  4.39693965e-02,  3.75201777e-02, -2.74190214e-02,\n",
       "          2.51956731e-02, -5.14291087e-03,  1.49017163e-02, -8.37946031e-03,\n",
       "         -2.23763864e-02,  1.30865192e-02, -4.24643792e-02,  1.82854626e-02,\n",
       "          3.32839787e-02,  3.55731994e-02, -1.88381728e-02,  5.84599450e-02,\n",
       "         -2.88417023e-02, -2.63027772e-02,  4.48809490e-02,  2.49596238e-02,\n",
       "          5.05856574e-02,  1.21965287e-02,  5.54220378e-02,  1.59249995e-02,\n",
       "          4.17655185e-02, -1.62021201e-02, -3.63881551e-02,  3.76417041e-02,\n",
       "         -8.65607802e-03,  2.75907088e-02,  1.71568170e-02,  4.12327237e-02,\n",
       "         -2.43860893e-02, -5.19627556e-02,  2.65987776e-02, -7.47941062e-03,\n",
       "         -2.11980771e-02, -4.26165760e-02, -6.38686307e-03, -2.09741648e-02,\n",
       "          5.38588651e-02, -2.53044367e-02, -4.66902256e-02, -1.24243451e-02,\n",
       "         -2.61932276e-02, -4.52288054e-03,  1.04179112e-02, -1.54287377e-02,\n",
       "         -5.16536683e-02,  3.83301899e-02, -3.45919654e-02, -1.41711496e-02,\n",
       "          1.00758038e-02,  9.23011452e-03, -2.89759897e-02,  1.24783255e-02,\n",
       "         -1.87135525e-02,  7.42580369e-03, -3.98700014e-02,  2.00805999e-02,\n",
       "          7.92887993e-03, -5.40301343e-03, -4.49664379e-03, -2.85536144e-02,\n",
       "         -3.97906154e-02,  1.62949152e-02,  2.73976009e-02,  5.23445122e-02,\n",
       "          2.29093130e-04,  1.66344997e-02, -8.44834023e-04, -5.90881752e-03,\n",
       "          4.29174155e-02,  8.66499171e-03, -1.17886011e-02,  2.69000120e-02,\n",
       "         -5.15449867e-02,  2.68439073e-02,  5.06826080e-02,  3.99959609e-02,\n",
       "         -1.57606918e-02,  2.84515079e-02, -1.50721548e-02, -2.76506916e-02,\n",
       "          1.50888599e-02, -3.16742957e-02, -2.52345204e-02, -3.93166533e-03,\n",
       "          2.49241069e-02,  1.90467257e-02,  2.01166868e-02,  4.67200344e-03,\n",
       "         -4.26270217e-02,  6.86341804e-03,  5.08619212e-02, -1.79855842e-02,\n",
       "          1.04489615e-02, -4.16754037e-02, -1.86971705e-02, -4.10447605e-02,\n",
       "         -1.02113176e-03,  2.77887415e-02,  7.42495526e-04, -1.21124424e-02,\n",
       "         -4.24490310e-02, -1.08343745e-02, -5.51623404e-02,  2.23500058e-02,\n",
       "          8.06447701e-04,  2.93387771e-02, -2.92625614e-02,  4.48814481e-02,\n",
       "         -3.71088050e-02,  3.68646644e-02,  3.71169373e-02,  1.82270482e-02,\n",
       "          2.86459690e-03,  3.99419107e-02,  5.37663586e-02, -3.45474035e-02,\n",
       "         -8.36462341e-03,  3.34797315e-02, -1.23529695e-02, -6.97996002e-04,\n",
       "          1.44962873e-02, -3.23690325e-02,  4.32342291e-02, -1.65454652e-02,\n",
       "         -5.77060319e-03, -5.05706528e-03, -4.19995040e-02, -3.47329490e-02,\n",
       "          5.33530228e-02,  3.15524568e-03,  1.52401580e-02, -2.84043769e-03,\n",
       "          1.92635413e-02, -5.09384042e-03, -2.42594965e-02, -2.21850257e-02,\n",
       "         -3.15270945e-02,  1.19616054e-02, -1.14793172e-02, -1.26410397e-02,\n",
       "         -5.30391978e-03, -5.12986332e-02, -4.24970547e-03,  3.47599052e-02,\n",
       "          8.29802360e-03,  3.11607402e-02, -1.56070921e-03, -3.25931422e-02,\n",
       "         -2.38032695e-02, -3.53062376e-02,  9.11826082e-03,  3.01796608e-02,\n",
       "         -4.48887721e-02,  3.98652218e-02, -4.84103821e-02, -3.51910144e-02,\n",
       "         -3.07773799e-02, -2.39641406e-02,  1.57535207e-02,  3.60623449e-02,\n",
       "         -3.00284084e-02,  4.68364917e-02, -2.87420135e-02, -3.50907296e-02,\n",
       "          1.32289026e-02,  8.98129027e-03,  5.01543619e-02,  1.10496506e-02,\n",
       "          5.23996400e-03, -1.30921258e-02, -5.12803346e-02, -3.70950578e-03,\n",
       "         -1.47841191e-02,  9.43176821e-03,  2.85133701e-02,  5.40438890e-02,\n",
       "         -1.96444970e-02,  1.09443627e-02,  1.35712205e-02, -4.97957245e-02,\n",
       "         -3.81197780e-02, -2.78195851e-02, -3.28631327e-02,  3.05186529e-02,\n",
       "         -9.43106133e-04,  4.04794551e-02, -2.91964132e-02, -3.77496792e-04,\n",
       "         -2.89595909e-02, -3.59421112e-02,  2.39511877e-02,  2.06191614e-02,\n",
       "         -3.03632393e-02, -9.72882006e-03,  4.13624160e-02, -3.18560414e-02,\n",
       "          3.10893767e-02, -3.09419408e-02, -1.93577521e-02, -1.46099739e-02,\n",
       "         -4.23193537e-02, -8.33431352e-03,  1.89425573e-02, -1.56681854e-02,\n",
       "          4.47685225e-03,  2.60801073e-02, -3.05195134e-02, -3.34796421e-02,\n",
       "          1.74339954e-03, -2.58168746e-02, -1.46730719e-02, -8.31383001e-03,\n",
       "         -4.17510904e-02, -3.21615152e-02, -5.47090061e-02,  2.44351681e-02,\n",
       "         -5.01088351e-02,  1.09848594e-02, -1.64989308e-02, -2.62775365e-02,\n",
       "          1.70409624e-02,  4.34895605e-02,  3.15706469e-02,  2.58731507e-02,\n",
       "         -2.50341953e-03,  1.57897994e-02,  7.39740254e-03,  1.28859479e-03,\n",
       "          3.84756015e-04,  2.94724330e-02, -4.23891917e-02,  1.17738200e-02,\n",
       "          1.66239776e-02,  2.50744559e-02, -2.40732189e-02, -2.67619845e-02,\n",
       "          3.33779342e-02, -1.59520451e-02,  4.16398682e-02, -3.61946225e-02,\n",
       "         -4.32099216e-02,  1.79381855e-02, -5.55325765e-03,  4.11008783e-02,\n",
       "         -2.45240834e-02, -2.87066703e-03,  2.66782306e-02,  4.31773029e-02,\n",
       "         -4.01081517e-02,  3.81364711e-02,  2.58156117e-02, -4.41045426e-02,\n",
       "         -4.24839221e-02, -9.50638577e-03, -4.20647375e-02, -4.15711068e-02,\n",
       "         -5.40285418e-03,  9.01145511e-04,  4.56969626e-02,  2.22259443e-02,\n",
       "         -2.68500261e-02,  5.07030934e-02,  3.23050581e-02, -4.57149893e-02,\n",
       "          5.73642105e-02, -1.12300860e-02,  1.71203259e-02, -4.46263999e-02,\n",
       "         -1.78557821e-02,  3.71400006e-02, -2.47575957e-02,  3.78590007e-03,\n",
       "          3.27798910e-02, -5.67281386e-03, -5.49922176e-02,  2.25747470e-02,\n",
       "          4.62009870e-02,  4.03977819e-02,  5.13218790e-02,  8.46653245e-03,\n",
       "         -4.82244156e-02,  1.06712161e-02,  1.68988518e-02, -2.06525922e-02,\n",
       "          3.71374711e-02,  1.85105782e-02,  1.09151471e-02, -2.97471276e-03,\n",
       "          7.50872912e-03,  1.11983987e-02,  1.92860439e-02,  5.10260910e-02,\n",
       "          7.13587506e-03, -5.41373948e-03, -5.69847086e-03,  3.49506475e-02,\n",
       "          1.27157830e-02, -2.49080043e-02,  4.32375818e-02,  4.73723747e-02,\n",
       "          5.15603200e-02,  2.46810075e-02,  2.36408226e-02, -4.94609065e-02,\n",
       "         -4.40531410e-02, -3.10103386e-03, -2.80805323e-02, -9.41816904e-03,\n",
       "         -1.55680105e-02, -4.49999981e-03,  2.89266389e-02,  3.91798653e-02,\n",
       "          2.55088490e-02, -5.68260532e-03, -5.60093075e-02,  3.66905890e-02,\n",
       "         -1.95784848e-02,  1.38566401e-02,  7.13023916e-03, -4.98172268e-02,\n",
       "         -2.75930995e-03, -2.67777462e-02,  1.57189667e-02,  1.86030734e-02,\n",
       "          4.29656208e-02,  8.34928267e-03, -4.33504358e-02, -2.76171453e-02,\n",
       "         -7.19773630e-03, -4.94821323e-03, -2.56826002e-02, -2.84958575e-02,\n",
       "          4.06053960e-02,  1.77553147e-02,  4.21572104e-03,  2.81814095e-02,\n",
       "          1.19936792e-02, -5.18247932e-02, -1.64949670e-02, -3.72891277e-02,\n",
       "          2.67156083e-02, -5.46421036e-02, -2.98796240e-02,  1.88681053e-03,\n",
       "          5.28547727e-02, -5.22456020e-02,  8.38164706e-03,  5.70324287e-02,\n",
       "         -2.54601128e-02, -1.87975597e-02,  4.64537734e-05, -2.07361095e-02,\n",
       "          5.01166156e-04,  2.61480883e-02,  4.09707148e-03, -1.00994203e-02,\n",
       "          3.63143533e-02,  5.64153008e-02, -3.94507609e-02,  2.91209631e-02,\n",
       "          4.80115451e-02, -3.35900672e-02,  5.01035014e-03, -5.03799058e-02,\n",
       "         -5.60633950e-02,  6.66430965e-03,  4.51829880e-02,  2.95052286e-02,\n",
       "          1.54696377e-02, -1.08927842e-02, -3.22574400e-03, -2.44722739e-02,\n",
       "         -2.98255798e-03, -1.69919617e-02,  1.65901892e-02,  9.34622996e-03,\n",
       "          4.60062996e-02, -5.84982596e-02,  5.34385927e-02, -2.67316028e-02,\n",
       "         -4.31293584e-02, -5.41299246e-02, -3.83846834e-02, -4.75674914e-03,\n",
       "         -4.45051081e-02, -5.62102161e-02,  1.17526380e-02,  1.13272211e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 13,\n",
       "  'topic_words': array(['statistics', 'statistical', 'statistically', '통계청', 'datasets',\n",
       "         '통계', 'dataset', 'statistic', 'probabilistic', 'regression',\n",
       "         'stats', 'data', 'predictive', '파라미터', 'dataframe', 'correlations',\n",
       "         'predictor', 'parametric', 'correlation', 'predicts', '데이터',\n",
       "         'nonparametric', 'multivariate', 'models', 'parameters',\n",
       "         'predictors', 'predict', 'correlates', 'stat', 'correlate',\n",
       "         'analytics', 'predicting', 'variability', 'correlated', '예측',\n",
       "         'coefficient', 'asymptotic', 'neurobiological', 'paradigms', '모델',\n",
       "         'pathology', 'neurobiology', 'variance', 'patients',\n",
       "         'undergraduate', 'predictions', 'paradigm', 'modelling',\n",
       "         'percentage', 'quantitative'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.56586087e-02,  3.09141129e-02, -8.37340858e-03,  1.83821078e-02,\n",
       "         -1.36303976e-02, -3.98785435e-02,  3.00379414e-02, -7.31890835e-03,\n",
       "          3.76680829e-02,  3.23656797e-02,  1.52654536e-02,  2.28146333e-02,\n",
       "          3.61334123e-02,  1.37139997e-02, -3.26743089e-02, -3.55621189e-04,\n",
       "          6.96032634e-03, -1.51765570e-02,  3.48255262e-02,  2.40437146e-02,\n",
       "         -2.52715172e-03, -2.33259168e-03, -3.38278674e-02,  2.90519875e-02,\n",
       "         -5.68615347e-02, -2.84612309e-02,  3.15824314e-03, -3.25714611e-03,\n",
       "         -7.23697012e-03, -2.92012412e-02, -1.19215520e-02,  4.70178621e-03,\n",
       "          3.40490118e-02, -5.29230572e-02, -3.35477479e-02,  6.04904676e-03,\n",
       "          2.98592802e-02,  3.27684321e-02,  2.66095176e-02,  5.54646971e-03,\n",
       "         -1.34004643e-02,  2.18914244e-02,  2.75191721e-02, -2.42358241e-02,\n",
       "         -1.30122714e-02, -1.75152142e-02,  2.86505818e-02,  2.17587221e-02,\n",
       "         -2.45118681e-02, -3.48612517e-02, -1.88030284e-02, -2.57907882e-02,\n",
       "         -1.49582028e-02, -1.73305627e-02,  3.70285325e-02, -5.72230630e-02,\n",
       "          1.74583513e-02,  1.48391193e-02,  5.61930286e-03,  3.98163609e-02,\n",
       "          1.27817197e-02,  5.44452369e-02,  2.55191177e-02, -4.62888815e-02,\n",
       "          6.88757934e-03,  7.00641715e-04,  4.86214012e-02, -2.35645622e-02,\n",
       "         -1.83492694e-02, -2.34446325e-03, -3.96262333e-02,  1.81887485e-02,\n",
       "         -1.69248376e-02, -2.21504569e-02, -1.67513266e-02, -1.66495834e-02,\n",
       "          3.04314345e-02,  4.75486256e-02,  2.15101216e-04, -6.06606938e-02,\n",
       "         -5.99987097e-02, -2.54202578e-02, -2.42565945e-02,  2.20057946e-02,\n",
       "          4.35382500e-03, -1.52417468e-02, -3.46745364e-02, -3.80991027e-03,\n",
       "         -3.74391885e-03, -4.47220681e-03, -3.88947837e-02, -3.38276140e-02,\n",
       "         -5.58932684e-03, -5.22791930e-02,  2.75277328e-02,  5.08342385e-02,\n",
       "         -1.90216620e-02,  3.60056795e-02, -3.54135263e-04,  1.94522291e-02,\n",
       "          3.80433165e-02,  2.57799658e-03,  2.97884140e-02, -2.62437668e-02,\n",
       "          1.48307057e-02, -1.16987349e-02, -5.84639721e-02, -1.05944788e-02,\n",
       "          2.96086725e-02,  4.41629291e-02,  1.99301634e-02, -4.37618680e-02,\n",
       "         -2.35852953e-02, -1.45238778e-02,  2.68086623e-02, -2.53619459e-02,\n",
       "          1.01843430e-03,  9.49969608e-03, -1.33429014e-03,  1.93994995e-02,\n",
       "         -1.48376897e-02,  1.29337388e-03,  2.10053772e-02,  3.52958031e-02,\n",
       "          4.08189334e-02,  5.51774725e-03,  2.09580641e-03,  1.62669215e-02,\n",
       "         -2.57935654e-02,  1.58968978e-02, -4.97864373e-02, -1.59077477e-02,\n",
       "          3.24147642e-02,  3.44383232e-02,  2.08316315e-02,  6.03870004e-02,\n",
       "          1.19364290e-02, -2.14530379e-02,  5.38022481e-02,  1.45293055e-02,\n",
       "         -7.35260604e-04, -3.05410028e-02,  1.13248369e-02,  8.43836274e-03,\n",
       "          2.55862381e-02, -4.39038314e-03, -2.67179962e-02,  4.58778292e-02,\n",
       "          2.30224710e-02,  3.46728489e-02,  4.83204424e-02,  5.87502203e-04,\n",
       "         -3.96913178e-02, -1.64522473e-02,  9.81210638e-03, -1.80884078e-02,\n",
       "         -5.18699549e-03, -3.11820265e-02,  1.49510317e-02, -2.46481616e-02,\n",
       "          3.84544097e-02, -2.57149544e-02,  3.22262873e-03, -2.81270761e-02,\n",
       "         -2.34718230e-02, -1.44568540e-03, -3.33166681e-03, -5.47057204e-03,\n",
       "         -3.40152457e-02,  4.36052531e-02, -2.05139574e-02, -1.77489463e-02,\n",
       "          1.13491779e-02,  4.11994336e-03,  5.59584191e-03,  1.31458379e-02,\n",
       "         -1.68489944e-02,  6.61603874e-03, -3.49386334e-02,  3.63193862e-02,\n",
       "          3.77133787e-02, -2.25148946e-02, -1.64183434e-02, -1.47529272e-02,\n",
       "         -4.18881476e-02, -2.19092201e-02,  2.61884499e-02,  3.64279337e-02,\n",
       "         -1.49025125e-02, -1.09151797e-03,  2.00216249e-02, -6.75006351e-03,\n",
       "          3.93734351e-02, -1.54528907e-02,  1.09730624e-02,  1.29032508e-02,\n",
       "         -3.64373885e-02, -1.51404105e-02,  5.46230376e-02,  3.88333644e-03,\n",
       "         -4.50233258e-02,  5.73007250e-03, -4.54013385e-02, -2.51575708e-02,\n",
       "         -2.35034321e-02,  6.81385398e-04, -2.65200790e-02, -2.75503173e-02,\n",
       "         -8.66061170e-03,  2.07233354e-02,  8.52360856e-04, -3.26747634e-03,\n",
       "         -4.70020473e-02,  2.20682342e-02,  4.12659049e-02, -1.84679264e-03,\n",
       "         -1.93083491e-02, -3.58566567e-02, -1.41808549e-02, -3.20753790e-02,\n",
       "         -1.27152633e-03,  3.40727940e-02,  3.24396752e-02, -6.86823251e-03,\n",
       "         -3.24036367e-02, -2.87823100e-02, -5.39868623e-02, -1.55373467e-02,\n",
       "          1.26882838e-02,  1.22388368e-02, -1.63406339e-02,  1.26895532e-02,\n",
       "         -2.02678572e-02,  1.38757462e-02,  2.92054471e-02,  1.52331693e-02,\n",
       "         -1.06357289e-02,  3.57346199e-02,  5.85912131e-02, -1.13290772e-02,\n",
       "         -1.83485716e-03,  3.61242821e-03, -8.26873293e-04,  1.70078371e-02,\n",
       "          4.80477400e-02, -2.25959513e-02,  3.10888290e-02, -8.33128951e-03,\n",
       "          1.15792826e-02, -1.47386044e-02, -1.64052267e-02, -2.71903891e-02,\n",
       "          1.08086700e-02, -2.47649327e-02,  1.24453688e-02, -2.91364864e-02,\n",
       "         -2.28087697e-02,  1.45838587e-02, -1.64209846e-02, -1.27303666e-02,\n",
       "          4.42086486e-03,  1.87721122e-02, -3.47099081e-02, -1.86949652e-02,\n",
       "          7.96043966e-03, -3.98562588e-02, -2.09853258e-02,  9.64037434e-04,\n",
       "          1.09350504e-02,  7.67174782e-03,  1.48612140e-02, -9.52597801e-03,\n",
       "         -3.94249009e-03, -1.80909168e-02,  2.17265245e-02,  2.01109815e-02,\n",
       "         -3.89754735e-02,  5.17243743e-02, -3.62457298e-02, -1.14497719e-02,\n",
       "         -3.92405428e-02,  1.17437541e-03,  1.60432830e-02,  2.48912573e-02,\n",
       "         -1.67142153e-02,  3.21631730e-02, -3.42482850e-02, -9.97760054e-03,\n",
       "         -2.44746450e-02,  4.62631620e-02,  2.13884115e-02,  2.05233414e-02,\n",
       "          2.06373241e-02,  1.84305944e-02, -3.22917216e-02,  6.55085407e-03,\n",
       "          5.84049449e-05,  2.24389080e-02,  1.53132984e-02,  5.08948602e-02,\n",
       "         -2.19916180e-02,  3.05523630e-02, -2.81885657e-02, -3.80663835e-02,\n",
       "         -4.03229967e-02, -1.63176730e-02, -1.52299581e-02,  2.21803412e-02,\n",
       "          5.35044121e-03,  2.89244503e-02, -2.29344573e-02, -8.02464876e-03,\n",
       "         -4.86598425e-02, -3.27400900e-02,  4.14677262e-02,  2.60197520e-02,\n",
       "          1.57363936e-02, -3.58269848e-02,  2.91364342e-02, -3.34181525e-02,\n",
       "         -1.22805089e-02, -3.42891249e-03, -3.14399414e-02, -8.32782965e-03,\n",
       "         -2.27976069e-02, -1.78498756e-02, -2.74240132e-03, -3.03736757e-02,\n",
       "          5.02993353e-05, -9.42400843e-03, -2.97808293e-02, -2.69884262e-02,\n",
       "         -2.00063363e-03, -4.40790020e-02, -1.42794810e-02, -2.13380507e-03,\n",
       "         -2.34705433e-02, -1.30883828e-02, -5.41514643e-02, -2.57221833e-02,\n",
       "         -4.21393774e-02, -5.90967305e-04,  2.47384864e-03, -3.35634910e-02,\n",
       "         -2.26921048e-02,  1.55889029e-02,  4.72777188e-02,  2.18566656e-02,\n",
       "         -1.82112511e-02,  1.15455939e-02, -1.61056966e-03,  1.27812726e-02,\n",
       "          2.06426773e-02, -1.09834140e-02, -2.65106577e-02,  5.70810540e-03,\n",
       "          1.20994158e-03,  1.91106964e-02, -2.37379093e-02, -2.41298880e-02,\n",
       "          3.72404791e-02, -1.82581972e-02,  4.81933914e-02, -2.16323975e-02,\n",
       "         -2.01574732e-02,  2.50394735e-02,  4.47567319e-03,  3.64616327e-02,\n",
       "         -3.38969119e-02, -4.25435537e-05,  1.80907827e-02,  4.11312506e-02,\n",
       "         -2.82805357e-02,  2.58288477e-02,  7.21368333e-03, -3.79129164e-02,\n",
       "          3.69307841e-03, -1.89785510e-02, -1.99805666e-02, -4.18161042e-02,\n",
       "          1.03976252e-02, -1.63612701e-02,  1.43184066e-02,  1.43057080e-02,\n",
       "         -2.12003961e-02,  4.85721491e-02,  9.38868709e-03, -3.34620029e-02,\n",
       "          4.72338907e-02,  7.74280727e-03,  1.62160005e-02, -3.32419984e-02,\n",
       "         -1.74152907e-02,  4.63035256e-02, -3.63351814e-02, -2.00997703e-02,\n",
       "          4.69170511e-02,  3.18798572e-02, -4.63570394e-02,  1.39662623e-03,\n",
       "          3.95425260e-02,  4.45986502e-02,  4.96714748e-02,  6.60517020e-03,\n",
       "         -2.71782149e-02,  1.93133280e-02,  1.16541311e-02, -8.08246899e-03,\n",
       "          3.89032881e-03, -3.22256773e-03,  3.06103681e-03, -1.74706131e-02,\n",
       "          2.82504577e-02,  1.77355856e-03,  3.09662465e-02,  4.77623791e-02,\n",
       "          8.25101882e-03,  1.86999247e-03,  6.53127907e-03, -2.06011720e-02,\n",
       "         -7.55261490e-03, -4.23801579e-02,  5.89440065e-03,  5.04780374e-02,\n",
       "          4.84647788e-02,  5.73722878e-03, -2.74948422e-02, -3.39103751e-02,\n",
       "         -1.48695186e-02, -2.16102991e-02, -2.18548477e-02,  1.30024813e-02,\n",
       "         -3.69045772e-02, -1.66117046e-02,  3.68905999e-02,  1.94089394e-02,\n",
       "          2.56951656e-02, -8.12849670e-04, -4.73279171e-02,  1.55202476e-02,\n",
       "         -5.43705234e-03,  2.53173485e-02,  8.09774920e-03, -4.39758003e-02,\n",
       "          2.76215305e-03, -2.46945042e-02,  3.11969239e-02, -1.69094687e-03,\n",
       "          3.47203203e-03,  1.99767295e-02,  2.96240137e-03, -2.72917319e-02,\n",
       "         -5.36960251e-05, -1.27303926e-02, -2.96176877e-02,  1.47309154e-04,\n",
       "          2.67253462e-02,  5.78221167e-03, -1.30721861e-02,  3.68731096e-02,\n",
       "         -1.47713581e-02,  4.53498360e-04, -1.07565783e-02, -5.94567247e-02,\n",
       "          2.00586449e-02, -4.95473780e-02,  1.03000188e-02, -3.45208086e-02,\n",
       "          5.79874963e-02, -2.82359198e-02,  3.97143848e-02,  4.55318950e-02,\n",
       "          1.43156142e-03,  3.20802722e-03, -1.73956770e-02, -3.56992446e-02,\n",
       "          2.87807640e-02, -1.85854752e-02, -2.84842011e-02, -1.98062733e-02,\n",
       "          6.03900068e-02,  5.96287437e-02, -4.17951383e-02,  8.30142107e-03,\n",
       "          3.17049734e-02,  1.77282898e-03, -2.37943679e-02, -5.54422438e-02,\n",
       "         -2.50568092e-02, -1.50324358e-02,  1.45383691e-02,  2.35650558e-02,\n",
       "          2.81887297e-02, -1.96908507e-02, -1.95051339e-02, -3.48284468e-02,\n",
       "         -6.67872326e-03, -1.18995048e-02,  1.54541628e-02, -7.03573925e-03,\n",
       "          2.26521716e-02, -5.24534434e-02,  5.03043830e-02, -1.95964798e-02,\n",
       "         -4.01128270e-02, -4.66744453e-02,  8.85921996e-03, -3.80969979e-02,\n",
       "         -2.63840780e-02, -3.69547494e-02,  1.02553153e-02,  2.23571453e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 14,\n",
       "  'topic_words': array(['epidemic', '전염병', '감염자', '백신', '면역', 'prevalence', 'deaths',\n",
       "         '감염병', '사망', '전염', 'diseases', 'fatalities', '피해자', 'disease',\n",
       "         'population', '감염증', '감염', 'populations', 'infected', 'injuries',\n",
       "         '병원', 'illness', '손상', 'disorders', 'seoul', '신종', 'lesions', '증상',\n",
       "         'affected', '통계청', 'immune', 'suffering', '인구', '서울', '회복', '한국',\n",
       "         'death', 'deviation', 'psychosis', 'psychiatric', 'lesion',\n",
       "         'abnormalities', 'causal', 'widespread', 'transcranial',\n",
       "         'neuroimage', 'severity', 'neuroscientist', '서울대', 'statistics'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([ 0.01356217,  0.01784475,  0.0186967 , -0.00543488,  0.02329581,\n",
       "          0.02293354,  0.0080959 ,  0.00965842,  0.00342752,  0.03306086,\n",
       "          0.00708939, -0.00374879, -0.00190949,  0.01184197, -0.00574947,\n",
       "         -0.00590852, -0.01335737, -0.04506424, -0.03182342,  0.05104519,\n",
       "         -0.0040788 , -0.040461  ,  0.02327451, -0.00501904, -0.05968439,\n",
       "          0.00483894,  0.01017583,  0.00632113,  0.03084633, -0.04995514,\n",
       "         -0.02024567, -0.01993893,  0.00349054, -0.01582441, -0.00431878,\n",
       "         -0.03059142,  0.00577182, -0.01784447, -0.01429698, -0.03336627,\n",
       "          0.01249847,  0.03452085,  0.02414366, -0.02322575,  0.00584471,\n",
       "         -0.0423785 , -0.00999095, -0.03441707, -0.01351073,  0.00136928,\n",
       "         -0.0165942 , -0.04063417,  0.01456865, -0.00629183,  0.02656449,\n",
       "         -0.06138166,  0.02961049,  0.00792831, -0.0277528 ,  0.02176072,\n",
       "          0.00656047,  0.05785326, -0.00321499, -0.03437722, -0.00842925,\n",
       "          0.00742587,  0.03810759, -0.04341246, -0.02012716,  0.0239448 ,\n",
       "          0.01628476,  0.04561068,  0.02742324, -0.01805626,  0.00300642,\n",
       "          0.01220598,  0.02810374,  0.0219018 ,  0.00346398, -0.05763334,\n",
       "         -0.06289966, -0.03444513,  0.02768575,  0.02727374, -0.03565984,\n",
       "         -0.02489766, -0.05703703, -0.00481196, -0.00308713, -0.00817133,\n",
       "         -0.0313581 , -0.00932331, -0.01234478, -0.00098596,  0.00763287,\n",
       "          0.00895363,  0.03955555,  0.04684729,  0.00713655, -0.00442603,\n",
       "         -0.00215684,  0.01298542, -0.01436085,  0.00823325, -0.01298067,\n",
       "          0.03896195, -0.03357022, -0.02391803, -0.00119068, -0.02102182,\n",
       "          0.0265584 , -0.00068481,  0.026078  ,  0.01592085,  0.01436412,\n",
       "          0.00715136, -0.01580276,  0.00608518, -0.01759621, -0.01952368,\n",
       "          0.006532  ,  0.03339169,  0.03956645, -0.01879594,  0.0058704 ,\n",
       "          0.04076977,  0.01786668,  0.00222819, -0.02431671,  0.02249664,\n",
       "         -0.03435427, -0.02537799,  0.0079722 , -0.02087605,  0.00466985,\n",
       "          0.06232704,  0.02134051, -0.00017426,  0.05529028,  0.02822317,\n",
       "          0.03463769, -0.00083981,  0.02233557,  0.02569297,  0.03359197,\n",
       "         -0.04383337,  0.04748956,  0.00982202,  0.04260309,  0.02058433,\n",
       "          0.04246473,  0.02965417, -0.0366297 ,  0.01102567, -0.0037961 ,\n",
       "         -0.02118804, -0.01829354, -0.03019952,  0.02265107, -0.01822472,\n",
       "          0.01299034, -0.04512118,  0.00147899,  0.01458268, -0.00902645,\n",
       "         -0.03714502,  0.02565395, -0.0108582 , -0.03149157, -0.03430447,\n",
       "          0.00449874,  0.02781768, -0.02510144,  0.01841411,  0.00641786,\n",
       "          0.02467106, -0.00790562, -0.00014685, -0.04321769,  0.04816478,\n",
       "          0.04268954, -0.04267089,  0.01732467,  0.00658098,  0.00409519,\n",
       "          0.01404068,  0.01720374,  0.0566478 , -0.03934181,  0.01043819,\n",
       "         -0.0128266 , -0.01054832,  0.0101934 , -0.01517919, -0.02104486,\n",
       "          0.03136116,  0.02202222, -0.00427039,  0.02872632,  0.00617225,\n",
       "         -0.03953964,  0.00084344,  0.01326574, -0.04133298, -0.02497532,\n",
       "         -0.02963011,  0.01733828,  0.00695927,  0.00840748,  0.03220756,\n",
       "         -0.02327903,  0.00715014, -0.04066182,  0.00041538,  0.00608874,\n",
       "          0.0106588 , -0.00240159, -0.01557001, -0.02618228,  0.02406727,\n",
       "         -0.03889657,  0.01307766,  0.03061376,  0.01686161,  0.01371853,\n",
       "         -0.02841482, -0.02503618,  0.00845601, -0.01758153, -0.01368811,\n",
       "          0.02345863, -0.05438339, -0.03117243,  0.03737797,  0.02009214,\n",
       "         -0.01305983, -0.01663432, -0.0010009 ,  0.04558428, -0.00853578,\n",
       "          0.00898869, -0.02441647,  0.0207704 ,  0.02977971,  0.02703204,\n",
       "         -0.00728338,  0.04527952, -0.00445561,  0.01175845, -0.02948416,\n",
       "         -0.03738758, -0.03772429,  0.00275061,  0.02605927, -0.0045765 ,\n",
       "         -0.03324271, -0.03367671,  0.0377453 , -0.02191093,  0.0557455 ,\n",
       "          0.01983404,  0.05031499, -0.0239551 , -0.00755989,  0.027005  ,\n",
       "         -0.0452721 , -0.03072124,  0.03988719, -0.00135733,  0.00634654,\n",
       "         -0.02905628, -0.01016284, -0.00236217, -0.02780619,  0.00947418,\n",
       "          0.02494047,  0.03416291, -0.03802854, -0.0514842 , -0.03839449,\n",
       "         -0.00856818, -0.012922  ,  0.02530218, -0.01271354, -0.00878788,\n",
       "         -0.01167561, -0.0466507 ,  0.0172027 , -0.02552777, -0.0024419 ,\n",
       "         -0.02372601,  0.00648721, -0.01661353,  0.02705407,  0.00445466,\n",
       "          0.02822369, -0.00461506, -0.01320646,  0.02657728,  0.03346913,\n",
       "          0.01535027,  0.0281397 , -0.02385608, -0.02835777,  0.00438344,\n",
       "         -0.02227215,  0.02382155,  0.03167069,  0.02904144, -0.00267483,\n",
       "         -0.01587851,  0.00220229, -0.02378201,  0.0280338 ,  0.05283779,\n",
       "          0.03777362, -0.02704638, -0.01920974,  0.03633344, -0.01755832,\n",
       "          0.01687335, -0.03582668,  0.00014187,  0.02188394, -0.03618787,\n",
       "          0.00083673,  0.01180951,  0.00515807,  0.02030977,  0.01692517,\n",
       "         -0.03249053,  0.01474088, -0.04267536,  0.00857082, -0.00113721,\n",
       "         -0.02541542, -0.00963581,  0.02767244, -0.04658796, -0.01996558,\n",
       "         -0.0237668 ,  0.00816531, -0.02765856, -0.01974875, -0.02058936,\n",
       "          0.00963233,  0.02065243, -0.02114116,  0.01071065,  0.02644814,\n",
       "          0.0048261 ,  0.01417688,  0.01797364,  0.01725327,  0.02301846,\n",
       "          0.02279121, -0.0075913 ,  0.02838266, -0.02949465, -0.03610678,\n",
       "          0.03767486, -0.00068554,  0.05335697,  0.04913269, -0.01248229,\n",
       "          0.00042859, -0.04911083, -0.01880219,  0.01403839,  0.0331299 ,\n",
       "         -0.00823864,  0.03318702, -0.00895845,  0.01371854,  0.01340465,\n",
       "          0.01992756, -0.00950619, -0.01047838,  0.02886539, -0.01304831,\n",
       "          0.02130996, -0.01199427, -0.00179752,  0.03324361, -0.01041076,\n",
       "          0.05278682,  0.01717257, -0.0462338 ,  0.05309185,  0.03006958,\n",
       "         -0.02295686, -0.00467945,  0.00197189,  0.04469904,  0.03275262,\n",
       "         -0.03344884, -0.03325194,  0.02312166, -0.00383359,  0.01738466,\n",
       "          0.0296778 ,  0.05229175,  0.03515076, -0.00943948, -0.0179181 ,\n",
       "          0.03705275, -0.0072392 , -0.00315735,  0.01900793,  0.01057576,\n",
       "          0.02734109, -0.02136924,  0.00109414,  0.04764005,  0.02883991,\n",
       "          0.04963986,  0.02090428,  0.01952848, -0.01417573, -0.02318555,\n",
       "         -0.01099397,  0.02653518, -0.03218616,  0.033772  ,  0.04763177,\n",
       "          0.00405611,  0.01723121, -0.03023511, -0.00521204, -0.00463078,\n",
       "         -0.01602098, -0.00624082,  0.0145328 , -0.01566656,  0.03108763,\n",
       "         -0.02332673,  0.02352254,  0.01492971, -0.05483672,  0.03668899,\n",
       "         -0.00774065,  0.01559521, -0.03642863, -0.05196171, -0.00403213,\n",
       "          0.02833767,  0.05118443, -0.019319  , -0.01557669,  0.02284072,\n",
       "         -0.00240389,  0.03879841,  0.04281585,  0.00483688, -0.04671172,\n",
       "         -0.02007664,  0.02806322, -0.01819533, -0.02036754, -0.01003102,\n",
       "          0.00062942,  0.00341683, -0.02452909, -0.01092985,  0.00485288,\n",
       "         -0.05968919, -0.03266066,  0.03788279, -0.00502273, -0.00505722,\n",
       "          0.03237084,  0.01122112, -0.02674289,  0.01517928, -0.02405666,\n",
       "         -0.04791683,  0.03566859, -0.02422657, -0.02802196, -0.02160769,\n",
       "          0.0545572 ,  0.06467769, -0.03078134, -0.00304907, -0.02935583,\n",
       "          0.00741255, -0.00491758, -0.05730985, -0.0282287 ,  0.01669424,\n",
       "          0.03475291,  0.01304642,  0.0267207 ,  0.00547287, -0.00104999,\n",
       "         -0.00899938, -0.02133838,  0.01112822,  0.01474024,  0.01834607,\n",
       "          0.02155341, -0.01383553,  0.04711889, -0.0024009 , -0.05789081,\n",
       "         -0.0280527 , -0.00537064, -0.01111587, -0.01433482, -0.04718057,\n",
       "         -0.00655186, -0.00617672], dtype=float32)}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tm_model.get_topics_info_as_dict_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0, 'x': 9.661947, 'y': 7.911528, 'topic_idx': 8},\n",
       " {'id': 1, 'x': 9.733882, 'y': 9.075437, 'topic_idx': 2},\n",
       " {'id': 2, 'x': 10.371698, 'y': 8.945484, 'topic_idx': 13},\n",
       " {'id': 3, 'x': 9.234382, 'y': 8.37953, 'topic_idx': 8},\n",
       " {'id': 4, 'x': 12.9025345, 'y': 6.01009, 'topic_idx': 1},\n",
       " {'id': 5, 'x': 8.668866, 'y': 8.199829, 'topic_idx': 3},\n",
       " {'id': 6, 'x': 12.077867, 'y': 7.9338036, 'topic_idx': 1},\n",
       " {'id': 7, 'x': 8.833753, 'y': 5.3362575, 'topic_idx': 0},\n",
       " {'id': 8, 'x': 12.449157, 'y': 3.9774396, 'topic_idx': 11},\n",
       " {'id': 9, 'x': 11.269434, 'y': 1.0597181, 'topic_idx': 4},\n",
       " {'id': 10, 'x': 11.58171, 'y': 4.1386633, 'topic_idx': 4},\n",
       " {'id': 11, 'x': 11.505918, 'y': 1.368509, 'topic_idx': 4},\n",
       " {'id': 12, 'x': 11.364411, 'y': 1.2545571, 'topic_idx': 4},\n",
       " {'id': 13, 'x': 6.2473702, 'y': 4.681127, 'topic_idx': 5},\n",
       " {'id': 14, 'x': 8.093265, 'y': 7.7633862, 'topic_idx': 3},\n",
       " {'id': 15, 'x': 12.366834, 'y': 6.414103, 'topic_idx': 1},\n",
       " {'id': 16, 'x': 4.817207, 'y': 4.848057, 'topic_idx': 7},\n",
       " {'id': 17, 'x': 12.90095, 'y': 6.594368, 'topic_idx': 10},\n",
       " {'id': 18, 'x': 12.728445, 'y': 6.6855903, 'topic_idx': 10},\n",
       " {'id': 19, 'x': 13.067353, 'y': 6.6880836, 'topic_idx': 1},\n",
       " {'id': 20, 'x': 8.980434, 'y': 8.062093, 'topic_idx': 8},\n",
       " {'id': 21, 'x': 9.0501375, 'y': 7.148586, 'topic_idx': 3},\n",
       " {'id': 22, 'x': 10.166534, 'y': 6.726125, 'topic_idx': 11},\n",
       " {'id': 23, 'x': 6.560493, 'y': 6.2991266, 'topic_idx': 7},\n",
       " {'id': 24, 'x': 12.724635, 'y': 4.1920037, 'topic_idx': 9},\n",
       " {'id': 25, 'x': 9.268668, 'y': 7.2471375, 'topic_idx': 13},\n",
       " {'id': 26, 'x': 12.892448, 'y': 4.3058157, 'topic_idx': 9},\n",
       " {'id': 27, 'x': 12.582382, 'y': 4.514835, 'topic_idx': 11},\n",
       " {'id': 28, 'x': 9.357414, 'y': 9.773302, 'topic_idx': 2},\n",
       " {'id': 29, 'x': 9.085327, 'y': 8.439522, 'topic_idx': 8},\n",
       " {'id': 30, 'x': 9.092163, 'y': 8.160115, 'topic_idx': 8},\n",
       " {'id': 31, 'x': 11.882809, 'y': 3.4459472, 'topic_idx': 14},\n",
       " {'id': 32, 'x': 13.728649, 'y': 4.1692896, 'topic_idx': 9},\n",
       " {'id': 33, 'x': 13.7017355, 'y': 4.23036, 'topic_idx': 9},\n",
       " {'id': 34, 'x': 12.019207, 'y': 4.7020373, 'topic_idx': 11},\n",
       " {'id': 35, 'x': 11.575645, 'y': 4.18838, 'topic_idx': 13},\n",
       " {'id': 36, 'x': 9.348301, 'y': 8.32946, 'topic_idx': 8},\n",
       " {'id': 37, 'x': 8.012363, 'y': 5.238375, 'topic_idx': 0},\n",
       " {'id': 38, 'x': 4.0404067, 'y': 5.5131755, 'topic_idx': 6},\n",
       " {'id': 39, 'x': 4.4660892, 'y': 5.1972876, 'topic_idx': 6},\n",
       " {'id': 40, 'x': 4.159837, 'y': 5.7776785, 'topic_idx': 6},\n",
       " {'id': 41, 'x': 3.2996633, 'y': 5.8808293, 'topic_idx': 6},\n",
       " {'id': 42, 'x': 3.602309, 'y': 5.841158, 'topic_idx': 6},\n",
       " {'id': 43, 'x': 3.8359325, 'y': 5.560064, 'topic_idx': 6},\n",
       " {'id': 44, 'x': 13.729397, 'y': 4.263902, 'topic_idx': 9},\n",
       " {'id': 45, 'x': 10.119655, 'y': 10.231124, 'topic_idx': 2},\n",
       " {'id': 46, 'x': 11.245482, 'y': 6.521173, 'topic_idx': 12},\n",
       " {'id': 47, 'x': 10.498238, 'y': 6.4016814, 'topic_idx': 12},\n",
       " {'id': 48, 'x': 4.9074073, 'y': 5.3589473, 'topic_idx': 6},\n",
       " {'id': 49, 'x': 9.281545, 'y': 9.861766, 'topic_idx': 2},\n",
       " {'id': 50, 'x': 11.322673, 'y': 1.163632, 'topic_idx': 4},\n",
       " {'id': 51, 'x': 4.5352993, 'y': 5.3013444, 'topic_idx': 6},\n",
       " {'id': 52, 'x': 9.354645, 'y': 9.854903, 'topic_idx': 2},\n",
       " {'id': 53, 'x': 10.142219, 'y': 9.089616, 'topic_idx': 2},\n",
       " {'id': 54, 'x': 12.164692, 'y': 7.9059706, 'topic_idx': 1},\n",
       " {'id': 55, 'x': 9.59357, 'y': 9.785377, 'topic_idx': 2},\n",
       " {'id': 56, 'x': 9.122159, 'y': 2.127784, 'topic_idx': 4},\n",
       " {'id': 57, 'x': 11.744562, 'y': 7.6866894, 'topic_idx': 1},\n",
       " {'id': 58, 'x': 11.324392, 'y': 6.5206475, 'topic_idx': 12},\n",
       " {'id': 59, 'x': 11.838571, 'y': 1.6785818, 'topic_idx': 14},\n",
       " {'id': 60, 'x': 7.650744, 'y': 3.7030559, 'topic_idx': 5},\n",
       " {'id': 61, 'x': 8.608504, 'y': 5.499365, 'topic_idx': 0},\n",
       " {'id': 62, 'x': 12.5341215, 'y': 5.1308875, 'topic_idx': 9},\n",
       " {'id': 63, 'x': 11.681307, 'y': 1.4996679, 'topic_idx': 14},\n",
       " {'id': 64, 'x': 10.164951, 'y': 10.366416, 'topic_idx': 2},\n",
       " {'id': 65, 'x': 10.239733, 'y': 6.0781975, 'topic_idx': 12},\n",
       " {'id': 66, 'x': 10.140995, 'y': 10.315379, 'topic_idx': 2},\n",
       " {'id': 67, 'x': 9.925262, 'y': 9.700569, 'topic_idx': 2},\n",
       " {'id': 68, 'x': 9.81197, 'y': 9.936865, 'topic_idx': 2},\n",
       " {'id': 69, 'x': 12.157998, 'y': 4.88696, 'topic_idx': 11},\n",
       " {'id': 70, 'x': 10.2835865, 'y': 6.5797424, 'topic_idx': 12},\n",
       " {'id': 71, 'x': 10.686658, 'y': 6.4499855, 'topic_idx': 12},\n",
       " {'id': 72, 'x': 8.881877, 'y': 5.3665795, 'topic_idx': 0},\n",
       " {'id': 73, 'x': 11.735227, 'y': 5.8957086, 'topic_idx': 1},\n",
       " {'id': 74, 'x': 10.718047, 'y': 5.0207767, 'topic_idx': 0},\n",
       " {'id': 75, 'x': 13.735472, 'y': 4.1521573, 'topic_idx': 9},\n",
       " {'id': 76, 'x': 9.223359, 'y': 2.256964, 'topic_idx': 4},\n",
       " {'id': 77, 'x': 8.071774, 'y': 4.361289, 'topic_idx': 4},\n",
       " {'id': 78, 'x': 6.693082, 'y': 4.34632, 'topic_idx': 5},\n",
       " {'id': 79, 'x': 8.881656, 'y': 5.4119716, 'topic_idx': 0},\n",
       " {'id': 80, 'x': 8.748101, 'y': 4.5862713, 'topic_idx': 0},\n",
       " {'id': 81, 'x': -7.8710856, 'y': -0.87203586, 'topic_idx': 0},\n",
       " {'id': 82, 'x': 10.113136, 'y': 5.813702, 'topic_idx': 12},\n",
       " {'id': 83, 'x': 10.908046, 'y': 6.419099, 'topic_idx': 12},\n",
       " {'id': 84, 'x': -7.8215036, 'y': -0.822488, 'topic_idx': 0},\n",
       " {'id': 85, 'x': 11.997345, 'y': 3.482466, 'topic_idx': 14},\n",
       " {'id': 86, 'x': 3.948376, 'y': 5.4822464, 'topic_idx': 6},\n",
       " {'id': 87, 'x': 5.0419526, 'y': 5.23069, 'topic_idx': 6},\n",
       " {'id': 88, 'x': 4.8753586, 'y': 6.2558966, 'topic_idx': 6},\n",
       " {'id': 89, 'x': 4.429814, 'y': 6.035918, 'topic_idx': 6},\n",
       " {'id': 90, 'x': 4.9437947, 'y': 6.193065, 'topic_idx': 6},\n",
       " {'id': 91, 'x': 3.365242, 'y': 5.8103414, 'topic_idx': 6},\n",
       " {'id': 92, 'x': 5.957672, 'y': 5.4078064, 'topic_idx': 7},\n",
       " {'id': 93, 'x': 11.386641, 'y': 6.8322024, 'topic_idx': 1},\n",
       " {'id': 94, 'x': 4.6178, 'y': 6.1262045, 'topic_idx': 6},\n",
       " {'id': 95, 'x': 4.0186872, 'y': 5.626818, 'topic_idx': 6},\n",
       " {'id': 96, 'x': 9.228677, 'y': 3.9745483, 'topic_idx': 13},\n",
       " {'id': 97, 'x': 3.6043317, 'y': 5.8194957, 'topic_idx': 6},\n",
       " {'id': 98, 'x': 3.4498036, 'y': 5.9383698, 'topic_idx': 6},\n",
       " {'id': 99, 'x': 3.5398202, 'y': 5.9469123, 'topic_idx': 6},\n",
       " {'id': 100, 'x': 4.0061345, 'y': 5.5818644, 'topic_idx': 6},\n",
       " {'id': 101, 'x': 4.0377197, 'y': 5.850973, 'topic_idx': 6},\n",
       " {'id': 102, 'x': 3.6449003, 'y': 5.8598547, 'topic_idx': 6},\n",
       " {'id': 103, 'x': 3.3061578, 'y': 5.8679695, 'topic_idx': 6},\n",
       " {'id': 104, 'x': 7.9394336, 'y': 5.361235, 'topic_idx': 7},\n",
       " {'id': 105, 'x': 6.608768, 'y': 6.2677984, 'topic_idx': 7},\n",
       " {'id': 106, 'x': 9.049436, 'y': 5.3764524, 'topic_idx': 0},\n",
       " {'id': 107, 'x': 10.612933, 'y': 5.476888, 'topic_idx': 12},\n",
       " {'id': 108, 'x': 9.522749, 'y': 9.412938, 'topic_idx': 2},\n",
       " {'id': 109, 'x': 13.716542, 'y': 4.187198, 'topic_idx': 9},\n",
       " {'id': 110, 'x': 8.831142, 'y': 5.2064133, 'topic_idx': 0},\n",
       " {'id': 111, 'x': 10.079166, 'y': 9.576433, 'topic_idx': 2},\n",
       " {'id': 112, 'x': 10.11624, 'y': 9.416379, 'topic_idx': 2},\n",
       " {'id': 113, 'x': 11.345679, 'y': 2.2350745, 'topic_idx': 9},\n",
       " {'id': 114, 'x': 8.404936, 'y': 5.4040003, 'topic_idx': 0},\n",
       " {'id': 115, 'x': 10.084292, 'y': 10.251486, 'topic_idx': 2},\n",
       " {'id': 116, 'x': 10.494119, 'y': 5.82533, 'topic_idx': 12},\n",
       " {'id': 117, 'x': 11.111503, 'y': 7.5878587, 'topic_idx': 1},\n",
       " {'id': 118, 'x': 10.144109, 'y': 7.242717, 'topic_idx': 13},\n",
       " {'id': 119, 'x': 11.950792, 'y': 1.9998521, 'topic_idx': 14},\n",
       " {'id': 120, 'x': 8.281129, 'y': 6.732833, 'topic_idx': 3},\n",
       " {'id': 121, 'x': 10.132527, 'y': 6.413407, 'topic_idx': 12},\n",
       " {'id': 122, 'x': -7.866605, 'y': -0.86755675, 'topic_idx': 0},\n",
       " {'id': 123, 'x': 11.859954, 'y': 7.605029, 'topic_idx': 1},\n",
       " {'id': 124, 'x': -7.797153, 'y': -0.79810697, 'topic_idx': 0},\n",
       " {'id': 125, 'x': 8.194773, 'y': 7.615189, 'topic_idx': 3},\n",
       " {'id': 126, 'x': 8.131741, 'y': 7.627201, 'topic_idx': 3},\n",
       " {'id': 127, 'x': 10.322677, 'y': 5.748002, 'topic_idx': 12},\n",
       " {'id': 128, 'x': 10.717536, 'y': 5.812876, 'topic_idx': 12},\n",
       " {'id': 129, 'x': 10.036628, 'y': 9.9161005, 'topic_idx': 2},\n",
       " {'id': 130, 'x': 12.84437, 'y': 7.3273396, 'topic_idx': 1},\n",
       " {'id': 131, 'x': 12.435495, 'y': 2.5452237, 'topic_idx': 13},\n",
       " {'id': 132, 'x': 12.324241, 'y': 8.220574, 'topic_idx': 1},\n",
       " {'id': 133, 'x': 9.411568, 'y': 9.437466, 'topic_idx': 2},\n",
       " {'id': 134, 'x': 8.487902, 'y': 7.0059423, 'topic_idx': 3},\n",
       " {'id': 135, 'x': 8.760178, 'y': 7.0317025, 'topic_idx': 3},\n",
       " {'id': 136, 'x': 8.303671, 'y': 6.8424516, 'topic_idx': 3},\n",
       " {'id': 137, 'x': 7.7201695, 'y': 4.0817947, 'topic_idx': 5},\n",
       " {'id': 138, 'x': 9.973767, 'y': 7.5041986, 'topic_idx': 13},\n",
       " {'id': 139, 'x': 7.003099, 'y': 5.7615857, 'topic_idx': 7},\n",
       " {'id': 140, 'x': 12.827731, 'y': 8.148152, 'topic_idx': 10},\n",
       " {'id': 141, 'x': 8.7973795, 'y': 9.296703, 'topic_idx': 2},\n",
       " {'id': 142, 'x': 12.29905, 'y': 8.286784, 'topic_idx': 10},\n",
       " {'id': 143, 'x': 12.847934, 'y': 8.096304, 'topic_idx': 10},\n",
       " {'id': 144, 'x': 12.264049, 'y': 8.265304, 'topic_idx': 10},\n",
       " {'id': 145, 'x': 12.432818, 'y': 2.5504694, 'topic_idx': 13},\n",
       " {'id': 146, 'x': 12.891067, 'y': 8.055848, 'topic_idx': 10},\n",
       " {'id': 147, 'x': 12.339838, 'y': 6.4785414, 'topic_idx': 10},\n",
       " {'id': 148, 'x': 12.282369, 'y': 6.4956884, 'topic_idx': 1},\n",
       " {'id': 149, 'x': 12.975688, 'y': 6.593523, 'topic_idx': 10},\n",
       " {'id': 150, 'x': 11.2771, 'y': 1.1092497, 'topic_idx': 4},\n",
       " {'id': 151, 'x': 12.4527855, 'y': 4.2708125, 'topic_idx': 9},\n",
       " {'id': 152, 'x': 12.267612, 'y': 4.5738196, 'topic_idx': 11},\n",
       " {'id': 153, 'x': 11.046864, 'y': 7.313422, 'topic_idx': 10},\n",
       " {'id': 154, 'x': 9.368407, 'y': 9.855059, 'topic_idx': 2},\n",
       " {'id': 155, 'x': 12.5151615, 'y': 6.753862, 'topic_idx': 10},\n",
       " {'id': 156, 'x': 12.761976, 'y': 6.6480737, 'topic_idx': 10},\n",
       " {'id': 157, 'x': 11.766413, 'y': 7.036828, 'topic_idx': 1},\n",
       " {'id': 158, 'x': 12.329051, 'y': 6.8409543, 'topic_idx': 10},\n",
       " {'id': 159, 'x': 11.797454, 'y': 6.6276364, 'topic_idx': 1},\n",
       " {'id': 160, 'x': 12.074873, 'y': 6.927731, 'topic_idx': 10},\n",
       " {'id': 161, 'x': 12.022985, 'y': 6.889165, 'topic_idx': 10},\n",
       " {'id': 162, 'x': 9.700517, 'y': 9.151185, 'topic_idx': 2},\n",
       " {'id': 163, 'x': 9.735178, 'y': 8.087509, 'topic_idx': 8},\n",
       " {'id': 164, 'x': 15.043223, 'y': 3.13387, 'topic_idx': 0},\n",
       " {'id': 165, 'x': 8.362888, 'y': 4.4333286, 'topic_idx': 0},\n",
       " {'id': 166, 'x': 12.138782, 'y': 4.882088, 'topic_idx': 11},\n",
       " {'id': 167, 'x': 10.712128, 'y': 6.0068464, 'topic_idx': 12},\n",
       " {'id': 168, 'x': 10.260329, 'y': 8.598312, 'topic_idx': 2},\n",
       " {'id': 169, 'x': 12.676884, 'y': 3.4060526, 'topic_idx': 11},\n",
       " {'id': 170, 'x': 12.245933, 'y': 5.488599, 'topic_idx': 1},\n",
       " {'id': 171, 'x': 6.172431, 'y': 4.7776704, 'topic_idx': 5},\n",
       " {'id': 172, 'x': 4.777672, 'y': 5.2186966, 'topic_idx': 6},\n",
       " {'id': 173, 'x': 11.959376, 'y': 2.086452, 'topic_idx': 0},\n",
       " {'id': 174, 'x': 11.74767, 'y': 5.5629177, 'topic_idx': 12},\n",
       " {'id': 175, 'x': 12.531161, 'y': 7.5108247, 'topic_idx': 1},\n",
       " {'id': 176, 'x': 9.388748, 'y': 2.7829359, 'topic_idx': 4},\n",
       " {'id': 177, 'x': 11.262528, 'y': 1.0538635, 'topic_idx': 4},\n",
       " {'id': 178, 'x': 11.5724125, 'y': 1.3284787, 'topic_idx': 4},\n",
       " {'id': 179, 'x': 11.065284, 'y': 5.8702874, 'topic_idx': 12},\n",
       " {'id': 180, 'x': 11.864476, 'y': 4.306643, 'topic_idx': 9},\n",
       " {'id': 181, 'x': 12.246356, 'y': 5.4397674, 'topic_idx': 1},\n",
       " {'id': 182, 'x': 11.806397, 'y': 7.0215044, 'topic_idx': 1},\n",
       " {'id': 183, 'x': 11.622993, 'y': 3.775761, 'topic_idx': 14},\n",
       " {'id': 184, 'x': 5.04386, 'y': 6.264121, 'topic_idx': 6},\n",
       " {'id': 185, 'x': 13.375259, 'y': 4.4187636, 'topic_idx': 9},\n",
       " {'id': 186, 'x': 4.028068, 'y': 5.6259294, 'topic_idx': 6},\n",
       " {'id': 187, 'x': 12.065432, 'y': 4.606376, 'topic_idx': 11},\n",
       " {'id': 188, 'x': -7.9838934, 'y': -0.98492616, 'topic_idx': 0},\n",
       " {'id': 189, 'x': 8.476922, 'y': 5.583988, 'topic_idx': 0},\n",
       " {'id': 190, 'x': 9.526483, 'y': 8.9057045, 'topic_idx': 2},\n",
       " {'id': 191, 'x': 9.78703, 'y': 7.7702236, 'topic_idx': 13},\n",
       " {'id': 192, 'x': -7.9564433, 'y': -0.9574615, 'topic_idx': 0},\n",
       " {'id': 193, 'x': 13.8572445, 'y': 4.430462, 'topic_idx': 9},\n",
       " {'id': 194, 'x': 11.235562, 'y': 8.476722, 'topic_idx': 1},\n",
       " {'id': 195, 'x': 9.544391, 'y': 8.110481, 'topic_idx': 8},\n",
       " {'id': 196, 'x': 4.3116484, 'y': 5.2969146, 'topic_idx': 6},\n",
       " {'id': 197, 'x': 4.255658, 'y': 5.279476, 'topic_idx': 6},\n",
       " {'id': 198, 'x': 13.412334, 'y': 4.4643707, 'topic_idx': 9},\n",
       " {'id': 199, 'x': 9.360267, 'y': 7.5110064, 'topic_idx': 13},\n",
       " {'id': 200, 'x': -7.7617965, 'y': -0.76280385, 'topic_idx': 0},\n",
       " {'id': 201, 'x': 12.183069, 'y': 5.48552, 'topic_idx': 1},\n",
       " {'id': 202, 'x': 11.066126, 'y': 3.7503881, 'topic_idx': 11},\n",
       " {'id': 203, 'x': 7.7548304, 'y': 5.48125, 'topic_idx': 3},\n",
       " {'id': 204, 'x': 12.158607, 'y': 4.2320404, 'topic_idx': 9},\n",
       " {'id': 205, 'x': 11.34727, 'y': 2.7796583, 'topic_idx': 9},\n",
       " {'id': 206, 'x': 9.716721, 'y': 5.354894, 'topic_idx': 0},\n",
       " {'id': 207, 'x': 12.767483, 'y': 4.175686, 'topic_idx': 9},\n",
       " {'id': 208, 'x': 11.013138, 'y': 8.392642, 'topic_idx': 2},\n",
       " {'id': 209, 'x': 8.792424, 'y': 8.845675, 'topic_idx': 8},\n",
       " {'id': 210, 'x': 9.602197, 'y': 7.595374, 'topic_idx': 13},\n",
       " {'id': 211, 'x': 9.059051, 'y': 5.2250257, 'topic_idx': 0},\n",
       " {'id': 212, 'x': 9.551606, 'y': 8.206396, 'topic_idx': 8},\n",
       " {'id': 213, 'x': 9.5357065, 'y': 8.262359, 'topic_idx': 8},\n",
       " {'id': 214, 'x': 13.07944, 'y': 4.3401113, 'topic_idx': 9},\n",
       " {'id': 215, 'x': 13.085101, 'y': 4.330135, 'topic_idx': 9},\n",
       " {'id': 216, 'x': 9.77177, 'y': 8.272728, 'topic_idx': 8},\n",
       " {'id': 217, 'x': 8.779207, 'y': 8.849624, 'topic_idx': 8},\n",
       " {'id': 218, 'x': 7.5841346, 'y': 4.003849, 'topic_idx': 5},\n",
       " {'id': 219, 'x': 10.0051775, 'y': 8.771245, 'topic_idx': 2},\n",
       " {'id': 220, 'x': 7.3522434, 'y': 4.191154, 'topic_idx': 5},\n",
       " {'id': 221, 'x': 8.970657, 'y': 7.204931, 'topic_idx': 3},\n",
       " {'id': 222, 'x': 10.054209, 'y': 8.731936, 'topic_idx': 2},\n",
       " {'id': 223, 'x': 10.571141, 'y': 8.491997, 'topic_idx': 2},\n",
       " {'id': 224, 'x': 11.821122, 'y': 5.130262, 'topic_idx': 11},\n",
       " {'id': 225, 'x': 12.558816, 'y': 2.7987413, 'topic_idx': 11},\n",
       " {'id': 226, 'x': 7.181373, 'y': 4.483515, 'topic_idx': 5},\n",
       " {'id': 227, 'x': 13.500725, 'y': 4.381605, 'topic_idx': 9},\n",
       " {'id': 228, 'x': 8.144702, 'y': 6.9341965, 'topic_idx': 3},\n",
       " {'id': 229, 'x': 7.986744, 'y': 6.3081226, 'topic_idx': 3},\n",
       " {'id': 230, 'x': 7.997981, 'y': 6.648825, 'topic_idx': 3},\n",
       " {'id': 231, 'x': 12.917084, 'y': 3.0753121, 'topic_idx': 11},\n",
       " {'id': 232, 'x': 8.258266, 'y': 5.740551, 'topic_idx': 7},\n",
       " {'id': 233, 'x': 11.069297, 'y': 2.64592, 'topic_idx': 4},\n",
       " {'id': 234, 'x': 12.707201, 'y': 5.75847, 'topic_idx': 1},\n",
       " {'id': 235, 'x': 9.441287, 'y': 8.191514, 'topic_idx': 8},\n",
       " {'id': 236, 'x': 11.393141, 'y': 1.1655831, 'topic_idx': 4},\n",
       " {'id': 237, 'x': 9.285349, 'y': 2.4154987, 'topic_idx': 4},\n",
       " {'id': 238, 'x': 4.601405, 'y': 5.6415844, 'topic_idx': 6},\n",
       " {'id': 239, 'x': 11.2031145, 'y': 7.175557, 'topic_idx': 1},\n",
       " {'id': 240, 'x': 6.09822, 'y': 5.3115554, 'topic_idx': 7},\n",
       " {'id': 241, 'x': 8.488314, 'y': 9.136872, 'topic_idx': 7},\n",
       " {'id': 242, 'x': 7.609053, 'y': 9.383899, 'topic_idx': 3},\n",
       " {'id': 243, 'x': 7.7129135, 'y': 9.439999, 'topic_idx': 3},\n",
       " {'id': 244, 'x': 12.895499, 'y': 3.0706584, 'topic_idx': 11},\n",
       " {'id': 245, 'x': 11.160404, 'y': 7.274011, 'topic_idx': 1},\n",
       " {'id': 246, 'x': 12.579242, 'y': 4.7527657, 'topic_idx': 11},\n",
       " {'id': 247, 'x': 12.650382, 'y': 4.459827, 'topic_idx': 9},\n",
       " {'id': 248, 'x': 12.7692995, 'y': 6.292353, 'topic_idx': 1},\n",
       " {'id': 249, 'x': 15.009519, 'y': 3.1545994, 'topic_idx': 0},\n",
       " {'id': 250, 'x': 4.510007, 'y': 5.64834, 'topic_idx': 6},\n",
       " {'id': 251, 'x': 12.711692, 'y': 7.3419476, 'topic_idx': 1},\n",
       " {'id': 252, 'x': 12.936024, 'y': 7.0500026, 'topic_idx': 1},\n",
       " {'id': 253, 'x': 12.797649, 'y': 7.2547708, 'topic_idx': 1},\n",
       " {'id': 254, 'x': 12.729035, 'y': 7.0626917, 'topic_idx': 1},\n",
       " {'id': 255, 'x': -7.8565483, 'y': -0.85754293, 'topic_idx': 0},\n",
       " {'id': 256, 'x': 7.9923096, 'y': 7.744978, 'topic_idx': 3},\n",
       " {'id': 257, 'x': 7.961285, 'y': 7.8981323, 'topic_idx': 3},\n",
       " {'id': 258, 'x': 7.9357953, 'y': 7.8410482, 'topic_idx': 3},\n",
       " {'id': 259, 'x': 10.628502, 'y': 6.520915, 'topic_idx': 12},\n",
       " {'id': 260, 'x': 7.7108874, 'y': 5.023793, 'topic_idx': 3},\n",
       " {'id': 261, 'x': 4.455564, 'y': 5.6333523, 'topic_idx': 6},\n",
       " {'id': 262, 'x': 9.702502, 'y': 6.1077485, 'topic_idx': 13},\n",
       " {'id': 263, 'x': 10.188406, 'y': 8.671969, 'topic_idx': 2},\n",
       " {'id': 264, 'x': 11.832391, 'y': 6.898187, 'topic_idx': 10},\n",
       " {'id': 265, 'x': 11.957437, 'y': 6.9066386, 'topic_idx': 10},\n",
       " {'id': 266, 'x': 12.898783, 'y': 7.961203, 'topic_idx': 10},\n",
       " {'id': 267, 'x': 13.026162, 'y': 7.7198396, 'topic_idx': 10},\n",
       " {'id': 268, 'x': 9.765223, 'y': 9.752404, 'topic_idx': 2},\n",
       " {'id': 269, 'x': 8.317657, 'y': 7.4056787, 'topic_idx': 3},\n",
       " {'id': 270, 'x': 6.757171, 'y': 6.107296, 'topic_idx': 7},\n",
       " {'id': 271, 'x': 5.85045, 'y': 5.422478, 'topic_idx': 7},\n",
       " {'id': 272, 'x': 5.7158594, 'y': 5.4853315, 'topic_idx': 7},\n",
       " {'id': 273, 'x': 12.07871, 'y': 7.8581476, 'topic_idx': 1},\n",
       " {'id': 274, 'x': 11.102978, 'y': 7.1308537, 'topic_idx': 1},\n",
       " {'id': 275, 'x': 10.2628355, 'y': 8.680348, 'topic_idx': 2},\n",
       " {'id': 276, 'x': 12.09069, 'y': 5.4219327, 'topic_idx': 12},\n",
       " {'id': 277, 'x': 6.1684227, 'y': 6.866475, 'topic_idx': 7},\n",
       " {'id': 278, 'x': 7.051506, 'y': 5.735985, 'topic_idx': 7},\n",
       " {'id': 279, 'x': 10.038931, 'y': 5.0612736, 'topic_idx': 0},\n",
       " {'id': 280, 'x': 10.029813, 'y': 7.197857, 'topic_idx': 13},\n",
       " {'id': 281, 'x': 12.118936, 'y': 6.3400755, 'topic_idx': 1},\n",
       " {'id': 282, 'x': 9.672133, 'y': 9.305313, 'topic_idx': 2},\n",
       " {'id': 283, 'x': 9.293829, 'y': 8.354075, 'topic_idx': 8},\n",
       " {'id': 284, 'x': 8.242196, 'y': 7.519447, 'topic_idx': 3},\n",
       " {'id': 285, 'x': 8.8818865, 'y': 5.4473763, 'topic_idx': 0},\n",
       " {'id': 286, 'x': 10.706339, 'y': 8.769227, 'topic_idx': 2},\n",
       " {'id': 287, 'x': 8.901374, 'y': 8.802056, 'topic_idx': 8},\n",
       " {'id': 288, 'x': 9.780369, 'y': 8.440252, 'topic_idx': 8},\n",
       " {'id': 289, 'x': 9.940139, 'y': 8.282093, 'topic_idx': 8},\n",
       " {'id': 290, 'x': 10.058198, 'y': 8.2822, 'topic_idx': 2},\n",
       " {'id': 291, 'x': 9.759131, 'y': 8.505077, 'topic_idx': 8},\n",
       " {'id': 292, 'x': 9.50928, 'y': 8.54576, 'topic_idx': 8},\n",
       " {'id': 293, 'x': 8.185111, 'y': 7.848554, 'topic_idx': 3},\n",
       " {'id': 294, 'x': 12.420428, 'y': 2.5477467, 'topic_idx': 13},\n",
       " {'id': 295, 'x': 5.071731, 'y': 6.1104074, 'topic_idx': 6},\n",
       " {'id': 296, 'x': 7.539587, 'y': 9.307391, 'topic_idx': 3},\n",
       " {'id': 297, 'x': 7.5692053, 'y': 9.350823, 'topic_idx': 3},\n",
       " {'id': 298, 'x': 12.063083, 'y': 7.078375, 'topic_idx': 11},\n",
       " {'id': 299, 'x': 8.95771, 'y': 5.28769, 'topic_idx': 0},\n",
       " {'id': 300, 'x': 13.024746, 'y': 7.680589, 'topic_idx': 10},\n",
       " {'id': 301, 'x': 13.0125885, 'y': 7.5601587, 'topic_idx': 10},\n",
       " {'id': 302, 'x': 6.2710924, 'y': 6.746211, 'topic_idx': 7},\n",
       " {'id': 303, 'x': 6.2499304, 'y': 6.7574024, 'topic_idx': 7},\n",
       " {'id': 304, 'x': 9.257403, 'y': 8.788974, 'topic_idx': 8},\n",
       " {'id': 305, 'x': 12.911206, 'y': 8.014063, 'topic_idx': 10},\n",
       " {'id': 306, 'x': 12.9068985, 'y': 3.1174722, 'topic_idx': 11},\n",
       " {'id': 307, 'x': 10.274687, 'y': 8.872658, 'topic_idx': 2},\n",
       " {'id': 308, 'x': 15.0531435, 'y': 3.1271331, 'topic_idx': 0},\n",
       " {'id': 309, 'x': 12.958942, 'y': 6.5496006, 'topic_idx': 10},\n",
       " {'id': 310, 'x': 8.233522, 'y': 7.2920923, 'topic_idx': 3},\n",
       " {'id': 311, 'x': 10.936553, 'y': 5.4289355, 'topic_idx': 12},\n",
       " {'id': 312, 'x': 10.856071, 'y': 4.9857073, 'topic_idx': 14},\n",
       " {'id': 313, 'x': -7.9664288, 'y': -0.9674187, 'topic_idx': 0},\n",
       " {'id': 314, 'x': 10.9839735, 'y': 5.6828794, 'topic_idx': 12},\n",
       " {'id': 315, 'x': 11.336763, 'y': 6.791111, 'topic_idx': 1},\n",
       " {'id': 316, 'x': 10.925026, 'y': 5.303858, 'topic_idx': 0},\n",
       " {'id': 317, 'x': 9.867364, 'y': 7.3677464, 'topic_idx': 13},\n",
       " {'id': 318, 'x': 10.91339, 'y': 5.8893614, 'topic_idx': 12},\n",
       " {'id': 319, 'x': 11.754304, 'y': 1.5488228, 'topic_idx': 14},\n",
       " {'id': 320, 'x': 8.368522, 'y': 7.5282817, 'topic_idx': 3},\n",
       " {'id': 321, 'x': 11.1896305, 'y': 1.0035273, 'topic_idx': 4},\n",
       " {'id': 322, 'x': 11.125392, 'y': 6.8830223, 'topic_idx': 1},\n",
       " {'id': 323, 'x': 8.421603, 'y': 6.5781364, 'topic_idx': 3},\n",
       " {'id': 324, 'x': 4.865063, 'y': 4.5789733, 'topic_idx': 7},\n",
       " {'id': 325, 'x': 8.211044, 'y': 7.0350995, 'topic_idx': 3},\n",
       " {'id': 326, 'x': 5.1775236, 'y': 3.5858583, 'topic_idx': 5},\n",
       " {'id': 327, 'x': 5.1298614, 'y': 3.5622349, 'topic_idx': 5},\n",
       " {'id': 328, 'x': 8.084762, 'y': 7.990426, 'topic_idx': 3},\n",
       " {'id': 329, 'x': 9.201923, 'y': 2.2835014, 'topic_idx': 4},\n",
       " {'id': 330, 'x': 13.423155, 'y': 3.9383714, 'topic_idx': 9},\n",
       " {'id': 331, 'x': 12.911816, 'y': 6.112296, 'topic_idx': 10},\n",
       " {'id': 332, 'x': 12.721114, 'y': 6.2366743, 'topic_idx': 1},\n",
       " {'id': 333, 'x': 11.495744, 'y': 1.2617128, 'topic_idx': 4},\n",
       " {'id': 334, 'x': 6.1845036, 'y': 6.8665195, 'topic_idx': 0},\n",
       " {'id': 335, 'x': 13.84813, 'y': 4.367369, 'topic_idx': 9},\n",
       " {'id': 336, 'x': 6.2812786, 'y': 6.6946816, 'topic_idx': 7},\n",
       " {'id': 337, 'x': 6.178824, 'y': 6.8590317, 'topic_idx': 7},\n",
       " {'id': 338, 'x': 10.179357, 'y': 4.9502187, 'topic_idx': 0},\n",
       " {'id': 339, 'x': 7.0664506, 'y': 6.1006575, 'topic_idx': 7},\n",
       " {'id': 340, 'x': 7.550172, 'y': 9.332254, 'topic_idx': 3},\n",
       " {'id': 341, 'x': 12.96075, 'y': 3.0428212, 'topic_idx': 11},\n",
       " {'id': 342, 'x': 12.878215, 'y': 3.1352344, 'topic_idx': 11},\n",
       " {'id': 343, 'x': 9.266387, 'y': 2.2651286, 'topic_idx': 4},\n",
       " {'id': 344, 'x': 9.162467, 'y': 2.1594503, 'topic_idx': 4},\n",
       " {'id': 345, 'x': 9.158988, 'y': 2.187297, 'topic_idx': 4},\n",
       " {'id': 346, 'x': 4.9455624, 'y': 6.16655, 'topic_idx': 6},\n",
       " {'id': 347, 'x': 8.14938, 'y': 7.186205, 'topic_idx': 3},\n",
       " {'id': 348, 'x': 9.418706, 'y': 2.760508, 'topic_idx': 2},\n",
       " {'id': 349, 'x': -7.8486753, 'y': -0.8496821, 'topic_idx': 0},\n",
       " {'id': 350, 'x': 9.011164, 'y': 7.811616, 'topic_idx': 8},\n",
       " {'id': 351, 'x': 11.938909, 'y': 4.5183287, 'topic_idx': 11},\n",
       " {'id': 352, 'x': 6.408116, 'y': 6.5458155, 'topic_idx': 7},\n",
       " {'id': 353, 'x': 10.820019, 'y': 8.23535, 'topic_idx': 1},\n",
       " {'id': 354, 'x': 6.2653193, 'y': 5.813356, 'topic_idx': 5},\n",
       " {'id': 355, 'x': 6.242624, 'y': 5.82111, 'topic_idx': 5},\n",
       " {'id': 356, 'x': 6.2438364, 'y': 5.818013, 'topic_idx': 6},\n",
       " {'id': 357, 'x': 5.091975, 'y': 3.5657957, 'topic_idx': 5},\n",
       " {'id': 358, 'x': 5.108712, 'y': 3.5986972, 'topic_idx': 5},\n",
       " {'id': 359, 'x': 11.971687, 'y': 6.9781804, 'topic_idx': 10},\n",
       " {'id': 360, 'x': 6.1741114, 'y': 6.8673325, 'topic_idx': 7},\n",
       " {'id': 361, 'x': 12.2430525, 'y': 5.167499, 'topic_idx': 11},\n",
       " {'id': 362, 'x': 12.915394, 'y': 4.239021, 'topic_idx': 9},\n",
       " {'id': 363, 'x': 7.4967613, 'y': 4.1522946, 'topic_idx': 5},\n",
       " {'id': 364, 'x': 12.808979, 'y': 6.510523, 'topic_idx': 10},\n",
       " {'id': 365, 'x': 8.888895, 'y': 4.3264723, 'topic_idx': 0},\n",
       " {'id': 366, 'x': 5.1345587, 'y': 3.5696971, 'topic_idx': 5},\n",
       " {'id': 367, 'x': 9.22205, 'y': 3.8941135, 'topic_idx': 0},\n",
       " {'id': 368, 'x': 15.039146, 'y': 3.135859, 'topic_idx': 0},\n",
       " {'id': 369, 'x': 10.685871, 'y': 5.6498547, 'topic_idx': 12},\n",
       " {'id': 370, 'x': 10.826961, 'y': 5.1989174, 'topic_idx': 12},\n",
       " {'id': 371, 'x': 12.915945, 'y': 6.0087323, 'topic_idx': 1},\n",
       " {'id': 372, 'x': 13.900241, 'y': 4.509637, 'topic_idx': 9},\n",
       " {'id': 373, 'x': 6.7814746, 'y': 6.0839243, 'topic_idx': 7},\n",
       " {'id': 374, 'x': 6.649037, 'y': 6.2181168, 'topic_idx': 7},\n",
       " {'id': 375, 'x': 5.627921, 'y': 5.5019994, 'topic_idx': 7},\n",
       " {'id': 376, 'x': 5.31204, 'y': 5.315759, 'topic_idx': 7},\n",
       " {'id': 377, 'x': 5.3050013, 'y': 5.2792125, 'topic_idx': 7},\n",
       " {'id': 378, 'x': 11.991612, 'y': 7.750589, 'topic_idx': 1},\n",
       " {'id': 379, 'x': 10.913855, 'y': 5.826824, 'topic_idx': 12},\n",
       " {'id': 380, 'x': 12.909838, 'y': 3.0834227, 'topic_idx': 11},\n",
       " {'id': 381, 'x': 10.944964, 'y': 5.206026, 'topic_idx': 0},\n",
       " {'id': 382, 'x': 12.642918, 'y': 7.385674, 'topic_idx': 1},\n",
       " {'id': 383, 'x': 12.199137, 'y': 6.984648, 'topic_idx': 10},\n",
       " {'id': 384, 'x': 12.038385, 'y': 7.821585, 'topic_idx': 1},\n",
       " {'id': 385, 'x': 10.621995, 'y': 4.9721274, 'topic_idx': 0},\n",
       " {'id': 386, 'x': 11.886778, 'y': 6.541868, 'topic_idx': 1},\n",
       " {'id': 387, 'x': 10.686837, 'y': 5.110643, 'topic_idx': 0},\n",
       " {'id': 388, 'x': 11.129665, 'y': 7.0138655, 'topic_idx': 1},\n",
       " {'id': 389, 'x': 5.100026, 'y': 3.5386455, 'topic_idx': 5},\n",
       " {'id': 390, 'x': 7.732178, 'y': 3.5463655, 'topic_idx': 4},\n",
       " {'id': 391, 'x': 9.222637, 'y': 8.030208, 'topic_idx': 8},\n",
       " {'id': 392, 'x': 11.943139, 'y': 8.362715, 'topic_idx': 10},\n",
       " {'id': 393, 'x': 9.084054, 'y': 8.560512, 'topic_idx': 8},\n",
       " {'id': 394, 'x': 9.005602, 'y': 8.575792, 'topic_idx': 8},\n",
       " {'id': 395, 'x': 7.99687, 'y': 7.7517004, 'topic_idx': 3},\n",
       " {'id': 396, 'x': 12.998293, 'y': 4.561311, 'topic_idx': 9},\n",
       " {'id': 397, 'x': 5.538909, 'y': 5.3912053, 'topic_idx': 5},\n",
       " {'id': 398, 'x': 7.6467156, 'y': 6.6442723, 'topic_idx': 3},\n",
       " {'id': 399, 'x': 10.712769, 'y': 5.043411, 'topic_idx': 0},\n",
       " {'id': 400, 'x': 9.28867, 'y': 2.3679478, 'topic_idx': 4},\n",
       " {'id': 401, 'x': 9.628814, 'y': 5.400891, 'topic_idx': 0},\n",
       " {'id': 402, 'x': 10.870892, 'y': 5.2295704, 'topic_idx': 12},\n",
       " {'id': 403, 'x': 11.788852, 'y': 4.3022985, 'topic_idx': 11},\n",
       " {'id': 404, 'x': 12.517264, 'y': 3.9947293, 'topic_idx': 11},\n",
       " {'id': 405, 'x': 10.817209, 'y': 8.273537, 'topic_idx': 2},\n",
       " {'id': 406, 'x': 12.233818, 'y': 5.291821, 'topic_idx': 11},\n",
       " {'id': 407, 'x': 9.388827, 'y': 2.69792, 'topic_idx': 4},\n",
       " {'id': 408, 'x': 7.9974756, 'y': 4.259736, 'topic_idx': 0},\n",
       " {'id': 409, 'x': 11.293281, 'y': 6.726857, 'topic_idx': 1},\n",
       " {'id': 410, 'x': 11.222456, 'y': 1.013539, 'topic_idx': 4},\n",
       " {'id': 411, 'x': 10.496198, 'y': 7.1372423, 'topic_idx': 13},\n",
       " {'id': 412, 'x': 9.137749, 'y': 2.171249, 'topic_idx': 4},\n",
       " {'id': 413, 'x': 9.631785, 'y': 9.673213, 'topic_idx': 9},\n",
       " {'id': 414, 'x': 4.971979, 'y': 4.4123344, 'topic_idx': 7},\n",
       " {'id': 415, 'x': 7.9219985, 'y': 5.7642097, 'topic_idx': 3},\n",
       " {'id': 416, 'x': 5.0421143, 'y': 4.6137395, 'topic_idx': 7},\n",
       " {'id': 417, 'x': 12.79617, 'y': 5.824635, 'topic_idx': 1},\n",
       " {'id': 418, 'x': 7.5204263, 'y': 9.321992, 'topic_idx': 3},\n",
       " {'id': 419, 'x': 9.186711, 'y': 8.529496, 'topic_idx': 2},\n",
       " {'id': 420, 'x': 10.812317, 'y': 7.0900855, 'topic_idx': 13},\n",
       " {'id': 421, 'x': 11.263411, 'y': 1.0805435, 'topic_idx': 4},\n",
       " {'id': 422, 'x': 10.531329, 'y': 4.6376286, 'topic_idx': 0},\n",
       " {'id': 423, 'x': 10.724224, 'y': 2.9809427, 'topic_idx': 14},\n",
       " {'id': 424, 'x': 9.356536, 'y': 7.2853637, 'topic_idx': 13},\n",
       " {'id': 425, 'x': 9.391847, 'y': 8.825635, 'topic_idx': 8},\n",
       " {'id': 426, 'x': 7.5807486, 'y': 9.345248, 'topic_idx': 3},\n",
       " {'id': 427, 'x': 8.624153, 'y': 9.063567, 'topic_idx': 8},\n",
       " {'id': 428, 'x': 8.380217, 'y': 9.212266, 'topic_idx': 3},\n",
       " {'id': 429, 'x': 8.615765, 'y': 9.024089, 'topic_idx': 8},\n",
       " {'id': 430, 'x': 9.235732, 'y': 9.199606, 'topic_idx': 8},\n",
       " {'id': 431, 'x': 10.052009, 'y': 8.168009, 'topic_idx': 8},\n",
       " {'id': 432, 'x': 10.205616, 'y': 8.947726, 'topic_idx': 2},\n",
       " {'id': 433, 'x': 10.436638, 'y': 8.570394, 'topic_idx': 2},\n",
       " {'id': 434, 'x': 9.318452, 'y': 9.081612, 'topic_idx': 2},\n",
       " {'id': 435, 'x': 10.522434, 'y': 8.848514, 'topic_idx': 2},\n",
       " {'id': 436, 'x': 9.399957, 'y': 8.139533, 'topic_idx': 8},\n",
       " {'id': 437, 'x': 10.358083, 'y': 5.059401, 'topic_idx': 0},\n",
       " {'id': 438, 'x': 9.320946, 'y': 2.536077, 'topic_idx': 4},\n",
       " {'id': 439, 'x': 9.314197, 'y': 2.5597205, 'topic_idx': 4},\n",
       " {'id': 440, 'x': 7.0253882, 'y': 4.5846786, 'topic_idx': 5},\n",
       " {'id': 441, 'x': 6.924681, 'y': 4.5665393, 'topic_idx': 5},\n",
       " {'id': 442, 'x': 6.843282, 'y': 5.0231986, 'topic_idx': 7},\n",
       " {'id': 443, 'x': 6.9671288, 'y': 4.6165724, 'topic_idx': 5},\n",
       " {'id': 444, 'x': 7.075448, 'y': 4.690746, 'topic_idx': 5},\n",
       " {'id': 445, 'x': 6.926738, 'y': 4.777733, 'topic_idx': 7},\n",
       " {'id': 446, 'x': 7.4257374, 'y': 4.6735477, 'topic_idx': 5},\n",
       " {'id': 447, 'x': 7.2878675, 'y': 4.7135334, 'topic_idx': 5},\n",
       " {'id': 448, 'x': 6.0988154, 'y': 4.869005, 'topic_idx': 5},\n",
       " {'id': 449, 'x': 6.398596, 'y': 4.187365, 'topic_idx': 5},\n",
       " {'id': 450, 'x': 6.074091, 'y': 4.81083, 'topic_idx': 5},\n",
       " {'id': 451, 'x': 6.064846, 'y': 5.442536, 'topic_idx': 7},\n",
       " {'id': 452, 'x': 10.547729, 'y': 6.189655, 'topic_idx': 12},\n",
       " {'id': 453, 'x': 9.765096, 'y': 9.205067, 'topic_idx': 2},\n",
       " {'id': 454, 'x': 9.772745, 'y': 9.867459, 'topic_idx': 2},\n",
       " {'id': 455, 'x': 9.846148, 'y': 8.811097, 'topic_idx': 2},\n",
       " {'id': 456, 'x': 9.768736, 'y': 6.0613117, 'topic_idx': 13},\n",
       " {'id': 457, 'x': 9.784427, 'y': 9.162353, 'topic_idx': 2},\n",
       " {'id': 458, 'x': 12.239433, 'y': 3.8810227, 'topic_idx': 11},\n",
       " {'id': 459, 'x': 10.991354, 'y': 2.21688, 'topic_idx': 4},\n",
       " {'id': 460, 'x': 10.216553, 'y': 2.7297525, 'topic_idx': 4},\n",
       " {'id': 461, 'x': 8.153366, 'y': 4.44443, 'topic_idx': 0},\n",
       " {'id': 462, 'x': 7.8837457, 'y': 4.7454247, 'topic_idx': 5},\n",
       " {'id': 463, 'x': 7.8095536, 'y': 4.7873964, 'topic_idx': 5},\n",
       " {'id': 464, 'x': 8.11587, 'y': 4.480485, 'topic_idx': 0},\n",
       " {'id': 465, 'x': 7.754465, 'y': 4.8164115, 'topic_idx': 5},\n",
       " {'id': 466, 'x': 10.456771, 'y': 4.361446, 'topic_idx': 14},\n",
       " {'id': 467, 'x': 10.109796, 'y': 7.146917, 'topic_idx': 13},\n",
       " {'id': 468, 'x': 11.018209, 'y': 3.2688198, 'topic_idx': 14},\n",
       " {'id': 469, 'x': 10.952388, 'y': 3.2012343, 'topic_idx': 14},\n",
       " {'id': 470, 'x': 10.91879, 'y': 3.2781427, 'topic_idx': 14},\n",
       " {'id': 471, 'x': 11.77319, 'y': 4.345037, 'topic_idx': 9},\n",
       " {'id': 472, 'x': 10.341898, 'y': 8.481763, 'topic_idx': 13},\n",
       " {'id': 473, 'x': 10.980908, 'y': 3.0667899, 'topic_idx': 14},\n",
       " {'id': 474, 'x': 9.653137, 'y': 2.3617415, 'topic_idx': 4},\n",
       " {'id': 475, 'x': 9.2830515, 'y': 7.903241, 'topic_idx': 8},\n",
       " {'id': 476, 'x': 10.4918995, 'y': 7.2288156, 'topic_idx': 13},\n",
       " {'id': 477, 'x': 8.234137, 'y': 4.309266, 'topic_idx': 0},\n",
       " {'id': 478, 'x': 10.328001, 'y': 2.6710556, 'topic_idx': 14},\n",
       " {'id': 479, 'x': 11.585743, 'y': 3.5568056, 'topic_idx': 14},\n",
       " {'id': 480, 'x': 9.99917, 'y': 8.763361, 'topic_idx': 2},\n",
       " {'id': 481, 'x': 9.656572, 'y': 7.420884, 'topic_idx': 13},\n",
       " {'id': 482, 'x': 6.5874643, 'y': 4.331602, 'topic_idx': 5},\n",
       " {'id': 483, 'x': 10.0727215, 'y': 10.109094, 'topic_idx': 2},\n",
       " {'id': 484, 'x': 10.66852, 'y': 2.4721193, 'topic_idx': 4},\n",
       " {'id': 485, 'x': 10.728512, 'y': 2.4856658, 'topic_idx': 4},\n",
       " {'id': 486, 'x': 11.129399, 'y': 3.3573487, 'topic_idx': 1},\n",
       " {'id': 487, 'x': 10.762984, 'y': 6.646727, 'topic_idx': 12},\n",
       " {'id': 488, 'x': 10.684829, 'y': 2.5315754, 'topic_idx': 14},\n",
       " {'id': 489, 'x': 10.799142, 'y': 2.5202672, 'topic_idx': 14},\n",
       " {'id': 490, 'x': 10.862225, 'y': 2.6173797, 'topic_idx': 14},\n",
       " {'id': 491, 'x': 10.507734, 'y': 2.6234283, 'topic_idx': 14},\n",
       " {'id': 492, 'x': 8.014897, 'y': 5.8541594, 'topic_idx': 7},\n",
       " {'id': 493, 'x': 9.715962, 'y': 9.638327, 'topic_idx': 2},\n",
       " {'id': 494, 'x': 4.1927104, 'y': 6.0022235, 'topic_idx': 6},\n",
       " {'id': 495, 'x': 9.618808, 'y': 9.924, 'topic_idx': 2},\n",
       " {'id': 496, 'x': 8.062458, 'y': 4.8929386, 'topic_idx': 3},\n",
       " {'id': 497, 'x': 7.54081, 'y': 6.5383763, 'topic_idx': 7},\n",
       " {'id': 498, 'x': 4.361431, 'y': 5.6775904, 'topic_idx': 6},\n",
       " {'id': 499, 'x': 4.1916723, 'y': 5.998691, 'topic_idx': 6},\n",
       " {'id': 500, 'x': 10.871467, 'y': 2.5503871, 'topic_idx': 4},\n",
       " {'id': 501, 'x': 11.558313, 'y': 3.4603763, 'topic_idx': 14},\n",
       " {'id': 502, 'x': 11.140037, 'y': 3.171898, 'topic_idx': 14},\n",
       " {'id': 503, 'x': 12.511083, 'y': 4.252726, 'topic_idx': 11},\n",
       " {'id': 504, 'x': 12.368141, 'y': 4.306961, 'topic_idx': 11},\n",
       " {'id': 505, 'x': 10.977254, 'y': 2.2967174, 'topic_idx': 4},\n",
       " {'id': 506, 'x': 7.247097, 'y': 4.6934066, 'topic_idx': 5},\n",
       " {'id': 507, 'x': 5.9439955, 'y': 5.4050436, 'topic_idx': 7},\n",
       " {'id': 508, 'x': 6.8597455, 'y': 4.498241, 'topic_idx': 5},\n",
       " {'id': 509, 'x': 7.5280614, 'y': 4.0089545, 'topic_idx': 5},\n",
       " {'id': 510, 'x': 5.9246726, 'y': 4.936342, 'topic_idx': 5},\n",
       " {'id': 511, 'x': 9.161679, 'y': 7.994762, 'topic_idx': 8},\n",
       " {'id': 512, 'x': 10.10899, 'y': 2.8069386, 'topic_idx': 4},\n",
       " {'id': 513, 'x': 7.647691, 'y': 3.677638, 'topic_idx': 5},\n",
       " {'id': 514, 'x': 12.8249655, 'y': 6.9083114, 'topic_idx': 1},\n",
       " {'id': 515, 'x': 12.9070015, 'y': 6.8113327, 'topic_idx': 1},\n",
       " {'id': 516, 'x': 10.389225, 'y': 8.827667, 'topic_idx': 2},\n",
       " {'id': 517, 'x': 10.602715, 'y': 7.4345827, 'topic_idx': 13},\n",
       " {'id': 518, 'x': 10.482367, 'y': 2.7334547, 'topic_idx': 4},\n",
       " {'id': 519, 'x': 11.622025, 'y': 7.7264457, 'topic_idx': 1},\n",
       " {'id': 520, 'x': 11.536203, 'y': 7.713034, 'topic_idx': 1},\n",
       " {'id': 521, 'x': 8.693824, 'y': 4.8434343, 'topic_idx': 0},\n",
       " {'id': 522, 'x': 5.141072, 'y': 3.6229262, 'topic_idx': 5},\n",
       " {'id': 523, 'x': 11.086362, 'y': 3.204902, 'topic_idx': 14},\n",
       " {'id': 524, 'x': 11.080334, 'y': 2.313389, 'topic_idx': 4},\n",
       " {'id': 525, 'x': 11.093425, 'y': 3.221944, 'topic_idx': 14},\n",
       " {'id': 526, 'x': 11.012553, 'y': 3.2779636, 'topic_idx': 14},\n",
       " {'id': 527, 'x': 10.494453, 'y': 4.733418, 'topic_idx': 0},\n",
       " {'id': 528, 'x': 10.019914, 'y': 2.9243336, 'topic_idx': 14},\n",
       " {'id': 529, 'x': 7.608183, 'y': 3.744755, 'topic_idx': 5},\n",
       " {'id': 530, 'x': 9.60106, 'y': 6.0734615, 'topic_idx': 13},\n",
       " {'id': 531, 'x': 8.403122, 'y': 7.520437, 'topic_idx': 3},\n",
       " {'id': 532, 'x': 8.469591, 'y': 5.0239196, 'topic_idx': 13},\n",
       " {'id': 533, 'x': 8.479508, 'y': 7.5074973, 'topic_idx': 3}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_idx_vector, docs_idx_vector, words_idx_vector = my_tm_model.get_2d_vectors()\n",
    "docs_idx_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['models' '모델' 'modelling' ... 'samples' 'modulation' 'neurobiology']\n",
      " ['variance' 'coefficient' 'regression' ... 'varlambda' '확률' 'estimators']\n",
      " ['statistically' 'statistical' 'statistics' ... 'impairments'\n",
      "  'stability' 'vulnerability']\n",
      " ...\n",
      " ['clustering' 'topics' 'clusters' ... 'computationally' 'summarize'\n",
      "  'infrastructure']\n",
      " ['storage' '저장' '기억력' ... 'datasets' '전략' '기록']\n",
      " ['clustering' 'topics' 'clusters' ... 'textrm' '클래스' 'summarize']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('doc_500', 'topic_23'),\n",
       " ('doc_501', 'topic_68'),\n",
       " ('doc_502', 'topic_7'),\n",
       " ('doc_503', 'topic_11'),\n",
       " ('doc_504', 'topic_11'),\n",
       " ('doc_505', 'topic_23'),\n",
       " ('doc_506', 'topic_56'),\n",
       " ('doc_507', 'topic_14'),\n",
       " ('doc_508', 'topic_24'),\n",
       " ('doc_509', 'topic_20'),\n",
       " ('doc_510', 'topic_41'),\n",
       " ('doc_511', 'topic_9'),\n",
       " ('doc_512', 'topic_25'),\n",
       " ('doc_513', 'topic_20'),\n",
       " ('doc_514', 'topic_37'),\n",
       " ('doc_515', 'topic_37'),\n",
       " ('doc_516', 'topic_10'),\n",
       " ('doc_517', 'topic_3'),\n",
       " ('doc_518', 'topic_25'),\n",
       " ('doc_519', 'topic_65'),\n",
       " ('doc_520', 'topic_65'),\n",
       " ('doc_521', 'topic_1'),\n",
       " ('doc_522', 'topic_32'),\n",
       " ('doc_523', 'topic_7'),\n",
       " ('doc_524', 'topic_23'),\n",
       " ('doc_525', 'topic_7'),\n",
       " ('doc_526', 'topic_7'),\n",
       " ('doc_527', 'topic_4'),\n",
       " ('doc_528', 'topic_25'),\n",
       " ('doc_529', 'topic_20'),\n",
       " ('doc_530', 'topic_62'),\n",
       " ('doc_531', 'topic_0'),\n",
       " ('doc_532', 'topic_1'),\n",
       " ('doc_533', 'topic_0'),\n",
       " ('word_2653', 'topic_0'),\n",
       " ('word_1047', 'topic_0'),\n",
       " ('word_4440', 'topic_0'),\n",
       " ('word_1048', 'topic_0'),\n",
       " ('word_1049', 'topic_0'),\n",
       " ('word_1875', 'topic_0'),\n",
       " ('word_2846', 'topic_0'),\n",
       " ('word_136', 'topic_0'),\n",
       " ('word_3004', 'topic_0'),\n",
       " ('word_2505', 'topic_0'),\n",
       " ('word_4090', 'topic_1'),\n",
       " ('word_4619', 'topic_1'),\n",
       " ('word_4440', 'topic_1'),\n",
       " ('word_4417', 'topic_1'),\n",
       " ('word_2453', 'topic_1'),\n",
       " ('word_6408', 'topic_1'),\n",
       " ('word_4419', 'topic_1'),\n",
       " ('word_694', 'topic_1'),\n",
       " ('word_2454', 'topic_1'),\n",
       " ('word_4451', 'topic_1'),\n",
       " ('word_5349', 'topic_2'),\n",
       " ('word_5910', 'topic_2'),\n",
       " ('word_4150', 'topic_2'),\n",
       " ('word_5680', 'topic_2'),\n",
       " ('word_5684', 'topic_2'),\n",
       " ('word_6413', 'topic_2'),\n",
       " ('word_2342', 'topic_2'),\n",
       " ('word_5384', 'topic_2'),\n",
       " ('word_5372', 'topic_2'),\n",
       " ('word_5036', 'topic_2'),\n",
       " ('word_2924', 'topic_3'),\n",
       " ('word_2925', 'topic_3'),\n",
       " ('word_2908', 'topic_3'),\n",
       " ('word_2923', 'topic_3'),\n",
       " ('word_2928', 'topic_3'),\n",
       " ('word_2926', 'topic_3'),\n",
       " ('word_2927', 'topic_3'),\n",
       " ('word_2911', 'topic_3'),\n",
       " ('word_2921', 'topic_3'),\n",
       " ('word_2912', 'topic_3'),\n",
       " ('word_4649', 'topic_4'),\n",
       " ('word_2928', 'topic_4'),\n",
       " ('word_2927', 'topic_4'),\n",
       " ('word_6103', 'topic_4'),\n",
       " ('word_1913', 'topic_4'),\n",
       " ('word_2926', 'topic_4'),\n",
       " ('word_4666', 'topic_4'),\n",
       " ('word_17', 'topic_4'),\n",
       " ('word_979', 'topic_4'),\n",
       " ('word_2912', 'topic_4'),\n",
       " ('word_2928', 'topic_5'),\n",
       " ('word_2927', 'topic_5'),\n",
       " ('word_2929', 'topic_5'),\n",
       " ('word_2925', 'topic_5'),\n",
       " ('word_2931', 'topic_5'),\n",
       " ('word_2923', 'topic_5'),\n",
       " ('word_2924', 'topic_5'),\n",
       " ('word_2926', 'topic_5'),\n",
       " ('word_2930', 'topic_5'),\n",
       " ('word_2912', 'topic_5'),\n",
       " ('word_5418', 'topic_6'),\n",
       " ('word_2776', 'topic_6'),\n",
       " ('word_2775', 'topic_6'),\n",
       " ('word_2774', 'topic_6'),\n",
       " ('word_2772', 'topic_6'),\n",
       " ('word_2773', 'topic_6'),\n",
       " ('word_956', 'topic_6'),\n",
       " ('word_981', 'topic_6'),\n",
       " ('word_957', 'topic_6'),\n",
       " ('word_2861', 'topic_6'),\n",
       " ('word_1467', 'topic_7'),\n",
       " ('word_6113', 'topic_7'),\n",
       " ('word_4981', 'topic_7'),\n",
       " ('word_3337', 'topic_7'),\n",
       " ('word_5503', 'topic_7'),\n",
       " ('word_3338', 'topic_7'),\n",
       " ('word_6023', 'topic_7'),\n",
       " ('word_3409', 'topic_7'),\n",
       " ('word_5413', 'topic_7'),\n",
       " ('word_4980', 'topic_7'),\n",
       " ('word_2908', 'topic_8'),\n",
       " ('word_2912', 'topic_8'),\n",
       " ('word_2928', 'topic_8'),\n",
       " ('word_2911', 'topic_8'),\n",
       " ('word_2927', 'topic_8'),\n",
       " ('word_2926', 'topic_8'),\n",
       " ('word_2924', 'topic_8'),\n",
       " ('word_2925', 'topic_8'),\n",
       " ('word_2923', 'topic_8'),\n",
       " ('word_806', 'topic_8'),\n",
       " ('word_1047', 'topic_9'),\n",
       " ('word_4240', 'topic_9'),\n",
       " ('word_1048', 'topic_9'),\n",
       " ('word_4242', 'topic_9'),\n",
       " ('word_4241', 'topic_9'),\n",
       " ('word_6340', 'topic_9'),\n",
       " ('word_4239', 'topic_9'),\n",
       " ('word_6339', 'topic_9'),\n",
       " ('word_1049', 'topic_9'),\n",
       " ('word_2847', 'topic_9'),\n",
       " ('word_3670', 'topic_10'),\n",
       " ('word_5418', 'topic_10'),\n",
       " ('word_2776', 'topic_10'),\n",
       " ('word_956', 'topic_10'),\n",
       " ('word_2775', 'topic_10'),\n",
       " ('word_4725', 'topic_10'),\n",
       " ('word_981', 'topic_10'),\n",
       " ('word_4240', 'topic_10'),\n",
       " ('word_957', 'topic_10'),\n",
       " ('word_4241', 'topic_10'),\n",
       " ('word_3503', 'topic_11'),\n",
       " ('word_3505', 'topic_11'),\n",
       " ('word_3507', 'topic_11'),\n",
       " ('word_3506', 'topic_11'),\n",
       " ('word_3502', 'topic_11'),\n",
       " ('word_3504', 'topic_11'),\n",
       " ('word_2928', 'topic_11'),\n",
       " ('word_2927', 'topic_11'),\n",
       " ('word_3508', 'topic_11'),\n",
       " ('word_2926', 'topic_11'),\n",
       " ('word_906', 'topic_12'),\n",
       " ('word_291', 'topic_12'),\n",
       " ('word_908', 'topic_12'),\n",
       " ('word_4353', 'topic_12'),\n",
       " ('word_910', 'topic_12'),\n",
       " ('word_1807', 'topic_12'),\n",
       " ('word_911', 'topic_12'),\n",
       " ('word_4351', 'topic_12'),\n",
       " ('word_909', 'topic_12'),\n",
       " ('word_6227', 'topic_12'),\n",
       " ('word_5752', 'topic_13'),\n",
       " ('word_5269', 'topic_13'),\n",
       " ('word_5748', 'topic_13'),\n",
       " ('word_5954', 'topic_13'),\n",
       " ('word_5750', 'topic_13'),\n",
       " ('word_5968', 'topic_13'),\n",
       " ('word_5967', 'topic_13'),\n",
       " ('word_33', 'topic_13'),\n",
       " ('word_6110', 'topic_13'),\n",
       " ('word_1000', 'topic_13'),\n",
       " ('word_3534', 'topic_14'),\n",
       " ('word_6359', 'topic_14'),\n",
       " ('word_1035', 'topic_14'),\n",
       " ('word_4309', 'topic_14'),\n",
       " ('word_4249', 'topic_14'),\n",
       " ('word_2653', 'topic_14'),\n",
       " ('word_2846', 'topic_14'),\n",
       " ('word_3004', 'topic_14'),\n",
       " ('word_1884', 'topic_14'),\n",
       " ('word_385', 'topic_14'),\n",
       " ('word_4725', 'topic_15'),\n",
       " ('word_4240', 'topic_15'),\n",
       " ('word_4242', 'topic_15'),\n",
       " ('word_730', 'topic_15'),\n",
       " ('word_4241', 'topic_15'),\n",
       " ('word_981', 'topic_15'),\n",
       " ('word_3433', 'topic_15'),\n",
       " ('word_4724', 'topic_15'),\n",
       " ('word_731', 'topic_15'),\n",
       " ('word_4239', 'topic_15'),\n",
       " ('word_3433', 'topic_16'),\n",
       " ('word_4241', 'topic_16'),\n",
       " ('word_4240', 'topic_16'),\n",
       " ('word_4242', 'topic_16'),\n",
       " ('word_4239', 'topic_16'),\n",
       " ('word_3435', 'topic_16'),\n",
       " ('word_6340', 'topic_16'),\n",
       " ('word_3562', 'topic_16'),\n",
       " ('word_730', 'topic_16'),\n",
       " ('word_3382', 'topic_16'),\n",
       " ('word_4631', 'topic_17'),\n",
       " ('word_6310', 'topic_17'),\n",
       " ('word_5563', 'topic_17'),\n",
       " ('word_4917', 'topic_17'),\n",
       " ('word_5920', 'topic_17'),\n",
       " ('word_2513', 'topic_17'),\n",
       " ('word_4324', 'topic_17'),\n",
       " ('word_3007', 'topic_17'),\n",
       " ('word_2382', 'topic_17'),\n",
       " ('word_490', 'topic_17'),\n",
       " ('word_3534', 'topic_18'),\n",
       " ('word_1035', 'topic_18'),\n",
       " ('word_3004', 'topic_18'),\n",
       " ('word_6359', 'topic_18'),\n",
       " ('word_2846', 'topic_18'),\n",
       " ('word_2247', 'topic_18'),\n",
       " ('word_6390', 'topic_18'),\n",
       " ('word_2653', 'topic_18'),\n",
       " ('word_6313', 'topic_18'),\n",
       " ('word_790', 'topic_18'),\n",
       " ('word_6430', 'topic_19'),\n",
       " ('word_1799', 'topic_19'),\n",
       " ('word_3534', 'topic_19'),\n",
       " ('word_1803', 'topic_19'),\n",
       " ('word_1035', 'topic_19'),\n",
       " ('word_1800', 'topic_19'),\n",
       " ('word_2410', 'topic_19'),\n",
       " ('word_5136', 'topic_19'),\n",
       " ('word_5521', 'topic_19'),\n",
       " ('word_1801', 'topic_19'),\n",
       " ('word_933', 'topic_20'),\n",
       " ('word_4090', 'topic_20'),\n",
       " ('word_185', 'topic_20'),\n",
       " ('word_5575', 'topic_20'),\n",
       " ('word_527', 'topic_20'),\n",
       " ('word_2345', 'topic_20'),\n",
       " ('word_1884', 'topic_20'),\n",
       " ('word_675', 'topic_20'),\n",
       " ('word_1698', 'topic_20'),\n",
       " ('word_184', 'topic_20'),\n",
       " ('word_2919', 'topic_21'),\n",
       " ('word_2929', 'topic_21'),\n",
       " ('word_2909', 'topic_21'),\n",
       " ('word_2920', 'topic_21'),\n",
       " ('word_2924', 'topic_21'),\n",
       " ('word_2914', 'topic_21'),\n",
       " ('word_2918', 'topic_21'),\n",
       " ('word_2921', 'topic_21'),\n",
       " ('word_2917', 'topic_21'),\n",
       " ('word_2928', 'topic_21'),\n",
       " ('word_3824', 'topic_22'),\n",
       " ('word_3823', 'topic_22'),\n",
       " ('word_3906', 'topic_22'),\n",
       " ('word_999', 'topic_22'),\n",
       " ('word_2065', 'topic_22'),\n",
       " ('word_3907', 'topic_22'),\n",
       " ('word_4', 'topic_22'),\n",
       " ('word_6026', 'topic_22'),\n",
       " ('word_1584', 'topic_22'),\n",
       " ('word_1243', 'topic_22'),\n",
       " ('word_6233', 'topic_23'),\n",
       " ('word_4893', 'topic_23'),\n",
       " ('word_5194', 'topic_23'),\n",
       " ('word_5193', 'topic_23'),\n",
       " ('word_1423', 'topic_23'),\n",
       " ('word_6234', 'topic_23'),\n",
       " ('word_5124', 'topic_23'),\n",
       " ('word_6235', 'topic_23'),\n",
       " ('word_6232', 'topic_23'),\n",
       " ('word_4216', 'topic_23'),\n",
       " ('word_4688', 'topic_24'),\n",
       " ('word_4687', 'topic_24'),\n",
       " ('word_3665', 'topic_24'),\n",
       " ('word_3742', 'topic_24'),\n",
       " ('word_1431', 'topic_24'),\n",
       " ('word_4656', 'topic_24'),\n",
       " ('word_4704', 'topic_24'),\n",
       " ('word_3640', 'topic_24'),\n",
       " ('word_3641', 'topic_24'),\n",
       " ('word_1432', 'topic_24'),\n",
       " ('word_5648', 'topic_25'),\n",
       " ('word_5646', 'topic_25'),\n",
       " ('word_5647', 'topic_25'),\n",
       " ('word_3975', 'topic_25'),\n",
       " ('word_2405', 'topic_25'),\n",
       " ('word_6376', 'topic_25'),\n",
       " ('word_2404', 'topic_25'),\n",
       " ('word_6412', 'topic_25'),\n",
       " ('word_6413', 'topic_25'),\n",
       " ('word_6414', 'topic_25'),\n",
       " ('word_2907', 'topic_26'),\n",
       " ('word_5192', 'topic_26'),\n",
       " ('word_2906', 'topic_26'),\n",
       " ('word_2908', 'topic_26'),\n",
       " ('word_2924', 'topic_26'),\n",
       " ('word_2923', 'topic_26'),\n",
       " ('word_2905', 'topic_26'),\n",
       " ('word_2925', 'topic_26'),\n",
       " ('word_2912', 'topic_26'),\n",
       " ('word_2911', 'topic_26'),\n",
       " ('word_956', 'topic_27'),\n",
       " ('word_957', 'topic_27'),\n",
       " ('word_954', 'topic_27'),\n",
       " ('word_953', 'topic_27'),\n",
       " ('word_955', 'topic_27'),\n",
       " ('word_5584', 'topic_27'),\n",
       " ('word_2914', 'topic_27'),\n",
       " ('word_2911', 'topic_27'),\n",
       " ('word_2932', 'topic_27'),\n",
       " ('word_730', 'topic_27'),\n",
       " ('word_4886', 'topic_28'),\n",
       " ('word_1668', 'topic_28'),\n",
       " ('word_1667', 'topic_28'),\n",
       " ('word_1845', 'topic_28'),\n",
       " ('word_5844', 'topic_28'),\n",
       " ('word_1666', 'topic_28'),\n",
       " ('word_1844', 'topic_28'),\n",
       " ('word_4885', 'topic_28'),\n",
       " ('word_2605', 'topic_28'),\n",
       " ('word_2711', 'topic_28'),\n",
       " ('word_4917', 'topic_29'),\n",
       " ('word_3007', 'topic_29'),\n",
       " ('word_4631', 'topic_29'),\n",
       " ('word_2382', 'topic_29'),\n",
       " ('word_6310', 'topic_29'),\n",
       " ('word_2513', 'topic_29'),\n",
       " ('word_1910', 'topic_29'),\n",
       " ('word_4324', 'topic_29'),\n",
       " ('word_5920', 'topic_29'),\n",
       " ('word_1842', 'topic_29'),\n",
       " ('word_2345', 'topic_30'),\n",
       " ('word_4905', 'topic_30'),\n",
       " ('word_4907', 'topic_30'),\n",
       " ('word_2344', 'topic_30'),\n",
       " ('word_3918', 'topic_30'),\n",
       " ('word_4908', 'topic_30'),\n",
       " ('word_4906', 'topic_30'),\n",
       " ('word_3919', 'topic_30'),\n",
       " ('word_2388', 'topic_30'),\n",
       " ('word_4910', 'topic_30'),\n",
       " ('word_1875', 'topic_31'),\n",
       " ('word_2505', 'topic_31'),\n",
       " ('word_2653', 'topic_31'),\n",
       " ('word_3888', 'topic_31'),\n",
       " ('word_505', 'topic_31'),\n",
       " ('word_1047', 'topic_31'),\n",
       " ('word_1048', 'topic_31'),\n",
       " ('word_1049', 'topic_31'),\n",
       " ('word_3313', 'topic_31'),\n",
       " ('word_1919', 'topic_31'),\n",
       " ('word_1884', 'topic_32'),\n",
       " ('word_31', 'topic_32'),\n",
       " ('word_34', 'topic_32'),\n",
       " ('word_1134', 'topic_32'),\n",
       " ('word_1182', 'topic_32'),\n",
       " ('word_1135', 'topic_32'),\n",
       " ('word_4991', 'topic_32'),\n",
       " ('word_3469', 'topic_32'),\n",
       " ('word_6393', 'topic_32'),\n",
       " ('word_5032', 'topic_32'),\n",
       " ('word_2149', 'topic_33'),\n",
       " ('word_2929', 'topic_33'),\n",
       " ('word_2148', 'topic_33'),\n",
       " ('word_2928', 'topic_33'),\n",
       " ('word_3972', 'topic_33'),\n",
       " ('word_2914', 'topic_33'),\n",
       " ('word_4137', 'topic_33'),\n",
       " ('word_2927', 'topic_33'),\n",
       " ('word_2926', 'topic_33'),\n",
       " ('word_2919', 'topic_33'),\n",
       " ('word_1673', 'topic_34'),\n",
       " ('word_5685', 'topic_34'),\n",
       " ('word_2519', 'topic_34'),\n",
       " ('word_3906', 'topic_34'),\n",
       " ('word_5064', 'topic_34'),\n",
       " ('word_5063', 'topic_34'),\n",
       " ('word_3902', 'topic_34'),\n",
       " ('word_3907', 'topic_34'),\n",
       " ('word_2985', 'topic_34'),\n",
       " ('word_5452', 'topic_34'),\n",
       " ('word_1049', 'topic_35'),\n",
       " ('word_1048', 'topic_35'),\n",
       " ('word_1045', 'topic_35'),\n",
       " ('word_4241', 'topic_35'),\n",
       " ('word_4240', 'topic_35'),\n",
       " ('word_4242', 'topic_35'),\n",
       " ('word_1047', 'topic_35'),\n",
       " ('word_3201', 'topic_35'),\n",
       " ('word_5288', 'topic_35'),\n",
       " ('word_3382', 'topic_35'),\n",
       " ('word_3433', 'topic_36'),\n",
       " ('word_3435', 'topic_36'),\n",
       " ('word_981', 'topic_36'),\n",
       " ('word_4040', 'topic_36'),\n",
       " ('word_2967', 'topic_36'),\n",
       " ('word_4658', 'topic_36'),\n",
       " ('word_4041', 'topic_36'),\n",
       " ('word_718', 'topic_36'),\n",
       " ('word_4374', 'topic_36'),\n",
       " ('word_1244', 'topic_36'),\n",
       " ('word_2921', 'topic_37'),\n",
       " ('word_2922', 'topic_37'),\n",
       " ('word_2909', 'topic_37'),\n",
       " ('word_2917', 'topic_37'),\n",
       " ('word_2920', 'topic_37'),\n",
       " ('word_168', 'topic_37'),\n",
       " ('word_2926', 'topic_37'),\n",
       " ('word_167', 'topic_37'),\n",
       " ('word_2928', 'topic_37'),\n",
       " ('word_2911', 'topic_37'),\n",
       " ('word_2917', 'topic_38'),\n",
       " ('word_2924', 'topic_38'),\n",
       " ('word_2921', 'topic_38'),\n",
       " ('word_2909', 'topic_38'),\n",
       " ('word_2919', 'topic_38'),\n",
       " ('word_2911', 'topic_38'),\n",
       " ('word_2908', 'topic_38'),\n",
       " ('word_2920', 'topic_38'),\n",
       " ('word_2912', 'topic_38'),\n",
       " ('word_2925', 'topic_38'),\n",
       " ('word_4207', 'topic_39'),\n",
       " ('word_6310', 'topic_39'),\n",
       " ('word_2513', 'topic_39'),\n",
       " ('word_4631', 'topic_39'),\n",
       " ('word_3921', 'topic_39'),\n",
       " ('word_385', 'topic_39'),\n",
       " ('word_5563', 'topic_39'),\n",
       " ('word_5417', 'topic_39'),\n",
       " ('word_5920', 'topic_39'),\n",
       " ('word_1234', 'topic_39'),\n",
       " ('word_5570', 'topic_40'),\n",
       " ('word_1271', 'topic_40'),\n",
       " ('word_1272', 'topic_40'),\n",
       " ('word_1270', 'topic_40'),\n",
       " ('word_3433', 'topic_40'),\n",
       " ('word_3435', 'topic_40'),\n",
       " ('word_4725', 'topic_40'),\n",
       " ('word_4240', 'topic_40'),\n",
       " ('word_4241', 'topic_40'),\n",
       " ('word_4726', 'topic_40'),\n",
       " ('word_675', 'topic_41'),\n",
       " ('word_527', 'topic_41'),\n",
       " ('word_6323', 'topic_41'),\n",
       " ('word_5575', 'topic_41'),\n",
       " ('word_1698', 'topic_41'),\n",
       " ('word_2830', 'topic_41'),\n",
       " ('word_2345', 'topic_41'),\n",
       " ('word_4832', 'topic_41'),\n",
       " ('word_3856', 'topic_41'),\n",
       " ('word_4831', 'topic_41'),\n",
       " ('word_4240', 'topic_42'),\n",
       " ('word_6340', 'topic_42'),\n",
       " ('word_6339', 'topic_42'),\n",
       " ('word_4242', 'topic_42'),\n",
       " ('word_4241', 'topic_42'),\n",
       " ('word_185', 'topic_42'),\n",
       " ('word_3154', 'topic_42'),\n",
       " ('word_2961', 'topic_42'),\n",
       " ('word_3670', 'topic_42'),\n",
       " ('word_183', 'topic_42'),\n",
       " ('word_2929', 'topic_43'),\n",
       " ('word_2912', 'topic_43'),\n",
       " ('word_455', 'topic_43'),\n",
       " ('word_2911', 'topic_43'),\n",
       " ('word_459', 'topic_43'),\n",
       " ('word_6080', 'topic_43'),\n",
       " ('word_5873', 'topic_43'),\n",
       " ('word_2928', 'topic_43'),\n",
       " ('word_2927', 'topic_43'),\n",
       " ('word_2913', 'topic_43'),\n",
       " ('word_6185', 'topic_44'),\n",
       " ('word_6348', 'topic_44'),\n",
       " ('word_4017', 'topic_44'),\n",
       " ('word_2307', 'topic_44'),\n",
       " ('word_6484', 'topic_44'),\n",
       " ('word_5495', 'topic_44'),\n",
       " ('word_6383', 'topic_44'),\n",
       " ('word_33', 'topic_44'),\n",
       " ('word_6490', 'topic_44'),\n",
       " ('word_1804', 'topic_44'),\n",
       " ('word_5658', 'topic_45'),\n",
       " ('word_4320', 'topic_45'),\n",
       " ('word_5760', 'topic_45'),\n",
       " ('word_4321', 'topic_45'),\n",
       " ('word_1630', 'topic_45'),\n",
       " ('word_1632', 'topic_45'),\n",
       " ('word_1631', 'topic_45'),\n",
       " ('word_4906', 'topic_45'),\n",
       " ('word_5296', 'topic_45'),\n",
       " ('word_6069', 'topic_45'),\n",
       " ('word_993', 'topic_46'),\n",
       " ('word_3315', 'topic_46'),\n",
       " ('word_4432', 'topic_46'),\n",
       " ('word_1884', 'topic_46'),\n",
       " ('word_1918', 'topic_46'),\n",
       " ('word_491', 'topic_46'),\n",
       " ('word_1832', 'topic_46'),\n",
       " ('word_6430', 'topic_46'),\n",
       " ('word_3362', 'topic_46'),\n",
       " ('word_2653', 'topic_46'),\n",
       " ('word_956', 'topic_47'),\n",
       " ('word_4241', 'topic_47'),\n",
       " ('word_957', 'topic_47'),\n",
       " ('word_954', 'topic_47'),\n",
       " ('word_4240', 'topic_47'),\n",
       " ('word_955', 'topic_47'),\n",
       " ('word_953', 'topic_47'),\n",
       " ('word_1865', 'topic_47'),\n",
       " ('word_4051', 'topic_47'),\n",
       " ('word_3435', 'topic_47'),\n",
       " ('word_4440', 'topic_48'),\n",
       " ('word_2653', 'topic_48'),\n",
       " ('word_1884', 'topic_48'),\n",
       " ('word_3007', 'topic_48'),\n",
       " ('word_1838', 'topic_48'),\n",
       " ('word_1842', 'topic_48'),\n",
       " ('word_4631', 'topic_48'),\n",
       " ('word_4917', 'topic_48'),\n",
       " ('word_4799', 'topic_48'),\n",
       " ('word_5920', 'topic_48'),\n",
       " ('word_4631', 'topic_49'),\n",
       " ('word_5920', 'topic_49'),\n",
       " ('word_1842', 'topic_49'),\n",
       " ('word_4917', 'topic_49'),\n",
       " ('word_2513', 'topic_49'),\n",
       " ('word_385', 'topic_49'),\n",
       " ('word_4324', 'topic_49'),\n",
       " ('word_6310', 'topic_49'),\n",
       " ('word_2232', 'topic_49'),\n",
       " ('word_4656', 'topic_49'),\n",
       " ('word_318', 'topic_50'),\n",
       " ('word_1589', 'topic_50'),\n",
       " ('word_1259', 'topic_50'),\n",
       " ('word_6430', 'topic_50'),\n",
       " ('word_1919', 'topic_50'),\n",
       " ('word_806', 'topic_50'),\n",
       " ('word_1915', 'topic_50'),\n",
       " ('word_2646', 'topic_50'),\n",
       " ('word_807', 'topic_50'),\n",
       " ('word_805', 'topic_50'),\n",
       " ('word_4241', 'topic_51'),\n",
       " ('word_4240', 'topic_51'),\n",
       " ('word_981', 'topic_51'),\n",
       " ('word_1048', 'topic_51'),\n",
       " ('word_4242', 'topic_51'),\n",
       " ('word_4239', 'topic_51'),\n",
       " ('word_956', 'topic_51'),\n",
       " ('word_957', 'topic_51'),\n",
       " ('word_730', 'topic_51'),\n",
       " ('word_1047', 'topic_51'),\n",
       " ('word_2909', 'topic_52'),\n",
       " ('word_2919', 'topic_52'),\n",
       " ('word_2929', 'topic_52'),\n",
       " ('word_2911', 'topic_52'),\n",
       " ('word_2928', 'topic_52'),\n",
       " ('word_2920', 'topic_52'),\n",
       " ('word_2912', 'topic_52'),\n",
       " ('word_2924', 'topic_52'),\n",
       " ('word_2927', 'topic_52'),\n",
       " ('word_2917', 'topic_52'),\n",
       " ('word_1142', 'topic_53'),\n",
       " ('word_82', 'topic_53'),\n",
       " ('word_4241', 'topic_53'),\n",
       " ('word_4240', 'topic_53'),\n",
       " ('word_1143', 'topic_53'),\n",
       " ('word_1193', 'topic_53'),\n",
       " ('word_1194', 'topic_53'),\n",
       " ('word_4242', 'topic_53'),\n",
       " ('word_4380', 'topic_53'),\n",
       " ('word_3894', 'topic_53'),\n",
       " ('word_24', 'topic_54'),\n",
       " ('word_6126', 'topic_54'),\n",
       " ('word_25', 'topic_54'),\n",
       " ('word_5900', 'topic_54'),\n",
       " ('word_3083', 'topic_54'),\n",
       " ('word_286', 'topic_54'),\n",
       " ('word_5097', 'topic_54'),\n",
       " ('word_5951', 'topic_54'),\n",
       " ('word_4122', 'topic_54'),\n",
       " ('word_1860', 'topic_54'),\n",
       " ('word_4208', 'topic_55'),\n",
       " ('word_5920', 'topic_55'),\n",
       " ('word_1884', 'topic_55'),\n",
       " ('word_2513', 'topic_55'),\n",
       " ('word_4631', 'topic_55'),\n",
       " ('word_4249', 'topic_55'),\n",
       " ('word_385', 'topic_55'),\n",
       " ('word_2535', 'topic_55'),\n",
       " ('word_6332', 'topic_55'),\n",
       " ('word_6310', 'topic_55'),\n",
       " ('word_2055', 'topic_56'),\n",
       " ('word_2388', 'topic_56'),\n",
       " ('word_4688', 'topic_56'),\n",
       " ('word_4704', 'topic_56'),\n",
       " ('word_1035', 'topic_56'),\n",
       " ('word_6359', 'topic_56'),\n",
       " ('word_3534', 'topic_56'),\n",
       " ('word_1013', 'topic_56'),\n",
       " ('word_2345', 'topic_56'),\n",
       " ('word_5448', 'topic_56'),\n",
       " ('word_2647', 'topic_57'),\n",
       " ('word_2651', 'topic_57'),\n",
       " ('word_2650', 'topic_57'),\n",
       " ('word_2648', 'topic_57'),\n",
       " ('word_2645', 'topic_57'),\n",
       " ('word_5703', 'topic_57'),\n",
       " ('word_2649', 'topic_57'),\n",
       " ('word_1868', 'topic_57'),\n",
       " ('word_4467', 'topic_57'),\n",
       " ('word_553', 'topic_57'),\n",
       " ('word_1408', 'topic_58'),\n",
       " ('word_2590', 'topic_58'),\n",
       " ('word_4157', 'topic_58'),\n",
       " ('word_3352', 'topic_58'),\n",
       " ('word_78', 'topic_58'),\n",
       " ('word_2927', 'topic_58'),\n",
       " ('word_2928', 'topic_58'),\n",
       " ('word_3907', 'topic_58'),\n",
       " ('word_3965', 'topic_58'),\n",
       " ('word_76', 'topic_58'),\n",
       " ('word_82', 'topic_59'),\n",
       " ('word_666', 'topic_59'),\n",
       " ('word_4380', 'topic_59'),\n",
       " ('word_1193', 'topic_59'),\n",
       " ('word_1183', 'topic_59'),\n",
       " ('word_4379', 'topic_59'),\n",
       " ('word_664', 'topic_59'),\n",
       " ('word_2922', 'topic_59'),\n",
       " ('word_1194', 'topic_59'),\n",
       " ('word_2929', 'topic_59'),\n",
       " ('word_2361', 'topic_60'),\n",
       " ('word_3897', 'topic_60'),\n",
       " ('word_3513', 'topic_60'),\n",
       " ('word_2583', 'topic_60'),\n",
       " ('word_5857', 'topic_60'),\n",
       " ('word_3898', 'topic_60'),\n",
       " ('word_6406', 'topic_60'),\n",
       " ('word_5452', 'topic_60'),\n",
       " ('word_3514', 'topic_60'),\n",
       " ('word_17', 'topic_60'),\n",
       " ('word_1884', 'topic_61'),\n",
       " ('word_1234', 'topic_61'),\n",
       " ('word_1883', 'topic_61'),\n",
       " ('word_385', 'topic_61'),\n",
       " ('word_1728', 'topic_61'),\n",
       " ('word_1681', 'topic_61'),\n",
       " ('word_1842', 'topic_61'),\n",
       " ('word_1727', 'topic_61'),\n",
       " ('word_3716', 'topic_61'),\n",
       " ('word_4369', 'topic_61'),\n",
       " ('word_3433', 'topic_62'),\n",
       " ('word_806', 'topic_62'),\n",
       " ('word_805', 'topic_62'),\n",
       " ('word_4069', 'topic_62'),\n",
       " ('word_6340', 'topic_62'),\n",
       " ('word_807', 'topic_62'),\n",
       " ('word_4068', 'topic_62'),\n",
       " ('word_4067', 'topic_62'),\n",
       " ('word_3273', 'topic_62'),\n",
       " ('word_4468', 'topic_62'),\n",
       " ('word_1048', 'topic_63'),\n",
       " ('word_1935', 'topic_63'),\n",
       " ('word_1931', 'topic_63'),\n",
       " ('word_1932', 'topic_63'),\n",
       " ('word_1934', 'topic_63'),\n",
       " ('word_5117', 'topic_63'),\n",
       " ('word_1933', 'topic_63'),\n",
       " ('word_1047', 'topic_63'),\n",
       " ('word_3665', 'topic_63'),\n",
       " ('word_782', 'topic_63'),\n",
       " ('word_1048', 'topic_64'),\n",
       " ('word_2860', 'topic_64'),\n",
       " ('word_1047', 'topic_64'),\n",
       " ('word_2652', 'topic_64'),\n",
       " ('word_3004', 'topic_64'),\n",
       " ('word_2653', 'topic_64'),\n",
       " ('word_1049', 'topic_64'),\n",
       " ('word_4920', 'topic_64'),\n",
       " ('word_2859', 'topic_64'),\n",
       " ('word_2862', 'topic_64'),\n",
       " ('word_647', 'topic_65'),\n",
       " ('word_2266', 'topic_65'),\n",
       " ('word_2149', 'topic_65'),\n",
       " ('word_2265', 'topic_65'),\n",
       " ('word_1026', 'topic_65'),\n",
       " ('word_2924', 'topic_65'),\n",
       " ('word_646', 'topic_65'),\n",
       " ('word_2914', 'topic_65'),\n",
       " ('word_2912', 'topic_65'),\n",
       " ('word_2911', 'topic_65'),\n",
       " ('word_4771', 'topic_66'),\n",
       " ('word_1668', 'topic_66'),\n",
       " ('word_5075', 'topic_66'),\n",
       " ('word_3455', 'topic_66'),\n",
       " ('word_6397', 'topic_66'),\n",
       " ('word_4404', 'topic_66'),\n",
       " ('word_4930', 'topic_66'),\n",
       " ('word_3514', 'topic_66'),\n",
       " ('word_3730', 'topic_66'),\n",
       " ('word_3731', 'topic_66'),\n",
       " ('word_225', 'topic_67'),\n",
       " ('word_6312', 'topic_67'),\n",
       " ('word_6313', 'topic_67'),\n",
       " ('word_789', 'topic_67'),\n",
       " ('word_2344', 'topic_67'),\n",
       " ('word_790', 'topic_67'),\n",
       " ('word_3816', 'topic_67'),\n",
       " ('word_6065', 'topic_67'),\n",
       " ('word_193', 'topic_67'),\n",
       " ('word_5920', 'topic_67'),\n",
       " ('word_6318', 'topic_68'),\n",
       " ('word_1628', 'topic_68'),\n",
       " ('word_1467', 'topic_68'),\n",
       " ('word_1335', 'topic_68'),\n",
       " ('word_2687', 'topic_68'),\n",
       " ('word_5210', 'topic_68'),\n",
       " ('word_1648', 'topic_68'),\n",
       " ('word_5593', 'topic_68'),\n",
       " ('word_3300', 'topic_68'),\n",
       " ('word_1065', 'topic_68'),\n",
       " ('word_3433', 'topic_69'),\n",
       " ('word_4240', 'topic_69'),\n",
       " ('word_4241', 'topic_69'),\n",
       " ('word_3562', 'topic_69'),\n",
       " ('word_3670', 'topic_69'),\n",
       " ('word_981', 'topic_69'),\n",
       " ('word_3435', 'topic_69'),\n",
       " ('word_3383', 'topic_69'),\n",
       " ('word_4242', 'topic_69'),\n",
       " ('word_3382', 'topic_69'),\n",
       " ('word_718', 'topic_70'),\n",
       " ('word_719', 'topic_70'),\n",
       " ('word_2653', 'topic_70'),\n",
       " ('word_717', 'topic_70'),\n",
       " ('word_1048', 'topic_70'),\n",
       " ('word_1047', 'topic_70'),\n",
       " ('word_1049', 'topic_70'),\n",
       " ('word_4090', 'topic_70'),\n",
       " ('word_3004', 'topic_70'),\n",
       " ('word_1045', 'topic_70'),\n",
       " ('word_4238', 'topic_71'),\n",
       " ('word_4561', 'topic_71'),\n",
       " ('word_5866', 'topic_71'),\n",
       " ('word_5267', 'topic_71'),\n",
       " ('word_4237', 'topic_71'),\n",
       " ('word_6230', 'topic_71'),\n",
       " ('word_4558', 'topic_71'),\n",
       " ('word_5151', 'topic_71'),\n",
       " ('word_2731', 'topic_71'),\n",
       " ('word_6340', 'topic_71'),\n",
       " ('doc_0', 'word_2776'),\n",
       " ('doc_0', 'word_5418'),\n",
       " ('doc_0', 'word_2775'),\n",
       " ('doc_0', 'word_2773'),\n",
       " ('doc_0', 'word_2772'),\n",
       " ('doc_0', 'word_2774'),\n",
       " ('doc_0', 'word_2861'),\n",
       " ('doc_0', 'word_3460'),\n",
       " ('doc_0', 'word_4432'),\n",
       " ('doc_0', 'word_2788'),\n",
       " ('doc_0', 'word_4619'),\n",
       " ('doc_0', 'word_6391'),\n",
       " ('doc_0', 'word_3458'),\n",
       " ('doc_0', 'word_4090'),\n",
       " ('doc_0', 'word_5420'),\n",
       " ('doc_0', 'word_3459'),\n",
       " ('doc_0', 'word_2787'),\n",
       " ('doc_0', 'word_4127'),\n",
       " ('doc_0', 'word_3203'),\n",
       " ('doc_0', 'word_2786'),\n",
       " ('doc_0', 'word_3148'),\n",
       " ('doc_0', 'word_694'),\n",
       " ('doc_0', 'word_2613'),\n",
       " ('doc_0', 'word_3202'),\n",
       " ('doc_0', 'word_464'),\n",
       " ('doc_0', 'word_3893'),\n",
       " ('doc_0', 'word_491'),\n",
       " ('doc_0', 'word_979'),\n",
       " ('doc_0', 'word_1198'),\n",
       " ('doc_0', 'word_2784'),\n",
       " ('doc_0', 'word_3147'),\n",
       " ('doc_0', 'word_2781'),\n",
       " ('doc_0', 'word_5688'),\n",
       " ('doc_0', 'word_2783'),\n",
       " ('doc_0', 'word_2846'),\n",
       " ('doc_0', 'word_2685'),\n",
       " ('doc_0', 'word_4536'),\n",
       " ('doc_0', 'word_4431'),\n",
       " ('doc_0', 'word_1120'),\n",
       " ('doc_0', 'word_6366'),\n",
       " ('doc_0', 'word_3469'),\n",
       " ('doc_0', 'word_2614'),\n",
       " ('doc_0', 'word_2782'),\n",
       " ('doc_0', 'word_3892'),\n",
       " ('doc_0', 'word_3401'),\n",
       " ('doc_0', 'word_2771'),\n",
       " ('doc_0', 'word_4417'),\n",
       " ('doc_0', 'word_3867'),\n",
       " ('doc_0', 'word_2785'),\n",
       " ('doc_0', 'word_2912'),\n",
       " ('doc_1', 'word_4725'),\n",
       " ('doc_1', 'word_730'),\n",
       " ('doc_1', 'word_3670'),\n",
       " ('doc_1', 'word_731'),\n",
       " ('doc_1', 'word_4726'),\n",
       " ('doc_1', 'word_4722'),\n",
       " ('doc_1', 'word_4240'),\n",
       " ('doc_1', 'word_4242'),\n",
       " ('doc_1', 'word_4241'),\n",
       " ('doc_1', 'word_4724'),\n",
       " ('doc_1', 'word_3382'),\n",
       " ('doc_1', 'word_4239'),\n",
       " ('doc_1', 'word_981'),\n",
       " ('doc_1', 'word_3384'),\n",
       " ('doc_1', 'word_3383'),\n",
       " ('doc_1', 'word_3385'),\n",
       " ('doc_1', 'word_5521'),\n",
       " ('doc_1', 'word_3435'),\n",
       " ('doc_1', 'word_3433'),\n",
       " ('doc_1', 'word_2847'),\n",
       " ('doc_1', 'word_3377'),\n",
       " ('doc_1', 'word_3379'),\n",
       " ('doc_1', 'word_4730'),\n",
       " ('doc_1', 'word_6339'),\n",
       " ('doc_1', 'word_1496'),\n",
       " ('doc_1', 'word_2653'),\n",
       " ('doc_1', 'word_3434'),\n",
       " ('doc_1', 'word_6340'),\n",
       " ('doc_1', 'word_6287'),\n",
       " ('doc_1', 'word_4723'),\n",
       " ('doc_1', 'word_1589'),\n",
       " ('doc_1', 'word_1493'),\n",
       " ('doc_1', 'word_881'),\n",
       " ('doc_1', 'word_3381'),\n",
       " ('doc_1', 'word_956'),\n",
       " ('doc_1', 'word_6084'),\n",
       " ('doc_1', 'word_1494'),\n",
       " ('doc_1', 'word_1626'),\n",
       " ('doc_1', 'word_4440'),\n",
       " ('doc_1', 'word_1492'),\n",
       " ('doc_1', 'word_3338'),\n",
       " ('doc_1', 'word_6356'),\n",
       " ('doc_1', 'word_3879'),\n",
       " ('doc_1', 'word_4243'),\n",
       " ('doc_1', 'word_3380'),\n",
       " ('doc_1', 'word_1495'),\n",
       " ('doc_1', 'word_4729'),\n",
       " ('doc_1', 'word_4736'),\n",
       " ('doc_1', 'word_6476'),\n",
       " ('doc_1', 'word_1497'),\n",
       " ('doc_2', 'word_4241'),\n",
       " ('doc_2', 'word_4240'),\n",
       " ('doc_2', 'word_4242'),\n",
       " ('doc_2', 'word_4239'),\n",
       " ('doc_2', 'word_6340'),\n",
       " ('doc_2', 'word_6339'),\n",
       " ('doc_2', 'word_3670'),\n",
       " ('doc_2', 'word_4243'),\n",
       " ('doc_2', 'word_1048'),\n",
       " ('doc_2', 'word_3433'),\n",
       " ('doc_2', 'word_4229'),\n",
       " ('doc_2', 'word_1049'),\n",
       " ('doc_2', 'word_1270'),\n",
       " ('doc_2', 'word_957'),\n",
       " ('doc_2', 'word_6062'),\n",
       " ('doc_2', 'word_1272'),\n",
       " ('doc_2', 'word_3435'),\n",
       " ('doc_2', 'word_1271'),\n",
       " ('doc_2', 'word_894'),\n",
       " ('doc_2', 'word_3888'),\n",
       " ('doc_2', 'word_3762'),\n",
       " ('doc_2', 'word_2653'),\n",
       " ('doc_2', 'word_4725'),\n",
       " ('doc_2', 'word_4726'),\n",
       " ('doc_2', 'word_3761'),\n",
       " ('doc_2', 'word_3754'),\n",
       " ('doc_2', 'word_6490'),\n",
       " ('doc_2', 'word_1045'),\n",
       " ('doc_2', 'word_1047'),\n",
       " ('doc_2', 'word_3157'),\n",
       " ('doc_2', 'word_6342'),\n",
       " ('doc_2', 'word_956'),\n",
       " ('doc_2', 'word_350'),\n",
       " ('doc_2', 'word_5288'),\n",
       " ('doc_2', 'word_4688'),\n",
       " ('doc_2', 'word_2482'),\n",
       " ('doc_2', 'word_2300'),\n",
       " ('doc_2', 'word_4152'),\n",
       " ('doc_2', 'word_3753'),\n",
       " ('doc_2', 'word_1875'),\n",
       " ('doc_2', 'word_3130'),\n",
       " ('doc_2', 'word_4338'),\n",
       " ('doc_2', 'word_981'),\n",
       " ('doc_2', 'word_2776'),\n",
       " ('doc_2', 'word_2847'),\n",
       " ('doc_2', 'word_5876'),\n",
       " ('doc_2', 'word_3513'),\n",
       " ('doc_2', 'word_2125'),\n",
       " ('doc_2', 'word_4213'),\n",
       " ('doc_2', 'word_4801'),\n",
       " ('doc_3', 'word_4688'),\n",
       " ('doc_3', 'word_4687'),\n",
       " ('doc_3', 'word_3670'),\n",
       " ('doc_3', 'word_4240'),\n",
       " ('doc_3', 'word_4242'),\n",
       " ('doc_3', 'word_4241'),\n",
       " ('doc_3', 'word_4239'),\n",
       " ('doc_3', 'word_6340'),\n",
       " ('doc_3', 'word_956'),\n",
       " ('doc_3', 'word_957'),\n",
       " ('doc_3', 'word_185'),\n",
       " ('doc_3', 'word_4725'),\n",
       " ('doc_3', 'word_4724'),\n",
       " ('doc_3', 'word_6339'),\n",
       " ('doc_3', 'word_1047'),\n",
       " ('doc_3', 'word_4243'),\n",
       " ('doc_3', 'word_5521'),\n",
       " ('doc_3', 'word_2847'),\n",
       " ('doc_3', 'word_981'),\n",
       " ('doc_3', 'word_4726'),\n",
       " ('doc_3', 'word_6084'),\n",
       " ('doc_3', 'word_4722'),\n",
       " ('doc_3', 'word_1133'),\n",
       " ('doc_3', 'word_184'),\n",
       " ('doc_3', 'word_183'),\n",
       " ('doc_3', 'word_4229'),\n",
       " ('doc_3', 'word_182'),\n",
       " ('doc_3', 'word_4723'),\n",
       " ('doc_3', 'word_954'),\n",
       " ('doc_3', 'word_1135'),\n",
       " ('doc_3', 'word_955'),\n",
       " ('doc_3', 'word_1875'),\n",
       " ('doc_3', 'word_953'),\n",
       " ('doc_3', 'word_5567'),\n",
       " ('doc_3', 'word_4730'),\n",
       " ('doc_3', 'word_1134'),\n",
       " ('doc_3', 'word_1048'),\n",
       " ('doc_3', 'word_187'),\n",
       " ('doc_3', 'word_731'),\n",
       " ('doc_3', 'word_186'),\n",
       " ('doc_3', 'word_730'),\n",
       " ('doc_3', 'word_6356'),\n",
       " ('doc_3', 'word_3154'),\n",
       " ('doc_3', 'word_3696'),\n",
       " ('doc_3', 'word_6490'),\n",
       " ('doc_3', 'word_2653'),\n",
       " ('doc_3', 'word_2169'),\n",
       " ('doc_3', 'word_2961'),\n",
       " ('doc_3', 'word_118'),\n",
       " ('doc_3', 'word_1045'),\n",
       " ('doc_4', 'word_5873'),\n",
       " ('doc_4', 'word_3011'),\n",
       " ('doc_4', 'word_5463'),\n",
       " ('doc_4', 'word_6220'),\n",
       " ('doc_4', 'word_455'),\n",
       " ('doc_4', 'word_1382'),\n",
       " ('doc_4', 'word_5972'),\n",
       " ('doc_4', 'word_5971'),\n",
       " ('doc_4', 'word_106'),\n",
       " ('doc_4', 'word_3010'),\n",
       " ('doc_4', 'word_1737'),\n",
       " ('doc_4', 'word_6080'),\n",
       " ('doc_4', 'word_102'),\n",
       " ('doc_4', 'word_104'),\n",
       " ('doc_4', 'word_459'),\n",
       " ('doc_4', 'word_5851'),\n",
       " ('doc_4', 'word_457'),\n",
       " ('doc_4', 'word_2724'),\n",
       " ('doc_4', 'word_1647'),\n",
       " ('doc_4', 'word_103'),\n",
       " ('doc_4', 'word_6494'),\n",
       " ('doc_4', 'word_1378'),\n",
       " ('doc_4', 'word_2122'),\n",
       " ('doc_4', 'word_3830'),\n",
       " ('doc_4', 'word_458'),\n",
       " ('doc_4', 'word_2133'),\n",
       " ('doc_4', 'word_456'),\n",
       " ('doc_4', 'word_1659'),\n",
       " ('doc_4', 'word_1379'),\n",
       " ('doc_4', 'word_2199'),\n",
       " ('doc_4', 'word_3274'),\n",
       " ('doc_4', 'word_6488'),\n",
       " ('doc_4', 'word_3831'),\n",
       " ('doc_4', 'word_2723'),\n",
       " ('doc_4', 'word_2121'),\n",
       " ('doc_4', 'word_55'),\n",
       " ('doc_4', 'word_54'),\n",
       " ('doc_4', 'word_3594'),\n",
       " ('doc_4', 'word_58'),\n",
       " ('doc_4', 'word_560'),\n",
       " ('doc_4', 'word_4978'),\n",
       " ('doc_4', 'word_2198'),\n",
       " ('doc_4', 'word_3340'),\n",
       " ('doc_4', 'word_4256'),\n",
       " ('doc_4', 'word_5854'),\n",
       " ('doc_4', 'word_460'),\n",
       " ...]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tm_model.get_links_info()[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab', 'abc']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tm_model.vocab[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_docs_df = user_docs_df.reset_index(level=0).rename(columns={\"index\":\"id\", 'contents_prep_sum': 'text_sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=data[1:,1:],    # values\n",
    "...              index=data[1:,0],    # 1st column as index\n",
    "...              columns=data[0,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>529</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>530</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  topic_idx\n",
       "0      0          6\n",
       "1      1         15\n",
       "2      2         10\n",
       "3      3          9\n",
       "4      4         43\n",
       "..   ...        ...\n",
       "529  529         20\n",
       "530  530         62\n",
       "531  531          0\n",
       "532  532          1\n",
       "533  533          0\n",
       "\n",
       "[534 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(my_tm_model.get_documents_topics(user_docs_df['id'].values)[0], index=user_docs_df['id'].values).reset_index(level=0).rename(columns={\"index\":\"id\", 0: 'topic_idx'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_num_user_input = 20\n",
    "my_tm_model.reduce_topic(topic_num_user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'topic_idx': 0,\n",
       "  'topic_words': array(['matplotlib', 'ggplot', 'dataframe', 'lineplot', 'dataset',\n",
       "         'scatterplot', 'datasets', 'matlab', 'tensorflow', 'xticklabels',\n",
       "         'numpy', 'graphql', 'multiprocessing', 'data', 'algorithms',\n",
       "         'parametric', 'graphs', 'sklearn', 'mxmatrix', 'vertexcount',\n",
       "         'algorithmic', 'computationally', 'computational', 'boxplot',\n",
       "         'computation', '파라미터', 'subprocess', 'algorithm', 'graph',\n",
       "         'clustering', 'bmatrix', 'correlations', 'correlation', 'mxpath',\n",
       "         'statistics', 'genome', '데이터', 'calculations', 'gaussian',\n",
       "         'computed', 'quantitative', 'github', '알고리즘', 'calculation',\n",
       "         'dzdata', 'statistical', 'nonparametric', 'subplots', 'mzdata',\n",
       "         'statistically'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.39625734e-02, -1.99618135e-02, -2.29578372e-02,  3.86219472e-06,\n",
       "         -3.83860432e-02, -5.12448289e-02,  2.00778265e-02,  1.71963442e-02,\n",
       "          4.60006706e-02,  1.31648118e-02,  2.48969197e-02,  6.78287493e-03,\n",
       "          4.89275455e-02,  3.69818415e-03, -3.63608263e-02,  9.17210151e-03,\n",
       "          2.39833747e-03,  7.97213614e-03,  4.09760661e-02,  4.16760705e-02,\n",
       "          8.93758889e-03, -1.24433369e-03, -4.17724950e-03,  3.55742574e-02,\n",
       "         -5.13739325e-02, -3.85462232e-02,  3.75801362e-02, -1.60337072e-02,\n",
       "          2.26833075e-02, -5.29383384e-02, -4.58574779e-02,  1.21806832e-02,\n",
       "         -4.24140366e-03, -5.48699498e-02, -2.62069632e-03, -4.86961612e-03,\n",
       "          5.64761320e-03, -1.27565851e-02,  2.15130835e-03, -2.40852567e-03,\n",
       "         -1.91491786e-02,  1.20770070e-03, -1.00242682e-02, -2.79695541e-02,\n",
       "         -1.64607372e-02, -3.41060311e-02,  4.08038534e-02, -1.13448622e-02,\n",
       "         -2.83737611e-02, -2.50382902e-04, -3.42324674e-02, -1.61517542e-02,\n",
       "         -1.21480310e-02, -1.85998697e-02,  3.08136567e-02, -5.41240759e-02,\n",
       "         -1.16721727e-02,  2.66411602e-02,  7.00429874e-03,  4.70973887e-02,\n",
       "          7.68848648e-03,  5.21252863e-02,  1.25181368e-02, -2.29073670e-02,\n",
       "          1.53292045e-02, -1.86620615e-02,  4.34004748e-03,  2.19640490e-02,\n",
       "          4.61250059e-02,  1.93235334e-02, -3.11605632e-02,  1.07344869e-03,\n",
       "          1.16014211e-02, -2.30850857e-02, -2.22374499e-02, -2.55551785e-02,\n",
       "          2.04101708e-02,  1.97774041e-02, -1.26425577e-02, -5.80069534e-02,\n",
       "         -5.76212443e-02, -6.89808140e-03, -2.25649718e-02, -7.22388225e-03,\n",
       "          2.24900097e-02, -2.76241247e-02, -3.58283781e-02, -2.04174891e-02,\n",
       "          4.27222438e-03, -2.78227944e-02,  1.49484538e-02, -3.39139806e-04,\n",
       "         -2.08995342e-02, -3.59365456e-02,  2.42523253e-02,  4.69610244e-02,\n",
       "          4.18413011e-03,  1.42017594e-02,  3.10345609e-02, -1.41377409e-03,\n",
       "          4.24699672e-02,  1.85017902e-02,  1.94204375e-02, -1.00656198e-02,\n",
       "          3.92348580e-02,  1.64123401e-02, -4.25703265e-02, -3.39011215e-02,\n",
       "          2.92991456e-02,  2.48865690e-02,  8.40799510e-03, -4.10110615e-02,\n",
       "         -1.05655538e-02, -3.77327092e-02,  3.33148427e-02, -3.92217189e-04,\n",
       "         -2.49194447e-02, -1.52998380e-02, -1.86273362e-02,  8.51304922e-03,\n",
       "          4.17751027e-03,  1.50329927e-02,  1.55090438e-02,  4.02858704e-02,\n",
       "          4.15278114e-02, -2.54047159e-02, -2.80481298e-03,  9.04021412e-03,\n",
       "          5.69253555e-03,  1.57688279e-02, -4.36946489e-02,  1.28738284e-02,\n",
       "          5.38222305e-02,  7.25850509e-03,  1.00900503e-02,  4.34086584e-02,\n",
       "         -7.27469614e-03, -1.06696011e-02,  3.75494286e-02,  4.52733077e-02,\n",
       "         -1.14522427e-02, -2.32271831e-02,  9.27642826e-03, -5.81279397e-03,\n",
       "          2.75998246e-02, -2.18080673e-02, -2.94721872e-02,  4.11735810e-02,\n",
       "          3.14337499e-02, -5.57561824e-03,  4.22840826e-02,  3.66748646e-02,\n",
       "         -4.28859843e-03, -3.41161601e-02,  1.35739828e-02, -2.41119657e-02,\n",
       "          4.37008403e-03, -1.36906793e-02,  1.40417675e-02,  1.04592210e-02,\n",
       "          4.44920249e-02, -4.40102024e-03,  4.11590487e-02, -7.62628252e-03,\n",
       "         -5.22893993e-03, -2.27994025e-02, -1.58992801e-02, -1.77383740e-02,\n",
       "         -2.54352367e-03,  4.32933979e-02,  1.64319128e-02, -4.00441177e-02,\n",
       "          1.55223373e-04,  1.84107870e-02,  1.50465695e-02,  4.58349548e-02,\n",
       "         -4.86740135e-02,  1.09357191e-02, -4.49186862e-02,  3.82849500e-02,\n",
       "          2.22417396e-02, -2.47766804e-02, -1.05045112e-02,  3.40367830e-03,\n",
       "         -4.68934886e-02, -3.38199772e-02,  4.29001786e-02,  4.59329188e-02,\n",
       "          1.05948122e-02, -1.83337536e-02,  6.61271252e-03, -3.06032319e-02,\n",
       "          3.99481915e-02,  2.47626454e-02, -1.40073069e-03,  1.07640782e-02,\n",
       "         -4.48708870e-02, -3.72585678e-03,  4.09072079e-02,  2.59370971e-02,\n",
       "         -1.20690623e-02,  1.21375909e-02, -3.55607294e-03, -2.89394204e-02,\n",
       "         -2.21558604e-02, -2.16644183e-02,  1.76649652e-02, -1.87293673e-03,\n",
       "         -2.54243147e-02,  2.34260634e-02, -1.40444636e-02,  9.41493176e-03,\n",
       "         -4.39523496e-02,  9.37072374e-03,  3.69179882e-02, -1.66509990e-02,\n",
       "         -1.77829657e-02, -4.91903871e-02,  2.25804579e-02, -2.28686240e-02,\n",
       "         -4.72916849e-03,  2.91719753e-02,  1.33784208e-03,  2.14153854e-03,\n",
       "         -5.43711185e-02,  1.61242224e-02, -3.84250917e-02, -1.17033767e-02,\n",
       "          3.12363673e-02,  7.66485510e-03, -1.79602541e-02,  5.18947877e-02,\n",
       "         -2.90461816e-03,  1.99851394e-03,  1.24161383e-02,  2.83604283e-02,\n",
       "         -1.80510078e-02,  1.93298105e-02,  1.82549208e-02, -2.90373508e-02,\n",
       "          6.26318716e-03,  2.53337417e-02, -1.31583204e-02,  1.59408636e-02,\n",
       "         -1.26495175e-02, -5.18209673e-02,  5.43587701e-03, -1.80455800e-02,\n",
       "          2.51284260e-02, -2.80331876e-02, -2.62866113e-02, -4.32528667e-02,\n",
       "          1.20031962e-03,  2.58994196e-02,  1.70120865e-03, -1.61876774e-03,\n",
       "         -3.86490603e-03, -9.31322388e-03, -1.79315489e-02, -2.63165310e-03,\n",
       "         -1.79307722e-02,  1.40406331e-02, -2.58520003e-02, -3.11041418e-02,\n",
       "          9.25456639e-03, -4.55555320e-02, -1.90748591e-02, -3.42497113e-03,\n",
       "          1.57311019e-02,  2.17644889e-02, -2.65201926e-02, -3.56550403e-02,\n",
       "         -4.33437675e-02, -5.49785094e-03, -4.35922947e-03,  5.96826337e-03,\n",
       "         -4.00596820e-02,  2.37326976e-02, -4.16108742e-02,  9.73995135e-04,\n",
       "         -3.37703116e-02,  2.00833362e-02,  3.66114229e-02,  1.58240851e-02,\n",
       "         -6.75307913e-03,  3.43236439e-02, -4.44810092e-02, -3.77012119e-02,\n",
       "         -4.84011509e-03,  3.27104293e-02,  3.31605859e-02,  3.59650068e-02,\n",
       "          2.01155338e-02,  4.31076847e-02, -5.23796417e-02,  6.96814386e-03,\n",
       "         -3.21742184e-02,  1.05976770e-02,  2.55268160e-03,  4.47439887e-02,\n",
       "         -1.61942597e-02,  1.85274463e-02, -1.09734880e-02, -4.59004529e-02,\n",
       "         -4.94376086e-02, -3.30876075e-02, -2.03269143e-02, -3.78152425e-03,\n",
       "          1.40181193e-02,  2.63750628e-02, -1.63557995e-02, -9.53814667e-03,\n",
       "         -1.21624582e-02, -9.92745906e-03,  1.90879162e-02,  1.79801974e-02,\n",
       "          1.45436712e-02, -2.40912791e-02,  8.58506560e-03, -1.02133136e-02,\n",
       "          2.80294195e-03, -1.20024579e-02, -9.80681274e-03, -1.26891918e-02,\n",
       "         -1.96965560e-02,  4.02798271e-03, -8.28214642e-03, -3.56457047e-02,\n",
       "         -2.93990970e-02, -4.63195611e-05, -4.15231436e-02, -1.87465679e-02,\n",
       "         -2.43639480e-02, -2.47610044e-02, -1.10455798e-02,  2.73205359e-02,\n",
       "         -2.11173203e-03,  1.49681838e-03, -5.48136979e-02, -1.10017543e-03,\n",
       "         -4.13025878e-02, -1.88116319e-02,  3.41653116e-02, -1.34950308e-02,\n",
       "         -9.40683857e-03,  2.66283005e-02,  4.12216224e-02,  9.20891855e-03,\n",
       "         -1.11479573e-02, -1.36194332e-02,  1.98371261e-02,  1.98996644e-02,\n",
       "          1.45957693e-02, -3.94751914e-02, -7.71672791e-03,  2.77698418e-04,\n",
       "          2.48867702e-02,  3.63660790e-02, -2.10814923e-02, -4.63060737e-02,\n",
       "         -2.17958284e-03, -3.45179923e-02,  3.18380632e-02, -2.78966893e-02,\n",
       "         -2.63452698e-02,  1.27234384e-02,  3.38577852e-02,  3.50552239e-02,\n",
       "         -2.65840720e-02,  1.75209772e-02, -7.05334125e-03,  3.56145427e-02,\n",
       "         -2.84504667e-02,  3.92932855e-02,  1.15523031e-02, -3.61611396e-02,\n",
       "         -1.97703112e-02, -1.68387704e-02, -4.07730453e-02, -3.17418873e-02,\n",
       "          4.16192273e-03, -3.59764285e-02,  1.11957686e-02, -1.56943705e-02,\n",
       "         -3.35349403e-02,  3.95474248e-02,  2.96925753e-02, -5.28132021e-02,\n",
       "          3.80757339e-02, -6.19446160e-03, -9.68136359e-03, -1.73689164e-02,\n",
       "         -3.09583340e-02,  1.22657334e-02, -1.08727738e-02,  9.84621421e-03,\n",
       "          2.02368349e-02,  3.30375653e-04, -2.30451766e-02,  6.32846542e-03,\n",
       "          4.50899191e-02,  1.68640353e-02,  4.45440710e-02, -1.28247812e-02,\n",
       "         -3.56375836e-02, -6.77516125e-03,  1.48148360e-02, -3.75405289e-02,\n",
       "          2.76577994e-02,  1.05580753e-02, -3.61864362e-03,  1.90685187e-02,\n",
       "          3.40443552e-02, -1.59633160e-02,  3.63215804e-02,  4.33602044e-03,\n",
       "          2.76182611e-02,  3.38597931e-02,  1.19780526e-02,  2.78037209e-02,\n",
       "          4.12605144e-02,  5.54649578e-03,  3.29082422e-02,  3.59164588e-02,\n",
       "          2.30679158e-02,  1.65111832e-02,  4.01985459e-02, -1.15499943e-02,\n",
       "          4.85842320e-04, -1.07959136e-02, -1.12530300e-02, -1.22561455e-02,\n",
       "          8.56691226e-03,  7.87077565e-03, -2.04220065e-03,  8.82792752e-03,\n",
       "         -6.45917607e-03,  1.26306890e-02, -5.24518043e-02,  1.19047360e-02,\n",
       "         -3.85051370e-02,  1.20295258e-02,  2.11351668e-03, -5.07902652e-02,\n",
       "         -1.74375437e-02, -3.35702933e-02,  4.38165516e-02,  8.99408385e-03,\n",
       "         -3.11683561e-03,  2.76636425e-02,  1.62441116e-02, -5.37434593e-03,\n",
       "         -3.49558033e-02, -1.01731215e-02, -3.25236246e-02, -2.63736527e-02,\n",
       "          2.91762501e-02,  3.61827053e-02,  1.10922903e-02,  4.45026197e-02,\n",
       "         -6.22011907e-03, -3.36829759e-02, -7.23243458e-03, -3.30727994e-02,\n",
       "          2.54603177e-02, -4.11386304e-02, -2.18441729e-02, -4.02142443e-02,\n",
       "          5.39831407e-02, -2.04401482e-02,  3.87780182e-02,  1.30167194e-02,\n",
       "          4.36847145e-03,  7.86557421e-03, -3.96275856e-02, -1.58792660e-02,\n",
       "          1.66334379e-02, -2.20719278e-02,  1.09782359e-02, -1.24364607e-02,\n",
       "          4.78144549e-02,  4.40574773e-02, -2.10084710e-02,  1.17643615e-02,\n",
       "          1.91929226e-03, -2.08659619e-02, -2.88181636e-03, -5.38253523e-02,\n",
       "          1.21032149e-02, -4.09577088e-03,  1.26242628e-02,  1.06737474e-02,\n",
       "          4.70622908e-04,  2.01451359e-03, -9.22548678e-03, -2.53253039e-02,\n",
       "          4.14750772e-03, -3.39799114e-02,  2.50684842e-02,  2.32024733e-02,\n",
       "          1.87890546e-03, -3.27783935e-02,  4.85364608e-02,  1.04738101e-02,\n",
       "         -3.13559659e-02, -5.53548299e-02, -9.35465191e-03, -6.76801428e-03,\n",
       "          9.83473146e-04, -3.70481573e-02,  4.50024934e-04,  2.19555348e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 1,\n",
       "  'topic_words': array(['probabilistic', 'statistical', 'statistically', 'regression',\n",
       "         'statistics', 'coefficient', 'coefficients', 'predictive', '통계청',\n",
       "         'correlation', 'covariance', 'correlations', 'predictor',\n",
       "         'probability', 'variance', 'statistic', 'models', 'multivariate',\n",
       "         '통계', 'predictors', 'predicts', 'variances', 'datasets',\n",
       "         'normalization', 'predict', 'randomized', 'dataset', 'matplotlib',\n",
       "         'modelling', '모델', 'clustering', 'nonparametric', 'predicting',\n",
       "         'asymptotic', 'computationally', 'paradigms', 'quantitative',\n",
       "         'paradigm', 'model', 'parametric', 'simulations', 'probabilities',\n",
       "         'scatterplot', 'computational', 'graphql', 'dataframe', 'gaussian',\n",
       "         'computation', 'correlates', 'computed'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.60786054e-02,  9.39360878e-04, -3.77967730e-02,  2.22152080e-02,\n",
       "         -3.10585052e-02, -2.51437202e-02,  7.91066792e-03, -2.77873408e-02,\n",
       "          3.95399332e-02,  3.58101800e-02, -6.81668194e-03,  2.36450508e-02,\n",
       "          4.51504886e-02,  1.09528070e-02, -5.03984392e-02, -2.68829763e-02,\n",
       "         -8.22256843e-04, -2.05766577e-02,  3.07177249e-02,  2.63681486e-02,\n",
       "         -2.70294473e-02, -2.75893211e-02, -4.14224043e-02,  4.59385514e-02,\n",
       "         -5.63811101e-02, -4.18646373e-02,  2.88678706e-02,  1.34842191e-02,\n",
       "         -1.23966504e-02, -3.50814313e-02, -4.47856300e-02,  1.61280856e-02,\n",
       "          2.26403605e-02, -5.38276955e-02, -3.56760435e-02,  9.35841352e-03,\n",
       "         -1.85471363e-02,  9.77921952e-03,  2.56523248e-02,  3.30617018e-02,\n",
       "          1.63810141e-03, -2.11920636e-03,  4.20928821e-02, -4.34495062e-02,\n",
       "         -1.20497346e-02, -2.37424616e-02,  5.17413355e-02, -5.40473917e-03,\n",
       "         -3.54756601e-02, -2.32427083e-02, -1.02592334e-02, -2.46959738e-02,\n",
       "          2.20169444e-02, -1.65251195e-02,  4.51355092e-02, -5.26012480e-02,\n",
       "          2.63473969e-02,  2.77093668e-02, -9.68498923e-03,  4.23389450e-02,\n",
       "          6.72315666e-03,  4.51237857e-02,  1.71275977e-02, -4.04208302e-02,\n",
       "          8.96542706e-03, -1.25277359e-02,  1.94191821e-02, -1.75695866e-02,\n",
       "          4.49934648e-03,  6.25977619e-03, -3.89752500e-02,  9.52388719e-03,\n",
       "         -2.52598636e-02, -4.13649268e-02, -4.47275713e-02, -4.04878482e-02,\n",
       "          2.83103716e-02,  2.61708423e-02,  1.04699319e-03, -5.52978963e-02,\n",
       "         -5.61093502e-02, -4.64779846e-02,  6.59095775e-03,  9.11335368e-03,\n",
       "          9.44770593e-03, -1.07758548e-02, -4.71974686e-02, -2.74052750e-02,\n",
       "         -1.29111297e-02, -2.05130596e-02, -4.02460620e-02, -3.54474857e-02,\n",
       "          3.13143595e-03, -5.45903184e-02,  3.80067863e-02,  5.37826791e-02,\n",
       "          1.74171291e-02,  3.29824798e-02,  2.69253552e-02,  2.61819232e-02,\n",
       "          4.40836549e-02, -1.11171668e-02,  3.79547738e-02, -2.64316387e-02,\n",
       "          1.92765128e-02, -3.87500525e-02, -4.53152508e-02, -2.30641738e-02,\n",
       "          2.09376477e-02,  5.16695939e-02,  4.06455025e-02, -4.43622246e-02,\n",
       "         -3.82189602e-02,  2.76516163e-04,  3.48311812e-02,  5.47705451e-03,\n",
       "          1.23869600e-02,  1.54007897e-02, -3.20486538e-02,  2.88877785e-02,\n",
       "         -1.83297843e-02,  2.10734829e-02,  2.30534449e-02,  8.70392472e-03,\n",
       "          3.31269763e-02,  6.67978590e-03, -2.33989339e-02,  3.39836664e-02,\n",
       "         -3.68057266e-02,  3.61696742e-02, -5.47093004e-02,  1.91199854e-02,\n",
       "          5.17359897e-02,  4.18326035e-02,  4.45503090e-03,  5.22079505e-02,\n",
       "         -9.38657951e-03, -5.36012230e-03,  4.69159298e-02,  1.58884879e-02,\n",
       "          5.12112491e-03, -2.82295421e-02,  3.05915996e-02, -3.00091617e-02,\n",
       "          3.77239585e-02, -4.66564158e-03, -4.72449139e-02,  4.44889888e-02,\n",
       "          2.27063969e-02,  3.30093242e-02,  3.77560928e-02, -4.67048911e-03,\n",
       "         -3.15120369e-02, -3.91225293e-02,  2.79778633e-02, -3.54577899e-02,\n",
       "          7.94658344e-03, -6.04769448e-03,  8.11100006e-03, -1.87699753e-03,\n",
       "          3.06631736e-02, -1.94882248e-02, -1.04757762e-02, -3.66994925e-02,\n",
       "         -3.29441801e-02, -1.59698911e-02,  1.26133217e-02, -1.55392010e-02,\n",
       "         -3.07412036e-02,  5.18268608e-02, -2.15435810e-02, -1.48105361e-02,\n",
       "          3.32888588e-02, -9.07840393e-03, -1.82200260e-02,  2.72368379e-02,\n",
       "          1.19757708e-02,  2.66013443e-02, -4.23638001e-02,  3.85394357e-02,\n",
       "          3.39835398e-02, -2.17150003e-02, -1.44276218e-02, -1.38291176e-02,\n",
       "         -4.88716401e-02, -3.85660380e-02,  2.87571959e-02,  4.86893915e-02,\n",
       "         -3.82158868e-02, -3.74441408e-02,  2.30808696e-03,  1.66329183e-02,\n",
       "          3.74039896e-02, -1.34444237e-02,  5.81824174e-03,  1.81316417e-02,\n",
       "         -5.48117124e-02, -1.20078837e-02,  5.47754206e-02,  2.64720004e-02,\n",
       "         -2.37271674e-02,  1.14605995e-02, -4.71052974e-02, -1.07293958e-02,\n",
       "         -1.98475029e-02, -2.07503736e-02, -4.27996963e-02,  2.59665679e-03,\n",
       "         -1.97574683e-02,  4.53491695e-02,  6.18883222e-03,  8.20877682e-03,\n",
       "         -5.54927215e-02,  2.05221260e-03,  4.74967137e-02, -2.45213527e-02,\n",
       "         -2.60427017e-02, -4.30273712e-02, -1.43858418e-02, -4.17293273e-02,\n",
       "          1.03745358e-02,  2.68208478e-02,  3.55791561e-02, -9.57387313e-03,\n",
       "         -4.93576750e-02,  8.81484244e-03, -5.46917319e-02, -1.29871164e-02,\n",
       "         -7.98706990e-03,  1.76183563e-02, -1.92125943e-02,  4.33561355e-02,\n",
       "         -4.38829139e-02, -1.47407816e-03,  7.61118811e-03,  8.48744716e-03,\n",
       "         -1.88060347e-02,  4.67714928e-02,  1.26873199e-02, -8.16502981e-03,\n",
       "          2.19351687e-02,  1.94115043e-02, -1.54464552e-02,  4.28185333e-03,\n",
       "          4.63401005e-02, -4.44864109e-02,  2.65180375e-02, -2.10522600e-02,\n",
       "         -7.97345827e-04,  1.91443053e-03, -2.53857952e-02, -4.31600288e-02,\n",
       "          6.49259612e-03, -1.35990912e-02, -1.43512907e-02, -1.73916798e-02,\n",
       "         -2.16077324e-02,  9.61615704e-03, -1.59303397e-02, -2.33400278e-02,\n",
       "         -1.55260591e-02,  1.88675895e-02, -3.16958167e-02, -3.40652950e-02,\n",
       "          1.18284943e-02, -5.30228168e-02, -1.04147121e-02,  1.17045101e-02,\n",
       "          9.44152009e-03,  4.86388383e-03,  1.06864581e-02, -2.06827763e-02,\n",
       "         -2.15091649e-02, -3.86936627e-02,  6.46005897e-03,  3.15553881e-02,\n",
       "         -4.74623628e-02,  4.65490110e-02, -5.50718158e-02, -1.84889801e-03,\n",
       "         -5.00992723e-02,  7.01750908e-03,  2.69734468e-02,  3.10589317e-02,\n",
       "         -2.37210970e-02,  4.56987657e-02, -3.85270827e-02, -2.05009412e-02,\n",
       "         -1.26836784e-02,  3.38496044e-02,  3.70991006e-02,  2.39177868e-02,\n",
       "          4.52770703e-02, -2.85184407e-03, -4.87144478e-02,  1.11247525e-02,\n",
       "         -2.54501514e-02,  2.04580948e-02,  3.52334939e-02,  5.31911403e-02,\n",
       "         -3.74559201e-02,  3.39835212e-02, -1.61201861e-02, -5.28722182e-02,\n",
       "         -5.57238385e-02, -1.04460260e-02, -3.05463206e-02,  1.46504389e-02,\n",
       "         -2.61183586e-02,  1.72870234e-02, -4.72636260e-02, -5.60852280e-03,\n",
       "         -4.41711061e-02, -3.96923311e-02,  4.00126576e-02,  3.26720737e-02,\n",
       "          3.06874644e-02, -4.54323888e-02,  2.67107077e-02, -3.04269399e-02,\n",
       "         -3.19758110e-05, -1.72159076e-03, -4.13372666e-02, -1.60791799e-02,\n",
       "         -2.49387715e-02, -9.16978903e-03, -1.65425781e-02, -2.72314157e-02,\n",
       "         -1.06656700e-02, -1.72378868e-03, -2.79048439e-02, -4.30527478e-02,\n",
       "          1.53119909e-02, -3.40468287e-02, -4.85494034e-03,  1.20893940e-02,\n",
       "         -4.07867432e-02, -2.86705736e-02, -5.36975972e-02, -2.54050884e-02,\n",
       "         -4.09279540e-02, -9.86127555e-03,  1.57892797e-02, -2.54101530e-02,\n",
       "         -1.41141638e-02,  4.10252512e-02,  5.23213893e-02,  2.73953211e-02,\n",
       "         -2.04173960e-02,  2.37485245e-02,  2.68276092e-02,  8.86028446e-03,\n",
       "         -1.11761154e-03,  4.77335742e-03,  3.61079630e-03,  1.42877670e-02,\n",
       "         -1.01703464e-03,  3.06432713e-02, -4.49962020e-02, -3.52577418e-02,\n",
       "          3.73945385e-02, -4.42878604e-02,  3.74162346e-02, -2.48998217e-02,\n",
       "         -4.45914492e-02,  1.48357069e-02,  7.61280209e-03,  4.07653525e-02,\n",
       "         -3.28170359e-02,  3.99014242e-02,  2.59949639e-02,  5.00308536e-02,\n",
       "         -3.31967212e-02,  3.81519049e-02, -1.26871178e-02, -4.96952869e-02,\n",
       "          1.19047589e-03,  7.13021122e-03, -4.65795621e-02, -4.78355847e-02,\n",
       "          2.20274311e-02, -4.12363298e-02,  2.01529209e-02,  5.78554161e-03,\n",
       "         -2.77862046e-02,  5.27041331e-02,  1.29301380e-02, -4.60018739e-02,\n",
       "          4.82795611e-02, -1.31983953e-02,  2.08169352e-02, -1.62838884e-02,\n",
       "         -1.97671782e-02,  4.98972833e-02, -3.47775370e-02, -7.68750068e-03,\n",
       "          1.80813540e-02,  7.42647937e-03, -5.22364527e-02,  1.83778964e-02,\n",
       "          3.54613215e-02,  4.77354415e-02,  4.81436700e-02,  5.69397118e-03,\n",
       "         -4.27763611e-02,  1.40364179e-02,  1.38262846e-02, -3.00755855e-02,\n",
       "          5.19006699e-03, -1.07756313e-02, -3.94696649e-03, -2.27518231e-02,\n",
       "          2.81650038e-03, -9.56681278e-03,  2.49463376e-02,  4.11906578e-02,\n",
       "          9.54966992e-03,  1.02943722e-02,  3.38774920e-02, -1.97075470e-03,\n",
       "          3.19810910e-03, -4.84714285e-02, -8.04830168e-04,  5.22529595e-02,\n",
       "          4.77780811e-02,  2.27099583e-02, -9.70555656e-03, -5.04471771e-02,\n",
       "         -6.00978686e-03,  1.08470372e-03, -3.64549719e-02,  8.69472511e-03,\n",
       "         -2.87657417e-02, -2.03819275e-02,  4.33367379e-02,  4.42650206e-02,\n",
       "          3.20543796e-02,  2.20659412e-02, -5.40863872e-02,  2.07047388e-02,\n",
       "         -2.44969204e-02, -7.39059411e-03, -1.49316275e-02, -5.49073257e-02,\n",
       "          2.63393652e-02, -4.05754559e-02,  2.81055253e-02,  2.20671427e-02,\n",
       "          1.16268767e-03,  2.07873378e-02, -1.75392646e-02, -3.40195373e-02,\n",
       "          1.71532333e-02, -3.49387862e-02, -4.51289788e-02, -3.27874720e-02,\n",
       "          4.58432920e-03,  3.75429280e-02,  1.87132158e-04,  4.97158021e-02,\n",
       "         -1.11648929e-03, -3.71188968e-02,  3.72970034e-03, -5.06987199e-02,\n",
       "          4.66555655e-02, -4.86404933e-02,  6.04585418e-03, -4.74041849e-02,\n",
       "          5.44224568e-02, -2.08684020e-02,  3.45342457e-02,  4.17857990e-02,\n",
       "         -1.96017548e-02,  1.63935367e-02, -4.12531309e-02, -5.40651986e-03,\n",
       "          4.10457142e-02, -1.26398094e-02, -1.34247774e-02, -1.70104261e-02,\n",
       "          3.41335796e-02,  5.64881824e-02, -3.86925228e-02,  1.26036434e-02,\n",
       "          3.91353779e-02,  7.80204544e-03, -8.90501682e-03, -5.35733365e-02,\n",
       "         -3.37932557e-02,  2.91163521e-03,  3.12791467e-02,  3.36658992e-02,\n",
       "          3.93168256e-03,  2.38146493e-03, -2.58691292e-02, -3.32951769e-02,\n",
       "          1.37403756e-02, -2.50301138e-02,  2.48740613e-02, -5.01741748e-03,\n",
       "          2.72340160e-02, -4.94546928e-02,  5.56386448e-02, -1.10262344e-02,\n",
       "         -3.90072130e-02, -5.30936979e-02,  1.27969319e-02, -3.26061845e-02,\n",
       "         -1.41723072e-02, -4.44835573e-02, -2.64558215e-02,  2.32227575e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 2,\n",
       "  'topic_words': array(['urllib', 'github', 'javascript', 'browser', 'chrome', '브라우저',\n",
       "         'khtml', 'url', 'firefox', 'cython', 'html', 'mozilla',\n",
       "         'createpage', 'dataframe', 'dependencies', 'dependency', '구글',\n",
       "         'sklearn', 'linewidth', 'python', 'bootstrap', 'regex', '변수',\n",
       "         'cookies', 'webdriver', 'multiprocessing', 'matplotlib',\n",
       "         'localhost', 'selenium', 'plugins', '홈페이지', 'sites', 'google',\n",
       "         '크롬', 'utf', '파라미터', 'crawler', 'encode', 'websites', 'webgl',\n",
       "         'tensorflow', 'xpath', 'pages', 'encoded', 'bandwidth', 'gencode',\n",
       "         'proteins', 'dataset', 'variables', 'css'], dtype='<U15'),\n",
       "  'topic_vector': array([-4.30822819e-02,  1.52914608e-02, -1.51512604e-02,  9.03585739e-03,\n",
       "          1.51584996e-03, -5.61208278e-02,  2.15586443e-02, -9.11154225e-03,\n",
       "          5.09487838e-02,  2.68593170e-02,  2.14712918e-02,  2.46213358e-02,\n",
       "          3.67283709e-02,  1.32817822e-02,  6.20892970e-03,  1.37801003e-02,\n",
       "          8.59084539e-03, -2.09636893e-03,  2.41574850e-02,  4.30831723e-02,\n",
       "          2.49496028e-02,  3.21129970e-02,  6.19739667e-03,  3.78660634e-02,\n",
       "         -5.66158108e-02, -2.32324041e-02,  6.83080929e-04, -9.42613836e-03,\n",
       "         -5.76812103e-02, -4.92180698e-02, -2.85017118e-02,  1.25662815e-02,\n",
       "          1.61236356e-04, -5.16144745e-02, -1.52934538e-02, -3.68341547e-03,\n",
       "          3.83754224e-02,  5.30924555e-03,  2.27398202e-02, -8.80943425e-03,\n",
       "         -2.19362341e-02, -1.06640514e-02, -1.48378247e-02, -2.11422779e-02,\n",
       "         -3.28836823e-03, -4.02661972e-03,  4.74784290e-03,  3.17280483e-03,\n",
       "         -1.07588675e-02, -5.77924261e-03, -2.22215857e-02,  4.08069603e-03,\n",
       "         -1.79312453e-02, -7.92894512e-03,  6.94147777e-03, -5.50588481e-02,\n",
       "          2.81085968e-02,  2.90648602e-02,  1.86277367e-03, -1.95858702e-02,\n",
       "          8.56845547e-03,  4.80759107e-02,  3.03876605e-02, -3.99540812e-02,\n",
       "         -1.61673594e-02,  2.48445757e-02,  1.05701424e-02, -2.78657880e-02,\n",
       "          2.23903097e-02, -1.65592898e-02, -3.13099474e-02, -2.88100634e-03,\n",
       "          6.38275314e-03, -3.05139888e-02, -5.54693490e-03, -8.88069859e-04,\n",
       "          1.67428423e-02,  3.06451991e-02,  2.80024633e-02, -5.96488304e-02,\n",
       "         -6.58935159e-02, -4.56179269e-02, -3.40238698e-02, -2.37268824e-02,\n",
       "          6.87382510e-03,  1.35501176e-02, -1.78817399e-02, -1.85729004e-02,\n",
       "         -4.14338754e-03,  4.95414995e-03, -4.74148989e-03, -3.90364137e-03,\n",
       "          2.34288778e-02, -7.18156400e-04,  2.80100033e-02,  2.50850711e-03,\n",
       "         -3.54180820e-02, -9.03678965e-03,  4.20978479e-03, -2.01381836e-02,\n",
       "          3.69176343e-02,  3.38694043e-02, -1.66290486e-03,  1.81430876e-02,\n",
       "          2.70802602e-02, -1.04867630e-02, -4.57747579e-02, -4.58996976e-03,\n",
       "          6.86983811e-03,  3.27727348e-02,  2.03379616e-02, -3.04594841e-02,\n",
       "          2.58168168e-02, -3.41069624e-02,  3.40987295e-02, -2.97591351e-02,\n",
       "         -6.18078141e-03, -1.75300483e-02, -2.15146597e-03,  8.12604371e-03,\n",
       "         -6.10259175e-03, -9.95497219e-03, -9.11726430e-03,  7.20518921e-03,\n",
       "          2.76191458e-02,  1.57650393e-02, -2.10340731e-02, -1.43098487e-02,\n",
       "          1.96605339e-03, -3.81206302e-03, -3.82335857e-02,  9.02377069e-03,\n",
       "          6.14754483e-02, -9.65733640e-03, -2.64557078e-02,  3.83766890e-02,\n",
       "          1.17737596e-04, -1.22579373e-02,  3.59323286e-02,  2.05953419e-02,\n",
       "          9.55088250e-03,  2.13084016e-02, -3.04720700e-02,  2.71375570e-02,\n",
       "          1.12754293e-02, -5.43075614e-04, -1.59821436e-02,  1.95372384e-02,\n",
       "          1.35288909e-02,  1.38069699e-02,  1.19839208e-02,  2.24775672e-02,\n",
       "         -3.38765699e-03, -3.66724841e-02,  9.47969127e-03, -1.09312376e-02,\n",
       "         -1.56250075e-02,  1.24621792e-02,  3.93930171e-03, -3.30054224e-03,\n",
       "          4.45051342e-02, -2.49605216e-02,  4.38953489e-02,  3.38022294e-03,\n",
       "          3.48986387e-02, -2.46267039e-02,  2.08113752e-02,  1.13650244e-02,\n",
       "         -7.75767025e-03,  3.86941654e-04,  2.12571025e-02, -1.45414043e-02,\n",
       "         -1.07400082e-02,  5.39937709e-03, -1.14188604e-02,  2.64681187e-02,\n",
       "         -5.00212945e-02,  3.07826232e-03, -4.38617766e-02,  4.58368845e-02,\n",
       "          2.28930078e-03,  1.58448759e-02,  1.09668508e-04,  7.39553664e-03,\n",
       "         -2.37351470e-02,  1.01529919e-02,  2.70561464e-02,  4.38345708e-02,\n",
       "          3.36757698e-03,  1.28921149e-02,  1.26081603e-02, -3.11355814e-02,\n",
       "          3.95284332e-02,  8.03510993e-05, -2.55877897e-02,  1.78323232e-03,\n",
       "          5.30380085e-02, -2.26702988e-02,  2.12997291e-02,  1.00164851e-02,\n",
       "          2.15774179e-02, -7.39548262e-03,  3.48863169e-03, -2.71879379e-02,\n",
       "         -6.40854426e-03, -3.41677591e-02,  3.83826457e-02, -1.55469282e-02,\n",
       "          1.35814631e-03,  2.04722323e-02, -2.20533833e-02,  1.23571828e-02,\n",
       "          1.15597919e-02,  1.02831507e-02,  3.15291397e-02, -6.27973909e-03,\n",
       "         -1.97541919e-02, -2.50231512e-02, -8.55742581e-03,  1.40030701e-02,\n",
       "         -1.42030735e-02, -1.71917491e-04,  3.07831988e-02, -7.83068128e-03,\n",
       "         -5.53468652e-02, -1.35930888e-02, -2.43605915e-02, -7.65398378e-04,\n",
       "          1.83219165e-02, -9.84170847e-03, -3.38756777e-02,  4.17849906e-02,\n",
       "          2.65103113e-02, -9.95603856e-04,  3.07527417e-03,  2.90025938e-02,\n",
       "          1.93639714e-02, -4.35777847e-03,  4.05173935e-02, -3.04727033e-02,\n",
       "         -2.16332544e-02,  1.83419930e-03,  5.90334646e-03,  1.61982160e-02,\n",
       "         -1.16716989e-03, -5.37901744e-02,  2.01444328e-02,  4.07104194e-03,\n",
       "         -2.71605439e-02,  2.07724795e-02, -1.78628005e-02, -2.63627414e-02,\n",
       "         -2.66178492e-02, -3.42276171e-02,  3.88239995e-02, -3.25537659e-02,\n",
       "         -3.39950342e-03,  5.20407148e-02, -1.02344016e-02,  1.50717776e-02,\n",
       "         -1.21143963e-02,  3.10170092e-02, -2.70778779e-02, -4.59089428e-02,\n",
       "         -1.54750980e-03, -2.29070913e-02, -3.61242741e-02,  6.43556751e-03,\n",
       "         -8.69127735e-03,  3.36369388e-02, -1.16795413e-02, -1.81841999e-02,\n",
       "         -2.74654813e-02,  3.60146314e-02,  3.67040671e-02, -5.82558010e-03,\n",
       "          8.94221291e-03,  7.93965720e-03, -3.33198644e-02, -1.59207210e-02,\n",
       "         -5.60123008e-03,  1.98974032e-02,  1.96663570e-02, -2.38816962e-02,\n",
       "         -4.50690743e-03, -2.86564659e-02, -3.73496599e-02, -1.21053429e-02,\n",
       "         -1.64685324e-02,  7.45300390e-03,  2.81384867e-03,  2.55971309e-02,\n",
       "         -1.56310722e-02,  5.26368953e-02, -6.07314259e-02,  7.00777955e-03,\n",
       "         -5.37626669e-02,  5.21966144e-02, -6.84170797e-03,  4.24184687e-02,\n",
       "          9.68372822e-03,  9.22432169e-03, -1.26771908e-02, -8.85521621e-03,\n",
       "         -6.28398499e-03,  8.23585689e-03,  1.80786308e-02, -3.65907582e-03,\n",
       "         -8.30834208e-04,  2.20678914e-02,  4.77192402e-02, -1.58964917e-02,\n",
       "         -1.21609438e-02, -1.79634267e-03, -1.17615713e-02,  3.12313605e-02,\n",
       "          1.18645877e-02,  6.10236079e-03,  1.67411659e-02,  6.69881329e-03,\n",
       "          2.59352792e-02, -7.58766383e-03, -1.47089232e-02, -4.70802374e-03,\n",
       "         -9.99163557e-03, -2.40288470e-02,  1.37481675e-03, -3.07127163e-02,\n",
       "          2.56780814e-02, -2.68014111e-02, -2.39804890e-02, -2.54553147e-02,\n",
       "         -1.13929957e-02, -1.52299935e-02,  3.33229788e-02,  1.41182281e-02,\n",
       "          2.03005616e-02,  9.47511848e-03, -5.71191125e-02, -3.00019775e-02,\n",
       "          8.98629613e-03,  2.26180982e-02, -1.86546799e-02, -2.38789506e-02,\n",
       "         -1.89829934e-02,  2.43618228e-02,  1.39293857e-02,  1.34149175e-02,\n",
       "         -7.79923471e-03, -2.89644324e-03, -3.66366655e-02,  7.63595337e-03,\n",
       "          4.10102366e-04, -2.57947855e-03, -2.45722160e-02, -1.33175384e-02,\n",
       "         -3.00257467e-02,  1.49576766e-02,  2.01466493e-03, -3.07162032e-02,\n",
       "         -6.04774384e-03, -2.88818683e-02,  2.00518053e-02, -2.73267012e-02,\n",
       "          1.52848857e-02, -1.64612364e-02,  8.90647247e-03,  8.90435651e-03,\n",
       "         -3.86596806e-02, -1.48277897e-02, -1.00694429e-02,  4.47213231e-03,\n",
       "         -8.23105220e-03,  5.02426410e-04,  1.24186873e-02, -3.95452939e-02,\n",
       "         -1.44781508e-02, -1.19225867e-02, -8.14537518e-03, -1.39123118e-02,\n",
       "         -2.70051882e-02, -1.95117109e-02, -7.63826910e-03,  2.34471634e-02,\n",
       "          4.45576897e-03,  3.36474515e-02,  2.77768429e-02, -5.17003909e-02,\n",
       "          1.07247680e-02,  2.03683618e-02,  2.55885646e-02, -2.81194840e-02,\n",
       "         -1.96352657e-02,  7.67350709e-03,  1.70547254e-02, -3.87305990e-02,\n",
       "          2.19036713e-02,  1.49185956e-02,  1.13572469e-02,  7.69702438e-03,\n",
       "          1.86446998e-02,  1.00775091e-02,  5.64566404e-02, -1.11174025e-02,\n",
       "          8.56594369e-03, -9.75298975e-03, -5.39649604e-03, -1.22693414e-03,\n",
       "          2.12697368e-02, -2.17088945e-02, -1.55834425e-02,  2.90073990e-03,\n",
       "          2.57356185e-02,  1.06152461e-03,  8.27319396e-04,  2.20572739e-03,\n",
       "          3.45109254e-02, -3.67452428e-02, -6.95806835e-03, -3.11744586e-02,\n",
       "          1.98743120e-02,  1.11288093e-02,  4.36124066e-03,  2.01266333e-02,\n",
       "         -9.43524530e-04,  2.59943157e-02,  1.76565554e-02,  1.99085101e-04,\n",
       "          6.06188178e-03, -4.83836010e-02,  8.74477997e-03,  1.68926716e-02,\n",
       "          1.77843496e-02,  1.98952388e-02,  1.74078438e-02,  4.40171063e-02,\n",
       "         -2.03186143e-02, -2.00405233e-02, -3.91598195e-02,  4.58111055e-03,\n",
       "         -1.92534700e-02,  9.50336922e-03,  3.49846110e-03, -5.05958162e-02,\n",
       "         -1.00794714e-02, -1.83981247e-02,  5.49895912e-02, -2.87517700e-02,\n",
       "          4.60634893e-03,  2.52482630e-02,  2.47791912e-02,  2.82179154e-02,\n",
       "         -5.93930334e-02, -1.03059700e-02, -1.65570173e-02, -1.44746620e-02,\n",
       "          2.45867744e-02, -3.91213074e-02, -6.87709125e-03,  3.90565321e-02,\n",
       "         -3.30943801e-03,  1.93095789e-03, -1.31995268e-02, -3.08840238e-02,\n",
       "         -4.05903347e-03, -3.21482718e-02, -3.22377565e-03,  6.25563553e-04,\n",
       "          5.74355461e-02,  2.61240848e-03,  4.47081961e-02, -8.73220991e-03,\n",
       "          3.36300731e-02,  2.30096001e-03, -2.31751222e-02, -3.09931170e-02,\n",
       "          2.20763311e-02,  2.21641567e-02, -1.47901606e-02,  1.84446611e-02,\n",
       "          3.79937924e-02,  3.27900685e-02, -1.74420550e-02,  1.01580359e-02,\n",
       "         -4.27068258e-03,  1.74060483e-02, -1.81300361e-02, -6.01245686e-02,\n",
       "          2.75323391e-02,  2.88335024e-03, -2.84375809e-03,  1.95294376e-02,\n",
       "          2.42514145e-02, -7.03585474e-03,  9.23390873e-03, -1.48864901e-02,\n",
       "         -3.34810605e-03, -3.78672704e-02,  3.22300419e-02,  1.54455733e-02,\n",
       "         -6.57827593e-03, -6.97183516e-03,  3.55533548e-02,  2.19522286e-02,\n",
       "         -3.03783547e-02, -4.99766618e-02, -2.98102871e-02,  1.02439045e-03,\n",
       "         -2.95618698e-02,  3.72836087e-03,  3.10324728e-02,  2.22233012e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 3,\n",
       "  'topic_words': array(['psychological', 'psychology', 'neurosciences', 'neuroscience',\n",
       "         'neurofeminism', 'psychosis', 'psychiatric', 'psychiatry',\n",
       "         'neurofeminist', 'neurosci', 'feminist', 'neuroscientific',\n",
       "         'neuroscientist', '학문', 'scientists', '심리', 'scientist',\n",
       "         'neuroscientists', 'psychotherapy', 'psychol', 'neurons',\n",
       "         'brainstem', 'neuronal', 'neuron', 'scientific', 'neurology',\n",
       "         'alzheimers', 'neuro', 'mental', 'alzheimer', 'neurological',\n",
       "         'neurol', 'neuroethics', 'academic', 'intellectual', 'brains',\n",
       "         'scholar', 'depressive', 'researchers', 'forebrain', 'brain',\n",
       "         'scholars', 'neurocultures', 'neurobiology', 'cerebrospinal',\n",
       "         'neurobiological', 'neural', 'schizophrenia', 'cognitive',\n",
       "         'depression'], dtype='<U15'),\n",
       "  'topic_vector': array([-2.24075392e-02,  3.00532337e-02,  7.50658382e-03, -3.70252319e-02,\n",
       "          3.91837861e-03,  4.53720503e-02, -1.16905374e-02,  9.35369916e-03,\n",
       "          3.47155035e-02,  2.87474021e-02, -9.23701003e-03,  2.42770696e-03,\n",
       "          2.27966588e-02, -1.12922387e-02, -3.04431207e-02,  2.09924430e-02,\n",
       "         -9.08955187e-03, -5.10536991e-02,  7.85569660e-03,  4.87916134e-02,\n",
       "         -1.70194712e-02, -4.34684232e-02,  1.84696484e-02,  1.80758815e-02,\n",
       "         -5.60992546e-02, -6.64214022e-04,  1.46483025e-02, -8.67344346e-03,\n",
       "          8.76576919e-03, -4.48643193e-02,  1.27973296e-02,  3.53755197e-03,\n",
       "         -3.34589998e-03, -3.82679328e-02,  2.21391711e-02, -2.75008269e-02,\n",
       "          2.59576496e-02, -8.21214914e-03, -3.09474953e-02, -2.38113627e-02,\n",
       "         -5.97361894e-03,  1.42182475e-02,  4.96860147e-02,  6.76243007e-03,\n",
       "         -3.06363404e-02, -7.32201152e-03,  1.31785572e-02, -4.19064146e-03,\n",
       "         -3.68599594e-03, -1.12540834e-02,  2.89547611e-02, -1.43742245e-02,\n",
       "          1.30478498e-02, -1.04454448e-02, -2.45855073e-04, -5.35979904e-02,\n",
       "          2.71855798e-02,  5.11018001e-03,  7.84183852e-03,  3.30630019e-02,\n",
       "         -1.97307188e-02,  5.59692420e-02,  4.02684091e-03, -4.52043153e-02,\n",
       "         -2.75522727e-03,  5.55593567e-03,  2.87545733e-02, -2.86798850e-02,\n",
       "         -1.79685894e-02, -1.66397600e-03,  9.98714939e-03,  1.68456063e-02,\n",
       "          2.42516883e-02, -4.07951288e-02,  5.36128134e-03, -2.18212865e-02,\n",
       "          2.18579173e-02,  3.67354229e-02, -2.20768005e-02, -6.00804090e-02,\n",
       "         -6.09546788e-02, -3.10701299e-02, -2.10360698e-02,  4.17447351e-02,\n",
       "         -2.14875992e-02, -5.24710398e-03, -2.23491024e-02, -3.95891443e-03,\n",
       "          2.36041873e-04,  2.52868775e-02, -4.67681885e-02, -1.68304034e-02,\n",
       "         -3.40491049e-02, -2.42313650e-02, -6.59105834e-04,  1.35120349e-02,\n",
       "          5.49820364e-02,  4.49695550e-02, -2.41403584e-03,  1.58302169e-02,\n",
       "         -2.00503506e-03, -3.23835318e-03, -6.39196578e-03,  6.44816784e-03,\n",
       "          1.95898544e-02,  5.57004428e-03, -4.76826392e-02, -4.38228622e-03,\n",
       "         -2.11109985e-02,  2.54748240e-02,  5.10194944e-03, -3.04296222e-02,\n",
       "         -1.61837935e-02,  1.09849414e-02,  2.88056489e-02, -3.46368700e-02,\n",
       "          1.49545930e-02,  9.20011755e-03, -1.58283710e-02,  1.59907639e-02,\n",
       "         -4.15187422e-03,  4.15416285e-02,  3.25022861e-02,  1.33432988e-02,\n",
       "         -6.47364929e-03,  3.93513851e-02,  1.24339219e-02,  3.23807565e-03,\n",
       "         -2.80607138e-02,  2.02957597e-02, -3.70803438e-02, -8.53984850e-04,\n",
       "          2.42377445e-02,  2.36113127e-02,  1.57543290e-02,  5.85989542e-02,\n",
       "         -3.59676080e-03, -3.08343731e-02,  5.44959344e-02,  1.06024398e-02,\n",
       "          2.57867016e-02,  2.64451876e-02,  1.49919940e-02,  1.60645079e-02,\n",
       "          2.71934774e-02, -9.90507752e-03,  4.27237339e-02,  4.86006960e-03,\n",
       "          1.66333783e-02,  9.24810302e-05,  5.00365607e-02,  9.90566332e-03,\n",
       "          6.33368222e-03, -7.30322953e-03, -2.88987365e-02, -5.03544509e-03,\n",
       "         -3.06632183e-03, -2.11486071e-02, -2.93734148e-02, -2.86685470e-02,\n",
       "          3.62390578e-02, -4.12857011e-02, -9.99997370e-03,  3.79109464e-04,\n",
       "         -2.89915930e-02, -3.79095562e-02,  2.07159221e-02, -8.56984686e-03,\n",
       "         -8.83894041e-03,  4.16355440e-03, -2.66324207e-02,  3.90956784e-03,\n",
       "         -1.78893562e-04, -7.37824198e-03, -1.92125160e-02,  2.58431435e-02,\n",
       "         -2.43032966e-02,  1.81556232e-02, -4.26883288e-02,  2.39567030e-02,\n",
       "          3.50091681e-02,  1.93310529e-02,  9.94378608e-03, -2.05765348e-02,\n",
       "         -1.54329427e-02,  1.05422400e-02,  2.43832972e-02,  5.75767532e-02,\n",
       "          2.26721503e-02,  1.73349995e-02,  1.41297262e-02, -3.18413414e-02,\n",
       "          2.56039072e-02, -7.23003363e-03, -1.12252589e-02,  2.47368440e-02,\n",
       "         -9.80720762e-03,  3.94196389e-03,  2.97789313e-02,  1.53223891e-02,\n",
       "         -3.03359926e-02,  2.10759472e-02, -1.47396140e-03, -3.20730731e-02,\n",
       "          1.47745935e-02, -3.89926694e-02,  2.34611740e-04,  2.35481113e-02,\n",
       "          1.92765184e-02,  3.83363776e-02, -3.65400407e-03, -3.50744203e-02,\n",
       "          4.08110442e-03, -6.63562678e-03, -1.26703666e-03, -3.80995404e-03,\n",
       "         -2.30572023e-03, -3.19009684e-02,  6.03310298e-03,  1.97999589e-02,\n",
       "         -3.78934182e-02,  3.76529954e-02,  4.06925343e-02,  1.91291645e-02,\n",
       "         -1.11221317e-02, -4.26359512e-02, -3.53500731e-02, -5.56592876e-03,\n",
       "         -3.41686867e-02, -3.67653966e-02,  2.10577659e-02, -2.42586173e-02,\n",
       "         -1.98488608e-02,  4.27855700e-02,  3.17021050e-02, -1.81038138e-02,\n",
       "         -6.02967688e-04, -5.20391040e-04,  5.53401224e-02, -2.37581264e-02,\n",
       "         -3.52780037e-02, -7.46120512e-03,  1.56973302e-02,  3.19145583e-02,\n",
       "          3.73033918e-02,  1.34540247e-02,  3.94035727e-02,  3.84500297e-03,\n",
       "          2.10336968e-02, -1.87466331e-02, -1.29223168e-02, -2.56374534e-02,\n",
       "          1.66497994e-02, -3.44138630e-02,  2.19614822e-02, -2.17972156e-02,\n",
       "         -1.25940908e-02,  2.35346034e-02, -2.33369190e-02,  2.84966547e-02,\n",
       "         -9.79657006e-03,  3.44787166e-02, -1.71666238e-02,  1.53618492e-02,\n",
       "          3.88866477e-02, -4.10966352e-02, -2.66513843e-02,  3.37067060e-02,\n",
       "         -1.12888692e-02,  1.28352419e-02,  1.81117319e-02,  2.81306542e-03,\n",
       "          1.37217389e-02, -4.04052846e-02,  3.31729725e-02,  1.36765093e-02,\n",
       "         -2.10877880e-02,  2.20269095e-02, -5.26838079e-02, -3.44270468e-02,\n",
       "         -2.57066973e-02,  6.98965159e-04,  1.21339727e-02,  1.63972173e-02,\n",
       "         -3.21286619e-02,  2.01731194e-02, -4.26703878e-02, -1.16312429e-02,\n",
       "         -1.94356721e-02, -1.56549476e-02,  1.36188688e-02,  1.73038691e-02,\n",
       "          8.92244373e-03,  2.39883866e-02,  3.53517942e-02,  2.62136944e-02,\n",
       "          3.33639048e-03,  2.71889009e-02,  2.50151679e-02,  3.92221436e-02,\n",
       "          3.70641891e-03,  2.19885893e-02, -3.14250737e-02, -3.95569094e-02,\n",
       "          8.96373577e-03, -1.70053691e-02, -2.13725287e-02,  4.16802466e-02,\n",
       "          2.93701477e-02,  2.48246547e-03, -8.81631335e-04, -1.46807637e-02,\n",
       "          1.65249559e-03,  3.93772032e-03,  4.33432981e-02,  4.01991680e-02,\n",
       "         -1.12042781e-02, -8.95752385e-03,  4.71339859e-02, -2.70363335e-02,\n",
       "         -2.59895530e-02, -3.62390541e-02, -7.36817857e-03,  2.15993337e-02,\n",
       "         -1.54484427e-02, -1.88861080e-02, -5.47624845e-03, -1.19180512e-02,\n",
       "          3.55341658e-02,  2.50309221e-02, -1.49951801e-02, -1.14278554e-03,\n",
       "         -3.88583504e-02, -3.08834668e-02, -9.37832240e-03,  6.12485921e-03,\n",
       "         -1.76142380e-02, -1.55965211e-02, -4.60306630e-02, -7.26691214e-03,\n",
       "         -3.91013883e-02, -1.76793449e-02, -1.24267600e-02, -3.38661484e-02,\n",
       "         -8.33054306e-04,  2.46628989e-02,  4.38973866e-02, -1.71357039e-02,\n",
       "         -1.15988981e-02, -8.03756993e-04,  1.02205509e-02, -1.08645530e-02,\n",
       "          1.19957337e-02,  4.07862663e-02, -1.98883824e-02,  2.96575725e-02,\n",
       "         -1.34880785e-02,  3.48534733e-02, -2.20840052e-02, -2.16308199e-02,\n",
       "         -6.24997634e-03,  1.06692230e-02,  4.90928665e-02,  2.97713168e-02,\n",
       "         -6.04947750e-03,  1.60305761e-02, -3.19979601e-02,  1.22209992e-02,\n",
       "         -2.73317154e-02,  1.11884894e-02,  3.86580452e-03,  3.07645425e-02,\n",
       "          1.23877767e-02,  8.91789515e-03,  1.87938400e-02,  2.68511754e-02,\n",
       "         -1.33613618e-02,  5.42744342e-03,  1.51185039e-02, -1.22978427e-02,\n",
       "          9.44552477e-03, -2.45920271e-02,  2.61391196e-02,  9.78259649e-03,\n",
       "         -1.35269118e-02,  6.00360483e-02,  2.21425183e-02, -5.57252057e-02,\n",
       "          5.66977784e-02,  2.98832320e-02,  4.08463692e-03, -1.96651053e-02,\n",
       "          2.56134961e-02,  5.09961918e-02,  5.22636808e-03,  2.34310739e-02,\n",
       "          2.07325388e-02, -4.01365943e-03,  1.39810806e-02,  1.06468014e-02,\n",
       "          2.69692726e-02,  4.24614213e-02,  2.40671784e-02,  8.22228100e-03,\n",
       "         -9.24532302e-03,  6.53177360e-03,  1.97158623e-02, -1.62637997e-02,\n",
       "          2.01221649e-02,  2.22472660e-02,  3.98220904e-02,  6.37074409e-04,\n",
       "          9.64099821e-03,  1.43566290e-02,  4.82107978e-03,  5.42201847e-02,\n",
       "          1.76398959e-02, -6.53905002e-03,  1.15767983e-03, -1.09870639e-02,\n",
       "         -3.76643264e-03, -1.12871928e-02,  5.92701696e-03,  2.76366342e-02,\n",
       "          5.09266108e-02, -1.39063764e-02, -1.36379590e-02, -6.54050941e-03,\n",
       "         -4.00405377e-02, -5.62050566e-03, -9.72099695e-03,  6.84839394e-03,\n",
       "         -1.60190463e-02, -3.37920338e-02,  5.72557747e-03, -3.05645391e-02,\n",
       "          6.76992116e-03, -1.75499171e-02, -4.99092601e-02,  3.23098190e-02,\n",
       "         -4.27720416e-03,  5.00253867e-03,  2.98921205e-03, -4.88612242e-02,\n",
       "          1.62520949e-02,  4.22420315e-02,  3.75944786e-02,  7.29948143e-03,\n",
       "          3.44254337e-02,  1.73500590e-02, -1.48684122e-02,  2.56201513e-02,\n",
       "          1.27940448e-02,  8.93559866e-03, -1.72325354e-02, -8.43327027e-03,\n",
       "          7.82093313e-03,  8.03015009e-03,  3.31186913e-02, -2.99477056e-02,\n",
       "         -7.50190206e-03, -3.03083789e-02, -2.42215227e-02, -4.00930047e-02,\n",
       "         -3.82383429e-02, -5.66852242e-02, -5.18252030e-02,  2.06196140e-02,\n",
       "         -1.20968800e-02,  1.79219693e-02,  2.39442103e-03,  3.98379751e-02,\n",
       "         -3.76995280e-02,  1.75779238e-02, -8.47890414e-03, -7.62441289e-03,\n",
       "          1.79550536e-02, -1.83555961e-03, -2.24516448e-02,  3.11031588e-04,\n",
       "          3.00191268e-02,  5.97785376e-02, -3.57238948e-02,  1.38452128e-02,\n",
       "         -8.44714697e-03, -5.53246541e-03, -3.15441303e-02, -5.74272051e-02,\n",
       "         -4.24447889e-03, -2.77608447e-02,  9.97339841e-03,  8.26373603e-03,\n",
       "          2.64828298e-02, -5.10676252e-03,  3.30903335e-03, -5.12161106e-03,\n",
       "         -3.04846670e-02,  9.43818688e-03,  2.10829191e-02,  1.22436928e-02,\n",
       "          1.75680015e-02, -3.75715010e-02,  4.08973768e-02, -2.12856289e-02,\n",
       "         -4.50140275e-02, -1.56889781e-02,  6.33394066e-03,  1.69645355e-03,\n",
       "         -3.30991633e-02, -4.56224531e-02,  6.66612014e-03,  2.86031999e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 4,\n",
       "  'topic_words': array(['서울', '서울시', '서울대', 'seoul', '한국', '평양', 'korean', '한국어', 'korea',\n",
       "         '지하철', '한글', 'population', 'regularization', '전공', 'uniformity',\n",
       "         '대중', '공공', '수많', '인구', '정리', '학회', 'normalized', 'soup',\n",
       "         'populations', 'public', 'station', '서민', 'renaming',\n",
       "         'normalization', 'cities', '대중교통', 'normality', 'procedures',\n",
       "         'commonly', 'basic', '마태오', '직원', '일반', 'simplest', 'fundamental',\n",
       "         '퍼센트', 'prevalence', 'general', '면역', '복지', 'normalize', '음식점',\n",
       "         '식당', '동시', '병원'], dtype='<U15'),\n",
       "  'topic_vector': array([ 1.50344288e-02,  2.44039507e-03,  3.02110449e-03,  9.77915805e-03,\n",
       "          2.99511552e-02,  4.73872349e-02, -8.27141572e-03,  2.25814562e-02,\n",
       "          2.35317126e-02,  3.83156128e-02, -1.38306459e-02,  1.82049396e-03,\n",
       "          1.48571534e-02, -1.33750970e-02, -1.10606924e-02,  1.31723490e-02,\n",
       "          9.12251975e-03, -1.86518412e-02,  1.67275108e-02,  4.49481122e-02,\n",
       "          4.44382057e-03, -3.06319967e-02,  1.88022293e-02, -6.93220040e-03,\n",
       "         -5.68983965e-02, -2.01307926e-02, -6.37093210e-04,  4.55130078e-03,\n",
       "          3.33413072e-02, -4.59626354e-02, -3.77703905e-02, -1.38200577e-02,\n",
       "          7.98676163e-03, -3.36273722e-02,  1.63535830e-02, -1.14535280e-02,\n",
       "          7.40141200e-04, -5.14116026e-02, -2.63831066e-03, -2.83755828e-02,\n",
       "         -8.32397025e-03, -1.47797763e-02, -5.05755248e-04, -3.99853885e-02,\n",
       "          1.64779220e-02, -3.99490595e-02, -3.64955552e-02, -2.31047887e-02,\n",
       "         -4.20353152e-02,  1.29165314e-02, -9.08516813e-03, -2.55793016e-02,\n",
       "          1.24575980e-02, -1.74385142e-02,  2.86023337e-02, -5.86077794e-02,\n",
       "          3.18138376e-02, -2.76539288e-02, -1.18793622e-02,  2.57260888e-03,\n",
       "          1.13265906e-02,  5.53517491e-02,  1.40246237e-02, -3.48159522e-02,\n",
       "          1.73068009e-02, -1.72879326e-03,  1.94973778e-02, -2.44465303e-02,\n",
       "         -2.26097554e-02, -9.17975232e-03,  6.75556064e-03,  4.73932847e-02,\n",
       "          1.68386120e-02, -3.11349588e-03, -7.13640638e-03,  9.76176746e-03,\n",
       "          5.88868698e-03,  1.82851392e-04,  3.37080145e-03, -6.24574684e-02,\n",
       "         -6.52409494e-02, -1.88817065e-02,  2.87193879e-02,  1.52965281e-02,\n",
       "         -9.27536003e-03, -3.02762426e-02, -5.17898351e-02, -9.21285246e-03,\n",
       "          2.34451834e-02, -1.01071084e-02, -2.39241146e-03,  1.67830859e-03,\n",
       "         -2.09063143e-02, -2.96807569e-03,  8.37110856e-04,  8.58145393e-03,\n",
       "         -3.48190544e-03,  4.79790829e-02, -1.83334630e-02,  1.41923372e-02,\n",
       "         -1.05554331e-02,  8.37781187e-03, -9.52023081e-03,  1.14373537e-02,\n",
       "         -2.29763128e-02, -1.01509793e-02, -1.89542433e-03, -2.59157233e-02,\n",
       "         -6.13729795e-03, -1.21953711e-02,  2.06671692e-02,  9.04400926e-03,\n",
       "          4.97388169e-02,  2.47199535e-02,  1.97740961e-02, -9.98031162e-03,\n",
       "          1.53700793e-02, -1.50543055e-03,  5.66108804e-03, -4.65514883e-02,\n",
       "         -2.84850746e-02, -2.94119231e-02,  2.11598389e-02, -1.95730608e-02,\n",
       "          7.98533019e-03, -1.86225064e-02,  1.07914712e-02,  3.66364680e-02,\n",
       "         -2.80622393e-02,  2.92626899e-02, -3.67948934e-02, -6.41641719e-03,\n",
       "         -3.42092768e-04,  1.68603286e-02, -1.82514042e-02,  6.00035116e-02,\n",
       "         -5.56904776e-03, -4.98797977e-03,  4.79934514e-02, -1.50699308e-02,\n",
       "          4.23075594e-02, -1.02442177e-02, -7.87737407e-03,  2.30119359e-02,\n",
       "          1.30438535e-02, -1.43340770e-02,  4.90260534e-02, -1.68557428e-02,\n",
       "          1.27093438e-02,  1.34829059e-02,  1.37927290e-02,  3.47799733e-02,\n",
       "         -3.48765403e-02, -1.00257704e-02,  2.38811392e-02, -2.38934532e-02,\n",
       "         -2.34973393e-02,  1.33577082e-03,  5.90374693e-03, -3.82270887e-02,\n",
       "          4.61327098e-03, -5.07742502e-02,  2.26558428e-02,  3.21243666e-02,\n",
       "         -1.49392907e-03, -2.05594450e-02,  2.23282296e-02, -3.65242618e-03,\n",
       "         -2.63481680e-02, -1.50914872e-02,  1.08421845e-02,  1.75174419e-02,\n",
       "         -2.67599672e-02,  2.07860451e-02,  3.01190168e-02,  3.73321027e-02,\n",
       "         -1.68065529e-03, -1.00327004e-02, -1.16471248e-02,  4.90778051e-02,\n",
       "          8.08027107e-03, -7.34697608e-03,  1.28312018e-02,  6.19846582e-03,\n",
       "         -2.88940184e-02,  2.33597704e-03,  1.97758395e-02,  5.21356016e-02,\n",
       "         -1.12690963e-02,  2.41164397e-02, -3.47592030e-03,  2.70802085e-03,\n",
       "          4.48235730e-03, -2.60959622e-02, -1.40460255e-02,  8.94383900e-03,\n",
       "          7.19231227e-03, -4.08837525e-03,  1.54209370e-02,  1.00063672e-02,\n",
       "         -5.15448675e-02, -5.59452455e-03,  8.29548761e-03, -3.36637199e-02,\n",
       "         -2.77520008e-02,  1.69680710e-03,  4.21338566e-02, -4.13234020e-03,\n",
       "          2.40962463e-03,  4.22748625e-02, -9.05667525e-03,  1.26898205e-02,\n",
       "         -3.36663984e-02, -1.02890953e-02, -1.57162417e-02,  1.93524314e-03,\n",
       "          2.12670173e-02, -3.67922569e-03, -3.88725176e-02,  3.46222892e-02,\n",
       "         -2.23203022e-02,  1.16649959e-02,  9.78189148e-03,  9.51269642e-03,\n",
       "          1.13560958e-02, -1.93803757e-02, -2.40738429e-02,  7.56562920e-04,\n",
       "          9.85443708e-04, -1.16795930e-03,  9.74404626e-03, -4.58094366e-02,\n",
       "          1.47260837e-02, -5.16139611e-04,  2.54318602e-02,  1.01838252e-02,\n",
       "         -2.19934359e-02,  1.27012692e-02,  2.97571626e-03,  6.51758281e-04,\n",
       "          8.34959559e-03, -2.04475131e-02,  4.32008244e-02, -9.33114998e-03,\n",
       "          3.02601811e-02,  1.62613820e-02,  4.30125259e-02,  2.33375579e-02,\n",
       "          1.60388332e-02, -2.83175819e-02, -3.84394987e-03, -1.47077022e-02,\n",
       "         -2.14840062e-02,  3.11336555e-02,  1.27072409e-02, -1.19739724e-03,\n",
       "         -4.40455787e-03,  2.14724895e-02, -2.23856792e-02,  5.79989478e-02,\n",
       "          3.05627808e-02,  3.84417437e-02, -2.67174989e-02, -1.83381215e-02,\n",
       "         -2.74192728e-03, -4.86486480e-02, -1.99362319e-02,  4.39194590e-02,\n",
       "          1.67734195e-02,  2.26696543e-02, -1.80830937e-02, -2.09694281e-02,\n",
       "          1.80572420e-02, -2.61775479e-02,  4.02344111e-03,  1.29810013e-02,\n",
       "          2.23506913e-02, -3.03215496e-02, -5.04088774e-02, -2.88497079e-02,\n",
       "          2.98606884e-02, -1.83751956e-02,  2.04430986e-02, -1.63408387e-02,\n",
       "          1.50680412e-02, -1.02248425e-02, -4.54665385e-02,  1.49756204e-02,\n",
       "         -2.73053609e-02, -3.03768776e-02, -2.78723761e-02,  4.59454861e-03,\n",
       "          6.13660784e-04,  1.04796991e-03,  1.49833942e-02,  3.19151804e-02,\n",
       "          8.17495678e-03,  1.14905545e-02, -1.92608945e-02, -9.37859528e-03,\n",
       "          5.84817445e-03,  8.85895174e-03, -8.65573063e-03, -1.00989835e-02,\n",
       "          3.62634771e-02, -3.63092422e-02,  3.20516899e-02,  2.02553887e-02,\n",
       "          2.89229974e-02, -5.48722805e-04,  1.18292077e-02, -1.64807402e-02,\n",
       "         -3.35546285e-02,  1.50731085e-02,  2.10602749e-02,  3.32128294e-02,\n",
       "         -4.35831547e-02, -9.92032140e-03,  3.42364199e-02,  1.79327913e-02,\n",
       "         -1.42835984e-02, -1.76277962e-02, -2.18060184e-02,  1.68301277e-02,\n",
       "          1.31021403e-02, -1.96445640e-02,  1.47700189e-02,  1.57763027e-02,\n",
       "          1.86193176e-02,  8.70695524e-03, -2.35811640e-02, -2.73272749e-02,\n",
       "         -2.67441813e-02,  1.28576588e-02, -1.43874418e-02, -4.18083593e-02,\n",
       "         -2.08763685e-02,  3.49064283e-02, -3.88853811e-02, -2.42887959e-02,\n",
       "         -3.33715528e-02, -1.15721552e-02, -2.02168543e-02,  8.41731147e-04,\n",
       "         -2.24600062e-02,  2.51859706e-02, -9.55273025e-03,  1.64360572e-02,\n",
       "          2.09446438e-02,  1.14752091e-02,  1.11392941e-02, -1.95662174e-02,\n",
       "          1.68616138e-02,  3.67419934e-03,  1.43438606e-02,  2.30206139e-02,\n",
       "         -2.87112389e-02,  4.37406544e-03, -1.24559132e-02, -2.94786114e-02,\n",
       "          1.99083518e-02,  9.93986335e-03,  4.85130325e-02, -2.03553624e-02,\n",
       "          1.03385178e-02, -1.91183053e-02, -3.67780887e-02, -2.83892564e-02,\n",
       "          3.68712991e-02,  7.85683747e-04,  2.91273510e-03,  3.39869671e-02,\n",
       "          8.80067609e-03, -5.12866769e-03,  2.07622536e-02,  5.34972455e-03,\n",
       "         -1.28453330e-03, -1.45133436e-02,  3.92559990e-02,  1.17873903e-02,\n",
       "          1.76586621e-02,  2.23005824e-02,  8.93874746e-03,  4.46117744e-02,\n",
       "          5.16779022e-03,  3.15776132e-02, -1.81846749e-02, -5.40280864e-02,\n",
       "          4.48030792e-02,  2.71203108e-02, -6.55279029e-03,  1.86257605e-02,\n",
       "          5.52748656e-03,  2.25596018e-02,  3.07600331e-02, -2.31749881e-02,\n",
       "         -1.64365936e-02,  1.74131878e-02, -3.19830189e-03,  2.33860351e-02,\n",
       "          1.24292066e-02,  2.67770737e-02,  4.00689170e-02,  1.50488252e-02,\n",
       "         -8.76689702e-03, -6.30169921e-03, -2.64171958e-02,  1.57010998e-03,\n",
       "         -7.45704630e-03, -4.82161879e-04,  2.76417527e-02, -2.60619726e-03,\n",
       "          1.60369519e-02,  6.61174417e-04, -1.01187369e-02,  3.01451255e-02,\n",
       "          5.70619525e-03,  2.79445462e-02,  2.22675371e-05, -3.24449316e-02,\n",
       "          1.55546973e-02,  4.07205559e-02, -3.73680592e-02,  3.53248455e-02,\n",
       "          1.51807042e-02, -3.93469771e-03,  2.86672506e-02, -1.49998330e-02,\n",
       "         -2.99284123e-02, -2.86027323e-02, -8.01988132e-03,  2.69663287e-03,\n",
       "          3.11539918e-02,  2.06684235e-05,  4.59114574e-02, -2.62927543e-02,\n",
       "          2.84249950e-02,  3.27692106e-02, -5.92527762e-02,  3.72957699e-02,\n",
       "          6.72912784e-03,  4.61203642e-02, -1.34968897e-02, -4.27765436e-02,\n",
       "          1.70101970e-02,  1.48324696e-02,  5.13376147e-02,  3.93344508e-03,\n",
       "          1.30017996e-02,  4.33557816e-02,  1.17144901e-02,  3.85153219e-02,\n",
       "          2.28895936e-02,  7.31260609e-03, -4.03462201e-02,  1.72565319e-02,\n",
       "          1.03065046e-02, -1.27376895e-02,  9.40168183e-03,  1.16882715e-02,\n",
       "          1.80047434e-02, -4.53356700e-03, -6.75174221e-03, -1.37150765e-03,\n",
       "          9.77332052e-03, -5.18571772e-02, -2.95382012e-02, -3.17449844e-03,\n",
       "          1.73954293e-02,  1.13487570e-02,  1.98466573e-02, -5.28003415e-03,\n",
       "         -6.37103710e-03,  2.64020730e-03, -3.01804412e-02, -2.29590107e-02,\n",
       "          2.99196877e-02, -1.65913533e-02, -1.84886400e-02, -9.15304478e-03,\n",
       "          1.46539705e-02,  5.17304167e-02, -1.07761566e-02,  1.43507426e-03,\n",
       "          2.18530670e-02,  2.56402157e-02,  2.95415055e-02, -5.93398958e-02,\n",
       "         -3.11650969e-02, -1.21851079e-02,  2.03466378e-02,  3.08377687e-02,\n",
       "          3.50582041e-02, -1.35097532e-02, -4.21691872e-03, -2.62513235e-02,\n",
       "         -2.51265578e-02,  2.18679593e-03,  2.78871823e-02,  1.89045798e-02,\n",
       "          1.82705205e-02,  1.25090014e-02,  4.68259379e-02,  2.91325115e-02,\n",
       "         -5.53831309e-02, -3.96706946e-02,  1.77038498e-02, -1.57264341e-02,\n",
       "         -2.83232890e-03, -4.02554646e-02, -8.08980782e-03, -2.14516744e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 5,\n",
       "  'topic_words': array(['statistical', 'dataframe', 'statistically', 'statistics',\n",
       "         'dataset', 'covariance', 'variance', 'statistic', 'datasets',\n",
       "         'correlation', 'matplotlib', '통계청', 'coefficient', 'variances',\n",
       "         'correlations', 'coefficients', 'multivariate', 'regression', '통계',\n",
       "         'scatterplot', 'probabilistic', 'ggplot', 'variables', 'numpy',\n",
       "         'variability', 'stats', 'data', '변수', 'quantitative',\n",
       "         'calculations', 'computationally', '잠재변수', 'computation',\n",
       "         'probability', 'computed', 'multiprocessing', 'bivariate',\n",
       "         'correlated', 'calculation', 'computational', 'correlates',\n",
       "         'correlate', 'tensorflow', 'estimator', 'nonparametric', 'sklearn',\n",
       "         'lineplot', '모델', '비율', 'matlab'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.06127923, -0.0189661 , -0.00519899,  0.00690749, -0.03819732,\n",
       "         -0.03881706,  0.00709101, -0.02387483,  0.0485031 ,  0.02742366,\n",
       "          0.02321878,  0.02774713,  0.05151859, -0.00670428, -0.05826847,\n",
       "         -0.00500281,  0.01294745, -0.01449448,  0.03043582,  0.03372572,\n",
       "         -0.00996355, -0.03773057, -0.03023364,  0.03922783, -0.04951314,\n",
       "         -0.04975424,  0.01394093,  0.00264184,  0.01637732, -0.04686427,\n",
       "         -0.05005504,  0.01613354,  0.02011276, -0.05685425,  0.01065443,\n",
       "          0.0097609 , -0.02920826,  0.01154   , -0.0165141 ,  0.02730265,\n",
       "          0.0013236 ,  0.00225364,  0.0137885 , -0.0504377 , -0.01582977,\n",
       "         -0.04540794,  0.04335766,  0.00543758, -0.02913178, -0.01922578,\n",
       "         -0.00410619, -0.01907369,  0.00427598, -0.01217561,  0.02658633,\n",
       "         -0.05085085,  0.00615472,  0.03370508,  0.00048424,  0.04062351,\n",
       "          0.0197772 ,  0.04508729,  0.02389906, -0.04122325,  0.00958526,\n",
       "         -0.0075462 ,  0.01207826, -0.00855015,  0.02484358,  0.01856892,\n",
       "         -0.04217552, -0.00553306, -0.02396486, -0.0377005 , -0.04273948,\n",
       "         -0.04563205,  0.01954232,  0.03405167, -0.01213885, -0.06261573,\n",
       "         -0.06248823, -0.03537709, -0.03559274, -0.00153763,  0.00866325,\n",
       "         -0.02747445, -0.04344879, -0.02231644, -0.00587195, -0.02363573,\n",
       "         -0.00805076, -0.01614043,  0.02972021, -0.04511116,  0.02210561,\n",
       "          0.05209731, -0.00544886,  0.02161   ,  0.00920447,  0.0267756 ,\n",
       "          0.04114612, -0.00496267,  0.04170703, -0.01101709,  0.02079387,\n",
       "         -0.03511471, -0.04276885, -0.00849373,  0.01046733,  0.04947884,\n",
       "          0.03241458, -0.03427641, -0.02157621, -0.00992556,  0.01822122,\n",
       "          0.01103153,  0.00405512, -0.02088806, -0.00536566, -0.01229966,\n",
       "         -0.010086  ,  0.02521771,  0.00381083,  0.03232637,  0.04409567,\n",
       "          0.0083096 , -0.0277176 ,  0.03626252, -0.04478945,  0.03274042,\n",
       "         -0.05297226,  0.0241798 ,  0.05571223,  0.01652554, -0.01417259,\n",
       "          0.02761257,  0.00548725, -0.02667959,  0.04434536,  0.04122184,\n",
       "         -0.0183284 , -0.02785938,  0.02757205, -0.01875974,  0.01841661,\n",
       "          0.0081789 , -0.03617518,  0.0394305 ,  0.0080813 ,  0.01157457,\n",
       "          0.0451606 ,  0.0102148 ,  0.00674065, -0.03489126,  0.03311411,\n",
       "         -0.01097204, -0.00497842, -0.016046  ,  0.01229492, -0.00844987,\n",
       "          0.02719698,  0.00423946,  0.00542114, -0.03125835, -0.04833804,\n",
       "         -0.019013  , -0.02243459,  0.01364864, -0.02432472,  0.04654086,\n",
       "         -0.03348601,  0.00135283,  0.02235603, -0.00628465,  0.00830653,\n",
       "          0.04193496, -0.01999515,  0.02871164, -0.04536323,  0.03466713,\n",
       "          0.03152665, -0.00738763,  0.01722785, -0.01247058, -0.05157437,\n",
       "         -0.02689171,  0.04210902,  0.05010096, -0.01198211, -0.04645803,\n",
       "         -0.00733527, -0.0055943 ,  0.04388369, -0.01601219, -0.0049893 ,\n",
       "          0.01694409, -0.05483168, -0.02051828,  0.04390329,  0.02094461,\n",
       "         -0.01489032,  0.00140931, -0.03715833, -0.0080748 , -0.02162494,\n",
       "         -0.02502288, -0.03436426,  0.00463426, -0.02841022,  0.0421177 ,\n",
       "         -0.0182875 ,  0.02405928, -0.05391428,  0.00695069,  0.03871625,\n",
       "         -0.01851877, -0.0099589 , -0.05722111,  0.02113014, -0.01588532,\n",
       "          0.01069141,  0.00683191,  0.01801376, -0.03205417, -0.05511481,\n",
       "          0.00799112, -0.04102905, -0.02715804,  0.0117602 , -0.00201411,\n",
       "         -0.01054377,  0.04659658, -0.01816683, -0.02163836,  0.03400414,\n",
       "          0.01518369, -0.00955621,  0.03737943,  0.02215529, -0.01217556,\n",
       "         -0.01242691,  0.03119935,  0.00061747,  0.02284508,  0.00153069,\n",
       "         -0.05915627, -0.02915802,  0.00693401,  0.00544699,  0.00571824,\n",
       "         -0.02588016, -0.03759227, -0.01723614, -0.02804493, -0.02043466,\n",
       "         -0.01825954, -0.00893819, -0.01443401, -0.00770141, -0.02119919,\n",
       "          0.0041476 ,  0.01155111, -0.02090914, -0.01997591,  0.0190161 ,\n",
       "         -0.04531259, -0.02256062, -0.01800515, -0.00752254, -0.00717577,\n",
       "         -0.02867656, -0.04500729, -0.01900394, -0.03160629, -0.01222098,\n",
       "          0.00239303, -0.04687524,  0.03445039, -0.038965  ,  0.00153613,\n",
       "         -0.05015739,  0.02198064,  0.02308404,  0.00844413, -0.02571456,\n",
       "          0.03481491, -0.02721966, -0.0417569 , -0.02797634,  0.04223584,\n",
       "          0.03666603,  0.05530834,  0.04398232,  0.00764562, -0.05454184,\n",
       "          0.02957792, -0.02808823,  0.01926314,  0.03831662,  0.04285774,\n",
       "         -0.04228604,  0.04208626, -0.02141665, -0.05156278, -0.05810183,\n",
       "         -0.00769201, -0.01657256,  0.00858827, -0.01452033,  0.03520305,\n",
       "         -0.0112557 , -0.00720382, -0.042768  , -0.00729022,  0.00851792,\n",
       "          0.04226805,  0.03380019, -0.02266833,  0.01565211, -0.00761055,\n",
       "          0.0135165 , -0.01641373, -0.03704185,  0.01010962, -0.03122235,\n",
       "         -0.00606721, -0.02890941, -0.02489953,  0.00041499,  0.00150571,\n",
       "         -0.01928547, -0.03704612, -0.01615738, -0.04870367, -0.03054812,\n",
       "          0.0274218 , -0.00131343, -0.02845331, -0.0611189 , -0.02914069,\n",
       "         -0.03594907, -0.01860473,  0.04883894, -0.01517013, -0.02263139,\n",
       "          0.03658948,  0.04966757,  0.0259671 , -0.03027626, -0.01376534,\n",
       "          0.02531692,  0.01383462,  0.02340117, -0.00564353, -0.00017638,\n",
       "          0.0151263 ,  0.01191457,  0.04444032, -0.04132738, -0.04206584,\n",
       "          0.01136782, -0.03000816,  0.02821643, -0.01292239, -0.04492183,\n",
       "          0.01368191,  0.01545784,  0.03307011, -0.00176582,  0.05415877,\n",
       "          0.02802485,  0.04128285, -0.01905922,  0.02907131, -0.0176564 ,\n",
       "         -0.04897056,  0.02025474, -0.02862723, -0.04534885, -0.0450518 ,\n",
       "          0.01950377, -0.04918172,  0.00013113, -0.01167749, -0.03896779,\n",
       "          0.05254517,  0.00916274, -0.0461341 ,  0.03472416, -0.01773853,\n",
       "          0.0305814 , -0.03224526, -0.04905877,  0.04953863, -0.04415253,\n",
       "          0.01874015,  0.03783072,  0.00482235, -0.03941714,  0.01374325,\n",
       "          0.0234256 ,  0.05405728,  0.0396435 , -0.022701  , -0.03509463,\n",
       "          0.02079264, -0.01077929, -0.03121668,  0.03331719, -0.02265129,\n",
       "         -0.00659236,  0.00738953,  0.02004329, -0.01693859,  0.03176941,\n",
       "          0.01890874,  0.03117133,  0.01659868,  0.03672149,  0.00245932,\n",
       "          0.00164688, -0.04562026,  0.00981642,  0.04612006,  0.04172214,\n",
       "          0.02357122, -0.00883401, -0.02629311,  0.00184961, -0.01280278,\n",
       "         -0.03415524,  0.00175817, -0.00069935, -0.01009758,  0.00796721,\n",
       "          0.02768284,  0.04335891, -0.00188132, -0.05336614,  0.03232605,\n",
       "         -0.01258241,  0.00904477, -0.00778594, -0.05363443,  0.01349792,\n",
       "         -0.00925076,  0.04691249,  0.00103168,  0.00883722,  0.01418127,\n",
       "         -0.00423673, -0.01285866, -0.02282703, -0.01535312, -0.04634478,\n",
       "         -0.02626525,  0.02269515,  0.02757752,  0.03215649,  0.03015037,\n",
       "         -0.00758256, -0.01624327, -0.00479732, -0.0426241 ,  0.04681041,\n",
       "         -0.02976581,  0.01206937, -0.05048718,  0.05918538, -0.0036089 ,\n",
       "          0.02703091,  0.02428607,  0.00863424,  0.01254207, -0.04756196,\n",
       "         -0.02557311,  0.02612921, -0.01104808, -0.02686948, -0.02066705,\n",
       "          0.04972783,  0.03167871, -0.04002541, -0.0053496 ,  0.01839178,\n",
       "          0.00728702, -0.02140552, -0.0551888 , -0.01928116, -0.0235366 ,\n",
       "          0.02471686, -0.01072037, -0.0033717 , -0.01782789, -0.00149064,\n",
       "         -0.02714636,  0.00381139, -0.04272444,  0.03305225,  0.01237067,\n",
       "          0.00555768, -0.04466873,  0.04739966, -0.00364625, -0.01623096,\n",
       "         -0.05700923, -0.00445337, -0.02259741, -0.00729239, -0.04049734,\n",
       "         -0.01228938,  0.03956572], dtype=float32)},\n",
       " {'topic_idx': 6,\n",
       "  'topic_words': array(['sklearn', '강좌', 'teach', 'textbooks', 'pdf', '학습', 'resource',\n",
       "         'learner', 'learning', 'taught', 'courses', 'classes', 'learns',\n",
       "         'teaching', 'tutorial', 'access', 'accessible', 'techniques',\n",
       "         'sources', '강의', 'basic', 'learn', 'resources', 'skills',\n",
       "         'scholar', 'student', 'documentation', 'article', 'source',\n",
       "         'faculty', 'students', 'undergraduate', 'studying', '저작권법',\n",
       "         'document', 'abilities', '커널', 'class', 'neural', '학문', '전공',\n",
       "         'forebrain', '배울', '연습', 'fundamental', 'literature', 'bootstrap',\n",
       "         '클래스', 'copyright', 'fluent'], dtype='<U15'),\n",
       "  'topic_vector': array([-3.43496539e-02,  2.26944108e-02, -2.67785252e-03,  3.09734549e-02,\n",
       "         -5.17277000e-03, -3.38230319e-02,  2.47332733e-02,  9.72975232e-03,\n",
       "          3.40110175e-02,  4.25975025e-03,  1.01891551e-02, -1.28315222e-02,\n",
       "          1.20291272e-02, -2.11633388e-02, -4.60984111e-02,  2.00173855e-02,\n",
       "          5.52105252e-03, -4.23535518e-02,  2.06914078e-02,  3.19162272e-02,\n",
       "          5.43030305e-03,  2.41349693e-02,  1.38741313e-02,  1.48703158e-02,\n",
       "         -2.15340257e-02, -1.21634845e-02, -1.99729633e-02, -1.77582763e-02,\n",
       "         -1.18255410e-02, -3.54005620e-02, -2.57278737e-02, -6.84425118e-04,\n",
       "          1.84851736e-02, -4.06245068e-02, -1.50839752e-02, -2.32298602e-03,\n",
       "          2.60363761e-02, -6.55243499e-03,  6.17690897e-03, -2.57509612e-02,\n",
       "         -1.53890334e-03,  1.75949205e-02, -1.37346620e-02,  3.91078601e-03,\n",
       "         -3.35593782e-02,  2.20594723e-02, -1.75925698e-02,  1.09277596e-03,\n",
       "         -2.02080905e-02,  7.52241875e-04, -3.81745398e-03, -3.15834326e-03,\n",
       "         -2.49924441e-03,  2.88868207e-03,  2.42932644e-02, -3.93121131e-02,\n",
       "          3.21874991e-02, -5.86129259e-03, -2.86200829e-02,  1.88045464e-02,\n",
       "         -1.68721634e-03,  4.21569385e-02,  1.59173682e-02, -1.92265790e-02,\n",
       "          7.28494069e-03,  1.34339342e-02,  3.11585087e-02, -1.41948806e-02,\n",
       "          1.83003338e-03,  2.08596475e-02, -1.54959047e-02,  8.13649874e-03,\n",
       "          1.24938590e-02, -2.21618713e-04,  2.14165431e-02,  1.93667002e-02,\n",
       "         -2.79317051e-03,  3.41662229e-03,  2.00142208e-02, -5.73093556e-02,\n",
       "         -7.17094764e-02,  6.60036830e-03, -3.85000333e-02,  7.85809476e-03,\n",
       "          2.55358368e-02, -2.79256105e-02, -2.10429151e-02,  4.43968410e-03,\n",
       "          3.36783603e-02,  5.04555553e-03, -1.11070992e-02,  3.87232215e-03,\n",
       "         -5.43735502e-03, -3.32985967e-02,  2.57385485e-02,  2.78991871e-02,\n",
       "         -2.87674237e-02,  8.22546892e-03, -2.08650231e-02,  6.80397218e-03,\n",
       "          2.94492114e-02,  3.00986413e-02,  1.11249825e-02, -2.45450623e-02,\n",
       "          1.85488220e-02, -4.18520579e-03, -4.48366329e-02, -9.01395746e-04,\n",
       "          2.31557917e-02,  1.22976284e-02,  1.23911095e-03, -4.22506668e-02,\n",
       "          1.79898459e-02,  7.74478400e-03,  8.63221288e-03, -1.95686221e-02,\n",
       "         -3.10669579e-02,  1.20283021e-02,  1.43980654e-02, -7.41476147e-03,\n",
       "          2.50879838e-03,  1.49137452e-02,  1.31601794e-02,  2.22462807e-02,\n",
       "         -5.33219101e-03, -2.12066285e-02, -1.55456513e-02,  2.45823269e-03,\n",
       "          1.00414604e-02, -1.85946878e-02, -2.33200081e-02, -2.25107260e-02,\n",
       "          2.62488090e-02,  2.77060755e-02,  2.22200621e-02,  6.76229522e-02,\n",
       "         -2.33778241e-03, -1.02278888e-02,  3.73691693e-02,  3.39600112e-04,\n",
       "          1.24439914e-02,  1.23720327e-02,  3.10879364e-03,  2.41642687e-02,\n",
       "          1.39353229e-02,  2.18017064e-02,  1.08631309e-02,  1.20586818e-02,\n",
       "         -5.82662178e-03,  2.95450520e-02,  3.62831317e-02,  1.03122760e-02,\n",
       "         -1.49245765e-02, -8.10975861e-03,  5.56832971e-03, -5.73770935e-03,\n",
       "         -2.31448412e-02, -2.10452266e-02, -1.36312796e-02, -6.00430602e-03,\n",
       "          4.21966873e-02, -3.26282490e-04,  1.58773083e-02, -1.78476609e-03,\n",
       "         -2.59787962e-03, -1.97968949e-02, -7.63073040e-04, -1.82023998e-02,\n",
       "          1.51916863e-02,  5.90296369e-03, -9.06935800e-03,  2.77817366e-03,\n",
       "         -2.60214768e-02,  3.63195920e-03,  9.21424362e-04,  1.04065612e-02,\n",
       "         -3.12954187e-02,  3.64043261e-03, -3.80014852e-02,  1.98038351e-02,\n",
       "          5.22035360e-03,  4.31755045e-03, -2.38529630e-02,  1.45974485e-02,\n",
       "         -3.37073468e-02, -1.58154196e-03,  3.89468111e-02,  3.11090499e-02,\n",
       "         -9.99424048e-03,  2.10067127e-02,  2.60160863e-02,  2.48107128e-03,\n",
       "          4.59352732e-02,  6.02330174e-03, -8.66520312e-03,  1.40693607e-02,\n",
       "          9.53773968e-03, -1.69171579e-02,  2.93728914e-02,  9.56322532e-03,\n",
       "         -2.64352765e-02,  2.12569581e-03, -2.56759115e-02, -2.69920919e-02,\n",
       "         -1.47233179e-04,  1.05856499e-02,  1.59090403e-02, -2.72336155e-02,\n",
       "          1.22128548e-02,  4.83143558e-05, -4.95277869e-04, -1.43206585e-02,\n",
       "         -2.72750016e-02,  9.83621646e-03,  2.47653443e-02,  5.89480344e-03,\n",
       "          1.44580042e-03, -2.02325732e-02,  4.48414451e-03,  2.20570574e-03,\n",
       "         -1.29030924e-02,  2.19206344e-02,  3.22775878e-02, -5.89698274e-03,\n",
       "         -2.76257303e-02, -2.40338929e-02, -2.46669948e-02,  2.83148838e-03,\n",
       "         -1.52645784e-03, -7.80121563e-03,  2.07446460e-02,  8.42681620e-03,\n",
       "          1.61190201e-02,  1.96551178e-02,  3.42422985e-02,  2.41620000e-02,\n",
       "         -2.11400036e-02,  1.79072525e-02,  4.96473648e-02, -1.78760085e-02,\n",
       "         -2.24254895e-02, -3.05686388e-02,  2.00197790e-02,  9.23171733e-03,\n",
       "          8.28493666e-03,  8.08441732e-03,  1.45220151e-02, -2.81702690e-02,\n",
       "          1.59729365e-02, -2.41165478e-02,  4.02838504e-03, -1.93092376e-02,\n",
       "          2.03004619e-03, -9.08979774e-03,  7.78365880e-03, -2.38540815e-03,\n",
       "          1.62587631e-02,  1.50434393e-02,  4.82714130e-03,  8.95791035e-03,\n",
       "          7.86347687e-03,  1.59719866e-02, -1.26944548e-02, -1.60757024e-02,\n",
       "          1.67497899e-02,  1.13674602e-03, -3.67181026e-03,  5.33076376e-03,\n",
       "          1.70358960e-02,  1.04554743e-02,  2.23162565e-02, -1.31021086e-02,\n",
       "         -4.37110383e-03, -5.20978868e-03,  1.91654060e-02,  1.28861964e-02,\n",
       "          1.95166897e-02,  9.22974106e-03, -1.99976414e-02, -1.22384578e-02,\n",
       "         -9.90017690e-03,  3.43302781e-05, -1.98899955e-02,  5.79438964e-03,\n",
       "          1.33511815e-02,  6.72459183e-03, -3.47634479e-02, -4.21673618e-03,\n",
       "         -3.95871960e-02,  9.46821179e-03, -7.96835031e-03,  1.24896793e-02,\n",
       "         -3.30745033e-03,  2.89026313e-02, -3.02787013e-02,  1.64062958e-02,\n",
       "         -2.77685095e-02,  1.04266657e-02,  1.90111641e-02,  2.11924054e-02,\n",
       "          5.52175613e-03, -6.34340709e-03, -6.02945453e-03, -1.07448455e-02,\n",
       "          1.99158061e-02, -4.41204011e-03,  9.76458006e-03, -6.45137997e-03,\n",
       "          4.41676304e-02,  2.69222539e-02,  8.48304387e-03, -1.48407379e-02,\n",
       "         -1.16140898e-02, -1.41814202e-02,  4.01384048e-02,  2.69275028e-02,\n",
       "          1.31162498e-02, -7.42849847e-03,  2.97916327e-02, -1.45359579e-02,\n",
       "          8.02022498e-03,  2.18274761e-02, -5.51311625e-03, -7.69052049e-03,\n",
       "         -1.92343374e-03,  2.89079471e-04, -1.93788391e-03, -1.09365778e-02,\n",
       "          2.19331887e-02, -1.71930920e-02, -3.30031402e-02,  1.55447228e-02,\n",
       "         -2.19779778e-02, -3.56970802e-02,  1.12826452e-02, -8.05029180e-03,\n",
       "         -6.48973742e-03,  1.45840039e-02, -5.65713644e-02, -3.08289332e-03,\n",
       "         -2.23457925e-02,  2.60920264e-02, -2.25442834e-02,  2.29486963e-03,\n",
       "         -2.45878901e-02,  3.17067816e-03,  8.74714274e-03,  7.62830907e-03,\n",
       "          1.39261140e-02, -3.27410921e-03,  7.44998315e-03,  1.28145497e-02,\n",
       "          1.79329775e-02, -3.34227383e-02, -7.20012281e-03, -5.84697467e-04,\n",
       "         -3.12651251e-03,  1.73752997e-02,  4.77916049e-03, -2.79415268e-02,\n",
       "          8.86372570e-03, -1.52387014e-02,  3.39941010e-02, -2.42072232e-02,\n",
       "         -8.08070414e-03,  1.05887717e-02,  4.00493760e-03,  8.58259480e-03,\n",
       "         -4.44075093e-02, -7.92151224e-03, -1.01397345e-02,  1.63582377e-02,\n",
       "         -2.09543090e-02,  1.95012242e-02,  5.16790617e-03, -1.55050624e-02,\n",
       "         -4.91456420e-04, -2.76933555e-02, -2.26457865e-04, -3.29554342e-02,\n",
       "         -8.02267622e-03,  1.28577063e-02,  2.09840741e-02,  5.62992226e-03,\n",
       "         -1.01705194e-02,  4.83129844e-02, -1.93747878e-02, -2.24923603e-02,\n",
       "          4.14921641e-02,  3.83579433e-02,  1.48950052e-03, -4.13842425e-02,\n",
       "         -2.33725342e-03,  9.20999981e-03, -1.67988297e-02, -4.20740657e-02,\n",
       "          2.79497262e-02,  1.59909483e-02, -7.52611691e-03,  8.28963146e-03,\n",
       "          2.26168390e-02,  3.78709175e-02,  2.44284328e-02, -2.10736431e-02,\n",
       "         -1.11782392e-02,  2.88943537e-02,  7.69422436e-03, -1.30860182e-02,\n",
       "          1.00226682e-02,  1.20506380e-02, -6.79297373e-05,  3.66371195e-03,\n",
       "          5.03481664e-02, -9.39719565e-03,  7.72931194e-03,  3.34717594e-02,\n",
       "          1.13594802e-02, -2.87622586e-03, -1.65097136e-02, -2.08688416e-02,\n",
       "          1.56585593e-02,  1.21742245e-02, -1.00204358e-02,  3.00351195e-02,\n",
       "          4.16680574e-02,  9.14953742e-03, -2.33995798e-03,  4.29239124e-03,\n",
       "          8.77228286e-03, -3.18667404e-02,  8.40013847e-03,  1.73375402e-02,\n",
       "         -1.44072408e-02, -9.28652473e-03,  1.87529568e-02,  5.21580689e-04,\n",
       "         -3.36868176e-03,  1.70422737e-02, -3.47432382e-02, -8.45596939e-03,\n",
       "         -2.00915691e-02,  2.97724660e-02,  1.05954567e-02, -3.47696505e-02,\n",
       "          4.26326739e-03, -1.12805916e-02,  2.04650257e-02,  5.95170725e-03,\n",
       "          2.28600595e-02,  1.85036156e-02,  2.66585965e-02,  2.15199180e-02,\n",
       "          8.72468692e-04,  7.28268595e-03, -3.78809199e-02,  1.76347699e-02,\n",
       "          1.69845801e-02, -9.15694237e-03, -2.69989464e-02,  6.10217685e-03,\n",
       "          9.11310315e-03,  7.04094023e-03, -4.98126168e-03, -2.62245126e-02,\n",
       "         -3.01976055e-02, -4.37551141e-02, -1.78772341e-02,  1.55993113e-02,\n",
       "          5.70441410e-02, -1.29359821e-02,  1.80097502e-02,  2.05089469e-02,\n",
       "          1.10874267e-03, -3.04771680e-02, -6.60755998e-03, -1.12164300e-02,\n",
       "         -1.22941230e-04, -2.76893117e-02, -1.51887322e-02, -1.05642052e-02,\n",
       "          3.55657227e-02,  2.61911880e-02, -1.78885292e-02,  3.33457403e-02,\n",
       "          9.23757534e-03,  2.17824858e-02, -4.23788046e-03, -5.74845485e-02,\n",
       "         -3.43564112e-04, -1.52010126e-02,  3.44905746e-03,  1.67873017e-02,\n",
       "          2.61297133e-02, -7.92137440e-03, -1.39798140e-02,  5.88871026e-03,\n",
       "         -1.93599313e-02,  1.02833575e-02,  2.76346272e-03,  5.75391296e-03,\n",
       "          2.69952673e-03, -2.29866151e-02,  1.65431891e-02,  1.04363365e-02,\n",
       "         -2.44775452e-02, -2.79671978e-02,  5.70460735e-03, -1.75694022e-02,\n",
       "         -1.70704704e-02, -2.20804475e-02,  8.00154055e-04,  3.43766622e-03],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 7,\n",
       "  'topic_words': array(['fiction', '소설', 'scientist', 'deviance', 'writer', 'novel', '작가',\n",
       "         'literature', 'authors', 'scholar', 'heuristics', '과학자',\n",
       "         'scientists', 'scholars', 'author', 'neuroscientist', 'heuristic',\n",
       "         'abilities', 'feminist', 'neurocultures', 'darwin', 'intellectual',\n",
       "         'plausible', '문학', 'psychosis', 'neuroscientists', '아이언맨',\n",
       "         'kruskal', 'repetitive', 'humanities', 'ability', 'creatures',\n",
       "         '마태오', 'skill', 'destruction', 'heroes', '저자', 'robots', 'skills',\n",
       "         'neurosciences', 'selvars', 'gatsby', 'zimbardo', 'neurosci',\n",
       "         'published', '마미코', 'substantia', '능력', 'psychiatric', 'attempts'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([ 3.91873941e-02,  1.57202464e-02,  1.58437937e-02, -6.70314254e-03,\n",
       "         -1.55833755e-02,  4.74054404e-02, -7.77413789e-03, -7.17411283e-03,\n",
       "          4.07202989e-02,  1.33084785e-03,  4.40641679e-03,  2.27600033e-03,\n",
       "          4.15163413e-02, -7.89413787e-03, -4.11632881e-02, -1.66339949e-02,\n",
       "          3.36363656e-03, -5.02350070e-02,  4.14547976e-03,  3.95729542e-02,\n",
       "         -3.15284953e-02, -4.78665605e-02,  5.00736013e-02,  1.28488820e-02,\n",
       "         -5.32359779e-02,  1.05224270e-02,  1.99804343e-02,  2.16401089e-03,\n",
       "          1.94460917e-02, -5.16420230e-02,  5.33455238e-03,  2.09182613e-02,\n",
       "          2.55532023e-02, -2.87465677e-02,  2.85295420e-03, -9.15406737e-03,\n",
       "          1.57950483e-02, -1.76603906e-02, -1.85202770e-02, -3.78790982e-02,\n",
       "         -1.74987689e-02,  1.37630515e-02,  3.58220078e-02,  8.41718074e-03,\n",
       "         -1.31845307e-02, -9.40610305e-04,  8.21135938e-03, -3.20998989e-02,\n",
       "          1.76312272e-02, -6.33753370e-03,  4.85154829e-04, -1.65436100e-02,\n",
       "         -1.62506499e-03,  1.06889028e-02,  7.33376481e-03, -5.40949628e-02,\n",
       "          4.09538224e-02, -7.73777952e-03,  8.02326389e-03,  1.11044450e-02,\n",
       "         -9.68879461e-03,  5.34872375e-02, -1.02352789e-02, -3.95686328e-02,\n",
       "         -6.07118709e-03,  2.12111860e-03,  2.52395794e-02, -3.10683288e-02,\n",
       "         -1.98514182e-02,  9.50761884e-03,  4.21566190e-03,  8.35067313e-03,\n",
       "          2.12063976e-02, -2.06389558e-02,  3.75929987e-03,  1.03244577e-02,\n",
       "         -2.26913728e-02,  6.93085790e-03, -4.57808329e-03, -5.65586574e-02,\n",
       "         -6.16879538e-02, -2.79211737e-02,  3.24041978e-03,  3.59314531e-02,\n",
       "          6.48537977e-03, -2.00723149e-02, -3.23134698e-02, -2.63155513e-02,\n",
       "         -7.00733904e-03,  2.17984673e-02, -2.91738193e-02, -2.10739635e-02,\n",
       "         -3.63672189e-02,  1.89324026e-03,  2.75733918e-02, -4.21596365e-03,\n",
       "          3.82245444e-02,  4.27092873e-02, -3.68212823e-05,  2.02025101e-02,\n",
       "          1.05396323e-02,  1.61182694e-02, -2.83270143e-02, -1.17783144e-03,\n",
       "         -3.17716924e-03, -2.87520643e-02, -1.90312732e-02,  2.32321792e-03,\n",
       "         -1.19175771e-02,  2.05880660e-03,  2.71030851e-02, -2.24946961e-02,\n",
       "         -3.40885692e-03,  1.05958711e-02,  2.46366188e-02, -1.41548403e-02,\n",
       "         -3.62796185e-04, -1.97873823e-02, -8.72761011e-03,  5.15618268e-03,\n",
       "          9.16046090e-03,  3.73708755e-02,  2.35404968e-02,  2.72805262e-02,\n",
       "          1.25673926e-03,  2.30396464e-02,  1.44024603e-02, -8.31285771e-03,\n",
       "         -4.50938428e-03,  4.16025566e-03, -3.28822434e-02, -3.02608348e-02,\n",
       "         -1.96517557e-02,  1.09198792e-02, -3.26749636e-03,  5.55660091e-02,\n",
       "         -1.35488948e-02,  3.46650463e-03,  4.79535945e-02,  3.04180430e-03,\n",
       "          2.54929196e-02,  1.22232735e-02,  6.79665105e-03,  2.39782184e-02,\n",
       "          2.14754362e-02,  2.11407337e-03,  4.69724871e-02, -1.66788548e-02,\n",
       "          8.17232486e-03, -2.38680802e-02,  3.65611091e-02,  1.21881336e-03,\n",
       "         -9.85238608e-03, -4.62767016e-03,  7.04378646e-04,  4.83471714e-03,\n",
       "          2.27176142e-03, -1.65112540e-02, -2.82698628e-02,  6.84699789e-03,\n",
       "          2.78946310e-02, -3.60239595e-02,  2.99674319e-03,  9.04426537e-03,\n",
       "         -1.18465563e-02, -2.53379736e-02,  1.33218411e-02, -1.83768217e-02,\n",
       "         -7.56712910e-03, -1.42244436e-02, -2.16411762e-02,  2.25548763e-02,\n",
       "         -3.65526904e-03,  1.37820430e-02, -1.68566741e-02,  1.55782513e-02,\n",
       "         -2.50447765e-02,  2.55426746e-02,  9.25198290e-03,  3.48820016e-02,\n",
       "          1.04869828e-02,  8.06500763e-03,  9.56733618e-03, -2.70205978e-02,\n",
       "         -1.58846993e-02,  3.11782164e-03,  1.35910809e-02,  5.51573038e-02,\n",
       "          1.92274507e-02,  2.40239501e-02,  7.31377210e-03, -2.04167757e-02,\n",
       "          2.75056828e-02, -2.95536686e-03, -1.00969402e-02,  3.59120406e-02,\n",
       "         -1.44387521e-02, -4.49456554e-03,  5.10975905e-03,  8.28033499e-03,\n",
       "         -1.62559710e-02,  2.30511799e-02, -1.51877257e-03, -4.68899906e-02,\n",
       "          1.85114071e-02,  2.96307518e-03,  1.80315096e-02,  2.77522001e-02,\n",
       "          5.50413178e-03,  1.99005213e-02, -8.09807517e-03, -1.84821319e-02,\n",
       "          1.62700769e-02,  1.54463081e-02,  1.02277361e-02, -7.26003014e-03,\n",
       "          1.45267220e-02, -3.02751604e-02,  5.10284677e-03,  2.61305608e-02,\n",
       "         -2.07936596e-02, -3.01098474e-03,  2.45079976e-02,  2.40958557e-02,\n",
       "         -8.00317805e-03, -2.84965616e-02, -2.90912613e-02, -2.95894011e-03,\n",
       "         -4.94872369e-02, -2.58966237e-02,  8.45967513e-03, -6.53691683e-03,\n",
       "         -1.06942868e-02,  1.68040060e-02,  2.52081715e-02,  7.47826276e-03,\n",
       "         -8.52819346e-03,  9.28977225e-03,  3.32114734e-02, -8.60659033e-03,\n",
       "          8.27452727e-03, -5.39707718e-03,  3.64969075e-02,  4.12506424e-03,\n",
       "          1.74455848e-02,  2.70697903e-02,  4.20507677e-02,  1.24854420e-03,\n",
       "          2.64772605e-02,  9.29032639e-03,  5.73987234e-03, -1.98854059e-02,\n",
       "          1.66736599e-02, -1.19747166e-02,  3.15779704e-03, -1.01397857e-02,\n",
       "         -1.82883092e-03,  2.29682773e-03, -2.67160982e-02,  4.80521433e-02,\n",
       "          5.83298225e-03,  3.70007418e-02, -1.20963259e-02, -3.78092960e-03,\n",
       "          6.24866737e-03, -5.16786464e-02, -1.99055392e-02,  3.00301686e-02,\n",
       "         -4.75263968e-03, -2.65449714e-02, -3.77270882e-03, -1.52624846e-02,\n",
       "          1.61171309e-03, -2.80910488e-02,  4.05535921e-02,  1.43362740e-02,\n",
       "         -2.67148996e-03, -9.63292364e-03, -4.91740257e-02, -2.20383182e-02,\n",
       "         -3.26455794e-02, -6.89713471e-03,  1.82246026e-02, -9.03428532e-03,\n",
       "          6.14730921e-03,  2.46007405e-02, -3.69661525e-02, -1.11728916e-02,\n",
       "         -1.34278862e-02, -2.11054436e-03, -8.91911052e-03,  8.20414070e-03,\n",
       "          1.48916934e-02,  3.54443341e-02,  2.64489818e-02,  3.68454084e-02,\n",
       "          9.01986752e-03, -4.89461981e-03, -6.77638222e-03,  2.71480344e-02,\n",
       "          5.06378571e-03,  2.08639074e-02,  4.17431816e-03, -3.54556963e-02,\n",
       "          1.76418684e-02, -4.66730073e-03, -3.22615989e-02,  4.47606258e-02,\n",
       "          2.36901082e-02, -1.51266567e-02, -5.13112172e-03, -7.15298345e-03,\n",
       "          2.28383974e-03, -4.86138742e-03,  4.50290665e-02,  2.95100231e-02,\n",
       "          2.52791159e-02,  2.25188304e-03,  2.48832745e-03, -7.18269777e-03,\n",
       "          1.82395745e-02, -1.18976831e-02, -1.26150046e-02,  7.47143198e-03,\n",
       "         -4.61723767e-02,  1.09328628e-02,  7.67015107e-03, -1.50613701e-02,\n",
       "          3.52777615e-02,  2.39583272e-02,  3.26259271e-03,  1.27376840e-02,\n",
       "         -2.06553135e-02, -2.46812962e-02,  6.66602980e-03,  1.47191726e-03,\n",
       "         -2.48083249e-02,  6.38684584e-03, -5.20733334e-02, -2.05619875e-02,\n",
       "         -2.26378776e-02,  2.56523825e-02, -3.44646871e-02, -1.85210574e-02,\n",
       "         -1.03226732e-02, -1.46791211e-03,  4.79547977e-02, -7.78401829e-03,\n",
       "          2.73646205e-04,  5.65316412e-04,  9.52680968e-03,  1.17470734e-02,\n",
       "          1.93901025e-02, -1.21185626e-03, -1.31682782e-02, -1.19323106e-02,\n",
       "         -4.86274250e-03,  2.40104217e-02, -1.14353923e-02, -8.80006514e-03,\n",
       "          4.71352693e-03,  1.53288776e-02,  4.09679115e-02,  2.85326075e-02,\n",
       "          1.24482373e-02, -2.84082768e-03, -1.35791413e-02,  1.01871593e-02,\n",
       "          2.27362179e-05,  2.28555165e-02, -1.46239894e-02,  1.79160349e-02,\n",
       "          4.77227848e-03,  6.13099197e-03,  2.22496856e-02,  4.01709750e-02,\n",
       "         -2.91641578e-02,  9.77838598e-03,  1.53077375e-02, -2.00936198e-02,\n",
       "         -1.31168067e-02,  3.58271122e-04,  3.12982593e-03,  3.41928005e-02,\n",
       "         -4.69681434e-03,  4.94551659e-02, -1.01549430e-02, -5.76421134e-02,\n",
       "          5.26800528e-02,  2.10003927e-02, -3.83367459e-03, -3.41455676e-02,\n",
       "          2.60396078e-02, -3.62597406e-03, -1.27271982e-03,  6.43082056e-03,\n",
       "          1.29105896e-03, -1.45250447e-02,  1.17028374e-02, -7.66356662e-03,\n",
       "          1.78524181e-02,  3.87587696e-02, -3.56982462e-02, -8.95439927e-03,\n",
       "         -3.77431861e-03,  1.29649136e-02, -2.78505441e-02, -1.57778412e-02,\n",
       "         -2.46146531e-03,  1.46182701e-02,  3.96064073e-02,  4.93148051e-04,\n",
       "          3.43927629e-02,  1.83784927e-03,  1.60492733e-02,  4.07650881e-02,\n",
       "          3.35428230e-02,  1.14879180e-02, -1.37638235e-02, -1.98253840e-02,\n",
       "          2.45203376e-02,  1.10653518e-02, -4.47470415e-03,  2.06538886e-02,\n",
       "          5.23532480e-02,  2.34476943e-02,  2.10943092e-02, -4.90499055e-03,\n",
       "         -4.58775461e-02, -2.24125497e-02,  3.05399094e-02, -1.10914530e-02,\n",
       "         -2.14130208e-02, -2.88417730e-02,  1.69893075e-02, -1.22447005e-02,\n",
       "          2.06363164e-02,  6.17803913e-03, -5.40611260e-02,  1.79147497e-02,\n",
       "         -9.63822845e-03,  4.07180116e-02,  1.49091259e-02, -4.82025519e-02,\n",
       "          1.13675911e-02,  2.25867294e-02,  5.59465066e-02,  3.41991410e-02,\n",
       "          2.92689968e-02,  9.58455913e-03,  3.78527213e-03,  4.32206541e-02,\n",
       "          4.05802904e-03,  8.76318291e-03, -2.46584099e-02,  1.33788446e-02,\n",
       "         -9.19129816e-04,  3.45388637e-03,  1.56451296e-02,  1.27752908e-02,\n",
       "          3.26744537e-03, -2.77123065e-04, -1.33202169e-02,  8.81359447e-04,\n",
       "         -2.64854636e-02, -5.48476428e-02, -3.52805965e-02,  3.10985651e-02,\n",
       "         -3.63965891e-02,  5.56722470e-03, -1.05209984e-02,  9.47834738e-03,\n",
       "         -1.03097642e-02,  6.08222187e-03,  2.84614274e-03,  1.15594650e-02,\n",
       "          2.15635169e-02, -5.19587891e-03, -3.41464998e-04, -4.98784101e-03,\n",
       "         -6.66029379e-03,  4.97128852e-02, -3.85965109e-02,  9.90232266e-03,\n",
       "         -3.41601223e-02, -8.49038269e-03, -1.34773850e-02, -5.68066388e-02,\n",
       "         -2.11854912e-02, -2.67545450e-02,  1.50451837e-02, -1.21000560e-03,\n",
       "          3.37461121e-02, -3.84607445e-03,  2.06837188e-02,  4.49719001e-03,\n",
       "         -2.55192649e-02, -4.14451642e-05, -2.45231986e-02, -1.31756684e-03,\n",
       "          1.46934355e-03, -1.72715224e-02,  4.08586524e-02, -6.62960485e-03,\n",
       "         -4.67103086e-02, -1.96390116e-04, -3.72388487e-04,  4.93393699e-03,\n",
       "         -1.17784524e-02, -4.80515137e-02,  2.46078484e-02,  2.44774427e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 8,\n",
       "  'topic_words': array(['correlation', 'neuroscientific', 'correlations', 'neuronal',\n",
       "         'adhd', 'neurological', 'somatosensory', 'statistical',\n",
       "         'correlated', 'statistically', 'neurosciences', 'neuroimaging',\n",
       "         'neurosci', 'neuroethics', 'correlates', 'correlate',\n",
       "         'neuroscience', 'neuro', 'statistics', 'perceptual', 'neurology',\n",
       "         'neurogenesis', 'psychology', 'sensory', 'neurol', 'asymptotic',\n",
       "         'neurobiological', 'demographic', 'neurons', 'psychological',\n",
       "         'populations', 'cognitive', 'impulsivity', 'neurosurg',\n",
       "         'coefficient', 'neuroimage', 'neuron', 'selective', 'coefficients',\n",
       "         'neural', 'alzheimers', 'predictors', 'syndromes', 'predictor',\n",
       "         'statistic', 'neuroscientists', 'distinctiveness', 'predictive',\n",
       "         'differentiated', 'impulsive'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.05343088,  0.02022746,  0.00414246,  0.0015332 , -0.00938556,\n",
       "          0.03662354, -0.03337096,  0.00339997,  0.00498784,  0.03536805,\n",
       "          0.0142963 , -0.02849222,  0.03386584, -0.01384476, -0.03452722,\n",
       "          0.03627609, -0.01143452, -0.0264877 ,  0.03923668,  0.03765052,\n",
       "         -0.00014308, -0.04465134, -0.03781911,  0.04601126, -0.05504148,\n",
       "         -0.01084181,  0.00230133,  0.02236429,  0.00453836,  0.00742209,\n",
       "         -0.0267906 ,  0.02191028,  0.02182888, -0.05087814,  0.00704368,\n",
       "         -0.03462546, -0.0187589 ,  0.01509654, -0.01319105, -0.04182675,\n",
       "         -0.02109858, -0.001567  ,  0.05194359, -0.0241993 , -0.03594428,\n",
       "         -0.00735228,  0.05492505,  0.02966063, -0.00205521, -0.03685119,\n",
       "          0.04510107, -0.00228196,  0.03414177, -0.04615854,  0.025036  ,\n",
       "         -0.0270552 ,  0.00706412,  0.01617681,  0.00558187,  0.03937921,\n",
       "         -0.02354723,  0.05224258, -0.02196297, -0.03724017, -0.03329416,\n",
       "         -0.0036122 ,  0.0282978 , -0.00507434, -0.02968922, -0.01438628,\n",
       "         -0.01821717,  0.01515197, -0.0055799 , -0.04672771, -0.02191055,\n",
       "         -0.02025874,  0.0367044 ,  0.03364353, -0.02469633, -0.05415438,\n",
       "         -0.05517102, -0.04323045,  0.01644717,  0.02374921, -0.04486148,\n",
       "          0.00715518, -0.03669258, -0.01335076, -0.01876188, -0.02892283,\n",
       "         -0.04084888, -0.04630499, -0.02454208, -0.03936068,  0.00532539,\n",
       "          0.04707526,  0.04840336,  0.05196569,  0.00933167,  0.01908474,\n",
       "          0.02708563, -0.03906942,  0.0321881 , -0.00030991,  0.01948446,\n",
       "          0.03041878, -0.05301236, -0.01278937, -0.01778322,  0.04614302,\n",
       "          0.03822563, -0.04498896, -0.04766801,  0.01738476,  0.04379701,\n",
       "         -0.01948176,  0.03088034,  0.02486788, -0.01406789, -0.00338189,\n",
       "         -0.03260776,  0.04278352,  0.03813174,  0.02802148, -0.00649342,\n",
       "          0.02889412,  0.04577345,  0.0246136 , -0.04526682,  0.04455486,\n",
       "         -0.04112647, -0.02063984,  0.02470262,  0.03643645,  0.00164744,\n",
       "          0.05503457, -0.03736927, -0.03765789,  0.0544045 ,  0.03415039,\n",
       "          0.04887801, -0.00376634,  0.03406333, -0.01432916,  0.04013628,\n",
       "          0.03124898, -0.03261134,  0.04660535,  0.04038052,  0.04780624,\n",
       "          0.04951807,  0.00171723, -0.01576689, -0.01764009, -0.03541905,\n",
       "         -0.01086704,  0.01706229, -0.01848521,  0.0065421 , -0.03479438,\n",
       "          0.03220611, -0.04435608, -0.04383584, -0.01963158, -0.00125456,\n",
       "         -0.03825845,  0.02828522, -0.00072337, -0.04180324,  0.0341386 ,\n",
       "         -0.0351091 , -0.03677231,  0.02087647,  0.01304706, -0.02165606,\n",
       "          0.03292801,  0.02215092,  0.02035609, -0.00890102,  0.01657612,\n",
       "          0.01743843, -0.02768057, -0.00492515, -0.02639162, -0.02984409,\n",
       "         -0.01018055,  0.03501767,  0.05174247,  0.03415281,  0.03121598,\n",
       "         -0.0121592 , -0.02149529,  0.01339913, -0.01603376, -0.03757044,\n",
       "         -0.00479933, -0.03005381,  0.02636084,  0.04650754,  0.01989971,\n",
       "         -0.02886139,  0.02114208, -0.01645772, -0.03349891, -0.00048341,\n",
       "         -0.04823129, -0.04659525,  0.0352211 ,  0.01489335,  0.04325366,\n",
       "          0.01234156, -0.03206221,  0.0128758 ,  0.0070055 ,  0.04719008,\n",
       "         -0.00483496,  0.02601652, -0.0456054 , -0.00096027, -0.03179492,\n",
       "          0.00852457,  0.03326458,  0.05046048,  0.02392762, -0.04474905,\n",
       "         -0.02659973, -0.05429933,  0.02107267, -0.01416029, -0.03392944,\n",
       "         -0.01040643,  0.0333537 , -0.0308343 ,  0.04117709,  0.01726454,\n",
       "         -0.04061281,  0.00726361,  0.03181136,  0.04662457,  0.00415567,\n",
       "          0.00225481,  0.02099555, -0.02128041,  0.03725962,  0.04567925,\n",
       "         -0.02264929,  0.04250583, -0.00571776, -0.00285866,  0.02609552,\n",
       "         -0.02107777, -0.04495233, -0.00403564, -0.04107315,  0.00505003,\n",
       "         -0.02800674, -0.0038294 ,  0.01358103, -0.02074807,  0.00254621,\n",
       "         -0.00714923,  0.04470601, -0.04098304,  0.02439755,  0.03668282,\n",
       "         -0.05487881, -0.03729615,  0.03612605,  0.01573585,  0.01841251,\n",
       "          0.02186674,  0.01427732, -0.00453659, -0.03992099,  0.02761768,\n",
       "          0.02389312, -0.04257758,  0.03357642, -0.05376693, -0.00363039,\n",
       "         -0.03957326, -0.01236183,  0.02095795,  0.03842035, -0.04267152,\n",
       "          0.03331991, -0.04990924, -0.03414739, -0.03065359,  0.02437583,\n",
       "          0.04978674,  0.02537769,  0.03196745, -0.02118913, -0.03656828,\n",
       "         -0.04319363,  0.01545977,  0.0234572 ,  0.0404393 ,  0.04283743,\n",
       "         -0.05076778,  0.03516274, -0.02839238, -0.00905315, -0.03812223,\n",
       "         -0.02537368, -0.02220112,  0.03553361, -0.01309677,  0.02646105,\n",
       "         -0.04320694, -0.03623392,  0.00590151, -0.03999263,  0.05161628,\n",
       "          0.04755007,  0.01312688, -0.0287736 ,  0.01844641, -0.04628303,\n",
       "         -0.00274832, -0.04640066, -0.02209359,  0.03922946, -0.01483809,\n",
       "         -0.02949647, -0.03134192, -0.00982383,  0.00179193,  0.01247134,\n",
       "         -0.0068518 , -0.04647332, -0.04108623, -0.0292771 ,  0.01279435,\n",
       "         -0.00589055, -0.0477295 , -0.03915862, -0.04571899,  0.00331265,\n",
       "         -0.0409742 , -0.0119923 ,  0.00997445, -0.05109508, -0.0049317 ,\n",
       "          0.04432783,  0.05322176, -0.01582145, -0.04306057,  0.02686371,\n",
       "          0.03692799,  0.02035504, -0.00295949,  0.04642833,  0.02588348,\n",
       "          0.03734782,  0.02009586,  0.025693  , -0.04252997, -0.03926644,\n",
       "          0.01885279, -0.03142489,  0.0459085 ,  0.01107752, -0.04004595,\n",
       "          0.02520629, -0.03309347,  0.02664021, -0.03336824,  0.01373706,\n",
       "          0.02191053,  0.04502636, -0.00927223,  0.02057768, -0.00336806,\n",
       "         -0.04252026, -0.00052109,  0.00184566,  0.01013589, -0.0349854 ,\n",
       "          0.04749811, -0.01731637,  0.02893074,  0.02165623, -0.02888882,\n",
       "          0.05526275,  0.03855437, -0.04179673,  0.05349964, -0.02450006,\n",
       "          0.02470295,  0.0080102 ,  0.00244662,  0.04431091, -0.03848499,\n",
       "          0.0234953 ,  0.0540351 , -0.02355791, -0.01633427,  0.02767817,\n",
       "          0.02472341,  0.04561339,  0.03953167,  0.0481433 , -0.03669687,\n",
       "          0.01358367,  0.01983914, -0.03680984,  0.03791694, -0.01779046,\n",
       "          0.01870839, -0.01525736, -0.00378573,  0.04274272, -0.00406361,\n",
       "          0.05275133,  0.01564805, -0.032708  ,  0.0332839 ,  0.00169817,\n",
       "         -0.04783204, -0.05077586,  0.03187124,  0.04662994,  0.05260146,\n",
       "         -0.02043313, -0.04808238, -0.03686535, -0.01226136,  0.01564071,\n",
       "         -0.04905783, -0.02425465, -0.02199142, -0.04260524,  0.02442002,\n",
       "         -0.00407035,  0.00734415, -0.0340794 , -0.05517177,  0.03473135,\n",
       "          0.00354721, -0.01352525,  0.02778311, -0.04867025,  0.02708333,\n",
       "          0.00472827, -0.01083413,  0.03153513,  0.00575906, -0.00448866,\n",
       "         -0.02582085, -0.01491769,  0.00274837,  0.00175517, -0.0374377 ,\n",
       "         -0.00323328,  0.01310094,  0.02189366, -0.00811578,  0.00516128,\n",
       "         -0.03635131, -0.02571964, -0.02135666, -0.04671923,  0.0277873 ,\n",
       "         -0.0534157 , -0.02834064, -0.04505177,  0.05207986,  0.02582094,\n",
       "          0.01825022,  0.04946284, -0.03033293,  0.01960223, -0.01778265,\n",
       "         -0.01619994,  0.00073615, -0.02242656, -0.02857461,  0.00798275,\n",
       "          0.03384724,  0.05557656, -0.04075481, -0.01610229,  0.03623184,\n",
       "         -0.02219227, -0.02024959, -0.04709774, -0.03323454, -0.02656906,\n",
       "          0.02744075,  0.01963034, -0.02113608,  0.00599736, -0.02832425,\n",
       "         -0.03372472, -0.03061142,  0.00013719,  0.03417524,  0.00924159,\n",
       "          0.02508013, -0.05052344,  0.05500985, -0.03730611, -0.04755074,\n",
       "         -0.05102   ,  0.01085863, -0.03593952, -0.04064365, -0.04966885,\n",
       "         -0.00250312,  0.02535665], dtype=float32)},\n",
       " {'topic_idx': 9,\n",
       "  'topic_words': array(['python', 'cython', 'numpy', '파이썬', 'multiprocessing',\n",
       "         'subprocess', 'matplotlib', '함수', '프로그래밍', 'tensorflow', 'stdout',\n",
       "         'scipy', '컴파일러', 'compiler', 'function', 'varlambda', '컴파일',\n",
       "         'compile', 'kwargs', 'functions', 'sklearn', '코딩', 'preprocessing',\n",
       "         'programming', 'dataframe', 'integer', '변수', 'algorithmic', 'args',\n",
       "         'dict', 'nipype', 'integers', 'computational', 'github',\n",
       "         'computation', 'algorithms', 'gcc', 'functional', 'tuple',\n",
       "         'algorithm', 'processes', 'matlab', '잠재변수', 'dataset', 'lineplot',\n",
       "         'syntax', 'workflow', 'coding', 'java', 'computationally'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-5.40070273e-02, -1.50047429e-03, -3.92539389e-02, -5.10307634e-03,\n",
       "          1.65639743e-02, -6.08284809e-02, -5.27557358e-03,  2.30286550e-02,\n",
       "          5.83412014e-02, -2.63771694e-02,  6.94278860e-03,  3.13736759e-02,\n",
       "          3.98431793e-02,  1.37659954e-02, -4.95991893e-02, -4.94801113e-03,\n",
       "          3.74444053e-02, -8.95454455e-03,  3.66887450e-02,  3.97116728e-02,\n",
       "          2.58960575e-02, -6.89474028e-03,  4.05168440e-03,  5.07297516e-02,\n",
       "         -5.91312274e-02, -4.19449136e-02, -2.25121016e-03, -3.12870881e-03,\n",
       "          3.82978283e-02, -3.69301215e-02, -1.24883149e-02,  3.11007611e-02,\n",
       "         -4.25243471e-03, -5.73729761e-02,  7.53899990e-03,  8.71128030e-03,\n",
       "         -3.24715339e-02, -3.15260934e-03,  1.65800210e-02,  1.00686578e-02,\n",
       "         -9.55502968e-03, -8.82469304e-03,  9.13651939e-03,  1.14441039e-02,\n",
       "         -2.05087680e-02,  9.61359683e-03,  4.23369966e-02,  2.35939398e-03,\n",
       "         -3.01544983e-02,  2.28058379e-02, -7.15459319e-05, -3.09866667e-02,\n",
       "         -3.52445431e-02, -1.01639181e-02,  1.60903409e-02, -5.18812761e-02,\n",
       "          8.81885272e-03,  5.01300506e-02,  4.47298400e-02,  8.77324678e-03,\n",
       "          4.35551116e-03,  2.56599244e-02, -1.10449567e-02, -3.83406319e-02,\n",
       "          2.56923609e-03, -2.62401300e-03, -3.32977856e-03, -2.58810651e-02,\n",
       "          3.20012495e-02, -3.37724350e-02, -3.63263674e-02,  1.61762480e-02,\n",
       "         -1.85633413e-02, -1.79264992e-02,  3.20525677e-03, -3.03582903e-02,\n",
       "         -1.06489798e-02,  6.15737634e-03,  5.24703935e-02, -6.11300170e-02,\n",
       "         -6.16827942e-02, -1.13013703e-02, -7.46998936e-03,  1.11790104e-02,\n",
       "          3.72896455e-02,  2.54386780e-03,  1.46061564e-02, -1.57517251e-02,\n",
       "          1.15741948e-02,  1.78149287e-02, -2.09170412e-02, -1.77406110e-02,\n",
       "          2.82223970e-02, -1.45418914e-02,  4.19730283e-02,  3.50922421e-02,\n",
       "         -5.08447699e-02,  4.10703495e-02,  2.54151318e-02,  2.19994714e-03,\n",
       "          1.18905846e-02,  6.67420449e-03, -1.32724540e-02,  2.39510997e-03,\n",
       "          3.96256782e-02,  7.21117621e-03, -1.58594958e-02, -1.99499894e-02,\n",
       "          1.20822126e-02,  3.22624221e-02,  1.42808054e-02, -3.23177688e-02,\n",
       "          1.88767575e-02, -2.74328478e-02,  3.96423563e-02, -1.35022607e-02,\n",
       "         -3.35013755e-02, -1.92378163e-02, -4.06818604e-03,  2.45680623e-02,\n",
       "         -3.97529081e-02,  4.91194194e-03, -3.37263424e-04,  3.51519398e-02,\n",
       "          4.10872325e-02, -8.99042655e-03, -3.19620073e-02,  2.58170944e-02,\n",
       "         -1.15091102e-02,  2.11513527e-02, -4.63892557e-02,  1.47638451e-02,\n",
       "          5.76410368e-02,  2.42863279e-02, -4.02907915e-02,  3.26584689e-02,\n",
       "          6.71066251e-03,  5.30748302e-03,  3.31903845e-02,  2.16635205e-02,\n",
       "          4.52014012e-03,  1.27496372e-03,  2.05843244e-02,  2.19119675e-02,\n",
       "          8.19217972e-03, -2.39934772e-03, -3.43156382e-02,  4.46363948e-02,\n",
       "          1.59709137e-02, -1.14088347e-02,  4.32239957e-02,  4.33911420e-02,\n",
       "         -2.68239062e-02, -1.54115260e-02, -1.56618822e-02, -2.30897944e-02,\n",
       "         -2.38404013e-02, -1.67127233e-02, -2.36315113e-02, -1.11011853e-02,\n",
       "          3.37851271e-02,  9.01292916e-03,  2.90797781e-02,  1.37383062e-02,\n",
       "         -2.85780319e-04, -4.81621828e-03, -2.34440100e-04,  4.72942227e-03,\n",
       "         -1.21201938e-02,  2.99471710e-02,  3.41760367e-02, -4.95987758e-03,\n",
       "          2.15990189e-02,  1.92679316e-02, -1.94310807e-02,  3.21339779e-02,\n",
       "         -3.14963534e-02, -8.25589523e-05, -5.19649759e-02,  4.19179685e-02,\n",
       "         -5.44452714e-03,  3.81728113e-02,  4.70842095e-03, -2.65339278e-02,\n",
       "         -3.66257429e-02, -1.37286237e-03,  1.61576532e-02,  4.36091386e-02,\n",
       "          8.44884384e-03, -1.65260993e-02,  2.51757051e-03, -1.95780527e-02,\n",
       "          4.39116731e-02, -6.89701061e-04, -3.08482349e-02,  1.48422774e-02,\n",
       "         -3.10249031e-02, -1.55427875e-02,  3.49448919e-02,  6.76334789e-03,\n",
       "          2.22843904e-02,  1.71207394e-02, -2.60815490e-02, -1.80009808e-02,\n",
       "         -2.00370215e-02,  1.65711176e-02,  4.32716198e-02, -3.14597823e-02,\n",
       "          2.66361404e-02,  8.87221377e-03, -1.49472281e-02,  3.15207802e-02,\n",
       "         -7.32631981e-03, -2.56520845e-02,  2.41122264e-02, -3.62216891e-03,\n",
       "         -1.00468355e-03, -2.48323884e-02, -2.17726966e-03, -8.45557079e-03,\n",
       "         -6.58834307e-03,  5.50096156e-03,  2.47417409e-02, -9.60683264e-03,\n",
       "         -5.55913076e-02, -3.74541595e-03, -1.70046352e-02,  5.33477915e-03,\n",
       "          3.86160286e-03,  1.88889410e-02,  8.02027248e-03,  5.72889447e-02,\n",
       "          2.97310539e-02, -3.55844549e-03,  1.83265680e-03,  9.09052510e-03,\n",
       "         -1.75482389e-02,  2.03318484e-02,  4.02377080e-03, -1.03359250e-02,\n",
       "          2.81495741e-03,  2.28175633e-02, -8.94886069e-03,  1.25390189e-02,\n",
       "          1.01269716e-02, -5.96297160e-02,  9.91416816e-03,  8.79775209e-04,\n",
       "         -3.26169119e-03, -1.70920063e-02, -1.92680229e-02, -3.38305719e-02,\n",
       "         -6.78950083e-03, -7.08731171e-03,  3.57995369e-02,  5.40152309e-04,\n",
       "          2.74591614e-02, -3.60564478e-02,  2.51551881e-03, -1.19318245e-02,\n",
       "          4.23574410e-02,  2.59102471e-02, -2.62484383e-02, -4.33785990e-02,\n",
       "          2.69560851e-02, -5.02677448e-02, -7.91399553e-03,  2.37546414e-02,\n",
       "          1.91298388e-02,  2.52738111e-02,  1.77872255e-02, -4.29028384e-02,\n",
       "         -1.65298916e-02,  4.73028049e-03,  9.79061984e-03,  1.11701060e-02,\n",
       "         -2.74668392e-02, -2.00818647e-02, -4.46915664e-02, -1.14303390e-02,\n",
       "         -1.82465743e-02,  1.12996995e-02, -1.75796729e-02,  1.30079119e-02,\n",
       "         -3.51024754e-02,  2.64547318e-02, -3.42648625e-02, -2.05057617e-02,\n",
       "          2.01894194e-02,  2.06792802e-02, -4.64364234e-03,  1.83942113e-02,\n",
       "          1.89668965e-02,  4.28255871e-02, -5.89669831e-02,  2.89336331e-02,\n",
       "         -1.63583253e-02,  3.64976749e-02, -3.10038053e-03,  4.15439308e-02,\n",
       "         -5.37091214e-03, -2.18598396e-02, -2.96690483e-02, -5.07418811e-02,\n",
       "          3.87197360e-04, -1.83338975e-03, -3.14084627e-02,  7.33087072e-03,\n",
       "         -1.90635026e-02,  1.12924930e-02,  2.70331074e-02,  2.31327750e-02,\n",
       "         -5.31542813e-03, -1.30652646e-02, -5.14848670e-03,  1.68989394e-02,\n",
       "          1.62783023e-02, -3.82005656e-03,  9.58990213e-03, -1.84883606e-02,\n",
       "         -1.14988862e-02, -9.04906727e-03,  8.22313409e-03, -1.19508104e-02,\n",
       "         -7.02760834e-03, -1.60545930e-02, -4.24366631e-02, -3.99585329e-02,\n",
       "          3.55629027e-02, -4.72097704e-03, -1.97928734e-02, -3.79401073e-02,\n",
       "         -4.86299694e-02, -6.41743001e-03, -4.71761404e-03,  2.00765412e-02,\n",
       "         -8.99994373e-03, -2.34397035e-02, -5.63288294e-02, -2.80088522e-02,\n",
       "          1.39639049e-03,  4.34025796e-03,  1.61400773e-02, -2.10330933e-02,\n",
       "          3.77571746e-03,  3.57444375e-03,  2.13718060e-02,  2.93980408e-02,\n",
       "          2.66045537e-02,  2.45245788e-02,  3.66678199e-04,  1.09677147e-02,\n",
       "          1.28299082e-02, -2.07138062e-02, -1.79473478e-02,  1.46694854e-02,\n",
       "          7.86229875e-03,  1.68873705e-02, -5.84545266e-03, -3.06843016e-02,\n",
       "          2.41782656e-03, -2.44285766e-04,  5.23234578e-03, -3.24306600e-02,\n",
       "          1.23198507e-02, -2.59298086e-02,  2.33786255e-02,  3.03872228e-02,\n",
       "          8.09373055e-03,  1.74199659e-02, -9.68731288e-03, -1.22440309e-04,\n",
       "         -3.55007537e-02, -1.88117791e-02,  1.77186783e-02, -2.98891496e-02,\n",
       "         -2.57536415e-02,  2.63079461e-02, -4.44475338e-02, -4.35264818e-02,\n",
       "         -3.96331437e-02, -4.34836112e-02,  5.67310629e-03, -3.14369388e-02,\n",
       "         -2.24028025e-02,  2.60896962e-02,  3.03504672e-02, -5.32673337e-02,\n",
       "          3.20110954e-02,  4.68491428e-02,  3.33755277e-02, -1.64482240e-02,\n",
       "         -2.19379477e-02,  1.01858163e-02, -2.90203393e-02, -1.86665468e-02,\n",
       "          5.24524553e-03,  1.78965461e-02, -2.87898351e-02,  2.36028321e-02,\n",
       "          2.90747136e-02,  3.12788971e-03,  5.72841130e-02, -3.31405886e-02,\n",
       "          2.83864606e-02,  2.73275673e-02, -7.18183070e-03, -3.82718407e-02,\n",
       "          1.50528876e-02, -2.22334303e-02, -4.97630704e-03,  1.85109060e-02,\n",
       "          3.34724747e-02, -2.60259211e-02,  1.90009587e-02, -2.73042507e-02,\n",
       "          4.41831127e-02,  4.58050035e-02, -2.90657692e-02,  3.45324837e-02,\n",
       "          3.51604037e-02,  1.05087524e-02,  4.26395833e-02,  4.95174192e-02,\n",
       "         -1.81967001e-02,  3.94345038e-02,  1.10219996e-02, -1.42998453e-02,\n",
       "         -1.03580635e-02,  1.19732525e-02,  1.34907691e-02,  2.48193536e-02,\n",
       "          1.39178289e-02,  6.46647578e-03,  1.74781941e-02,  2.20035352e-02,\n",
       "          1.35657741e-02,  9.93527193e-03, -4.95439358e-02,  1.29241152e-02,\n",
       "         -4.47129346e-02,  2.26802509e-02,  7.20225507e-03, -5.23320138e-02,\n",
       "         -1.14810383e-02, -2.99407672e-02,  4.96658683e-02,  1.01982834e-04,\n",
       "          3.02688330e-02, -2.98451749e-03,  2.02853866e-02, -2.42580473e-03,\n",
       "         -4.75104749e-02,  4.63674823e-03,  2.34806854e-02, -4.12612520e-02,\n",
       "          4.00908664e-02, -1.20184934e-02,  2.00452190e-03,  4.65497114e-02,\n",
       "         -1.27375973e-02, -1.59324054e-02,  1.44257408e-03, -3.22742313e-02,\n",
       "          7.02887541e-03, -3.22988592e-02, -1.20347887e-02, -3.33297513e-02,\n",
       "          5.57198003e-02, -3.82872485e-02,  2.11117454e-02,  5.95724117e-03,\n",
       "          1.61314046e-03, -1.40214255e-02, -4.46223207e-02, -1.34771671e-02,\n",
       "         -6.73315371e-04, -8.81843362e-03, -1.22752134e-03, -9.76184674e-04,\n",
       "          1.35518014e-02,  1.23913288e-02, -8.89180973e-03,  1.51997972e-02,\n",
       "         -2.85984315e-02,  3.37646753e-02,  1.35607729e-02, -5.05184941e-02,\n",
       "          1.58319660e-02, -3.51657420e-02,  3.26806708e-04,  2.83798911e-02,\n",
       "         -4.82654981e-02, -1.16578015e-02,  1.76141374e-02, -7.74723990e-03,\n",
       "         -3.26474868e-02, -4.28720601e-02,  4.25761826e-02,  5.08382656e-02,\n",
       "         -2.50654425e-02, -8.55207723e-03,  4.42213118e-02, -2.45942716e-02,\n",
       "         -2.58996226e-02, -6.19723462e-02,  1.68633647e-02, -2.73146462e-02,\n",
       "         -1.25524793e-02, -3.93443033e-02,  1.49262073e-02, -5.57788124e-04],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 10,\n",
       "  'topic_words': array(['ubuntu', 'xorg', '커널', 'linux', '우분투', 'nvidia', 'kernel', 'sudo',\n",
       "         '부팅', 'stdout', 'bashrc', 'gedit', 'gpu', 'config', 'gnome', 'cpu',\n",
       "         'boot', 'unix', 'grub', 'ssd', 'terminal', 'sli', 'command',\n",
       "         'commands', 'glm', '명령', 'partition', 'lightdm', '터미널', 'htop',\n",
       "         'synaptic', 'github', 'subprocess', 'canonical', 'gtx', 'bash',\n",
       "         '윈도우', 'localhost', '명령어', 'grep', 'tensorflow', 'vertexcount',\n",
       "         'firefox', 'windows', 'bootstrap', 'cbind', 'openmx', 'disable',\n",
       "         'bootstrapping', 'multiprocessing'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.19085303e-02,  1.73485633e-02,  4.30273032e-03,  2.56453641e-02,\n",
       "         -4.60348604e-03, -6.05990030e-02,  1.53310876e-02,  1.06562618e-02,\n",
       "          3.59919965e-02, -3.78301665e-02,  9.13464464e-03, -2.55668759e-02,\n",
       "          4.17703837e-02,  1.27458367e-02, -2.93806195e-03, -1.05406987e-02,\n",
       "         -6.72567636e-04, -5.62858349e-03,  2.70807706e-02,  4.89739627e-02,\n",
       "          2.61172224e-02,  2.85551418e-02, -5.49959345e-03,  3.30215655e-02,\n",
       "         -5.45803271e-02, -2.80518029e-02,  2.42113676e-02, -2.76321974e-02,\n",
       "          2.89528333e-02, -5.14231287e-02,  5.31590544e-03,  1.98540669e-02,\n",
       "         -1.21243736e-02, -5.51753975e-02, -2.77712010e-02,  1.62669607e-02,\n",
       "          2.65133251e-02, -1.76933184e-02,  4.78374027e-02,  4.48474288e-02,\n",
       "         -2.19321437e-02,  4.91561033e-02,  2.34541316e-02, -9.41872690e-03,\n",
       "          3.42472047e-02, -2.30369251e-02,  4.63751219e-02, -2.01314371e-02,\n",
       "         -5.58832064e-02, -2.05019712e-02, -3.92610580e-03, -6.21225126e-03,\n",
       "          4.91870008e-02, -1.84284020e-02,  6.70273602e-03, -5.27385473e-02,\n",
       "         -4.46288800e-03,  4.95392457e-02, -3.70428013e-03,  2.13289056e-02,\n",
       "          2.25375015e-02,  5.12392707e-02,  2.80931331e-02, -5.17616943e-02,\n",
       "         -1.14499312e-02, -2.10323203e-02,  2.19943598e-02, -3.37827355e-02,\n",
       "          5.10216728e-02, -9.93940141e-03, -2.41902173e-02,  1.91064160e-02,\n",
       "          1.95105281e-02,  1.95219386e-02, -4.62944880e-02,  2.79447008e-02,\n",
       "         -3.93105373e-02, -3.71019021e-02, -3.04375272e-02, -5.87946326e-02,\n",
       "         -6.01850599e-02, -1.31766498e-02, -3.18937935e-02, -3.84509228e-02,\n",
       "          1.24237975e-02,  2.02894434e-02, -6.41999114e-03, -2.57794857e-02,\n",
       "          2.93617286e-02, -2.72541475e-02,  1.74287066e-04, -1.10576982e-02,\n",
       "         -8.52025754e-04,  9.77605674e-03,  5.30529954e-02, -1.49945365e-02,\n",
       "         -5.12993149e-02,  1.33262966e-02,  2.81931348e-02,  1.69169419e-02,\n",
       "          3.58057097e-02, -9.87729989e-04,  1.03564877e-02,  1.47489626e-02,\n",
       "          5.13783190e-03, -1.81097910e-02, -2.95102168e-02, -3.18154357e-02,\n",
       "          3.81212942e-02,  2.65104752e-02, -1.53017528e-02, -5.57710677e-02,\n",
       "         -1.55990431e-03,  5.01063792e-03,  3.39018889e-02, -1.12549067e-02,\n",
       "          9.56412591e-03,  2.46885978e-02, -2.25862134e-02,  1.07937688e-02,\n",
       "         -2.91196480e-02, -7.41983438e-03, -5.87901473e-03, -1.62203349e-02,\n",
       "         -1.10246735e-02,  3.60680372e-02, -2.17930544e-02,  4.91158329e-02,\n",
       "          2.01692376e-02, -1.34396441e-02, -3.31039950e-02,  4.35979245e-03,\n",
       "          5.18526509e-02,  1.57747585e-02,  2.68850699e-02,  3.00479196e-02,\n",
       "          4.35008556e-02,  5.11439384e-06,  4.68016788e-02,  1.43048326e-02,\n",
       "          3.49873230e-02, -1.65805686e-02,  2.28827391e-02,  4.21072394e-02,\n",
       "          3.68328160e-03, -1.91019829e-02,  2.73691639e-02,  4.29261848e-02,\n",
       "          2.61067729e-02, -5.19746216e-03,  2.62343585e-02, -6.04558410e-03,\n",
       "         -3.78046483e-02, -1.88385975e-02,  9.56373848e-03,  3.86571256e-03,\n",
       "          7.99602922e-03,  3.83083709e-02,  2.40056850e-02, -5.01122326e-02,\n",
       "          3.75954323e-02,  1.54818445e-02,  4.23792079e-02, -1.97444130e-02,\n",
       "         -1.00973835e-02, -2.37999447e-02, -3.16298753e-02, -3.04161385e-02,\n",
       "          2.25961786e-02,  1.91370472e-02,  8.95507447e-03, -2.55551804e-02,\n",
       "         -3.95886377e-02, -1.09297251e-02,  1.24861684e-03,  4.46817689e-02,\n",
       "         -5.13665304e-02, -5.06447293e-02, -2.60606483e-02,  3.97182330e-02,\n",
       "          2.12408714e-02,  1.78800691e-02, -1.16270520e-02, -2.87530310e-02,\n",
       "         -4.03259210e-02, -5.60070248e-03,  7.09805079e-03,  5.38344570e-02,\n",
       "          2.63815224e-02,  5.57691716e-02, -4.01323941e-03, -3.34777460e-02,\n",
       "          2.76857242e-02, -2.09066533e-02, -4.64973003e-02,  1.64656565e-02,\n",
       "         -4.28824797e-02,  4.74969484e-03, -2.71758065e-03, -4.89278464e-03,\n",
       "          1.57311850e-04, -2.67982259e-02, -5.33458497e-03, -1.41556915e-02,\n",
       "         -6.30252901e-03, -1.36310989e-02,  2.81012319e-02,  2.39441600e-02,\n",
       "         -2.61481665e-02,  2.99636815e-02,  2.36643963e-02,  3.48540395e-02,\n",
       "          3.90697457e-02,  2.07747053e-02,  1.06258253e-02,  1.43616814e-02,\n",
       "          1.56726968e-02, -2.29206448e-03, -3.38403732e-02,  2.45210454e-02,\n",
       "         -1.11790365e-02,  3.95071283e-02,  1.38458777e-02,  4.80128825e-03,\n",
       "         -5.84620088e-02, -5.23577444e-04, -3.86473387e-02,  1.64810698e-02,\n",
       "          7.99879804e-03, -3.85823995e-02, -2.59773508e-02,  5.20727001e-02,\n",
       "          2.09677648e-02,  4.94111329e-02,  6.20195968e-03,  5.10001741e-02,\n",
       "         -4.31541465e-02,  2.90150531e-02, -1.56034790e-02,  2.72644829e-04,\n",
       "          8.18949891e-04, -5.54004963e-03,  2.29842793e-02,  1.95075385e-02,\n",
       "          2.72265635e-02,  1.06466422e-02,  1.70819834e-02, -3.19735445e-02,\n",
       "          4.24641185e-02,  4.13086936e-02, -2.33744085e-02, -3.36789381e-04,\n",
       "          9.24791489e-03,  4.16017137e-03, -7.57916272e-03, -1.99852157e-02,\n",
       "         -7.97109958e-03, -5.05720712e-02, -1.26509778e-02, -9.29322746e-03,\n",
       "          2.16868985e-02,  3.14613432e-02, -4.67749778e-03,  3.82927209e-02,\n",
       "          2.90510543e-02, -4.67918776e-02,  1.31640863e-02,  1.50527293e-02,\n",
       "          6.79516979e-03,  1.16017452e-02,  6.60955440e-03, -1.20711690e-02,\n",
       "         -1.12044234e-02,  3.74131314e-02, -7.56297912e-03, -3.50234285e-02,\n",
       "          2.61045061e-02, -1.77463517e-02, -3.36723551e-02,  2.86268163e-02,\n",
       "          1.65854972e-02,  1.65381618e-02, -1.97092798e-02, -1.45885460e-02,\n",
       "         -3.18200677e-03,  4.71929722e-02, -5.60090914e-02,  1.00212991e-02,\n",
       "         -9.81849059e-03, -3.32123600e-02, -1.99562591e-03,  6.80599362e-03,\n",
       "         -1.39332507e-02,  2.45405105e-03, -5.97469024e-02,  2.80121639e-02,\n",
       "         -4.45968322e-02,  4.37287800e-03, -1.25833405e-02, -1.87772848e-02,\n",
       "          1.31633878e-02, -1.88325029e-02, -2.06990205e-02, -2.51164641e-02,\n",
       "          1.55811515e-02,  2.38269307e-02, -2.61756089e-02, -1.57694947e-02,\n",
       "          2.62939446e-02,  2.37385347e-03,  2.11584903e-02, -1.49765275e-02,\n",
       "         -2.12221611e-02,  9.05641541e-03, -5.44746779e-03,  3.27254571e-02,\n",
       "          3.60575020e-02, -2.32014637e-02, -7.22952187e-03, -2.33020615e-02,\n",
       "          7.24447519e-03,  3.25628966e-02,  1.07925674e-02,  2.46379115e-02,\n",
       "          3.24340127e-02,  7.49444170e-03, -4.53540422e-02, -2.77480390e-02,\n",
       "          1.73555582e-03, -1.12846233e-02, -2.80972086e-02, -3.53455804e-02,\n",
       "         -3.59906927e-02,  9.94638167e-03,  4.00281651e-03,  2.29554344e-02,\n",
       "          3.58564332e-02,  2.83940190e-05, -5.48182689e-02,  4.45465557e-03,\n",
       "         -1.25703970e-02,  4.45938855e-02, -7.63702719e-03, -3.04261278e-02,\n",
       "          3.80839221e-02,  7.06186658e-03,  5.13092848e-03,  3.08152102e-02,\n",
       "         -1.86076146e-02,  2.78567360e-03,  2.17735991e-02,  8.95633420e-04,\n",
       "          1.16885267e-02, -4.47392538e-02,  4.09044400e-02, -1.22216651e-02,\n",
       "         -1.86432172e-02,  2.52740774e-02, -1.51957031e-02, -3.67407389e-02,\n",
       "         -3.53252725e-03,  3.11856065e-02,  4.13289107e-02,  1.67662092e-02,\n",
       "          2.02277079e-02, -3.48207019e-02, -2.19648518e-02,  1.52050462e-02,\n",
       "         -3.34889553e-02,  2.00593304e-02,  1.20471930e-02,  3.86237167e-02,\n",
       "          5.12061780e-03, -1.57282166e-02, -6.53456943e-03, -2.29269993e-02,\n",
       "         -1.03114760e-02,  3.50735448e-02,  5.06216958e-02,  9.73156095e-03,\n",
       "         -1.43948607e-02, -4.20358405e-02,  2.46705627e-03, -5.17051294e-02,\n",
       "          6.44421019e-03,  3.79091948e-02, -2.59032529e-02, -5.70401587e-02,\n",
       "          4.96392058e-05,  9.12013277e-03, -1.43217035e-02, -3.27736586e-02,\n",
       "          3.01006511e-02,  1.25386035e-02, -3.17129008e-02,  4.44274629e-03,\n",
       "          7.45204138e-03,  3.22151631e-02,  2.29781885e-02,  3.40066329e-02,\n",
       "          3.26069444e-02, -3.67190223e-03,  4.50771637e-02,  1.78188309e-02,\n",
       "          1.21967774e-02,  7.69130327e-03,  1.93815597e-03, -3.55854034e-02,\n",
       "          3.30751054e-02,  4.05241586e-02, -2.96650492e-02,  2.60456223e-02,\n",
       "          2.66032410e-03,  1.71898715e-02, -2.93138623e-03,  1.17160790e-02,\n",
       "          1.20649347e-02,  4.98046875e-02, -1.91262048e-02, -1.11097163e-02,\n",
       "          4.04932126e-02,  7.52059137e-03,  4.40775342e-02,  2.74558738e-02,\n",
       "         -1.75668497e-03,  1.78187024e-02,  2.77291629e-02, -3.12782191e-02,\n",
       "          9.73209925e-03, -1.28758531e-02,  4.31810096e-02,  1.35137700e-02,\n",
       "          3.52034830e-02,  3.15663293e-02,  1.79729685e-02, -8.80233943e-03,\n",
       "          7.37718167e-03,  2.07200758e-02, -4.81560752e-02,  3.51593122e-02,\n",
       "         -4.58965674e-02, -6.51357323e-03, -1.00789722e-02, -3.69075947e-02,\n",
       "         -1.01181772e-02, -2.93906778e-03,  4.82933484e-02,  1.99810788e-02,\n",
       "          4.93823849e-02,  1.39230331e-02,  3.94056365e-02,  3.96265201e-02,\n",
       "         -4.98345867e-02, -2.31002793e-02, -1.49046546e-02, -2.75702756e-02,\n",
       "          3.99295539e-02, -5.08065103e-03,  1.67927667e-02,  4.27437499e-02,\n",
       "          5.01269754e-03,  2.72401096e-03,  3.34157273e-02,  4.16390747e-02,\n",
       "          2.61957776e-02, -4.66468148e-02,  1.19392211e-02,  4.53614034e-02,\n",
       "          4.84395400e-02, -3.37531641e-02,  4.35804129e-02, -4.33741212e-02,\n",
       "         -8.57414212e-03, -8.87056929e-04, -3.80783081e-02,  5.20487968e-03,\n",
       "         -6.28092559e-04, -3.29373442e-02,  6.01027720e-03, -1.69864483e-03,\n",
       "         -1.40879434e-02,  1.06407013e-02, -1.23278946e-02, -1.58236537e-03,\n",
       "         -8.12400423e-04,  5.74749836e-04,  2.45798118e-02, -5.57710603e-02,\n",
       "         -7.67763378e-03, -2.94508524e-02,  2.96192840e-02,  3.47152799e-02,\n",
       "         -7.87486043e-03, -1.96169149e-02,  8.23759846e-03, -1.60884820e-02,\n",
       "         -4.73122969e-02,  8.47574417e-03, -6.16924232e-03,  2.96994112e-02,\n",
       "          1.04803527e-02,  5.31160757e-02,  3.15544233e-02,  2.53567770e-02,\n",
       "         -1.53092528e-02, -5.61725236e-02, -1.96202770e-02,  1.18616270e-02,\n",
       "          9.30281635e-03, -1.39225891e-03, -2.07779626e-03,  2.01293230e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 11,\n",
       "  'topic_words': array(['github', 'bashrc', 'tensorflow', 'ubuntu', '우분투', 'matplotlib',\n",
       "         'gedit', '컴파일', '컴파일러', 'compile', 'gcc', 'linux', '커널',\n",
       "         'filename', 'directory', 'compiler', 'stdout', 'xorg', 'mxpath',\n",
       "         'sudo', 'kernel', 'localhost', 'apk', 'urllib', 'argv', 'cython',\n",
       "         'python', 'kwargs', 'foldername', 'grep', 'svms', 'subprocess',\n",
       "         'xpath', 'plugins', 'unix', 'filenametype', 'folder',\n",
       "         'dependencies', 'unicode', 'files', 'installed', 'svm',\n",
       "         'repository', 'install', 'regex', 'installing', '파일', 'gencode',\n",
       "         'rjava', 'installer'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.05348034e-02, -2.30201278e-02, -1.61387380e-02,  2.84943730e-02,\n",
       "         -8.26940686e-03, -5.52034862e-02,  3.28531576e-04,  2.55774707e-02,\n",
       "          4.85223494e-02,  2.86297500e-03,  2.54221056e-02, -9.21184663e-03,\n",
       "          4.78445478e-02,  5.66411158e-03, -1.56538580e-02, -8.17349472e-04,\n",
       "         -6.97870739e-04,  1.78398993e-02,  3.12733203e-02,  3.57448310e-02,\n",
       "          3.45242135e-02,  2.27975938e-02,  1.92768052e-02,  3.51747535e-02,\n",
       "         -5.03399856e-02, -3.71788032e-02,  1.14565017e-02,  1.62067276e-03,\n",
       "          2.80780885e-02, -5.19596785e-02, -3.69788110e-02,  2.19500344e-02,\n",
       "         -2.20756186e-03, -5.67760281e-02, -1.88109875e-02,  2.74258852e-03,\n",
       "         -8.39865126e-04, -1.80222783e-02,  2.95007676e-02, -4.76726443e-02,\n",
       "         -7.82612152e-03, -1.08662648e-02,  7.12358719e-03,  9.59592871e-03,\n",
       "          8.59845095e-05, -5.22418122e-04,  4.57025208e-02, -2.94619445e-02,\n",
       "         -2.82143075e-02, -6.71216100e-03, -4.57620323e-02, -2.53137499e-02,\n",
       "          1.81884132e-02, -1.37019865e-02,  2.07304489e-02, -4.76740561e-02,\n",
       "         -1.08054727e-02,  3.62962820e-02,  1.69782657e-02,  2.38781869e-02,\n",
       "          1.32844513e-02,  4.86397892e-02,  1.81291588e-02, -4.32848297e-02,\n",
       "         -2.52131429e-02, -1.47766732e-02, -9.51167848e-03, -5.52073866e-03,\n",
       "          4.08530571e-02,  1.28151402e-02, -2.23528538e-02,  1.07275009e-04,\n",
       "          3.19344215e-02, -2.71199029e-02, -3.97636332e-02, -2.59203697e-03,\n",
       "         -2.84551587e-02, -3.06961089e-02,  3.98101099e-03, -5.75743020e-02,\n",
       "         -5.93478568e-02,  3.02488133e-02, -2.44401302e-02, -3.13180014e-02,\n",
       "          3.00007612e-02, -6.48139569e-04, -9.66310035e-03, -2.31032651e-02,\n",
       "          3.65811028e-02,  1.31832780e-02,  1.97991569e-04, -1.56714283e-02,\n",
       "          5.68535039e-03, -1.52476272e-03,  4.17124815e-02,  6.58115139e-03,\n",
       "         -5.53855635e-02,  2.78210174e-02,  3.35282981e-02, -2.65895370e-02,\n",
       "          1.22708296e-02, -2.99349683e-03, -3.43527682e-02,  3.75607088e-02,\n",
       "          4.11555283e-02,  1.00498283e-02, -3.80889736e-02, -1.93098951e-02,\n",
       "          4.44051484e-03,  2.22999379e-02,  2.23524217e-02, -3.31262834e-02,\n",
       "          2.74051446e-03, -5.40021323e-02,  3.15758176e-02,  5.51766576e-03,\n",
       "         -1.62253361e-02, -2.42354278e-03, -1.35952858e-02,  1.63967982e-02,\n",
       "         -1.65498976e-04, -4.11523366e-03, -1.11921066e-02,  3.02665811e-02,\n",
       "         -1.15556708e-02,  3.02872788e-02, -9.92898922e-03,  4.59991256e-03,\n",
       "          2.46315245e-02, -2.28784960e-02, -2.63579190e-02,  1.08999582e-02,\n",
       "          5.76873533e-02,  2.55059432e-02, -1.25973383e-02,  1.47245117e-02,\n",
       "          4.50441353e-02,  2.54123844e-03,  3.86366434e-02,  1.62583925e-02,\n",
       "          1.08334806e-03,  1.61169854e-03,  6.24784315e-03,  2.60042790e-02,\n",
       "         -1.89975183e-02, -2.01507006e-02, -1.96465962e-02,  3.02694086e-02,\n",
       "          2.10556816e-02,  1.84406005e-02,  2.03490425e-02, -7.46677397e-03,\n",
       "         -1.73408911e-02, -2.79378369e-02, -1.81510653e-02,  1.47765465e-02,\n",
       "         -3.14954333e-02,  4.12065350e-02, -9.68221948e-03, -1.70995966e-02,\n",
       "          2.00307425e-02,  1.54418880e-02,  4.96298112e-02, -1.05625326e-02,\n",
       "          2.88987905e-02, -1.43185640e-02, -2.51632044e-03,  4.35457192e-03,\n",
       "          2.19103247e-02, -2.80730799e-03,  4.14365791e-02, -1.73726063e-02,\n",
       "         -9.15422011e-03,  6.08179485e-03, -1.12269735e-02,  3.66287641e-02,\n",
       "         -5.30918352e-02, -2.57360307e-03, -5.33627309e-02,  5.21109700e-02,\n",
       "         -1.45204337e-02,  3.47306319e-02, -2.32217330e-02,  8.58320389e-03,\n",
       "         -1.81522164e-02,  7.89606199e-03,  3.62748355e-02,  5.08407205e-02,\n",
       "         -6.89337216e-03,  5.08655719e-02,  1.38518624e-02, -3.72581407e-02,\n",
       "          3.90229896e-02,  1.78002790e-02, -2.41452809e-02,  3.59898917e-02,\n",
       "          2.38090986e-03, -2.33748164e-02,  8.34468938e-03, -2.01753080e-02,\n",
       "         -9.23744496e-03,  4.35966346e-03, -1.10713122e-02,  1.12369275e-02,\n",
       "         -1.32494336e-02, -7.18337065e-03,  2.14470308e-02, -1.97310094e-03,\n",
       "          9.52698756e-03,  2.72166077e-02, -2.98967287e-02,  2.92990189e-02,\n",
       "          4.02521789e-02, -2.84227710e-02,  8.35411903e-03, -1.21967606e-02,\n",
       "         -1.76685322e-02, -5.34912432e-03,  1.40460813e-02,  9.88901407e-03,\n",
       "         -7.33188912e-03,  1.22452993e-03,  1.93085300e-03,  2.37810356e-03,\n",
       "         -5.46256416e-02, -2.11763252e-02, -1.23474291e-02,  6.90607401e-03,\n",
       "          1.36690037e-02, -2.63792783e-04, -1.96362678e-02,  4.94807363e-02,\n",
       "          2.15703379e-02, -1.17481798e-02,  2.17362288e-02,  2.88495477e-02,\n",
       "         -9.09239228e-04,  9.01796017e-03,  2.42486354e-02, -1.86677743e-02,\n",
       "          1.04650585e-02, -2.45484780e-03,  1.02241114e-02,  2.13561486e-02,\n",
       "         -1.06139593e-02, -4.55182195e-02,  1.51060882e-03,  3.34479497e-03,\n",
       "          2.62705814e-02, -1.04257576e-02, -3.55122499e-02, -4.04056953e-03,\n",
       "         -2.26058662e-02,  3.11758816e-02,  2.71491464e-02, -4.07400392e-02,\n",
       "         -1.38859684e-03, -3.57530303e-02, -1.22875618e-02, -1.65735669e-02,\n",
       "          1.57208426e-03,  3.96931879e-02, -3.57311554e-02, -1.35906460e-02,\n",
       "          3.73201631e-02, -4.14904393e-02, -1.50711956e-02, -4.30828286e-03,\n",
       "          2.36728359e-02,  1.80578530e-02,  7.79387727e-03, -1.87244825e-02,\n",
       "         -1.07158376e-02,  3.15775014e-02,  2.68572811e-02, -8.88656359e-03,\n",
       "          7.26483902e-03, -1.98850241e-02, -2.72155609e-02,  1.71521474e-02,\n",
       "          3.23714465e-02,  3.40451263e-02,  8.15681007e-04, -2.40970999e-02,\n",
       "         -1.10123791e-02, -3.34065687e-03, -4.21928205e-02, -2.03161407e-03,\n",
       "          1.41402846e-02, -1.01584336e-03,  9.24819987e-03,  2.60682255e-02,\n",
       "         -7.71016115e-03,  4.91475575e-02, -5.82281798e-02,  3.07704881e-03,\n",
       "         -2.30581239e-02,  2.83354055e-02,  1.87012702e-02,  3.81315388e-02,\n",
       "          1.19636115e-03,  1.04297802e-03, -2.55459547e-02, -3.14873159e-02,\n",
       "          1.49851665e-02, -3.74303688e-03, -1.48079330e-02, -2.60685086e-02,\n",
       "         -1.26732485e-02,  3.00126728e-02,  2.89021973e-02,  8.67619738e-03,\n",
       "         -3.14772092e-02,  3.49284969e-02, -1.81764122e-02,  1.88469682e-02,\n",
       "          3.59860957e-02, -2.68265307e-02,  1.36395022e-02, -1.58178397e-02,\n",
       "         -2.42019519e-02,  4.98169474e-03, -1.52695598e-02,  1.66376773e-02,\n",
       "          5.55210607e-03,  3.26033235e-02, -3.11342869e-02, -2.14594454e-02,\n",
       "          2.58992258e-02, -1.91978049e-02, -2.43610516e-02, -2.02712771e-02,\n",
       "         -2.97443140e-02, -3.49940662e-03, -2.23794114e-03,  3.58289517e-02,\n",
       "          5.03642345e-03, -1.19146546e-02, -5.64743727e-02, -3.90661508e-02,\n",
       "         -1.72700752e-02,  3.78657952e-02, -9.78271011e-03, -6.47064624e-03,\n",
       "          6.02926768e-04, -1.91383939e-02, -7.39869243e-03, -5.78501215e-03,\n",
       "         -6.21889392e-03, -3.53472889e-03,  2.26165410e-02, -2.03748308e-02,\n",
       "         -5.53542981e-03, -4.91447411e-02,  1.95845272e-02,  1.05463983e-02,\n",
       "          4.46448149e-03,  1.38843758e-02,  8.06970615e-03, -4.82150912e-02,\n",
       "         -1.10038510e-02,  3.22650117e-03,  2.48990934e-02,  9.67262313e-05,\n",
       "          2.77773291e-02, -2.99045593e-02,  3.05078756e-02,  1.78197119e-02,\n",
       "         -4.21891697e-02,  3.38636301e-02, -8.31994507e-03,  2.56989454e-03,\n",
       "          1.17018691e-03,  1.24874823e-02,  1.37822255e-02, -3.32932435e-02,\n",
       "         -1.62802469e-02,  1.92703381e-02,  3.92683484e-02, -3.93752567e-02,\n",
       "         -3.68827246e-02, -5.56499511e-02, -1.50526175e-02, -5.61544932e-02,\n",
       "         -3.83536890e-03,  2.49459296e-02,  8.29376280e-03, -5.36243916e-02,\n",
       "         -8.49334523e-03,  2.48705894e-02, -3.64683829e-02, -2.14004447e-03,\n",
       "          1.27112831e-03, -3.01865581e-02, -1.12452889e-02, -1.20419888e-02,\n",
       "          2.13021245e-02,  1.67275146e-02,  1.28740259e-02,  6.39858609e-03,\n",
       "          2.52511054e-02, -2.64963936e-02,  5.06580323e-02, -4.61426862e-05,\n",
       "          1.72027741e-02, -9.53501090e-03,  2.26189774e-02, -2.75930855e-02,\n",
       "          1.85043942e-02,  6.51187438e-04,  1.75263931e-03,  1.45783052e-02,\n",
       "          6.62968308e-03, -1.45567537e-04,  1.09994421e-02, -1.78968050e-02,\n",
       "          3.80589180e-02,  2.72652339e-02, -1.06076815e-03, -2.56537516e-02,\n",
       "          4.47341464e-02,  1.01431450e-02,  4.29488868e-02,  1.40303662e-02,\n",
       "         -2.37622540e-02,  1.72594395e-02,  2.50523705e-02, -2.28226408e-02,\n",
       "          2.03491617e-02, -9.09258705e-03,  1.48327099e-02,  1.95862055e-02,\n",
       "          3.96604743e-03,  9.76932142e-03,  1.10713830e-02,  1.69149544e-02,\n",
       "         -8.12974852e-03,  5.09896921e-03, -4.42913324e-02, -5.63335093e-03,\n",
       "         -4.85914499e-02, -1.04080513e-03,  5.27356332e-03, -3.89248319e-02,\n",
       "         -2.62583569e-02, -8.75367131e-03,  5.03832288e-02, -2.61948514e-03,\n",
       "          2.91038081e-02,  2.67967395e-03,  1.36503605e-02,  3.76542695e-02,\n",
       "         -5.70599139e-02, -1.49549404e-02, -1.93070285e-02,  4.09476971e-03,\n",
       "          3.63742448e-02, -1.09071250e-03,  9.41854902e-03,  4.95518483e-02,\n",
       "          1.12621561e-02, -5.85230812e-03,  1.52836191e-02, -4.43987083e-03,\n",
       "          2.44896137e-03, -4.45332825e-02,  1.76208839e-02,  2.81372592e-02,\n",
       "          5.07051647e-02, -3.71656045e-02,  4.56643142e-02, -3.06973998e-02,\n",
       "          2.13138927e-02, -6.14322163e-03, -4.61861156e-02, -1.40311597e-02,\n",
       "         -2.95794755e-02,  7.30525004e-03,  5.79426298e-03,  1.15731908e-02,\n",
       "          1.45052448e-02, -5.32176113e-03, -1.17940539e-02,  1.46656558e-02,\n",
       "          8.28392431e-03,  1.46953650e-02, -1.33017423e-02, -5.33644371e-02,\n",
       "          3.73664894e-03, -3.03184185e-02, -2.40955758e-03,  1.64774898e-02,\n",
       "          1.24261191e-03,  1.38189783e-02,  1.58031117e-02, -1.98998023e-02,\n",
       "         -3.31944823e-02, -3.02566271e-02,  4.47112918e-02,  2.74681021e-02,\n",
       "         -1.18703442e-02,  4.20533754e-02,  3.26161794e-02, -1.21897133e-02,\n",
       "         -1.32382764e-02, -5.34890704e-02,  1.37653956e-02,  1.20369543e-03,\n",
       "          5.83003275e-03, -5.60897822e-03, -2.55093351e-02,  1.78820956e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 12,\n",
       "  'topic_words': array(['neurological', 'neuroscientific', 'neurogenesis', 'neuro',\n",
       "         'neurol', 'neuronal', 'neuroimaging', 'neurosciences',\n",
       "         'neurobiological', 'neurosci', 'neuroscience', 'neural',\n",
       "         'neurology', 'neurobiology', 'neuroimage', 'neuroethics',\n",
       "         'neurons', 'neuron', 'neuroscientists', 'neurobiol', '신경망',\n",
       "         'neuroscientist', 'cerebrospinal', 'neurosurg', '신경', 'brainstem',\n",
       "         'neurofeminism', '자극', 'synapses', 'alzheimers', 'neurocultures',\n",
       "         'brain', 'neurofeminist', 'cerebral', 'brains', 'midbrain',\n",
       "         'alzheimer', '뉴런', 'cognitive', 'stimuli', 'stimulus',\n",
       "         'developmental', 'psychotherapy', 'syndromes', 'somatosensory',\n",
       "         'psychological', 'serotonin', 'disorders', 'forebrain',\n",
       "         'cognitively'], dtype='<U15'),\n",
       "  'topic_vector': array([-4.67339344e-02,  8.60325899e-03, -3.29631045e-02, -2.50804308e-03,\n",
       "         -3.53240818e-02,  4.47454602e-02, -1.33041302e-02,  7.08691264e-03,\n",
       "         -5.49752312e-03,  3.20105590e-02, -1.22779906e-02, -3.77185978e-02,\n",
       "          7.92632345e-03, -1.15450630e-02, -4.81269248e-02,  2.77092047e-02,\n",
       "          1.96039546e-02, -2.09849421e-03,  1.69910844e-02,  4.63320985e-02,\n",
       "         -4.36362019e-03, -4.18583080e-02,  1.25192637e-02,  3.97267900e-02,\n",
       "         -5.45504577e-02, -8.78821407e-03, -2.37529427e-02,  1.24984644e-02,\n",
       "          4.46116924e-02, -1.91836711e-02, -4.00699377e-02,  4.56629209e-02,\n",
       "         -1.43123530e-02, -5.41795380e-02,  2.93103661e-02, -4.92474660e-02,\n",
       "         -2.67533176e-02,  5.21751354e-03,  1.26148630e-02, -4.71196026e-02,\n",
       "         -1.82957891e-02,  3.29023302e-02,  4.43082526e-02,  9.75952577e-03,\n",
       "         -2.58735437e-02, -2.23247819e-02,  3.94804440e-02,  4.74618003e-03,\n",
       "          3.76443118e-02, -1.54120950e-02,  3.35403197e-02, -1.93876326e-02,\n",
       "          1.66741721e-02,  1.15806228e-02,  1.63566675e-02, -4.00490947e-02,\n",
       "          3.57595421e-02,  6.41159387e-03,  1.73989348e-02,  2.85418816e-02,\n",
       "         -2.25507207e-02,  5.24243265e-02, -4.56996858e-02, -3.39244977e-02,\n",
       "         -1.20340167e-02,  2.61429753e-02,  9.90076922e-03, -3.88435386e-02,\n",
       "         -4.08031698e-03, -1.53377894e-02, -1.63711153e-03,  9.90485307e-03,\n",
       "          2.86740512e-02, -3.90739031e-02, -3.05585749e-02, -4.84417984e-03,\n",
       "          1.55820642e-02,  4.00906764e-02, -3.24136242e-02, -5.46455383e-02,\n",
       "         -5.49278110e-02, -3.70575562e-02,  3.08634154e-02,  3.37236784e-02,\n",
       "         -3.87997250e-04, -7.61640258e-03, -4.32690419e-02,  1.23580289e-03,\n",
       "         -1.03794318e-03,  9.55792784e-04, -4.57304977e-02, -4.86223586e-02,\n",
       "         -3.03714629e-02, -4.94666919e-02,  2.62383949e-02,  5.21719232e-02,\n",
       "          4.98583950e-02,  5.27633987e-02,  3.86942215e-02,  3.07885744e-02,\n",
       "          2.13496145e-02,  3.02789006e-02, -3.19708325e-02,  1.27761671e-02,\n",
       "         -1.03841092e-04,  5.40952832e-02, -5.14874160e-02, -2.47206483e-02,\n",
       "         -5.73095307e-03,  4.27937135e-02,  3.55946459e-02, -4.15009893e-02,\n",
       "         -4.36724722e-03,  1.72609966e-02,  1.91713814e-02, -1.35201085e-02,\n",
       "          3.86855379e-02,  4.46394309e-02, -2.51051448e-02, -2.01401184e-03,\n",
       "         -3.98899280e-02,  3.53094339e-02,  3.62419486e-02, -5.54997381e-03,\n",
       "         -2.41787359e-02,  3.64644453e-02,  5.04425503e-02,  1.57142822e-02,\n",
       "         -2.80603059e-02,  5.08840233e-02, -4.06265296e-02, -2.74220221e-02,\n",
       "          4.59430851e-02,  3.63192968e-02, -2.63180919e-02,  5.42045869e-02,\n",
       "         -3.49646509e-02,  2.02079955e-02,  5.28026782e-02,  1.62964910e-02,\n",
       "          4.60222960e-02, -3.20934318e-02,  3.33235823e-02, -1.42784910e-02,\n",
       "          5.14811650e-02,  3.62361930e-02,  4.41037671e-04,  4.54590209e-02,\n",
       "          5.24533773e-03,  3.03919055e-02,  5.02376407e-02,  4.88515720e-02,\n",
       "         -3.06026023e-02, -3.26696560e-02, -1.19364988e-02, -1.33941825e-02,\n",
       "          7.50320032e-03, -3.46700586e-02,  2.43321992e-02, -3.22255455e-02,\n",
       "          3.95910293e-02, -3.74150909e-02, -4.30562347e-02,  1.03371805e-02,\n",
       "          1.91300847e-02, -4.32818048e-02, -1.42071780e-03, -9.39085148e-03,\n",
       "         -5.12670651e-02,  2.82257851e-02, -3.14409249e-02, -2.83350665e-02,\n",
       "          1.65915471e-02, -1.56157017e-02, -3.80874351e-02, -6.23705843e-03,\n",
       "          4.10713181e-02,  3.73290256e-02, -2.23254096e-02,  2.61808448e-02,\n",
       "          3.98608902e-03, -4.92533855e-02, -1.31581025e-02, -3.44871804e-02,\n",
       "          3.14872041e-02, -1.22106140e-02,  1.84158534e-02,  4.75604273e-02,\n",
       "          2.78015006e-02, -9.13103763e-03, -3.41510004e-03, -1.76025387e-02,\n",
       "         -1.34183560e-02, -1.78559721e-02, -4.39672582e-02, -2.42347978e-02,\n",
       "         -1.02237193e-02,  3.74917611e-02,  5.12672551e-02, -7.27225279e-06,\n",
       "         -3.38280275e-02,  3.72571163e-02,  4.97716963e-02, -3.86975780e-02,\n",
       "          3.53597812e-02, -4.18047383e-02, -2.88187750e-02,  9.27304383e-03,\n",
       "          4.57590558e-02,  2.47754138e-02,  1.17765674e-02, -1.62391681e-02,\n",
       "          2.84830318e-03, -9.62262880e-03,  3.59339043e-02,  5.27263712e-03,\n",
       "          2.11226493e-02, -2.35359278e-02, -2.18654629e-02,  1.19572682e-02,\n",
       "         -2.74273753e-02,  3.56001481e-02,  5.25205247e-02,  3.35811935e-02,\n",
       "         -3.88259627e-02, -2.88208574e-02, -5.30401990e-02,  3.27959880e-02,\n",
       "         -9.51860938e-03, -2.30709724e-02,  1.22923395e-02,  4.95682992e-02,\n",
       "         -3.93258631e-02,  3.54343802e-02,  2.21690647e-02,  9.32770967e-03,\n",
       "          7.47552142e-03,  1.24045387e-02,  5.04105613e-02, -1.41361682e-02,\n",
       "         -2.55523771e-02,  1.61385890e-02, -1.00210551e-02, -5.93744405e-03,\n",
       "          3.81900780e-02,  2.10903725e-03,  3.97213474e-02,  8.36211164e-03,\n",
       "          1.40232779e-02,  2.53331941e-02,  7.02556595e-03, -4.91363630e-02,\n",
       "          3.19714770e-02,  1.35042134e-03,  1.35545470e-02, -5.61909890e-03,\n",
       "          3.41873877e-02,  2.49405149e-02, -3.92589495e-02,  4.07097153e-02,\n",
       "         -1.64408679e-03,  4.71216701e-02, -2.19021328e-02,  2.39674337e-02,\n",
       "          3.04714758e-02, -5.41737117e-02, -4.25442494e-02,  3.39227691e-02,\n",
       "          1.16473492e-02,  3.33243571e-02,  2.00402718e-02, -3.65882032e-02,\n",
       "         -4.21235189e-02, -1.62053984e-02, -9.47108306e-03,  1.22319134e-02,\n",
       "         -4.41969149e-02,  3.48242223e-02, -5.37317470e-02, -3.26319896e-02,\n",
       "         -1.88206658e-02, -7.56107876e-03,  2.22564787e-02,  2.13676933e-02,\n",
       "         -2.31511388e-02,  3.27646658e-02, -4.68600690e-02, -3.91574353e-02,\n",
       "          7.67468568e-03, -2.78481599e-02,  3.93661708e-02, -1.62962009e-03,\n",
       "          3.68565023e-02, -1.72195211e-02, -2.39569489e-02, -2.48836931e-02,\n",
       "          2.11471003e-02,  2.56400853e-02,  2.97724586e-02,  3.74576673e-02,\n",
       "         -3.88789736e-02, -1.44900782e-02,  9.86660458e-03, -3.57164219e-02,\n",
       "         -2.15072948e-02, -3.59541662e-02, -2.16028374e-02,  1.75850056e-02,\n",
       "          1.09484699e-02,  3.32783572e-02, -4.28126939e-02, -4.13594060e-02,\n",
       "          3.01607456e-02, -4.48198281e-02,  5.13836630e-02,  4.87111025e-02,\n",
       "          1.42812971e-02, -2.99565177e-02,  2.81885136e-02, -3.95509638e-02,\n",
       "          2.20341031e-02, -5.49763590e-02,  1.51499445e-02,  2.45414451e-02,\n",
       "         -3.89425457e-02, -1.58828441e-02,  2.57047489e-02, -1.42412512e-02,\n",
       "         -2.21793656e-03,  3.22836265e-02, -4.89911363e-02, -3.53538767e-02,\n",
       "         -4.72979695e-02, -1.21425530e-02,  1.34691000e-02, -2.06012349e-03,\n",
       "         -4.36665229e-02, -2.19437946e-02, -1.88740939e-02,  2.97333207e-02,\n",
       "         -3.21812928e-02, -1.23563632e-02, -1.73287150e-02, -3.77687737e-02,\n",
       "          3.23022120e-02,  4.17469032e-02,  4.67780791e-02, -4.06665877e-02,\n",
       "         -1.38303395e-02,  3.54689993e-02,  3.62254642e-02,  1.42684383e-02,\n",
       "         -2.72803307e-02,  3.17732207e-02,  2.72921044e-02,  2.12330148e-02,\n",
       "         -1.08676478e-02,  1.87432077e-02, -2.85925791e-02, -4.22651768e-02,\n",
       "          2.68984511e-02, -4.73667169e-03,  4.34868373e-02, -4.58398322e-03,\n",
       "         -2.28480902e-02,  1.01203620e-02, -3.45326327e-02, -1.37847262e-02,\n",
       "         -3.65852490e-02,  2.53078286e-02,  3.55619341e-02,  2.25421712e-02,\n",
       "          3.59576289e-03, -1.35137206e-02,  1.77030135e-02, -4.82486077e-02,\n",
       "         -1.04659637e-02,  3.27944830e-02,  2.47522015e-02, -1.98408924e-02,\n",
       "          3.98639292e-02, -3.15406956e-02,  3.27127613e-02,  3.13737281e-02,\n",
       "          1.70561876e-02,  4.98548895e-02,  3.42713334e-02, -5.35216890e-02,\n",
       "          5.42516671e-02,  2.30477354e-03,  1.26230689e-02, -1.79021731e-02,\n",
       "          2.35568415e-02,  4.97749373e-02, -4.31650914e-02, -2.96262209e-03,\n",
       "          5.25892265e-02, -1.45607358e-02, -1.28362803e-02,  4.23431806e-02,\n",
       "          4.40836363e-02,  4.28679883e-02,  2.58706789e-02,  1.78308075e-03,\n",
       "          5.11521054e-03,  5.50319580e-03,  6.61396130e-04, -1.81596279e-02,\n",
       "          2.33827177e-02,  2.98787970e-02,  4.44347225e-02, -1.53551763e-02,\n",
       "          1.13048013e-02,  5.26882820e-02, -8.29663128e-03,  5.42335995e-02,\n",
       "         -5.45144954e-04, -3.80874984e-02,  5.10543697e-02,  2.86678392e-02,\n",
       "         -4.28143963e-02, -5.95186511e-03,  4.89188023e-02,  2.02002898e-02,\n",
       "          5.15431017e-02,  1.59479361e-02, -3.78713049e-02, -2.82661449e-02,\n",
       "         -4.82909977e-02, -6.14813855e-03, -4.81260382e-02,  1.69973653e-02,\n",
       "         -1.38112446e-02, -9.53586306e-03,  3.53667736e-02,  2.08087023e-02,\n",
       "          6.28685812e-03, -4.24068458e-02, -5.47620952e-02,  3.31848487e-02,\n",
       "          2.25360505e-02,  7.40804570e-03,  1.51981646e-02, -5.11977375e-02,\n",
       "          2.66444199e-02, -3.72487903e-02, -2.38071010e-02,  4.73165289e-02,\n",
       "          6.19840482e-03,  1.77190024e-02, -5.25941607e-03, -1.53076341e-02,\n",
       "         -5.95600763e-03, -1.69800024e-03, -4.67073508e-02, -5.50667942e-03,\n",
       "          3.66361849e-02,  3.01264282e-02, -4.17739376e-02,  1.64292641e-02,\n",
       "         -1.06253354e-02, -4.12037410e-02, -8.62790551e-03, -2.97182947e-02,\n",
       "          3.15703191e-02, -5.02270423e-02, -2.14005839e-02,  5.85109368e-03,\n",
       "          5.40940054e-02, -3.03187352e-02, -1.90269528e-03,  3.60329635e-02,\n",
       "         -4.33892608e-02, -3.14632431e-02,  1.37000671e-02, -1.12050893e-02,\n",
       "         -9.82988533e-03, -3.32945143e-03, -2.88083497e-02, -1.25362119e-02,\n",
       "          3.63984704e-02,  5.49702793e-02, -2.49543767e-02,  1.38991680e-02,\n",
       "          4.30022813e-02, -3.83278839e-02, -1.83343906e-02, -5.38709201e-02,\n",
       "         -3.61087471e-02, -3.73914130e-02,  3.31930444e-02,  2.64177937e-02,\n",
       "          4.84414864e-03,  3.42988744e-02, -3.44762690e-02, -1.70791019e-02,\n",
       "         -4.02075015e-02,  1.02294656e-02,  2.08926923e-03,  3.81970927e-02,\n",
       "          3.53831537e-02, -3.93976159e-02,  5.46963923e-02, -7.98433833e-03,\n",
       "         -5.08900322e-02, -5.29090799e-02,  1.54329250e-02, -1.79123320e-02,\n",
       "         -3.57313566e-02, -5.22042550e-02,  1.61981490e-02,  1.73435602e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 13,\n",
       "  'topic_words': array(['neurosciences', 'undergraduate', 'neuroscience', '전공', 'neurosci',\n",
       "         'neural', 'sklearn', 'neurobiology', 'university', 'courses',\n",
       "         'graduate', 'neurol', 'academic', 'neuronal', 'neuro', 'phd', '과정',\n",
       "         '학습', 'neuron', 'computational', 'neuroscientist', 'faculty',\n",
       "         'neurons', 'neurobiological', 'classes', 'neuroscientific',\n",
       "         'neurological', 'computing', '대학교', 'computation', 'neurobiol',\n",
       "         'neurology', 'forebrain', 'sciences', 'neuroscientists', 'degree',\n",
       "         '학문', 'college', 'study', 'programming', 'learner', '대학원',\n",
       "         'institute', '공부', 'learning', 'computationally', '공학', 'studying',\n",
       "         'education', 'neuroethics'], dtype='<U15'),\n",
       "  'topic_vector': array([-0.02481128,  0.04661888,  0.00500437, -0.00493359,  0.01905727,\n",
       "         -0.01249116,  0.00761687,  0.01122016,  0.02226687,  0.01594968,\n",
       "          0.02473897, -0.00584028,  0.01360919,  0.00856285, -0.05108814,\n",
       "         -0.00069308,  0.02190154, -0.04208903,  0.01825308,  0.03756894,\n",
       "         -0.02807687, -0.0150711 ,  0.02694023,  0.04319386, -0.05683181,\n",
       "         -0.01397507, -0.00071725,  0.01824736, -0.03225009, -0.0229501 ,\n",
       "         -0.01256983,  0.02872084, -0.00192226, -0.04633546,  0.00194775,\n",
       "          0.00525545,  0.01737669,  0.01347989, -0.00409956,  0.00192553,\n",
       "         -0.01353276,  0.03824954,  0.03809851, -0.01471487, -0.04525986,\n",
       "          0.04558212,  0.01637039,  0.01105359, -0.02523814, -0.02046067,\n",
       "          0.00151502, -0.02738282, -0.00148947,  0.00713231,  0.00523156,\n",
       "         -0.04623779, -0.00347636, -0.00614196,  0.01683411,  0.01336459,\n",
       "         -0.02829107,  0.05696116, -0.01057331, -0.04182272, -0.01242307,\n",
       "          0.00578259,  0.04728025, -0.03687187, -0.02511789, -0.02584779,\n",
       "          0.00462743,  0.01482673,  0.00721973,  0.01679609,  0.02807388,\n",
       "          0.00451171,  0.02197909,  0.01782953,  0.02576811, -0.06101966,\n",
       "         -0.06577956, -0.04280606, -0.00416503,  0.02770294,  0.0108042 ,\n",
       "         -0.01248671, -0.02774653,  0.01630272,  0.02386827, -0.00179782,\n",
       "         -0.03565553, -0.0107687 , -0.02986571, -0.03842056,  0.04246171,\n",
       "          0.03343525, -0.01757958,  0.02256703, -0.00174957,  0.01483293,\n",
       "          0.01275471,  0.03095125, -0.00321275, -0.02705037,  0.00322377,\n",
       "          0.0058759 , -0.06465158, -0.01503246,  0.00401643,  0.02582831,\n",
       "          0.00688285, -0.02526246,  0.01684666,  0.01643198,  0.03905563,\n",
       "         -0.06510515, -0.00763199,  0.0204419 , -0.00197627,  0.02210828,\n",
       "         -0.02657904,  0.03730483,  0.01594825, -0.00810639,  0.02031171,\n",
       "         -0.01043266, -0.02652806, -0.02245889, -0.01264   , -0.00516969,\n",
       "         -0.02519545, -0.02043328,  0.03878957,  0.02995317,  0.0028465 ,\n",
       "          0.06180258,  0.00677119, -0.02874579,  0.05323142,  0.01323013,\n",
       "          0.03703226,  0.01295005,  0.03219664,  0.04121498,  0.03138217,\n",
       "         -0.01578035,  0.00883052,  0.02934773, -0.00137392,  0.02406185,\n",
       "          0.03699706,  0.03330032, -0.02968213, -0.02870466, -0.00108818,\n",
       "         -0.02160894, -0.01161936, -0.02380116, -0.02117787, -0.0319509 ,\n",
       "          0.04145549, -0.0129304 , -0.03363481,  0.0102794 , -0.02100201,\n",
       "          0.0055754 , -0.0198393 , -0.02905407, -0.04377094,  0.02101226,\n",
       "         -0.01008318, -0.01438082, -0.00656708,  0.03317779, -0.00758549,\n",
       "         -0.02822222, -0.03753009,  0.0082047 , -0.04924214,  0.03943466,\n",
       "         -0.00385973, -0.00853518,  0.02110424, -0.03162852, -0.02714349,\n",
       "          0.01908009,  0.00868405,  0.05632892, -0.0022264 , -0.01525588,\n",
       "          0.01742293, -0.02501153,  0.03812782,  0.00208661, -0.00749316,\n",
       "          0.03339355, -0.02200083,  0.00510581,  0.03619329,  0.02998493,\n",
       "         -0.01467746,  0.01556362, -0.04031413, -0.03777031, -0.00825748,\n",
       "         -0.00408518,  0.02937865, -0.01682153,  0.01205753,  0.01799693,\n",
       "         -0.00063965, -0.01825401, -0.03898325,  0.00759931,  0.03211039,\n",
       "         -0.00823234,  0.01826931, -0.01583832, -0.01613012, -0.01209048,\n",
       "         -0.01991923,  0.03765075,  0.02502398,  0.00701404, -0.03715253,\n",
       "         -0.03405147, -0.04605268,  0.03253949,  0.00369823,  0.01971422,\n",
       "         -0.01386872, -0.01285763,  0.00241035,  0.01913043,  0.02284435,\n",
       "          0.0334865 , -0.00494984,  0.0182575 ,  0.0633164 , -0.01447923,\n",
       "         -0.03892866,  0.00257662,  0.00611326, -0.01935265,  0.03004082,\n",
       "         -0.01780386,  0.03885447, -0.01616515,  0.0172487 , -0.04037986,\n",
       "         -0.00517829, -0.02201842,  0.04393044,  0.00074209,  0.02315633,\n",
       "         -0.02540941,  0.00091373, -0.01102866, -0.03322684,  0.01816211,\n",
       "         -0.01126966,  0.02717662,  0.00812429, -0.01451446,  0.01728129,\n",
       "         -0.02447245, -0.01508504,  0.03376221, -0.00613548,  0.0220458 ,\n",
       "         -0.00944378, -0.03176653,  0.0112328 , -0.00939408,  0.01710206,\n",
       "          0.02844441, -0.04316026,  0.02217448, -0.04830484, -0.0333229 ,\n",
       "         -0.00086709, -0.01445136,  0.02844307,  0.0084459 , -0.03259813,\n",
       "          0.01904353, -0.03107733, -0.01138928, -0.01069848,  0.00919475,\n",
       "          0.02635681,  0.02669078, -0.00695457,  0.0182694 , -0.03754371,\n",
       "          0.00482878, -0.03571339,  0.03047396,  0.00868731,  0.01831163,\n",
       "         -0.00143411, -0.00242343,  0.0013917 , -0.03791505, -0.00566266,\n",
       "         -0.01470697, -0.01713446,  0.02644172,  0.02139807,  0.0164575 ,\n",
       "          0.005248  ,  0.00055756, -0.03124614, -0.01483785,  0.03410268,\n",
       "          0.02096829, -0.04344425,  0.00779515,  0.04483818, -0.01606326,\n",
       "          0.02694453,  0.01104956, -0.009711  , -0.021517  , -0.01112009,\n",
       "          0.01406001,  0.02259566, -0.02192715,  0.00583644, -0.00569762,\n",
       "         -0.03202413, -0.03393689, -0.02052977, -0.04641983, -0.00817006,\n",
       "          0.00687161, -0.00666279, -0.00735583, -0.04480963, -0.0048509 ,\n",
       "         -0.03345365,  0.02586988, -0.0058216 , -0.03108154, -0.0051267 ,\n",
       "          0.03645667,  0.00407039,  0.01818827, -0.00513904,  0.00601077,\n",
       "         -0.02211112, -0.00755522, -0.00668836, -0.00017082, -0.0311603 ,\n",
       "          0.0063415 , -0.006991  ,  0.02660829, -0.02685866, -0.04322405,\n",
       "          0.03231236, -0.00532911,  0.04393667, -0.03819508, -0.01821748,\n",
       "          0.0355878 , -0.02646632,  0.0322421 , -0.03349337, -0.01042222,\n",
       "          0.02023922,  0.01262839, -0.02825791,  0.0311174 ,  0.01088798,\n",
       "         -0.0073988 , -0.01737489, -0.01550001, -0.02375687, -0.03094848,\n",
       "         -0.01131033,  0.0160457 ,  0.02154647,  0.01910389, -0.00642654,\n",
       "          0.03219622,  0.01490105, -0.04852458,  0.05484419,  0.02789045,\n",
       "          0.00033801, -0.01637446, -0.02479041,  0.03917308, -0.02543186,\n",
       "         -0.02754521,  0.03350713,  0.02528148, -0.04307472,  0.01180663,\n",
       "          0.04252071,  0.04873315,  0.05615987, -0.00416551, -0.02017425,\n",
       "         -0.0043982 , -0.02035233, -0.00033603,  0.01388833, -0.00256624,\n",
       "          0.01653037,  0.01307005,  0.0172902 , -0.02300982,  0.03112606,\n",
       "          0.05058001, -0.00165075,  0.00614387, -0.02359095, -0.00263124,\n",
       "          0.00557248, -0.00815789,  0.03084071,  0.01746836,  0.04363444,\n",
       "          0.03312301,  0.01638591, -0.03596223, -0.01790177, -0.03296508,\n",
       "         -0.00030959,  0.01858961,  0.00251831, -0.01148789,  0.03079094,\n",
       "          0.03429948,  0.02653216, -0.00302624, -0.05241504,  0.01940034,\n",
       "         -0.0339089 ,  0.03956166,  0.0082038 , -0.04534788, -0.00119311,\n",
       "         -0.00323774,  0.05515599,  0.00158705,  0.05984917,  0.00148293,\n",
       "         -0.02665064,  0.00952852,  0.01950582,  0.02054547, -0.03718222,\n",
       "         -0.01509892,  0.02940225, -0.00919923, -0.0156739 , -0.01399808,\n",
       "          0.00052747, -0.0233863 ,  0.0194907 , -0.0072408 , -0.01132078,\n",
       "         -0.05063866, -0.04443861,  0.03658485,  0.05479605, -0.05248621,\n",
       "          0.03173257,  0.06073261, -0.01568636, -0.01391021, -0.02307153,\n",
       "         -0.04037082,  0.00062201,  0.02550983, -0.00473854, -0.00746483,\n",
       "          0.02612587,  0.0533659 , -0.03465053,  0.00296415,  0.03920162,\n",
       "          0.02531679, -0.00483847, -0.05347988, -0.04239222,  0.00365025,\n",
       "          0.02879946, -0.02716425,  0.03503141, -0.00753221,  0.02040704,\n",
       "         -0.02497881,  0.00376029, -0.01075665,  0.00586264, -0.00375862,\n",
       "          0.02653196, -0.05262525,  0.03178865, -0.02332493, -0.05070003,\n",
       "         -0.03644537, -0.03864831,  0.01132957, -0.03170429, -0.05193925,\n",
       "          0.00109902,  0.02432655], dtype=float32)},\n",
       " {'topic_idx': 14,\n",
       "  'topic_words': array(['neural', 'neuronal', 'neurosciences', 'neurobiology',\n",
       "         'neurobiological', 'neurons', 'neuroscience', 'neuron', 'neurosci',\n",
       "         'neuro', 'neurological', 'neurol', 'neuroscientific',\n",
       "         'neuroscientists', 'neuroscientist', 'neuroethics', 'neurogenesis',\n",
       "         'neuroimaging', 'neurobiol', 'neurology', 'neuroimage',\n",
       "         'computational', 'neurosurg', 'brainstem', 'neurocultures',\n",
       "         'computationally', 'computation', '신경망', 'cerebrospinal', 'brains',\n",
       "         'brain', 'computing', 'clustering', 'forebrain', 'cerebral', '신경',\n",
       "         'cognitive', 'clusters', 'computed', 'synapses', 'probabilistic',\n",
       "         '알고리즘', 'networks', 'somatosensory', 'cerebellum', 'intelligence',\n",
       "         'correlates', 'algorithms', 'alzheimers', 'correlated'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-5.11753634e-02,  5.08948863e-02, -2.16335319e-02,  2.79333182e-02,\n",
       "         -3.12745720e-02,  5.12760598e-03, -5.29572600e-03, -7.93687534e-03,\n",
       "          3.36234905e-02,  4.01292108e-02, -2.00636033e-02,  5.10474155e-03,\n",
       "          3.09235193e-02,  2.04860996e-02, -4.67763245e-02,  3.25731598e-02,\n",
       "          1.04813324e-02, -4.30866666e-02,  2.68686116e-02,  4.06428203e-02,\n",
       "         -2.73892726e-03, -4.45305221e-02, -5.52054495e-03,  4.25443314e-02,\n",
       "         -5.58080450e-02, -1.70532744e-02,  4.39726040e-02,  4.20056656e-02,\n",
       "         -1.64585118e-03,  7.18592247e-03, -7.15587521e-03,  4.31924760e-02,\n",
       "          3.12090758e-02, -5.35924248e-02, -9.37473029e-03, -3.19782682e-02,\n",
       "         -3.31334993e-02, -2.99400501e-02,  3.43714794e-03, -2.32678689e-02,\n",
       "         -1.61934085e-02,  3.10111847e-02,  4.58506793e-02,  3.79783357e-03,\n",
       "         -4.97503132e-02,  4.36498784e-02,  4.46901731e-02,  3.33554521e-02,\n",
       "         -2.12120693e-02, -1.23263067e-02,  2.68782936e-02, -1.42595619e-02,\n",
       "         -6.75677881e-03,  6.46583131e-03,  1.42739099e-02, -3.35541964e-02,\n",
       "          1.12700751e-02,  2.06652377e-02,  2.24299617e-02,  3.29623185e-02,\n",
       "         -3.37405130e-02,  4.44943160e-02, -2.79422589e-02, -5.04490808e-02,\n",
       "         -2.51766052e-02,  2.24481290e-03,  3.67881730e-02, -4.33174260e-02,\n",
       "         -1.44676166e-02, -2.45337822e-02, -2.44983304e-02,  1.52351614e-02,\n",
       "          1.05415296e-03, -1.06771374e-02,  7.28169968e-03, -4.93249041e-04,\n",
       "          2.99124606e-02,  1.32067893e-02, -2.93667288e-03, -5.66875115e-02,\n",
       "         -6.13923445e-02, -4.58428636e-02,  2.67236531e-02,  2.92718001e-02,\n",
       "         -1.08987857e-02,  3.83284083e-03, -6.68641459e-03,  1.84382573e-02,\n",
       "          3.09500732e-02,  2.89477613e-02, -3.89410853e-02, -2.52733268e-02,\n",
       "         -2.76363231e-02, -5.43468297e-02,  9.70925298e-03,  4.98682037e-02,\n",
       "          4.11471799e-02,  4.70667593e-02,  2.49448530e-02,  2.66127801e-03,\n",
       "          3.48620974e-02,  2.60997079e-02,  2.58443709e-02, -2.95299944e-02,\n",
       "          2.34998055e-02, -7.88235664e-03, -5.53254187e-02,  6.22356730e-03,\n",
       "          2.38270797e-02,  4.97172177e-02,  1.65234692e-02, -5.36369011e-02,\n",
       "         -3.34283113e-02, -1.16363093e-02,  3.88056785e-02, -4.12038080e-02,\n",
       "          1.70213711e-02,  2.75395997e-02, -3.78815420e-02,  3.06966845e-02,\n",
       "         -1.20927040e-02,  5.24108894e-02,  4.46326919e-02, -2.85849310e-02,\n",
       "          3.24197039e-02,  9.97141236e-04,  2.63718870e-02,  4.25463961e-03,\n",
       "         -3.57350521e-02,  2.76296884e-02, -4.12315801e-02,  4.10371972e-03,\n",
       "          2.85434686e-02,  4.04310450e-02, -3.46499570e-02,  5.79732247e-02,\n",
       "         -3.66323330e-02, -1.86289418e-02,  4.88608070e-02,  2.02427041e-02,\n",
       "          5.55931330e-02,  2.31846925e-02,  5.19590899e-02,  2.33591441e-02,\n",
       "          4.09066752e-02, -2.17719190e-02, -4.45301458e-02,  3.51362564e-02,\n",
       "         -8.75701196e-03,  3.71610709e-02,  3.24154496e-02,  3.33331302e-02,\n",
       "         -1.11047905e-02, -5.25037572e-02,  2.38309987e-02, -1.66845880e-02,\n",
       "         -5.85056841e-03, -4.30397168e-02, -7.45683443e-03, -3.26697193e-02,\n",
       "          4.97013703e-02, -4.91687208e-02, -4.64776754e-02, -1.99498367e-02,\n",
       "         -1.00837741e-02,  2.55773077e-03,  1.85807720e-02,  4.70798044e-03,\n",
       "         -4.84037325e-02,  4.10927758e-02, -4.55038138e-02, -3.58673860e-03,\n",
       "          3.23133031e-03, -1.01914275e-02, -3.83538976e-02, -6.03172835e-03,\n",
       "          5.26938587e-03,  8.15568399e-03, -2.08460819e-02,  2.22887751e-02,\n",
       "          1.18258372e-02,  4.21981607e-03, -2.52777897e-02, -3.09169739e-02,\n",
       "         -4.01432887e-02,  1.49139669e-02,  1.75760668e-02,  4.77031432e-02,\n",
       "          1.33735491e-02,  3.48903611e-02, -1.15304422e-02, -9.85775609e-03,\n",
       "          3.92610282e-02, -1.51796443e-02, -1.48617728e-02,  2.04559639e-02,\n",
       "         -4.69794720e-02,  3.48118171e-02,  5.46750426e-02,  3.76838967e-02,\n",
       "         -2.21083369e-02,  2.88240351e-02, -1.77662931e-02, -3.54960375e-02,\n",
       "          1.15507012e-02, -3.12208328e-02, -3.86626944e-02, -1.30006103e-02,\n",
       "          3.51283029e-02,  1.11410571e-02,  2.70181298e-02,  4.49857302e-03,\n",
       "         -3.33888307e-02, -2.64845788e-03,  4.85876054e-02, -2.43223831e-02,\n",
       "          8.18843767e-03, -4.05530110e-02, -2.14883294e-02, -4.09501866e-02,\n",
       "          6.38631266e-03,  3.38019133e-02,  2.19220221e-02, -2.22860882e-03,\n",
       "         -4.80369516e-02, -1.81110371e-02, -5.80601282e-02,  2.37492044e-02,\n",
       "          1.27018373e-02,  1.53513821e-02, -2.85527352e-02,  4.92453054e-02,\n",
       "         -3.20167169e-02,  4.39243130e-02,  2.74455938e-02,  1.77964084e-02,\n",
       "          1.39086340e-02,  4.24417630e-02,  5.63101396e-02, -2.73567028e-02,\n",
       "         -4.00692271e-03,  3.41899917e-02, -1.84809417e-02, -1.08782318e-03,\n",
       "          2.30197217e-02, -3.09937634e-02,  4.51161936e-02,  3.09876679e-03,\n",
       "         -7.33004301e-04,  2.49811448e-02, -4.30655777e-02, -3.18900794e-02,\n",
       "          5.51915839e-02, -1.09419110e-03,  1.99597161e-02, -2.32663993e-02,\n",
       "          1.86388157e-02,  4.79982328e-03, -1.63997672e-02, -2.26235446e-02,\n",
       "         -2.09265910e-02,  1.48337018e-02, -2.26132688e-03,  1.98137052e-02,\n",
       "         -3.69394943e-03, -5.19364588e-02,  1.29186269e-03,  2.04093046e-02,\n",
       "          1.20117217e-02,  3.62603292e-02,  1.51007099e-03, -2.42588893e-02,\n",
       "         -2.21301652e-02, -3.98354046e-02,  7.25573441e-03,  2.87241377e-02,\n",
       "         -5.18021286e-02,  3.64965498e-02, -4.94677611e-02, -2.68115290e-02,\n",
       "         -2.95975301e-02, -2.52295826e-02,  7.25252539e-05,  4.27564010e-02,\n",
       "         -2.11323537e-02,  4.08075526e-02, -3.57243977e-02, -4.17298637e-02,\n",
       "          1.12861898e-02,  1.19076800e-02,  4.30228300e-02,  1.31367221e-02,\n",
       "          2.11881846e-02, -1.96374971e-02, -4.60027196e-02, -2.45225225e-02,\n",
       "         -3.14744236e-03,  2.76186764e-02,  3.60203013e-02,  5.53053245e-02,\n",
       "         -3.82884853e-02,  1.74590126e-02,  1.74196698e-02, -4.85973991e-02,\n",
       "         -4.43237945e-02, -3.92864645e-02, -2.16006003e-02,  2.74447147e-02,\n",
       "         -1.55160185e-02,  4.97130975e-02, -3.17383334e-02, -2.01011430e-02,\n",
       "         -2.61780974e-02, -4.03510109e-02,  3.10682505e-02,  2.36433279e-02,\n",
       "         -3.73351984e-02, -1.06965024e-02,  3.57842371e-02, -3.15578766e-02,\n",
       "          3.47786620e-02, -4.40982021e-02, -2.00370159e-02,  2.30600522e-03,\n",
       "         -5.27736768e-02, -3.70409302e-02,  1.67987701e-02, -8.41613766e-03,\n",
       "          1.44252954e-02,  2.99787782e-02, -1.88279711e-02, -3.68532240e-02,\n",
       "         -1.53608825e-02, -1.22247040e-02, -2.64115594e-02, -1.08885914e-02,\n",
       "         -4.47036698e-02, -4.66869995e-02, -5.43597154e-02,  2.50654425e-02,\n",
       "         -5.46268038e-02,  6.06835121e-03,  1.16829481e-02, -4.12409604e-02,\n",
       "          2.25542169e-02,  4.18333709e-02,  3.24265435e-02,  1.92184672e-02,\n",
       "         -2.61174291e-02,  1.38333049e-02,  2.27280390e-02, -4.97323554e-03,\n",
       "          3.47357313e-03,  4.75629084e-02, -3.68426815e-02,  2.00330205e-02,\n",
       "          2.95913424e-02,  2.53241397e-02, -2.60938145e-02, -3.18030305e-02,\n",
       "          3.81112285e-02, -1.79888420e-02,  4.31623980e-02, -4.14803103e-02,\n",
       "         -3.84384766e-02,  2.88066901e-02, -1.62982512e-02,  3.63023914e-02,\n",
       "         -2.02088058e-02, -1.24831889e-02,  4.20209430e-02,  4.35846075e-02,\n",
       "         -3.80938277e-02,  3.60673107e-02,  2.32773609e-02, -4.33331206e-02,\n",
       "         -3.60644609e-02,  8.73132143e-03, -4.24593650e-02, -4.40088995e-02,\n",
       "          2.33636145e-02,  6.31385809e-03,  3.98425348e-02,  1.19700255e-02,\n",
       "         -2.81651076e-02,  5.29626086e-02,  3.63707840e-02, -4.12208810e-02,\n",
       "          5.86505905e-02, -1.40192509e-02,  2.58977599e-02, -3.48500088e-02,\n",
       "         -6.51862193e-03,  3.45492288e-02, -3.20467278e-02,  1.36056598e-02,\n",
       "          3.96674983e-02, -2.50564329e-02, -5.43647595e-02,  1.97452325e-02,\n",
       "          4.01855931e-02,  3.88742015e-02,  4.52599116e-02,  2.65783332e-02,\n",
       "         -4.36093248e-02,  1.59067067e-03,  2.75977198e-02, -2.43253708e-02,\n",
       "          2.73104962e-02,  7.87844229e-03,  2.04662811e-02, -4.45804559e-03,\n",
       "         -2.45200470e-04,  3.31126936e-02,  1.81504674e-02,  5.73961921e-02,\n",
       "          4.76467144e-03, -3.04023530e-02,  1.27612334e-02,  4.25988995e-02,\n",
       "         -7.27690989e-03, -3.90080102e-02,  4.20371778e-02,  4.73732240e-02,\n",
       "          5.13869449e-02,  2.31578592e-02,  8.11844599e-03, -5.60842976e-02,\n",
       "         -4.38831411e-02, -2.10015289e-03, -2.83651203e-02, -2.52333051e-03,\n",
       "         -1.12039717e-02, -2.48094779e-02,  2.76561137e-02,  3.50411199e-02,\n",
       "          2.13124249e-02, -1.68740824e-02, -5.60631976e-02,  4.65166494e-02,\n",
       "         -9.00393166e-03,  1.56833101e-02,  1.10011129e-02, -4.97530326e-02,\n",
       "          2.00349260e-02, -2.62997840e-02, -1.60531551e-02,  3.71470675e-02,\n",
       "          4.11281288e-02,  1.30254747e-02, -4.90952209e-02, -3.94622162e-02,\n",
       "         -2.02918965e-02,  1.21170003e-03, -2.66591795e-02, -1.94686893e-02,\n",
       "          3.84800620e-02,  1.51103735e-02, -9.44807380e-03,  3.20737734e-02,\n",
       "         -1.65279303e-02, -5.21950796e-02, -2.76785549e-02, -4.35880199e-02,\n",
       "          2.58612875e-02, -5.53019531e-02, -3.91098447e-02, -7.32964417e-03,\n",
       "          5.24117276e-02, -4.97314930e-02,  7.42844027e-03,  5.83981648e-02,\n",
       "         -2.22635958e-02, -9.46422294e-03,  1.71165336e-02, -2.44997758e-02,\n",
       "         -6.50191819e-03,  2.56455876e-02, -2.06216169e-03, -8.56906932e-04,\n",
       "          4.45198379e-02,  5.65246567e-02, -4.46190685e-02,  1.07228607e-02,\n",
       "          4.10295688e-02, -3.75250541e-02,  1.20032895e-02, -4.73460034e-02,\n",
       "         -5.60727529e-02, -2.03850921e-02,  4.00468409e-02,  3.60667296e-02,\n",
       "          2.80156708e-03, -1.57370046e-03, -9.69920307e-03, -3.25597562e-02,\n",
       "          2.95133516e-03, -1.13567980e-02,  2.95554884e-02,  2.49879491e-02,\n",
       "          3.62067446e-02, -5.79572320e-02,  5.64642362e-02, -3.27072069e-02,\n",
       "         -4.05623689e-02, -5.32511249e-02, -2.25570723e-02, -1.41398581e-02,\n",
       "         -4.42160591e-02, -5.33730201e-02,  2.19168216e-02, -2.72477046e-03],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 15,\n",
       "  'topic_words': array(['probabilistic', 'statistical', 'statistically', 'probability',\n",
       "         'statistics', 'variance', 'covariance', 'coefficient', 'statistic',\n",
       "         'correlation', 'coefficients', 'correlations', 'variances',\n",
       "         'calculation', 'calculations', 'approximation', 'computationally',\n",
       "         'computation', '확률', '통계', '분포', 'proportional', '통계청', '추정',\n",
       "         'computed', 'scatterplot', 'mathbf', 'estimator', 'parametric',\n",
       "         'computational', 'mathematical', 'probabilities', 'nonparametric',\n",
       "         'correlated', 'relation', 'convergence', 'calculated',\n",
       "         'predictive', 'multivariate', 'matplotlib', 'approximate',\n",
       "         'mathematics', 'estimated', 'numerical', 'asymptotic',\n",
       "         'correlates', 'exponential', 'correlate', 'calculate', 'predictor'],\n",
       "        dtype='<U15'),\n",
       "  'topic_vector': array([-0.05328254, -0.0170897 , -0.00621546, -0.01512329, -0.01770566,\n",
       "          0.01567571,  0.01290909,  0.00444419,  0.03723799,  0.00325724,\n",
       "          0.00672434,  0.02502692,  0.04401648,  0.00905718, -0.06003013,\n",
       "         -0.00959744, -0.00336178, -0.01582699,  0.03602002,  0.04225374,\n",
       "         -0.00428237, -0.01573798, -0.02780872,  0.03862058, -0.04812925,\n",
       "         -0.01083608,  0.01439817, -0.01206092, -0.00769759, -0.03054872,\n",
       "         -0.05399604,  0.01092005,  0.02295696, -0.04823382,  0.01516288,\n",
       "         -0.00909253, -0.04964169, -0.01591482,  0.01047813,  0.00577918,\n",
       "          0.0110757 , -0.02581886,  0.02348029, -0.04126112, -0.00955312,\n",
       "         -0.03432345,  0.04431367, -0.00892024, -0.04408193,  0.00705694,\n",
       "         -0.00694929, -0.01542181,  0.01025053,  0.00785254,  0.0388054 ,\n",
       "         -0.04747497,  0.00864993,  0.01621882,  0.00455951,  0.01470254,\n",
       "          0.0159869 ,  0.04166299,  0.03186219, -0.01570143,  0.00541137,\n",
       "          0.00068507, -0.00216431,  0.02040287,  0.02751094,  0.01804114,\n",
       "         -0.00461986,  0.00091292,  0.00335922, -0.02565372, -0.04203143,\n",
       "         -0.03286274,  0.03281782,  0.02283703, -0.00185531, -0.05793305,\n",
       "         -0.05793564, -0.02428658, -0.01162768,  0.02718594, -0.00399691,\n",
       "         -0.00809622, -0.04013877, -0.02511468, -0.03948419, -0.04024663,\n",
       "         -0.02400311, -0.01334509,  0.00569681, -0.0384336 ,  0.04282068,\n",
       "          0.04415665,  0.03279359,  0.00849491,  0.03843736, -0.00475012,\n",
       "          0.05086331,  0.01342082,  0.03827318, -0.01554702,  0.01823187,\n",
       "         -0.05449557, -0.0110526 , -0.02393145,  0.02316839,  0.03946258,\n",
       "          0.04537977, -0.02143734, -0.04392459, -0.00375333,  0.0258414 ,\n",
       "          0.01858261,  0.00528394, -0.00607989, -0.03827054,  0.01473441,\n",
       "         -0.02794002,  0.03651937,  0.01555986,  0.02112283,  0.02466923,\n",
       "          0.00725849, -0.04706052,  0.02610315, -0.02137786,  0.03347317,\n",
       "         -0.05185367,  0.02341878,  0.04674757,  0.00814496, -0.00949332,\n",
       "          0.03027408,  0.01669153,  0.00917705,  0.05213224, -0.00344945,\n",
       "          0.01163013, -0.01647184,  0.03332003, -0.03174312,  0.04487386,\n",
       "         -0.01412014, -0.03212409, -0.00211458,  0.02851697,  0.02988196,\n",
       "          0.0269857 ,  0.00525414, -0.00405964, -0.03243096,  0.02893496,\n",
       "         -0.01855002, -0.00802002,  0.00426375,  0.00880473,  0.01568   ,\n",
       "          0.02134181, -0.01338132,  0.00631666, -0.03444525, -0.0222413 ,\n",
       "         -0.01201238, -0.00830056, -0.00642987, -0.0003949 ,  0.04493433,\n",
       "         -0.00830053,  0.0040015 ,  0.02117045,  0.01978588, -0.01408732,\n",
       "          0.03151459,  0.02979846,  0.02140416, -0.02381844,  0.01079472,\n",
       "          0.01983866, -0.01755663, -0.01234116,  0.02598287, -0.04389506,\n",
       "         -0.02558365,  0.04607117,  0.04771162,  0.00509484, -0.05077297,\n",
       "         -0.01176958, -0.00613858,  0.03752537, -0.02340355,  0.00551514,\n",
       "          0.02012077, -0.05401471, -0.02809796,  0.03653476, -0.00431497,\n",
       "          0.00146164,  0.01937101, -0.02162728,  0.00559304, -0.01526341,\n",
       "         -0.02951853, -0.02559872,  0.0130573 , -0.01208131,  0.01499548,\n",
       "         -0.01816858,  0.00330312, -0.06003588,  0.00231487,  0.02103176,\n",
       "         -0.02707853, -0.00414397, -0.01378414,  0.02421549, -0.00065593,\n",
       "         -0.00070911,  0.01610697,  0.03578952,  0.00520892, -0.05279987,\n",
       "          0.00721394, -0.04100453, -0.00521462,  0.01396245,  0.01004131,\n",
       "         -0.02187478,  0.05134011,  0.00526149, -0.034619  , -0.00569424,\n",
       "         -0.0052656 ,  0.00122424,  0.00923961, -0.01301656,  0.00585318,\n",
       "         -0.00417818, -0.03527229, -0.0105277 ,  0.01842393,  0.0372014 ,\n",
       "         -0.02388776,  0.00804297,  0.00484677,  0.01281594,  0.02999526,\n",
       "         -0.03357686, -0.02956859,  0.00710326,  0.00471948, -0.02923357,\n",
       "         -0.00673339, -0.00798899, -0.01557165, -0.02622587,  0.01314863,\n",
       "          0.02495513,  0.01687853, -0.01194374, -0.0044291 ,  0.04792099,\n",
       "         -0.04839513, -0.01343733, -0.00883635, -0.02374629,  0.01684367,\n",
       "         -0.00136547, -0.03920973, -0.04353911, -0.04497451, -0.0168709 ,\n",
       "          0.0226111 , -0.04158933,  0.01992787, -0.05041358, -0.01684132,\n",
       "         -0.0469857 ,  0.0126976 ,  0.03375936,  0.0133276 , -0.01681519,\n",
       "          0.02647724, -0.03969798, -0.03197965, -0.01096861,  0.01947792,\n",
       "          0.01901353,  0.03695693,  0.01079657,  0.0331487 , -0.02151637,\n",
       "          0.01534834, -0.03865311,  0.00444754,  0.04995452,  0.02974736,\n",
       "         -0.04319997,  0.02695047, -0.04553561, -0.04703386, -0.0600494 ,\n",
       "          0.00730617,  0.03305427, -0.01525784, -0.03214868, -0.00080265,\n",
       "         -0.01014991, -0.01930625, -0.04468392, -0.03790563,  0.02346919,\n",
       "          0.03235201,  0.02134216, -0.03255044,  0.00483743, -0.00804112,\n",
       "          0.00107308,  0.03492178, -0.02293752,  0.03338187, -0.02244557,\n",
       "          0.00670212, -0.03161984, -0.00943657,  0.00074842, -0.01522437,\n",
       "         -0.04867674, -0.02433406,  0.0260338 , -0.01784344, -0.00159208,\n",
       "         -0.00143245, -0.01017983, -0.00500142, -0.04551736, -0.04359784,\n",
       "         -0.04310773, -0.01394556,  0.01993406,  0.00978498, -0.01594573,\n",
       "          0.03949672,  0.03589326,  0.00673365, -0.01994846,  0.01000116,\n",
       "          0.03022702,  0.02362226, -0.02248087,  0.0131918 ,  0.01693591,\n",
       "          0.02749281, -0.01119866,  0.02422701, -0.03685445, -0.00530061,\n",
       "          0.02149378, -0.04716819,  0.02616457, -0.00591666, -0.03354599,\n",
       "          0.02767235,  0.00747153,  0.02137242, -0.02023661,  0.03346577,\n",
       "          0.04238712,  0.02579635, -0.0058697 ,  0.04573347,  0.0077744 ,\n",
       "         -0.01658247,  0.0058853 ,  0.00051476, -0.05652023, -0.04409183,\n",
       "          0.02369143, -0.03692579,  0.00931186,  0.00585117, -0.01244143,\n",
       "          0.05307848,  0.03708265, -0.0438126 ,  0.04466918,  0.03362339,\n",
       "         -0.02111405,  0.02727118, -0.02209551,  0.02911139, -0.01954201,\n",
       "          0.01873935,  0.02209405,  0.00157559, -0.03805279, -0.01063626,\n",
       "          0.01575493,  0.03390952,  0.04706785,  0.0015912 , -0.03425444,\n",
       "          0.02589065,  0.00568259, -0.03428813,  0.00558141,  0.00503994,\n",
       "          0.00231488,  0.00349645,  0.02067254, -0.01363514,  0.01787258,\n",
       "          0.02257953,  0.00806326,  0.02973476,  0.03075348,  0.0341429 ,\n",
       "         -0.02587208, -0.05702866, -0.03000281,  0.04560738,  0.05239697,\n",
       "          0.02088156, -0.01344468, -0.00292557,  0.02671184, -0.03790963,\n",
       "         -0.00647539,  0.0182698 , -0.00385014, -0.00713387,  0.0419851 ,\n",
       "          0.0218762 ,  0.00161223,  0.00983882, -0.05626079,  0.02455199,\n",
       "         -0.02759879,  0.00875932, -0.03816006, -0.05690249,  0.00857705,\n",
       "         -0.03966033,  0.04279786,  0.0014697 , -0.00029295,  0.0184205 ,\n",
       "         -0.02005069,  0.02282678, -0.01103301, -0.01763407, -0.04234787,\n",
       "         -0.02937709,  0.00882125,  0.0208251 ,  0.03351009,  0.04932631,\n",
       "         -0.00275712, -0.01206629,  0.03564911, -0.0544221 ,  0.04257547,\n",
       "         -0.04621439, -0.0087521 , -0.0325854 ,  0.056796  , -0.01016183,\n",
       "          0.03448377, -0.00650063, -0.03300019,  0.03040228, -0.04726849,\n",
       "         -0.02953287,  0.02549696, -0.02429135, -0.00318316, -0.02642637,\n",
       "          0.03293192,  0.05528102, -0.01865039, -0.0079111 ,  0.04110671,\n",
       "          0.02958997,  0.00091456, -0.05088255,  0.01095078,  0.01270929,\n",
       "          0.01372333, -0.00084348,  0.01125789,  0.0076462 ,  0.00568398,\n",
       "         -0.02909714, -0.00723332, -0.00681425,  0.0261825 , -0.00316301,\n",
       "          0.02324305, -0.04053091,  0.05856003,  0.00352917, -0.03385929,\n",
       "         -0.04532336,  0.02409075, -0.03153453,  0.00514711, -0.02696176,\n",
       "         -0.01958536,  0.03370144], dtype=float32)},\n",
       " {'topic_idx': 16,\n",
       "  'topic_words': array(['correlation', 'genotype', 'correlations', 'correlated',\n",
       "         'correlates', 'genome', 'correlate', 'genotypes', 'genetically',\n",
       "         'probabilistic', 'populations', 'genetic', 'genes',\n",
       "         'statistically', 'gene', 'probability', 'variability',\n",
       "         'statistical', '유전자', 'clustering', 'datasets', 'demographic',\n",
       "         'traits', 'neurogenesis', 'prevalence', 'genetics',\n",
       "         'distinctiveness', 'neurobiological', 'dataset', 'differentiated',\n",
       "         'covariance', 'population', 'neuroethics', 'multivariate',\n",
       "         'classification', 'cohort', 'variance', 'distributed', '확률',\n",
       "         'zygosity', 'probabilities', 'regression', 'neuronal', 'phenotype',\n",
       "         'individuals', 'variances', 'qualitative', 'coefficient', '비율',\n",
       "         'statistics'], dtype='<U15'),\n",
       "  'topic_vector': array([-5.22513725e-02, -6.21799100e-03, -4.52225432e-02,  4.63461690e-03,\n",
       "         -3.53739560e-02,  3.10192332e-02,  1.34745622e-02, -4.59870370e-03,\n",
       "         -2.12316937e-03,  3.48714218e-02,  3.33769247e-03, -3.82162891e-02,\n",
       "          3.93152162e-02, -6.61031576e-03, -4.68074493e-02,  2.64573917e-02,\n",
       "         -1.94946006e-02, -5.67134656e-03,  4.50472571e-02,  1.67355090e-02,\n",
       "         -5.83483954e-04, -4.97879945e-02, -4.03216295e-02,  4.19732332e-02,\n",
       "         -5.35535403e-02, -1.41997738e-02,  2.51783673e-02,  3.38743888e-02,\n",
       "          7.76660442e-03, -7.78322760e-03, -2.83189341e-02, -9.85758472e-03,\n",
       "          1.36057204e-02, -5.15271910e-02,  5.43903792e-04, -4.66853566e-02,\n",
       "         -2.03674715e-02,  1.70436073e-02,  2.44834833e-03, -1.30494544e-02,\n",
       "         -8.04594383e-05,  2.60139853e-02,  4.15771790e-02, -2.43502967e-02,\n",
       "         -2.59676743e-02, -4.27136756e-02,  5.25887236e-02, -2.58939783e-03,\n",
       "         -2.21350128e-04, -6.54790131e-03,  3.74470931e-03, -1.89366490e-02,\n",
       "          3.84983011e-02,  2.40251608e-02,  2.61828229e-02, -3.57448012e-02,\n",
       "          3.85655612e-02,  2.46896502e-02, -2.17449572e-02,  4.72336300e-02,\n",
       "         -9.78002558e-04,  5.25120348e-02, -2.88851932e-02, -3.78775150e-02,\n",
       "         -2.12689582e-02, -2.03445982e-02,  2.79906169e-02,  1.47499340e-02,\n",
       "         -1.84681751e-02, -4.23526205e-03, -4.22841078e-03, -3.97229334e-03,\n",
       "         -2.68245358e-02, -5.28660901e-02, -4.39514294e-02, -3.84928770e-02,\n",
       "          4.19335105e-02, -3.17799929e-03, -2.78185606e-02, -5.11959344e-02,\n",
       "         -5.37979081e-02, -3.07193734e-02,  3.59751061e-02,  3.98898125e-02,\n",
       "         -4.88796569e-02, -1.01239979e-02, -4.82566208e-02, -1.36577385e-02,\n",
       "         -1.42195625e-02, -4.07126769e-02, -2.55425442e-02, -4.51303795e-02,\n",
       "         -1.56768821e-02, -5.13394438e-02,  3.29712257e-02,  4.82018292e-02,\n",
       "          5.04796281e-02,  4.96694334e-02,  3.07632759e-02,  2.42307261e-02,\n",
       "          4.81786057e-02,  1.79916248e-02,  1.66501384e-02, -2.58531626e-02,\n",
       "          1.38497604e-02,  1.09724021e-02, -5.26121035e-02, -3.39633375e-02,\n",
       "          2.21666768e-02,  4.48500104e-02,  4.54995483e-02, -4.38957065e-02,\n",
       "         -2.78867576e-02, -6.18328713e-03,  2.42117140e-02,  2.40089209e-03,\n",
       "          3.23433466e-02,  5.70792379e-03, -4.86251935e-02,  7.37502426e-03,\n",
       "         -4.05805446e-02,  4.69568036e-02,  3.67353037e-02, -8.05919431e-03,\n",
       "         -1.25418184e-02,  2.10318454e-02,  5.22311218e-02,  1.05828531e-02,\n",
       "         -4.44865972e-02,  3.65289710e-02, -4.82476167e-02, -1.22550838e-02,\n",
       "          4.10926752e-02,  3.15433294e-02, -2.64780317e-02,  5.22823185e-02,\n",
       "         -3.51392552e-02, -3.80940572e-03,  4.84227687e-02,  1.16268164e-02,\n",
       "          3.53632905e-02, -3.70842144e-02,  3.80785018e-02, -4.17289250e-02,\n",
       "          4.60292436e-02,  1.80249196e-02, -4.27617244e-02,  4.62890454e-02,\n",
       "          2.21996997e-02,  2.43714526e-02,  4.90109958e-02,  4.70145531e-02,\n",
       "         -1.75466705e-02, -3.36410590e-02, -2.87050102e-03,  2.55838297e-02,\n",
       "          2.86009395e-03, -3.66494805e-03,  2.39258781e-02, -2.31706984e-02,\n",
       "          3.69859934e-02, -3.50222699e-02, -4.28762250e-02, -3.64575759e-02,\n",
       "         -7.02449027e-03, -3.13153304e-02, -1.65656339e-02,  1.02221845e-02,\n",
       "         -5.03886640e-02,  2.75079925e-02, -1.00560868e-02, -2.22394038e-02,\n",
       "          2.53909845e-02,  1.89976767e-02, -2.05201432e-02,  3.44311967e-02,\n",
       "          3.61706018e-02,  2.47008950e-02, -1.01455320e-02,  4.35280018e-02,\n",
       "          2.82115843e-02, -3.86961289e-02, -9.91991535e-03,  2.59046927e-02,\n",
       "         -1.92901660e-02, -3.44625190e-02,  8.90533254e-03,  5.27715087e-02,\n",
       "         -1.46289654e-02, -8.53393041e-03, -2.45235059e-02, -9.68702231e-03,\n",
       "         -7.70421093e-03, -2.21233573e-02, -4.24077883e-02,  1.36764860e-03,\n",
       "         -3.09866592e-02,  1.28640700e-02,  5.03204726e-02,  1.09665366e-02,\n",
       "         -2.63802279e-02,  3.43053006e-02, -1.96152292e-02,  8.29846784e-03,\n",
       "         -1.43264132e-02, -4.07756604e-02, -5.05600199e-02,  3.12792808e-02,\n",
       "          3.73051092e-02,  4.33098823e-02,  3.19837313e-03,  2.27310173e-02,\n",
       "         -4.74697948e-02,  1.54845612e-02,  5.02607822e-02,  5.29470714e-03,\n",
       "         -4.13047802e-03, -4.84139547e-02,  2.07340941e-02, -2.60668267e-02,\n",
       "          2.41459813e-02,  4.61134501e-02,  4.20270190e-02,  3.15141119e-02,\n",
       "         -4.40338068e-02,  1.10409950e-04, -5.36437929e-02, -1.08050145e-02,\n",
       "          1.55465603e-02, -1.70290153e-02, -2.41819359e-02,  3.41998599e-02,\n",
       "         -3.77010927e-02,  4.25274894e-02,  8.66677891e-03, -1.69056579e-02,\n",
       "          1.84540600e-02,  3.06429043e-02,  4.47143912e-02, -1.99669786e-02,\n",
       "         -1.44594572e-02,  9.71857179e-03, -1.78309698e-02,  3.87063511e-02,\n",
       "          4.43166941e-02, -3.55667025e-02,  3.63040268e-02, -2.94048116e-02,\n",
       "         -3.05238739e-02,  4.91629029e-03, -2.41829958e-02, -3.27602439e-02,\n",
       "          3.17006856e-02,  1.03341797e-02, -2.90761217e-02,  2.78004189e-03,\n",
       "          1.34670297e-02,  2.01230496e-02, -4.32249531e-02,  1.48878312e-02,\n",
       "         -1.01174880e-02,  3.89897786e-02, -5.19010127e-02,  5.52702288e-04,\n",
       "          9.19994432e-03, -5.36644906e-02, -4.09901030e-02,  2.92171314e-02,\n",
       "         -1.64214731e-03,  1.88157912e-02,  1.77059043e-02, -2.48607267e-02,\n",
       "         -4.95221950e-02, -3.44998389e-02, -4.00159992e-02,  5.27458638e-03,\n",
       "         -3.81741598e-02,  2.50091758e-02, -5.30312210e-02,  8.76263715e-03,\n",
       "         -3.58427651e-02,  5.78008778e-03,  4.23166901e-02,  2.81093977e-02,\n",
       "         -3.40056117e-03,  2.99514104e-02, -4.29493375e-02, -1.10756867e-02,\n",
       "         -1.35672009e-02,  2.76467577e-02,  4.97037172e-02,  4.07305434e-02,\n",
       "          3.48301455e-02, -4.63265926e-02, -3.42298634e-02, -1.16188275e-02,\n",
       "          1.10896677e-02,  2.45169420e-02,  4.11529802e-02,  4.41893227e-02,\n",
       "         -3.42421979e-02,  4.05676439e-02, -2.08269283e-02, -2.40107477e-02,\n",
       "         -4.55148816e-02, -1.95494760e-02, -2.52897777e-02,  8.50575790e-03,\n",
       "         -2.77475733e-02, -1.56103692e-03, -5.26079983e-02, -2.45250389e-02,\n",
       "         -9.98383574e-03, -4.22618240e-02,  4.84716184e-02,  4.55386080e-02,\n",
       "          2.58743782e-02, -4.24285010e-02,  5.93014807e-03, -2.87661329e-02,\n",
       "          1.22209601e-02, -5.14581986e-02, -1.38725042e-02,  4.66461591e-02,\n",
       "         -4.09332700e-02,  1.85177531e-02, -1.39482273e-02, -1.38223087e-02,\n",
       "         -2.58869063e-02,  3.51683758e-02, -2.26526409e-02, -4.06183861e-02,\n",
       "         -3.04961465e-02, -1.56814810e-02, -1.32445218e-02,  1.59453023e-02,\n",
       "         -4.57865447e-02, -4.49801646e-02, -5.11081219e-02,  6.09245058e-03,\n",
       "         -3.26299630e-02,  2.48742737e-02, -2.15639379e-02, -2.82094944e-02,\n",
       "         -1.47939790e-02,  4.08328101e-02,  5.21343723e-02, -1.64901707e-02,\n",
       "         -3.11286617e-02,  3.54939587e-02,  4.06125374e-02,  4.17072363e-02,\n",
       "         -8.53704009e-03,  2.55907886e-02,  2.81004086e-02,  1.74927376e-02,\n",
       "         -3.31053957e-02,  4.25603874e-02, -3.06705963e-02, -3.82868499e-02,\n",
       "          2.61801872e-02, -4.93806973e-02,  4.97670956e-02,  8.08417425e-03,\n",
       "         -4.49505374e-02,  3.29570174e-02, -2.95903180e-02,  2.55077109e-02,\n",
       "         -2.11142115e-02,  3.71597297e-02,  3.69304754e-02,  4.19455469e-02,\n",
       "         -3.78899388e-02,  3.97118367e-02,  2.33537946e-02, -3.80684510e-02,\n",
       "          5.85076027e-03, -2.56568119e-02,  1.32619007e-03, -2.15746295e-02,\n",
       "          4.41193655e-02, -3.74182314e-02,  1.98964756e-02, -1.62509233e-02,\n",
       "         -3.85663076e-03,  5.35510853e-02,  3.52640077e-02, -5.31522781e-02,\n",
       "          5.18045761e-02, -2.83840597e-02,  5.39611327e-03, -5.45274233e-03,\n",
       "         -1.36765316e-02,  3.68813239e-02, -3.92572582e-02, -1.48470199e-03,\n",
       "          4.49164808e-02, -1.05191590e-02, -4.19365987e-02,  1.62086170e-02,\n",
       "          3.98654491e-02,  5.09270616e-02,  3.37397493e-02, -7.88631383e-03,\n",
       "         -4.74479236e-02,  2.17641108e-02,  1.92122534e-02, -3.53502110e-02,\n",
       "          2.54087429e-02, -2.89145410e-02,  3.27164195e-02, -3.46913487e-02,\n",
       "          1.16933770e-02,  5.24727441e-02,  4.21038549e-03,  5.29248714e-02,\n",
       "          2.24813377e-03, -3.27019803e-02,  5.02291434e-02,  5.50736382e-04,\n",
       "         -4.50617149e-02, -4.69645225e-02,  3.15523110e-02,  5.01990989e-02,\n",
       "          5.05565219e-02, -3.23100239e-02, -4.20202464e-02, -3.31045501e-02,\n",
       "         -2.31640488e-02,  2.16130763e-02, -5.14616482e-02, -3.18851210e-02,\n",
       "         -3.26518193e-02, -3.26397195e-02,  3.33976299e-02,  3.47533636e-02,\n",
       "          3.81045565e-02, -3.37949097e-02, -5.19784056e-02,  2.28722040e-02,\n",
       "         -7.59254629e-03, -2.39871014e-02,  1.74979605e-02, -5.25738262e-02,\n",
       "          1.84526313e-02,  4.15182952e-03, -3.17513011e-02,  6.34075142e-03,\n",
       "         -9.95109789e-03,  1.59125403e-02, -1.22127635e-02, -2.35918481e-02,\n",
       "          3.43072899e-02, -1.20036751e-02, -4.80128527e-02,  1.14870900e-02,\n",
       "          7.89772067e-03,  2.03385036e-02, -4.82756039e-03,  1.37152569e-02,\n",
       "         -7.10599637e-03, -4.84068654e-02, -2.44229473e-03, -4.06146683e-02,\n",
       "          2.67287418e-02, -4.43893820e-02, -1.15304701e-02, -2.44135763e-02,\n",
       "          5.21940775e-02,  1.37703912e-02, -1.86090916e-02,  1.96048133e-02,\n",
       "         -3.49654183e-02,  1.55562712e-02, -3.53112184e-02, -9.50884074e-03,\n",
       "         -4.04222794e-02, -3.37374993e-02, -1.83407627e-02, -7.49349268e-03,\n",
       "          3.69091891e-02,  5.40462621e-02, -3.98047008e-02,  5.00752870e-03,\n",
       "          3.69817540e-02, -3.16743590e-02, -2.78685763e-02, -5.32473773e-02,\n",
       "         -4.02353406e-02, -1.45165073e-02,  3.33490372e-02,  3.02761868e-02,\n",
       "         -8.87159631e-03,  2.26740036e-02, -5.15729338e-02,  1.89902037e-02,\n",
       "         -3.86010408e-02, -1.34709561e-02,  4.33902293e-02,  1.70869846e-02,\n",
       "          4.01007682e-02, -5.01655936e-02,  5.34200445e-02, -1.73604526e-02,\n",
       "         -4.17200513e-02, -5.17811812e-02, -1.84065476e-02, -4.35406454e-02,\n",
       "         -1.50199942e-02, -5.35687879e-02,  3.89589532e-03,  2.32959748e-03],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 17,\n",
       "  'topic_words': array(['arxiv', 'populations', 'community', 'funding', 'funded',\n",
       "         'contribute', 'contributes', 'supporting', 'spreading',\n",
       "         'initiatives', '백신', 'epidemic', 'spread', 'population',\n",
       "         'contribution', 'promote', '혁명', 'support', 'fund', '생존',\n",
       "         'propagation', 'grant', 'contributing', 'initiative', 'groups',\n",
       "         'immune', 'contributed', '전염병', 'contributions', 'cohort',\n",
       "         'increase', 'society', 'supported', 'volunteer', 'diseases',\n",
       "         'disease', '지원', 'increasing', 'volunteers', '인구', 'scientific',\n",
       "         'degeneration', 'organizations', 'illness', '면역', 'advances',\n",
       "         'affected', '기금', 'supports', 'participate'], dtype='<U15'),\n",
       "  'topic_vector': array([-4.95217741e-03, -8.66813213e-03,  7.29462365e-03, -4.13700799e-03,\n",
       "          4.36140373e-02,  3.94682474e-02,  7.61962542e-03, -6.97095832e-03,\n",
       "         -2.04615928e-02,  8.62262212e-03,  1.20078842e-03,  1.00096185e-02,\n",
       "         -3.14815156e-02, -3.42021277e-03, -1.33898538e-02, -5.78262703e-03,\n",
       "         -4.61423304e-03, -6.17443547e-02,  3.33749864e-04,  3.33051160e-02,\n",
       "         -2.21529976e-02,  4.06920305e-03,  6.87894970e-03,  2.24081008e-03,\n",
       "         -1.81531720e-02,  1.99848451e-02,  4.27590534e-02, -2.03543808e-02,\n",
       "          4.97284811e-03, -4.50749137e-02, -4.92997766e-02,  2.31001433e-03,\n",
       "         -1.89909376e-02, -2.70525701e-02,  1.41379889e-02, -2.00366918e-02,\n",
       "          1.67125762e-02,  6.47421414e-03,  5.21111023e-03, -2.28577014e-02,\n",
       "          2.46038251e-02,  4.04825695e-02, -7.37400819e-03, -1.28715811e-02,\n",
       "         -3.21363285e-02, -4.69974764e-02, -1.14228409e-02, -3.42558399e-02,\n",
       "          6.83592050e-04,  2.19237357e-02, -3.25976647e-02, -3.32871787e-02,\n",
       "          3.33603919e-02, -1.96464173e-02, -8.43871851e-03, -4.78245430e-02,\n",
       "          2.97421217e-02,  2.90316846e-02, -3.60550657e-02, -2.00980417e-02,\n",
       "          3.64298176e-04,  4.00521308e-02,  2.14106664e-02, -4.92751785e-02,\n",
       "         -2.79996190e-02, -2.17686780e-02,  5.25649898e-02, -1.10395476e-02,\n",
       "          3.30739766e-02,  1.42480265e-02,  1.41809192e-02,  2.37828586e-02,\n",
       "          1.72599964e-02, -1.48821939e-02,  9.16223973e-03, -2.83996705e-02,\n",
       "          1.34860156e-02,  1.44973937e-02, -1.65702216e-02, -5.59381247e-02,\n",
       "         -6.18621707e-02, -4.29750197e-02, -1.50334314e-02, -2.88743824e-02,\n",
       "         -3.43048051e-02, -3.76639590e-02, -2.77023725e-02,  2.56607821e-03,\n",
       "          9.59260389e-03, -1.22529995e-02,  9.55155678e-03, -3.78767945e-05,\n",
       "         -3.94269999e-04,  1.10591818e-02,  9.88998078e-03,  1.35933431e-02,\n",
       "          5.41421957e-02,  3.60094123e-02,  1.34899262e-02, -8.47691484e-03,\n",
       "          2.05594003e-02, -1.39126312e-02,  4.00679484e-02, -1.87449791e-02,\n",
       "         -4.07927670e-03,  5.28771505e-02, -5.16364165e-02,  3.02067660e-02,\n",
       "          9.12652258e-03, -1.51631981e-02, -7.11876608e-04,  2.33034194e-02,\n",
       "          4.46000174e-02,  1.46675957e-02, -7.77777005e-03, -8.30761343e-03,\n",
       "         -2.43109111e-02,  4.76657450e-02, -3.69309969e-02,  6.82619493e-03,\n",
       "         -2.09635659e-03,  6.03313884e-03,  2.46425457e-02, -3.13091427e-02,\n",
       "         -3.04502640e-02, -2.13288749e-03,  6.07411563e-03, -1.46499053e-02,\n",
       "         -3.72631438e-02, -1.25684608e-02, -3.55039025e-03, -3.85516845e-02,\n",
       "          4.21670303e-02, -1.24527719e-02, -1.32234450e-02,  7.26484135e-02,\n",
       "         -2.38134968e-03, -6.29418110e-03,  2.40499377e-02,  1.64664146e-02,\n",
       "          2.83614844e-02,  1.82328336e-02,  2.12948732e-02,  2.49845013e-02,\n",
       "         -1.66291781e-02, -4.53109182e-02,  5.08368239e-02,  1.50968861e-02,\n",
       "         -2.36056605e-03, -1.05192931e-02,  5.74483871e-02, -1.38929170e-02,\n",
       "         -1.63419582e-02,  1.17756454e-02, -3.47658247e-02, -4.69246740e-03,\n",
       "          2.20453721e-02, -6.59178291e-03,  3.14458981e-02,  8.05708842e-05,\n",
       "          1.38274012e-02, -3.87611203e-02, -1.12804992e-03, -6.58722129e-03,\n",
       "          2.45392732e-02, -6.98902458e-03,  4.66283038e-03,  2.04832684e-02,\n",
       "         -1.49636911e-02, -2.07404345e-02,  4.76976857e-03, -2.88262335e-03,\n",
       "         -3.78497131e-02,  8.30612611e-03, -1.97667740e-02, -2.55575664e-02,\n",
       "         -4.28245366e-02, -1.35121541e-02, -6.09467700e-02,  5.96588328e-02,\n",
       "          1.81063730e-02, -4.85729687e-02, -1.08807627e-02,  4.00898121e-02,\n",
       "         -1.91852562e-02,  4.24794300e-04, -1.06195884e-03,  3.89755890e-02,\n",
       "         -3.19413207e-02,  1.13104563e-02,  9.87738464e-03,  2.08527539e-02,\n",
       "         -5.75753581e-03, -3.47719411e-03, -3.21686380e-02,  1.56179126e-02,\n",
       "          1.02564450e-02,  2.08723862e-02,  1.66839715e-02,  4.27484252e-02,\n",
       "          7.93856848e-03, -3.29409470e-03,  1.15363840e-02, -2.51515629e-03,\n",
       "         -1.27377911e-02, -1.57003999e-02, -1.14038987e-02,  5.97780664e-03,\n",
       "         -7.87311979e-03,  1.62653476e-02, -3.22564447e-04,  1.46417217e-02,\n",
       "         -2.06981339e-02,  2.01830268e-02, -9.47144721e-03,  1.85501913e-03,\n",
       "         -1.54831577e-02, -1.77526064e-02, -4.97206226e-02,  8.25222954e-03,\n",
       "         -3.23584899e-02,  1.97396558e-02,  2.10706182e-02,  1.34018045e-02,\n",
       "          1.98138226e-02, -3.30555215e-02, -4.82917298e-03,  2.87028253e-02,\n",
       "         -1.70654599e-02, -3.17130014e-02, -1.48890587e-02, -1.60827897e-02,\n",
       "         -5.80799170e-02,  5.29192016e-02,  4.24680347e-03,  3.15135606e-02,\n",
       "         -1.64852105e-03, -3.67478293e-04,  2.82069687e-02, -1.31971110e-02,\n",
       "          1.19971135e-03, -1.53942537e-02,  7.83786364e-03,  2.71361927e-03,\n",
       "          1.17337285e-02, -8.72593373e-03, -7.72774313e-03, -1.98431071e-02,\n",
       "         -5.38200326e-03, -5.48972078e-02,  2.38023847e-02, -3.10367532e-02,\n",
       "          3.72604020e-02,  2.08921023e-02, -1.05126724e-02,  9.44291521e-03,\n",
       "          6.85211411e-03,  2.46451683e-02, -4.12374400e-02,  4.31709588e-02,\n",
       "          2.04693489e-02,  5.15621854e-03, -2.96153631e-02,  9.31310293e-04,\n",
       "          1.65473931e-02,  4.95730573e-03, -2.72023492e-04,  1.34254936e-02,\n",
       "          2.59072054e-04, -1.70693118e-02, -2.88172960e-02,  4.44334513e-03,\n",
       "         -3.49020138e-02, -2.47118454e-02,  3.15024629e-02,  1.28891673e-02,\n",
       "          2.93833844e-04, -1.96243599e-02, -4.67099436e-02, -2.09381375e-02,\n",
       "         -3.42646912e-02,  1.95059422e-02,  5.84388245e-03, -1.32533461e-02,\n",
       "          1.07298102e-02,  2.80788243e-02, -5.37525602e-02,  2.83466484e-02,\n",
       "         -5.16453274e-02, -2.75645107e-02,  3.19497399e-02,  1.69269312e-02,\n",
       "         -2.74793617e-02,  5.60944434e-03, -2.44652424e-02,  1.75209902e-02,\n",
       "          7.45251542e-03, -2.31983196e-02,  8.40346236e-03,  4.42270339e-02,\n",
       "         -2.51522474e-02,  1.55909285e-02, -5.16931489e-02, -4.54251356e-02,\n",
       "         -4.92090955e-02, -2.23236457e-02,  3.14915664e-02, -7.96857011e-03,\n",
       "          2.02965774e-02, -1.40196066e-02,  4.38977685e-03,  7.09497929e-03,\n",
       "          1.26787070e-02,  3.45476577e-03,  5.93110435e-02,  1.13028595e-02,\n",
       "         -3.22455913e-02,  2.20096181e-03,  4.17116238e-03, -3.59754525e-02,\n",
       "          2.92832367e-02, -3.90066132e-02, -2.81970762e-02,  2.92822830e-02,\n",
       "         -4.87282947e-02,  2.74773594e-02,  4.44842950e-02, -2.04700977e-02,\n",
       "          2.15792172e-02,  2.47604474e-02, -1.28767444e-02,  2.22745687e-02,\n",
       "         -2.99784988e-02,  1.46405529e-02, -2.97325454e-03,  7.07025547e-03,\n",
       "          2.54820846e-02,  9.37337708e-03, -2.97301859e-02,  3.90211865e-03,\n",
       "          1.33457463e-02,  5.00182714e-03, -3.87641899e-02, -3.56649468e-03,\n",
       "         -2.89543960e-02,  3.29109319e-02, -2.52859835e-02, -1.24648074e-02,\n",
       "         -6.36163342e-04,  3.59395216e-03,  1.48921851e-02,  3.20046581e-02,\n",
       "          2.05068421e-02,  4.88870665e-02,  7.85932690e-03,  1.54914260e-02,\n",
       "          9.58311744e-03,  1.65426657e-02, -1.18799787e-02, -5.08693643e-02,\n",
       "          3.15871905e-03, -2.60552801e-02,  3.15519720e-02,  4.32421379e-02,\n",
       "         -3.95863038e-03,  4.84954715e-02, -5.04218563e-02, -5.13152368e-02,\n",
       "         -3.90565535e-03,  5.79958931e-02, -3.51592228e-02,  5.27116284e-02,\n",
       "         -4.73272204e-02,  1.50940390e-02,  2.52906028e-02,  2.80183051e-02,\n",
       "          2.52175368e-02, -3.10420431e-02,  4.87201549e-02, -3.53273302e-02,\n",
       "          1.61631927e-02, -1.20408032e-02, -4.56732735e-02, -8.63061380e-03,\n",
       "         -3.51060703e-02,  1.90915354e-02,  4.30453047e-02, -1.26779703e-02,\n",
       "          7.04087224e-03, -8.83555599e-03, -3.19194794e-02,  3.53478710e-03,\n",
       "          1.06544923e-02,  2.40470022e-02,  2.36236751e-02,  1.50799556e-02,\n",
       "         -4.74182628e-02, -5.47844870e-03,  4.65900358e-03,  4.76600602e-02,\n",
       "          4.76950034e-02,  6.84699491e-02,  5.39463758e-02,  1.30423915e-03,\n",
       "         -4.29801457e-02,  4.44211774e-02, -1.34595688e-02,  1.10323895e-02,\n",
       "          2.37404797e-02, -1.97273865e-02,  4.69272211e-02,  5.91328135e-03,\n",
       "         -1.79835258e-03,  3.44147757e-02,  2.63840798e-02,  4.33564037e-02,\n",
       "          1.42146926e-02,  1.90284699e-02,  1.76307857e-02,  1.00687519e-02,\n",
       "         -1.73493046e-02,  3.61777768e-02, -2.14214027e-02,  9.50486958e-03,\n",
       "          4.61644158e-02, -1.40236514e-02,  3.06928810e-02, -5.59145994e-02,\n",
       "          8.72577168e-03, -1.71026401e-02, -2.78093070e-02,  2.23602615e-02,\n",
       "         -1.28375739e-02,  2.67088450e-02,  3.39063182e-02, -2.09790915e-02,\n",
       "          5.10070240e-03,  2.81629376e-02, -2.83161793e-02,  3.20325792e-03,\n",
       "         -1.73298770e-03,  1.71654839e-02, -2.13639904e-03, -5.16732410e-02,\n",
       "          8.25120043e-03,  5.61577454e-02,  4.28461656e-02, -2.20491849e-02,\n",
       "         -2.34885514e-02,  5.80660477e-02, -2.80957855e-02,  7.58502726e-03,\n",
       "          2.11943779e-02,  1.08281132e-02, -5.24443612e-02, -3.24949399e-02,\n",
       "          8.71772505e-03, -1.38651282e-02, -3.41240615e-02, -2.37237327e-02,\n",
       "          2.66617294e-02,  3.79478605e-03, -3.32913175e-02, -4.62299678e-03,\n",
       "         -2.49848492e-03, -4.57861573e-02, -3.98982828e-03,  3.64566781e-02,\n",
       "          1.29535217e-02, -3.56931686e-02,  5.21359928e-02,  1.36566889e-02,\n",
       "         -1.24561843e-02,  1.09574161e-02, -8.76113586e-03, -3.63701209e-02,\n",
       "          2.89445519e-02,  9.66813974e-03, -5.52393962e-03, -2.80755013e-02,\n",
       "          3.33514884e-02,  6.44807667e-02, -2.42693536e-02, -4.73956354e-02,\n",
       "          2.43187118e-02, -7.43525568e-03,  1.61999092e-02, -6.68041781e-02,\n",
       "         -2.62717940e-02,  1.37138125e-02,  4.49833507e-03, -2.73364037e-02,\n",
       "          1.47729348e-02,  8.70395452e-03,  5.48490370e-03, -9.98147298e-03,\n",
       "          8.13973509e-03, -7.01166550e-03, -1.09444652e-02,  2.04568859e-02,\n",
       "          9.54236276e-03, -8.98445584e-03,  5.14472052e-02,  2.32504532e-02,\n",
       "         -2.18108688e-02, -2.63727605e-02, -3.40459980e-02, -4.46968302e-02,\n",
       "         -4.41533849e-02, -4.19908948e-02, -8.60659778e-03, -1.08837262e-02],\n",
       "        dtype=float32)},\n",
       " {'topic_idx': 18,\n",
       "  'topic_words': array(['neurosciences', 'neuroscience', 'neuroscientific',\n",
       "         'neuroscientists', 'scientists', 'neurons', 'scientist', 'neuron',\n",
       "         'neuroscientist', 'neurosci', 'neuronal', 'neurobiology',\n",
       "         'scientific', '과학', 'neuro', 'neural', 'science', 'neurology',\n",
       "         'neurobiological', 'neurobiol', 'neurological', 'brainstem',\n",
       "         'neurol', '과학자', 'brains', 'neurocultures', 'neuroimaging',\n",
       "         'neuroimage', 'brain', 'neurogenesis', 'neuroethics', 'sciences',\n",
       "         'neurosurg', 'cerebrospinal', 'alzheimers', 'forebrain',\n",
       "         'alzheimer', 'biology', '신경망', 'nucleus', 'genome', 'paramagnetic',\n",
       "         '신경', 'researchers', 'magnetic', '뉴런', 'intelligence', '뉴턴',\n",
       "         'intelligent', 'sensory'], dtype='<U15'),\n",
       "  'topic_vector': array([ 0.00754703,  0.03482311, -0.01678376,  0.00427209,  0.000971  ,\n",
       "          0.02777264,  0.00601572, -0.0166492 ,  0.02834346,  0.04427302,\n",
       "          0.00962287,  0.01619403,  0.03925561,  0.02316906, -0.05591239,\n",
       "          0.00138199,  0.01146621, -0.05846041,  0.02770711,  0.0126354 ,\n",
       "         -0.00412613, -0.02756315,  0.0311443 ,  0.01930721, -0.05520181,\n",
       "          0.03772325,  0.03471224, -0.01224229,  0.00581938, -0.03071059,\n",
       "          0.01227373,  0.02079019, -0.0113285 , -0.04460019,  0.00067595,\n",
       "         -0.03540602,  0.0130351 , -0.0239561 , -0.00365706, -0.03186559,\n",
       "         -0.02001212, -0.00012852,  0.0629555 ,  0.00784923, -0.0334123 ,\n",
       "         -0.0009394 ,  0.01610721,  0.00127617,  0.01245494,  0.00086983,\n",
       "         -0.0085932 , -0.02323852,  0.02329481,  0.03065875,  0.00480185,\n",
       "         -0.05973481,  0.0434804 ,  0.00242895,  0.00252794,  0.02993981,\n",
       "         -0.01930775,  0.05418373, -0.01729296, -0.03317016,  0.02190364,\n",
       "         -0.00414886,  0.03735472, -0.03940915, -0.0351781 , -0.02106992,\n",
       "         -0.02769223, -0.01337599,  0.02134779,  0.00293983, -0.02125905,\n",
       "         -0.0081706 ,  0.0132744 ,  0.01915382, -0.02034182, -0.063712  ,\n",
       "         -0.06493463, -0.04964973, -0.01252772,  0.03095396, -0.03282784,\n",
       "         -0.02158443,  0.01850285, -0.01625283,  0.03845289,  0.03534541,\n",
       "         -0.01443582, -0.0249699 , -0.03638099, -0.04966657,  0.00020304,\n",
       "          0.02060243,  0.041133  ,  0.02090397,  0.00829108,  0.00883591,\n",
       "          0.01991845, -0.00276153,  0.00854715, -0.01528266,  0.02659546,\n",
       "          0.00826836, -0.0542478 ,  0.01658685, -0.00672596,  0.03645904,\n",
       "         -0.01060051, -0.05859704, -0.03543554,  0.03569767,  0.03313566,\n",
       "         -0.0446004 , -0.00732861,  0.01328775, -0.03817777,  0.02722464,\n",
       "          0.03342579,  0.04607268,  0.02479727,  0.00602818, -0.00247939,\n",
       "          0.02630498, -0.00022512, -0.02101667, -0.01634717,  0.00447922,\n",
       "         -0.04259074,  0.01472369, -0.02754361,  0.02178475, -0.01699067,\n",
       "          0.05138841, -0.02254144, -0.03527639,  0.02780318,  0.01590347,\n",
       "          0.03301959,  0.01196165,  0.03597239,  0.00594054,  0.01686206,\n",
       "         -0.0092883 ,  0.01925559,  0.01256457, -0.00371519,  0.01060143,\n",
       "          0.05627163,  0.01641279, -0.01972986, -0.06076942,  0.00231353,\n",
       "          0.01116154, -0.02712258, -0.036397  , -0.01505973, -0.03563115,\n",
       "          0.04384361, -0.03554796, -0.05103045,  0.0053475 , -0.00142514,\n",
       "         -0.01605416,  0.03475359, -0.01283271, -0.03583403,  0.03506733,\n",
       "         -0.03190582,  0.00526032,  0.02564677,  0.01781102, -0.01913379,\n",
       "          0.03518652, -0.01228992,  0.01337522, -0.03480518,  0.02545359,\n",
       "          0.00948553,  0.00375935, -0.01472856, -0.01151293, -0.01630158,\n",
       "          0.00286031,  0.01946103,  0.05827724,  0.0327938 ,  0.04959929,\n",
       "          0.007962  , -0.0379976 ,  0.00606827, -0.02846703, -0.05016745,\n",
       "          0.01338754, -0.00453846,  0.00422014,  0.04964535,  0.0341663 ,\n",
       "          0.00326985,  0.00204569,  0.02952772, -0.05438591,  0.02509951,\n",
       "         -0.00817222, -0.01186502,  0.03538891,  0.01703339,  0.04348913,\n",
       "         -0.00274463,  0.00063961, -0.0288565 ,  0.02554728,  0.01053407,\n",
       "         -0.01395596,  0.01571382, -0.04292245,  0.01402325,  0.00779961,\n",
       "         -0.03092953,  0.03027363,  0.01797009,  0.02461345, -0.01916486,\n",
       "         -0.02490006, -0.03131945,  0.03861685,  0.02123914, -0.0085303 ,\n",
       "         -0.00196906,  0.03600777, -0.01744958,  0.03685654,  0.02082676,\n",
       "          0.00122576,  0.00357315,  0.01578213,  0.05338098, -0.00808916,\n",
       "         -0.02593505,  0.01432892,  0.0179281 ,  0.01967717,  0.03273738,\n",
       "          0.01415531,  0.04358014,  0.02031425, -0.0289968 ,  0.00587778,\n",
       "         -0.00753973, -0.0425764 ,  0.05199729, -0.00550516,  0.02967237,\n",
       "          0.01367912,  0.03135271,  0.01628783, -0.03469934,  0.02278334,\n",
       "         -0.01999984,  0.03733181,  0.00781486, -0.00697094,  0.02803057,\n",
       "         -0.04153293, -0.04970095,  0.02640877,  0.00104214,  0.02610466,\n",
       "          0.02785212, -0.01507311, -0.01757796, -0.01423935,  0.03129138,\n",
       "          0.01575377, -0.04755697,  0.03033689, -0.05166576, -0.05264795,\n",
       "         -0.01033775, -0.0266226 ,  0.01086046,  0.01852637, -0.02393447,\n",
       "          0.03468483, -0.01329473, -0.02995971,  0.01558522, -0.05142928,\n",
       "          0.02740344,  0.00460196, -0.00974235,  0.02828488,  0.01278684,\n",
       "         -0.01028423,  0.00512433,  0.02060224,  0.01218562,  0.03804065,\n",
       "         -0.00237408,  0.01720149,  0.02130902, -0.03361953,  0.00659362,\n",
       "         -0.03383214, -0.02118654,  0.03678369,  0.04152956,  0.02463995,\n",
       "          0.00172853, -0.04540316,  0.0225097 , -0.01448373,  0.04178438,\n",
       "          0.03519394, -0.0538555 , -0.00179216,  0.03573114, -0.02725969,\n",
       "          0.01453076, -0.04072706, -0.01043474,  0.0229829 , -0.05273767,\n",
       "         -0.02007332,  0.04758253,  0.03338003,  0.03065817,  0.01800157,\n",
       "         -0.02897497,  0.00453285, -0.01763489, -0.01814157,  0.0038894 ,\n",
       "         -0.00082656, -0.02246203, -0.02929655, -0.05404787,  0.01741373,\n",
       "          0.00267042,  0.02647459, -0.00765276, -0.03738048,  0.04503895,\n",
       "          0.03946013,  0.05103402, -0.03457778, -0.01738486, -0.00761927,\n",
       "          0.00083937,  0.00100863, -0.02952395,  0.03706434, -0.05370706,\n",
       "         -0.01745236, -0.01159668,  0.00955521,  0.00139185, -0.02086468,\n",
       "          0.00971194, -0.02108932,  0.03174218,  0.01100217, -0.02212197,\n",
       "          0.0353753 , -0.02686571,  0.02268698, -0.0201312 , -0.00380529,\n",
       "          0.02526561,  0.02778544, -0.02991751,  0.02451472, -0.01556688,\n",
       "          0.00812955, -0.0296121 ,  0.00307899,  0.00545204, -0.00585251,\n",
       "         -0.00580565, -0.00840272, -0.0003201 ,  0.01597046, -0.04787214,\n",
       "          0.05590084,  0.04330891, -0.04600334,  0.04422741,  0.02292804,\n",
       "          0.01430119, -0.01121103,  0.0165012 ,  0.01105414,  0.00889771,\n",
       "          0.00201248,  0.04624714,  0.00876489, -0.01644963,  0.01791171,\n",
       "          0.01652031,  0.05589221,  0.02945706,  0.00783087, -0.00955325,\n",
       "          0.00721442,  0.00120379, -0.02442238, -0.00106484,  0.02117482,\n",
       "          0.05751067, -0.00267886, -0.0016242 ,  0.03306213,  0.0183747 ,\n",
       "          0.04270004,  0.01690217, -0.01932427,  0.00085538,  0.03875215,\n",
       "          0.01511576, -0.00530528,  0.03094278,  0.04816905,  0.05586057,\n",
       "          0.00190585, -0.00442808, -0.01832438, -0.03289067,  0.02413127,\n",
       "          0.00388633,  0.02514618, -0.02017253,  0.00063936,  0.01988374,\n",
       "         -0.00500207,  0.01954013, -0.00028808, -0.05285893,  0.02108507,\n",
       "         -0.02252659,  0.04014906,  0.03034062, -0.05100988,  0.01488391,\n",
       "         -0.01281894,  0.0562951 ,  0.03383198,  0.03116215,  0.0205439 ,\n",
       "         -0.02887177, -0.01677726,  0.01906933,  0.02373727,  0.00210803,\n",
       "         -0.0362731 ,  0.02224371,  0.01195799, -0.01803476,  0.00164129,\n",
       "          0.00577932, -0.05448023, -0.01269109, -0.01758432, -0.03870276,\n",
       "         -0.04075782, -0.03448532, -0.00241628,  0.01509793, -0.01922833,\n",
       "          0.00188212,  0.03354365, -0.06006236,  0.01743101, -0.0032896 ,\n",
       "          0.01938467,  0.02036632,  0.02824021, -0.01856117,  0.0042206 ,\n",
       "          0.04246463,  0.04066933, -0.04283564, -0.02805807,  0.01836864,\n",
       "         -0.02860179,  0.02469704, -0.0591661 , -0.02498974, -0.00816667,\n",
       "          0.03648102,  0.01613194,  0.0549799 , -0.00751129, -0.00094409,\n",
       "          0.0075409 , -0.02776058, -0.00478796,  0.00944149,  0.01806698,\n",
       "          0.01241953, -0.05250502,  0.04151598, -0.02358832, -0.03319581,\n",
       "         -0.02582057, -0.02499632, -0.01041268, -0.04658113, -0.03386315,\n",
       "          0.03313939,  0.04375789], dtype=float32)},\n",
       " {'topic_idx': 19,\n",
       "  'topic_words': array(['신한은행', '대출', '신용', '융자', 'accounting', '은행원', '은행', '전세금', '신청',\n",
       "         '금융', 'bonds', '계좌', '급여', '소득', 'accounted', '무소득', 'accounts',\n",
       "         'application', 'documents', 'fund', '주식', 'applications', '보증금',\n",
       "         'payments', '투자', '방정식', 'investment', 'shares', '환율', 'account',\n",
       "         '경제', 'credit', '포트폴리오', '예금', 'hypotheses', 'asset', '이자',\n",
       "         'income', '영수증', '기금', '수수료', 'interest', 'benefits',\n",
       "         'extracellular', 'document', '증권', '반환', 'defaults', '원금',\n",
       "         'multiple'], dtype='<U15'),\n",
       "  'topic_vector': array([-2.27564834e-02,  2.08807420e-02, -4.44782153e-02,  8.57955776e-03,\n",
       "          3.94104049e-02,  3.38101760e-02, -2.94081867e-03, -2.48671714e-02,\n",
       "         -2.16914695e-02,  5.61044086e-03, -2.43177991e-02, -8.73484742e-03,\n",
       "          3.84766944e-02,  8.44845362e-03,  1.44734904e-02,  2.60081440e-02,\n",
       "          8.18497781e-03, -3.63099240e-02,  4.99424823e-02,  5.49917482e-02,\n",
       "          5.01859095e-03, -2.85735098e-03, -2.56888885e-02,  3.28988768e-02,\n",
       "         -5.67376018e-02, -2.17965674e-02, -1.88852809e-02,  1.30161215e-02,\n",
       "          1.46493316e-02, -3.18594538e-02, -1.14769926e-02,  1.90123282e-02,\n",
       "          2.90457327e-02, -4.11724448e-02,  3.81798074e-02, -2.25962941e-02,\n",
       "          2.65047196e-02, -2.56400723e-02,  2.11183298e-02,  6.64010970e-03,\n",
       "         -2.57670283e-02, -2.25283373e-02,  2.06580963e-02,  3.60011049e-02,\n",
       "         -2.19205506e-02, -5.20631298e-02,  1.20290648e-02, -2.39665247e-02,\n",
       "          3.57643999e-02,  8.63739848e-03, -6.27741823e-03,  1.87595300e-02,\n",
       "          5.85894194e-03, -1.69628263e-02,  4.91806790e-02, -5.47178723e-02,\n",
       "          2.05468070e-02, -3.57823744e-02, -2.60913763e-02,  1.14706496e-03,\n",
       "          1.17698442e-02,  5.74005842e-02, -1.13786999e-02, -3.44633125e-03,\n",
       "         -3.73301879e-02,  2.75397152e-02,  3.69519368e-02,  9.69562156e-04,\n",
       "         -1.43567529e-02, -4.16108072e-02,  4.07573581e-03,  1.61693469e-02,\n",
       "          1.12888645e-02,  1.77944428e-03,  4.80728690e-03,  2.63532866e-02,\n",
       "         -1.81800965e-02,  2.50049625e-02,  1.18071446e-02, -5.86619787e-02,\n",
       "         -5.91457151e-02,  1.14240665e-02,  4.48960066e-03,  1.87719706e-02,\n",
       "          6.36178162e-03, -2.39495300e-02, -4.07694690e-02, -3.72261442e-02,\n",
       "          6.95381640e-03,  1.88153423e-03, -4.10689227e-02,  1.02825603e-02,\n",
       "          8.41808098e-04, -2.23584194e-02,  3.53837423e-02,  2.01151222e-02,\n",
       "          2.19226331e-02,  3.03455889e-02,  6.89933368e-04,  1.97017808e-02,\n",
       "          2.54433998e-03,  3.91590893e-02,  5.72942616e-03,  1.22860549e-02,\n",
       "          2.87077222e-02, -2.04263665e-02, -4.20021228e-02, -9.67741013e-03,\n",
       "          3.60019840e-02,  1.03574526e-02,  2.24095695e-02,  1.31534250e-03,\n",
       "          2.06792485e-02,  1.28311273e-02,  3.80520597e-02,  4.84447554e-02,\n",
       "          2.96287630e-02,  2.85522867e-04, -5.03840372e-02,  2.33995868e-03,\n",
       "         -6.01788284e-03, -3.24009322e-02,  9.57160909e-03,  3.88384098e-03,\n",
       "          2.04659216e-02, -1.00889588e-02, -2.90166382e-02,  3.93356122e-02,\n",
       "         -3.34985629e-02,  9.56825353e-03, -5.28227687e-02, -3.68498489e-02,\n",
       "          4.99042682e-02,  8.17546993e-03, -3.94516103e-02,  5.88806458e-02,\n",
       "          7.34064681e-03, -3.44526395e-02,  5.10595366e-02, -4.94992435e-02,\n",
       "          2.55893115e-02,  8.67287908e-03, -1.62060130e-02, -1.35834068e-02,\n",
       "          2.38903221e-02, -1.15836235e-02,  1.81340408e-02,  9.24916007e-03,\n",
       "          3.56996618e-02,  2.40696799e-02,  3.20151113e-02, -6.29875064e-03,\n",
       "         -3.27833928e-02,  1.64832901e-02,  2.86285784e-02,  2.34135217e-03,\n",
       "          6.94960123e-03, -3.51915546e-02,  8.00184254e-03, -1.75065044e-02,\n",
       "          3.90972383e-02, -3.33117917e-02,  1.33276908e-02, -1.48669388e-02,\n",
       "          3.33873816e-02, -3.60236466e-02,  1.87262241e-02, -1.96303185e-02,\n",
       "         -4.72364854e-03, -2.80116592e-02,  1.75938532e-02, -7.62430904e-03,\n",
       "          2.57044123e-03, -2.04444565e-02,  2.15420108e-02,  4.81672920e-02,\n",
       "          2.74496246e-02, -3.13207656e-02,  7.22203311e-03,  3.16150188e-02,\n",
       "          3.65852825e-02, -3.09070367e-02, -2.39178203e-02, -1.15855620e-03,\n",
       "         -2.73547061e-02, -5.68942633e-03,  3.73380668e-02,  5.47760352e-02,\n",
       "          1.56967323e-02, -4.90310602e-02, -1.91036072e-02,  1.97699256e-02,\n",
       "          3.92528251e-02, -2.29639206e-02, -3.85349169e-02,  3.69122997e-02,\n",
       "          4.80540359e-04,  2.24365480e-02,  8.98747705e-03,  3.66645935e-03,\n",
       "         -2.11178442e-03, -3.40581238e-02, -1.90802608e-02, -3.94963883e-02,\n",
       "         -1.01119594e-03, -1.08386828e-02,  1.21067837e-02,  1.12396032e-02,\n",
       "         -1.29481982e-02,  3.54290977e-02,  1.51063397e-03, -2.55033793e-03,\n",
       "         -5.39414845e-02, -1.22908000e-02, -1.19904485e-02, -2.39792708e-02,\n",
       "          3.73942815e-02,  1.39513111e-03, -3.89626101e-02,  1.92083158e-02,\n",
       "         -1.78679284e-02, -3.55311222e-02,  1.20099168e-02, -1.17307808e-02,\n",
       "         -3.36233489e-02, -2.90398840e-02, -1.56921037e-02,  3.82493483e-03,\n",
       "         -1.43727632e-02,  8.33510607e-03,  2.90562324e-02, -5.78802489e-02,\n",
       "          1.30641712e-02,  1.61859430e-02, -4.98460326e-03, -1.03544146e-02,\n",
       "         -1.05923628e-02,  3.62547003e-02,  1.83766689e-02,  3.54645438e-02,\n",
       "         -3.40852998e-02, -3.40791345e-02,  1.66425966e-02, -1.14319893e-02,\n",
       "          5.33477776e-02,  3.26755084e-02,  4.57880013e-02,  1.56853404e-02,\n",
       "          1.91061702e-02, -9.72204562e-03, -5.49249770e-03,  1.48660531e-02,\n",
       "         -2.94217914e-02, -1.41064469e-02,  1.48760073e-03,  3.64996539e-03,\n",
       "          1.82908087e-03,  7.46345962e-04, -1.83639638e-02,  5.33989593e-02,\n",
       "          1.28808385e-02,  1.37037905e-02, -2.18169522e-02,  1.52411619e-02,\n",
       "          3.86571325e-02, -5.79879023e-02,  4.38138545e-02,  3.89620773e-02,\n",
       "          2.49642152e-02, -6.48582960e-03,  3.30446213e-02, -1.35962153e-02,\n",
       "          2.52812300e-02,  1.05925845e-02,  4.05224450e-02,  1.79254152e-02,\n",
       "          6.15643105e-03, -1.95705574e-02, -5.67969792e-02, -4.79758307e-02,\n",
       "         -5.89801706e-02, -2.78693326e-02, -1.27443876e-02, -1.75627358e-02,\n",
       "          2.24054027e-02,  2.75640027e-03, -4.95645590e-02,  2.05684919e-02,\n",
       "         -4.37219776e-02, -6.39915140e-03, -8.67219642e-03,  3.87083478e-02,\n",
       "          6.66098250e-03, -3.55473273e-02,  2.46331338e-02,  1.10396845e-02,\n",
       "         -8.04581400e-03, -3.74384224e-02, -9.29931272e-03, -2.80890055e-02,\n",
       "         -8.15490354e-03,  1.55358138e-02, -1.38518680e-02, -3.75331305e-02,\n",
       "          1.73875857e-02, -4.10612579e-03,  2.80212313e-02,  2.08943011e-03,\n",
       "          8.64761136e-03, -2.37257276e-02,  4.25896570e-02, -1.46458056e-02,\n",
       "          1.22905625e-02,  1.39309764e-02,  5.35294898e-02,  4.78895195e-02,\n",
       "          1.22878635e-02, -3.85380350e-02, -1.84464511e-02,  1.80178080e-02,\n",
       "          1.66339017e-02,  3.68179977e-02,  9.49004956e-04, -1.30527560e-02,\n",
       "          8.72961991e-03,  9.10307281e-03, -8.85810237e-03, -3.79740223e-02,\n",
       "          2.70064287e-02, -2.45493418e-03, -2.41712611e-02, -3.18173654e-02,\n",
       "         -1.20459544e-02, -3.49551030e-02,  5.90195581e-02, -3.53231579e-02,\n",
       "         -7.05869403e-03,  1.71985235e-02, -3.21721919e-02, -3.32833044e-02,\n",
       "         -3.50625662e-04,  1.49181914e-02, -1.58469472e-02, -2.26715263e-02,\n",
       "          2.23178114e-03,  5.22071961e-03, -2.14307643e-02, -1.59463640e-02,\n",
       "          1.48638478e-02,  1.24400975e-02,  5.27040660e-02, -6.83296984e-03,\n",
       "          4.18442711e-02,  1.57299414e-02, -4.30493020e-02,  4.72466238e-02,\n",
       "         -3.23212296e-02,  1.98758114e-02, -3.88309695e-02, -2.93411780e-02,\n",
       "          3.61649394e-02, -2.04038508e-02,  2.88514141e-02,  5.03332820e-03,\n",
       "          4.49288171e-03,  2.70938929e-02, -9.72495507e-03,  2.45651025e-02,\n",
       "         -1.90159176e-02,  1.19479606e-02, -8.91302247e-03,  1.39879948e-02,\n",
       "         -4.19949964e-02,  4.50473884e-03,  3.36570403e-04,  5.77072147e-03,\n",
       "          6.67345384e-03, -3.46792713e-02,  4.05206084e-02, -5.56491641e-03,\n",
       "         -4.88512963e-03,  3.42967734e-02,  3.35381739e-02,  1.91742927e-02,\n",
       "          1.15641672e-02,  4.70411591e-02,  1.83446351e-02, -5.65519221e-02,\n",
       "          5.66854514e-02,  4.31115814e-02, -2.26637460e-02,  3.17874029e-02,\n",
       "         -7.27502955e-03,  3.12483497e-02,  2.33656671e-02,  1.04458956e-02,\n",
       "          1.76146235e-02, -1.13118012e-02,  2.10968740e-02,  1.88300963e-02,\n",
       "          2.61195842e-02,  1.99101190e-03,  3.77461836e-02,  8.83547869e-03,\n",
       "          7.05712941e-03, -1.02164531e-02, -2.09214631e-02, -9.50959802e-04,\n",
       "          2.62339432e-02,  1.92167368e-02,  1.65711925e-03,  1.13679105e-02,\n",
       "          3.12878862e-02, -1.33264149e-02,  1.97887439e-02,  4.07135822e-02,\n",
       "          2.50507463e-02,  3.94668393e-02, -4.67885802e-05, -1.58430859e-02,\n",
       "          1.38121948e-03,  2.42274664e-02,  5.18646464e-02,  4.00777385e-02,\n",
       "          3.13770883e-02, -3.23466072e-03,  3.41794379e-02, -3.58148851e-02,\n",
       "         -5.98132843e-03, -3.50833945e-02,  1.83667447e-02,  4.04033586e-02,\n",
       "          1.51729491e-02, -1.29377181e-02,  4.01543900e-02,  1.13992942e-02,\n",
       "          3.11806779e-02,  1.64880715e-02, -5.70802614e-02, -8.46036337e-03,\n",
       "          5.13284095e-02,  2.51788143e-02, -9.03979596e-03, -4.63627577e-02,\n",
       "         -1.62147135e-02,  1.00838682e-02,  3.96270268e-02, -4.97285426e-02,\n",
       "          7.27627752e-03,  3.97289805e-02,  3.00509650e-02,  2.66520232e-02,\n",
       "          3.47643122e-02,  1.26774155e-03, -3.40879597e-02,  8.95224977e-03,\n",
       "          1.22136495e-03, -5.30603295e-03,  2.02909708e-02,  8.52434803e-03,\n",
       "          3.34133096e-02, -6.59932196e-03, -5.87623892e-03, -1.45148654e-02,\n",
       "          1.56549104e-02, -5.10015376e-02,  4.00224589e-02, -1.60053354e-02,\n",
       "          4.74306941e-02, -8.12267046e-03,  3.92464586e-02, -1.79315936e-02,\n",
       "         -2.78013926e-02, -2.27142591e-02, -3.86732742e-02, -2.38110106e-02,\n",
       "         -1.31916543e-02,  1.18343551e-02, -2.19922662e-02,  2.76755681e-03,\n",
       "          3.37397642e-02,  5.94256781e-02, -3.23198619e-03, -1.30203934e-02,\n",
       "          3.01327389e-02, -1.02630304e-02,  3.86255905e-02, -5.52132726e-02,\n",
       "         -5.18357754e-03, -1.47957960e-02,  1.67686138e-02,  5.11264475e-03,\n",
       "         -8.62886291e-03, -1.85970813e-02, -4.06740000e-03, -3.31281684e-02,\n",
       "         -2.63990257e-02, -2.44167093e-02, -7.60364020e-03,  3.48365642e-02,\n",
       "          2.20031235e-02, -5.90411900e-03,  5.31482399e-02,  2.44056340e-02,\n",
       "         -5.50501272e-02, -4.30718027e-02,  1.16750235e-02,  1.84308756e-02,\n",
       "          3.53636482e-04, -4.75581661e-02,  1.76228750e-02,  2.49429885e-02],\n",
       "        dtype=float32)}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tm_model.get_topics_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids = [469,473]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([73,  4,  4]),\n",
       " array([0.7833977, 0.7542943, 0.5097479], dtype=float32),\n",
       " array([['groups', 'group', 'activation', 'activity', 'activities',\n",
       "         'items', '영향', 'factors', 'negative', '기능', 'interactions',\n",
       "         'tool', 'populations', 'food', 'article', 'tools', '효과',\n",
       "         'interaction', 'feature', 'selection', 'areas', 'findings', '연구',\n",
       "         'effects', 'extraction', 'genetic', 'team', 'species', '부분',\n",
       "         'role', 'ants', 'arrows', 'functions', 'individuals', 'func',\n",
       "         'organizations', 'features', 'teams', 'section', 'product',\n",
       "         'interest', 'components', 'benefit', 'factor', 'researchers',\n",
       "         'correlated', '유전자', 'humans', 'functional', 'effect'],\n",
       "        ['population', '데이터', 'impairment', 'statistical', '발생',\n",
       "         'statistics', 'populations', 'dropout', 'error', '영향', 'nouveau',\n",
       "         'pain', 'effects', '다시', 'regression', 'public', 'latest',\n",
       "         'data', '상황', 'effect', 'trying', 'symptoms', 'cases', 'recent',\n",
       "         '패러다임', 'again', '종료', 'people', '변화', 'results', '최근',\n",
       "         'disorders', 'renaming', 'neuroimaging', '이상', '효과', 'fix',\n",
       "         'previous', 'findings', '진행', 'individuals', 'normal',\n",
       "         'probability', 'rate', 'delayed', 'estimated', 'moment', 'down',\n",
       "         'behavioural', '행동'],\n",
       "        ['population', '데이터', 'impairment', 'statistical', '발생',\n",
       "         'statistics', 'populations', 'dropout', 'error', '영향', 'nouveau',\n",
       "         'pain', 'effects', '다시', 'regression', 'public', 'latest',\n",
       "         'data', '상황', 'effect', 'trying', 'symptoms', 'cases', 'recent',\n",
       "         '패러다임', 'again', '종료', 'people', '변화', 'results', '최근',\n",
       "         'disorders', 'renaming', 'neuroimaging', '이상', '효과', 'fix',\n",
       "         'previous', 'findings', '진행', 'individuals', 'normal',\n",
       "         'probability', 'rate', 'delayed', 'estimated', 'moment', 'down',\n",
       "         'behavioural', '행동']], dtype='<U15'),\n",
       " array([[0.21399955, 0.19353491, 0.17859608, 0.16122493, 0.15727179,\n",
       "         0.15576208, 0.14051987, 0.14022908, 0.13085341, 0.12937224,\n",
       "         0.12757774, 0.12583256, 0.12554933, 0.12263383, 0.12224889,\n",
       "         0.12201747, 0.11937447, 0.11863677, 0.11803237, 0.11531249,\n",
       "         0.11396527, 0.11379296, 0.11348441, 0.11329817, 0.11097687,\n",
       "         0.110375  , 0.11003233, 0.10881844, 0.1070085 , 0.10674293,\n",
       "         0.10663066, 0.10610311, 0.10574006, 0.10549113, 0.10523566,\n",
       "         0.10518897, 0.10507945, 0.10363994, 0.10337313, 0.10322556,\n",
       "         0.10294119, 0.10236046, 0.1011317 , 0.10024199, 0.09986912,\n",
       "         0.09854165, 0.09848434, 0.09699772, 0.09662446, 0.09612966],\n",
       "        [0.1501672 , 0.14849567, 0.1381338 , 0.13789283, 0.13724819,\n",
       "         0.13615231, 0.1321958 , 0.12687758, 0.12430423, 0.12274691,\n",
       "         0.12248605, 0.12185793, 0.1198778 , 0.11903816, 0.11854757,\n",
       "         0.11710379, 0.11591784, 0.11541997, 0.11469009, 0.11261002,\n",
       "         0.11140243, 0.10660971, 0.1052684 , 0.10518445, 0.10448581,\n",
       "         0.10446602, 0.10338489, 0.10211348, 0.10204202, 0.10202298,\n",
       "         0.10082099, 0.09858467, 0.09774862, 0.09751839, 0.09707044,\n",
       "         0.09694606, 0.09669257, 0.09665412, 0.09658653, 0.09657568,\n",
       "         0.09545939, 0.09500995, 0.09465253, 0.09450731, 0.09448523,\n",
       "         0.09349168, 0.09135833, 0.09123373, 0.09062601, 0.09046447],\n",
       "        [0.1501672 , 0.14849567, 0.1381338 , 0.13789283, 0.13724819,\n",
       "         0.13615231, 0.1321958 , 0.12687758, 0.12430423, 0.12274691,\n",
       "         0.12248605, 0.12185793, 0.1198778 , 0.11903816, 0.11854757,\n",
       "         0.11710379, 0.11591784, 0.11541997, 0.11469009, 0.11261002,\n",
       "         0.11140243, 0.10660971, 0.1052684 , 0.10518445, 0.10448581,\n",
       "         0.10446602, 0.10338489, 0.10211348, 0.10204202, 0.10202298,\n",
       "         0.10082099, 0.09858467, 0.09774862, 0.09751839, 0.09707044,\n",
       "         0.09694606, 0.09669257, 0.09665412, 0.09658653, 0.09657568,\n",
       "         0.09545939, 0.09500995, 0.09465253, 0.09450731, 0.09448523,\n",
       "         0.09349168, 0.09135833, 0.09123373, 0.09062601, 0.09046447]],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tm_model.get_documents_topics([4] + doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_num: 4, The number of Document: 12\n",
      "Document: 469, Score: 0.7542942762374878, URL: https://www.google.co.kr/amp/s/m.biz.chosun.com/news/article.amp.html%3fcontid=2020051501319\n",
      "신종 코로나 바이러스 감염증 ( 코로나 19 ) 이 확산 하 면서 작년 대비 5 8 % 수준 까지 떨어졌 던 국내 이 동량 이 황금연휴 때 8 3 % 수준 까지 회복 한 것 으로 나타났 다 . 1 5 일 sk 텔레콤 과 통계청 이 모바일 빅 데이터 를 기반 으로 분석 한 결과 , 2 월 2 9 일 ( 토요일 ) 전 국민 이 동량 은 2 5 0 3 만 건 으로 1 년 전 같 은 시기 ( 4307 만 건 ) 의 5 8 . 원정연 통계청 빅 데이터 통계 과장 은 \" 코로나 19 감염자 가 늘어난 영향 으로 이 동량 이 줄 었 으며 , 특히 지역 집단 감염 이 발생 한 2 0 일 이후 첫 주말 인 2 9 일 에 가장 큰 폭 으로 줄어들 었 다 \" 고 분석 했 다 . 이러 한 국내 인구 이 동량 은 통계청 이 국내 점유 율 4 2 % 를 차지 하 는 sk 텔레콤 의 모바일 이 동 데이터 를 토대 로 전 국민 수준 으로 변환 한 수 치 다 . 이 는 지난 7 일 서울 이태원 클럽 발 코로나 집단 감염 이 알려 지 기 시작 하 면서 이동 을 줄인 영향 으로 보인다 . 코로나 19 발생 이후 에 는 상업 지역 · 관광지 · 레저 스포츠 시설 이 주거 지역 보다 이 동량 감소 가 컸 다 . 다만 황금연휴 가 있 던 발생 후 1 3 주 차 에 는 관광지 , 레저 스포츠 시설 에서 이 동량 이 크 게 늘 었 다 .\n",
      "\n",
      "Document: 468, Score: 0.7166489362716675, URL: https://www.google.co.kr/amp/s/m.yna.co.kr/amp/view/GYH20200515000800044\n",
      "[ 그래픽 ] 코로나 19 발생 전후 인구 이동 추이 . ( 서울 = 연합뉴스 ) 김영은 기자 = 신종 코로나 바이러스 감염증 ( 코로나 19 ) 이 확산 하 면서 작년 대비 5 8 % 수준 까지 떨어졌 던 국내 이 동량 이 황금연휴 때 8 3 % 수준 까지 회복 한 것 으로 나타났 다 . 1 5 일 통계청 과 sk 텔레콤 이 모바일 빅 데이터 를 기반 으로 분석 한 결과 , 2 월 2 9 일 ( 토요일 ) 전 국민 이 동량 은 2 천 503 만 건 으로 1 년 전 같 은 시기 ( 4 천 307 만 건 ) 의 5 8 . 1 % 수준 으로 떨어진 것 으로 나타났 다 . 0 eun @ yna . co . kr\n",
      "\n",
      "Document: 423, Score: 0.6653056144714355, URL: https://www.neca.re.kr/lay1/bbs/S1T12C49/A/12/view.do?article_seq=8324&cpage=1&rows=10&condition=&keyword=&show=&cat=\n",
      "홈 > 알림 마당 > 공지 사항 . 행정 안 전부 는 2 0 2 0 년 정부 혁신 핵심 과제 인 사회 문제 공모 사업 「 도전 . 한국 」 을 추진 중 이 며 본 공모전 에 앞서 아래 와 같이 코로나 19 관련 「 도전 . 한국 」 국민 아이디어 긴급 공모전 을 개최 합니다 . 국민 여러분 의 많 은 관심 부탁 드립니다 . ○ 과제 : 감염병 상 황시 재난 관련 긴급 물자 ( 보건 용 마스크 등 ) 를 본인 이 직접 수령 하 거나 구매 하 기 어려운 사람 들 에게 안전 하 고 효과 적 으로 공급 할 수 있 는 방안 ○ 기간 : ' 20 . 4 . 1 . ~ 4 . 15 . * 접수 마감 4 . 15 . 1 8 : 00 시 ○ 시상 : 최우 수상 1 , 000 만 원 ( 최우수 아이디어 1 건 ) ○ 문의 : 행정 안 전부 혁신 기획 과 0 4 4 - 205 - 2220 , 2 2 1 3 / jwm 123 @ korea . kr\n",
      "\n",
      "Document: 470, Score: 0.6471940279006958, URL: http://mn.kbs.co.kr/mobile/news/view.do?ncd=4447307\n",
      "URL 정부 가 sk 텔레콤 의 인구 이동 빅 데이터 를 이용해 코로나 19 의 영향 을 분석 한 자료 를 내놨 다 . 자료 에서 눈여겨볼 만 한 데이터 몇 개 를 추려서 소개 한다 . 이동성 데이터 는 그 자체 가 경제 적 충격 이나 심리 적 충격 을 의미 하 지 는 않 지만 살펴보 면 다양 한 의미 를 추론 해낼 수 있 다 . 분명 한 건 코로나 19 의 충격 과 상처 가 똑같 지 는 않 았 단 점 이 다 지난주 까지 데이터 는 더 할 나위 없이 긍정 적 이 다 . 추세 가 이렇게 꺾인 원인 을 좀 더 정확히 들여다보 려면 이번 주말 데이터 를 봐야 할 것 같 다 \" 고 설명 했 다 . 이후 로 도 꾸준히 남녀 간 이 동량 차이 는 분명 했 는데 , 완화 된 거리 두기 이후 여성 의 이 동량 이 증가 하 는 추세 는 남성 보다 더 빨랐 다 . 입지 유형 별 데이터 를 살펴보 면 대형 복합 상 가 는 이 동량 감소 폭 이 비교 적 적 고 관광지 나 상업 지역 의 이 동량 감소 폭 이 크 다 . 관광 의 경우 지난주 연휴 에 는 급증 했 다 . 하지만 앞서 언급 했 듯 이 동량 데이터 는 매출 타격 이나 심리 적 충격 의 크기 를 정확히 보여 주 지 는 않 는다 . 앞서 kbs 는 빅 데이터 분석 을 통해 소상 공인 들 의 매출 타격 을 분석 해 보도 한 바 있 다 .\n",
      "\n",
      "Document: 31, Score: 0.6245574355125427, URL: http://m.news.naver.com/rankingRead.nhn?oid=032&aid=0002726065&ntype=RANKING\n",
      "지난 2 4 일 오전 ( 현지 시간 ) 독일 라인란트팔츠주 의 작 은 도시 진 치히 에서 만난 탈리도마이드 피해자 포겔 은 자신 의 삶 에 대해 이야기 하 면서 계속 울먹거리 며 말 을 잇 지 못했 다 . 역시 탈리도마이드 피해자 인 비어 깃 슬 뢰서 ( 55 ) 의 아버지 는 죽 을 때 까지 죄책감 에서 벗어나 지 못했 다 . 어머니 는 처음 엔 “ 안 먹 겠 다 ” 고 했 지만 아버지 의 설득 으로 약 을 먹 었 다 . 슬 뢰서 의 아버지 는 딸 이 기형아 로 태어난 게 자신 이 권한 약 때문 이 라는 사실 을 안 뒤 벽 에 머리 를 박 았 다 . 미국 에서 는 프랜시스 올덤 켈시 라는 공무원 이 이 약 허가 를 검토 하 면서 ‘ 사람 에게 는 수면제 효과 를 내 고 동물 실험 에서 는 효과 가 나타나 지 않 았 다 ’ 는 허가 제출 자료 를 이상 하 게 여기 고 허가 를 내주 지 않 아 피해자 가 1 7 명 에 그쳤 다 . 현재 이 연금 을 받 고 있 는 피해자 는 2 4 0 0 명 정도 다 . 현재 이 연금 을 받 고 있 는 피해자 는 2 4 0 0 명 정도 다 . 현재 이 연금 을 받 고 있 는 피해자 는 2 4 0 0 명 정도 다 . 현재 이 연금 을 받 고 있 는 피해자 는 2 4 0 0 명 정도 다 .\n",
      "\n",
      "Document: 460, Score: 0.5684407949447632, URL: http://www.ictchallenge.kr/index.php\n",
      "솔 · 직 챌린지 . 활용 사례 내용 공 적 마스크 재고 현황 알림 서비스 공 적 마스크 판매처 · 판매 현황 ( 건강 보험 심사 평가 원 ) , 공 적 마스크 판매처 정보 제공 서비스 ( 한국 정보 화 진 흥원 ) 를 활용 해 약국 별 코로나 19 방역 공 적 마스크 재고 현황 을 제공 함 으로써 국민 비상사태 대응 및 편의 성 제고 미세먼지 정보 앱 대기 정보 데이터 ( 한국환경공단 , 기상청 등 ) 와 gps 기술 을 융합 하 여 실시간 으로 지역 별 미세먼지 농도 정보 를 업데이트 하 여 호흡기 질환 을 예방 할 수 있 도록 정보 제공 대중교통 도착 시간 알림 서비스 지하철 정보 서비스 , 실시간 도착 정보 ( 국토 교통부 , 서울특별시 ) , 버스 노선 · 도착 정보 조회 서비스 ( 경기도 ) 등 을 활용 하 여 대중교통 이용자 의 대기 시간 감소 병원 · 약국 정보 서비스 병원 정보 서비스 ( 건강 보험 심사 평가 원 ) 를 통해 주변 병원 의 위치 와 진료 정보 등 을 제공 주차장 정보 앱 자치 구별 주차장 현황 ( 국토 교통부 , 서울특별시 ) 을 활용 하 여 주변 의 주차장 위치 와 요금 등 을 한 곳 에 모아서 제공 화장품 정보 제공 앱 화장품 원료 및 성분 정보 ( 식품 의 약 품안 전처 ) 데이터 를 활용 · 가공 하 여 소비자 가 화장품 성분 을 쉽 게 이해 하 고 적합 한 화장품 을 합리 적 으로 구매 할 수 있 도록 도움 제공\n",
      "\n",
      "Document: 10, Score: 0.5409467220306396, URL: http://m.news.naver.com/rankingRead.nhn?oid=028&aid=0002313953&sid1=105&ntype=RANKING\n",
      "[ 토요 판 ] 원본 보 기 ‘ 팔꿈치 로 슬쩍 찌르 다 ’ 는 뜻 ‘ 넛지 ’ 미 교수 책 출간 이후 세계 적 유행 강요 나 제약 않 고 도 행동 변화 유도 명령 · 지시 없이 개인 선택 에 영향 행동 경제학 에 관심 몰려 화장실 파리 스티커 가 대표 적 인 예 녹화 재 생기 디자인 적용 해 대 히트 공공 분야 활용 방안 모색 움직임 미 정부 , 신용카드 개선 에 적용 검토 오류 막 는 데 유용 하 게 쓰일 수 도 ▶ 정재승 카 이스트 ( kaist · 한국과학기술원 ) 바이오 및 뇌 공학 과 교수 . 그런데 미국 시카고 경영 대학원 의 행동 경제학자 리처드 탈러 와 하버드 로스쿨 의 캐스 선스 타인 교수 가 라는 저서 를 통해 사람 들 에게 어떤 선택 을 금지 하 거나 그 들 의 경제 적 인센티브 를 크 게 변화 시키 지 않 고 도 , 예상 가능 한 방향 으로 그 들 의 행동 을 변화 시키 는 ‘ 자유주의 적 개입 주의 ’ 를 ‘ 넛지 ’ 로 새롭 게 정의 하 고 그것 의 중요 성 을 역설 하 면서 화제 가 됐 다 . ( 필자 도 스히폴 공항 에 갔 을 때 제일 먼저 화장실 에 들어가 그 유명 한 소변기 를 사진 찍 은 바 있 다 . 최근 스히폴 공항 의 소변기 에 는 파리 외 에 도 다양 한 동물 스티커 가 붙 어 있 다 . 인간 이 언제 실수 하 고 제품 을 보 면 어떻게 사용 하 려고 하 는지 이해 해야 만 , 직관 적 으로 쉽 게 사용 하 는 제품 을 디자인 할 수 있 다 .\n",
      "\n",
      "Document: 85, Score: 0.521232008934021, URL: http://ppss.kr/archives/105164\n",
      "통상 경비원 은 눈 이 그렇게 많이 오 면 아파트 어린이 놀이터 에 눈 이 쌓이 지 않 도록 구석구석 쓸 어 놓 습니다 . 그러니까 당사자 는 경비원 으로 제설 작업 을 하 던 중 미끄러져 넘어지 는 사고 를 당했 는데 , 왼쪽 무릎 은 다쳐서 피 가 나 고 , 오른쪽 무릎 의 의족 은 부서진 것 이 었 다 . 근로복지공단 에서 연락 이 왔 더라고요 . 알 고 보 니 그분 은 당사자 와 는 아무 관계 도 아닌 같 은 아파트 주민 이 셨 다 . 같이 ‘ 분기탱천 ’ 하 던 , 오지랖 넓 을 뿐 인 그 사람 법무법인 태평양 과 재단법 인 동천 은 이 사건 을 공익 사건 으로 수임 했 다 . 한 사람 의 ‘ 오지랖 ’ 이 수많 은 지체 장애인 의 권리 를 지켰 다 그렇게 1 년 을 넘 게 기다려 마침내 대법원 은 이 사건 원심 판결 을 파 기 환송 했 다 . 이 사건 은 애초 에 당사자 가 소송 까지 는 생각 하 지 않 은 사건 이 었 기 때문 이 다 . 사건 초기 당사자 주변 의 대부분 사람 들 이 ‘ 재수 가 없 으려니 하 고 잊 어 ! 그런데 가까운 거리 에서 지켜보 던 한 동네 주민 의 ‘ 오지랖 ’ 이 당사자 에게 는 소송 으로 나서 는 용기 가 되 었 고 , 그 결과 수많 은 다른 지체 장애인 의 권리 도 신장 될 수 있 었 던 것 이 다 .\n",
      "\n",
      "Document: 473, Score: 0.5097479224205017, URL: http://ncov.mohw.go.kr/tcmBoardView.do?brdId=&brdGubun=&dataGubun=&ncvContSeq=358768&contSeq=358768&board_id=&gubun=ALL\n",
      "코로나 바이러스 감염증 - 19 국내 발생 현황 ( 7 월 2 9 일 정례 브리핑 ) 질병관리본부 중앙 방역 대책 본부 ( 본부 장 정은경 ) 는 7 월 2 9 일 0 시 기준 으로 , 국내 발생 신규 확진 자 는 1 4 명 이 확인 되 었 고 , 해외 유입 사례 는 3 4 명 이 확인 되 어 총 누적 확진 자수 는 1 4 , 251 명 ( 해외 유입 2 , 363 명 ) 이 라고 밝혔 다 . 6 %) ※ 아메리카 : 미국 8 명 ( 외국인 4 명 ) , 유럽 : 프랑스 1 명 , 아시아 ( 중국 외 ) : 러시아 1 3 명 ( 12 명 ) , 우즈베키스탄 7 명 ( 4 명 ) , 카자흐스탄 2 명 ( 1 명 ) , 인도 1 명 ( 1 명 ) , 이라크 1 명 , 필리핀 1 명 【 확진 자 관리 현황 *( 7 . 부산 러시아 선박 ( petr 1 호 ) 관련 하 여 선박 수리공 1 명 이 추가 확진 되 어 지역 사회 누적 확진 자 는 총 1 1 명 * 이 다 . 해외 유입 확진 자 3 4 명 의 추정 유입 국가 는 아메리카 8 명 ( 미국 8 명 ) , 유럽 1 명 ( 프랑스 1 명 ) , 중국 외 아시아 2 5 명 ( 러시아 1 3 명 , 우즈베키스탄 7 명 , 카자흐스탄 2 명 , 인도 1 명 , 이라크 1 명 , 필리핀 1 명 ) 이 다 .\n",
      "\n",
      "Document: 233, Score: 0.46390751004219055, URL: https://1boon.daum.net/newsade/coldnoodles?dmp_channel=foodfighter&dmp_id=1131422\n",
      "‘ 옥류관 서울 1 호 점 ’ 에서 맛본 냉면 의 충격 반전 . 잠시 후 다시 시도 해 주 세요 please try again in a moment\n",
      "\n",
      "Document: 183, Score: 0.4419657588005066, URL: https://www.technologyreview.com/s/609968/a-new-map-of-the-darknet-suggests-your-local-drug-pusher-now-works-online/\n",
      "this darknet trade offers an entirely new way for drug dealers to sell their wares and for customers to score . the market is worth some $ 150 million a year — a small fraction of the $ 300 billion estimated worth of the global trade in illegal drugs — but it is growing rapidly . the drug trade has traditionally operated along well - established supply chains . they have mapped the darknet drug trade for the first time and compared it with known patterns of illegal trade . the team then estimated trading volumes by counting the number of buyer reviews — a total of 1 . by this measure , just five countries account for 7 0 percent of darknet trade : the u . finally , the team compared this pattern with the conventional illegal drug market . dittus and the team gathered government data on drug use in each country . dittus and company say the data suggests that darknet traders sit at the “ last mile ” end of the supply chain , at least as far as cannabis and cocaine are concerned . however , opiate darknet trading volumes are highest in the “ top five ” countries , suggesting that there is a different pattern at work here . according to the team , none of these drugs is shipped over the darknet from countries traditionally associated with producing them . an important question is whether darknet markets are slowly reorganizing the global drug trade .\n",
      "\n",
      "Document: 205, Score: 0.28210359811782837, URL: http://1boon.kakao.com/bookclub/minibook20180203\n",
      "[ 미니 북 ] 나 는 얼굴 없 는 작가 가 아닙니다 . 잠시 후 다시 시도 해 주 세요 please try again in a moment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_num = 4\n",
    "num_docs = my_tm_model.get_topic_sizes()[0][topic_num]\n",
    " \n",
    "documents, document_scores, document_ids = my_tm_model.search_documents_by_topic(topic_num=topic_num, num_docs=num_docs)\n",
    "print(f\"topic_num: {topic_num}, The number of Document: {num_docs}\")\n",
    "# print(topic_words[topic_num], '\\n')\n",
    "\n",
    "for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
    "    print(f\"Document: {doc_id}, Score: {score}, URL: {docs_info_prep_df['url'][doc_id]}\")\n",
    "    print(doc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([468, 470, 423])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tm_model.get_docs_by_doc(doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([['영향', 'effects', 'role', '효과', 'effect', 'food', 'activity',\n",
       "         'activities', 'activation', '연구', 'increased', 'contribution',\n",
       "         'factors', 'interactions', 'significantly', 'significant',\n",
       "         'scientific', 'negative', 'significance', 'article', 'changes',\n",
       "         'interest', 'findings', 'published', '변화', 'performance',\n",
       "         'output', 'interaction', 'benefit', '작업', 'internal', 'movement',\n",
       "         'ventral', '부분', 'tasks', 'things', 'functions', 'new',\n",
       "         'researchers', 'observed', 'little', 'studies', 'factor',\n",
       "         'positive', 'func', '기능', 'lower', 'works', 'items',\n",
       "         'distributed']], dtype='<U13'),\n",
       " array([[0.24826243, 0.18974277, 0.17923524, 0.17731381, 0.17352056,\n",
       "         0.17155015, 0.1655323 , 0.16119431, 0.15022378, 0.1475901 ,\n",
       "         0.140185  , 0.13532774, 0.12363472, 0.12275739, 0.12215174,\n",
       "         0.12113585, 0.12072752, 0.11677276, 0.11515312, 0.11481932,\n",
       "         0.11420466, 0.11356058, 0.11297913, 0.11238598, 0.11224764,\n",
       "         0.11063359, 0.10954873, 0.10951133, 0.10945245, 0.10835286,\n",
       "         0.10480099, 0.10328019, 0.10166452, 0.10075174, 0.10071026,\n",
       "         0.09974362, 0.09949773, 0.09898412, 0.09772561, 0.09750893,\n",
       "         0.09741074, 0.09690429, 0.09640389, 0.0963551 , 0.09633495,\n",
       "         0.09522916, 0.09505265, 0.09450875, 0.09427698, 0.09348983]]))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tm_model.get_keywords_by_doc([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['영향', 'populations', 'population', 'statistics', '발생',\n",
       "        'statistical', 'factors', 'findings', 'effects', 'correlations'],\n",
       "       dtype='<U12'),\n",
       " array([0.18777566, 0.17245457, 0.17219058, 0.1574989 , 0.15602871,\n",
       "        0.15092292, 0.14844488, 0.14490564, 0.14370645, 0.14241781]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tm_model.get_hot_keywords_by_docs([4] + doc_ids, [1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_idx_vector, docs_idx_vector, words_idx_vector = my_tm_model.get_2d_vectors()\n",
    "\n",
    "topics_idx_vector_df = pd.DataFrame(topics_idx_vector)\n",
    "docs_idx_vector_df = pd.DataFrame(docs_idx_vector)\n",
    "words_idx_vector_df = pd.DataFrame(words_idx_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>element_type</th>\n",
       "      <th>topic_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12.271623</td>\n",
       "      <td>6.511519</td>\n",
       "      <td>topic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15.529943</td>\n",
       "      <td>5.850564</td>\n",
       "      <td>topic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.517497</td>\n",
       "      <td>3.071488</td>\n",
       "      <td>topic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13.477629</td>\n",
       "      <td>2.486977</td>\n",
       "      <td>topic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8.730590</td>\n",
       "      <td>-1.422772</td>\n",
       "      <td>topic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>358</td>\n",
       "      <td>-3.703612</td>\n",
       "      <td>17.719889</td>\n",
       "      <td>word</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>1150</td>\n",
       "      <td>12.071407</td>\n",
       "      <td>1.585322</td>\n",
       "      <td>word</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>443</td>\n",
       "      <td>7.419833</td>\n",
       "      <td>9.488334</td>\n",
       "      <td>word</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>448</td>\n",
       "      <td>9.574939</td>\n",
       "      <td>0.447628</td>\n",
       "      <td>word</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>569</td>\n",
       "      <td>9.528579</td>\n",
       "      <td>-2.182111</td>\n",
       "      <td>word</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1364 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id          x          y element_type  topic_idx\n",
       "0       0  12.271623   6.511519        topic          0\n",
       "1       1  15.529943   5.850564        topic          1\n",
       "2       2   7.517497   3.071488        topic          2\n",
       "3       3  13.477629   2.486977        topic          3\n",
       "4       4   8.730590  -1.422772        topic          4\n",
       "..    ...        ...        ...          ...        ...\n",
       "813   358  -3.703612  17.719889         word         -1\n",
       "814  1150  12.071407   1.585322         word         -1\n",
       "815   443   7.419833   9.488334         word         -1\n",
       "816   448   9.574939   0.447628         word         -1\n",
       "817   569   9.528579  -2.182111         word         -1\n",
       "\n",
       "[1364 rows x 5 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_idx_vector_df['element_type'] ='topic'\n",
    "topics_idx_vector_df['topic_idx'] = topics_idx_vector_df['id']\n",
    "docs_idx_vector_df['element_type'] = 'doc'\n",
    "words_idx_vector_df['element_type'] = 'word'\n",
    "words_idx_vector_df['topic_idx'] = -1\n",
    "\n",
    "temp_df = pd.concat([topics_idx_vector_df,docs_idx_vector_df, words_idx_vector_df])\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1     818\n",
       " 0      20\n",
       " 1      18\n",
       " 2      15\n",
       " 3      15\n",
       "      ... \n",
       " 59      4\n",
       " 58      4\n",
       " 57      4\n",
       " 70      4\n",
       " 71      3\n",
       "Name: topic_idx, Length: 73, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df['topic_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tm_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepo import topic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lab13/prepo/prepo/topic_model.py'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.abspath(topic_model.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'topic_idx': 0,\n",
       "  'topic_words': array(['dataset', 'matlab', 'numpy', 'data', 'mxpath', 'tensorflow',\n",
       "         'bmatrix', 'algorithm', '데이터', 'information', 'computational',\n",
       "         'parameters', 'correlations', 'correlation', 'populations',\n",
       "         'optimization', '회귀분석', 'regression', 'statistics', 'parameter',\n",
       "         'integration', 'datetime', 'statistical', 'preprocessing', '정보',\n",
       "         'correlated', 'population', 'patients', 'groups', '행렬', 'subjects',\n",
       "         'distributed', 'neural', 'variables', 'analyses', 'analysis',\n",
       "         'analytics', 'extraction', 'source', 'coefficients', 'individuals',\n",
       "         'files', 'voxel', 'neurons', 'voxels', 'methods', 'openmx', 'fsl',\n",
       "         'index', 'treatment'], dtype='<U15')},\n",
       " {'topic_idx': 1,\n",
       "  'topic_words': array(['statistical', 'statistics', 'regression', 'probability',\n",
       "         'variance', 'covariance', 'coefficients', 'predict', '회귀분석',\n",
       "         'correlation', 'dataset', 'correlations', 'parameters', 'matlab',\n",
       "         'populations', 'optimization', 'distribution', 'population',\n",
       "         'data', 'parameter', 'computational', 'estimated', 'numpy',\n",
       "         'distributed', 'correlated', 'variables', 'estimate', 'estimates',\n",
       "         '변수', 'models', 'bias', 'tensorflow', '모델', 'algorithm', '예측',\n",
       "         '데이터', 'random', 'integration', 'sigma', 'model', 'sample',\n",
       "         'alzheimer', 'approach', '방정식', 'linear', 'mathbf', 'bmatrix',\n",
       "         'significance', '관계', 'individuals'], dtype='<U15')},\n",
       " {'topic_idx': 2,\n",
       "  'topic_words': array(['scientists', 'prison', 'published', 'researchers', 'psychology',\n",
       "         'populations', 'scientific', 'individuals', 'authors', 'alzheimer',\n",
       "         'stanford', 'neuroscience', 'students', 'mental', 'evidence',\n",
       "         'theory', 'individual', 'documents', 'degree', 'science', '과학',\n",
       "         'findings', 'author', 'people', 'humans', 'levels', 'papers',\n",
       "         'intelligence', 'samples', 'others', 'species', 'statistics',\n",
       "         'article', 'hippocampus', 'studies', 'experiment', 'student',\n",
       "         'organizations', 'population', 'groups', 'trained', 'public',\n",
       "         'traits', 'subjects', '교수', 'self', 'study', 'disorders', 'layers',\n",
       "         'were'], dtype='<U15')},\n",
       " {'topic_idx': 3,\n",
       "  'topic_words': array(['neural', 'networks', 'neurons', 'network', 'neuroscience',\n",
       "         'neuroimaging', 'algorithm', 'computational', '신경망', 'dataset',\n",
       "         'tensorflow', 'learning', 'theoretical', 'traits', 'regression',\n",
       "         'coefficients', 'training', 'information', 'derived',\n",
       "         'populations', 'trained', 'numpy', 'optimization', 'github',\n",
       "         'matlab', 'intelligence', 'class', 'technology', 'data', 'layers',\n",
       "         'distributed', '학습', 'coding', 'cognitive', 'computer', 'nucleus',\n",
       "         'layer', 'genetic', 'concepts', 'sequence', 'connectivity',\n",
       "         'psychology', 'systems', '회귀분석', 'web', 'cerebral', 'brain',\n",
       "         'encoding', 'learn', 'predict'], dtype='<U15')},\n",
       " {'topic_idx': 4,\n",
       "  'topic_words': array(['population', '데이터', 'impairment', 'statistical', '발생',\n",
       "         'statistics', 'populations', 'dropout', 'error', '영향', 'nouveau',\n",
       "         'pain', 'effects', '다시', 'regression', 'public', 'latest', 'data',\n",
       "         '상황', 'effect', 'trying', 'symptoms', 'cases', 'recent', '패러다임',\n",
       "         'again', '종료', 'people', '변화', 'results', '최근', 'disorders',\n",
       "         'renaming', 'neuroimaging', '이상', '효과', 'fix', 'previous',\n",
       "         'findings', '진행', 'individuals', 'normal', 'probability', 'rate',\n",
       "         'delayed', 'estimated', 'moment', 'down', 'behavioural', '행동'],\n",
       "        dtype='<U15')},\n",
       " {'topic_idx': 5,\n",
       "  'topic_words': array(['neuroscience', 'university', 'neural', 'neurons', 'computational',\n",
       "         'degree', 'intelligence', 'college', 'neuroimaging', 'computer',\n",
       "         'science', 'stanford', 'scientists', 'scientific', 'institute',\n",
       "         'brain', 'cerebral', 'study', 'apply', 'student', 'psychology',\n",
       "         '과학', 'program', '학습', '신경망', 'correlated', 'nucleus', 'programs',\n",
       "         'studies', '과정', 'data', 'information', 'students', '프로그램',\n",
       "         'technology', 'applied', 'subjects', 'researchers', 'free',\n",
       "         'ability', 'field', 'matlab', 'learning', 'midbrain',\n",
       "         'correlations', 'inputs', 'statistics', 'software', 'major',\n",
       "         'hippocampus'], dtype='<U15')},\n",
       " {'topic_idx': 6,\n",
       "  'topic_words': array(['부팅', 'ubuntu', 'linux', 'xorg', '우분투', 'kernel', 'boot', 'sudo',\n",
       "         'cpu', '파티션', '리눅스', 'optimization', 'nvidia', 'grub', '명령', '명령어',\n",
       "         'directory', 'command', 'default', 'gpu', 'localhost', 'processes',\n",
       "         '윈도우', 'gb', '메모리', 'windows', 'sd', 'performance', '옵션',\n",
       "         'computational', 'mxpath', '기본', 'define', 'foldername', 'option',\n",
       "         'firefox', 'tensorflow', 'files', 'process', 'root', 'system',\n",
       "         'script', 'args', 'options', 'prefix', 'usb', 'regions', 'primary',\n",
       "         'systems', 'defined'], dtype='<U15')},\n",
       " {'topic_idx': 7,\n",
       "  'topic_words': array(['법칙', '소스', 'states', 'differences', 'method', 'difference',\n",
       "         'parameter', 'approach', 'healthy', 'health', '법선', '언어',\n",
       "         'defined', 'language', 'representations', 'representation',\n",
       "         'prefix', 'terms', 'food', 'methods', 'grub', '정리', 'kwargs',\n",
       "         'understanding', 'making', 'parameters', 'approaches', 'version',\n",
       "         'simple', 'process', 'ways', 'clear', '버전', 'google', 'term',\n",
       "         'answer', '는지', 'show', 'state', 'services', 'shows', 'specify',\n",
       "         'make', 'expression', 'expr', 'understand', 'summary', 'learning',\n",
       "         'solution', 'mind'], dtype='<U15')},\n",
       " {'topic_idx': 8,\n",
       "  'topic_words': array(['url', 'firefox', 'browser', 'github', 'html', 'localhost',\n",
       "         'mozilla', 'request', 'python', 'tensorflow', 'requests', 'chrome',\n",
       "         'web', '파이썬', 'google', 'regression', 'page', 'mxpath', 'safari',\n",
       "         'parameters', 'utf', 'function', 'parameter', 'correlations', '요청',\n",
       "         '페이지', 'correlated', 'source', 'functions', 'correlation', '변수',\n",
       "         'response', 'dataset', 'solution', 'kwargs', 'responses',\n",
       "         'optimization', 'functional', 'coding', 'site', '구글', 'index',\n",
       "         'factors', 'connectivity', 'xorg', 'variable', 'variables',\n",
       "         'encoding', 'numpy', 'application'], dtype='<U15')},\n",
       " {'topic_idx': 9,\n",
       "  'topic_words': array(['psychology', 'statistical', 'behavioural', 'behavioral',\n",
       "         'behaviors', 'statistics', 'correlation', 'regression', 'neurons',\n",
       "         'behavior', 'cognitive', 'correlations', 'neuroscience',\n",
       "         'individuals', 'traits', 'coefficients', 'interaction',\n",
       "         'correlated', 'populations', 'neuroimaging', 'neural', 'predict',\n",
       "         'individual', 'interactions', 'alzheimer', 'scores', 'variance',\n",
       "         'estimates', 'intelligence', 'population', 'selection',\n",
       "         'activities', 'estimated', 'impairment', 'factors', '신경망',\n",
       "         'variables', 'participants', 'mental', 'ability', 'activity',\n",
       "         'covariance', 'groups', 'dementia', 'factor', 'rate', '예측',\n",
       "         'emotional', 'activation', 'estimate'], dtype='<U15')},\n",
       " {'topic_idx': 10,\n",
       "  'topic_words': array(['arxiv', 'supporting', 'contribution', 'support', '지원',\n",
       "         'community', 'giving', 'organizations', 'benefit', 'groups', 'don',\n",
       "         'foundation', 'give', 'we', '우리', 'join', 'group', 'us',\n",
       "         'increased', 'you', 'september', 'voxels', 'reward', 'our',\n",
       "         'scientific', 'provide', 'your', 'help', 'voxel', 'populations',\n",
       "         'improve', 'create', 'rewards', 'gather', 'df', 'movement',\n",
       "         'useful', 'new', 'activation', 'provides', 'anova', 'let',\n",
       "         'improvements', 'aov', 'send', 'already', 'creating', 'science',\n",
       "         'information', 'distributed'], dtype='<U15')},\n",
       " {'topic_idx': 11,\n",
       "  'topic_words': array(['dataset', 'plot', 'plots', 'data', '데이터', 'numpy', 'geom',\n",
       "         'matlab', 'statistics', '그래픽', 'statistical', 'information',\n",
       "         'correlation', 'gradient', 'correlations', 'populations',\n",
       "         'graphics', 'significance', '정보', 'coefficients', 'probability',\n",
       "         'regression', 'variables', 'github', 'population', 'datetime',\n",
       "         'variance', 'correlated', 'tensorflow', 'index', 'labels',\n",
       "         'values', 'distribution', 'estimates', 'covariance', '변수',\n",
       "         'traits', 'df', 'distributed', 'predict', 'python', 'algorithm',\n",
       "         'rate', 'scale', 'vtk', 'computational', 'bmatrix', 'estimated',\n",
       "         'textrm', 'levels'], dtype='<U15')},\n",
       " {'topic_idx': 12,\n",
       "  'topic_words': array(['python', 'numpy', '파이썬', 'tensorflow', 'integers', 'github',\n",
       "         'dataset', 'computational', '코딩', 'module', 'nipype', 'algorithm',\n",
       "         'kwargs', 'coding', 'matlab', 'encoding', 'linux', '변수', 'mozilla',\n",
       "         'ubuntu', 'hippocampus', '인코딩', 'optimization', 'function',\n",
       "         'hippocampal', 'variables', 'xorg', 'coefficients',\n",
       "         'preprocessing', 'array', 'kernel', 'import', 'mathbf', '코드',\n",
       "         'variable', 'firefox', 'gecko', 'data', 'code', 'args', 'software',\n",
       "         'functions', '윈도우', 'usb', '우분투', '변환', 'py', 'nvidia', 'windows',\n",
       "         '데이터'], dtype='<U15')},\n",
       " {'topic_idx': 13,\n",
       "  'topic_words': array(['neural', 'neurons', 'neuroscience', 'computational',\n",
       "         'neuroimaging', 'correlations', 'brain', 'correlated',\n",
       "         'correlation', 'statistical', 'coefficients', '신경망', 'statistics',\n",
       "         'cerebral', 'models', '메모리', 'cognitive', 'memory', 'distributed',\n",
       "         'intelligence', 'dataset', 'functional', '모델', 'functions',\n",
       "         'model', 'interaction', 'traits', 'networks', 'populations', '계산',\n",
       "         'estimates', 'psychology', 'features', 'estimated', 'data',\n",
       "         'modeling', '기능', 'distribution', 'ability', 'individuals',\n",
       "         'interactions', 'midbrain', '관계', 'estimate', 'population',\n",
       "         'probability', 'regression', 'feature', 'alzheimer', 'function'],\n",
       "        dtype='<U15')},\n",
       " {'topic_idx': 14,\n",
       "  'topic_words': array(['neuroimaging', 'neuroscience', 'dopamine', 'neurons', 'neural',\n",
       "         '신경망', 'psychology', 'cognitive', 'researchers', 'correlation',\n",
       "         'correlated', 'correlations', 'adhd', 'anxiety', 'interaction',\n",
       "         'behavioral', 'depression', 'behavioural', '연구', 'interactions',\n",
       "         'mental', 'rewards', 'disorders', 'activities', 'hippocampus',\n",
       "         'studies', 'activity', 'brain', 'midbrain', 'functions',\n",
       "         'intelligence', 'reward', 'cerebral', 'behaviors', 'ventral',\n",
       "         'functional', 'disorder', 'traits', 'interest', 'behavior',\n",
       "         'emotional', '기능', 'selection', 'alzheimer', 'depressive',\n",
       "         'function', 'effects', 'scientists', 'scientific', 'research'],\n",
       "        dtype='<U15')},\n",
       " {'topic_idx': 15,\n",
       "  'topic_words': array(['github', 'git', 'commit', 'account', '구글', 'development',\n",
       "         'tensorflow', 'project', '개발', 'email', 'kwargs', 'problems', '문제',\n",
       "         'localhost', 'delayed', 'problem', 'environment', '코드', 'dataset',\n",
       "         '기본', 'projected', '우분투', 'issues', 'ubuntu', 'default', 'disease',\n",
       "         'environmental', '변수', 'delay', 'changes', '코딩', 'code',\n",
       "         'community', 'kernel', 'encoding', 'coding', 'ssh', '변화', 'issue',\n",
       "         'variables', 'foldername', 'google', 'significant', 'covariance',\n",
       "         'feature', 'regression', 'disorders', 'neuroscience', 'we',\n",
       "         'terms'], dtype='<U15')},\n",
       " {'topic_idx': 16,\n",
       "  'topic_words': array(['correlations', 'correlation', 'correlated', 'covariance',\n",
       "         'probability', 'genetic', 'statistical', 'variance', '유전자',\n",
       "         'statistics', 'populations', '관계', 'relationship', 'pairs',\n",
       "         'relative', 'dataset', 'twin', 'distributed', 'models',\n",
       "         'coefficients', 'related', 'regression', '모델', 'traits',\n",
       "         'distribution', '관련', 'interactions', 'interaction', 'modeling',\n",
       "         'model', 'population', 'associated', 'data', 'connectivity',\n",
       "         'integration', 'groups', 'shared', '데이터', 'variables', 'species',\n",
       "         'individuals', 'individual', 'generation', 'estimated',\n",
       "         'comparisons', 'estimate', '회귀분석', 'pairwise', 'estimates',\n",
       "         'predict'], dtype='<U15')},\n",
       " {'topic_idx': 17,\n",
       "  'topic_words': array(['browser', 'chrome', 'firefox', 'mozilla', 'html', 'analytics',\n",
       "         'safari', '사이트', 'github', 'learning', 'xorg', 'web', 'site',\n",
       "         'analyses', 'matlab', 'page', 'learn', 'bmatrix', '구글', 'ctrl',\n",
       "         '페이지', 'mxpath', 'url', 'numpy', 'useful', 'algorithm', 'assess',\n",
       "         'analysis', '학습', 'comparisons', 'methods', 'tutorial',\n",
       "         'parameters', '변수', 'compare', 'computational', 'better',\n",
       "         'optimization', 'cognitive', 'statistics', 'dataset', 'processes',\n",
       "         '파이썬', 'log', 'google', 'online', 'python', 'compared',\n",
       "         'improvements', 'regression'], dtype='<U15')},\n",
       " {'topic_idx': 18,\n",
       "  'topic_words': array(['statistical', 'dataset', 'covariance', 'statistics',\n",
       "         'coefficients', 'probability', 'distribution', 'computational',\n",
       "         'correlations', 'distributed', 'variance', 'correlation', 'numpy',\n",
       "         'matlab', 'data', 'populations', 'algorithm', 'correlated', '데이터',\n",
       "         'regression', '회귀분석', '계산', 'population', '행렬', 'random',\n",
       "         'variables', 'tensorflow', 'comparisons', 'optimization', 'mathbf',\n",
       "         'groups', 'estimated', 'python', 'estimate', 'estimates', 'factor',\n",
       "         '변수', 'compare', 'group', 'function', 'predict', 'functions', '관계',\n",
       "         'networks', '비교', 'mathrm', 'integration', 'neurons', 'sample',\n",
       "         'relationship'], dtype='<U15')},\n",
       " {'topic_idx': 19,\n",
       "  'topic_words': array(['genetic', '유전자', 'selection', 'populations', 'correlated',\n",
       "         'groups', 'traits', 'statistical', 'probability', 'variance',\n",
       "         'correlations', 'correlation', 'generation', 'group', 'risk',\n",
       "         'distributed', 'alzheimer', 'statistics', 'individuals',\n",
       "         'population', 'distribution', 'dataset', '생성', 'individual',\n",
       "         'template', '세대주', 'factors', 'adhd', 'species', 'neuroimaging',\n",
       "         'available', 'neuroscience', '데이터', 'regression', 'increased',\n",
       "         'parameters', 'team', 'born', 'data', 'select', 'models',\n",
       "         'researchers', 'special', 'discounting', 'export', 'scientific',\n",
       "         'published', 'factor', 'additional', 'relative'], dtype='<U15')},\n",
       " {'topic_idx': 20,\n",
       "  'topic_words': array(['variance', 'covariance', 'statistical', 'correlation',\n",
       "         'statistics', 'regression', 'correlations', 'variables', '변수',\n",
       "         'probability', 'variable', 'coefficients', 'correlated', '회귀분석',\n",
       "         'estimated', 'estimate', 'estimates', 'significance', 'dataset',\n",
       "         'relative', 'predict', 'parameters', '관계', 'relationship', 'data',\n",
       "         '예측', 'computational', 'factor', 'populations', 'distribution',\n",
       "         'independent', 'tensorflow', 'interaction', 'comparisons',\n",
       "         'interactions', 'parameter', 'means', 'numpy', 'distributed',\n",
       "         'dependent', 'population', 'differences', '데이터', 'information',\n",
       "         'average', '모델', 'values', 'difference', 'scale', 'inference'],\n",
       "        dtype='<U15')},\n",
       " {'topic_idx': 21,\n",
       "  'topic_words': array(['tensorflow', 'ubuntu', '우분투', 'github', 'xorg', 'linux', 'nvidia',\n",
       "         'sudo', 'installed', 'kernel', 'numpy', 'install', 'installing',\n",
       "         'localhost', 'python', 'gpu', 'installation', 'vtk', 'kwargs',\n",
       "         '설치', 'mxpath', 'matlab', 'nipype', 'distribution', 'cuda', 'pip',\n",
       "         'package', 'cpu', 'hippocampus', 'packages', 'mozilla', 'openmx',\n",
       "         'firefox', '패키지', 'amygdala', 'safari', 'integration', 'directory',\n",
       "         'usb', 'lib', '리눅스', 'apk', '파이썬', 'distributed', 'community',\n",
       "         'source', 'library', 'hippocampal', 'tigger', '드라이버'], dtype='<U15')},\n",
       " {'topic_idx': 22,\n",
       "  'topic_words': array(['mathbf', 'mathrm', 'computational', 'matlab', '방정식',\n",
       "         'coefficients', '계산', 'mxalgebra', 'sum', 'functions', 'linear',\n",
       "         'function', 'algorithm', 'integers', 'bmatrix', '그래픽', 'graphics',\n",
       "         'sigma', 'alzheimer', 'square', 'statistics', 'convex',\n",
       "         'regression', 'matrix', 'statistical', 'tensorflow', 'estimated',\n",
       "         'solve', '회귀분석', 'datetime', 'representation', '평면', '메모리',\n",
       "         'estimate', 'optimization', 'defined', 'memory', 'correlation',\n",
       "         'displaystyle', 'integration', 'probability', 'representations',\n",
       "         'functional', '행렬', 'gradient', 'predict', 'numpy', 'dataset',\n",
       "         'define', 'estimates'], dtype='<U15')},\n",
       " {'topic_idx': 23,\n",
       "  'topic_words': array(['neural', 'neuroscience', 'neurons', 'technology', 'neuroimaging',\n",
       "         'cognitive', '신경망', 'humans', 'brain', 'intelligence',\n",
       "         'artificial', 'algorithm', '기술', 'networks', 'computational', '인간',\n",
       "         'psychology', 'network', 'ability', 'concepts', 'cerebral',\n",
       "         'alzheimer', 'web', 'anova', 'scientists', 'coding', 'human',\n",
       "         'github', 'systems', '기능', 'computer', 'patients', 'researchers',\n",
       "         'knowledge', 'interaction', 'browser', '가능', 'traits', 'cortex',\n",
       "         'science', 'possible', '개념', 'functional', '시스템', 'mxpath', '과학',\n",
       "         'interactions', 'theoretical', 'android', 'matlab'], dtype='<U15')},\n",
       " {'topic_idx': 24,\n",
       "  'topic_words': array(['women', 'gender', 'men', 'scientists', 'environmental',\n",
       "         'environment', 'researchers', 'statistics', 'studies', 'groups',\n",
       "         'scientific', 'correlations', 'values', 'statistical',\n",
       "         'correlation', 'findings', 'subjects', 'levels', 'differences',\n",
       "         '연구', 'populations', 'study', 'comparisons', 'science', '교수',\n",
       "         'student', 'students', '관계', 'rate', 'psychology', 'inference',\n",
       "         'preference', 'neuroscience', 'relationship', 'compared',\n",
       "         'correlated', 'latent', '기간', 'adolescents', 'polyamor', 'sex',\n",
       "         'she', 'degree', 'emotional', 'rewards', 'difference', 'variance',\n",
       "         'bias', 'estimated', 'research'], dtype='<U15')},\n",
       " {'topic_idx': 25,\n",
       "  'topic_words': array(['author', 'authors', 'novel', 'scientists', 'emotional', 'read',\n",
       "         '과학', '이야기', 'neuroscience', '아니', 'non', 'intelligence', 'write',\n",
       "         'book', 'gatsby', '없이', 'human', 'science', 'no', 'written',\n",
       "         'published', 'without', 'end', '교수', 'humans', 'scientific', '아닌',\n",
       "         '인간', 'sem', 'person', 'args', 'latent', 'none', 'deep', 'self',\n",
       "         'midbrain', '사람', 'neurons', 'born', 'not', 'close', 'special',\n",
       "         'arguments', 'subject', '라는', 'independent', 'mind', 'ability',\n",
       "         'artificial', 'labels'], dtype='<U15')},\n",
       " {'topic_idx': 26,\n",
       "  'topic_words': array(['mental', 'neuroscience', 'neurons', 'psychology', 'depression',\n",
       "         'brain', 'cognitive', 'neuroimaging', 'neural', 'intelligence',\n",
       "         'depressive', 'cerebral', 'midbrain', 'alzheimer', 'disorders',\n",
       "         '신경망', 'disorder', 'populations', 'anxiety', 'groups', 'traits',\n",
       "         'correlation', 'correlations', 'stress', 'hippocampus',\n",
       "         'researchers', 'correlated', 'dementia', 'adhd', 'mind', 'social',\n",
       "         'behavioural', 'symptoms', 'emotional', 'behavioral', 'disease',\n",
       "         'group', 'factors', 'dopamine', 'scientific', 'clinical',\n",
       "         'genetic', 'scientists', 'statistics', 'studies', '연구',\n",
       "         'population', '유전자', 'individuals', 'ability'], dtype='<U15')},\n",
       " {'topic_idx': 27,\n",
       "  'topic_words': array(['tutorial', '강의', '학습', 'introduction', 'tensorflow', 'learning',\n",
       "         'students', 'student', 'training', 'class', '과정', 'learn',\n",
       "         'trained', 'openmx', 'technology', 'neural', 'school', '기술', '러닝',\n",
       "         'guide', 'subjects', 'pdf', 'preprocessing', 'begin',\n",
       "         'theoretical', 'neuroscience', 'source', 'university', 'start',\n",
       "         'course', 'open', 'derived', 'concepts', '교수', 'manual', 'methods',\n",
       "         'approaches', 'subject', 'startvar', 'processes', 'train',\n",
       "         'computational', 'sneakers', 'extraction', 'college', '시작',\n",
       "         'knowledge', 'understanding', 'processing', '메소드'], dtype='<U15')},\n",
       " {'topic_idx': 28,\n",
       "  'topic_words': array(['depression', 'depressive', 'adhd', 'symptoms', 'disorders',\n",
       "         'disorder', 'psychology', 'mental', 'dopamine', 'cognitive',\n",
       "         'clinical', 'correlation', 'statistical', 'dementia',\n",
       "         'behavioural', 'statistics', 'emotional', 'correlations',\n",
       "         'anxiety', 'behavioral', 'impairment', 'alzheimer', 'neuroimaging',\n",
       "         'mood', 'coefficients', 'correlated', 'patients', '영향', 'traits',\n",
       "         'populations', 'groups', 'disease', 'behaviors', 'effects',\n",
       "         'stress', 'behavior', 'population', 'neuroscience', 'social',\n",
       "         'variance', 'effect', 'interaction', 'neurons', 'group', '신경망',\n",
       "         'regression', 'cerebral', 'dataset', 'labels', 'probability'],\n",
       "        dtype='<U15')},\n",
       " {'topic_idx': 29,\n",
       "  'topic_words': array(['encoding', 'utf', '코딩', 'python', 'coding', '인코딩', '파이썬', 'html',\n",
       "         'string', '코드', 'code', '변수', 'function', 'url', 'variables',\n",
       "         'kwargs', 'numpy', 'localhost', 'integers', 'variable', 'output',\n",
       "         'language', '변환', 'functions', 'github', 'algorithm', 'command',\n",
       "         'keyword', 'tensorflow', 'script', 'py', '명령어', 'textrm', '명령',\n",
       "         'args', 'mxpath', 'input', 'fmriprep', 'print', 'renaming',\n",
       "         'problems', '출력', 'solve', 'expr', 'error', 'convert', 'array',\n",
       "         '방정식', '언어', 'prefix'], dtype='<U15')},\n",
       " {'topic_idx': 30,\n",
       "  'topic_words': array(['neuroscience', '과학', 'scientists', 'science', 'scientific',\n",
       "         'neurons', 'magnetic', 'neuroimaging', 'neural', '신경망', 'nucleus',\n",
       "         'theoretical', 'researchers', 'brain', 'theory', 'alzheimer',\n",
       "         'intelligence', 'psychology', 'small', 'technology', 'cerebral',\n",
       "         'university', 'mind', 'new', 'physical', 'nouveau', 'kernel',\n",
       "         'midbrain', 'little', 'lab', 'possible', 'sneakers', 'integers',\n",
       "         'computational', 'resonance', 'computer', 'genetic', 'matlab',\n",
       "         'hippocampus', 'students', 'coding', 'networks', 'subjects',\n",
       "         'probability', 'matter', 'college', 'algorithm', 'ability',\n",
       "         'complex', 'patients'], dtype='<U15')},\n",
       " {'topic_idx': 31,\n",
       "  'topic_words': array(['published', 'university', 'documents', 'document', '교수',\n",
       "         'library', 'authors', 'author', 'book', 'pdf', 'degree', 'college',\n",
       "         'study', 'copy', 'papers', 'student', 'institute', '학습',\n",
       "         'stanford', 'students', 'studies', 'psychology', 'school',\n",
       "         'written', 'paper', 'source', 'support', 'apply', 'utf', '과정',\n",
       "         'applied', '지원', 'novel', 'application', 'article', 'programs',\n",
       "         '교육', 'disorders', '프로그램', 'full', 'supporting', 'subjects',\n",
       "         'foundation', 'template', 'learning', 'adhd', 'applications',\n",
       "         'useful', 'benefit', 'manual'], dtype='<U15')},\n",
       " {'topic_idx': 32,\n",
       "  'topic_words': array(['alzheimer', 'brain', 'midbrain', 'scientific', 'measures',\n",
       "         'behavioral', '과학', 'scientists', 'practice', '적용', 'method',\n",
       "         'gata', 'activities', 'amygdala', 'memory', 'ability', 'treatment',\n",
       "         'methods', 'normal', 'cerebral', 'science', '행동', 'renaming',\n",
       "         'cognitive', 'known', 'activation', '한글', 'activity', 'effective',\n",
       "         'caudate', 'specific', 'cells', 'process', 'resonance', 'dementia',\n",
       "         'works', 'actually', 'hippocampus', 'behavior', 'just',\n",
       "         'behavioural', 'common', 'work', 'behaviors', 'really', 'body',\n",
       "         'evidence', 'anxiety', '메모리', 'application'], dtype='<U15')},\n",
       " {'topic_idx': 33,\n",
       "  'topic_words': array(['access', 'article', 'library', 'pdf', 'options', 'side', '옵션',\n",
       "         'available', 'option', 'documents', 'document', '기술', 'genetic',\n",
       "         '유전자', 'technology', 'psychology', 'allows', '여기', 'items', 'left',\n",
       "         'author', 'published', 'here', '연구', 'blog', 'disease',\n",
       "         'conditions', 'mxpath', 'space', 'authors', 'dementia', 'able',\n",
       "         'cerebral', 'supporting', 'policy', '파티션', 'these', 'humans',\n",
       "         'section', 'disorders', 'part', '아래', 'support', '가능', 'alzheimer',\n",
       "         'depression', 'environmental', 'social', '인간', 'environment'],\n",
       "        dtype='<U15')},\n",
       " {'topic_idx': 34,\n",
       "  'topic_words': array(['documents', 'application', '대출', 'applications', 'apply',\n",
       "         'document', 'applied', '적용', '세대주', 'benefit', 'app',\n",
       "         'preprocessing', 'registration', 'account', 'previous', '대부분',\n",
       "         'age', 'alt', 'form', '일반', '청년', 'building', 'primary', 'phase',\n",
       "         'generation', 'evidence', 'multiple', 'college', 'population',\n",
       "         'papers', 'interest', 'sequence', 'term', '한지', 'contribution',\n",
       "         'university', 'foundation', 'process', '기본', 'scores', 'terms',\n",
       "         'default', 'processes', 'common', 'populations', 'general', 'hypo',\n",
       "         'degree', 'levels', 'life'], dtype='<U15')},\n",
       " {'topic_idx': 35,\n",
       "  'topic_words': array(['name', '이름', 'foldername', 'numpy', 'python', '변수', 'renaming',\n",
       "         'keyword', 'variables', 'self', 'utf', 'function', 'class',\n",
       "         'individual', '파이썬', 'auto', 'instance', 'variable', 'object',\n",
       "         'called', '메소드', 'prefix', 'functions', '객체', 'individuals',\n",
       "         'kwargs', 'create', 'objects', 'training', 'traits', 'university',\n",
       "         'ability', 'functional', 'term', 'creating', 'define', 'feature',\n",
       "         'title', 'dataset', 'modeling', '기능', 'address', 'itself', '코딩',\n",
       "         'alzheimer', 'quality', 'weight', 'features', 'stanford', 'nature'],\n",
       "        dtype='<U15')},\n",
       " {'topic_idx': 36,\n",
       "  'topic_words': array(['matlab', 'ssh', 'github', 'computational', '우분투', 'linux',\n",
       "         'numpy', 'python', 'ubuntu', 'ylab', 'remote', 'localhost', 'port',\n",
       "         'command', 'script', '명령', '명령어', 'usb', 'program', '파이썬', 'input',\n",
       "         'bmatrix', 'software', 'inputs', 'ip', 'xorg', 'computer',\n",
       "         'openmx', 'dataset', 'lab', 'connectivity', 'output', 'sudo',\n",
       "         'html', 'tool', 'postaladdress', 'tutorial', 'tools', 'kernel',\n",
       "         'data', 'tensorflow', '접속', 'ctrl', 'array', 'experiment',\n",
       "         'programs', 'algorithm', 'theoretical', '메소드', 'module'],\n",
       "        dtype='<U15')},\n",
       " {'topic_idx': 37,\n",
       "  'topic_words': array(['kwargs', 'args', 'numpy', 'python', 'integers', '파이썬', 'list',\n",
       "         'parameter', 'parameters', 'function', '변수', 'functions',\n",
       "         'command', '명령어', 'keyword', '명령', 'arguments', 'variables',\n",
       "         'computational', 'terms', 'array', 'mathrm', 'script', 'algorithm',\n",
       "         'foldername', 'textrm', 'prefix', 'answer', 'optimization',\n",
       "         'functional', 'sudo', 'nipype', 'variable', 'useful', 'expr',\n",
       "         'tasks', '코딩', 'renaming', 'questions', 'mathbf', 'coefficients',\n",
       "         'ability', 'matlab', 'responses', 'name', 'intelligence',\n",
       "         'methods', 'applications', 'define', 'sequence'], dtype='<U15')},\n",
       " {'topic_idx': 38,\n",
       "  'topic_words': array(['python', 'preprocessing', 'processes', '파이썬', 'numpy', 'process',\n",
       "         'function', '프로세스', 'args', '변수', 'functions', 'processing',\n",
       "         'kwargs', '처리', 'tensorflow', '과정', 'import', 'integers', '코딩',\n",
       "         'treatment', 'functional', '기능', 'program', 'variable',\n",
       "         'variables', 'output', 'parameter', 'computational', 'func',\n",
       "         'matlab', 'tasks', 'step', 'important', 'print', 'cpu', '실행',\n",
       "         'coding', 'array', '출력', 'py', 'parameters', 'sequence', 'nucleus',\n",
       "         '메모리', 'pip', 'algorithm', 'linux', 'module', 'programs', 'task'],\n",
       "        dtype='<U15')},\n",
       " {'topic_idx': 39,\n",
       "  'topic_words': array(['dataset', 'statistical', 'statistics', 'models', 'predict',\n",
       "         'data', '모델', 'model', 'regression', '데이터', 'sample',\n",
       "         'probability', 'samples', 'numpy', 'populations', 'patients', '예측',\n",
       "         'modeling', 'preprocessing', 'patterns', 'documents', 'individual',\n",
       "         'distribution', 'pattern', 'template', 'variance', 'distributed',\n",
       "         'parameters', 'population', 'individuals', 'variables',\n",
       "         'tensorflow', 'values', 'files', 'estimates', 'random',\n",
       "         'correlation', 'correlations', 'pdf', 'estimated', 'traits', '파일',\n",
       "         'import', 'document', 'future', 'information', 'estimate',\n",
       "         'coefficients', 'analyses', 'expected'], dtype='<U15')},\n",
       " {'topic_idx': 40,\n",
       "  'topic_words': array(['dataset', 'statistics', 'analytics', 'statistical', 'data',\n",
       "         'analysis', '데이터', 'correlations', 'analyses', 'matlab', '회귀분석',\n",
       "         'correlation', 'computational', '분석', 'coefficients', 'regression',\n",
       "         'correlated', 'tools', 'tensorflow', 'integration', 'useful',\n",
       "         'estimates', 'parameters', '예측', 'numpy', 'tool', 'linear',\n",
       "         'tutorial', 'predict', 'samples', '과정', 'training', 'estimate',\n",
       "         '학습', 'parameter', 'estimated', 'sample', 'values', 'datetime',\n",
       "         'module', 'index', 'variables', 'optimization', 'class', 'github',\n",
       "         'functions', 'scale', '계산', 'future', 'learning'], dtype='<U15')},\n",
       " {'topic_idx': 41,\n",
       "  'topic_words': array(['blog', 'html', 'gatsby', 'url', 'template', 'page', '페이지', 'path',\n",
       "         'github', 'localhost', 'write', 'author', 'mxpath', 'needed',\n",
       "         'necessary', 'paths', 'integration', 'function', 'written',\n",
       "         'functions', 'designed', 'load', 'functional', 'utf', 'need',\n",
       "         'published', 'include', 'optimization', 'important', 'begin',\n",
       "         'site', 'with', 'access', 'guide', 'gradient', 'index', 'article',\n",
       "         'by', 'web', 'title', 'analytics', 'mit', 'component', 'to', 'add',\n",
       "         'useful', 'profile', 'use', 'using', 'authors'], dtype='<U15')},\n",
       " {'topic_idx': 42,\n",
       "  'topic_words': array(['statistical', 'probability', 'statistics', 'covariance',\n",
       "         'coefficients', 'variance', 'sample', 'distribution', 'samples',\n",
       "         'distributed', 'random', 'correlations', 'correlation',\n",
       "         'populations', 'regression', 'variables', 'cases', 'comparisons',\n",
       "         'population', '변수', 'predict', 'tensorflow', 'computational',\n",
       "         'numpy', 'bias', 'examples', 'sigma', 'correlated', 'compare',\n",
       "         'sequence', 'groups', 'estimated', 'sum', 'instance', 'variable',\n",
       "         '회귀분석', 'estimate', 'example', 'optimization', 'compared', '비교',\n",
       "         'conditions', 'often', 'estimates', 'participants', 'rate',\n",
       "         'algorithm', 'consistent', 'mathbf', 'group'], dtype='<U15')},\n",
       " {'topic_idx': 43,\n",
       "  'topic_words': array(['neurons', 'neuroimaging', 'neural', 'neuroscience', '신경망',\n",
       "         'brain', 'nucleus', 'midbrain', 'cerebral', 'cells', 'cell',\n",
       "         'functions', 'hippocampus', 'module', 'movement', 'disorders',\n",
       "         'interaction', 'interactions', 'basal', 'motor', 'internal', '기능',\n",
       "         'activation', 'function', 'cognitive', 'functional', 'mental',\n",
       "         'symptoms', 'disorder', 'alzheimer', 'ventral', 'genetic',\n",
       "         'development', 'ability', 'potential', 'traits', 'features',\n",
       "         'correlated', 'psychology', 'regions', 'mind', 'feature',\n",
       "         'magnetic', 'intelligence', 'func', 'areas', 'disease', 'factors',\n",
       "         'negative', 'memory'], dtype='<U15')},\n",
       " {'topic_idx': 44,\n",
       "  'topic_words': array(['xorg', 'ubuntu', 'nvidia', 'sudo', 'gpu', 'kernel', 'linux',\n",
       "         '우분투', '그래픽', 'graphics', 'cpu', '드라이버', 'tensorflow', 'grub',\n",
       "         'driver', '부팅', 'install', 'desktop', 'boot', 'problem', '리눅스',\n",
       "         '윈도우', 'installed', 'fix', 'kwargs', 'github', 'firefox', 'ctrl',\n",
       "         'textrm', 'windows', 'installing', 'command', 'fixed', 'openmx',\n",
       "         'matlab', 'root', '화면', 'startvar', '명령', 'apt', 'arxiv', 'args',\n",
       "         'vtk', '문제', 'problems', 'alt', 'issue', 'latest', 'pain',\n",
       "         'derived'], dtype='<U15')},\n",
       " {'topic_idx': 45,\n",
       "  'topic_words': array(['adhd', 'children', 'disorder', 'disorders', 'adolescents',\n",
       "         'cognitive', 'traits', 'clinical', 'born', 'sd', 'emotional',\n",
       "         'dementia', 'midbrain', 'correlation', 'genetic', 'generation',\n",
       "         'mental', 'cerebral', 'age', 'september', 'correlated', 'abc',\n",
       "         'symptoms', 'correlations', 'alzheimer', 'dopamine', 'identify',\n",
       "         'relative', 'ad', 'neuroscience', 'young', 'disease', 'rate',\n",
       "         'cdt', 'development', '데이터', 'students', 'cdh', 'behavioural',\n",
       "         'twin', 'patients', 'neuroimaging', '유전자', 'directory', 'defined',\n",
       "         'variance', 'impairment', 'mdd', 'index', 'differences'],\n",
       "        dtype='<U15')},\n",
       " {'topic_idx': 46,\n",
       "  'topic_words': array(['nvidia', 'xorg', 'ubuntu', 'kernel', 'linux', 'gpu', 'sudo',\n",
       "         '우분투', 'driver', 'grub', '드라이버', '부팅', 'boot', 'tensorflow', 'vtk',\n",
       "         'cpu', 'command', 'windows', '윈도우', 'openmx', 'run', 'installed',\n",
       "         'github', 'fix', 'firefox', 'help', 'matlab', 'runs', 'fixed',\n",
       "         'install', 'running', 'give', 'mode', 'trying', 'startvar', '명령',\n",
       "         'installing', 'let', 'problem', '실행', 'remove', 'solve', 'numpy',\n",
       "         'enter', 'got', 'graphics', 'solution', 'option', 'having', 'try'],\n",
       "        dtype='<U15')},\n",
       " {'topic_idx': 47,\n",
       "  'topic_words': array(['학습', 'learning', 'learn', 'coding', '교수', 'inference', 'data',\n",
       "         'training', 'disorders', 'error', 'experience', 'computer',\n",
       "         'computational', 'trained', 'impairment', 'institute', 'machine',\n",
       "         'datetime', 'tutorial', 'knowledge', 'performance', 'subjects',\n",
       "         '코딩', 'linux', '과정', 'apply', 'programs', 'dataset', 'behaviors',\n",
       "         'neural', 'study', 'correlated', 'software', '데이터', 'papers',\n",
       "         'college', '프로그램', 'students', 'array', 'behavior', 'models',\n",
       "         'correlations', 'technology', 'command', 'nvidia', 'effects',\n",
       "         'applications', 'documents', 'class', 'student'], dtype='<U15')},\n",
       " {'topic_idx': 48,\n",
       "  'topic_words': array(['independent', '변수', 'variables', '모델', 'variance', 'regression',\n",
       "         'variable', 'covariance', 'models', 'model', 'modeling',\n",
       "         'statistics', 'module', 'statistical', 'parameters',\n",
       "         'coefficients', 'structural', 'probability', 'correlations', '구조',\n",
       "         'relationship', 'individual', '관계', 'dependent', 'correlation',\n",
       "         'separate', 'parameter', 'single', 'structure', 'own',\n",
       "         'correlated', 'pairs', 'interaction', 'interactions', 'analysis',\n",
       "         'template', 'concepts', 'analytics', 'free', 'predict', 'factor',\n",
       "         'sample', 'samples', 'dataset', 'differences', 'estimates', '분석',\n",
       "         'theoretical', 'building', 'distribution'], dtype='<U15')},\n",
       " {'topic_idx': 49,\n",
       "  'topic_words': array(['한글', 'chiang', 'scale', 'major', 'keyword', 'range', '동량', 'grub',\n",
       "         'language', '일반', '언어', 'notes', 'prefix', 'public', '소스', '이야기',\n",
       "         'known', 'general', 'common', 'terms', '러닝', '상관', 'note', '법칙',\n",
       "         'term', '전세', 'process', '법선', 'significance', 'processes', 'open',\n",
       "         'called', 'approach', '부분', 'inference', 'food', 'central',\n",
       "         'region', 'estimated', 'word', '처리', 'volume', 'important', 'area',\n",
       "         'close', 'state', 'processing', 'total', 'gender', 'key'],\n",
       "        dtype='<U15')},\n",
       " {'topic_idx': 50,\n",
       "  'topic_words': array(['회귀분석', '방정식', 'factors', 'theoretical', '예측', 'factor',\n",
       "         'correlations', 'statistical', 'university', 'interest',\n",
       "         'correlation', 'benefit', 'correlated', 'probability',\n",
       "         'statistics', 'activation', '영향', 'variance', 'positive', 'bias',\n",
       "         '파티션', 'experience', 'common', 'activities', '대출', 'theory',\n",
       "         'activity', 'findings', 'experiment', '결과', 'impairment',\n",
       "         'performance', 'effect', 'predict', 'rate', 'scores', 'groups',\n",
       "         'intelligence', 'cognitive', 'negative', 'results', 'papers',\n",
       "         'students', 'expected', '효과', '발생', 'public', 'expr', 'potential',\n",
       "         '학습'], dtype='<U15')},\n",
       " {'topic_idx': 51,\n",
       "  'topic_words': array(['tutorial', 'mv', '학습', 'class', '과정', 'tensorflow', 'programs',\n",
       "         'learning', 'subjects', 'files', 'ubuntu', 'program', 'students',\n",
       "         'learn', '교수', '우분투', '강의', '프로그램', 'student', 'training',\n",
       "         'github', 'software', 'bmatrix', 'linux', 'subject', 'file', '파일',\n",
       "         'trained', 'numpy', 'matlab', 'download', 'university', 'layers',\n",
       "         'ylab', 'module', 'course', 'manual', 'fsl', 'format', 'models',\n",
       "         'college', 'neural', '교육', 'vtk', 'sneakers', 'layer',\n",
       "         'introduction', 'tools', '구글', 'modeling'], dtype='<U15')},\n",
       " {'topic_idx': 52,\n",
       "  'topic_words': array(['concepts', 'computational', 'student', 'design', '디자인',\n",
       "         'neuroscience', 'theoretical', 'designed', 'degree', 'students',\n",
       "         'university', 'similar', '학습', 'experiment', 'physical', '개념',\n",
       "         'school', 'estimated', 'computer', 'ability', 'psychology',\n",
       "         'experience', 'midbrain', 'tests', 'statistical', 'brain', '계산',\n",
       "         '테스트', 'page', 'science', 'estimate', 'study', 'functional',\n",
       "         'assess', 'project', 'class', 'statistics', 'college', 'google',\n",
       "         'stanford', 'none', 'individual', 'html', 'total', 'tutorial',\n",
       "         'theory', 'traits', '교수', 'scores', 'factor'], dtype='<U15')},\n",
       " {'topic_idx': 53,\n",
       "  'topic_words': array(['correlation', 'correlations', 'correlated', 'cognitive',\n",
       "         'interaction', 'connectivity', 'interactions', '관계',\n",
       "         'neuroscience', 'neuroimaging', 'networks', 'coefficients',\n",
       "         'relationship', 'neurons', 'cerebral', 'psychology', 'differences',\n",
       "         'connection', 'neural', 'associated', 'emotional', 'network',\n",
       "         'brain', 'between', 'covariance', 'connections', 'functional',\n",
       "         'comparisons', 'difference', 'traits', 'pairs', '기능', 'related',\n",
       "         'internal', '신경망', 'functions', '비교', 'index', 'behavioural',\n",
       "         'regression', 'compare', 'behaviors', 'separate', 'dependent',\n",
       "         'factor', 'compared', 'intelligence', 'scores', 'association',\n",
       "         'behavioral'], dtype='<U15')},\n",
       " {'topic_idx': 54,\n",
       "  'topic_words': array(['email', 'postaladdress', 'neuroscience', 'scientists', 'address',\n",
       "         'scientific', 'science', 'electronic', '과학', 'interest', 'none',\n",
       "         'neurons', 'send', 'dopamine', 'neural', 'alzheimer',\n",
       "         'neuroimaging', 'magnetic', '교수', 'species', 'ants', '신경망',\n",
       "         'environmental', 'humans', 'cells', 'random', 'space', 'positive',\n",
       "         'nucleus', 'researchers', 'benefit', 'not', 'environment',\n",
       "         'effective', 'individuals', '아닌', 'don', 'psychology', 'message',\n",
       "         'note', 'particular', 'arrows', 'pdf', 'subjects', 'notes',\n",
       "         'specific', 'cell', '메소드', 'no', 'non'], dtype='<U15')},\n",
       " {'topic_idx': 55,\n",
       "  'topic_words': array(['변수', 'variables', 'variance', 'covariance', 'variable',\n",
       "         'regression', 'correlation', 'statistical', 'correlations',\n",
       "         'statistics', 'dataset', 'numpy', '모델', 'models', 'probability',\n",
       "         'tensorflow', 'coefficients', 'parameters', 'model', 'matlab',\n",
       "         'correlated', 'parameter', 'modeling', 'estimates', '관계', 'values',\n",
       "         '회귀분석', 'datetime', 'populations', 'relationship', 'python',\n",
       "         'differences', 'distribution', 'data', 'integration',\n",
       "         'interactions', 'estimated', 'sample', 'samples', 'comparisons',\n",
       "         'computational', 'gender', 'distributed', 'analytics', 'analyses',\n",
       "         'analysis', 'random', 'interaction', 'estimate', '방정식'],\n",
       "        dtype='<U15')},\n",
       " {'topic_idx': 56,\n",
       "  'topic_words': array(['대출', 'account', 'interest', 'services', '전세', 'cell', 'export',\n",
       "         'term', '서비스', 'major', 'service', 'short', 'details', 'benefit',\n",
       "         'lower', 'greater', 'processes', 'neurons', 'low', 'increased',\n",
       "         'cells', '회귀분석', 'clear', 'terms', 'information', 'default', '방정식',\n",
       "         'basal', 'process', 'functions', 'simple', 'depression', 'most',\n",
       "         'multiple', '기본', 'number', 'relative', 'previous', 'options',\n",
       "         'further', 'end', 'preprocessing', 'begin', 'close', '세대주', '대부분',\n",
       "         'alt', 'total', 'sum', 'stanford'], dtype='<U15')},\n",
       " {'topic_idx': 57,\n",
       "  'topic_words': array(['neurons', 'brain', 'neuroscience', 'neural', 'midbrain',\n",
       "         'intelligence', 'mice', 'hippocampus', 'neuroimaging',\n",
       "         'scientists', 'cerebral', 'memory', 'cognitive', '메모리',\n",
       "         'researchers', '신경망', 'nucleus', 'alzheimer', 'study', 'studies',\n",
       "         'computational', 'scientific', '연구', 'cells', 'ants', 'psychology',\n",
       "         '과학', 'science', 'species', 'learning', 'humans', 'lab', '학습',\n",
       "         'populations', 'cell', '계산', 'dopamine', 'research', 'knowledge',\n",
       "         'ability', 'learn', 'dementia', 'mind', 'trained', 'correlations',\n",
       "         'numpy', 'students', 'mental', 'integers', 'module'], dtype='<U15')},\n",
       " {'topic_idx': 58,\n",
       "  'topic_words': array(['numpy', 'hypo', 'statistical', 'hippocampus', 'likelihood',\n",
       "         'coefficients', 'python', 'probability', 'statistics', 'function',\n",
       "         'variance', 'estimated', 'regression', 'functions', 'hippocampal',\n",
       "         'dataset', '파이썬', 'variables', 'computational', 'estimates',\n",
       "         'matlab', 'estimate', '변수', 'variable', 'covariance', 'parameter',\n",
       "         'values', 'algorithm', 'correlations', 'mathbf', 'args',\n",
       "         'parameters', 'similar', 'factor', 'kwargs', 'correlation',\n",
       "         'think', 'data', 'alzheimer', 'sigma', 'auto', 'populations',\n",
       "         'integers', 'rate', 'int', 'model', 'predict', 'self', 'def',\n",
       "         'fmriprep'], dtype='<U15')},\n",
       " {'topic_idx': 59,\n",
       "  'topic_words': array(['neuroscience', 'neuroimaging', 'neural', 'adhd', 'neurons',\n",
       "         'cerebral', 'alzheimer', 'cognitive', '신경망', 'brain', 'correlated',\n",
       "         'correlations', 'correlation', 'midbrain', 'increased',\n",
       "         'distributed', 'module', 'disorders', 'interaction',\n",
       "         'interactions', '메모리', 'memory', 'disorder', 'intelligence',\n",
       "         'distribution', 'development', 'integration', 'psychology',\n",
       "         'regression', 'coefficients', 'ability', 'functional',\n",
       "         'additional', 'variance', 'models', 'functions', '기능', 'dopamine',\n",
       "         'traits', 'variables', 'parameters', 'directory', 'more',\n",
       "         'selection', 'import', '개발', 'parameter', 'connectivity',\n",
       "         'dementia', 'mental'], dtype='<U15')},\n",
       " {'topic_idx': 60,\n",
       "  'topic_words': array(['인간', 'human', 'ability', 'humans', 'mask', 'main', 'traits',\n",
       "         'revealed', 'matrix', '생성', 'name', 'derived', 'species',\n",
       "         'amygdala', 'individuals', 'effects', '기술', '발생', 'types', 'alt',\n",
       "         '사람', 'technology', 'random', 'items', 'enter', 'list', 'role',\n",
       "         'real', '이름', '라는', 'type', 'inputs', 'keyword', 'who', 'caudate',\n",
       "         'major', 'previous', 'significant', 'rank', 'authors', 'special',\n",
       "         'arxiv', 'evidence', 'utf', 'these', 'health', 'meta', 'numpy',\n",
       "         'tigger', 'person'], dtype='<U15')},\n",
       " {'topic_idx': 61,\n",
       "  'topic_words': array(['numpy', 'tensorflow', 'python', 'nipype', 'github', '파이썬',\n",
       "         'ubuntu', 'neural', 'linux', 'computational', 'neurons',\n",
       "         'neuroimaging', 'interactions', '기능', 'dataset', 'functions',\n",
       "         'software', 'correlated', 'introduction', 'neuroscience',\n",
       "         'correlations', 'integration', 'extraction', 'algorithm', 'kernel',\n",
       "         'matlab', 'correlation', 'preprocessing', 'programs', 'functional',\n",
       "         'openmx', 'function', 'xorg', 'interaction', 'features', 'feature',\n",
       "         'relative', 'optimization', 'graphics', '우분투', 'packages',\n",
       "         'applications', 'processes', 'mxpath', '신경망', '프로그램', 'associated',\n",
       "         'program', 'relationship', 'datetime'], dtype='<U15')},\n",
       " {'topic_idx': 62,\n",
       "  'topic_words': array(['apk', 'android', '우분투', '파일', 'jar', 'app', 'github', 'file',\n",
       "         'files', '코딩', 'root', '코드', 'shared', 'localhost', 'component',\n",
       "         'lib', 'ubuntu', 'vtk', 'application', 'similar', 'kernel',\n",
       "         'school', 'port', 'tutorial', '실행', 'integration', 'mozilla',\n",
       "         'instance', 'install', 'installing', 'ip', 'installed', 'url',\n",
       "         '설치', 'covariance', 'foldername', 'source', 'installation',\n",
       "         'class', 'mixture', 'sudo', '구글', 'linux', 'code', 'cp', 'path',\n",
       "         'coding', 'prison', 'extraction', 'method'], dtype='<U15')},\n",
       " {'topic_idx': 63,\n",
       "  'topic_words': array(['alzheimer', 'disease', 'cognitive', '기능', 'neuroimaging',\n",
       "         'disorders', 'dementia', 'disorder', 'symptoms', 'functions',\n",
       "         'memory', 'functional', 'function', 'neurons', 'neuroscience',\n",
       "         'cerebral', 'features', '신경망', '메모리', 'mental', 'brain', 'neural',\n",
       "         'feature', 'impairment', 'ability', 'parameters', 'midbrain',\n",
       "         'depression', 'traits', 'intelligence', 'coefficients', 'hypo',\n",
       "         'anxiety', 'parameter', 'dopamine', 'correlated', 'models',\n",
       "         'correlation', 'condition', 'correlations', 'hippocampus', 'phase',\n",
       "         'concepts', 'psychology', 'module', 'quality', 'mind', 'model',\n",
       "         'discounting', 'associated'], dtype='<U15')},\n",
       " {'topic_idx': 64,\n",
       "  'topic_words': array(['coefficients', 'numpy', 'values', 'dataset', 'variables',\n",
       "         'computational', '변수', 'estimates', 'tensorflow', 'covariance',\n",
       "         'estimated', 'matlab', 'statistics', 'variable', 'variance',\n",
       "         'value', 'statistical', 'estimate', 'correlation', 'anova',\n",
       "         'correlations', 'regression', '모델', 'data', '계산', 'algorithm',\n",
       "         'model', '데이터', 'parameters', 'models', 'parameter', 'openmx',\n",
       "         'mathbf', 'correlated', 'probability', 'optimization', 'modeling',\n",
       "         '회귀분석', 'sum', 'python', '방정식', 'pairs', 'rate', 'assess',\n",
       "         'thanks', 'comparisons', 'factor', '결과', 'aov', 'sigma'],\n",
       "        dtype='<U15')},\n",
       " {'topic_idx': 65,\n",
       "  'topic_words': array(['언어', 'language', 'algorithm', '코딩', 'expr', 'python', '파이썬',\n",
       "         'coding', '수준', 'experience', 'html', 'linux', 'encoding',\n",
       "         'intelligence', 'ubuntu', 'github', 'utf', '코드', 'learning',\n",
       "         'firefox', '한글', 'optimization', 'program', '명령어', 'easily',\n",
       "         'script', '인코딩', 'code', 'level', '드라이버', 'midbrain', 'matlab',\n",
       "         'learn', '학습', '명령', 'neural', 'deep', 'tutorial', 'command',\n",
       "         'keyword', '프로그램', 'motor', 'int', 'expression', '과정', '개발',\n",
       "         'numpy', 'xorg', 'google', 'easy'], dtype='<U15')},\n",
       " {'topic_idx': 66,\n",
       "  'topic_words': array(['comparisons', '비교', 'correlations', 'correlation', 'group',\n",
       "         'groups', 'compare', 'correlated', 'compared', 'statistical',\n",
       "         'covariance', 'variance', 'index', 'statistics', 'relative',\n",
       "         'coefficients', 'average', 'dataset', 'differences', 'distributed',\n",
       "         '관계', 'difference', 'scores', 'based', 'shared', 'pairs',\n",
       "         'associated', 'association', 'among', 'relationship', 'regression',\n",
       "         'individuals', 'significantly', '관련', 'related', 'computational',\n",
       "         'populations', 'distribution', 'pairwise', '회귀분석', 'between',\n",
       "         'primary', 'rate', 'interaction', 'bias', 'significance',\n",
       "         'similar', 'keyword', 'score', 'individual'], dtype='<U15')},\n",
       " {'topic_idx': 67,\n",
       "  'topic_words': array(['nucleus', 'midbrain', 'neurons', 'brain', 'cerebral', 'neural',\n",
       "         'neuroimaging', 'ventral', 'cortex', 'neuroscience', 'hippocampus',\n",
       "         'central', 'core', 'development', '신경망', 'dataset', '개발',\n",
       "         'caudate', 'primary', 'intelligence', 'cognitive', 'alzheimer',\n",
       "         'data', 'basal', 'traits', 'numpy', 'kernel', 'computational',\n",
       "         'cells', 'individuals', 'species', 'internal', 'humans', 'memory',\n",
       "         '데이터', 'mental', 'selection', 'psychology', 'python', 'project',\n",
       "         'index', 'cell', 'module', 'genetic', 'form', 'usb', 'computer',\n",
       "         'adolescents', 'generation', 'mind'], dtype='<U15')},\n",
       " {'topic_idx': 68,\n",
       "  'topic_words': array(['textrm', 'mxalgebra', 'dataset', 'covariance', 'bmatrix',\n",
       "         'matlab', 'mxpath', 'matrix', 'numpy', 'mathrm', 'voxel', 'openmx',\n",
       "         'tensorflow', 'variance', 'name', 'xorg', 'variables', '이름', 'cov',\n",
       "         'renaming', 'regression', 'convex', 'mri', '행렬', '회귀분석', 'arxiv',\n",
       "         'sum', 'integration', 'hippocampal', 'values', 'variable',\n",
       "         'prefix', 'sigma', 'voxels', 'data', 'mixture', 'linear', 'mni',\n",
       "         'mv', 'algorithm', 'terms', 'fmriprep', 'define', 'text',\n",
       "         'hippocampus', 'expression', 'derived', 'term', 'expr', 'keyword'],\n",
       "        dtype='<U15')},\n",
       " {'topic_idx': 69,\n",
       "  'topic_words': array(['python', '파이썬', 'github', 'environment', 'environmental',\n",
       "         'directory', 'pip', 'numpy', 'path', 'paths', '패키지', 'foldername',\n",
       "         'mxpath', 'packages', 'kwargs', 'tensorflow', 'pipeline',\n",
       "         'package', 'localhost', 'installing', 'installed', 'ubuntu', '우분투',\n",
       "         'import', 'installation', '설치', 'files', 'nipype', 'install',\n",
       "         'linux', '변수', '기본', 'default', '파일', 'apk', '명령어', 'parameter',\n",
       "         '명령', 'hippocampal', 'systems', 'dataset', 'command', 'policy',\n",
       "         'firefox', '시스템', 'hippocampus', 'where', 'parameters', 'xorg',\n",
       "         'script'], dtype='<U15')},\n",
       " {'topic_idx': 70,\n",
       "  'topic_words': array(['tensorflow', 'files', '파일', 'mxpath', 'file', 'numpy', 'matlab',\n",
       "         '변환', 'bmatrix', 'format', 'dataset', 'convert', 'foldername',\n",
       "         'parameters', 'github', '인코딩', '변수', 'variable', 'mv', 'nii',\n",
       "         'encoding', 'variables', 'parameter', 'data', 'mxalgebra',\n",
       "         'python', 'import', 'linear', 'kwargs', 'path', 'mni', 'download',\n",
       "         'renaming', 'integers', 'paths', 'reg', 'gradient', '우분투', 'gb',\n",
       "         'mathrm', 'ftd', 'geom', 'measures', 'transform', '데이터', 'openmx',\n",
       "         'inputs', 'behavioural', 'input', 'nipype'], dtype='<U15')},\n",
       " {'topic_idx': 71,\n",
       "  'topic_words': array(['neuroscience', 'neurons', 'neural', 'neuroimaging', 'brain',\n",
       "         '신경망', 'cerebral', 'midbrain', 'cognitive', 'mental', 'memory',\n",
       "         'computational', '메모리', 'psychology', 'nucleus', 'alzheimer',\n",
       "         'concepts', 'mind', 'scientific', 'intelligence', 'theoretical',\n",
       "         'temporal', 'computer', '개념', '과학', 'cortex', 'scientists', 'body',\n",
       "         'science', 'selection', '시간', 'functions', 'theory', 'parameters',\n",
       "         'clinical', 'coefficients', 'objects', 'physical', 'hippocampus',\n",
       "         'internal', 'delayed', 'index', 'humans', '계산', 'datetime',\n",
       "         'ability', 'disorders', 'dementia', 'parameter', 'symptoms'],\n",
       "        dtype='<U15')}]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tm_model.get_topics_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'access',\n",
       " 'account',\n",
       " 'activation',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'add',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'adhd',\n",
       " 'adolescents',\n",
       " 'again',\n",
       " 'age',\n",
       " 'algorithm',\n",
       " 'allows',\n",
       " 'already',\n",
       " 'alt',\n",
       " 'alzheimer',\n",
       " 'among',\n",
       " 'amygdala',\n",
       " 'analyses',\n",
       " 'analysis',\n",
       " 'analytics',\n",
       " 'android',\n",
       " 'anova',\n",
       " 'answer',\n",
       " 'ants',\n",
       " 'anxiety',\n",
       " 'aov',\n",
       " 'apk',\n",
       " 'app',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'applied',\n",
       " 'apply',\n",
       " 'approach',\n",
       " 'approaches',\n",
       " 'apt',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'args',\n",
       " 'arguments',\n",
       " 'array',\n",
       " 'arrows',\n",
       " 'article',\n",
       " 'artificial',\n",
       " 'arxiv',\n",
       " 'assess',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'author',\n",
       " 'authors',\n",
       " 'auto',\n",
       " 'available',\n",
       " 'average',\n",
       " 'basal',\n",
       " 'based',\n",
       " 'begin',\n",
       " 'behavior',\n",
       " 'behavioral',\n",
       " 'behaviors',\n",
       " 'behavioural',\n",
       " 'benefit',\n",
       " 'better',\n",
       " 'between',\n",
       " 'bias',\n",
       " 'blog',\n",
       " 'bmatrix',\n",
       " 'body',\n",
       " 'book',\n",
       " 'boot',\n",
       " 'born',\n",
       " 'brain',\n",
       " 'browser',\n",
       " 'building',\n",
       " 'by',\n",
       " 'called',\n",
       " 'cases',\n",
       " 'caudate',\n",
       " 'cdh',\n",
       " 'cdt',\n",
       " 'cell',\n",
       " 'cells',\n",
       " 'central',\n",
       " 'cerebral',\n",
       " 'changes',\n",
       " 'chiang',\n",
       " 'children',\n",
       " 'chrome',\n",
       " 'class',\n",
       " 'clear',\n",
       " 'clinical',\n",
       " 'close',\n",
       " 'code',\n",
       " 'coding',\n",
       " 'coefficients',\n",
       " 'cognitive',\n",
       " 'college',\n",
       " 'command',\n",
       " 'commit',\n",
       " 'common',\n",
       " 'community',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'comparisons',\n",
       " 'complex',\n",
       " 'component',\n",
       " 'computational',\n",
       " 'computer',\n",
       " 'concepts',\n",
       " 'condition',\n",
       " 'conditions',\n",
       " 'connection',\n",
       " 'connections',\n",
       " 'connectivity',\n",
       " 'consistent',\n",
       " 'contribution',\n",
       " 'convert',\n",
       " 'convex',\n",
       " 'copy',\n",
       " 'core',\n",
       " 'correlated',\n",
       " 'correlation',\n",
       " 'correlations',\n",
       " 'cortex',\n",
       " 'course',\n",
       " 'cov',\n",
       " 'covariance',\n",
       " 'cp',\n",
       " 'cpu',\n",
       " 'create',\n",
       " 'creating',\n",
       " 'ctrl',\n",
       " 'cuda',\n",
       " 'data',\n",
       " 'dataset',\n",
       " 'datetime',\n",
       " 'deep',\n",
       " 'def',\n",
       " 'default',\n",
       " 'define',\n",
       " 'defined',\n",
       " 'degree',\n",
       " 'delay',\n",
       " 'delayed',\n",
       " 'dementia',\n",
       " 'dependent',\n",
       " 'depression',\n",
       " 'depressive',\n",
       " 'derived',\n",
       " 'design',\n",
       " 'designed',\n",
       " 'desktop',\n",
       " 'details',\n",
       " 'development',\n",
       " 'df',\n",
       " 'difference',\n",
       " 'differences',\n",
       " 'directory',\n",
       " 'discounting',\n",
       " 'disease',\n",
       " 'disorder',\n",
       " 'disorders',\n",
       " 'displaystyle',\n",
       " 'distributed',\n",
       " 'distribution',\n",
       " 'document',\n",
       " 'documents',\n",
       " 'don',\n",
       " 'dopamine',\n",
       " 'down',\n",
       " 'download',\n",
       " 'driver',\n",
       " 'dropout',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'effects',\n",
       " 'electronic',\n",
       " 'email',\n",
       " 'emotional',\n",
       " 'encoding',\n",
       " 'end',\n",
       " 'enter',\n",
       " 'environment',\n",
       " 'environmental',\n",
       " 'error',\n",
       " 'estimate',\n",
       " 'estimated',\n",
       " 'estimates',\n",
       " 'evidence',\n",
       " 'example',\n",
       " 'examples',\n",
       " 'expected',\n",
       " 'experience',\n",
       " 'experiment',\n",
       " 'export',\n",
       " 'expr',\n",
       " 'expression',\n",
       " 'extraction',\n",
       " 'factor',\n",
       " 'factors',\n",
       " 'feature',\n",
       " 'features',\n",
       " 'field',\n",
       " 'file',\n",
       " 'files',\n",
       " 'findings',\n",
       " 'firefox',\n",
       " 'fix',\n",
       " 'fixed',\n",
       " 'fmriprep',\n",
       " 'foldername',\n",
       " 'food',\n",
       " 'form',\n",
       " 'format',\n",
       " 'foundation',\n",
       " 'free',\n",
       " 'fsl',\n",
       " 'ftd',\n",
       " 'full',\n",
       " 'func',\n",
       " 'function',\n",
       " 'functional',\n",
       " 'functions',\n",
       " 'further',\n",
       " 'future',\n",
       " 'gata',\n",
       " 'gather',\n",
       " 'gatsby',\n",
       " 'gb',\n",
       " 'gecko',\n",
       " 'gender',\n",
       " 'general',\n",
       " 'generation',\n",
       " 'genetic',\n",
       " 'geom',\n",
       " 'git',\n",
       " 'github',\n",
       " 'give',\n",
       " 'giving',\n",
       " 'google',\n",
       " 'got',\n",
       " 'gpu',\n",
       " 'gradient',\n",
       " 'graphics',\n",
       " 'greater',\n",
       " 'group',\n",
       " 'groups',\n",
       " 'grub',\n",
       " 'guide',\n",
       " 'having',\n",
       " 'health',\n",
       " 'healthy',\n",
       " 'help',\n",
       " 'here',\n",
       " 'hippocampal',\n",
       " 'hippocampus',\n",
       " 'html',\n",
       " 'human',\n",
       " 'humans',\n",
       " 'hypo',\n",
       " 'identify',\n",
       " 'impairment',\n",
       " 'import',\n",
       " 'important',\n",
       " 'improve',\n",
       " 'improvements',\n",
       " 'include',\n",
       " 'increased',\n",
       " 'independent',\n",
       " 'index',\n",
       " 'individual',\n",
       " 'individuals',\n",
       " 'inference',\n",
       " 'information',\n",
       " 'input',\n",
       " 'inputs',\n",
       " 'install',\n",
       " 'installation',\n",
       " 'installed',\n",
       " 'installing',\n",
       " 'instance',\n",
       " 'institute',\n",
       " 'int',\n",
       " 'integers',\n",
       " 'integration',\n",
       " 'intelligence',\n",
       " 'interaction',\n",
       " 'interactions',\n",
       " 'interest',\n",
       " 'internal',\n",
       " 'introduction',\n",
       " 'ip',\n",
       " 'issue',\n",
       " 'issues',\n",
       " 'items',\n",
       " 'itself',\n",
       " 'jar',\n",
       " 'join',\n",
       " 'just',\n",
       " 'kernel',\n",
       " 'key',\n",
       " 'keyword',\n",
       " 'knowledge',\n",
       " 'known',\n",
       " 'kwargs',\n",
       " 'lab',\n",
       " 'labels',\n",
       " 'language',\n",
       " 'latent',\n",
       " 'latest',\n",
       " 'layer',\n",
       " 'layers',\n",
       " 'learn',\n",
       " 'learning',\n",
       " 'left',\n",
       " 'let',\n",
       " 'level',\n",
       " 'levels',\n",
       " 'lib',\n",
       " 'library',\n",
       " 'life',\n",
       " 'likelihood',\n",
       " 'linear',\n",
       " 'linux',\n",
       " 'list',\n",
       " 'little',\n",
       " 'load',\n",
       " 'localhost',\n",
       " 'log',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'machine',\n",
       " 'magnetic',\n",
       " 'main',\n",
       " 'major',\n",
       " 'make',\n",
       " 'making',\n",
       " 'manual',\n",
       " 'mask',\n",
       " 'mathbf',\n",
       " 'mathrm',\n",
       " 'matlab',\n",
       " 'matrix',\n",
       " 'matter',\n",
       " 'mdd',\n",
       " 'means',\n",
       " 'measures',\n",
       " 'memory',\n",
       " 'men',\n",
       " 'mental',\n",
       " 'message',\n",
       " 'meta',\n",
       " 'method',\n",
       " 'methods',\n",
       " 'mice',\n",
       " 'midbrain',\n",
       " 'mind',\n",
       " 'mit',\n",
       " 'mixture',\n",
       " 'mni',\n",
       " 'mode',\n",
       " 'model',\n",
       " 'modeling',\n",
       " 'models',\n",
       " 'module',\n",
       " 'moment',\n",
       " 'mood',\n",
       " 'more',\n",
       " 'most',\n",
       " 'motor',\n",
       " 'movement',\n",
       " 'mozilla',\n",
       " 'mri',\n",
       " 'multiple',\n",
       " 'mv',\n",
       " 'mxalgebra',\n",
       " 'mxpath',\n",
       " 'name',\n",
       " 'nature',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'negative',\n",
       " 'network',\n",
       " 'networks',\n",
       " 'neural',\n",
       " 'neuroimaging',\n",
       " 'neurons',\n",
       " 'neuroscience',\n",
       " 'new',\n",
       " 'nii',\n",
       " 'nipype',\n",
       " 'no',\n",
       " 'non',\n",
       " 'none',\n",
       " 'normal',\n",
       " 'not',\n",
       " 'note',\n",
       " 'notes',\n",
       " 'nouveau',\n",
       " 'novel',\n",
       " 'nucleus',\n",
       " 'number',\n",
       " 'numpy',\n",
       " 'nvidia',\n",
       " 'object',\n",
       " 'objects',\n",
       " 'often',\n",
       " 'online',\n",
       " 'open',\n",
       " 'openmx',\n",
       " 'optimization',\n",
       " 'option',\n",
       " 'options',\n",
       " 'organizations',\n",
       " 'others',\n",
       " 'our',\n",
       " 'output',\n",
       " 'own',\n",
       " 'package',\n",
       " 'packages',\n",
       " 'page',\n",
       " 'pain',\n",
       " 'pairs',\n",
       " 'pairwise',\n",
       " 'paper',\n",
       " 'papers',\n",
       " 'parameter',\n",
       " 'parameters',\n",
       " 'part',\n",
       " 'participants',\n",
       " 'particular',\n",
       " 'path',\n",
       " 'paths',\n",
       " 'patients',\n",
       " 'pattern',\n",
       " 'patterns',\n",
       " 'pdf',\n",
       " 'people',\n",
       " 'performance',\n",
       " 'person',\n",
       " 'phase',\n",
       " 'physical',\n",
       " 'pip',\n",
       " 'pipeline',\n",
       " 'plot',\n",
       " 'plots',\n",
       " 'policy',\n",
       " 'polyamor',\n",
       " 'population',\n",
       " 'populations',\n",
       " 'port',\n",
       " 'positive',\n",
       " 'possible',\n",
       " 'postaladdress',\n",
       " 'potential',\n",
       " 'practice',\n",
       " 'predict',\n",
       " 'preference',\n",
       " 'prefix',\n",
       " 'preprocessing',\n",
       " 'previous',\n",
       " 'primary',\n",
       " 'print',\n",
       " 'prison',\n",
       " 'probability',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'process',\n",
       " 'processes',\n",
       " 'processing',\n",
       " 'profile',\n",
       " 'program',\n",
       " 'programs',\n",
       " 'project',\n",
       " 'projected',\n",
       " 'provide',\n",
       " 'provides',\n",
       " 'psychology',\n",
       " 'public',\n",
       " 'published',\n",
       " 'py',\n",
       " 'python',\n",
       " 'quality',\n",
       " 'questions',\n",
       " 'random',\n",
       " 'range',\n",
       " 'rank',\n",
       " 'rate',\n",
       " 'read',\n",
       " 'real',\n",
       " 'really',\n",
       " 'recent',\n",
       " 'reg',\n",
       " 'region',\n",
       " 'regions',\n",
       " 'registration',\n",
       " 'regression',\n",
       " 'related',\n",
       " 'relationship',\n",
       " 'relative',\n",
       " 'remote',\n",
       " 'remove',\n",
       " 'renaming',\n",
       " 'representation',\n",
       " 'representations',\n",
       " 'request',\n",
       " 'requests',\n",
       " 'research',\n",
       " 'researchers',\n",
       " 'resonance',\n",
       " 'response',\n",
       " 'responses',\n",
       " 'results',\n",
       " 'revealed',\n",
       " 'reward',\n",
       " 'rewards',\n",
       " 'risk',\n",
       " 'role',\n",
       " 'root',\n",
       " 'run',\n",
       " 'running',\n",
       " 'runs',\n",
       " 'safari',\n",
       " 'sample',\n",
       " 'samples',\n",
       " 'scale',\n",
       " 'school',\n",
       " 'science',\n",
       " 'scientific',\n",
       " 'scientists',\n",
       " 'score',\n",
       " 'scores',\n",
       " 'script',\n",
       " 'sd',\n",
       " 'section',\n",
       " 'select',\n",
       " 'selection',\n",
       " 'self',\n",
       " 'sem',\n",
       " 'send',\n",
       " 'separate',\n",
       " 'september',\n",
       " 'sequence',\n",
       " 'service',\n",
       " 'services',\n",
       " 'sex',\n",
       " 'shared',\n",
       " 'she',\n",
       " 'short',\n",
       " 'show',\n",
       " 'shows',\n",
       " 'side',\n",
       " 'sigma',\n",
       " 'significance',\n",
       " 'significant',\n",
       " 'significantly',\n",
       " 'similar',\n",
       " 'simple',\n",
       " 'single',\n",
       " 'site',\n",
       " 'small',\n",
       " 'sneakers',\n",
       " 'social',\n",
       " 'software',\n",
       " 'solution',\n",
       " 'solve',\n",
       " 'source',\n",
       " 'space',\n",
       " 'special',\n",
       " 'species',\n",
       " 'specific',\n",
       " 'specify',\n",
       " 'square',\n",
       " 'ssh',\n",
       " 'stanford',\n",
       " 'start',\n",
       " 'startvar',\n",
       " 'state',\n",
       " 'states',\n",
       " 'statistical',\n",
       " 'statistics',\n",
       " 'step',\n",
       " 'stress',\n",
       " 'string',\n",
       " 'structural',\n",
       " 'structure',\n",
       " 'student',\n",
       " 'students',\n",
       " 'studies',\n",
       " 'study',\n",
       " 'subject',\n",
       " 'subjects',\n",
       " 'sudo',\n",
       " 'sum',\n",
       " 'summary',\n",
       " 'support',\n",
       " 'supporting',\n",
       " 'symptoms',\n",
       " 'system',\n",
       " 'systems',\n",
       " 'task',\n",
       " 'tasks',\n",
       " 'team',\n",
       " 'technology',\n",
       " 'template',\n",
       " 'temporal',\n",
       " 'tensorflow',\n",
       " 'term',\n",
       " 'terms',\n",
       " 'tests',\n",
       " 'text',\n",
       " 'textrm',\n",
       " 'thanks',\n",
       " 'theoretical',\n",
       " 'theory',\n",
       " 'these',\n",
       " 'think',\n",
       " 'tigger',\n",
       " 'title',\n",
       " 'to',\n",
       " 'tool',\n",
       " 'tools',\n",
       " 'total',\n",
       " 'train',\n",
       " 'trained',\n",
       " 'training',\n",
       " 'traits',\n",
       " 'transform',\n",
       " 'treatment',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'tutorial',\n",
       " 'twin',\n",
       " 'type',\n",
       " 'types',\n",
       " 'ubuntu',\n",
       " 'understand',\n",
       " 'understanding',\n",
       " 'university',\n",
       " 'url',\n",
       " 'us',\n",
       " 'usb',\n",
       " 'use',\n",
       " 'useful',\n",
       " 'using',\n",
       " 'utf',\n",
       " 'value',\n",
       " 'values',\n",
       " 'variable',\n",
       " 'variables',\n",
       " 'variance',\n",
       " 'ventral',\n",
       " 'version',\n",
       " 'volume',\n",
       " 'voxel',\n",
       " 'voxels',\n",
       " 'vtk',\n",
       " 'ways',\n",
       " 'we',\n",
       " 'web',\n",
       " 'weight',\n",
       " 'were',\n",
       " 'where',\n",
       " 'who',\n",
       " 'windows',\n",
       " 'with',\n",
       " 'without',\n",
       " 'women',\n",
       " 'word',\n",
       " 'work',\n",
       " 'works',\n",
       " 'write',\n",
       " 'written',\n",
       " 'xorg',\n",
       " 'ylab',\n",
       " 'you',\n",
       " 'young',\n",
       " 'your',\n",
       " '가능',\n",
       " '강의',\n",
       " '개념',\n",
       " '개발',\n",
       " '객체',\n",
       " '결과',\n",
       " '계산',\n",
       " '과정',\n",
       " '과학',\n",
       " '관계',\n",
       " '관련',\n",
       " '교수',\n",
       " '교육',\n",
       " '구글',\n",
       " '구조',\n",
       " '그래픽',\n",
       " '기간',\n",
       " '기능',\n",
       " '기본',\n",
       " '기술',\n",
       " '는지',\n",
       " '다시',\n",
       " '대부분',\n",
       " '대출',\n",
       " '데이터',\n",
       " '동량',\n",
       " '드라이버',\n",
       " '디자인',\n",
       " '라는',\n",
       " '러닝',\n",
       " '리눅스',\n",
       " '메모리',\n",
       " '메소드',\n",
       " '명령',\n",
       " '명령어',\n",
       " '모델',\n",
       " '문제',\n",
       " '발생',\n",
       " '방정식',\n",
       " '버전',\n",
       " '법선',\n",
       " '법칙',\n",
       " '변수',\n",
       " '변화',\n",
       " '변환',\n",
       " '부분',\n",
       " '부팅',\n",
       " '분석',\n",
       " '비교',\n",
       " '사람',\n",
       " '사이트',\n",
       " '상관',\n",
       " '상황',\n",
       " '생성',\n",
       " '서비스',\n",
       " '설치',\n",
       " '세대주',\n",
       " '소스',\n",
       " '수준',\n",
       " '시간',\n",
       " '시스템',\n",
       " '시작',\n",
       " '신경망',\n",
       " '실행',\n",
       " '아니',\n",
       " '아닌',\n",
       " '아래',\n",
       " '언어',\n",
       " '없이',\n",
       " '여기',\n",
       " '연구',\n",
       " '영향',\n",
       " '예측',\n",
       " '옵션',\n",
       " '요청',\n",
       " '우리',\n",
       " '우분투',\n",
       " '윈도우',\n",
       " '유전자',\n",
       " '이름',\n",
       " '이상',\n",
       " '이야기',\n",
       " '인간',\n",
       " '인코딩',\n",
       " '일반',\n",
       " '적용',\n",
       " '전세',\n",
       " '접속',\n",
       " '정리',\n",
       " '정보',\n",
       " '종료',\n",
       " '지원',\n",
       " '진행',\n",
       " '처리',\n",
       " '청년',\n",
       " '최근',\n",
       " '출력',\n",
       " '코드',\n",
       " '코딩',\n",
       " '테스트',\n",
       " '파이썬',\n",
       " '파일',\n",
       " '파티션',\n",
       " '패러다임',\n",
       " '패키지',\n",
       " '페이지',\n",
       " '평면',\n",
       " '프로그램',\n",
       " '프로세스',\n",
       " '학습',\n",
       " '한글',\n",
       " '한지',\n",
       " '행동',\n",
       " '행렬',\n",
       " '화면',\n",
       " '회귀분석',\n",
       " '효과'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_topic_words = set()\n",
    "topic_vectors = []\n",
    "for info in my_tm_model.get_topics_info():\n",
    "    total_topic_words.update(info['topic_words'])\n",
    "    topic_vectors.append(info['topic_vector'])\n",
    "    \n",
    "my_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tm_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_model.get_topics_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_docs = [{'topic_num': 4, \n",
    "  'docs':[{'docs_id': 469, 'title':'aaaaaaaaaa'},\n",
    "          {'docs_id': 471, 'title':'aaaaaaaaaa'},\n",
    "         ]\n",
    " },\n",
    " {'topic_num': 6, \n",
    "  'docs':[{'docs_id': 469, 'title':'aaaaaaaaaa'},\n",
    "          {'docs_id': 471, 'title':'aaaaaaaaaa'},\n",
    "         ]\n",
    " }]\n",
    "\n",
    "topics_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  이전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0,2], [1,3], [2,4]])\n",
    "y=np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 2]\n",
      " [3 4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2],\n",
       "       [ 2,  6],\n",
       "       [ 6, 12]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(-1,1)*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2],\n",
       "       [1, 3],\n",
       "       [2, 4]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 2, 3, 4])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ravel(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 3, 2, 1, 0])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.flip((np.argsort(np.ravel(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'www.nytimes.com'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlparse(test_urls[0]).netloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://promotion.gmarket.co.kr/Event/CouponZone.asp'\n",
    "newspaper.urls.valid_url(test_urls[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 're' from '/home/lab13/anaconda3/envs/top2vec/lib/python3.6/re.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/lab13/anaconda3/envs/top2vec/lib/python36.zip',\n",
       " '/home/lab13/anaconda3/envs/top2vec/lib/python3.6',\n",
       " '/home/lab13/anaconda3/envs/top2vec/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/home/lab13/anaconda3/envs/top2vec/lib/python3.6/site-packages',\n",
       " '/home/lab13/anaconda3/envs/top2vec/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/lab13/.ipython']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = newspaper.Article(url)  # , language='ko'\n",
    "article.download()  # request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArticleException",
     "evalue": "Article `download()` failed with No connection adapters were found for ':/www.gmarket.co.kr' on URL :/www.gmarket.co.kr",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArticleException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-ebbb9c35d0bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/top2vec/lib/python3.6/site-packages/newspaper/article.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow_if_not_downloaded_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/top2vec/lib/python3.6/site-packages/newspaper/article.py\u001b[0m in \u001b[0;36mthrow_if_not_downloaded_verbose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mArticleDownloadState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAILED_RESPONSE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             raise ArticleException('Article `download()` failed with %s on URL %s' %\n\u001b[0;32m--> 532\u001b[0;31m                   (self.download_exception_msg, self.url))\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mthrow_if_not_parsed_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArticleException\u001b[0m: Article `download()` failed with No connection adapters were found for ':/www.gmarket.co.kr' on URL :/www.gmarket.co.kr"
     ]
    }
   ],
   "source": [
    "article.parse()\n",
    "article.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile('[a-z]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gmarket.co.kr', 'auction.co.kr', '11st.co.kr', 'coupang.com', 'tmon.co.kr', 'interpark.com', 'ssg.com', 'wemakeprice.com', 'danawa.com', 'yes24.com', 'amazon.com', 'ebay.com', 'amazon.co.jp', 'amazon.co.uk', 'ppomppu.co.kr']\n",
      "ParseResult(scheme='', netloc='', path='gmarket.co.kr', params='', query='', fragment='')\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "sensitive_webpage_dict = {\n",
    "    'Shopping': ['gmarket.co.kr','auction.co.kr','11st.co.kr','coupang.com','tmon.co.kr','interpark.com','ssg.com','wemakeprice.com','danawa.com','yes24.com','amazon.com','ebay.com','amazon.co.jp','amazon.co.uk','ppomppu.co.kr',],\n",
    "    \"OTT\": ['youtube.com','netflix.com','melon.com','afreecatv.com','pandora.tv','wavve.com','twitch.tv','gomtv.com','toptoon.com',],\n",
    "    \"SNS/Community\": ['dcinside.com','fmkorea.com','humoruniv.com','facebook.com','instagram.com', 'twitter.com'],\n",
    "    \"Cloud\": ['dropbox.com','drive.google.com',],\n",
    "}\n",
    "\n",
    "def check_sensitive_webpage(url, sensitive_webpage_types=None):\n",
    "    #assert isinstance(sensitive_webpage_types, collections.Iterable), \"sensitive_webpage_types should be iterable type\"\n",
    "    \n",
    "    if sensitive_webpage_types is None:\n",
    "        return False\n",
    "    else:\n",
    "        netloc = urlparse(url).netloc\n",
    "        for type in sensitive_webpage_types:\n",
    "            print(sensitive_webpage_dict[type])\n",
    "            print(urlparse(url))\n",
    "            if netloc in sensitive_webpage_dict[type]:\n",
    "                return True\n",
    "        return False\n",
    "            \n",
    "print(check_sensitive_webpage('gmarket.co.kr', ['Shopping']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResult(scheme='', netloc='', path='www.nytimes.com/2020/10/20/us/politics/stimulus-deal-mitch-mcconnell-nancy-pelosi.html', params='', query='action=click&module=Top%20Stories&pgtype=Homepage', fragment='')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlparse('www.gmarket.co.kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'www.gmarket.co.kr'\n",
    "scheme = newspaper.urls.get_scheme(url)\n",
    "if scheme is None:\n",
    "    scheme = 'http'\n",
    "source_url = scheme + '://' + newspaper.urls.get_domain(url)\n",
    "source_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResult(scheme='https', netloc='www.nytimes.com', path='/2020/10/20/us/politics/stimulus-deal-mitch-mcconnell-nancy-pelosi.html', params='', query='action=click&module=Top%20Stories&pgtype=Homepage', fragment='')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlparse(test_urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for url in test_urls:\n",
    "    urls_component.append()\n",
    "    \n",
    "urls_can_parse_df = pd.DataFrame(data=urls_component)\n",
    "urls_can_parse_df['can_parse'] = True\n",
    "urls_can_parse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "다음주시작&내년자격증 반"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "N35w21Ntfrn-",
    "1O4KVGGx-C8x"
   ],
   "include_colab_link": true,
   "name": "topic_modeling_hangil.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "top2vec",
   "language": "python",
   "name": "top2vec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04faad3665314772b0ce673c11846e84": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0fe26c0a5cab401496e73eba458f8418": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "129202303ac0438cbeec69f04e1d5406": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15141aab9362477f8e744a1a821e36fe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c3a667956d84dd4a343f59572cddf14": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_129202303ac0438cbeec69f04e1d5406",
      "placeholder": "​",
      "style": "IPY_MODEL_35d49c4d1040440d9ee9e5c71bbcfcc1",
      "value": " 363/363 [2:19:02&lt;00:00, 22.98s/it]"
     }
    },
    "208ab8fb8c684db893617675f1d16873": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2104b0d692904fb0a10744008a6111ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "318966561cfa49289d40a1ca334ca8ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_375e7569ca694499b9823489848314de",
      "placeholder": "​",
      "style": "IPY_MODEL_c77fcdce35714a5f81d517ebfc0b9b8a",
      "value": " 500/500 [02:25&lt;00:00,  3.44it/s]"
     }
    },
    "33f9184548404abca6b1a66933832038": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e42af7de27b4cb3868cac5b9789fd77",
       "IPY_MODEL_8c139055f79d4c6586b3f8a3b2f3bd47"
      ],
      "layout": "IPY_MODEL_b6f7511276d14f12bb484248be0202e4"
     }
    },
    "35d49c4d1040440d9ee9e5c71bbcfcc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "375e7569ca694499b9823489848314de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b086d4b2efe4f768a16f9c341b7e226": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53276b8e90884868be56d2468db2df20": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "565380ffc24840a4b145835ddbbac15a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5795b03651b44eb191a100983995469b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6372a2e3e3bb4ee1b3743c6dbd6de197": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f291ba4e3ee74aabaf3c902dd40d0fe3",
       "IPY_MODEL_318966561cfa49289d40a1ca334ca8ff"
      ],
      "layout": "IPY_MODEL_f8ddd7d347bb48f0b642759d45106614"
     }
    },
    "63adeffb86684943a2bd8cea2b9a65c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_956e6fc808f249e390b438c1fea99af9",
       "IPY_MODEL_9fb75f0165144e8eb9177b1a69fb093e"
      ],
      "layout": "IPY_MODEL_2104b0d692904fb0a10744008a6111ac"
     }
    },
    "683e6f34fa0846b6986fab71434327c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6a97ac676f364802acb5df32da0a96e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a4567c912feb4b03af8447d69285f294",
       "IPY_MODEL_1c3a667956d84dd4a343f59572cddf14"
      ],
      "layout": "IPY_MODEL_565380ffc24840a4b145835ddbbac15a"
     }
    },
    "8b5f74c491704f70987c194ee179a934": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c139055f79d4c6586b3f8a3b2f3bd47": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b5f74c491704f70987c194ee179a934",
      "placeholder": "​",
      "style": "IPY_MODEL_ec3d288b2251468c9892c6a2c07d5c79",
      "value": " 219454/219454 [00:35&lt;00:00, 6202.96it/s]"
     }
    },
    "91b78731517d4905a6276bce63e17a77": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93c90973af4a40ce93b844834a182f15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cbbb09787ab84b7e801103b33286abde",
       "IPY_MODEL_9813e30f4bac4621b6db34a98485b43a"
      ],
      "layout": "IPY_MODEL_3b086d4b2efe4f768a16f9c341b7e226"
     }
    },
    "956e6fc808f249e390b438c1fea99af9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_208ab8fb8c684db893617675f1d16873",
      "max": 219454,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eb7e80a40e5f45baaf621e65dccd9de4",
      "value": 219454
     }
    },
    "9813e30f4bac4621b6db34a98485b43a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15141aab9362477f8e744a1a821e36fe",
      "placeholder": "​",
      "style": "IPY_MODEL_ba9f5856b33a4de98ce91218a3d95e3a",
      "value": " 363/363 [18:32&lt;00:00,  3.06s/it]"
     }
    },
    "9e42af7de27b4cb3868cac5b9789fd77": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd59aae536134cb2b08b95346e87abd2",
      "max": 219454,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_04faad3665314772b0ce673c11846e84",
      "value": 219454
     }
    },
    "9fb75f0165144e8eb9177b1a69fb093e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fe26c0a5cab401496e73eba458f8418",
      "placeholder": "​",
      "style": "IPY_MODEL_5795b03651b44eb191a100983995469b",
      "value": " 219454/219454 [20:55&lt;00:00, 174.86it/s]"
     }
    },
    "a4567c912feb4b03af8447d69285f294": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53276b8e90884868be56d2468db2df20",
      "max": 363,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_be53806e30424e128886c9f945421872",
      "value": 363
     }
    },
    "a5f957ea413449bba27813a280a7d8d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b6f7511276d14f12bb484248be0202e4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba9f5856b33a4de98ce91218a3d95e3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be53806e30424e128886c9f945421872": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c77fcdce35714a5f81d517ebfc0b9b8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbbb09787ab84b7e801103b33286abde": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2627b781ac842b8917cbfc98c19df2b",
      "max": 363,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_683e6f34fa0846b6986fab71434327c1",
      "value": 363
     }
    },
    "d2627b781ac842b8917cbfc98c19df2b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd59aae536134cb2b08b95346e87abd2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb7e80a40e5f45baaf621e65dccd9de4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ec3d288b2251468c9892c6a2c07d5c79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f291ba4e3ee74aabaf3c902dd40d0fe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91b78731517d4905a6276bce63e17a77",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a5f957ea413449bba27813a280a7d8d0",
      "value": 500
     }
    },
    "f8ddd7d347bb48f0b642759d45106614": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
